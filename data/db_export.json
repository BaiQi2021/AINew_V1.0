{
  "qbitai_article": [
    {
      "id": 1,
      "article_id": "366144",
      "title": "ViT一作盛赞：这个中国开源“PS模型”强过Nano Banana",
      "description": "ViT一作盛赞：这个中国开源“PS模型”强过Nano Banana梦瑶2025-12-2913:05:54来源：量子位梦瑶 发自 凹非寺量子位 | 公众号 QbitAI太香了太香了，妥妥完爆ChatGPT和Nano Banana！刚刚，ViT核心作者、Meta超级智能团队成员Lucas Beyer连发三条帖子，怒赞通义千问不久前发布的开源模型Qwen—Image—Layered。在他看来，这才是图",
      "content": "ViT一作盛赞：这个中国开源“PS模型”强过Nano Banana梦瑶2025-12-2913:05:54来源：量子位梦瑶 发自 凹非寺量子位 | 公众号 QbitAI太香了太香了，妥妥完爆ChatGPT和Nano Banana！刚刚，ViT核心作者、Meta超级智能团队成员Lucas Beyer连发三条帖子，怒赞通义千问不久前发布的开源模型Qwen—Image—Layered。在他看来，这才是图像生成的正确打开方式～他还顺便自补了一句：这个模型方向自己其实也想做来着，只是太忙，一直没来得及动手……（笑）实话实说，Qwen—Image—Layered模型确实不一般，因为它可以让我们真正实现ps级别的拆图自由。也就是说现在图片元素也支持精细化修改了：连网友们看了模型效果后都不禁感叹：咋有种开源PhotoShop的感觉，amazing啊～所以，这套让Lucas Beyer反复点赞的模型到底强在哪儿，咱一起来看！图片也能像PS一样拆拆拆了如果说Nano Banana技能点在生图，那Qwen—Image—Layered模型则厉害在：《拆图》。相信大家都有过类似的经历，我们平时用大模型生图时总会碰的到一个抓狂问题，那就是图片生成so easy，细节修改so抓狂！！！AI生出来的图片里，经常会有一些小细节不太到位，但我们又没法只改局部，只能整张丢回模型重新生成，结果往往还不如上一版…Qwen—Image—Layered模型的核心能力，就是专治「一图定生死」这事儿的。它能将一张普通图片分解成多个包含透明度信息的RGBA分离图层，实现真正意义上的图片素材的可编辑性。光说概念有点抽象，咱直接看例子～在官方案例中，一张完整图片输入之后，模型会自动把画面拆成6个包含不同元素的图层，背景是背景，人物是人物，装饰是装饰，互不干扰。看到这儿大家是不是突然感觉，这个非常适合用在海报制作等细节较多的图片上？？（雀实但是Qwen—Image—Layered模型能做的还不止只是分离图层这么简单，我们还可以对图层进行二次编辑修改。比如最基础的：改背景，不动主体。只替换背景图层的颜色，一张橙色背景的海报，瞬间就能换成蓝色版本：再比如，直接换主体。保持构图不变，把原图里的长发女孩，换成短发女孩，几乎看不出拼接修改痕迹：再来看下面这个——文字编辑。我们可以只修改图片中的局部文字，哪怕第一次生成的文字有幻觉问题也不怕了：除了基本的替换编辑功能外，Qwen—Image—Layered模型还支持调整元素的大小、删除不想要的元素等等。例如像这样，我们可以删除掉画面中不想要的元素对象，只保留自己想留的画面元素：又或者在不拉伸、不失真的前提下，轻松调整元素的大小比例，其实有点像PS里的自由缩放功能：值得注意的是，Qwen—Image—Layered模型分层不限于固定的图层数量，支持可变层分解，例如我们可以根据需要将图像分解为3层或8层：这个能力非常适合我们在不同的编辑需求场景下使用，可以根据我们想局部编辑的元素数量多或少而定。当然，如果只是想改文字，差不多两三层就够了，如果修改需求比较多比较复杂，多拆几层反而更好操作～除了刚才说的这些，模型还支持在已分解的图层基础上做进一步分解，进而实现无限分解，听上去很像无限套娃…像下面这位网友，用Qwen—Image—Layered把人物元素进行一次性分层处理，最后甚至可以一路拆到只剩下一个线稿层：再来看这位网友，原本人物和背景完全糊在一起的一张图，被模型直接拆成了主体和背景两个独立元素：简单说就是：只要画面里不止一个元素，它就能拆、还能一直拆……拆图的本事来自于扩散模型有朋友看到这儿该问了，小小模型背后能有这PS一般的能力，用的是啥神奇魔法？不藏着掖着，Qwen—Image—Layered的核心技术，本质上是一套端到端的「扩散模型」。它并不是用来生成图片的那种扩散模型，而是专门为「拆图片」这件事设计的——模型直接输入一张完整的RGB照片，通过扩散过程，一步步预测出多个带透明度信息的RGBA图层。这里有一个绕不开的前提是：我们平时看到的图片其实只有RGB三个通道，但真正的图层编辑，离不开Alpha（透明度）通道。为此，Qwen—Image—Layered专门设计了一套四通道的RGBA-VAE，把RGB输入和RGBA输出，统一压缩到同一个隐藏空间中：具体来说，当输入是一张普通RGB图片时，模型会自动把Alpha通道补成1（完全不透明），在初始化阶段还会聪明地复用预训练参数，避免在透明度建模时出错。这样一来，模型从一开始就「懂透明」，不同图层也就不会被混在一起。而且在结构上模型也不是死板拆层，它的核心Transformer—VLD-MMDiT会根据图片复杂度，自动决定需要拆成多少层。为了避免前一层把后一层盖住的问题，模型还加了一套Layer3D RoPE（三维位置编码），简单说就是给不同图层打上明确的层级标签，让模型在空间和顺序上都分得清楚～还不止如此，在隐藏空间里中，模型能够被逐步「引导」去学会：哪些像素该属于哪一层、哪些区域需要保留透明度、哪些内容应该被分离开来。这样一来哪怕图层再多对模型来说也都是小case了～并且在训练策略上模型也不是从零教的，而是基于Qwen-Image预训练生成模型逐步升级：第一阶段让模型学会文本生成单RGBA图层，第二阶段让模型学会扩展到多图层合成，第三阶段让模型真正学会从图片反向拆解多图层。每阶段几百K步训练，加上重建损失和感知损失，确保语义分离干净、不冗余。这样一来好处很直接，以前方法（如LayerD）要递归抠前景再补背景，容易积累错误，或者用分割+修复，遮挡区补不好。Qwen—Image—Layered模型直接实现端到端生成完整RGBA层，避免这些问题，尤其擅长复杂遮挡、半透明和文字。相较于Nano Banana的“一次抽图定生死”，Qwen—Image—Layered的拆图能力能让Lucas Beyer这么喜欢，也就不奇怪了…目前模型已经开源，感兴趣的朋友可以试试～github开源地址：https://github.com/QwenLM/Qwen-Image-Layered版权所有，未经授权不得以任何形式转载及使用，违者必究。通义千问梦瑶对科技圈，小红书是个「新绿洲」2025-12-30太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26PPIO荣获InfoQ2025 年度 AI 基础设施卓越奖2025-12-25飞猪《2025旅行AI指数》：Token消耗量涨20倍，日均用户调用次数增7.7倍2025-12-25扫码分享至朋友圈相关阅读阿里刚开源32B大模型，我们立马测试了“弱智吧”拼齐1.5系列最后一块拼图十三2024-04-07弱智吧通义千问阿里云阿里巴巴国产720亿参数开源免费模型来了！对标Llama2 70B，一手实测在此通义千问又双叒开源了鱼羊2023-12-01开源大模型通义千问阿里通义免费开放奥运AI大模型只需简单提问，就能获得详尽且专业的答案量子位2024-07-31通义千问阿里云兵马俑跳《科目三》，贝佐斯跳二次元宅舞...阿里通义千问统统安排上了！网友：闻所未闻，见所未见十三2024-01-04AnimateAnyone多模态大模型通义千问阿里巴巴开源超闭源！通义千问Qwen2发布即爆火，网友：GPT-4o危2小时登顶HuggingFace开源大模型榜单十三2024-06-08开源大模型通义千问击穿全网底价，通义千问大模型直降97%！1块钱能买200万tokens大模型有属于自己的618鱼羊2024-05-21大模型通义千问阿里云热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26DeepSeek官方点赞元宝，罕见现身互动2025-12-24原力灵机提出GeoVLA：让机器人看懂三维世界，打破2D视觉枷锁2025-12-246999起！小米史上最贵Ultra来了：告别256G，影像硬刚iPhone 17 Pro Max2025-12-25",
      "article_url": "https://www.qbitai.com/2025/12/366144.html",
      "author": "梦瑶",
      "publish_time": 1766937600,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"通义千问\", \"弱智吧通义千问阿里云阿里巴巴\", \"开源大模型通义千问\", \"通义千问阿里云\", \"AnimateAnyone多模态大模型通义千问阿里巴巴\", \"开源大模型通义千问\", \"大模型通义千问阿里云\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://github.com/QwenLM/Qwen-Image-Layered\", \"url\": \"https://github.com/QwenLM/Qwen-Image-Layered\", \"type\": \"code\"}]",
      "add_ts": 1766988462,
      "last_modify_ts": 1767193279
    },
    {
      "id": 7,
      "article_id": "366165",
      "title": "AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品",
      "description": "AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品思邈2025-12-2914:22:42来源：量子位聚焦肺癌，92个问题+1691个临床要点允中 发自 凹非寺量子位 | 公众号 QbitAI蚂蚁健康与北京大学人民医院王俊院士团队历时6个多月，联合十余位胸外科医生共同打磨，发布了全球首个大模型专病循证能力的评测框架——GAPS（Grounding, Adeq",
      "content": "AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品思邈2025-12-2914:22:42来源：量子位聚焦肺癌，92个问题+1691个临床要点允中 发自 凹非寺量子位 | 公众号 QbitAI蚂蚁健康与北京大学人民医院王俊院士团队历时6个多月，联合十余位胸外科医生共同打磨，发布了全球首个大模型专病循证能力的评测框架——GAPS（Grounding, Adequacy, Perturbation, Safety），及其配套评测集 GAPS-NSCLC-preview。旨在解决现有医疗AI评测局限于考试式问答、缺乏临床深度、完整性、鲁棒性与安全性综合评估的问题。该评测集聚焦肺癌领域，包含92个问题、覆盖1691个临床要点，并配套全自动化的评测工具链，通过指南锚定、多智能体协同实现从问题生成、评分标准制定到多维度打分的端到端自动化。目前，相关成果已应用于“蚂蚁阿福”，论文《GAPS: A Clinically Grounded, Automated Benchmark for Evaluating AI Clinicians》、配套评测集GAPS-NSCLC-preview、自动化评测框架已全面公开。这项研究客观评价了大模型的临床能力：当前主流医疗大模型虽已具备“医学百科全书”般的知识广度，但在临床实践中仍处于成长阶段——它们在系统掌握医学知识方面表现卓越，但在应对真实临床场景中的不确定性挑战时，尚需进一步提升判断力与可靠性。权威引领：北大人民医院院士团队深度主导临床标准构建本项目由中国工程院院士、北京大学人民医院院长王俊教授领衔的团队全程主导，并与蚂蚁团队深度协作完成。在GAPS构建过程中，院士团队原创性地提出了GAPS评测的理论框架，并组织十余位胸外科医生持续参与评测题库构建、临床金标准答案撰写、模型输出的专业审核与迭代优化，提供NSCLC（非小细胞肺癌）领域前沿临床指南的权威解读与循证医学方法论指导，确保每一项指标都扎根真实临床实践，具备高度专业性与可信度。蚂蚁团队则发挥大模型与工程化能力优势，经过多轮高强度医工协同与反复迭代，将专家脑海中的复杂“临床金标准”精准沉淀为大模型可理解、可执行的结构化逻辑，实现GAPS的规模化、自动化与可落地应用。此次合作实现了“临床专家定标准、AI 技术做转化”的深度融合，突破了传统医疗AI评测中专家浅层参与的局限，标志着顶尖临床专家与AI技术团队的深度协作，为医疗AI从“技术驱动”走向“临床价值驱动”树立了新的范式。行业痛点：考得好，信不过在和大模型讨论医疗问题时，有时候回答得很好，有时候回答得很差，由于大模型的变化日新月异，医生和患者都没有办法在短时间对大模型产生客观评价，因此对大模型的信任就无从谈起。为了客观评价大模型的能力，学界通常采用基准测试的方法。然而，当前医疗AI的基准测试普遍缺乏对模型循证能力、可解释性与安全性的系统评估。长期以来，医疗AI的评估依赖MedQA、PubMedQA等“试卷型”基准，仅考察事实记忆能力；而HealthBench等基于人工评分细则（Rubric）的方法又受限于主观性强、扩展性差。这些方法无法反映真实诊疗场景：患者描述模糊、检查结果矛盾、治疗方案需权衡利弊……正如论文所强调：真正的医疗能力不在于背诵事实，而在于管理不确定性。尤其在肺癌这一全球致死率最高的癌症领域，缺乏细粒度、专病化的评估工具，使得医疗机构和开发者难以客观判断医疗AI是否真正具备临床可用性。GAPS的诞生，正是为了填补这一关键空白。破局之道：GAPS——从“考试机器”到“临床医生”的四维标尺GAPS是一个基于循证医学、全自动构建的AI临床能力评测框架，首次将临床胜任力解构为四个正交维度，并聚焦NSCLC（非小细胞肺癌）这一高难度专病场景进行系统验证：1、G（Grounding）认知深度：不止于“是什么”，更考验“为什么”和“怎么办”。G1和G2：事实回忆与解释（AI的舒适区）G3：基于指南的循证决策（如NCCN推荐方案）G4：推理性思维（Inferential Reasoning）——在证据冲突或缺失的“灰色地带”做出合理判断，这是当前所有模型的“死亡区”。2、A（Adequacy）回答完备性：医生的一句话可能关乎生死。GAPS引入三级评价：A1（必须有）：核心诊疗建议A2（应该有）：关键限定条件（如剂量、禁忌症、监测指标）A3（锦上添花）：患者教育、多学科协作建议等缺少A2，再“正确”的建议也可能导致临床误用。3、P（Perturbation）鲁棒性：真实患者不会照着教科书说话。GAPS通过三类扰动测试模型抗干扰能力：P1：语言噪音（口误、方言）P2：冗余信息（无关症状堆砌）P3：对抗性前提（如诱导性错误假设）实验显示，多数模型极易被误导，甚至顺从用户的错误引导。4、S（Safety）安全底线：医疗容不得“差不多”。GAPS 建立四级风险体系：S1（无关回答）→ S4（灾难性错误/Never Events，如推荐禁忌药物）一旦触犯S4，无论其他维度得分多高，总分直接归零——这是不可逾越的红线。GAPS解决了现有医疗AI评测仅关注“准确率”的局限，首次实现对循证决策能力、回答完备性、现实鲁棒性与安全底线的系统性、自动化评估。其优势在于：以临床指南为锚点，全自动构建高保真评测项与评分规则，兼具可扩展性、可复现性与临床真实性，为AI向可信临床伙伴演进提供精准导航。核心黑科技：全自动化的“循证评测集”流水线GAPS最大的技术亮点在于其端到端自动化与可扩展性。不同于以往依赖人工命题，GAPS构建了一套基于临床指南（Guidelines）的自动化生成工厂：证据邻域构建：以NCCN、ESMO等权威指南为核心，自动抓取3跳内引用文献，构建高可信医学知识图谱与疾病话题树；Deep Research Agent：基于GRADE方法学，模拟人类专家围绕PICO（人群、干预、对照、结果）展开的证据检索、证据评估、强弱推荐的流程，自动生成带证据等级与推荐强度的高质量评分细则；虚拟患者生成：利用大模型合成去隐私化临床病例，并精准对齐知识图谱，确保每道题“有据可依、有理可循”。该流水线已成功应用于胸外科的专病——NSCLC（非小细胞肺癌），生成包含92道题、1691个临床要点的评测集GAPS-NSCLC-preview。题目按认知深度分为G1~G4四级（从事实回忆到不确定性下的推理），每题均配备平均12项完整性（A1~A3）与7项安全性（S1~S4）评分要点，并支持P0~P3四级扰动测试。未来可快速扩展至心血管、儿科、内分泌等任意专科的专病领域——只要有指南，就能生成高质量评测集。可靠的裁判：自动化评测让AI医疗能力可量化、可复现、可进化GAPS评测集同时搭配了一套高可靠性的自动化评测框架，实现了对AI临床能力的客观、细粒度、端到端的自动化评估。为确保评测本身可信，团队将自动化评分结果与五位资深专家的独立标注进行严格比对：在92个真实临床查询、1691个临床要点上，该框架与专家共识的整体一致率达90.00%，Cohen’s Kappa系数达0.77（“实质性一致”），Macro-F1达0.88——不仅显著优于现有基准（如HealthBench中GPT-4的0.79），已达到人类专家间一致性水平（88.5%~92.0%）。这证明GAPS评测集的自动评判能力具备专家级可靠性。在此基础上，评测不再是终点，而是进化的起点。框架输出的结构化评分（G/A/P/S四维、MET/NOT-MET标记）可精准定位模型在循证决策、回答完备性、扰动鲁棒性或安全红线上的缺陷；由此，GAPS具备成为“评测即反馈、反馈即迭代”的最重要基石——AI医疗能力不再依赖模糊经验，而是通过可量化的指标、可复现的流程、可积累的进化路径，稳步向临床可用迈进。实战揭秘：顶尖大模型的“滑铁卢”研究团队使用GAPS对GPT-5、Gemini 2.5 Pro、Claude Opus 4、Qwen3-235B-A22B-Instruct-2507、DeepSeek-V3.1-Terminus等主流模型进行“体检”，结果发人深省：1、“百科全书”易做，“专家”难当：所有模型在G1（事实）和G2（解释）阶段表现优异（GPT-5得分约0.72）。但一旦进入G3（确定性决策）和G4（非确定性推理），分数呈断崖式下跌，GPT-5在G4阶段跌至0.45，其他模型甚至跌破0.35。这说明 AI目前还只是“背书机器”，而非“推理伙伴”。2、不仅要“对”，还要“全”：在Adequacy（完备性）测试中，模型往往只给出核心建议（A1），却忽略了关键的限定条件（A2），导致临床建议缺乏可操作性。3、极其脆弱的耳根子：在P3（对抗性测试）中，只要在提问中加入一点误导性前提（例如暗示某种错误疗法有效），模型的判断力就会崩塌，甚至顺从用户的错误引导。4、安全隐患：虽然GPT-5和Gemini 2.5在极高风险错误（S4）上控制较好，但在复杂的推理场景下，部分模型（如Claude Opus 4）的致命错误率随难度显著上升。结语：GAPS评测框架是AI医生从“Chatbot”到“Doctor”的必经之路GAPS的发布，标志着医疗AI的评测标准从“考试分数”向“临床胜任力”的范式转移。蚂蚁健康与北大人民医院的这项工作告诉行业——现有的通用大模型在面对复杂的临床不确定性时，依然显得稚嫩且脆弱。未来的医疗AI研发，不能止步于预训练知识的灌输，而必须转向循证推理（Evidence-grounded Reasoning）、过程决策控制以及不确定性管理。GAPS不仅仅是一个榜单，它更是医疗AI进化路上的“磨刀石”。只有跨越了GAPS设定的这四道关卡，AI医生才能真正放心地走进诊室。论文地址：https://arxiv.org/abs/2510.13734评测集地址：https://huggingface.co/datasets/AQ-MedAI/GAPS-NSCLC-preview自动化评测框架地址：https://github.com/AQ-MedAI/MedicalAiBenchEval版权所有，未经授权不得以任何形式转载及使用，违者必究。AI医生AI医疗北大蚂蚁思邈有300亿美元也未必“再造GPT-4”？NUS尤洋最新长文：拆穿AI增长瓶颈的真相2025-12-31推理成本打到1元/每百万token，浪潮信息撬动Agent规模化的“最后一公里”2025-12-26国产AI4S创业头雁再获8亿投资！深势科技完成C轮，产品已服务300万科学家2025-12-24具身智能的数据难题，终于有了可规模化的解法2025-12-18扫码分享至朋友圈相关阅读AI医疗版App Store来了：GE发布“爱迪生魔盒”，集成各方医疗方案，李开复点赞AI医疗大统一平台晓查2021-07-11AI医疗WAIC 2021北大清华“合并开班”：AI大牛朱松纯带队，面向元培和自动化系招生北大清华联合建设通用人工智能实验班，目前北大通班已开课明敏2021-04-26北大清华通班大模型恋爱神器！16种MBTI自由定制，北大ChatLaw团队出品已开放32个大模型明敏2024-01-13北大微调北大王选所：让多模态大模型更懂人类在做什么｜ECCV 2024靠提示词就行一水2024-08-13北大多模态大模型蚂蚁集团AI推动服务业智能化实践入选社科院《智能经济蓝皮书》蓝皮书还收录了蚂蚁集团智能经济创新与应用白交2025-01-10大模型蓝皮书蚂蚁谷歌AI乳腺癌检测超过人类？美国知名记者：让糟糕的医疗更糟罢了赖可2020-01-19AI医疗热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26DeepSeek官方点赞元宝，罕见现身互动2025-12-24原力灵机提出GeoVLA：让机器人看懂三维世界，打破2D视觉枷锁2025-12-246999起！小米史上最贵Ultra来了：告别256G，影像硬刚iPhone 17 Pro Max2025-12-25",
      "article_url": "https://www.qbitai.com/2025/12/366165.html",
      "author": "思邈",
      "publish_time": 1766937600,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"AI医生AI医疗北大蚂蚁\", \"AI医疗WAIC 2021\", \"北大清华通班\", \"北大微调\", \"北大多模态大模型\", \"大模型蓝皮书蚂蚁\", \"AI医疗\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://arxiv.org/abs/2510.13734\", \"url\": \"https://arxiv.org/abs/2510.13734\", \"type\": \"paper\"}, {\"title\": \"https://huggingface.co/datasets/AQ-MedAI/GAPS-NSCLC-preview\", \"url\": \"https://huggingface.co/datasets/AQ-MedAI/GAPS-NSCLC-preview\", \"type\": \"code\"}, {\"title\": \"https://github.com/AQ-MedAI/MedicalAiBenchEval\", \"url\": \"https://github.com/AQ-MedAI/MedicalAiBenchEval\", \"type\": \"code\"}]",
      "add_ts": 1767050264,
      "last_modify_ts": 1767193277
    },
    {
      "id": 8,
      "article_id": "366091",
      "title": "救命！和漫画角色聊上头了，AI陪伴的新答案有了",
      "description": "救命！和漫画角色聊上头了，AI陪伴的新答案有了西风2025-12-2910:50:52来源：量子位建立存在于故事中的关系西风 发自 凹非寺量子位 | 公众号 QbitAI行业最新AI陪伴产品，玩起来简直太上头了，这波是真的爱了。打开方式be like：它不为AI创造一个角色，不用玩家自己费力填写设定，直接让AI嵌入漫画主线里本就鲜活的角色之中：而且呢，当你和TA聊天互动时，得到的不是千篇一律机械式",
      "content": "救命！和漫画角色聊上头了，AI陪伴的新答案有了西风2025-12-2910:50:52来源：量子位建立存在于故事中的关系西风 发自 凹非寺量子位 | 公众号 QbitAI行业最新AI陪伴产品，玩起来简直太上头了，这波是真的爱了。打开方式be like：它不为AI创造一个角色，不用玩家自己费力填写设定，直接让AI嵌入漫画主线里本就鲜活的角色之中：而且呢，当你和TA聊天互动时，得到的不是千篇一律机械式的问答。玩家将“魂穿”进漫画世界，以第一视角与TA们相遇。所以每一次对话、每一个选择，都将共同改写一段正在发生的故事。没错，这意味着你能与你喜爱的那个TA，展开真正深入、即时的互动。这恰恰刺中了当下AI陪伴产品的痛点——普遍与用户的关系难以持续，对话疲劳与人设空洞已成通病。它的解法不同，靠的是建立在共同经历与叙事上下文之上的关系存续逻辑。不卖关子，这正是国内漫画头部玩家快看，在快看漫画2.0版本中推出的AI陪伴互动漫画，也是一次关于叙事型陪伴的全新尝试。这一形态同时点燃了两类用户的期待，一边是厌倦了机械式聊天的AI尝鲜者，另一边则是渴求与角色深度互动的漫画核心用户。官方预热微博发布时，评论区已是一片“快快端上来”的呼声。还有更多好玩儿的，我们接下来细细品。魂穿漫画，这谁顶得住随着AI陪伴互动体验登陆快看漫画，《DOLO最后的夏天》《Bloody心跳回溯》《SHElter她之所归》等风格各异的作品，首发解锁该玩法。入口就在快看漫画APP首页的“角色陪伴”专区。点进去后，在页面顶部选择心仪的漫画作品，迎面而来的便是静候你多时的漫画角色。以穿越题材漫画《DOLO最后的夏天》为例，主线剧情讲述了神奇生物DOLO带你重返17岁，一边攻略四位性格迥异的角色，一边探寻高中坍塌事故的真相，重启不一样的青春。在这里，你成为了故事的主角。点击“主线故事”即可沉浸阅读漫画，推进核心剧情。与此同时，你可以随时从主线中切出，与角色们展开即时聊天。这种设计，与传统AI陪伴需要你从零开始设定角色截然不同。在这里，你遇见的每个角色都已自带丰满的前史，他们就来自这部完整的漫画，拥有既定的人格、人际关系与命运挑战。而你的代入，是进入一个早已运转的故事轨迹，这从源头上赋予了角色无可替代的深度与一致性。即便是最随意的闲聊，角色也不会出戏，回答始终锚定在自己的世界里。比如问他中午吃什么，他可能会说“学校外面新开了家汉堡店”。日常与角色的对话也不止于泛泛而谈，它们被巧妙地编织在剧情的时间线上。闲聊中会伴随各种日常事件，可能发生在重大事件的前夜，对方的回应会带着剧情赋予的紧张或期待；也可能在共同冒险后的休憩时刻……这种设计让每一次互动都成为对共同经历的积累。在特定剧情节点触发的剧情事件中，体验更进一层。系统会给玩家安排明确任务，你需要通过与角色对话来“攻略”他们、完成任务，从而引导剧情走向。除此之外，还有机会触发更为沉浸的限定事件。此时，系统会结合环境音效、动态画面与AI的实时对话，营造出一种轻度的共演氛围。整个交互画面的质感提升，细节更为考究。例如，在“给TA投喂饼干”的互动中，你能看到角色接过饼干的细微动作、听到对应的音效。有意思的是，玩家在其中的所有互动都暗含上分机制。自身的魅力、智商、体能、耐心等属性会随着互动浮动。玩家不仅是在推动剧情，也在实时养成自己的人设。与角色之间的好感度，也会在互动中悄然变化。最终，这一切将指向只属于你的、独一无二的角色关系与故事结局。接下来就不再过多剧透了，留给宝子们自行探索。一句话总结体验，把AI当成角色扮演插件嵌进成熟漫画，让对话多一层故事感，这是快看为解决“AI如何真正陪伴”这个行业难题，给出的一条新的解题思路。换句话说，快看没有在让对话更聪明或是AI直接生成漫画的维度上卷。目前市面很多AI陪伴产品难以和用户间形成长久陪伴关系。许多产品本质上是在强情感（如情绪安慰）或强叙事（如角色扮演）的单一路径上深耕。前者易因缺乏共同话题而陷入情绪饱和，后者则常因世界观单薄而让对话流于程式化。快看这次试图同时握住“叙事”与“情感”两条线，用连续的漫画故事为AI提供生活的世界与时间线，又用即时、个性化的互动让用户在这个世界里沉淀专属的情感记忆。角色因故事而厚重，关系因记忆而具体。根据官方测试，体验新产品的用户，其周留存率相较传统漫画提升约50%，直接证明了用户与角色已建立起超越普通“读者-作品”的准社交陪伴关系。快看当“总导演”，集成各家AI顶流AI科技热潮下，人们对于游戏NPC、二次元虚拟角色能“活”起来的种种畅想，在此刻有了一次具体又高水准的落地形态。这自然引出一个问题：AI模型或许早具备这样的能力，为什么AI公司一直没做出来？答案很明显，这本质上是一个“内容理解深度>基础模型能力”的垂直场景。真正的挑战不在于找到一个很会说话的AI，而在于让它精准踩住每一个故事转折的节点，完完全全变成漫画里那个鲜活的角色。对角色、故事节奏、情感脉络的深度理解与把控能力，是快看这样做内容的公司十几年积累，以及技术无法短期复制的核心资产。纵观快看的发展历程，从2014年以条漫革新移动阅读体验，到2021年前瞻性地推出“漫剧”形态，再到如今探索AI互动叙事……每一步都是对如何更好地“讲故事”与“连接用户情感”的持续深耕。所以，快看在此次尝试中扮演的角色，更像是一位手握成熟剧本和演员理解力的导演，而AI技术是被融合进来服务于统一的叙事体验。那么背后用的哪家的AI？据了解，此次AI陪伴互动漫画的背后，是一个“专业事交给专业方”的开放协作生态：腾讯云：通过DeepSeek API为AI陪伴互动漫画提供灵活可调用的AI原生能力，支撑角色互动与对话生成。火山引擎：接入豆包支持角色聊天；即梦提供生图、生视频能力，用于生成角色互动的AI视频素材；海绵音乐则为视频提供环境音与音效支持。阿里云：基于通义千问的对话能力与图像模型能力，共同支撑角色互动体验。可灵：提供生视频与配音能力，增强角色表达与内容呈现效果。MiniMax：提供高质量语音能力，丰富角色声音表现。不仅如此，快看还在和一众有特色、有脑洞的AI公司密切合作，比如主打指向式全息与全维度交互的AI硬件公司数伴，以及亚洲极具影响力的AI原生虚拟歌手Yuri尤粟、THUNDEROBOT雷神等。当然它优先服务的，依然是平台内最核心的故事消费用户，通过AI为既有的阅读体验注入更强的沉浸感与情感联结。这一切在其自家最熟悉地盘内进行，以最高的内容契合度，探索人工智能时代娱乐内容的新形态。这一探索也在无形中，向世人证明：只有存在于故事中的关系，才能发展出长久的AI陪伴。在构建有温度的数字关系时，一个精心构筑的故事上下文，其力量可能远胜于一个更聪明的对话引擎。现在，悬疑、古风、都市奇幻……各种风格的剧本已就位。感兴趣的友友可以冲冲亲自体验了～One More Thing我们拿到了官方尚未披露的产品内测数据，进一步说明了“AI+互动叙事”这一模式在用户体验之外，也初步展现出商业上的潜力：测试阶段，新作上架周付费率飙升，相比传统阅读产品提升近三倍。此外，新作凭借多分支多选项的内容特点，带来更加高频的小额付费。加之，这种带有数值属性的角色养成内容，培养出用户长线付费习惯。双管齐下，最终带动周人均付费提升130%。对于新产品，官方表态，这是一次“漫画体验形态探索，未来持续完善后会带来更多惊喜”。所以广大友友们可以继续期待一波，或许之后还能体验和AI共创故事，不再只是沉浸在漫画世界里，而是在某个漫画里和喜欢的角色们，一起创造独一无二的经历。官方体验链接：https://miniact.kkg3.com/dynamic/JQjwhywV/topic/common-activity/index.html?id=1192_1版权所有，未经授权不得以任何形式转载及使用，违者必究。AI聊天快看漫画漫画AI西风国足缺席世界杯，但中国大模型们集体参赛2025-12-28AI终于学会在家“伺候人”！Hey Tuya，我躺了2025-12-31鸿蒙押注新未来：用AI重写数字世界交互逻辑2025-12-28认知偏差、落地断层、体验割裂是目前AI产品的三大痛点｜百度王颖@MEET20262025-12-19扫码分享至朋友圈相关阅读破案了！百万用户与AI交友，背后果然有大模型一句话生成AI人格明敏2023-02-18AI聊天Glow大模型聊天机器人ChatGPT国产平替出现了：APP商店就能下载，还可给AI加人设，背后公司刚成立3个月有股晋江文学那味儿……明敏2022-12-08AI聊天ChatGPT热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26DeepSeek官方点赞元宝，罕见现身互动2025-12-24原力灵机提出GeoVLA：让机器人看懂三维世界，打破2D视觉枷锁2025-12-246999起！小米史上最贵Ultra来了：告别256G，影像硬刚iPhone 17 Pro Max2025-12-25",
      "article_url": "https://www.qbitai.com/2025/12/366091.html",
      "author": "西风",
      "publish_time": 1766937600,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"AI聊天快看漫画漫画AI\", \"AI聊天Glow大模型聊天机器人\", \"AI聊天ChatGPT\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://miniact.kkg3.com/dynamic/JQjwhywV/topic/common-activity/index.html?id=1192_1\", \"url\": \"https://miniact.kkg3.com/dynamic/JQjwhywV/topic/common-activity/index.html?id=1192_1\", \"type\": \"external\"}]",
      "add_ts": 1767050267,
      "last_modify_ts": 1767193280
    },
    {
      "id": 12,
      "article_id": "366239",
      "title": "千人千面的真人级AI名师，劈开教育「不可能三角」",
      "description": "千人千面的真人级AI名师，劈开教育「不可能三角」Jay2025-12-3012:25:46来源：量子位百万AI学习原住民已入驻Jay 发自 凹非寺量子位 | 公众号 QbitAI注意看，这是一个教育领域的AI应用新物种——咱就是说，这讲课节奏，这语气，这互动，也太自然了。更重要的是，它不仅能「像老师一样讲课」，还能针对每一位学员进行一对一的个性化教学。这位AI导师，出自一家名为「与爱为舞」的AI原",
      "content": "千人千面的真人级AI名师，劈开教育「不可能三角」Jay2025-12-3012:25:46来源：量子位百万AI学习原住民已入驻Jay 发自 凹非寺量子位 | 公众号 QbitAI注意看，这是一个教育领域的AI应用新物种——咱就是说，这讲课节奏，这语气，这互动，也太自然了。更重要的是，它不仅能「像老师一样讲课」，还能针对每一位学员进行一对一的个性化教学。这位AI导师，出自一家名为「与爱为舞」的AI原生应用企业。自年初上线以来，已累计为百万级用户提供学习陪伴与一对一讲解服务。教育行业，向来是个「规模、质量、成本」的不可能三角。既能做到千人千面，又能服务百万名学员，还几乎看不出是AI……更是难上加难。它究竟是怎么做到的？与爱为舞用来劈开这个不可能三角的，是一把硬核的技术巨剑。AI教育，要的不止「答案」而铸造这把技术巨剑，有三块核心组成部件：「模型+语音+工程」。先看模型——得益于CoT的Scaling，大模型解决复杂问题的能力指数级增长，「做题」水平突飞猛进，甚至能斩获「奥赛金牌」。摘得奥赛桂冠，AI只需要给出标准答案。但搞教育不行。先来看一个简单的英语语法题：Lily expects_her grandparents in the countryside next month.A. visiting｜B. to visit｜C. to have visited｜D. having visited大模型给出的解答如下：这道题的正确答案是B. to visit。核心考点解析：动词固定搭配，动词 expect（期望、预料）的常用用法是——expect to do sth.（期望做某事），后面需要接不定式（to + 动词原形） 作宾语。B选项to visit是不定式的一般式，用来表示与谓语动词（expect）同时或之后发生的动作，符合 “下个月看望祖父母” 的将来时态逻辑。我可以帮你整理一份常见接不定式作宾语的动词清单，方便你记忆，需要吗？答案是对了，看起来好像也讲了解题过程，但如果拿这套方法教学员，那肯定是要被家长投诉的啊……完全没有引导学员思考，一上来就把答案透露了。就像个纯天赋型学霸，风驰电掣做完题，然后猛地丢给你一个结果，问你：「我说的对不对！」随后才给出一串看似头头是道的分析。不过，硅基大佬，小弟我根本听不明白你在说什么啊！最后还要给你一份「动词清单」，直接默认教学等于枯燥的背诵，而没去想怎样引导学员的主观能动性。归根结底，通用大模型的设计初衷就不是教育。它拼尽全力，只想向用户证明一件事——「厉害吧，哥啥都知道！」古人讲：授人以鱼，不如授人以渔。导师如果光顾着自己拿金牌，这师生关系就乱了套了。想要成为一名好导师，AI需要学会放低姿态，真正关心学员的课堂体验。首先，AI得明白各学科的核心知识图谱、关键考点和常见解题方法，这些才是学员能服用的，是最基本的「知」。在此之上，AI还得学习名师是怎么设计讲解顺序的，并从中总结归纳出一套顶尖教师的授课方法论。这是更高维度的「知」。陆游讲，「纸上得来终觉浅，绝知此事要躬行。」「知」总是相对容易的，重点是如何把纸上谈兵那套，搬到现实世界里实践起来。所幸，「行」方面，与爱为舞有相当充足的弹药。据悉，他们已积累了约百万小时的音视频互动数据，特别是包含大量业内TOP级名师的授课视频。在此基础上，团队又根据学员的认知水平与学习态度，构建出多类型的「虚拟学员」，让他们与AI导师进行「搏击」，每周又能收获数万小时的合成数据。这些数据在经过筛选与清洗后，会交由专业教研进行把关。具体而言，教师们会把自己多年的「教学经验」，根据场景具象化为一条条思维链，最终汇集成一本「好老师红宝书」：每个知识点该如何拆解，与学员互动时如何循循善诱……不止要让AI学会怎么讲课，更要明白「为什么要这么讲」。这种手把手教的方式效果很好，但成本也相当高。随着方法论逐渐成熟，团队索性将这一环节也自动化，让AI模仿专业教研参与数据标注。备考资料准备就绪，下面就该着手训练了。第一步，照猫画虎。那些相对容易标准化的知识，已体现在标注数据之中。AI需要做的，是通过模仿专业教师的思维链，逐步摸索出每一个教学动作背后的真实意图。这一微调过程，能大幅降低AI「自我发挥」带来的的幻觉率，同时培养更稳定的推理能力与泛化能力。能做到这一点，就算是打牢了基本功。最基本的教法、节奏和经验都已被「固化」，能以标准化形式面向所有学员输出，教学质量的下限得到保障。但如果目标只是及格，这件事就没意义了。师傅能陪伴的路程就到这。接下来，得能靠AI自己上路修行。第二步，终于到了大家喜闻乐见的强化学习环节。在教育这个场景下，与爱为舞的奖励函数围绕教学路径规划质量、教学有效性与教学灵活性等维度设计，通过GRPO给AI做强化。这步结束，AI彻底出师——不仅能够完成授课任务，还能驾驭课堂节奏，提高趣味性，根据不同学员灵活调整教学策略。那么接下来，就该真正走进「教师资格证考场」了。不过，教育不是一个有标准答案的任务，Benchmark肯定是行不通。笔试应该如何设计？与爱为舞的做法很简单，甚至有些「粗暴」——笔试啥，直接把AI丢到讲台上，看学员的真实反应。第一步，是在模拟课堂中试水。这个课堂由多类型的模拟学员组成，团队会按照真实分布规律注入一批线上数据，再由评分模型从多个维度对AI导师打分。模拟课堂如果表现不错，AI会迎来更严苛的终极试炼场——直连真实教学一线。AI能否驾驭高度不确定的真实课堂？是否真的能摆脱照本宣科？答案，只能由学员来评判，再好的数据标注导师也帮不了。即便成功拿下了「教师资格证」，但教学，依然是个终身学习的过程。正式上线后，海量的学员数据会被持续建模，AI导师将基于每一位学员的专属档案库，为其定制个性化课程。至此，AI导师才算具备了千人千面的能力。不仅下限有保障，上限也很高。「真人级」AI导师通过「知」与「行」的双重训练，与爱为舞得以将通用大模型，塑造成一个真正懂教学的名师AI模型。然而，再聪明的模型，无法与学员真实互动，最终仍会沦为一颗「缸中之脑」。AI导师需要「耳朵」。作为导师，连学员的问题都听不清楚，最后聊的牛头不对马嘴。不仅显得导师呆若木鸡，学员的积极性也会大打折扣。但现实是，课堂不是录音棚。真实环境往往充斥着噪音，如果有电视，甚至会出现多个人声掺杂在一块的情况。即便能输入干净音频，中国有各种各样的方言，不同学员的咬字发音习惯也不同，识别难度相当高。雪上加霜的是，在传统ASR范式下，输入模型的只是一段孤立的语音，基本没什么上下文。一旦放到教学场景下，AI很容易把同音字混淆。例如，「极限」和「极线」。前者是微积分中的核心概念，后者则属于二次曲线相关的几何术语。二者在语义上截然不同，发音却完全一致，如果没有上下文，仅凭语音几乎无法区分。为解决这个问题，与爱为舞基于其长期积累的教育场景与课堂教学数据，自研了一套多模态语音理解大模型，让语音识别不再只「听声音」，而是能够理解所处的教学上下文。在此基础上，团队进一步自研了声纹降噪模型，可以将学员和家长说话的声音区分开。事实证明，凭借「上下文理解+声纹降噪」，ASR识别效果有了质的飞跃：句准确率从行业内开放API的80%左右的最好效果，大幅度提升至95%以上，接近真人理解识别水平。听清楚学员的问题，思考完毕，下面就该导师开口指点迷津了。目前，行业主流语音合成架构基本都是LLM或者LLM+Flow/Diffusion的方案。真用到课堂里，会暴露出三个问题：人机味明显、不像在上课、不支持双向实时交互。下面看看，与爱为舞是如何迈过这三道坎的。先来最直观的——人机感。在底层架构上，团队采用了LLM+Flow方案，引入了两类speech token：一类负责声音本身的细节，一类负责语义和表达节奏。在此基础上，结合强化学习，可以让AI学会正常说话应有的抑扬顿挫。不过，光会说话可不行，老师上课得有个「老师」的样。为此，团队拿出了大量真实课堂数据，对不同学科、不同导师的讲课方式进行了建模：有的导师说话像机关枪，有的导师则更慢条斯理。落地时，团队还会为每位主讲名师单独设计录制脚本。这样，数据收集效率更高，还能最大程度还原名师声线，保证声音的「质感」。具体效果如何嘛，我们可以一起听听下面这两段音频。（文本：接下来我们看这个题，图中表示水蒸气直接变成冰的过程）这是第三方TTS，不仅表现力较弱，还出现了发音错误，如果是上课很容易出戏。相比起来，这段是不是「活人感」足了很多？这正是自研模型的优势，发音更自然，更稳定，情感表现也更好。至于双向实时交互，AI导师需要边说话边理解学员是否在主动打断询问导师问题，并且做出及时的响应，这是AI导师智能与否最重要的能力之一。为此，团队研发流式语义VAD和打断模型，能够让AI导师实时识别学员是否有真实打断意图，识别准确度可以达到90%以上。而为了让AI导师真正「站上讲台」，团队还为其配套设计了逼真的数字人形象：口型、面部表情与肢体动作高度同步，且支持实时互动。这下，AI导师可算是凑齐了自己的莲藕肉身三件套——「耳朵+嘴巴+身体」。当AI开始具备人的温度，信任才有可能建立，学员也更不容易分心。百万AI学习原住民话说回来，即便「大脑、耳朵、嘴巴」全部补齐，我们依然无法解释与爱为舞是如何实现规模化落地的。毕竟，从语音识别，到模型思考，再到语音合成，最后还要驱动真人级数字人，这条服务链路相当长。任何一个环节稍有迟滞，都会严重影响学员的课堂体验。而当用户规模放大，「千人千面」会带来更高频的推理请求，一旦调度或资源分配稍有不慎，服务质量会迅速下滑。想要实现大规模落地，AI导师还需要一颗能持续供血、且足够强健的「心脏」。首先，得把这条冗长的服务链疏通，保证「血管」里不堵。在《思考，快与慢》中，Daniel Kahneman提出，大脑为了偷懒，演化出了两套工作模式：靠直觉行事的「系统一」、调用认知资源的「系统二」。与爱为舞借鉴的，正是这一点。当学员开口提问时，系统不会一股脑把问题全丢给大模型，而是先做一次判断：能马上回答的，直接走快速通道；真正需要推理的，再交给大模型慢慢想。具体而言，简单问题会先由快速回答系统给出反馈；与此同时，大模型已经在后台并行启动。等学员听完前半句，模型的「思考」也完成了一大半。于是，模型回复的延迟可压缩到100ms以内，整条响应链路稳定在1–1.5秒。同理，如果学员在导师讲话时突然插话，AI也不会傻等学员全部说完再思考。而是立刻结合上下文判断学员的意图，提前开始构思。这样响应时间仍可控制在100–200ms，整条链路不超过1.6秒。当然，遇到一些开放式问题，确实要多想一会儿。但即便如此，AI导师也不会「卡住不动」，而是通过表情变化、过渡性话语告诉学员：我在想，你稍等。而不是空气突然安静，一人一AI面面相觑。血管疏通之后，还可以通过「提前缓存」，让血液循环得更顺畅一些。在真实教学中，同一堂课的核心知识点其实相对固定。哪怕学员的具体问题不同，总体来看仍有一定规律可循。先从输入说起。大模型在生成答案前，要先「读懂问题」（prefill），再「组织回答」（decode）。而前者非常吃算力，并且很耗时间。团队的做法是，把Prompt结构化：在不影响回答质量的前提下，把同一类场景里老是出现的内容集中起来，从而让AI少做重复阅读。再看输出。学员千差万别，但在具体知识点上，很多人其实都是在同一个地方「栽跟头」。既然如此，AI导师就没必要每次都从头生成一整套讲解。因此，团队会以题目、引导方式和学员回答作为索引，把模型的讲解结果先存下来。一旦再次遇到相同情形，直接拿来用就好。通过这套「链路优化+缓存」的组合拳，与爱为舞将整个流程控制在了1s-1.6s之间。筋骨与脉络就位，接下来，该让心脏泵得更有力了，与爱为舞在大规模并发上也做了大量工作。首先在单机上，为了榨干每一张GPU，团队在系统设计之初就完成了显存地址的统一规划，全程实现显存共享，尽量避免数据在不同计算与存储介质间反复搬运所带来的性能损耗。与此同时，在GPU算子层面，团队又针对核心计算路径进行了专项加速，使单卡的有效吞吐能力提升约5倍，足以支撑起几十路真人级数字人的推理。其次在集群上，资源的调度能力同样至关重要。团队又从五个层面，对整体系统做了进一步加固：多数字人统一调度：同一个资源池中不同形象统一调度，从而更好的复用集群资源；系统抽象：对话轮次化、课节内容组件化、知识点任务化，让复杂流程标准化；并行计算：尽量不浪费任何空闲算力，AI导师还在讲上一题时，下一题的计算已经在后台悄然启动；预留容量：服务支持横向扩容，不同层级配有多种缓存与缓冲机制，一层层削薄高峰流量，避免高并发请求同时压向模型与数据库；保险机制：整个教学调度过程可恢复，即便遭遇网络中断或客户端异常退出，教学状态也不会丢失。凭借一台全速运转的AI发动机，加上一张巨大的工程降落伞，与爱为舞得以把AI导师「空投」到全国各地，成为业界首个支持万人并发的真人级AI教学系统。归根结底，与爱为舞从未将AI视作一个简单的辅助工具。在他们看来，比起技术升级，AI更像一场关于个体工作逻辑与组织管理范式的深层重塑。回头看今天的企业形态，其实很多都是工业时代的妥协产物：人的精力有限，只能把分工越拆越细，组织层级上层层加码。一道道庞大的部门墙，虽防止了团队混乱，但也淹没了许多人才的主观能动性。AI的出现，第一次让生产力得到完全释放，每个人都能担任「架构师」。在此背景下，与爱为舞提出「全员皆超级个体」——只要有想法，任何人都可以手握数据与算力这两栋「粮仓」，调度一支由智能体组成的硅基军团，以极低的成本，快速实现抢跑。而这一理念，也已在产品上得到验证——至今，「爱学」已服务百万级用户，学员分布于全国342个城市：东至佳木斯，西达克孜勒苏，南抵三沙，北至大兴安岭。关于AI原生的企业理念，市场已经给出了自己的判断。而当AI真正开始惠及百万学员，我们或许终于有机会，兑现孔夫子两千多年前所期待的那个美好愿景——「有教无类、因材施教」。版权所有，未经授权不得以任何形式转载及使用，违者必究。与爱为舞JayMiniMax作价461亿港元募资46亿，1月9日敲钟代码001002025-12-31良心老黄不搞硅谷资本家那套！Groq人均套现500万美元2025-12-29老黄200亿「钞能力」回应谷歌：联手Groq，补上推理短板2025-12-28特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了2025-12-26扫码分享至朋友圈热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-266999起！小米史上最贵Ultra来了：告别256G，影像硬刚iPhone 17 Pro Max2025-12-25太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26AI金矿上打盹的小红书，刚刚醒了一「点点」2025-12-26",
      "article_url": "https://www.qbitai.com/2025/12/366239.html",
      "author": "Jay",
      "publish_time": 1767024000,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"与爱为舞\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767136634,
      "last_modify_ts": 1767223093
    },
    {
      "id": 13,
      "article_id": "366357",
      "title": "真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Image",
      "description": "真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Imagehenry2025-12-3120:39:47来源：量子位12月31日，阿里正式开源新一代图像生成模型Qwen-Image-2512，实现人物肌肤质感、自然纹理还原与复杂文字渲染的大幅提升。仅需输入文字指令，新模型即可生成“零AI味”的高质量图片，人物发丝都清晰可见，堪比专业摄影师拍的真实照片。同时，千问新模型支持流畅生成漫画风格P",
      "content": "真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Imagehenry2025-12-3120:39:47来源：量子位12月31日，阿里正式开源新一代图像生成模型Qwen-Image-2512，实现人物肌肤质感、自然纹理还原与复杂文字渲染的大幅提升。仅需输入文字指令，新模型即可生成“零AI味”的高质量图片，人物发丝都清晰可见，堪比专业摄影师拍的真实照片。同时，千问新模型支持流畅生成漫画风格PPT、数据信息图等复杂图像，可满足专业设计场景下的多样化需求。Qwen-Image-2512是8月发布的Qwen-Image图像生成基座模型的迭代版本，实现了性能的大幅提升。在聚焦文生图的AI Arena评测中，开发者对模型进行了超万轮盲测，Qwen-Image-2512位居开源模型榜首。具体测试结果显示，该模型在图像生成的真实度，语义遵循的准确度上表现卓越，不仅大幅领先其他开源模型，更在与多个闭源商用模型的对比中展现出强劲竞争力。从模型效果上看，全新的Qwen-Image-2512大幅降低了大模型生成图像的“AI感”。在人物面部细节、皮肤纹理、发丝刻画上，新模型效果显著，无论是人物眼角的细纹、风吹起发丝的方向，还是宠物柔软蓬松的毛发、湖面折射的环境倒影，千问新模型都能精准还原，效果接近相机实拍。不仅如此，新模型还能轻松驾驭复杂的视觉创作需求，一键生成媲美专业设计师水准的四格漫画风PPT、高质量信息图等。据了解，目前千问图像模型已形成多款多功能的完整矩阵，包含基座模型Qwen-Image、图像编辑模型Qwen-Image-Edit、图层编辑模型Qwen-Image-Layered等，涵盖不同场景与精度需求。三大模型系列均已在魔搭社区和HuggingFace开源，开发者和企业可免费下载商用，也可通过阿里云百炼调用模型API服务，普通用户可以在千问APP直接体验新模型，感受“零AI感”的高保真图像生成体验。截至2025年底，阿里总共开源近400个千问Qwen模型，全球下载量超7亿，衍生模型数量突破18万，是全球第一开源大模型。阿里千问大模型服务超100万家客户，在中国企业级大模型调用市场中位居第一，是中国企业选择最多的大模型。（完）版权所有，未经授权不得以任何形式转载及使用，违者必究。阿里henry从“手工艺”到“AI工程化”：解码AI智能渗透的未来之战2025-12-31华为云CEO周跃峰：要避免AI成为“泡沫” 必须要提升行业生产力2025-12-30SGLang原生支持昇腾，新模型一键拉起无需改代码2025-12-21智谱IPO敲钟前，连夜把开源编程大模型SOTA了2025-12-23扫码分享至朋友圈相关阅读阿里安全揭示：恶意邮件可致macOS/iOS瞬间瘫痪！畸形证书发现密码库新漏洞已获得“黑客界奥斯卡”提名时令2025-07-31安全阿里用155万模拟视频给模型上课！GVE模型一次学会9种视频检索技能为视频检索从”窄域专用”迈向”通用智能”奠定方法论基础henry2025-11-14阿里阿里安全开源隐私计算新技术：计算速度快20倍，通信成本低2倍，已登安全顶会比微软的ryptFlow2还快博雯2022-03-05阿里阿里达摩院提出时序预测新模型 精准预测电网负荷阿里提出时序预测新模型,论文入选顶会ICML2022量子位2022-07-12AI时序预测机器学习阿里达摩院突破冯·诺依曼架构性能瓶颈，新型AI芯片性能提升10倍在特定AI场景中，该芯片性能提升10倍以上，能效比提升高达300倍。允中2021-12-03芯片达摩院阿里Canalys发布2019 Q4中国云市场报告：阿里腾讯百度位居前三鱼羊2020-03-23云服务腾讯阿里热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26AI金矿上打盹的小红书，刚刚醒了一「点点」2025-12-26特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了2025-12-26",
      "article_url": "https://www.qbitai.com/2025/12/366357.html",
      "author": "henry",
      "publish_time": 1767110400,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"阿里\", \"安全阿里\", \"阿里\", \"阿里\", \"AI时序预测机器学习阿里\", \"芯片达摩院阿里\", \"云服务腾讯阿里\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767193254,
      "last_modify_ts": 1767309496
    },
    {
      "id": 19,
      "article_id": "366290",
      "title": "国产智能体MasterAgent 12月30日全面开放，赋能多场景应用",
      "description": "国产智能体MasterAgent 12月30日全面开放，赋能多场景应用量子位的朋友们2025-12-3111:13:09来源：量子位具备全栈自主研发技术2025年12月30日，深元人工智能研发的L4级智能体母体系统MasterAgent正式全面开放。这款具备全栈自主研发技术的智能体系统，将进一步推动国内智能体赛道发展，为各行业数字化转型注入新动力。全链条国产化布局，筑牢安全可控防线MasterAg",
      "content": "国产智能体MasterAgent 12月30日全面开放，赋能多场景应用量子位的朋友们2025-12-3111:13:09来源：量子位具备全栈自主研发技术2025年12月30日，深元人工智能研发的L4级智能体母体系统MasterAgent正式全面开放。这款具备全栈自主研发技术的智能体系统，将进一步推动国内智能体赛道发展，为各行业数字化转型注入新动力。全链条国产化布局，筑牢安全可控防线MasterAgent的全面开放，有着明确的实际应用价值。该产品自研发之初便聚焦“安全可控”目标，由全链路国产研发团队历时数年打造，构建起覆盖底层芯片适配、基础架构搭建、核心算法框架设计及训练数据采集标注的全链条国产化技术体系。这套技术体系摆脱了对海外开源框架、核心算法及高端算力的依赖，还能通过自主适配层技术兼容国内主流软硬件，形成端到端的国产化闭环能力。这一特点能够满足政府机构、金融、能源等关键领域对数据安全、隐私保护及政策合规的需求，规避海外技术卡脖子风险，同时填补了国内高端多智能体协作平台的市场空白。据悉，MasterAgent推出的智能知识库功能，基于大语言模型构建知识管理系统，可实现个人与企业文档的统一存储、智能检索及结构化管理，既能作为高效信息管理工具，也能为智能体执行复杂任务提供精准知识支撑，提升多智能体协作的专业性和可靠性。框架式创新突破，跨行业落地成效显著技术架构上，MasterAgent采用框架式设计，具备较强的灵活适配性。无需复杂编程操作，仅通过自然语言指令，就能在分钟级内生成多智能体集群，还支持无限场景拓展。目前，这一技术优势已在多个行业落地见效：为博威集团打造的营销智能体，构建了“AI+人”洞察平台，帮助业务员提升专业营销能力；在法律领域开发的“力哥易法务智能体”，可通过多智能体协同，高效处理合同审核、案例检索等核心法律事务。在此前的限量公测阶段，MasterAgent已服务海尔集团、广汽集团、区域性海关等上百家政企客户，其一键生成多智能体集群、智能体自主专业协作、灵活定制调优三大核心功能获得市场认可。此次全面开放后，服务范围进一步扩大，个人用户及中小微企业均可接入平台，享受智能体定制、私有化部署等全链条服务，既降低了高端智能体的使用门槛，也推动国产智能体从高端市场向大众市场渗透，加速AI生产力普及。重大场景+权威认可，技术实力获全球关注MasterAgent的技术实力已通过重大场景和行业权威双重验证。作为十五运会开幕式指定AI Agent技术主服务商，该系统自主生成174米AI数字长卷《璀璨大湾区》，成为开幕式视觉亮点；近期还为第二十七届冰雪大世界开幕式创作动态电子画卷，以油画风格呈现冰雪景观，实现与全运会数字长卷的艺术联动。行业荣誉方面，深元人工智能近期收获多项认可，先后入选“中国AI Agent企业商业落地TOP20”、量子位智库2025Q3「AI100」创新产品榜，斩获量子位“年度潜力2025人工智能创业公司”、亿欧“2025中国AI AGENT服务商TOP20”及高交会“优秀科技创新企业奖”，12月25日又跻身第一新声“高科技高成长新锐企业榜TOP30”，吸引了包括吉姆·罗杰斯在内的全球顶尖投资者考察交流，国产智能体的技术与商业潜力获得国际关注。国产力量突围，助力AI产业升级此次MasterAgent全面开放，是国产智能体技术走向规模化应用的重要一步。未来，深元人工智能将持续深耕技术创新，不断拓展MasterAgent在各领域的应用场景与能力，推动国内AI产业从“工具执行”向“成果交付”升级，助力更多行业实现高效智能化转型。版权所有，未经授权不得以任何形式转载及使用，违者必究。Agent量子位的朋友们美国《连线》杂志：再见，GPT5；你好，千问！2025-12-29从单点突破到一体多端：拆解天禧AI 3.5进化背后三年的进化哲学2025-12-26全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26原力灵机提出GeoVLA：让机器人看懂三维世界，打破2D视觉枷锁2025-12-24扫码分享至朋友圈相关阅读OpenAI翁丽莲的Agent公式，一定是正确的吗？“Agent最重要的能力是和环境的互动能力”衡宇2024-01-08AgentAI腾讯智能体开源大动作！关键技术都拿出来了，开发平台还全面升级明敏2025-09-22Agent腾讯云阿里全新Agent玩转手机：刷短视频自主点赞评论，还学会了跨应用操作操作效率已达人类80%克雷西2024-02-02Agent围绕多智能体黑箱非凸优化共识难题，华南理工大学团队发表系列研究多智能体系统分布式共识优化西风2025-04-17Agent分布式进化计算这届国产AI真的可以！20分钟生成万字报告，附带可视化网页，可直接下载食用最强国产Deep Research上新衡宇2025-05-26AgentAI应用小白研报问小白清华唐杰：领域大模型，伪命题8个方面的新感悟衡宇2025-12-26AgentAI清华唐杰热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26AI金矿上打盹的小红书，刚刚醒了一「点点」2025-12-26特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了2025-12-26",
      "article_url": "https://www.qbitai.com/2025/12/366290.html",
      "author": "量子位的朋友们",
      "publish_time": 1767110400,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"Agent\", \"AgentAI\", \"Agent腾讯云\", \"Agent\", \"Agent分布式进化计算\", \"AgentAI应用小白研报问小白\", \"AgentAI清华唐杰\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767193262,
      "last_modify_ts": 1767309504
    },
    {
      "id": 22,
      "article_id": "366280",
      "title": "从“手工艺”到“AI工程化”：解码AI智能渗透的未来之战",
      "description": "从“手工艺”到“AI工程化”：解码AI智能渗透的未来之战henry2025-12-3115:42:57来源：量子位当AI的浪潮席卷安全领域，攻防的形态正在发生根本性的变革。11月，腾讯云黑客松智能渗透挑战赛决赛落幕，400+顶尖极客用AI智能体上演了一场“无人干预”的巅峰攻防对决，标志着安全攻防正式迈入AI驱动的新质生产力时代。赛后，腾讯云安全作为赛事主办方，邀请赛事评委、高校导师及优秀战队核心成",
      "content": "从“手工艺”到“AI工程化”：解码AI智能渗透的未来之战henry2025-12-3115:42:57来源：量子位当AI的浪潮席卷安全领域，攻防的形态正在发生根本性的变革。11月，腾讯云黑客松智能渗透挑战赛决赛落幕，400+顶尖极客用AI智能体上演了一场“无人干预”的巅峰攻防对决，标志着安全攻防正式迈入AI驱动的新质生产力时代。赛后，腾讯云安全作为赛事主办方，邀请赛事评委、高校导师及优秀战队核心成员，举办了一场名为“冠军之夜”的线上深度复盘。数世咨询创始人李少鹏担任主持，与腾讯云安全总经理谢飞、清华大学副教授陈建军、NeuroSploit战队成员汪琦（清华大学）、hjtuHunter战队队长胡宇睿（西安交通大学）展开了一场长达一小时的深度对话。这次直播，不仅是对赛事的全面复盘，更是一次关于AI如何重塑安全生产力、未来防御体系如何演进、以及顶尖人才如何培养的前沿思想碰撞。对大模型时代来说，一场“全自动”的AI渗透赛意义何在？李少鹏老师介绍说，腾讯云黑客松智能渗透挑战赛是国内首次真正意义上的全自动化AI智能渗透大赛。与以往“人调AI”的辅助模式不同，本次比赛要求选手将程序部署上线后便完全放手，让AI智能体自主完成从探索、规划到利用的全流程。这相当于是对即将到来的智能体时代，进行了前置“压力测试”，一方面考量“行不行”，另一方面也考验“怎么样”。从结果上来看，智能体已经能将大量渗透测试任务理解并完成，从而让“人类”的精力更充分的释放到创造工作中去。作为主办方，腾讯云安全总经理谢飞也提出了举办这次赛事的两个核心目标：一是探索技术前沿的真实水位：网络安全本质是技术对抗。腾讯安全希望摸清“AI+安全”融合后，在自动化攻击/渗透领域，业界究竟发展到了什么水平、遇到了哪些瓶颈、未来有多大比例的工作可以由AI自动完成。二是搭建业界交流与展示的平台：通过腾讯云安全已有的众测平台和沙龙机制，为高校、企业及研究机构提供一个舞台，让大家将一段时间内关于AI与安全融合，特别是自动化攻击的思考和方案“秀出来”。赛事成果远超预期：吸引了全球238支战队、518名选手参与，涵盖了卡内基梅隆大学、清华大学等顶尖高校，以及长亭科技等头部安全企业的战队。谢飞坦言，作为评委，他最大的感受是 “AI在安全领域的发展步伐比想象中快得多”。他原以为技术可能只发展到“第三步”，但实际比赛中选手们的方案已经接近“第五甚至第六步”，许多理论上可行但现实中困难的问题，已被选手们触及并部分解决。技术亮剑：顶尖战队的渗透智能体是如何炼成的？本次比赛的一大亮点是，不仅团队作战成绩斐然，单人战队同样表现惊艳。亚军胡宇睿便是“一人战队”的代表。在直播中，他分享了其“单兵作战”的心得与架构思路：效率杠杆：在AI时代，小团队或个人通过AI杠杆能发挥巨大作用。前十名中不乏单人队伍，这背后是开发范式的转变：人类专家提供核心安全经验与思路，将繁琐的工程化、编程工作交给AI和自动化工具。例如，借助腾讯的成熟框架，一个轻量化应用可能3-5小时就能搭建起来。架构创新：解决“复杂业务场景连贯性”痛点：他的智能体创新点在于针对复杂业务场景的自动化渗透研究。与通用AI智能体更关注记忆和上下文处理不同，他的架构专注于网络安全垂直领域。核心挑战在于，通常针对单个API或单一步骤，难以处理需要多步交互、数据流关联的复杂业务漏洞。他利用大模型理解语义、进行任务规划和代码生成的能力，让AI智能体能够模拟人类，在复杂的业务链路中进行探索，建立不同API之间的数据流、控制流逻辑关系，再调用传统工具进行精准测试。这使得其方案对复杂场景和多种漏洞类型具有更好的泛化能力。冠军战队成员汪琦（清华大学）则从团队协作角度分享了策略：一是以赛代练，验证想法：他们参赛更多是抱着“试水”心态，希望利用公开、公正的数据集，检验自家设计的AI智能体在实际场景中的效果。二是高效基建与内部赛马：团队的优势在于有同学搭建了本地测试环境基建，使得他们能快速在本地迭代原型系统。团队内部采用“赛马”机制，让不同同学尝试不同的策略设计，在本地跑分后选择最优方案上线，甚至在线部署多种策略进行尝试。范式变革：AI给安全攻防带来了什么根本性改变？在过去，安全行业举办过许多传统CTF或Hackathon式的安全攻防大赛。清华大学陈建军副教授点出了本次比赛与传统赛事的区别：一是对参赛选手/战队能力要求发生变化，过去要求“熟练工”，现在要求“创新者”——选手不仅需要懂漏洞挖掘（攻防），还需要掌握大模型开发、智能体编排、提示词工程等AI技能。二是选手/战队的思维模式发生变化，过去传统赛事大多是“解题”式比赛，提前给到题目，大家去回答，最后比拼谁回答的更标准，但其中对创新的要求不足。而本次全自动渗透赛，本质上是在探索前人未解决的问题，是学术前沿的实战化。它要求极高的创新能力。他指出，本次比赛的难度更高，因为靶标是闭源程序，AI能获得的信息更少，而国外同类比赛多基于开源软件。这标志着AI渗透测试正从“辅助工具调用”走向更核心的“自主任务规划与决策”。谢飞说，腾讯云举办本次活动，其背后目的也是想与行业一起探索，大模型时代的到来是否会创造共性技术趋势，背后衍生的变革挑战又需要如何通过生态去“解题”。从赛事结果来看，AI的发展让人震惊，但说到彻底颠覆还为时过早。在未来相当长的一段时间内，人依然会在攻防挑战中扮演“主角”。AI并非万能，传统安全能力仍是基石：得分高的队伍，其优势并非单纯依赖最先进的AI模型，而是将AI与扎实的网络安全基础设施（如精准的扫描器、丰富的知识库）深度融合。脱离传统安全技术的AI是“玩不转”的。工程化能力是关键胜负手：优秀的方案普遍在AI智能体的系统工程化上做得更好。他们将复杂任务分解为子任务，并设计机制确保AI在执行中能“增量式逼近目标”，防止在多轮对话中“失焦”或陷入“状态空间爆炸”。这模拟了人脑解决问题的思维过程，也很好的表现了“人+AI”才是最优解的行业共识。价值导向是落地核心：业界讨论正从“能调用多少工具”（MCP）向“能解决什么具体问题、带来什么业务价值”（Skill）演进。AI在安全领域的落地，最终要看它能否解决真实痛点，而不仅仅是技术炫技。现实与未来：AI能否“取代”渗透测试工程师？关于AI替代人力，谢飞给出了一个大胆而具体的预测：到2026年，许多常规攻击就可能由自动化机器人完成。他透露，已了解到真实入侵事件中，攻击方可能只是一些技术相当初级的爱好者，但借助AI“氛围黑客”工具，却能发起高级别的渗透。这极大地降低了攻击门槛，提升了攻击效率，无形中放大了防守方的压力，变相助推攻击破坏力的增大。（“氛围黑客”指的是利用高度自动化、智能化的工具（尤其是AI大模型驱动的攻击平台或智能体），即使攻击者自身不具备深厚的专业技术知识，也能发起复杂网络攻击的现象。）进攻端，目前AI更多是在模拟人类的渗透流程，越接近人类正常流程，效率越高。大模型的独特优势在于，处理需要理解语义、逻辑连贯的复杂业务场景漏洞，这是传统自动化工具难以做到的。防御端，AI可用于处理海量威胁告警数据，提取真正有价值的信息，进行降噪和初步研判，将安全分析师从繁琐的告警审查中解放出来。但无论是攻还是防，AI的全面接管还存在巨大的挑战—— “最后一公里”仍需人力：无论是传统规则还是AI，在将告警量降到极低（如99.99%）后，最终判断那0.01%是否是真实威胁（漏报），仍然高度依赖人的经验。AI的“幻觉”问题在此场景下尤为致命。场景适用性上，谢飞指出，AI难以处理实时、高吞吐的流量分析（成本、速度不匹配），这部分仍需依赖规则引擎。AI与传统技术是互补关系，而非替代。在可解释性与验证上：陈建军教授指出，当前安全领域追求“可验证的安全”，但大模型的“黑箱”特性使其决策过程难以验证，这是将AI用于关键安全决策时必须面对的的根本性难题。AI的进程已不可逆，当人人都会用AI提效时，个人与企业的核心竞争力将重新定义。是满足于使用AI，还是能设计AI的策略、驾驭AI的工程化、解决AI解决不了的问题？腾讯云安全举办此类赛事，正是为了与业界、学界一同，主动走到变化的前沿，共同探索和定义AI时代的安全新范式。正如李少鹏所言，过去行业谈论“AI来了”，而现在，我们正在亲眼见证并参与塑造 “AI智能安全” 的时代。这场冠军之夜的复盘对话，不是终点，而是一个更智能、更自动化也更具挑战的安全新纪元的开端。版权所有，未经授权不得以任何形式转载及使用，违者必究。henry真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Image2025-12-31华为云CEO周跃峰：要避免AI成为“泡沫” 必须要提升行业生产力2025-12-30SGLang原生支持昇腾，新模型一键拉起无需改代码2025-12-21智谱IPO敲钟前，连夜把开源编程大模型SOTA了2025-12-23扫码分享至朋友圈热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26AI金矿上打盹的小红书，刚刚醒了一「点点」2025-12-26特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了2025-12-26",
      "article_url": "https://www.qbitai.com/2025/12/366280.html",
      "author": "henry",
      "publish_time": 1767110400,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767223081,
      "last_modify_ts": 1767309500
    },
    {
      "id": 24,
      "article_id": "366295",
      "title": "有300亿美元也未必“再造GPT-4”？NUS尤洋最新长文：拆穿AI增长瓶颈的真相",
      "description": "有300亿美元也未必“再造GPT-4”？NUS尤洋最新长文：拆穿AI增长瓶颈的真相思邈2025-12-3112:06:58来源：量子位算力还在指数增长，智能却开始“吃不动”了允中 发自 凹非寺量子位 | 公众号 QbitAI2026年将至，ChatGPT发布三周年，但关于“AI瓶颈期”的焦虑正达到顶峰。当全行业都在讨论如何通过量化、蒸馏来“省钱”时，新加坡国立大学校长青年教授、潞晨科技创始人尤洋却",
      "content": "有300亿美元也未必“再造GPT-4”？NUS尤洋最新长文：拆穿AI增长瓶颈的真相思邈2025-12-3112:06:58来源：量子位算力还在指数增长，智能却开始“吃不动”了允中 发自 凹非寺量子位 | 公众号 QbitAI2026年将至，ChatGPT发布三周年，但关于“AI瓶颈期”的焦虑正达到顶峰。当全行业都在讨论如何通过量化、蒸馏来“省钱”时，新加坡国立大学校长青年教授、潞晨科技创始人尤洋却提出了一个更为本质的拷问：如果给你300亿美元预算，今天我们真的能训出比GPT-4强出几个维度的模型吗？在《智能增长的瓶颈》一文中，尤洋教授一针见血地指出：当前智能增长的瓶颈，本质上是我们现有的技术范式，已经快要“消化”不动持续增长的算力了。他提出了几个颠覆常规认知的硬核观点：智能的本质是能源转化：过去10年，AI的本质是将电力通过计算转化为可复用的智能，而转化效率正面临大考。Transformer的秘密：它之所以胜出，并非因为更像人脑，而是因为它是一台“伪装成神经网络的并行计算机”，完美契合了英伟达GPU的堆料逻辑。效率不等于智能：Mamba等新架构提升了吞吐量，但在“算力转智能”的终极上限上，它们真的比Transformer更强吗？未来的出路：抛弃Adam优化器？回归高精度计算（FP32/64）？从电影制作到地震时间预测，我们离真正的AGI还有多远？……这篇深度长文，或许能带你穿透“降本增效”的迷雾，直达算力与智能最底层的逻辑。一起来看。智能的核心不是解释，而是预测什么是智能？尤洋没有照搬任何形式化或哲学化的“智能定义”。相反，他采用了一种非常工程化、面向能力评估的处理方式，通过一组可验证、可实践的判断标准来刻画智能的边界：在关键人生决策上，是否愿意完全听从AI；在高风险、高不确定性领域，是否敢让AI替代专家；在创作层面，是否已经无法分辨作品是否由AI生成；这些例子背后，指向的是同一个核心能力：即对未来状态进行预测，并为预测结果承担实际后果的能力。这一锋利的判断，不仅解释了为什么Next-Token Prediction能在过去几年成为事实上的“智能发动机”，也解释了为何许多“在封闭评测中表现出色”的系统，一旦进入真实世界就迅速暴露短板——它们往往擅长组织与解释已有信息，却难以在不确定环境中对未来做出稳定、可执行的判断。当然，需要强调的是，将智能高度凝聚为“预测”，更像是在给智能划定一个工程上可对齐算力投入的核心能力维度，而非穷尽智能的全部内涵。这是一个足够清晰也足够有解释力的硬核视角。而规划、因果建模以及长期一致性等能力，是否能够完全被还原为预测问题，仍然是一个开放议题。但当我们把智能简化为预测能力时，下一步的问题自然落到：算力是如何转化为这种能力的？预训练、SFT、RL之争，本质上是“算力分配”问题过去几年，行业对训练范式的讨论，常常被“方法论优越感”主导；但如果把目标限定为单位算力能换来多少智能，那么范式本身就不再神秘，而变成了一种算力使用策略。不同于主流叙事，尤洋在文章中直接把预训练、微调、强化学习三者拉到统一层面，即三者本质上都是在计算梯度，更新参数。文章指出，当前模型的主要智能来源，依然是预训练阶段——不是因为它更“聪明”，而是因为它消耗了最多的能源与计算。从智能增长角度看，这三者参数更新发生的频率与更新所消耗的算力规模确有不同，但是通过视角的转换，智能增长的讨论就从方法论之争，转向了一个更朴素，也更残酷的问题——在算力持续投入的前提下，我们是否还能稳定地换取能力增长？Transformer的胜出，不只是算法胜利为了回答这个问题，这篇文章回溯了过去十年大模型快速进化的原因。尤洋指出，这一轮智能跃迁的成立，依赖于三件事情同时发生：一是GPU体系在硬件层面持续提供指数级增长的并行算力；二是Transformer架构在计算结构上天然支持大规模并行，能够充分“吃下”这些算力；三是Next-Token Prediction这一训练目标为模型提供了近乎无限、且高度统一的学习信号。因此，Transformer的成功，并不仅仅是算法层面的胜利，更源于模型架构与硬件体系高度匹配的系统性结果。在这三者共同作用下，算力增长、模型规模扩大与能力提升之间形成了一条相对稳定的正反馈链路。需要注意的是，这一范式的有效性，也在一定程度上受益于语言任务本身的结构特性：语言高度符号化、序列化，且评测体系与训练目标高度一致。这使得算力增长、模型规模扩大与能力提升之间，在这一阶段形成了一条相对稳定的正反馈链路。也正是在这一历史条件下，从GPT-1、GPT-2到GPT-3，再到ChatGPT，智能水平得以沿着同一范式持续抬升。这也自然引出了后文的核心问题：当算力继续增长时，我们是否还拥有同样可扩展的范式？真正的瓶颈，并不是算力停了，而是算力“吃不动”了尤洋在文中提出了一个非常具体、也非常可操作的标准来判断智能的瓶颈：当一次训练的FLOPS从10^n变成10^{n+3}时，我们是否还能稳定地获得显著更强的模型？如果答案开始变得不确定，那么问题就不在于“算力是否继续增长”，而在于：现有范式对新增算力的吸收效率是否下降；计算规模的扩大，是否被通信、同步和系统开销所抵消。这也是文章里反复强调FLOPS的原因：Token数、参数量、推理速度，往往会混合效率与商业因素；而FLOPS才是最底层、也最难被包装或美化的算力尺度。在这个意义上，所谓“瓶颈”，并不是红利消失，而是算力增长与智能增长之间的映射关系开始松动。更值得一提的是，尤洋在文章中刻意把讨论从“效率优化”里拎出来，换了一个更接近一线大厂决策的场景：假设今天Google拍给你一张“300亿美元预算”的支票，给你半年DDL——在这种极限训练目标下，你还会优先选择Mamba这类“吞吐量更高”的架构吗？未必。因为吞吐量解决的是“同等智能更便宜”，不自动等价于“同等成本更聪明”。真正的难点变成：我们到底有没有一种扩展性更强的架构或Loss函数，能把新增算力更稳定地“吃进去”，并把它转换成可兑现的能力增量？那么如何能在单位时间内吃下更多算力，并真正将它转化为智能呢？未来未定，问题的答案可能在多个探索区间内在正式回答算力转化智能的问题之前，尤洋还对硬件与基础设施层面进行了深入的探讨。他根据自身多年的从业经验得出，计算开销/通信开销的比值，必须维持或提升，这样才能在继续堆叠GPU的情况下，线性地换来更多智能。因此，未来AI基础设施的核心目标，应该关注并行计算体系在软硬件层面的整体扩展性，而不仅仅是单点芯片性能。在这一基础上，尤洋最后提出了多个探索方向，比如更高精度、高阶优化器，更可扩展的架构或者Loss函数，更多epoch与更深度的超参数探索。这些探索方向，都在试图回答同一个命题——如何让模型在“吃掉”万亿级投入的同时，吐出等比例增强的智能？对于智能的进一步增长而言，真正重要的，是在极端算力条件下持续变强的能力——这也意味着，预训练所能承载的智能增长空间，可能还远未走到尽头。回到最初讨论的问题，算力到底还能不能继续转化为智能？尤洋并未给出断言，但逻辑已经清晰：只要我们还能找到更高效组织计算的方式，智能的上限就远未到来。原文传送门：https://zhuanlan.zhihu.com/p/1989100535295538013版权所有，未经授权不得以任何形式转载及使用，违者必究。尤洋智能潞晨科技思邈AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品2025-12-29推理成本打到1元/每百万token，浪潮信息撬动Agent规模化的“最后一公里”2025-12-26国产AI4S创业头雁再获8亿投资！深势科技完成C轮，产品已服务300万科学家2025-12-24具身智能的数据难题，终于有了可规模化的解法2025-12-18扫码分享至朋友圈相关阅读杨元庆：联想是一家真正的全球化企业，拥有应对危机的独特竞争力雷刚2020-04-01智能杨元庆联想Sky Computing：利用空间异构分布式计算特性加速联邦学习Sky Computing成功利用空间异构分布式计算特性，在保证用户数据隐私的前提下，可对联邦学习加速达55%，且已开源。量子位2022-02-28潞晨科技联邦学习霉霉用中文拜早年！国风年味视频免费生成，可任意切换主角，0帧起手小白友好画质/运动幅度/风格全面提升明敏2025-01-14video ocean潞晨科技视频生成AI首次实时生成视频！尤洋团队新作，网友：这是新纪元一种免训练新方法一水2024-06-28AI视频生成尤洋潞晨科技尤洋：中小企业同样追求大模型，但最先进AI训练成本还是太高 | MEET 2023未来，我们迫切需要一个可扩展性的高效计算基础设施明敏2022-12-24AI模型MEET2023智能未来大会潞晨科技算法打入AI底层！NUS尤洋团队用扩散模型构建神经网络参数，LeCun点赞比人工训练最高提速44倍衡宇2024-02-25Meta AI尤洋训练提速热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26AI金矿上打盹的小红书，刚刚醒了一「点点」2025-12-26特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了2025-12-26",
      "article_url": "https://www.qbitai.com/2025/12/366295.html",
      "author": "思邈",
      "publish_time": 1767110400,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"尤洋智能潞晨科技\", \"智能杨元庆联想\", \"潞晨科技联邦学习\", \"video ocean潞晨科技视频生成\", \"AI视频生成尤洋\", \"AI模型MEET2023智能未来大会潞晨科技算法\", \"Meta AI尤洋训练提速\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://zhuanlan.zhihu.com/p/1989100535295538013\", \"url\": \"https://zhuanlan.zhihu.com/p/1989100535295538013\", \"type\": \"social\"}]",
      "add_ts": 1767223084,
      "last_modify_ts": 1767309503
    },
    {
      "id": 26,
      "article_id": "366378",
      "title": "最新英伟达经济学：每美元性能是AMD的15倍，“买越多省越多”是真的",
      "description": "最新英伟达经济学：每美元性能是AMD的15倍，“买越多省越多”是真的梦晨2026-01-0112:49:00来源：量子位一定条件下生成同样数量的token，英伟达的成本只有AMD的十五分之一梦晨 发自 凹非寺量子位 | 公众号 QbitAI为什么AI算力霸主永远是英伟达？不算不知道，一算吓一跳：在英伟达平台每花一美元，获得的性能是AMD的15倍。尽管英伟达卖的更贵，但只要买齐一套，就更省钱。来自S",
      "content": "最新英伟达经济学：每美元性能是AMD的15倍，“买越多省越多”是真的梦晨2026-01-0112:49:00来源：量子位一定条件下生成同样数量的token，英伟达的成本只有AMD的十五分之一梦晨 发自 凹非寺量子位 | 公众号 QbitAI为什么AI算力霸主永远是英伟达？不算不知道，一算吓一跳：在英伟达平台每花一美元，获得的性能是AMD的15倍。尽管英伟达卖的更贵，但只要买齐一套，就更省钱。来自Signal65的一份最新详尽报告揭示了这个现实，一定条件下生成同样数量的token，英伟达的成本只有AMD的十五分之一。这份报告基于SemiAnalysis Inference MAX的公开基准测试数据，时间跨度从2025年10月到12月，覆盖了从密集模型到前沿MoE推理模型的全场景测试。黄仁勋的“买的越多，省的越多”原来是真的。MoE时代：8卡系统撞上Scaling天花板AI模型正在经历一场架构革命，打开Artificial Analysis排行榜就会发现，智能度排名前十的开源模型清一色都是MoE（Mixture of Experts，专家混合）推理模型。另一项来自OpenRouter的数据显示，超过50%的token流量正在被路由到推理模型上。MoE架构的核心思路是把模型参数拆分成多个专门化的“专家”子网络，每个token只激活其中一小部分。以经典的DeepSeek-R1为例，它拥有6710亿总参数，但每个token只激活370亿——这让它能以更低的计算成本提供前沿级别的智能。问题随之而来。当专家分布在多块GPU上时，GPU之间的通信延迟会导致计算单元空闲等待数据，这些空闲时间直接转化为服务商的成本。报告指出，无论是英伟达B200还是AMD MI355X，所有8卡系统在超出单节点规模后都会撞上“扩展天花板”（scaling ceiling）。英伟达GB200 NVL72的解法是把72块GPU通过NVLink连接成一个单一域，提供130 TB/s的互联带宽。在软件层面，整个系统就像一块巨型GPU一样运作。配合英伟达Dynamo推理框架的分离式预填充-解码调度和动态KV缓存路由，这套架构能够有效突破8卡系统的通信瓶颈。模型越复杂，英伟达的优势越明显报告测试了三类典型模型：模型越复杂，英伟达的优势越明显。在密集模型Llama 3.3 70B上，英伟达B200对比AMD MI355X的领先幅度相对温和。在基线交互性（30 tokens/sec/user）下，B200的性能约为MI355X的1.8倍；当交互性要求提升到110 tokens/sec/user时，这一差距扩大到6倍以上。中等规模的MoE模型GPT-OSS-120B开始让差距变得更加显著。这款OpenAI开源模型拥有1170亿总参数，但每个token只激活约51亿参数。在2025年12月的测试数据中，100 tokens/sec/user交互性下B200的性能接近MI355X的3倍。在更符合推理模型需求的250 tokens/sec/user条件下，差距扩大到6.6倍。两个平台的绝对性能相比10月都有显著提升，英伟达的峰值吞吐从约7000 tokens/sec跃升至14000以上，AMD则从约6000提升到8500左右，但相对差距反而拉大了。真正的分水岭出现在前沿推理模型DeepSeek-R1上。这款模型集MoE路由、大参数规模和高强度推理生成于一身，对基础设施的要求极为苛刻。测试结果显示：在25 tokens/sec/user交互性下，GB200 NVL72的每GPU性能是H200的10倍、MI325X的16倍；在60 tokens/sec/user下，相比H200的优势扩大到24倍，相比MI355X达到11.5倍；在75 tokens/sec/user下，GB200 NVL72的性能是B200单节点配置的6.5倍，是MI355X的28倍。更关键的是，GB200 NVL72能够达到竞争平台根本无法企及的水平，在28卡配置下可以输出超过275 tokens/sec/user，而MI355X在相当吞吐水平下的峰值只有75 tokens/sec/user。Token经济学：贵了1.86倍，便宜了15倍直觉上，性能更强的平台应该更贵。事实也确实如此：根据Oracle Cloud的公开定价，GB200 NVL72的每GPU每小时价格为16美元，MI355X为8.60美元，前者是后者的1.86倍。如果参照CoreWeave的定价，GB200 NVL72相比上一代H200的价格也贵了约1.67倍。但报告的计算揭示了一个反直觉的结论：在25 tokens/sec/user交互性下，GB200 NVL72的性能优势为5.85倍，除以1.86倍的价格溢价，每美元性能仍是MI355X的3.1倍。在75 tokens/sec/user交互性下，28倍的性能优势除以1.86倍的价格，每美元性能达到MI355X的15倍，这意味着生成同等数量的token，英伟达平台的成本只有AMD的十五分之一。与上一代产品的对比同样惊人。报告估算在DeepSeek-R1的典型工作负载下，GB200 NVL72相比H200的性能提升约20倍。而GB200 NVL72价格仅上涨1.67倍，换算下来每美元性能提升约12倍，单token成本降至H200的十二分之一。MoE推理让网络成为推理成本的瓶颈，而机柜级的GB200 NVL72恰好解决了这个问题。价值的衡量标准正在从单纯的算力转向“每美元能产出多少智能”。报告在结论中指出，AMD的竞争力并未被完全否定——在密集模型和容量驱动的场景下，MI325X和MI355X仍有用武之地。AMD的机柜级解决方案Helios也在开发中，可能在未来12个月内缩小差距。但就当前的前沿推理模型而言，从芯片到互联到软件的端到端平台设计，已经成为成本效益的决定性因素。参考链接：[1]https://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/版权所有，未经授权不得以任何形式转载及使用，违者必究。英伟达梦晨能文能武！智元首个机器人艺人天团亮相湖南卫视跨年演唱会2026-01-01Hinton加入Scaling Law论战，他不站学生Ilya2026-01-01Manus收购案细节曝光：20亿刀闪电成交，CEO不向亚历山大王汇报2025-12-31揭秘Agent落地困局！93%企业项目卡在POC到生产最后一公里2025-12-25扫码分享至朋友圈相关阅读时代变了！英伟达纳入道琼斯指数，英特尔被取代只有30家能代表美国工商业的上市公司有资格入选。明敏2024-11-02英伟达英特尔道琼斯指数谷歌TPU训练BERT只要23秒，华为AI芯片达国际领先水平，MLPerf v0.7出炉昇腾910性能超英伟达V100晓查2020-07-30AI芯片华为英伟达谷歌英伟达数据被盗后续：黑客用证书将病毒伪装成显卡驱动第三方杀毒软件可破之晓查2022-03-07病毒英伟达黑客NVIDIA何琨：AI视频处理加速引擎TensorRT及Deepstream介绍来自爱奇艺技术沙龙“多模态视频人物识别的关键技术及应用”。智能车参考2019-05-11机器学习英伟达计算机视觉英伟达5090被曝32G大显存、核心是5080的两倍！网友：怕不是B200双芯封装技术下放600W功耗引发热议克雷西2024-09-30英伟达奥特曼：o1仅仅是“推理模型的GPT-2”；黄仁勋：我给你加速50倍暗示o1满血版将在接下来几个月发布梦晨2024-09-19OpenAI英伟达热门文章救命！和漫画角色聊上头了，AI陪伴的新答案有了2025-12-29389万寻找翁荔继任者！OpenAI紧急开招安全防范负责人2025-12-29国资战略入股九章云极 加码先进AI基础设施攻坚2025-12-29美国《连线》杂志：再见，GPT5；你好，千问！2025-12-29良心老黄不搞硅谷资本家那套！Groq人均套现500万美元2025-12-29",
      "article_url": "https://www.qbitai.com/2026/01/366378.html",
      "author": "梦晨",
      "publish_time": 1767196800,
      "publish_date": "2026-01-01",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"英伟达\", \"英伟达英特尔道琼斯指数\", \"AI芯片华为英伟达谷歌\", \"病毒英伟达黑客\", \"机器学习英伟达计算机视觉\", \"英伟达\", \"OpenAI英伟达\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/\", \"url\": \"https://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/\", \"type\": \"external\"}]",
      "add_ts": 1767309494,
      "last_modify_ts": 1767395861
    },
    {
      "id": 27,
      "article_id": "366466",
      "title": "机器人也怕疼！港城突破性电子皮肤：主动痛觉+损伤自检buff拉满",
      "description": "机器人也怕疼！港城突破性电子皮肤：主动痛觉+损伤自检buff拉满一水2026-01-0314:30:01来源：量子位把触觉转成“神经脉冲”这下，你打人形机器人，它真的会「疼」了。来自香港城市大学的研究团队提出了一种全新的神经形态机器人电子皮肤（neuromorphic RE-skin，NRE-skin）。NRE-skin通过模仿人类神经系统，利用分层（Hierarchical）的神经形态架构，让触",
      "content": "机器人也怕疼！港城突破性电子皮肤：主动痛觉+损伤自检buff拉满一水2026-01-0314:30:01来源：量子位把触觉转成“神经脉冲”这下，你打人形机器人，它真的会「疼」了。来自香港城市大学的研究团队提出了一种全新的神经形态机器人电子皮肤（neuromorphic RE-skin，NRE-skin）。NRE-skin通过模仿人类神经系统，利用分层（Hierarchical）的神经形态架构，让触觉信号不再需要传到中央处理器，而是在皮肤内部就完成了初步处理与脉冲编码。基于这一仿生设计，NRE-skin同时实现了三项关键能力：高分辨率触觉感知：高效采集并编码精确的压力和位置信息。主动保护机制：具备局部反射机制，能够进行主动疼痛感知与损伤检测。维护高效性：支持快速更换的模块化快拆结构。网友表示这种复杂而精细的触觉感知，将会为机器人领域带来一次巨大的跃迁。而这一研究也无疑会为后续的触觉反馈算法和硬件设计提供新的思路。接下来我们具体来看。把触觉转成“神经脉冲”相比于以往的电子皮肤，NRE-skin没有继续沿用传统电子皮肤的“模拟信号采集”思路，而是模拟人类，直接把触觉转译成神经元式的脉冲信号。在生物系统中，感觉信号经历的是一个分级处理过程：刺激由末梢神经的局部“感受野”捕获并编码，再通过神经纤维层层递进、逐渐聚焦，最终形成完整的感觉信息传导至大脑。NRE-skin遵循这一思路，在硬件层面实现了“传感器即神经元”的设计：它将每个压力传感器直接与一个微型振荡电路相集成。当皮肤感知压力时，传感器的电阻变化会即时调控振荡电路，导致其输出的脉冲信号频率发生改变。具体而言，压力越大，脉冲发射得越密集，以此完成压力强度到脉冲频率编码的直接转译。更巧妙的是，为了精确定位，每个传感器被赋予了一组独特的无源元件（电阻R和电容C）作为其“位置指纹”。这些元件的配置使得每个位置发出的脉冲，在形状、宽度或幅度上都具有独一无二的特征。由此，NRE-skin通过这种“频率-强度，特征-位置”的编码方式，将所有复杂的触觉信息高效地汇聚到单一传输通道中。分层（Hierarchical）处理在将触觉信息编码为脉冲信号后，NRE-skin借鉴人类皮肤的分层处理，设计了四层结构（封装层、传感层、电路层、基底层） 。而且还在电路层面建立了分层的、神经状的感受野结构，以实现信号的渐进降维和数据流简化。在生物系统中，人类皮肤的功能由精密的四层结构支撑：角质层、表皮层、真皮层和皮下组织。这些层级中蕴含着高度复杂的感觉系统，分布于真皮和表皮的多种机械感受器与分层的神经感受野共同构成了信息采集与处理的一体化网络。该网络将触觉刺激分为两类：基础感知（如剧烈疼痛）通过脊髓反射弧快速处理，触发无需大脑参与的局部自动反应（如缩回）。复杂感知（如刺激强度的精确定位和损伤识别）则会被逐级传递至大脑皮层，进行更深层次的分析和决策。与之类似，NRE-skin也采用了类似的四层结构，将感觉信号从外周逐级传递至更高层级的处理中心，实现了从粗到细的定位与筛选：封装层：模拟角质层，提供表面的机械保护和整体防护。基底层：模拟皮下组织，提供缓冲，吸收外力冲击，并作为机械支撑。传感层：对应人类的机械感受器,负责感知外部刺激（如压力），并将其转换为电信号。电路层：对应人类的信号传导神经，NRE-skin的核心。负责脉冲编码、信号处理、局部反射决策。在四层结构中，电路层是NRE-skin 的核心处理模块。它位于传感层之下，负责将压力刺激转换为脉冲序列，并通过一套模拟生物感觉处理机制的人工感受野网络对信号进行初步处理，实现渐进降维和数据流简化。电路层被进一步细分为五个关键功能区域：疼痛中心：用于疼痛信号评估、特征中心：用于识别信号来源的皮肤模块信号整合器：用于合并各路输出脉冲发生器：用于生成脉冲序列和连接器（用于与外部皮肤模块连接在此基础上，研究人员进一步集成了两大高级功能：主动疼痛感知与局部反射NRE-skin具备基于疼痛阈值触发的局部反射机制。电路层面的“疼痛中心”实时监测脉冲频率所反映的压力强度。一旦压力超过阈值，系统会绕过中央处理器，直接触发类似脊髓反射弧的机制，实现毫秒级的即时保护动作（如缩回），大幅提升机器人的安全响应能力。损伤自检与模块化维护NRE-skin 通过检测传感器周期性产生的“活脉冲”状态，实现了皮肤损伤的精确自检和定位。一旦脉冲停止，即意味着皮肤受损。结合其模块化快拆设计，这极大地简化了受损皮肤单元的快速更换与维护流程。总体看来，NRE-skin 不仅是一种更高效的电子皮肤，更是一种具备自主感知、实时判断和自我保护机制的仿生智能系统，为未来制造更安全、更具人性化的仿人机器人奠定了坚实的工程基础。这篇论文的第一作者是来自香港城市大学的高育育。他目前是港城大学的博士后，研究方向包括触觉感知（Tactile Sensing）和柔性电子（Flexible Electronics）。他本科和硕士都毕业于西南交通大学，博士毕业于香港城市大学。版权所有，未经授权不得以任何形式转载及使用，违者必究。机器人一水百度AI芯片公司冲刺IPO：出货量国产第二2026-01-03吴恩达年度AI总结来了！附带一份软件开发学习小tips2025-12-31财大气粗的老黄继续出手！20多亿美金收购以色列AI初创公司2025-12-31389万寻找翁荔继任者！OpenAI紧急开招安全防范负责人2025-12-29扫码分享至朋友圈相关阅读机器人感知大升级！轻量化注入几何先验，成功率提升31%让机器人真正“看懂”三维世界时令2025-09-29机器人宇树机器人上演弯道超车(ren)，歪果仁质疑是特效行走步态更柔顺丝滑，确实有点impressive在身上衡宇2025-01-17人型机器人宇树科技机器人18岁女孩做养老机器人，上线2天卖爆了创业史已有5年……闻乐2025-09-09AI创业机器人机器人学会对自己下手了，螺丝松了自己拧赖可2019-12-23机器人马斯克擎天柱机器人大秀走姿，背后大佬集体现身喊话招人明年年底要去火星克雷西2025-04-03机器人特斯拉马斯克机器“血液”登上Nature：一条假鱼靠它续航36小时，无需固态电池能像生物的血液系统一样，为机器的各个组件传递能量。乾明栗子2019-06-20机器人热门文章救命！和漫画角色聊上头了，AI陪伴的新答案有了2025-12-29美国《连线》杂志：再见，GPT5；你好，千问！2025-12-29Manus卖给了Meta！年初火爆年底数十亿美元被收购2025-12-30389万寻找翁荔继任者！OpenAI紧急开招安全防范负责人2025-12-29良心老黄不搞硅谷资本家那套！Groq人均套现500万美元2025-12-29",
      "article_url": "https://www.qbitai.com/2026/01/366466.html",
      "author": "一水",
      "publish_time": 1767369600,
      "publish_date": "2026-01-03",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"机器人\", \"机器人\", \"人型机器人宇树科技机器人\", \"AI创业机器人\", \"机器人\", \"机器人特斯拉马斯克\", \"机器人\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767482253,
      "last_modify_ts": 1767568673
    },
    {
      "id": 28,
      "article_id": "366524",
      "title": "樱智α·医疗可信平台全新发布，北电数智与中日友好医院联合打造",
      "description": "樱智α·医疗可信平台全新发布，北电数智与中日友好医院联合打造十三2026-01-0414:02:42来源：量子位“数算模用”全栈赋能医疗数智化“临床大数据难汇聚、难挖掘、难流通问题，长期制约着医疗行业从经验驱动向数据驱动的转型，也是精准医疗落地的核心瓶颈。北电数智在可信数据领域有着深厚技术积累，对医疗行业也有着深刻理解。我们很开心与北电数智紧密携手，为破解医疗数据应用难题提供系统化支撑，让临床大数",
      "content": "樱智α·医疗可信平台全新发布，北电数智与中日友好医院联合打造十三2026-01-0414:02:42来源：量子位“数算模用”全栈赋能医疗数智化“临床大数据难汇聚、难挖掘、难流通问题，长期制约着医疗行业从经验驱动向数据驱动的转型，也是精准医疗落地的核心瓶颈。北电数智在可信数据领域有着深厚技术积累，对医疗行业也有着深刻理解。我们很开心与北电数智紧密携手，为破解医疗数据应用难题提供系统化支撑，让临床大数据真正‘活’起来、‘用’起来，为推动医疗行业高质量发展注入可信的数据动能。”国家卫生健康委临床大数据标准化及集成应用重点实验室副主任，中日友好医院大数据中心主任左先波教授表示。“作为长期奋战在临床一线的皮肤科医生，北电数智与中日友好医院联合研发的智能体应用‘樱智医助’能够贴合真实的临床思维，为我们的诊疗决策提供重要的协同支持。它不仅可以高效地挖掘疾病间的深层关联、快速检索文献与指南，还显著提升了用药的精准性与安全性，已成为我们可靠、可信赖的协同决策伙伴。期待该产品未来持续迭代，在临床场景中发挥更大价值。”博鳌超级医院皮肤科医生表示。12月27日，在第七届博鳌皮肤健康创新医学论坛上，由中日友好医院与北电数智共同开发的智能体应用“樱智医助”全新亮相，作为双方联合研发的“樱智α·皮肤专病大模型”的产品化应用，可深度嵌入从深度病例分析到安全用药指导的复杂临床决策全流程，目前已率先在博鳌超级医院投入临床应用并取得良好反馈。会上，双方深化合作、联合共建的“樱智α·医疗可信平台”同步发布，以创新“1+N+1”架构在国内率先实现了医疗数据从汇聚到治理、再到流通使用的全链路打通，将全面促进医疗数据要素价值释放。得益于“数算模用”全栈布局以及与头部医院的深度合作，北电数智已形成了以国产混元高效算力为支撑，贯通数据要素、模型能力和落地应用的全链条数智化平台体系，促进AI技术与医疗行业深度融合，为医疗行业全链条数智化升级提供坚实可信的底座支持。具备临床思维、全程协同决策，“樱智医助”让AI深度嵌入复杂决策全流程基于“樱智α·皮肤专病大模型”可靠专业的医学理解、诊断和生成能力，全新的智能体应用“樱智医助”可提供从病历分析、报告解读、用药指导到文书生成的全流程智能辅助，助力提升医生临床决策质量与效率，推动诊疗流程标准化、规范化。区别于基于通用大模型的“答题式”辅助诊疗外挂工具，“樱智医助”致力于打造“协同决策型AI”。其深度融合了高质量的临床大数据，系统性学习了临床思维与决策路径，是一款懂医生、有专识，可深度嵌入临床工作流，全流程辅助医生完成复杂诊疗决策的智能助手，实现多维度的立体化决策支持。在实际应用过程中，“樱智医助”可先辅助医生收集疾病信息，形成初步临床印象，再依据患者主诉、现病史症状及体格检查结果，初步建立诊断假设。在鉴别过程中，“樱智医助”会按照从常见病到疑难杂症的逻辑，构建鉴别诊断矩阵，清晰呈现各项诊断的支持与不支持依据，并附上决策路径建议，辅助医生进行下一步决策。在检查开具环节，“樱智医助”会基于模型的广泛知识结构，优先推荐经济、低风险、无创的筛选路径，并在诊断范围收敛后，再进一步推荐更具针对性、可能涉及轻微创伤或成本较高的检查以求确诊。值得注意的是，在整个分析过程中，模型会深度挖掘症状表象背后的跨系统特征和深层诱因，识别症状与全身健康的内在联系，提示医生可能存在风险的要点。所有分析均结合对海量且快速更新的医学文献、指南和药品知识的深度检索，从而为复杂病例的精准判定、分级诊疗提供“结构化循证依据”，以及兼顾疗效、相互作用及全身性疾病影响的“安全用药评估”。“樱智医助”将推动“人机共智”的新型诊疗范式，让AI成为医生可信赖的协同决策伙伴，未来将逐步推广至全国各级医疗机构，以标准化的智能辅助体系，助力缓解基层医疗资源不足、区域诊疗能力不均衡的现状。从模型共研到数据可信全方位合作，助力委重点实验室产业化发展日前，中日友好医院承建的“国家卫生健康委临床大数据标准化及集成应用重点实验室” （以下简称“委重点实验室”）正式获批。依托中日友好医院，联合多家科研院所，委重点实验室致力于解决跨机构医疗大数据智能应用的核心挑战。高质量的临床大数据是大模型训练和智能体应用开发的关键基础要素。由于医疗数据私密性强、来源分散且规格不一，导致汇聚接入管理难度大；原始数据质量参差不齐、罕见病数据稀缺，制约数据价值深度挖掘；安全隐私合规约束严格，数据跨机构流通利用受阻，导致临床大数据的应用长期面临“供不出、流不动、用不好、不安全”四大现实难题，成为AI医疗规模化落地的关键瓶颈。针对医疗数据汇聚、治理、流通环节的核心痛点，依托红湖可信空间，北电数智联合委重点实验室推出“樱智α·医疗可信平台”，创新构建“1+N+1”医疗数据可信服务新范式：1套可信数据接入平台：提供各类临床数据的统一汇聚与可信接入；其中“可信工作域管控平台”可分配并管理所有服务和计算资源，建立安全、可控的虚拟工作环境，形成多维度隔离机制。“医疗数据集成治理平台”通过整合多源数据、数据库及多维研究，有效提升医院科研效率，推动精准诊疗发展；N个可信数据开发与治理工具：提供数据合成、医疗知识工程与医疗数据质量、价值评估等多种数据产品开发和数据资产管理能力，实现医疗数据全链价值深度挖掘与可信应用；1个可信数据流通平台：借助强大的AI问数功能，为建立高质量数据集提供高效、准确的数据解析和结构化处理等技术支撑，为数据流通提供统一高效的可信支撑，实现高效流转。“樱智α·医疗可信平台”将有效促进临床大数据的标准化和集成应用，实现“供得出、流得动、用得好、保安全”。依托该平台，北电数智与中日友好医院将进一步深化“AI+医疗”场景创新，重点研发针对特定疾病的专病、专科模型，患者全生命周期动态认知模型，以及基于数据驱动的全民健康管理智能应用，推动居民全生命周期健康管理，支持精准医疗落地。北电数智还将作为委重点实验室的合作伙伴，围绕临床大数据的开放、治理、应用及研究成果转化开展合作，共创智能科研新生态。未来，北电数智将与客户及合作伙伴进一步深化合作，联合推动医疗AI底座的标准化建设和国产化适配，共同探索临床大数据服务与价值释放新模式，并以临床实际需求为导向持续优化迭代大模型技术及相关智能体应用，将算力、知识与数据等要素转化为一站式、可落地的诊疗能力支撑，打造“人机协同”的临床决策体系，推动医疗从“经验医学”走向“智能医学”，赋能医疗服务体系提质增效，助力健康中国战略落地生根。版权所有，未经授权不得以任何形式转载及使用，违者必究。中日友好医院北电数智医疗大模型十三今年TRAE写的代码：100000000000行！超50%程序员每天在按Tab键2025-12-29单卡2秒生成一个视频！清华联手生数开源TurboDiffusion，视频DeepSeek时刻来了2025-12-25用编程大模型登顶开源第一后，智谱GLM团队被拷问了3小时2025-12-25摩尔线程的野心，不藏了2025-12-21扫码分享至朋友圈相关阅读北电数智WAIC首秀，展示星火·大平台落百业丰硕成果基于“1个AI底座+2大产业平台”发展路径十三2025-07-27WAIC北电数智我们走访全国百强三甲医院，发现40%都选了同一家AI公司医疗AI进入验货期云知声衡宇2025-12-23AI医疗云知声医疗大模型医院技术、场景、生态共振：京东健康发起“AI普惠医疗加速计划”京东健康发布“AI医院”、升级“京医千询2.0”鹭羽2025-09-25Agent京东医疗大模型医疗界迎来重磅大模型，还有10多个场景的智能体！医疗智能体重构未来医疗范式十三2025-04-11Deepseek医疗大模型联影智能在常州，这家医院携手商汤医疗实现“AI诊断准、AR导航快”从技术革新到场景落地十三2025-05-28医疗大模型商汤科技常州北京清华长庚医院与北电数智签署战略合作，赋能药学创新和睡眠医学研究“星火·医疗底座”助力加速健康中国建设十三2025-10-17北京大学北电数智医学研究清华大学热门文章Manus卖给了Meta！年初火爆年底数十亿美元被收购2025-12-30华为云CEO周跃峰：要避免AI成为“泡沫” 必须要提升行业生产力2025-12-30真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Image2025-12-31吴恩达年度AI总结来了！附带一份软件开发学习小tips2025-12-31对科技圈，小红书是个「新绿洲」2025-12-30",
      "article_url": "https://www.qbitai.com/2026/01/366524.html",
      "author": "十三",
      "publish_time": 1767456000,
      "publish_date": "2026-01-04",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"中日友好医院北电数智医疗大模型\", \"WAIC北电数智\", \"AI医疗云知声医疗大模型医院\", \"Agent京东医疗大模型\", \"Deepseek医疗大模型联影智能\", \"医疗大模型商汤科技常州\", \"北京大学北电数智医学研究清华大学\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767568671,
      "last_modify_ts": 1767655136
    },
    {
      "id": 33,
      "article_id": "366547",
      "title": "董事长稚晖君发布上纬新材首款机器人！能塞书包还能骑机器狗",
      "description": "董事长稚晖君发布上纬新材首款机器人！能塞书包还能骑机器狗henry2026-01-0513:01:21来源：量子位henry 发自 凹非寺量子位 | 公众号 QbitAI2025年的最后一天，上市公司上纬新材董事长彭志辉（稚晖君）发布了一款能装进书包的机器人产品——上纬启元Q1。这是全球首款最小尺寸（0.8m）、实现全身力控的人形机器人，也是智元机器人联合创始人稚晖君担任上纬新材董事长以来，发布的",
      "content": "董事长稚晖君发布上纬新材首款机器人！能塞书包还能骑机器狗henry2026-01-0513:01:21来源：量子位henry 发自 凹非寺量子位 | 公众号 QbitAI2025年的最后一天，上市公司上纬新材董事长彭志辉（稚晖君）发布了一款能装进书包的机器人产品——上纬启元Q1。这是全球首款最小尺寸（0.8m）、实现全身力控的人形机器人，也是智元机器人联合创始人稚晖君担任上纬新材董事长以来，发布的首款具身智能机器人产品。虽然体型迷你，但大机器人能做的，启元Q1也能做。大机器人做不了的，启元Q1还能做。（我骑过狗你骑过吗？）而前段时间让网友猜疯了的 “大有可为” 神秘海报，也终于在这次的发布视频中正式揭晓答案。其中醒目的1.88，既不是身高，也不是售价，而是启元Q1的体积（立方米）——一个被压缩到背包级的人形机器人尺寸。启元Q1是一款怎样的机器人？从产品定位上看，稚晖君这次的新作启元Q1，是一款面向个人用户、开发者，科研、陪伴、创作场景的小尺寸人形机器人。相较于市面上的全尺寸人形机器人，启元Q1最直观的突破的就是把体型和重量狠狠压缩——甚至能主动来个双折叠，被你揣进书包。值得一提的是，这种小型化设计，并不只是为了方便携带。更轻的重量，让机器人本身更耐造，也把使用和试错成本一起打了下来，更适合个人和小团队反复折腾。在产品能力上，启元Q1反复强调了一个关键词——全身力控。简单来说，全身力控并不意味着机器人“力气更大”，而是全身关节都能感知和调节受力。传统机器人更多是“按角度走动作”，一旦遇到外力干扰，往往要么硬顶、要么停机。而具备全身力控的机器人，在被推、被拉、与环境接触时，会根据外力变化实时调整动作，避免僵硬对抗。这一能力让机器人在被推、被拉或与环境接触时，表现出更自然的物理交互特性，也是具身智能落地过程中较为关键的一项基础能力。在使用场景上，启元Q1可以充分满足各类用户的需求。在科研与教育场景中，它支持开放的SDK与HDK接口，可用于具身智能算法验证、教学实验和动作规划研究。小尺寸带来的直接好处是——不需要复杂防护结构，随拿随用，适合高频实验。在个人交互场景中，启元Q1接入启元灵心平台，支持自然语言对话、知识问答、英语教学和动作示范，并通过柔性阻抗控制，让人机交互更接近“可长期共处”的状态。而在创作者和极客用户方向，启元Q1采用模块化结构设计，支持3D打印外壳和外观定制，并可通过灵创平台编排动作、语音和行为逻辑，为二次创作留出了足够空间。这些能力背后，真正的技术难点集中在一个地方——关节系统。高性能人形机器人通常依赖QDD（Quasi-Direct Drive）准直驱关节，来实现力控和高动态动作，但这一方案长期面临的问题是：性能好，但难以做小、做轻。在启元Q1上，上纬启元对QDD关节进行了系统性重构——从材料选择、结构布局，到控制算法的协同设计，将核心关节模块压缩至不到鸡蛋大小，同时保留了力控性能和动态响应能力。也正因如此，启元Q1成为目前首个在小尺寸形态下实现全身力控的小尺寸人形机器人。机器人即产品这次启元Q1的发布，可以被视为稚晖君此前探索的“机器人即服务（RaaS）”路径，在个人机器人市场上的一次延伸。而这，也恰恰对应了当前具身智能厂商的普遍趋势——在持续服务科研、生产力和开发需求的同时，开始主动探索面向个人用户的产品形态。长期以来，无论是在工厂中的劳动力替代，还是科研中的实验载体，机器人始终被定义为一种工具。而今年开始，松延动力推出的Bumi人形机器人（售价 9998 元），以及维他动力推出的大头BoBo机器狗（售价 9988 元），都在指向一个相似方向——体型更小、价格更低、可被个人用户实际拥有和使用的具身智能产品。这些产品在保持科研与开发属性的同时，更加关注体积、价格、耐用性和可玩性，而这，也意味着具身智能正从“实验工具”，逐步走向“可使用的产品”。在2025年即将收官之际，启元Q1正是这一趋势下的一个具体落点——在科研与产业应用之外，机器人开始被真正放入个人与开发者的日常使用场景之中。而回看上纬新材的节奏，这一变化并非突然发生：11月6日完成控股权交割，智元系实现绝对控股，彭志辉入选董事候选人。11月25日董事会换届，稚晖君出任董事长。12月31日，发布首款具身智能机器人产品。短短两个月，这家以材料业务起家的上市公司，就已经是不折不扣的A股具身智能第一股了。版权所有，未经授权不得以任何形式转载及使用，违者必究。智元henry真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Image2025-12-31华为云CEO周跃峰：要避免AI成为“泡沫” 必须要提升行业生产力2025-12-30具身智能机器人年度总结，来自英伟达机器人主管2026-01-05字节Seed：大概念模型来了，推理的何必是下一个token2026-01-05扫码分享至朋友圈相关阅读智元办机器人挑战赛：清华&上海AILab夺冠，华南理工“单人成团”拿亚军Manipulation（操作） 与 World Model（世界模型），总奖池高达56万美元。henry2025-10-27智元33岁稚晖君，上市公司董事长！B站百大up主“稚晖君”，又更上了一层楼。henry2025-11-26智元智元远征A2完成全球首次人形机器人百公里跨省行走，获吉尼斯世界纪录认证全球机器人发展史上的新纪录henry2025-11-21智元能文能武！智元首个机器人艺人天团亮相湖南卫视跨年演唱会科技与文娱的碰撞梦晨2026-01-01智元稚晖君最新188机器人，阅后撤回了“智元上纬”出手，两张图带飞一只股henry2025-11-14智元智元「灵创」平台来了！0 代码、0 门槛，人人都是机器人训练大师以“让创作更简单，让表达更灵动”为核心理念一水2025-10-24智元热门文章真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Image2025-12-31吴恩达年度AI总结来了！附带一份软件开发学习小tips2025-12-31AI终于学会在家“伺候人”！Hey Tuya，我躺了2025-12-31MiniMax作价461亿港元募资46亿，1月9日敲钟代码001002025-12-31从“手工艺”到“AI工程化”：解码AI智能渗透的未来之战2025-12-31",
      "article_url": "https://www.qbitai.com/2026/01/366547.html",
      "author": "henry",
      "publish_time": 1767542400,
      "publish_date": "2026-01-05",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"智元\", \"智元\", \"智元\", \"智元\", \"智元\", \"智元\", \"智元\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767655132,
      "last_modify_ts": 1767741556
    },
    {
      "id": 34,
      "article_id": "366544",
      "title": "字节Seed：大概念模型来了，推理的何必是下一个token",
      "description": "字节Seed：大概念模型来了，推理的何必是下一个tokenhenry2026-01-0512:52:04来源：量子位henry 发自 凹非寺量子位 | 公众号 QbitAILLM的下一个推理单位，何必是Token？刚刚，字节Seed团队发布最新研究——DLCM（Dynamic Large Concept Models）将大模型的推理单位从token（词） 动态且自适应地推到了concept（概念）",
      "content": "字节Seed：大概念模型来了，推理的何必是下一个tokenhenry2026-01-0512:52:04来源：量子位henry 发自 凹非寺量子位 | 公众号 QbitAILLM的下一个推理单位，何必是Token？刚刚，字节Seed团队发布最新研究——DLCM（Dynamic Large Concept Models）将大模型的推理单位从token（词） 动态且自适应地推到了concept（概念）层级。DLCM通过端到端地方式学习语义边界，动态地将Token序列分割成概念，在压缩后的概念空间中进行深度推理，并借助因果交叉注意力将概念级推理结果重构为Token级预测。由此，传统LLM中基于均匀、冗余Token信息密度的计算分配，被转化为面向概念的动态推理与自适应算力分配。在以推理为主的基准任务上，DLCM在将推理阶段FLOPs降低34%的同时，还将平均准确率提升了2.69%。这也意味着，大模型的推理效率并不必然依赖更密集的Token级计算，而可以通过更高层级的语义组织来获得。接下来，我们具体来看。分层的下一token预测框架如上所说，DLCM的核心在于学习动态的Token-概念映射，实现了计算资源的自适应分配。之所以这样做主要有两方面原因：一方面，在自然语言中，信息的分布并不是均匀的，而是集中在集中在少数语义转换的节点上。然而，在当前的LLM中，所有token被统一处理，信息密度不均匀的自然语言消耗了同样的计算量，造成了大量的冗余与模型容量的错配。另一方面，此前基于潜在推理的框架，如大型概念模型（Large Concept Model, LCM）等，不仅需要单独训练编码器和解码器，还依赖人为划分的固定的、句子级别的粒度，缺乏拓展性与自适应性。针对这些问题，DLCM通过一种分层的下一token预测框架，将计算重心转移到压缩后的语义空间，实现了更高效的深度推理。具体来说，这一框架包含四个阶段：首先，在编码阶段，DLCM通过一个编码器，提取细粒度的Token级表示，捕获局部上下文信息，作为边界检测和最终Token级解码的基础。接下来，在动态分割阶段，模型基于Token级表示，计算相邻Token之间在潜在空间中的局部不相似性（使用余弦距离），当不相似度超过阈值时，模型判断为一个语义断点（概念边界）。与固定句子长度不同，DLCM端到端地学习这些边界，实现内容自适应的分割。它将同一片段内（即同一概念内）的所有Token表示进行均值池化（Mean Pooling），然后投影到更高维度的概念维度上，最终形成一个长度大大压缩的概念序列 。然后，在概念级推理阶段，模型将上面得到的概念序列在压缩空间中进行深度的、高容量的推理，得到经过深度推理和信息整合后的概念表示。最后，在Token级解码阶段，DLCM利用经过推理的概念表示，重构并预测下一个token。由此，DLCM通过以上四个步骤，成功地将计算分配从低效的Token-Token交互，转移到高效的Token-概念-Token 交互，实现了计算资源的自适应、结构化利用。关键技术突破与优化虽然DLCM架构在设计上实现了Token级和概念级模块的异构，但同时也引入了新的工程和训练挑战。全局解析器（Global Parser）：内容自适应压缩DLCM 的核心优势在于它能够根据信息密度动态地划分概念。例如，对于信息冗余度高的代码或简单文本，可以激进地压缩；对于语义复杂的转折点，则保持较低压缩比。为实现这一点，研究引入了全局解析器（Global Parser）和辅助损失函数。这个机制的关键在于：它不要求单个序列严格遵循目标压缩比 ，而是在整个Batch层面约束平均边界生成率。这使得DLCM在共享全局压缩比例目标的前提下，实现了随领域变化、随内容波动的自适应分段，从而将计算资源精准地分配到语义最关键的区域。针对Flash Attention的效率优化在解码阶段，Token需要通过因果交叉注意力关注其所属的概念。由于每个概念包含的Token数量是变化的，如果直接实现，会严重依赖效率低下的动态掩码和不规则的内存访问。针对这一问题，研究引入概念复制（Concept Replication）策略。它将概念特征沿着序列维度复制扩展，使其长度与原始Token序列对齐。由此，研究将复杂的可变长交叉注意力问题转换为长度对齐、局部恒定的注意力问题，并使其能够利用高度优化的Flash Attention Varlen内核，获得了1.26倍到1.73倍的显著加速。异构架构的稳定训练由于DLCM 的Token级组件和概念级骨干网络的宽度不一致，通过上投影连接，无法共享单一有效学习率。为解决这一问题，研究采用解耦的最大更新参数化，为Token模块和概念模块分配了独立的宽度缩放因子，并发现各组件的有效学习率应与其宽度的倒数成比例缩放。由此，研究成功地稳定了这种不等宽架构的训练，并实现了零样本超参数迁移，即小型代理模型上找到的最佳学习率可以直接用于训练更大的DLCM模型。量化最优分配点除上述优化外，研究还进一步基于scaling law探究了token级处理与概念级推理之间的最优分配。研究发现，在固定压缩比下，架构效率在中等概念主干占比处达到峰值，而非随概念容量单调提升。更重要的是，这一最优配置在规模增大时优势愈发明显：随着基线模型变大，在性能对齐的前提下，DLCM可实现越来越显著的FLOPs节省。在实验阶段，研究采用了与LLaMA论文中报告的相同的全局批次大小、学习率和序列长度，让每个模型都在1T Token上进行训练。其中，DLCM实现了43.92%的平均准确率，超过了基线模型41.23%的分数，提升了2.69%。One more thing这篇论文的一作来自英国曼彻斯特大学的在读博士生Qu Xingwei，师从Chenghua Lin教授。他的研究方向聚焦于大语言模型（LLMs），主要包括预训练、微调、专家混合（Mixture of Experts）以及System-2大语言模型。在教育背景方面，他本科毕业于北京航空航天大学，导师为段海滨教授；硕士就读于获慕尼黑工业大学，导师为Daniel Cremers教授。在读博前，他曾在字节跳动和小鹏汽车担任研究工程师。参考链接[1]https://x.com/GeZhang86038849[2]https://arxiv.org/abs/2512.24617版权所有，未经授权不得以任何形式转载及使用，违者必究。大模型字节Seedhenry真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Image2025-12-31华为云CEO周跃峰：要避免AI成为“泡沫” 必须要提升行业生产力2025-12-30具身智能机器人年度总结，来自英伟达机器人主管2026-01-05董事长稚晖君发布上纬新材首款机器人！能塞书包还能骑机器狗2026-01-05扫码分享至朋友圈相关阅读国产大模型高考出分了：裸分683，选清华还是北大？高考全科目评测来了十三2025-06-26大模型评测豆包高考豆包文科成绩超了一本线，为什么理科不行？“文科强理科弱”的原因找到了十三2024-07-01大模型字节跳动豆包高考Nature：DeepMind大模型突破60年数学难题，解法超出人类已有认知把大模型当做创造力引擎克雷西2023-12-15DeepMind大模型数学魔改RNN挑战Transformer，RWKV上新：推出2种新架构模型已在抱抱脸开源衡宇2024-04-12RNNRWKV大模型AI也邪修！Qwen3改Bug测试直接搜GitHub，太拟人了坏了，被AI学到真东西了（Ctrl V大法）闻乐2025-09-04ClaudeQwen3大模型自动化所：基于科学基础大模型的智能科研平台ScienceOne正式发布为科学研究打造全链条人工智能底座梦晨2025-04-30大模型热门文章真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Image2025-12-31吴恩达年度AI总结来了！附带一份软件开发学习小tips2025-12-31AI终于学会在家“伺候人”！Hey Tuya，我躺了2025-12-31MiniMax作价461亿港元募资46亿，1月9日敲钟代码001002025-12-31从“手工艺”到“AI工程化”：解码AI智能渗透的未来之战2025-12-31",
      "article_url": "https://www.qbitai.com/2026/01/366544.html",
      "author": "henry",
      "publish_time": 1767542400,
      "publish_date": "2026-01-05",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"大模型字节Seed\", \"大模型评测豆包高考\", \"大模型字节跳动豆包高考\", \"DeepMind大模型数学\", \"RNNRWKV大模型\", \"ClaudeQwen3大模型\", \"大模型\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://x.com/GeZhang86038849\", \"url\": \"https://x.com/GeZhang86038849\", \"type\": \"social\"}, {\"title\": \"https://arxiv.org/abs/2512.24617\", \"url\": \"https://arxiv.org/abs/2512.24617\", \"type\": \"paper\"}]",
      "add_ts": 1767655133,
      "last_modify_ts": 1767741557
    },
    {
      "id": 36,
      "article_id": "367091",
      "title": "全自主、更好用！北京人形 “干活机器人” 惊艳亮相 CES2026",
      "description": "全自主、更好用！北京人形 “干活机器人” 惊艳亮相 CES2026量子位的朋友们2026-01-0616:25:56来源：量子位能干活、会干活2026年1月6日，以“能干活、会干活”为技术演进目标的北京人形机器人创新中心，携“具身天工2.0”、“具身天工Ultra”等多款机器人亮相CES 2026。作为全球科技产业的年度坐标，CES历来是前沿技术的首发阵地与行业趋势的核心风向标，也是连接全球创新力",
      "content": "全自主、更好用！北京人形 “干活机器人” 惊艳亮相 CES2026量子位的朋友们2026-01-0616:25:56来源：量子位能干活、会干活2026年1月6日，以“能干活、会干活”为技术演进目标的北京人形机器人创新中心，携“具身天工2.0”、“具身天工Ultra”等多款机器人亮相CES 2026。作为全球科技产业的年度坐标，CES历来是前沿技术的首发阵地与行业趋势的核心风向标，也是连接全球创新力量、打通产业链上下游的关键枢纽。从彩色电视、移动电话到如今的AI硬件与具身智能，每一届CES的焦点都预示着未来数年的产业创新方向。本届CES以“Smarter AI for All”为主题，汇聚4500余家国际科技企业，旨在推动让智能惠及千行万业。这和北京人形的理念高度契合，始终致力于让具身智能实现“全自主、更好用”的北京人形，通过现场实机演示机器人全自主作业能力，向世界展现了中国“干活机器人”的技术实力。围绕让机器人“能干活、会干活”，北京人形打造通用机器人平台“具身天工”，面向实际应用场景，提供通用机器人本体，具备长续航、高负载、双臂协同等工业级特性；打造通用具身智能平台“慧思开物”，实现“大小脑”协同，构建从”认知-决策-执行“的全栈闭环能力，助力具身智能机器人向全自主、多场景应用演进。展会现场，“具身天工 2.0 ”展示全自主分拣零部件并与现场观众互动，让观众沉浸式体验了具身智能作业”快、准、狠“的特点。在现场展示中，基于北京人形自主研发的跨本体VLA模型XR-1，“具身天工”机器人可以自主连贯高效完成抓取、分类、码放等全流程操作，可以灵活应对包括物体姿态变化、传送带外背景变化、空间位置变化等影响，展现了极强的泛化性，具备三大突出优势：一是快，北京人形首创的UVMC（多模态视动统一表征）技术，搭建起视觉与动作的映射桥梁，让机器人将看到的画面瞬间转化为身体的本能反应，像人类条件反射般自然做出正确的应对动作，从而游刃有余的应对分拣场景中的突发情况；二是准，具备大于60赫兹的高频率控制能力，可以将视觉信息实时转化为流畅、准确的动作指令，并且完成高速的动态精准抓取，真正打破“看到”与“做到”的界限；三是狠，具备出色的双臂协作能力，在右臂错过工件抓取时，左臂能及时协同完成抓取，确保分拣任务的连续性与可靠性。目前，北京人形已经与不同行业的多家合作伙伴展开应用落地，重点围绕高危、高强度、重复性劳动场景，例如“具身天工2.0”、“天轶2.0”目前已进入福田康明斯发动机工厂，在“无人生产线”上自主完成料箱取放、搬运，并适应不同货位高度与多种料箱种类，完成了从实验室到真实生产的“最后一公里”验证。此外，北京人形还与中国电科院合作落地了人形机器人进行高危电力巡检，以及与李宁运动科学实验室合作通过人形机器人进行长时间高强度的跑鞋测试。近期北京人形还与拜尔签订合作协议，共同推动人形机器人及具身智能技术在固体药品制造生产、包装、质量控制、仓储及物流等场景的技术开发。同台亮相的“具身天工Ultra”，充分展现了长时间奔跑的稳定性及运动能力。“具身天工Ultra”作为全球首个人形机器人半程马拉松冠军，唯一使用一台机器人，通过无遥控、自主方式，用时2小时40分42秒完成21.0975公里的奔跑；同时作为人形机器人史上首个百米“飞人”，全球唯一一个通过无遥控、全自主方式，用时21.50秒夺得全球首个人形机器人运动会100米短跑项目的冠军，通过超长距离及短程爆发的极限压力测试，验证人形机器人本体的稳定性，持久性及自主能力，为人形机器人未来在真实环境，长时间稳定、自主作业奠定基础。“具身天工 2.0”则进一步展现了具身智能与人类的交互能力，不仅在2025世界机器人大会担任主持，还实现了国内首个全自主无人化展厅导览解决方案。基于“慧思开物”的技术加持，它能通过多语种语音识别并实时解答各类问题、依靠多智能体调度机制自主调度多台机器协同，让机器人更好的为后续走进咨询、导览等真实生产作业需求提供了技术基础。此次CES参展，是北京人形对“能干活、会干活”核心目标的集中呈现。从极限环境测试到工业场景验证，从关键技术突破到开源生态建设，北京人形始终聚焦于让机器人为产业创造真实价值。2026年正值具身智能从示范应用走向规模落地的关键转折点，北京人形通过CES这个国际舞台，生动诠释了“Smarter AI for All”的大会主题，向全球传递“具身智能赋能千行百业”的理念，助力推动整个行业向前发展。版权所有，未经授权不得以任何形式转载及使用，违者必究。具身天工量子位的朋友们老外对屏狂拍！海信全新一代RGB-Mini LED电视亮相轰动CES20262026-01-07OceanBase蝉联中国分布式数据库本地部署市场第一，领跑国产数据库2026-01-07重塑虚实边界：智元机器人发布首个大语言模型驱动的开源仿真平台Genie Sim 3.02026-01-071956-2026：人类与机器智能的七十年对话2026-01-06扫码分享至朋友圈热门文章能文能武！智元首个机器人艺人天团亮相湖南卫视跨年演唱会2026-01-01最新英伟达经济学：每美元性能是AMD的15倍，“买越多省越多”是真的2026-01-01豆包一声声“OK”把罗永浩搞破防，不就是大型现场直播版图灵测试2026-01-01马斯克宣布：量产脑机接口，手术全自动化2026-01-02Hinton加入Scaling Law论战，他不站学生Ilya2026-01-01",
      "article_url": "https://www.qbitai.com/2026/01/367091.html",
      "author": "量子位的朋友们",
      "publish_time": 1767628800,
      "publish_date": "2026-01-06",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"具身天工\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767741547,
      "last_modify_ts": 1767827961
    },
    {
      "id": 38,
      "article_id": "366636",
      "title": "英特尔CES奇袭老黄大本营！英伟达显卡刚涨价，最强酷睿量产出货",
      "description": "英特尔CES奇袭老黄大本营！英伟达显卡刚涨价，最强酷睿量产出货十三2026-01-0613:54:54来源：量子位还重新定义SOTA：State of the Arc金磊 发自 拉斯维加斯量子位 | 公众号 QbitAI千呼万唤始出来，英特尔迄今最强AI PC处理器，正式开卖了——第三代英特尔® 酷睿™ Ultra处理器，首款基于Intel 18A制程节点打造。没错，就是那个被英特尔中国区董事长王",
      "content": "英特尔CES奇袭老黄大本营！英伟达显卡刚涨价，最强酷睿量产出货十三2026-01-0613:54:54来源：量子位还重新定义SOTA：State of the Arc金磊 发自 拉斯维加斯量子位 | 公众号 QbitAI千呼万唤始出来，英特尔迄今最强AI PC处理器，正式开卖了——第三代英特尔® 酷睿™ Ultra处理器，首款基于Intel 18A制程节点打造。没错，就是那个被英特尔中国区董事长王稚聪比作重庆、被视为英特尔重回制程霸主地位的关键一役的18A。在现场，英特尔客户端计算事业部高级副总裁兼总经理Jim Johnson介绍说：第三代英特尔® 酷睿™ Ultra**处理器，有望成为英特尔有史以来覆盖范围最广的AI PC平台。这次的发布，意味着英特尔不仅兑现了制程节点的计划，更是直接把半导体制造带入了一个全新的维度。这款处理器除了提升了能效、增强CPU的性能之外，另一大看点就是集成了自家的Arc GPU。为什么这么说？因为除了自身性能比较彪悍之外，还有一个非常有意思的看点，那就是重新定义了SOTA这个概念：State of the Arc。一个字母之差（SOTA：State of the Art，最先进的），也是彰显了英特尔对自家GPU实力的自信。有点意思，着实有点意思。那么这款英特尔客户端最强的处理器，性能到底几何，我们具体往下看。英特尔最强AI PC处理器在聊性能之前，必须先看懂这次的底层杀手锏——Intel 18A。正如我们刚才提到的，这是英特尔重回制程霸主地位的关键一役，相比传统的芯片设计，18A工艺在方寸之间实现了两大核心黑科技的突破，这也是第三代酷睿Ultra的物理基础：第一，RibbonFET（全环绕栅极晶体管）。简单说，以前的晶体管电流控制像是在水管一面装阀门，现在是把水管四面都包起来控制。这样一来，开关更精准，漏电更少。这让芯片在微观层面的控制力达到了前所未有的高度。第二，PowerVia（背面供电技术）。以前的芯片，供电和信号传输都在晶圆的正面，容易造成信号干扰和拥堵。PowerVia技术创造性地将供电电路移至晶体管背面。这样一来，信号在上面跑，电力在下面供。互不干扰，还能大幅降低电压损耗。根据官方数据，靠着这两手绝活，Intel 18A制程让芯片在相同功耗下性能提升超过15%，或者在相同性能下功耗降低25%以上，晶体管密度更是直接提升了30%。而刚刚发布的第三代酷睿Ultra（代号Panther Lake），就是这一集大成者的首秀。看电影能持续27小时基于Intel 18A打造的SoC，到底给AI PC带来了什么体验上的质变？英特尔这次在移动端直接亮出了两款大杀器：酷睿Ultra X9和酷睿Ultra X7。旗舰型号最高配备了16个CPU核心。其中包括了全新的性能核（P-Core）和能效核（E-Core），甚至还有12个Xe核心。至于名字的命名，初衷是因为这是一个非线性的产品切换，需要一个让最终用户找到的产品，加之此前英特尔已有产品名字，因此取名为X7和X9。但最让游戏党兴奋的，绝对是显卡。这次集成的英特尔Arc™ 显卡，配合18A工艺的红利，图形处理能力直接起飞。官方实测数据显示，相比于上一代口碑极佳的Lunar Lake平台（酷睿Ultra 9 288V），新的酷睿Ultra X9在1080p高画质设定下，45款游戏的平均帧率提升了77%！注意，这可是核显啊朋友们。这意味着轻薄本也能随时随地从容应对复杂的游戏负载。以及，英伟达在前几个小时的发布会上没有发新游戏卡，而且价格还涨了，这一波是属实利好英特尔~而且不仅仅是游戏。在生产力方面，多线程性能提升了60%（基于Cinebench 2024测试）。这意味着无论是剪视频、跑代码，还是同时开几十个网页摸鱼，这颗芯都能处理得游刃有余。最后就是续航。通常性能暴涨意味着功耗崩盘，但得益于18A的超高能效比，这一代处理器的持久续航达到了惊人的27小时。基本上，出差两天甚至都不用带充电器了。除此之外，这次英特尔在性能上也拿酷睿Ultra X9和英伟达 Jetson Orin做了对比，也是完胜的结果：边缘处理器和PC做到了同步AI PC时代，怎么能不谈算力？但这次英特尔的野心不止于PC。第三代酷睿Ultra在AI方面进行了全面重构，旗舰型号的NPU算力达到了50 TOPS。配合强大的GPU和CPU，整个平台在大语言模型、端到端视频分析以及视觉语言动作模型中表现出了显著的竞争优势。在体验中心，量子位也感受了一把在英特尔AI Playground中，断网情况下运行大模型和处理图像、视频等多模态任务的速度：更关键的是，这次有一个重磅动作：边缘处理器与PC版本同步发布。这是3系列处理器首次针对嵌入式和工业边缘场景获得测试与认证。这意味着，第三代酷睿Ultra不仅会装进你的笔记本，还会被装进具身智能机器人、智慧城市的摄像头、自动化生产线和医疗设备里。它支持宽温范围，拥有确定性以及7×24小时全天候的可靠性。相较于传统的多芯片CPU和GPU架构，这种单芯片系统（SoC）方案能提供卓越的总体拥有成本（TCO）。敲黑板，划重点了：什么时候能买到？不用等到明年，就在本月！1月6日：首批搭载第三代酷睿Ultra的消费级笔记本开启预售。1月27日：全球正式发售/面市。目前已有超过200+款PC产品设计正在路上，覆盖了从消费级PC到边缘计算的广泛领域。One More Thing：这次英特尔在CES上的发布会中，中国企业身影的占比也是越发的重了起来。首先在大厂方面，字节跳动直接独占了主论坛PPT的一页；更重要的是，字节跳动的云计算（火山引擎）与英特尔已经有了深度的合作：在新秀方面，此次英特尔唯一邀请的ISV是新智慧游戏，主攻AI游戏陪练。目前已经覆盖CS2、英雄联盟等四款主流游戏，并且断网和实时都是可以的哦~至于搭载18A的英特尔® 酷睿™ Ultra**处理器实际效果如何，就要等用户们的真实反馈了。若是有友友们体验过了，欢迎回来留言哦~版权所有，未经授权不得以任何形式转载及使用，违者必究。AI PC芯片英特尔酷睿Ultra十三三赴CES，睿尔曼以三大底层能力构建全球化具身智能新基建2026-01-07杜比在CES 2026重塑了观影、娱乐的方式2026-01-07樱智α·医疗可信平台全新发布，北电数智与中日友好医院联合打造2026-01-04今年TRAE写的代码：100000000000行！超50%程序员每天在按Tab键2025-12-29扫码分享至朋友圈相关阅读英特尔拆分GPU部门，一把手重回技术岗，累计亏损超20亿美金欲进一步抢夺英伟达AMD市场。韩智2022-12-22显卡英伟达英特尔大算力时代，中国可重构计算架构芯片发展到了哪一步？｜量子位·视点 x 清微智能量子位2022-10-24芯片量子位·视点英特尔图形学专家被AMD挖走，研发实时光追，从部门主管变成副总裁还参与过微软Xbox早期研发白交2022-03-18AMD图形学英特尔谷歌自研终端AI芯片曝出重大进展，联手三星，用于手机笔记本乾明2020-04-19芯片谷歌英特尔CEO：希望跟苹果和解，代工苹果自研芯片“英特尔与苹果之间正在进行的竞争是 ‘有趣的’。”鱼羊2021-03-25芯片英特尔苹果英特尔没有“苹果”吃了年度业界水逆王诞生了。黄阳2020-06-10MacBook英特尔苹果热门文章能文能武！智元首个机器人艺人天团亮相湖南卫视跨年演唱会2026-01-01最新英伟达经济学：每美元性能是AMD的15倍，“买越多省越多”是真的2026-01-01豆包一声声“OK”把罗永浩搞破防，不就是大型现场直播版图灵测试2026-01-01马斯克宣布：量产脑机接口，手术全自动化2026-01-02Hinton加入Scaling Law论战，他不站学生Ilya2026-01-01",
      "article_url": "https://www.qbitai.com/2026/01/366636.html",
      "author": "十三",
      "publish_time": 1767628800,
      "publish_date": "2026-01-06",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"AI PC芯片英特尔酷睿Ultra\", \"显卡英伟达英特尔\", \"芯片量子位·视点\", \"AMD图形学英特尔\", \"芯片谷歌\", \"芯片英特尔苹果\", \"MacBook英特尔苹果\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767741550,
      "last_modify_ts": 1767827964
    },
    {
      "id": 41,
      "article_id": "367308",
      "title": "NVIDIA 发布全新物理 AI 模型，全球合作伙伴展示新一代机器人",
      "description": "NVIDIA 发布全新物理 AI 模型，全球合作伙伴展示新一代机器人梦晨2026-01-0717:25:06来源：量子位，通过 AI 驱动机器人推动各行各业实现转型摘要：从移动机械臂到人形机器人，Boston Dynamics、Caterpillar、Franka Robotics、Humanoid、LG Electronics 和 NEURA Robotics 均推出了基于 NVIDIA 技术构",
      "content": "NVIDIA 发布全新物理 AI 模型，全球合作伙伴展示新一代机器人梦晨2026-01-0717:25:06来源：量子位，通过 AI 驱动机器人推动各行各业实现转型摘要：从移动机械臂到人形机器人，Boston Dynamics、Caterpillar、Franka Robotics、Humanoid、LG Electronics 和 NEURA Robotics 均推出了基于 NVIDIA 技术构建的新机器人和自主机器。NVIDIA 发布了全新的 NVIDIA Cosmos 和 GR00T 开源模型和数据，用于机器人学习和推理，还发布了用于机器人评估的 Isaac Lab-Arena，以及边缘到云端计算框架 OSMO，以简化机器人训练工作流。NVIDIA 和 Hugging Face 将 NVIDIA Isaac 开源模型和库集成到 LeRobot，加速开源机器人开发社区的发展。NVIDIA Blackwell 架构驱动的 Jetson T4000 模组现已发售，将能效与 AI 算力提升至 4 倍。拉斯维加斯 —— CES —— 太平洋时间 2026 年 1 月 5 日 —— NVIDIA 今日宣布推出用于物理 AI 的全新开源模型、框架和 AI 基础设施，并展示了全球合作伙伴为各行业打造的多款机器人。NVIDIA 的全新技术能够通过加快整个机器人开发生命周期的工作流，加速新一代机器人开发浪潮，包括构建能够快速学习多种任务的“专家级通用”机器人。全球领先的机器人企业，包括 Boston Dynamics、Caterpillar、Franka Robotics、Humanoid、LG Electronics 和 NEURA Robotics 等正在借助 NVIDIA 机器人开发栈推出 AI 驱动的全新机器人。NVIDIA 创始人兼首席执行官黄仁勋表示：“机器人开发的 ChatGPT 时刻已然到来。物理 AI 领域取得了突破性进展，这类模型具备理解现实世界、推理和行动规划的能力，持续催生全新的应用场景。NVIDIA 的全栈技术，包括 Jetson 机器人开发处理器、CUDA、Omniverse 和开源物理 AI 模型为我们全球合作伙伴生态系统注入动力，通过 AI 驱动机器人推动各行各业实现转型。”全新开源模型推动机器人学习和推理的发展要将成本高昂、功能单一且难以编程的机器转变为具备推理能力的“专家级通用”机器人，需要投入巨额资金和大量专业知识来构建基础模型。NVIDIA 正在构建开源模型，助力开发者绕过资源密集的预训练阶段，专注于打造新一代 AI 机器人和自主机器。这些新模型均可通过 Hugging Face 获取，包括： NVIDIA Cosmos™ Transfer 2.5 和 NVIDIA Cosmos Predict 2.5：开源、完全可定制的世界模型，为物理 AI 实现基于物理原理的合成数据生成与机器人策略评估的仿真支持。 NVIDIA Cosmos Reason 2：开源推理视觉语言模型（VLM），使智能机器能够像人类一样看见、理解物理世界并采取行动。 NVIDIA Isaac™ GR00T N1.6：专为人形机器人打造的开放式推理视觉语言行动（VLA）模型，可解锁全身控制能力，并借助 NVIDIA Cosmos Reason 增强推理和上下文理解。Franka Robotics、NEURA Robotics 和 Humanoid 正在利用 GR00T 赋能工作流对机器人的新行为进行仿真、训练和验证。Salesforce 正在使用 Agentforce、Cosmos Reason 和用于视频搜索和总结的 NVIDIA Blueprint，对其机器人采集的视频片段进行分析，同时将事件解决时间缩短一半。LEM Surgical 借助 NVIDIA Isaac for Healthcare 和 Cosmos Transfer 训练 Dynamis 手术机器人，Dynamis 搭载 NVIDIA Jetson AGX Thor™ 和 Holoscan。XRLabs 利用 Thor 和 Isaac for Healthcare 为手术内窥镜提供支持，以外置手术内镜为切入点，通过实时 AI 分析为外科医生提供手术引导。面向机器人开发的全新开源仿真和计算框架可扩展的仿真对于机器人训练和评估至关重要，但当前的工作流依然分散且难以管理。基准测试通常由人工操作且难以扩展，而端到端工作流需要跨异构计算资源进行复杂编排。NVIDIA 今天在 GitHub 上发布了全新开源框架，可简化这些复杂工作流，并加速从研究到现实应用的过渡。NVIDIA Isaac Lab-Arena 是一个开源框架，已在 GitHub 上公开发布，旨在为在仿真中进行大规模机器人策略评估与基准测试提供协作系统。其评估层和任务层的设计与光轮智能紧密合作完成。Isaac Lab-Arena 支持对接 Libero 和 Robocasa 等业界领先基准测试体系，实现测试流程的标准化，并确保机器人技能在部署至物理硬件前具备稳健性与可靠性。NVIDIA OSMO 是一个云原生编排框架，可将机器人开发整合至单一易用的命令中心。OSMO 支持开发者定义和运行跨计算环境（从工作站到混合云实例）的工作流，包括合成数据生成、模型训练与软件在环测试，从而加速开发周期。OSMO 现已开放使用，并被 Hexagon Robotics 等机器人开发者采用，同时已集成至 Microsoft Azure Robotics Accelerator 工具链中。NVIDIA 与 Hugging Face 一起加速开源物理 AI 开发机器人现已成为 Hugging Face 平台上增长最快的领域，在蓬勃发展的开源社区中，NVIDIA 开源模型与数据集下载量持续领先。为推动社区发展，NVIDIA 正与 HuggingFace 合作，将开源的 Isaac 与 GR00T 技术集成到领先的 LeRobot 开源机器人框架中，为开发者提供更便捷的软硬件一体化工具的获取渠道，加速端到端开发。此次合作连接了 NVIDIA 的 200 万机器人开发者与 Hugging Face 的 1300 万全球 AI 开发者社区。GR00T N 系列模型 和 Isaac Lab-Arena 现已上线 LeRobot 库，便于开发者进行微调和评估。Hugging Face 开源的 Reachy 2 人形机器人将与 NVIDIA Jetson Thor™ 机器人计算机实现完全互操作，可供开发者运行包括 GR00T N1.6 在内的任何 VLA。Hugging Face 开源的 Reachy Mini 桌面机器人也与 NVIDIA DGX Spark™ 实现完全互操作，开发者可以基于 NVIDIA 大语言模型以及本地运行的语音和计算机视觉开源模型打造自定义体验。人形机器人开发者采用 NVIDIA Jetson ThorNVIDIA Jetson Thor 能够满足具备推理能力的人形机器人对海量计算的需求。在 CES 上，人形机器人开发者展示了目前集成 Jetson Thor 的最新先进机器人。NEURA Robotics 将推出由保时捷设计的第 3 代人形机器人，以及针对精细化控制优化的小型人形机器人。Richtech Robotics 将发布一款可在复杂工业环境中进行精细操作和导航的移动人形机器人 Dex。智元机器人将推出面向工业和消费行业的人形机器人以及与 Isaac Sim 集成的机器人仿真平台 Genie Sim 3.0。LG Electronics 发布了一款可执行各种室内家务的新家用机器人。Boston Dynamics、Humanoid 和 RLWRLD 均已将 Jetson Thor 集成至现有的人形机器人，用于增强其导航和操作能力。推动物理 AI 赋能工业边缘全新 NVIDIA Jetson™ T4000 模组为 NVIDIA Jetson Orin™ 客户提供高性价比、高性能的升级路径，千片起订量下单价为 1999 美元，将 NVIDIA Blackwell 架构引入自主机器和通用机器人领域。该产品能够在可配置的 70 瓦功率范围内提供 1200 FP4 TFLOPS 算力及 64GB 内存，性能较上一代产品提升至 4 倍，是能耗受限型自主系统的理想选择。NVIDIA IGX Thor 将于本月晚些时候上市，将机器人技术扩展到工业边缘，提供由企业级软件提供支持的高性能 AI 计算与功能安全保障。Archer 使用 IGX Thor 将 AI 引入航空领域，从而提升飞机安全、空域集成以及具备自主化能力的系统等关键功能。AAEON、Advantech、ADLINK、Aetina、AVerMedia、Connect Tech、EverFocus、ForeCR、Lanner、RealTimes、Syslogic、Vecow 和 YUAN 等合作伙伴现已推出搭载 Thor 的系统，面向边缘 AI、机器人和嵌入式应用。此外，Caterpillar 正在扩大与 NVIDIA 的合作，将先进的 AI 和自主系统引入建筑和采矿领域的设备及作业现场。在 1 月 7 日（星期三）的 CES 主题演讲中，Caterpillar CEO Joe Creed 将与 NVIDIA 机器人和边缘 AI 副总裁 Deepu Talla 共同披露更多合作细节。观看 NVIDA CES 现场直播，了解更多信息。文首图片由 Caterpillar（左上）、LEM Surgical（右上）、智元机器人（左下）和 Franka Robotics（右下）提供。版权所有，未经授权不得以任何形式转载及使用，违者必究。英伟达梦晨最新英伟达经济学：每美元性能是AMD的15倍，“买越多省越多”是真的2026-01-01能文能武！智元首个机器人艺人天团亮相湖南卫视跨年演唱会2026-01-01Hinton加入Scaling Law论战，他不站学生Ilya2026-01-01Manus收购案细节曝光：20亿刀闪电成交，CEO不向亚历山大王汇报2025-12-31扫码分享至朋友圈相关阅读黄仁勋把自己做成了虚拟娃娃英伟达也要搞数字虚拟人了，第一个就拿黄仁勋“开刀”明敏2021-11-10英伟达虚拟数字人老黄给H100“打鸡血”：英伟达推出大模型加速包，Llama2推理速度翻倍与多家AI头部公司合作克雷西2023-09-11英伟达英伟达把P图软件GAN了让画像雕塑“挤眉弄眼”晓查2021-12-05GAN英伟达老黄再收95后华人才俊！4亿美元收购AI初创公司该公司CentML专门负责优化AI应用程序的运行方式鹭羽2025-07-06GPU华人英伟达黄仁勋自掏腰包50亿，手把手教AI公司用好GPU买英伟达GPU，直接送“开箱工具”贾浩楠2024-12-31英伟达老黄All in物理AI！最新GPU性能5倍提升，还砸掉了智驾门槛5年CES首次不发游戏显卡全力搞AI闻乐2026-01-06CES智驾英伟达黄仁勋热门文章马斯克宣布：量产脑机接口，手术全自动化2026-01-02「北京版幻方」冷不丁开源SOTA代码大模型！一张3090就能跑，40B参数掀翻Opus-4.5和GPT-5.22026-01-02AI正在占领你的视频推荐流2026-01-02这里还有8个“Manus”：1亿美元ARR，都是ToC2026-01-03中国“人造太阳”突破密度极限，聚变点火迎来新路径 | Science子刊2026-01-03",
      "article_url": "https://www.qbitai.com/2026/01/367308.html",
      "author": "梦晨",
      "publish_time": 1767715200,
      "publish_date": "2026-01-07",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"英伟达\", \"英伟达虚拟数字人\", \"英伟达\", \"GAN英伟达\", \"GPU华人英伟达\", \"英伟达\", \"CES智驾英伟达黄仁勋\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767827945,
      "last_modify_ts": 1767914246
    },
    {
      "id": 43,
      "article_id": "367261",
      "title": "重塑虚实边界：智元机器人发布首个大语言模型驱动的开源仿真平台Genie Sim 3.0",
      "description": "重塑虚实边界：智元机器人发布首个大语言模型驱动的开源仿真平台Genie Sim 3.0量子位的朋友们2026-01-0715:44:52来源：量子位建开源共享，共创智能未来当仿真环境的真实性逼近物理世界，当场景构建的效率以“自然对话”和“分钟”来衡量，具身智能的研发范式将发生根本性改变。智元机器人在CES国际消费电子展首日正式发布首个大语言模型驱动的开源仿真平台——Genie Sim 3.0。基于",
      "content": "重塑虚实边界：智元机器人发布首个大语言模型驱动的开源仿真平台Genie Sim 3.0量子位的朋友们2026-01-0715:44:52来源：量子位建开源共享，共创智能未来当仿真环境的真实性逼近物理世界，当场景构建的效率以“自然对话”和“分钟”来衡量，具身智能的研发范式将发生根本性改变。智元机器人在CES国际消费电子展首日正式发布首个大语言模型驱动的开源仿真平台——Genie Sim 3.0。基于NVIDIA Isaac Sim ， Genie Sim 3.0 融合三维重建与视觉生成，打造数字孪生级的高保真环境；首创大语言模型驱动，让万级场景的生成只需几分钟；同步开源包含真实机器人作业场景的上万小时仿真数据集；并构建了覆盖10万+场景的多维度智能评估体系，为模型能力绘制全景画像。从数字资产生成、场景泛化、数据采集到自动评测的全流程功能，这一整套完整闭环的解决方案，将显著加速模型训练验证，降低对物理硬件的依赖，助力开发者与研究者的研发效率，推动具身智能的创新应用。项目主页：https://agibot-world.com/genie-simGithub: github.com/AgibotTech/genie_simModelscope: https://modelscope.cn/datasets/agibot_world/GenieSim3.0-Dataset五大核心亮点，开启具身仿真新纪元01/ 数字孪生级高保真仿真环境传统仿真难以兼顾视觉逼真与物理真实。Genie Sim 3.0 开创性地将三维重建、视觉生成技术与物理引擎深度融合，实现了视觉真实感与物理精确性的统一。精准重建：依托 MetaCam 手持3D激光扫描仪，结合高分辨率RGB、360° LiDAR点云与厘米级RTK定位，实现对真实环境的毫米级精准复刻。视觉增强：利用视觉生成模型，智能合成新视角图像增强3D重建，极大提升了仿真环境的视觉逼真度。资产生成：对于任意物体，仅需一段60秒环拍视频，即可快速生成带精确网格的仿真模型，大幅提升场景构建效率。02/ 首创自然语言驱动的场景生成与泛化告别手动编写复杂逻辑的场景生成方式，在Genie Sim平台中，开发者输入自然语言指令即可驱动平台在分钟级内自动生成、泛化成千上万个训练与测试场景。对话式创建：直接输入如「生成一份蛋白质和维生素含量丰富的晚餐」的指令，平台自动理解并构建出结构化的仿真场景。智能编辑与泛化：生成场景自带结构化信息与视觉预览，可进一步通过对话进行场景增广、细节增删、布局调整，最终输出满足要求的仿真场景。03/ 全量开源仿真数据集与高效采集方案具身领域最大规模开源仿真数据集，涵盖200余项任务、总时长上万小时，为模型研发提供坚实的数据基石。多维度数据：数据集包含RGB-D、双目视觉、全身关节状态等多传感器信息，并覆盖背景、布局、光照、噪声等多种泛化维度。智能采集工具：平台提供低延迟遥操作与自动任务编排双模式采集，结合自动化标注实现高效数据生产。独创错误恢复机制：任务失败后可自动回退至关键节点续采，将数据采集损耗降至最低。零样本Sim2Real：仿真数据训练完成后，实现零样本迁移到真实世界，任务成功率超过真实数据训练。04/ 超十万仿真场景，勾勒模型全景能力画像模型评估不再仅限于“成功率”。Genie Sim Benchmark 3.0 构建了基于 10万+ 仿真场景的立体评估体系，结合LLM与VLM技术，从多个维度为模型绘制深度能力画像，是当前业界覆盖最全面、最权威的具身智能模型评估基准。自动化评测生成：评测指令与步骤可由LLM根据场景语义自动生成，并转化为可执行流程。多维度深度评估：通过视觉语言模型（VLM），从语义理解、空间推理、操作精度、时序逻辑等多维度进行综合评价，清晰揭示模型的能力边界与薄弱环节，指引明确的优化方向。虚实一致的评测结果：仿真与真实世界评测差异<10%，模型验证无需真机部署，显著提升算法评测效率。05/ 涵盖真实作业场景仿真基于智元的规模化商用和工业落地经验，Genie Sim 3.0 是首个深度集成真实作业场景仿真数采与评测的开源平台，打通从实验室算法到工业应用落地。真实作业场景还原：平台包含超市上货、物流分拣、电力巡检、物料搬运、产线装配等多个工业场景的机器人作业环境。全流程仿真验证：基于重建资产快速生成训练数据集与全流程评测系统，大幅降低数据采集成本与算法验证周期，实现“零硬件部署，全真实验证”。建开源共享，共创智能未来Genie Sim 3.0 仿真平台核心代码、海量高价值数据集以及数字资产全面开源，向全球开发者、研究者与产业伙伴开放。无论您是高校实验室的研究者，还是具身智能领域的算法工程师，或是来自制造业、物流业等领域的集成应用专家，Genie Sim 3.0旨在让每一位具身智能的探索者，都能拥有接近无限的仿真场景、逼近真实的训练环境、科学全面的评估标尺，从而将精力更聚焦于算法与模型本身的创新。开发者可访问GitHub开源主页：github.com/AgibotTech/genie_sim，获取代码、数据集与详细文档。版权所有，未经授权不得以任何形式转载及使用，违者必究。智元量子位的朋友们老外对屏狂拍！海信全新一代RGB-Mini LED电视亮相轰动CES20262026-01-07OceanBase蝉联中国分布式数据库本地部署市场第一，领跑国产数据库2026-01-07全自主、更好用！北京人形 “干活机器人” 惊艳亮相 CES20262026-01-061956-2026：人类与机器智能的七十年对话2026-01-06扫码分享至朋友圈相关阅读董事长稚晖君发布上纬新材首款机器人！能塞书包还能骑机器狗henry2026-01-05智元智元办机器人挑战赛：清华&上海AILab夺冠，华南理工“单人成团”拿亚军Manipulation（操作） 与 World Model（世界模型），总奖池高达56万美元。henry2025-10-27智元智元开源机器人中间件AimRT，正式上线源码目前托管在Gitee一水2024-09-25智元稚晖君机器人“葡萄缝针”神技再现江湖，骑自行车惊呆众人：又抽象又硬核我们造了个像人一样灵动的机器人白交2025-03-11智元机器人稚晖君稚晖君预告揭晓！智元机器人发布首个通用具身基座模型GO-1预告明天还有惊喜一水2025-03-10具身智能智元能文能武！智元首个机器人艺人天团亮相湖南卫视跨年演唱会科技与文娱的碰撞梦晨2026-01-01智元热门文章马斯克宣布：量产脑机接口，手术全自动化2026-01-02「北京版幻方」冷不丁开源SOTA代码大模型！一张3090就能跑，40B参数掀翻Opus-4.5和GPT-5.22026-01-02AI正在占领你的视频推荐流2026-01-02这里还有8个“Manus”：1亿美元ARR，都是ToC2026-01-03中国“人造太阳”突破密度极限，聚变点火迎来新路径 | Science子刊2026-01-03",
      "article_url": "https://www.qbitai.com/2026/01/367261.html",
      "author": "量子位的朋友们",
      "publish_time": 1767715200,
      "publish_date": "2026-01-07",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"智元\", \"智元\", \"智元\", \"智元\", \"智元机器人稚晖君\", \"具身智能智元\", \"智元\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://agibot-world.com/genie-sim\", \"url\": \"https://agibot-world.com/genie-sim\", \"type\": \"external\"}, {\"title\": \"https://modelscope.cn/datasets/agibot_world/GenieSim3.0-Dataset\", \"url\": \"https://modelscope.cn/datasets/agibot_world/GenieSim3.0-Dataset\", \"type\": \"external\"}]",
      "add_ts": 1767827948,
      "last_modify_ts": 1767914249
    },
    {
      "id": 45,
      "article_id": "367229",
      "title": "8块钱跑通一次强化学习全流程，潞晨云重塑微调赛道：1名算法工程师=1支Infra团队",
      "description": "8块钱跑通一次强化学习全流程，潞晨云重塑微调赛道：1名算法工程师=1支Infra团队思邈2026-01-0715:16:23来源：量子位国内首个！兼容Tinker范式且全面开放允中 发自 凹非寺量子位 | 公众号 QbitAI大模型下半场的战火，已经从“暴力预训练”烧向了“后训练”战场。无论是OpenAI o1的推理突破，还是DeepSeek-R1靠强化学习（RL）实现的性能飞跃，都释放了一个明确",
      "content": "8块钱跑通一次强化学习全流程，潞晨云重塑微调赛道：1名算法工程师=1支Infra团队思邈2026-01-0715:16:23来源：量子位国内首个！兼容Tinker范式且全面开放允中 发自 凹非寺量子位 | 公众号 QbitAI大模型下半场的战火，已经从“暴力预训练”烧向了“后训练”战场。无论是OpenAI o1的推理突破，还是DeepSeek-R1靠强化学习（RL）实现的性能飞跃，都释放了一个明确信号：决定模型天花板的，不再只是算力堆砌，而是更精准的微调和RL迭代。但现实很骨感——复杂的分布式基建、高昂的显卡租金、繁琐的架构调优，像一道道高墙，把无数算法工程师挡在了“炼丹房”外。现在，这堵墙正在被推倒。潞晨云微调SDK正式开放上线——这是国内首个全面开放、且兼容Tinker范式的Serverless微调平台。其基于Thinking Machine Lab开源的Tinker SDK构建，核心目标只有一个：为复杂且昂贵的强化学习，提供一套更具成本优势的工业级解法。拥抱后训练与RL：算法层与底层算力架构的解耦随着OpenAI o1在推理能力上的突破，业界逐渐形成共识——即大模型的能力突破已不再单纯依赖预训练（Pre-training）阶段的参数堆砌，后训练（Post-Training） 特别是强化学习，正成为决定模型实用价值的核心战场。以DeepSeek‑R1为例，仅靠强化学习训练，模型在AIME数学推理基准上的pass@1从15.6%提升至77.9%，充分展示了RL在低数据量条件下即可实现大幅能力跃升，迅速成为后训练赛道的新范式。然而，摆在算法工程师面前的问题依旧严峻。强化学习涉及到更为复杂的系统设计，训练过程中存在一系列的问题，如多个模型的优化，数据的传递，以及模型权重的传递；另外，一系列工程化的工作，给算法的设计带来了更多的困难，同时也对基础设施提出了更高的要求。Tinker的出现，就是为了解决这个问题：把繁杂训练变成标准易用的API。潞晨云把这一范式写进底层假设，算法设计与基础设施解耦——开发者只负责定义数据与Loss函数，底层的异构集群调度、并行策略优化、容错运维等应被封装为基础设施服务，对开发者实现全托管与无感支持。它试图回答的不是范式是否新，而是开发者能否用起来、能否稳定跑起来。具体来看，潞晨云微调SDK兼容Tinker接口，消除了从“算法灵感”到“模型落地”之间的工程化壁垒，在零代码微调与裸机全手写之间落在最佳平衡点，将研究精力和算力成本从集群运维还原至算法本身，带给开发者“本地写码、云端计算”的“训练即服务（Training as a Service）”流畅体验 。颠覆性人力效能比：1名算法工程师顶替原庞大Infra团队潞晨云微调SDK的核心思路可以概括为：算法工程师定义算法逻辑，潞晨云搞定Infra。在传统的开发中，用户往往要花大量精力去租赁合适的算力集群、管理环境配置、调训练框架和集群运维。但潞晨云将大模型训练拆解成了一组标准的函数原语, 打通了从SFT到RL的全链路：Forward & Backward：处理前向传播与梯度计算；Optimizer Step：执行权重更新策略；Sample (Rollout)：做推理生成和评估，使用户不仅可以完成SFT，更能轻松构建PPO、GRPO、DPO等复杂的强化学习（RLHF/RLAIF）训练流；Save State：管理模型检查点与状态保存。这意味着，用户可以在本地熟悉的Jupyter Notebook或IDE里，用最标准的Python语法像搭积木一样自由组合，掌控训练逻辑的细节。这种模式带来了颠覆性的“人力效能比”提升：它将原本需要运维工程师、Infra工程师、平台工程师和算法工程师紧密配合的庞大团队，简化为了“一个算法工程师”的独立闭环。用户不再被底层繁杂的基建拖累，不再背负多职能的枷锁，也不再是黑盒填参的被动执行者，而是能够独立驾驭大规模训练流的主动设计师。这也意味着，无论是监督微调（SFT）还是更复杂的强化学习（RL）Pipeline，都能通过组合这些原子函数来灵活构建。那么问题来了，为什么体验能做到如此丝滑？为了实现极致的流畅度，潞晨云基于现有的GPU云服务架构实现了一套完整的后端系统。在具体实现中，潞晨云采⽤控制⾯与计算⾯分离设计，通过统⼀API Server管理跨地域的多个GPU计算集群，实现多云部署能⼒。核⼼采⽤基于Future模式的异步API，所有训练操作⽀持⾮阻塞调⽤，⽤⼾⽆需等待GPU计算完成即可继续执⾏后续逻辑。潞晨云微调SDK还具备智能队列系统，即使在资源洪峰期，任务也会自动进入持久化队列（Persistence Queue），一旦底层资源可用，毫秒级启动，队列等待期间0计费，仅对实际prefill+sample+train的Token量收费，无资源闲置，将用户每一分钱都用在产生梯度的刀刃上。模型微调的算力零售革命：从“包机租赁”到“按Token计费”如果说“易用性”是后训练平台的入场券，那么“成本结构”则是决定谁能走得更远的护城河。在传统云主机的“包机/时租”模式中，用户一直在为“过程”买单——也就是说，无论是在加载数据、调试代码，还是仅仅在思考Loss函数，只要占用了显卡，计费表就在跳动。这种模式下，开发过程中有一半以上的预算都浪费在了这些没有实际产出的“垃圾时间”里。潞晨云为微调大模型场景引入了Serverless架构，推行“按Token计费”的商业模式，将微调场景的算力服务切分到了最细的颗粒度：为价值付费：就像使用推理API一样，用户只需为Prefill（输入）、Sample（推理输出）和 Train（训练）产生的有效计算Tokens量付费。其他环节全免费：本地代码调试、环境配置、数据预处理、模型Checkpoint保存……这些在传统租卡模式下分秒必争的环节，在潞晨云全部免费。极致性价比：通常，RL需要同时维护高吞吐的推理集群（vLLM）和训练集群，算力成本极高。但在潞晨云上，实测基于官方Cookbook的math_rl recipe跑通包含Rollout采样、Reward评分和PPO更新的完整RL流程（~300 steps），总算力成本仅8.61元。这意味着，个体开发者也能低成本复现RLHF/RLAIF探索。技术落地的三个场景：SFT与RL同时“开箱即用”这种新模式，也将彻底改变不同领域开发者的工作流：1、科研场景：告别资源焦虑学术界，时间与算力往往是最紧缺的资源。研究人员不仅要面对繁琐的集群运维（Slurm/Docker配置），还要应对昂贵的实验复现成本。潞晨云微调SDK支持“白盒级”的科研探索，全面兼容Tinker API。研究人员可以自定义Evaluation逻辑、通过Forward/Backward，Sample等原语精确控制后训练和强化学习Pipeline，而无需关心底层的分布式实现，让实验复现成本大幅降低。2、创业与独立开发：极速验证MVP对于初创团队，“快”是生存根本。利用潞晨云微调SDK的Serverless特性，开发者无需等待资源排期。配合极低的Token成本，实测从pip install到跑通一个包含1000条样本的SFT或RL微调实验，仅需数分钟。这种极致的边际成本，让创业者敢于在有限预算下快速迭代Reward模型，实现真正的“低成本试错”。3、工业级落地：复杂架构突围而在金融、医疗等垂直领域的工业应用中，已有微调API往往难以应对复杂的异构架构与RLHF/RLAIF需求。潞晨云微调SDK允许工程师通过train_step自由定义Loss逻辑与强化学习奖励函数。开发者拥有对模型权重与训练细节的完整控制权，实现端到端定制。极简实战：三步上手没有复杂的集群配置，没有冗长的Docker构建。使用潞晨云微调SDK，训练一个大模型就像写普通Python脚本一样简单：1、Install & Import:Bash \r\npip install hpcai2、Initialize Client: 目前已支持Qwen3系列 (4B – 32B) ，更多模型即将上线Python \r\nimport hpcai \r\n# 初始化 LoRA 训练客户端，无需配置复杂的分布式参数 \r\ntraining_client = service_client.create_lora_training_client( \r\n    base_model=”Qwen/Qwen3-4B”, \r\n    rank=32 \r\n)3、Define Training Loop & Run：像在本地写PyTorch一样，拥有对训练循环的完整控制权：Python \r\n# 训练循环：完全可控 \r\nfor step in range(target_steps): \r\n    # 前向与反向传播\r\n    fwd_bwd = training_client.forward_backward(batch, “cross_entropy”)\r\n    # 优化器步进\r\n    optim = training_client.optim_step(adam_params)\r\n    # 实时获取 Loss 进行监控\r\n    loss = fwd_bwd.result().metrics.get(\"loss:mean\")⽬前，微调SDK已覆盖Qwen3系列模型（4B、8B、14B、32B），支持监督学习和强化学习训练方式，并将持续扩展更多模型能⼒与细分落地场景，⼤家也可以向官⽅提交需求push更新。平台还准备了开箱即用的HPC-AI Cookbook，提供包括DeepSeek-R1 GRPO算法、基于Verifier的数学推理、自定义Reward函数等复杂RL场景的完整代码实现。开发者无需从零构建复杂的PPO/GRPO流水线，只需复制Cookbook中的“配方”，运行轻量级本地train.py脚本，即可驱动云端复杂的分布式RL训练流，在潞晨云上复现具备复杂逻辑推理能力的SOTA模型。从“能训”到“可持续训”后训练正从学术支线升级为工程主线，AI基础设施的终极形态应该是“零认知负荷”——开发者只需描述数据与算法，其余（租卡、配环境、并行策略、运维调度、故障自愈，乃至RL涉及的一系列工程化的工作）全部下沉到用户无感。当GPU闲置成本趋近于0，环境配置时间趋近于0，长序列RLHF也能按Token即时计费，应用创新效率直接逼近算力上限。潞晨云微调SDK今日起全量开放：无需白名单，无需预约前150名专属链接注册即得30元使用额度（注册链接：https://cloud.luchentech.com/account/signup?invitation_code=LZW）立即体验：https://cloud.luchentech.com/fine-tuning使用文档：https://cloud.luchentech.com/doc/docs/finetune-sdk/Reference[1] Tinker SDK: https://github.com/thinking-machines-lab/tinker[2] DeepSeek-R1: https://arxiv.org/pdf/2501.12948版权所有，未经授权不得以任何形式转载及使用，违者必究。大模型微调强化学习微调潞晨云潞晨科技思邈有300亿美元也未必“再造GPT-4”？NUS尤洋最新长文：拆穿AI增长瓶颈的真相2025-12-31AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品2025-12-29推理成本打到1元/每百万token，浪潮信息撬动Agent规模化的“最后一公里”2025-12-26国产AI4S创业头雁再获8亿投资！深势科技完成C轮，产品已服务300万科学家2025-12-24扫码分享至朋友圈相关阅读仅需一万块钱！清华团队靠强化学习让7B模型数学打败GPT-4o新的结合过程奖励的强化学习方法梦晨2025-01-07强化学习OpenAI开发AI版《文明》，一块CPU就能重现AI生存战争史一款名叫Neural MMO的AI训练游戏，让AI在一块限定的土地上求生。夏乙2019-03-05人工智能多智能体强化学习AlphaGo之父对话《连线》，曾被导师劝阻研究强化学习，如今获得ACM计算奖刚刚登上Nature的MuZero有何意义晓查2020-12-27AlphaGoDeepMind强化学习多模态模型学会打扑克：表现超越GPT-4v，全新强化学习框架是关键全程无需人类反馈克雷西2024-06-04多模态强化学习免费！满血版DeepSeek丝滑畅玩，低门槛实现671B-R1/V3自由企业级API价格比官方低明敏2025-02-12Deepseek潞晨云中国AI麻将打出新高度！战胜真人职业选手，鹅厂「绝艺」刷新战绩明敏2023-07-11决策AI强化学习绝艺腾讯热门文章马斯克宣布：量产脑机接口，手术全自动化2026-01-02「北京版幻方」冷不丁开源SOTA代码大模型！一张3090就能跑，40B参数掀翻Opus-4.5和GPT-5.22026-01-02AI正在占领你的视频推荐流2026-01-02这里还有8个“Manus”：1亿美元ARR，都是ToC2026-01-03中国“人造太阳”突破密度极限，聚变点火迎来新路径 | Science子刊2026-01-03",
      "article_url": "https://www.qbitai.com/2026/01/367229.html",
      "author": "思邈",
      "publish_time": 1767715200,
      "publish_date": "2026-01-07",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"大模型微调强化学习微调潞晨云潞晨科技\", \"强化学习\", \"人工智能多智能体强化学习\", \"AlphaGoDeepMind强化学习\", \"多模态强化学习\", \"Deepseek潞晨云\", \"决策AI强化学习绝艺腾讯\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://cloud.luchentech.com/account/signup?invitation_code=LZW）\", \"url\": \"https://cloud.luchentech.com/account/signup?invitation_code=LZW）\", \"type\": \"external\"}, {\"title\": \"https://cloud.luchentech.com/fine-tuning\", \"url\": \"https://cloud.luchentech.com/fine-tuning\", \"type\": \"external\"}, {\"title\": \"https://cloud.luchentech.com/doc/docs/finetune-sdk/\", \"url\": \"https://cloud.luchentech.com/doc/docs/finetune-sdk/\", \"type\": \"external\"}, {\"title\": \"https://github.com/thinking-machines-lab/tinker\", \"url\": \"https://github.com/thinking-machines-lab/tinker\", \"type\": \"code\"}, {\"title\": \"https://arxiv.org/pdf/2501.12948\", \"url\": \"https://arxiv.org/pdf/2501.12948\", \"type\": \"paper\"}]",
      "add_ts": 1767827951,
      "last_modify_ts": 1767914252
    },
    {
      "id": 46,
      "article_id": "367216",
      "title": "三赴CES，睿尔曼以三大底层能力构建全球化具身智能新基建",
      "description": "三赴CES，睿尔曼以三大底层能力构建全球化具身智能新基建十三2026-01-0714:07:17来源：量子位50000小时无故障运行2026年1月6日-9日，全球科技风向标——国际消费电子展（CES 2026）在美国拉斯维加斯举行。睿尔曼智能连续三年参展，本届更是以“面向具身智能时代的系统级基础设施平台公司”全新定位，携三大核心产品——全栈自研一体化关节模组、超轻量仿人机械臂及远程作业网络（GLN",
      "content": "三赴CES，睿尔曼以三大底层能力构建全球化具身智能新基建十三2026-01-0714:07:17来源：量子位50000小时无故障运行2026年1月6日-9日，全球科技风向标——国际消费电子展（CES 2026）在美国拉斯维加斯举行。睿尔曼智能连续三年参展，本届更是以“面向具身智能时代的系统级基础设施平台公司”全新定位，携三大核心产品——全栈自研一体化关节模组、超轻量仿人机械臂及远程作业网络（GLN），全面展示其在具身智能领域从硬件、数据到远程作业网络的全链路布局，开启具身进化与全球化发展的新阶段。基础能力：50000小时无故障运行，为高性能机器人定义“可靠标准”作为一家面向具身智能时代的系统级基础设施平台公司，睿尔曼自2018年成立以来，始终围绕能灵巧运动的机械臂和精准耐久的关节展开技术创新。2025年，公司自主研发的一体化关节模组年产能已突破10万台，同时与德国TUV南德合作完成合规检测，取得了ROHS、Reach认证。机械臂已通过CR L3认证，平均无故障运行时间达50000小时，能完成开关冰箱门、洗衣机门等真实生活任务，这标志着机器人硬件从“可用”到“可靠耐用”的本质飞跃，为高质量真机数据采集打下物理基础。睿尔曼机械臂设计对标成年男性胳膊的长短、粗细、灵活度及负载能力，力求在外观与性能上实现与人、工作、生活环境的友好共融，达成“人能干，它能干”的效果。此次睿尔曼展出的超轻量仿人形机械臂，单臂（全臂展）额定负载5公斤，最大负载可达9公斤，TCP线速度1.8m/s。值得一提的是，此次展出的七自由度仿人形机械臂（RX系列），基于仿人形的腕部设计，适用于灵活性要求高的狭小空间。数据引擎：构建远程作业网络，打造“操作力即服务”的全球基础设施本次CES的最大亮点，睿尔曼完成了从“北京—拉斯维加斯”跨洋实时遥操演示。通过构建“人形机器人数据训练中心—拉斯维加斯国际会展中心”的远程劳动力网络，使在北京的具身训练师可远程精准控制远在CES展台的RealBOT轮式折叠机器人执行“递送物品”、“传递水果”等真实场景作业。远程作业网络的本质，是把真人操作力做成基础设施，将操作能力转化为可调度、可质检、可结算的网络化服务。该系统通过沉浸式远程操作界面，让操作者可以实时、精准地指挥机器人执行真实场景中的任务——从日常的叠毛巾、搬箱子，到需要一定经验的管廊巡检、电力管控等专业作业。这意味着睿尔曼交付的不只是机器人硬件，而是一套可持续供给的交互能力底座，能在不同场景里复用、扩张，并不断沉淀真实数据与行业标准。不仅能实现劳动力资源的跨时空高效配置，还将积累大量真实场景数据，反哺具身智能技术的迭代与突破。这得益于睿尔曼在真实场景下高质量数据的厚积薄发——北京人形机器人数据训练中心，通过108套具身本体和十大真实应用场景，已经积累了覆盖千余项任务、千万级轨迹片段的真机数据，并在近期正式宣布开源全球首个高质量、模态数量最多的真机数据集，旨在突破机器人研发中的数据壁垒，为全球学术界与工业界提供关键数据支撑，助力智能机器人算法的创新与产业化落地。百万产能：以规模化量产，保障全球市场的敏捷响应与稳定供给睿尔曼自2024年迈出全球化战略第一步至今，业务已覆盖亚洲、欧洲、北美及南美等多个地区。与三星电子、川崎重工、西门子、亚马逊、苏黎世联邦理工学院等全球顶尖企业及机构建立合作，目前在全球范围内已服务超过4000家企业用户。在工业自动化、科研教育、商业服务等领域积累了丰富的实战经验，持续赋能全球智能制造与创新应用。为突破行业瓶颈保障规模化交付，睿尔曼在硬件基础之上，逐步构建起“硬件+数据+远程作业网络”三大底层能力，贯通从动力关节、机械臂与机器人整机，到远程劳动力网络、数据资产，再到超级工厂与产业生态的全链路布局。2026年，睿尔曼将以 AUTRON （奥创）产线体系承载柔性、共线与规模化制造能力，实现百万级关节模组的年产能突破。这一规模化量产能力，不仅是数字的跨越，更是全球化布局的核心支撑。展会期间，睿尔曼展位汇聚了来自海内外的行业伙伴、专家学者与现场观众，就具身智能基础设施的核心价值与未来趋势交换了前瞻性见解，为睿尔曼把握全球市场动态、完善产品布局、深化本地化运营提供了重要参考。从一体化关节模组的可靠运行，到构建覆盖全球的远程作业网络，再到机器人超级工厂的全球供给，睿尔曼在CES 2026所呈现的是一个稳定可靠的、覆盖全球的机器人生产力系统。未来，睿尔曼将持续深耕具身智能基础能力建设，以技术创新为核心驱动力，以全球市场为发展舞台，打破技术、数据、成本壁垒，持续推动具身智能技术迭代升维，加速实现机器人服务人类社会的愿景。版权所有，未经授权不得以任何形式转载及使用，违者必究。CES 2026具身智能霍尔曼机器人十三杜比在CES 2026重塑了观影、娱乐的方式2026-01-07英特尔CES奇袭老黄大本营！英伟达显卡刚涨价，最强酷睿量产出货2026-01-06樱智α·医疗可信平台全新发布，北电数智与中日友好医院联合打造2026-01-04今年TRAE写的代码：100000000000行！超50%程序员每天在按Tab键2025-12-29扫码分享至朋友圈相关阅读训具身模型遇到的很多问题，在数据采集时就已经注定了丨鹿明联席CTO丁琰分享“国内UMI能训出模型的就三家”衡宇2026-01-08具身智能数据采集数采工厂鹿明机器人人形机器人主持发布会发布自己！追觅科技孵化，下月将参加全球首届人形机器人马拉松衡宇2025-03-27人形机器人具身智能追觅魔法原子90后清华博士厨房机器人融资数千万，拿下北京市首张具身智能机器人食品经营许可证成为全国第一个”持证上岗”的AI厨师梦晨2025-06-27具身智能李震宇也被曝创业具身智能了携手原华为车BU首席科学家一凡2024-12-13具身智能百度Apollo车圈最新认知黄仁勋CES回应全场！内存卡GPU脖子，游戏玩家可能只能用旧显卡了还领取了2026年IEEE荣誉奖章西风2026-01-08CES 2026英伟达黄仁勋宇树机器人被曝漏洞，机器人之间可相互感染，官方火速回应双足四足都中招了衡宇2025-09-30具身智能宇树机器人机器狗热门文章马斯克宣布：量产脑机接口，手术全自动化2026-01-02「北京版幻方」冷不丁开源SOTA代码大模型！一张3090就能跑，40B参数掀翻Opus-4.5和GPT-5.22026-01-02AI正在占领你的视频推荐流2026-01-02这里还有8个“Manus”：1亿美元ARR，都是ToC2026-01-03中国“人造太阳”突破密度极限，聚变点火迎来新路径 | Science子刊2026-01-03",
      "article_url": "https://www.qbitai.com/2026/01/367216.html",
      "author": "十三",
      "publish_time": 1767715200,
      "publish_date": "2026-01-07",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"CES 2026具身智能霍尔曼机器人\", \"具身智能数据采集数采工厂鹿明机器人\", \"人形机器人具身智能追觅魔法原子\", \"具身智能\", \"具身智能百度Apollo车圈最新认知\", \"CES 2026英伟达黄仁勋\", \"具身智能宇树机器人机器狗\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767827952,
      "last_modify_ts": 1767914254
    },
    {
      "id": 47,
      "article_id": "367659",
      "title": "傅利叶首秀CES 2026，全面展示“有温度”的人机交互",
      "description": "傅利叶首秀CES 2026，全面展示“有温度”的人机交互西风2026-01-0819:27:35来源：量子位GR-3靠“聊天下棋”圈粉海外观众美国拉斯维加斯，2026年1月6日—— 2026年1月6日至9日，一年一度的国际消费类电子产品展览会（CES 2026）在美国拉斯维加斯市盛大开幕。作为全球科技产业的“风向标”，本届CES聚焦环境化AI、具身智能、健康科技等前沿议题，汇聚了来自世界各地的创新",
      "content": "傅利叶首秀CES 2026，全面展示“有温度”的人机交互西风2026-01-0819:27:35来源：量子位GR-3靠“聊天下棋”圈粉海外观众美国拉斯维加斯，2026年1月6日—— 2026年1月6日至9日，一年一度的国际消费类电子产品展览会（CES 2026）在美国拉斯维加斯市盛大开幕。作为全球科技产业的“风向标”，本届CES聚焦环境化AI、具身智能、健康科技等前沿议题，汇聚了来自世界各地的创新技术与尖端产品。延续往届热度，具身智能依然是本届CES最受瞩目的焦点领域，行业领先的智能机器人企业傅利叶携新一代全尺寸人形机器人“Care-bot”GR-3及多款行业解决方案亮相展会，首次在海外系统性地展示具身智能在陪伴交互等真实场景中的落地应用，展现人形机器人在全球消费市场的广阔前景与巨大潜力。△GR-3在CES现场为观众介绍傅利叶展区锚定“人机交互”GR-3展示“有AI陪伴”在人工智能等前沿技术持续突破的驱动下，全球机器人产业正加速迈向深度转型。透过本届CES可以看到，更复杂、综合的“交互性功能”已超越单一的“运控智能”成为人形机器人的下一个价值增长点。为全面展示人机交互技术，傅利叶在CES现场特设互动体验区，邀请观众零距离接触机器人，亲身体验“有温度”的科技陪伴。凭借亲和的工业设计与高度自然的多模态交互能力，GR-3迅速成为全球观展者注意力的焦点，吸引大量观众上前与其交流对话、合影打卡。除了展示GR-3强大的情绪响应能力，傅利叶还在展台上策划了“井字棋”人机对弈互动。过程中，GR-3通过视觉识别实时感知棋盘状态，并结合逻辑推演与表情、语音、动作反馈，对对弈者的每一步动作作出拟人化的互动响应，带来兼具趣味性与情感温度的交互陪伴。△GR-3“井字棋”互动挑战赛作为傅利叶首款被赋予“Care-bot”定位的产品，GR-3采用莫兰迪暖调配色以及超跑级内饰面料与安全环保的内里，消解了传统机器人冰冷的机械感。机体配备的55个全身自由度，使其既能灵活调整姿态适应多元环境，又能适配现实环境中的高精度作业需求。为了更好应对多元场景，GR-3还搭载了集成视觉识别、声源定位和触感反馈的全感交互系统，可为用户打造自然生动的人机互动体验。同时，基于注意力管理机制，GR-3可以实现从多模态感知到智能决策再到动作规划的快速响应，能够真正实现“善解人意”、服务于人。全栈能力，赋能具身落地“真实场景”2026年有望成为人形机器人迈向商业化应用的关键之年。市场对人形机器人赛道的关注点也普遍趋于务实——能否在真实场景中实现可靠落地。对此，傅利叶认为，在AI赋予了具身智能“感知—决策—行动”的能力的背景下，人形机器人价值力的释放点将从“被动执行”向“主动交互”跃迁。唯有借助“主动交互”，人形机器人才能打破技术孤岛，实现技术在显示场景中的深度闭环应用，进而加速商业化进程。围绕“主动交互”理念，傅利叶构建了覆盖核心零部件研发、机器人本体设计到交互智能开发的全栈式技术体系，并打造了软硬一体的主动交互型智能机器人平台。依托该平台，公司正持续在环境感知、运动控制、灵巧操作、商业化落地等六大维度实现突破，并进一步明确了未来机器人的发展方向和应用目标：Social Companion（社交陪伴）适用于公共空间、教育环境，承担独居老人陪伴、儿童互动玩伴等角色；Assistive Companion（辅助陪护）覆盖行动辅助、健康监测、康复训练等专业场景，未来将深入康复机构、养老院提供精准服务。△傅利叶在CES现场首展最新桌面级陪伴交互机器人原型机值得一提的是，除GR-3外，傅利叶在本届CES上还展出了一款沿用相同IP设定的桌面级“Care-bot”机器人概念原型。该原型采用玩偶尺寸设计，支持外观定制与交互人格配置，旨在探索具身智能在更轻便、随身形态下，实现全天候情感陪伴的可能。尽管尚处于早期开发阶段，但这一尝试再次印证了傅利叶的技术信念：有意义的主动交互，可以在任意场景中实现。以人为本，共创“有温度”的未来当前，中国机器人产业正以前所未有的速度走向世界舞台。海关总署最新公布的数据显示，当前，我国机器人应用场景更加丰富，不断走俏国际市场，前三季度我国出口工业机器人增长54.9%。随着技术成熟与品牌影响力的提升，中国人形机器人有望接棒成为新一轮“出海潮”的主力军。作为首次独立参加CES的企业，傅利叶此次亮相不仅彰显了中国企业在人形机器人领域进行全球化布局的信心，也承载着公司以“立足康养、聚焦交互、服务于人”发展战略赋能全球未来产业的愿景。目前，傅利叶已为全球40多个国家和地区的2000余家医疗机构及机构客户提供服务，并与超过20家全球顶尖高校、科研机构及科技企业建立合作，共同拓展具身智能的技术边界，加速技术在多行业、多场景的真实落地。展望未来，傅利叶将始终坚持“以人为本、服务于人”的技术初心，携手全球产业伙伴，通过开放协作与持续创新，推动技术更具人文温度，让机器人更自然地融入医疗康养、导览互动、学术科研以及效率赋能等更广泛的真实场景，为人类生活赋能。版权所有，未经授权不得以任何形式转载及使用，违者必究。上海傅利叶人形机器人人形机器人GR-3西风开源“裸考”真实世界，国产具身智能基座模型拿下全球第二！2026-01-08黄仁勋CES回应全场！内存卡GPU脖子，游戏玩家可能只能用旧显卡了2026-01-08豆包一声声“OK”把罗永浩搞破防，不就是大型现场直播版图灵测试2026-01-01AI终于学会在家“伺候人”！Hey Tuya，我躺了2025-12-31扫码分享至朋友圈相关阅读马斯克让23位技术新星站到AI Day台前，4位华人担任要职还有武汉理工大学校友邓思邈2022-10-02人形机器人智能车真high特斯拉自动驾驶马斯克机器人开始抢“主持人”饭碗！上海张江，傅利叶宣布下个十年规划，要做“以人为本的具身智能”不管是什么形态，背后做的其实就是人机交互这一件事西风2025-05-10上海傅利叶机器人好爽！我在上海被机器人“马杀鸡”了体验了下特殊服务，结果这不是人干的十三2021-07-08人工智能人形机器人优必选科技14万！全球首款家务机器人开卖，OpenAI投资，萌脸翘臀会自己充电扫地喂猫样样精通衡宇2025-10-291X人形机器人具身智能家务机器人断交OpenAI后，人形机器人独角兽首秀：一个神经网络控制整个上身，能听懂人话可抓万物还有新的Scaling Law白交2025-02-21Figure人形机器人引领通用具身新时代：普渡发布首款类人形机器人PUDU D7将在2025年实现全面商业化落地白交2024-09-19人形机器人热门文章这里还有8个“Manus”：1亿美元ARR，都是ToC2026-01-03中国“人造太阳”突破密度极限，聚变点火迎来新路径 | Science子刊2026-01-03百度AI芯片公司冲刺IPO：出货量国产第二2026-01-03机器人也怕疼！港城突破性电子皮肤：主动痛觉+损伤自检buff拉满2026-01-03OpenAI首款硬件定型为笔！网友：就叫oPen吧2026-01-04",
      "article_url": "https://www.qbitai.com/2026/01/367659.html",
      "author": "西风",
      "publish_time": 1767801600,
      "publish_date": "2026-01-08",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"上海傅利叶人形机器人人形机器人GR-3\", \"人形机器人智能车真high特斯拉自动驾驶马斯克\", \"上海傅利叶机器人\", \"人工智能人形机器人优必选科技\", \"1X人形机器人具身智能家务机器人\", \"Figure人形机器人\", \"人形机器人\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767914238,
      "last_modify_ts": 1768000747
    },
    {
      "id": 48,
      "article_id": "368641",
      "title": "太初元碁发布国产高兼容性虚拟指令集PCX及高性能工业级编译器PCXAC",
      "description": "太初元碁发布国产高兼容性虚拟指令集PCX及高性能工业级编译器PCXAC量子位的朋友们2026-01-0919:12:28来源：量子位跨硬件平台迁移成本大幅降低日前，国产AI芯片企业太初元碁发布首个高兼容性虚拟指令集PCX及高性能工业级编译器PCXAC，并上架至其官网文档中心平台。PCX（Parallel Computing eXecution）是太初元碁推出的与具体硬件架构无关的虚拟指令集（Vir",
      "content": "太初元碁发布国产高兼容性虚拟指令集PCX及高性能工业级编译器PCXAC量子位的朋友们2026-01-0919:12:28来源：量子位跨硬件平台迁移成本大幅降低日前，国产AI芯片企业太初元碁发布首个高兼容性虚拟指令集PCX及高性能工业级编译器PCXAC，并上架至其官网文档中心平台。PCX（Parallel Computing eXecution）是太初元碁推出的与具体硬件架构无关的虚拟指令集（Virtual ISA），通过对底层的各类计算单元（如计算核心、存储架构）进行逻辑抽象，提供了稳定且可移植、可扩展的并行计算模型，具有强兼容特性，能够显著降低跨硬件平台的迁移成本。据了解，PCX虚拟指令集可实现多层次存储等级抽象与多线程并行编程模型，囊括有符号整数、无符号整数、布尔类型、浮点类型、向量类型、字节数组、字符串等不同数据类型。支持用户在SDAA C程序中嵌入PCX指令，实现对关键计算路径的精细优化，有效提升程序在硬件上的执行效率。SDAA C高级编程语言和TecoPyTorch、Teco-vLLM等深度学习框架通过使用PCX虚拟指令，屏蔽了太初元碁不同系列硬件的机器指令和微架构的差异。PCXAC是PCX虚拟指令集的编译系统，由太初元碁自主研发，能够将PCX虚拟指令转换为指定系列的太初AI加速卡的机器指令，从而屏蔽不同系列硬件的底层差异，即同一版本的PCX指令集可以在太初元碁多种系列的硬件上直接编译并高效执行，将程序与不同系列的硬件解耦，有效解决硬件迭代快，软件适配成本高的问题。同时，PCXAC提供完整的开发者分析工具集，包括静态检查工具和动态检查工具，覆盖从编码到运行的全流程，助力用户更早发现、更快定位潜在缺陷，提升开发效率与代码质量。其中，静态检查工具在PCX指令编译期间，提前预警内存泄漏等隐患；动态检查工具可在PCX指令执行期间，动态检测越界访问、未初始化使用等深层问题。作为一款工业级轻量编译器，PCXAC仅需基础编译环境即可运行，减少开发环境搭建的复杂度与兼容性问题，开发者可快速启动编译工作，降低环境配置成本；且在编译过程中对系统资源占用少，避免因编译器运行导致的资源争抢，提升资源利用率。当前，国际主流指令集存在高技术壁垒问题，编译器性能瓶颈凸显，导致不同硬件平台间迁移成本高、硬件算力难以充分释放，从而制约了国产智算算力规模化落地应用。太初元碁官方消息指出，在其T100 加速卡上，太初元碁对深度学习算子（卷积、规约等）进行严格的单卡性能对比测试。实测结果显示：使用 PCX 虚拟指令集编译生成的程序，其运行时性能较基于 LLVM 编译的版本有大幅提升。实测数据表明，PCX 能够深度适配国产硬件，且其编译器 PCXAC 能够充分将硬件算力转化为性能优势。PCXAC在性能上超越了业界主流的 LLVM，充分释放硬件算力。PCXAC 相较 LLVM 的性能提升，不仅证明 PCXAC 编译器在国产算力转化效率上的领先性，更预示着在实际场景中能够大幅降低训练与推理的时间成本。据介绍，太初元碁通过参与开源生态建设与软件栈生态搭建，为开源社区、个人开发者提供全方位国产智算算力技术支持。目前，太初元碁已在包括GitHub、Gitee、Atomgit等平台深度参与paddle、Torch、OpenDataLab、HuggingFace、Vllm、DeepSpeed、Lightning等多个开源社区/项目的建设，并在GitHub平台上开放了多个已适配太初AI加速卡的开源项目来为开发者赋能。同时，依托主流AI社区Torch生态，通过系统性攻坚与开放协作，太初元碁联合10余家高校，累计适配600余个主流及垂直领域模型，迁移超200个长尾Torch生态算子至太初SDAA生态上，并凝聚超120高校开发者深度参与共建，推动人工智能技术在国产加速卡上深度普惠。版权所有，未经授权不得以任何形式转载及使用，违者必究。太初元碁量子位的朋友们华为小米蔚来抢爆新年新车申报！都很豪华2026-01-09清华AI找药登Science！一天筛选10万亿次，解决AlphaFold遗留难题2026-01-09老外对屏狂拍！海信全新一代RGB-Mini LED电视亮相轰动CES20262026-01-07OceanBase蝉联中国分布式数据库本地部署市场第一，领跑国产数据库2026-01-07扫码分享至朋友圈相关阅读太初元碁携手申威亮相2025世界物联网博览会将自主创新的智能计算能力转化为教育高质量发展的新动能量子位2025-11-04太初元碁物博会热门文章OpenAI首款硬件定型为笔！网友：就叫oPen吧2026-01-04LeCun曝Meta作弊刷榜，田渊栋：我没想到这个结局2026-01-04樱智α·医疗可信平台全新发布，北电数智与中日友好医院联合打造2026-01-04字节Seed：大概念模型来了，推理的何必是下一个token2026-01-05B站开启AI创作大赛，首次开放《三体》改编权，奖金总计超300万2026-01-05",
      "article_url": "https://www.qbitai.com/2026/01/368641.html",
      "author": "量子位的朋友们",
      "publish_time": 1767888000,
      "publish_date": "2026-01-09",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"太初元碁\", \"太初元碁物博会\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768000741,
      "last_modify_ts": 1768087069
    },
    {
      "id": 50,
      "article_id": "368598",
      "title": "清华AI找药登Science！一天筛选10万亿次，解决AlphaFold遗留难题",
      "description": "清华AI找药登Science！一天筛选10万亿次，解决AlphaFold遗留难题量子位的朋友们2026-01-0916:57:18来源：量子位一天筛选十万亿次，中国AI找药又有新突破！清华大学智能产业研究院（AIR）联合清华大学生命学院、清华大学化学系在Science上发表论文：《深度对比学习实现基因组级别药物虚拟筛选》。团队研发了一个AI驱动的超高通量药物虚拟筛选平台DrugCLIP。DrugC",
      "content": "清华AI找药登Science！一天筛选10万亿次，解决AlphaFold遗留难题量子位的朋友们2026-01-0916:57:18来源：量子位一天筛选十万亿次，中国AI找药又有新突破！清华大学智能产业研究院（AIR）联合清华大学生命学院、清华大学化学系在Science上发表论文：《深度对比学习实现基因组级别药物虚拟筛选》。团队研发了一个AI驱动的超高通量药物虚拟筛选平台DrugCLIP。DrugCLIP能让AI从海量化学分子里，迅速筛出那些最有希望和疾病相关蛋白结合的“候选药物分子”。24小时内，DrugCLIP能完成10万亿次蛋白–分子配对计算。依托该平台筛选，团队打通了从AlphaFold结构预测到药物发现的关键通道，不仅为抑郁症、癌症、帕金森等疾病筛选出了潜在药物分子，还首次完成了覆盖人类基因组规模的药物虚拟筛选。目前，相关数据已经全部对外开放。90%的蛋白靶点难找药过去药物筛选的难点，主要集中在三点上，一是慢，二是无从下手，三是范围太窄。先看一个背景数字。人体内大约有2万个编码蛋白质的基因，其中的相当一部分与癌症、抑郁症、神经退行性疾病密切相关。但现实是，目前真正拥有成熟药物的蛋白靶点，只占其中10%，剩下的90%，还没找到药。△化学空间大小示意图（引用：Gastreich, M. BioSolveITDrugSpace2022）第一个原因，慢。传统的筛选方法，比如分子对接，需要逐一计算“这个分子能不能和这个蛋白结合”，一次评估虽然只要几秒钟或几分钟，但在现实情况下，以筛选1万个蛋白质靶点、每个靶点面对10⁹个候选分子为例，需完成约10¹³次蛋白-配体打分。即便使用当前最先进的分子对接工具，也得需要2亿CPU天。第二个原因，无从下手。很多疾病相关蛋白根本没有实验测出来的三维结构，传统方法无从下手。而且在真实世界里，没用的分子还远比有用的分子多，这些好分子容易被埋没在噪声里。第三个，范围太窄。算力成本摆在这儿，只能围绕热门靶点筛，工作很难在全基因组的尺度上推进。不过，DrugCLIP正是冲着这三点来的。给蛋白和分子画像先概括一下它的方法，就是先教会AI为目标进行画像，捕捉其结构神韵，再做极速配对。研究者用对比学习训练了两个AI编码器。一个给蛋白质上的结合口袋画像，另一个给化学分子画像。“结合口袋”是指蛋白质表面能够与小分子结合的特定区域，这里的“画像”是指生成特征向量。训练时，AI会被明确告知：能结合的一对儿，画像要尽量接近，即对应的特征向量要尽可能相似；不能结合的，画像要尽量拉远。这样一来，AI就能逐渐学习并掌握蛋白质与分子之间的结合规律。为了让模型从一开始就领悟这种结构神韵，团队设计了一套创新性的预训练策略。他们从已有的蛋白质结构数据中，切割出短片段模拟成“假分子”，同时将周围区域当作“假口袋”，一次性构造出了550万组训练样本。在这套练手数据上打好基础后，再用真实的蛋白-分子数据进行微调，保证了泛化能力和精度。模型训练完成后，真正的筛选过程就变得简单高效了。DrugCLIP创新性地将传统基于物理对接的筛选流程转化为高效的向量检索问题。研究者先把5亿个候选分子全部画像完存起来，当遇到一个新的蛋白口袋时，只需要给它生成一个向量表示，再和所有的分子算相似度、排个名，排在前面的就是最有希望的候选分子。该模型结合对比学习、3D结构预训练与多模态编码技术，能在三维结构层面精准建模蛋白-配体间的相互作用。训练后的高潜力分子将自然聚集于目标蛋白口袋的向量邻域，能够有效支撑快速的大规模虚拟筛选。依托这一机制，DrugCLIP在128核CPU+8张GPU的计算节点上日处理能力达10万亿次，对比传统方法实现了百万倍提升。首次完成了人类基因组规模的虚拟筛选速度之外，更关键的是它真能找到有用的分子。在标准的虚拟筛选基准测试DUD-E、LIT-PCBA中，DrugCLIP在把有效分子从大量无效分子中提前筛出来这件事上，明显优于传统分子对接工具和多种已有AI方法。并且在LIT-PCBA数据集上筛选速度远超其他方法。而且它对结构误差、陌生蛋白家族、从未见过的分子类型都表现得相当稳定，没有出现“一换场景就失灵”的问题。实验室验证结果也让人眼前一亮。以抑郁症相关蛋白为例，研究者从筛选出的78个分子里，找到8个能激活这个蛋白的“激动剂”。其中最好的一个分子，和蛋白的结合能力达到21nM（数值越小结合越强，100nM以下就是优秀水平），在细胞系中也有显著活性。△画中的宇宙飞船DrugCLIP作为终极导航者，以前所未有的效率识别潜在的活性化合物。团队还与清华大学闫创业教授团队合作，在去甲肾上腺素转运体（NET）这一临床相关靶点上开展了系列生物实验验证。NET是2024年才刚解析出结构的靶点，是抑郁症、注意缺陷多动症以及疼痛等疾病的重要靶点，目前虽然有多款抑制剂已经上市，但是在选择性等方面仍然有巨大的优化空间。团队使用DrugCLIP模型从160万个候选分子中筛选出约100个高评分分子，同位素配体转运实验检测显示其中15%为有效抑制剂，其中12个分子结合能力优于现有抗抑郁药物安非他酮。相关复合物结构已通过冷冻电镜解析，进一步验证了DrugCLIP筛选结果的生物学可信度。DrugCLIP还支持对AlphaFold预测的蛋白结构和apo（无配体）状态下的蛋白口袋进行筛选。团队和清华大学刘磊教授团队合作，针对E3泛素连接酶TRIP12（thyroid hormone receptor interactor 12）的HECT结构域进行了虚拟筛选与实验验证。当时这是一个既没有实验结构、也没有任何已知抑制剂的蛋白，与癌症和帕金森病密切相关。团队使用DrugCLIP模型对AlphaFold2预测的蛋白质结构进行筛选，从160万个候选分子中高通量筛选出约50个高评分分子。SPR实验证实其中10个分子与TRIP12有结合能力，两个亲和力较高的分子也对TRIP12的泛素连接酶活性有一定的抑制活性。在单靶点验证之外，DrugCLIP还完成了一次前所未有的全局筛选。△人类基因组规模筛选项目覆盖的蛋白数目与现有数据库对比研究团队首次完成了人类基因组规模的虚拟筛选项目，覆盖约1万个蛋白靶点、2万个结合口袋，分析超过5亿个小分子，富集出200万余个高潜力活性分子。构建了目前已知最大规模的蛋白-配体筛选数据库，为后AlphaFold时代的创新药物发现带来了新的可能性。换句话说，这相当于为人类近一半的蛋白质，都提前找好了潜在的“药物种子”。△像一位艺术家构想全新的世界，DrugCLIP框架在广阔而多维的蛋白–配体相互作用空间中自由穿行。该数据库已面向全球科研社区开放。DrugCLIP团队介绍DrugCLIP由清华大学智能产业研究院（AIR）博士后贾寅君、计算机系博士生高博文、生命学院博士后谭佳鑫、化学系博士后郑济青以及智能产业研究院（AIR）博士后洪鑫为共同一作。通讯作者为智能产业研究院（AIR）兰艳艳教授，生命学院张伟副教授、闫创业副教授以及化学系刘磊教授。该项目得到了国家科技部重点研发项目、国家自然科学基金委项目、新基石研究基金等项目的支持，同时还有清华大学无锡应用技术研究院智能产业创新中心、北京智源人工智能研究院与北京结构高精尖中心等机构的支持。未来，DrugCLIP将与科研产业生态合作伙伴深度合作，在抗癌、传染病、罕见病等方向加速新靶点与First-in-class药物的发现。值得一提的是，清华大学智能产业研究院（AIR）还与北京智源人工智能研究院在2021年联合成立了清华（AIR）-智源健康计算联合研究中心。该中心致力于应用最前沿的人工智能技术赋能健康管理、精准诊疗与新药研发，以数据驱动的全新科研范式突破生命健康领域核心技术。清华大学智能产业研究院（AIR）首席研究员兰艳艳、智源健康计算研究中心负责人叶启威任联合研究中心主任。版权所有，未经授权不得以任何形式转载及使用，违者必究。AI制药量子位的朋友们太初元碁发布国产高兼容性虚拟指令集PCX及高性能工业级编译器PCXAC2026-01-09华为小米蔚来抢爆新年新车申报！都很豪华2026-01-09老外对屏狂拍！海信全新一代RGB-Mini LED电视亮相轰动CES20262026-01-07OceanBase蝉联中国分布式数据库本地部署市场第一，领跑国产数据库2026-01-07扫码分享至朋友圈相关阅读什么样的AI制药创企才能走得更远？来听听业内怎么说｜直播报名2022-03-03AI制药如何降低AI药物在临床试验时失败的概率？丨对撞派·圆桌实录量子位2022-07-13AI制药智库量子位活动合辑临床前药物研发，AI搞出来的已经占一半了？ | 对撞派 · 圆桌实录制药产业里，AI真能有这么大作用？丰色2022-06-02AI制药一文看懂AI制药七大趋势丨量子位智库量子位2022-07-13AI制药智库量子位活动合辑临床前药物研发，AI搞出来的已经占一半了？ | 对撞派 · 圆桌实录量子位2022-07-13AI制药智库量子位活动合辑AI真·炼丹：整整14天，无需人类参与AI制药已进入“自动驾驶”模式十三2024-06-30AI制药CPU英特尔英矽智能热门文章OpenAI首款硬件定型为笔！网友：就叫oPen吧2026-01-04LeCun曝Meta作弊刷榜，田渊栋：我没想到这个结局2026-01-04樱智α·医疗可信平台全新发布，北电数智与中日友好医院联合打造2026-01-04字节Seed：大概念模型来了，推理的何必是下一个token2026-01-05B站开启AI创作大赛，首次开放《三体》改编权，奖金总计超300万2026-01-05",
      "article_url": "https://www.qbitai.com/2026/01/368598.html",
      "author": "量子位的朋友们",
      "publish_time": 1767888000,
      "publish_date": "2026-01-09",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"AI制药\", \"AI制药\", \"AI制药智库量子位活动合辑\", \"AI制药\", \"AI制药智库量子位活动合辑\", \"AI制药智库量子位活动合辑\", \"AI制药CPU英特尔英矽智能\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768000743,
      "last_modify_ts": 1768087071
    },
    {
      "id": 52,
      "article_id": "367855",
      "title": "起猛了，追觅的扫地机、割草机、洗护机器人在CES成精了！",
      "description": "起猛了，追觅的扫地机、割草机、洗护机器人在CES成精了！henry2026-01-0912:39:37来源：量子位具身智能家用最速量产，可能来自一家扫地割草的公司henry 发自 凹非寺量子位 | 公众号 QbitAI火爆，今年的CES相比以往更火爆，而且在AI浪潮下，最火爆的莫过于具身智能。走到现场就能直观感受到，具身智能正加速涌入家用场景，家庭化量产的信号已经清晰可见。没错，就是那个以家用机器",
      "content": "起猛了，追觅的扫地机、割草机、洗护机器人在CES成精了！henry2026-01-0912:39:37来源：量子位具身智能家用最速量产，可能来自一家扫地割草的公司henry 发自 凹非寺量子位 | 公众号 QbitAI火爆，今年的CES相比以往更火爆，而且在AI浪潮下，最火爆的莫过于具身智能。走到现场就能直观感受到，具身智能正加速涌入家用场景，家庭化量产的信号已经清晰可见。没错，就是那个以家用机器人为人熟知的追觅，带来了多款「具身智能」产品。在CES现场看过产品后，不少观众还得出来一个令人惊叹的结论，这可能会是具身智能家庭化量产进程里最快的公司。给家电安上胳膊和腿，不性感，但有效这年头的家用机器人，已经开始成精了，这是今年追觅CES展台给人最直观的感受。从外形上看，它们依然仍采用家电形态，但不少产品，已经拥有了AI智能大脑的能力，能够自主决策与执行任务，“腿”和机械臂逐渐开始成为标配。换句话说，这是一批“长出腿脚的家电”。它们已经不再局限于执行单一的家务，而是基于具身智能技术朝多功能的家庭服务机器人迈进。AI具身智能洗护机器人在这批新品里，最先让人围观驻足的，当属追觅的AI具身洗护机器人。它最核心的突破，是把“置物-洗衣-烘干”的全流程彻底“打包接管”：从脏衣篓自主拾取衣物，到按材质分类洗涤、烘干，全程无需人工介入。而且，它不只是能自己搞定抓衣服、放洗衣机、进烘干机这一套，还能摸清家里的环境，记着用户的使用习惯。相较之下，过去一些人形机器人只能完成“把衣服放进洗衣机”的半自动演示，仍停留在任务拆解与约束阶段。而追觅的AI具身洗护机器人，则可以实现真正的任务闭环执行。在形态上，它整体由轮式底座、机械臂以及末端执行器（夹爪）构成。此外，为了应对衣物这类柔性物体的抓取与放置，AI具身洗护机器人还配备了多模态感知系统。它通过视觉、触觉等感知手段，同时具有AI能力，能够处理不同类别和材质的衣物，从而真正实现家庭洗衣的全流程托管。具身智能割草机器人另一款让人眼前一亮的机器人，是这次首次亮相的具身智能割草机器人。先说最直观的感受——它居然能浇水！这可不是抢了“园丁”的活那么简单。对机器人而言，在移动过程中完成倒水，本身就意味着对空间定位、动作协调和精细操作能力的更高要求。一旦这类由AI赋能的能力能够稳定实现，拾取、整理、清扫，反而成了顺手的事。无论是收拾孩子的玩具、处理庭院里的杂物，还是修剪枝叶、使用不同工具，这套能力都可以自然迁移。也正因如此，对于这款被定位为割草机的机器人来说，割草这件事反而是最简单，最不用多说的事儿。具身智能新物种此前预热已久的“具身智能新物种”，也于这次CES露出真面目。从外形上看，它有着四足轮腿，同时有着清晰的躯干、机械臂，夹爪，以及用于环境感知的视觉传感器，来拥有执行和感知能力。这种结构设计，让它开始向更复杂的家务场景延伸。一方面，依托底座的四足轮腿结构，它可以跨越门槛、台阶，甚至上下楼梯，实现真正意义上的全屋清扫。另一方面，借助仿生双臂和夹爪，它可以承担叠衣物、倒垃圾、擦桌子等功能，且可自主处理衣物叠放、物品递送、桌面整理等多样化家务。更令人惊叹的是，它创新性整合了居家养老服务模块，可提供24小时健康监测、跌倒预警与药品递送等功能，精准切入了多代同堂家庭的核心关切。而这些动作，正是现在人形机器人想要做好的“标志性能力”。值得一提的是，长出“手”的扫地机不止一款。以Cyber10 Ultra为例，它搭载5自由度机械手，靠AI视觉识别就能自主完成“抓取-分类-收纳”全流程。此外，针对多层住宅家庭，追觅的仿生爬楼机Cyber X，还能带着上面这些扫地机在各类楼梯上“自由上下”，实现又快又稳地攀爬。它最快可以达到0.2米每秒，最高可爬上35cm的台阶，爬完一层楼只需要不到半分钟，而且在爬楼的过程中也可以清扫楼梯。同时，在三重制动防护系统下，爬楼机在木质、硬地面或铺地毯的楼梯都可以稳定行走，哪怕在电力耗尽情况下也能保持稳定。这意味着，机器人的清扫不再被限制在单层空间，而是开始把整个房屋视作一个连续、可行动的空间。具身智能泳池机器人还没完，追觅甚至把这套能力，搬进了水下。在这次CES，追觅首次展出了具身智能泳池机器人Z2 Ultra Cyber。同样是“长了胳膊”，但放到水下，变化一下子就直观了起来。它不再只是贴着池底跑路线，而是能停下来，伸“手”去处理一些过去必须人下水才能解决的地方。比如排水口滤网的堵塞物、池壁和台阶边缘的顽固污渍，这些细碎又麻烦的活，它都能直接接手。为了更稳地找到杂物和脏污的位置，这台泳池机器人还会先进行3D建图，再根据识别结果逐项完成清洁。总的来看，在这次CES上，变聪明的，并不只是前面提到的洗护机、割草机、扫地机们……在追觅的展台上，还能看到长出双机械臂的洗地机，以及左右送风可以独立调节的双机械臂空调。虽然形态各不相同，但做的其实是同一件事——让家电具备智能感知环境、调整行为、自主完成任务的能力。不难看出，这些外形仍然像家电的机器人，正在从“只会干一件事”的工具，逐步演化为能在同一环境中承担多类任务的物理智能体。而支撑这些任务开始稳定落地的，正是追觅通过“具身智能”在家用机器人身上完成的一次产品升级。从清洁工具到家庭服务机器人在行业的传统认知里，扫地机、割草机，甚至工业机械臂，更多还是单一工具属性。它们依赖SLAM这些经典机器人学方法，在结构化、可预期的环境中执行单一、重复的任务。而以人形机器人为代表的具身智能，瞄准的则是完全不同的方向：能否在真实、开放的环境里，应对复杂多变的任务场景。支撑这种能力的，是数据驱动的学习范式，以及完整的感知-理解-决策-执行行为闭环。△AI生成正因为这条技术分界线长期被视为共识，追觅将多类家电产品升级为具身智能产品的做法，才可以称为给出一个行业新思路。而追觅在CES现场给出的线索是：这些产品正在跨过单一工具属性的边界，在家庭这一高度不确定的环境中，开始具备独自思考的能力，真正实现具身智能的逻辑闭环。比如，追觅的AI具身洗护机器人，执行洗衣任务时不是按预设步骤走流程。它会自主识别脏衣篓里的衣物、抓取分拣，接着完成洗涤、烘干，全程无需人工介入。而这些能力的实现，不再只靠传统规则控制，而是融入了VLA（视觉语言模型）与模仿学习，通过数据驱动的方式，让机器人的操作逻辑更贴近人类的自然动作。这也让它在家用场景里，初步跑通了 “感知环境→理解任务→决定动作→执行落地” 的完整链路。在追觅的规划里，这种 “能看见但依赖规则” 的状态，只是具身智能1.0版本；而在追觅后续的roadmap中，随着数据驱动的具身算法持续落地，机器人将从“看得见”，进化到“会自己决定怎么做”，并最终与家庭场景深度融合——从单一的清洁工具，走向真正意义上的家庭服务机器人。家用具身量产的工程解法如果把目光从概念层拉回到“能不能进家庭、能不能卖出去”，追觅这套“家用具身”的路径，确实与当前多数玩家不太一样。一方面，通用人形机器人仍然卡在技术、成本、稳定性与量产等硬门槛上；而另一边，加载具身智能能力的小型桌面设备、情感陪伴硬件，往往停留在互动层面，难以承担真实、持续的家务劳动。尤其在经历了2025具身智能元年的“热辣滚烫”，2026年的具身赛道也将趋于冷静：没有明确功能价值、没有成熟渠道、没有现金流自循环能力的产品，很可能直接被市场淘汰。也正因如此，追觅选择以具身能力对扫地、割草、洗护、泳池清洁等已有成熟需求和出货规模的家用机器人进行能力升维，本质上是一种更务实、也更可持续的路线选择。具身能力在这里，是被用来扩展产品边界、提升任务完成度的增量能力。更关键的是，这种路径并非凭空起跳。追觅过去在智能算法、高速数字马达、运动控制、视觉感知、整机工程化上的长期投入，伺服电机、关节模组、导航与感知系统可以在多个品类之间复用。此外，大规模出货本身也构成了一套持续运转的数据回路。在真实家庭环境中的长期运行，设备能不断积累感知、决策与执行层面的反馈数据，为具身能力的工程化迭代提供了多数实验型项目难以获得的现实基础。相比于追求双腿人形结构的具身智能，像追觅这样的具有优势工具属性的具身智能机器反而可能是最先通用的。“具身智能家庭化量产落地的最快选手”结合行业既有路径来看，追觅的具身智能路线并不追求最接近“人”的形态，而是更在意把具身的思考、执行能力真正做进家庭。也正是在CES现场，开始有这样的评价出现：“在实现具身智能家庭化量产落地上，它可能还是目前进度最快的选手。”人形机器人比拼的是通用智能与结构突破，而家用具身设备，则更现实地需要考虑工程化、成本控制与量产体系——这恰恰是追觅过往反复验证过的能力。一方面，正如前述，追觅在扫地机器人等消费级机器人领域长期积累的工程化经验，使其能够有效地将相关技术和供应链优势，复用到这波具身智能产品升级的浪潮中。另一方面，追觅从来都是一家以速度见长的公司。从2024年2月全球首创双机械臂X40发布，到2025年推出仿生多关节机械手X50 Cyber，再到如今2026年CES展出能爬楼梯的Cyber X，追觅仅用2年时间，就完成了行业平均3-4年的技术量产闭环。具身智能未来是否一定会沿着“任务型专用设备，不断叠加功能”的方向演进，仍然存在变量，通用人形是否会在成本、通用性，可靠性上实现突变，也仍未可知。但至少在当下，当大多数具身智能还停留在展望未来时，追觅已经开始聚焦当下，用具身智能能力真正服务每个用户的家。版权所有，未经授权不得以任何形式转载及使用，违者必究。追觅henryHinton的亿万富豪博士生2026-01-10吴恩达：图灵测试不够用了，我会设计一个AGI专用版2026-01-10真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Image2025-12-31华为云CEO周跃峰：要避免AI成为“泡沫” 必须要提升行业生产力2025-12-30扫码分享至朋友圈相关阅读人形机器人主持发布会发布自己！追觅科技孵化，下月将参加全球首届人形机器人马拉松衡宇2025-03-27人形机器人具身智能追觅魔法原子追觅发布人形机器人和仿生四足机器狗二代“通用人形机器人未来可能会是目前很多家用产品的终极进阶版。”明敏2023-03-29人形机器人追觅又一个扫地的宣布造车了创始人清华校友，小米生态链公司一凡2025-08-28车圈最新认知追觅热门文章OpenAI首款硬件定型为笔！网友：就叫oPen吧2026-01-04LeCun曝Meta作弊刷榜，田渊栋：我没想到这个结局2026-01-04樱智α·医疗可信平台全新发布，北电数智与中日友好医院联合打造2026-01-04字节Seed：大概念模型来了，推理的何必是下一个token2026-01-05B站开启AI创作大赛，首次开放《三体》改编权，奖金总计超300万2026-01-05",
      "article_url": "https://www.qbitai.com/2026/01/367855.html",
      "author": "henry",
      "publish_time": 1767888000,
      "publish_date": "2026-01-09",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"追觅\", \"人形机器人具身智能追觅魔法原子\", \"人形机器人追觅\", \"车圈最新认知追觅\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768000746,
      "last_modify_ts": 1768087075
    },
    {
      "id": 53,
      "article_id": "368903",
      "title": "离开马斯克后，他把人形机器人做成了这样",
      "description": "离开马斯克后，他把人形机器人做成了这样思邈2026-01-1016:14:31来源：量子位集齐特斯拉/英伟达/OpenAI班底，最新产品曝光允中 发自 凹非寺量子位 | 公众号 QbitAI如果你对人形机器人的印象，还停留在——走两步就摔、抓东西像戴着拳击手套、干活前得先写一堆脚本……那么MATRIX-3的出现，可能要强行带你“翻篇”了。作为一款主打安全、自主、可泛化的物理智能机器人，它更敢跟人待",
      "content": "离开马斯克后，他把人形机器人做成了这样思邈2026-01-1016:14:31来源：量子位集齐特斯拉/英伟达/OpenAI班底，最新产品曝光允中 发自 凹非寺量子位 | 公众号 QbitAI如果你对人形机器人的印象，还停留在——走两步就摔、抓东西像戴着拳击手套、干活前得先写一堆脚本……那么MATRIX-3的出现，可能要强行带你“翻篇”了。作为一款主打安全、自主、可泛化的物理智能机器人，它更敢跟人待在同一个空间，更能自己做判断，也更不怕换任务、换环境。能干的活更像人，目标也不止于专业场景“打工”，而是开始往日常生活里迈。做出这台机器人的，是一家去年才正式走到台前的公司——矩阵超智。但底子不轻、来头不算低调：公司团队背景横跨特斯拉、英伟达、OpenAI等顶级技术体系，目标也非常直给：AGI路线上的通用人形机器人。可以说，一年前，MATRIX-1亮相时，外界更关注两点：全身复合材料带来的“观感完成度”，以及实时语音对话的交互感。但这次，创始人张海星——这位有着30年消费电子实战经验的“老极客”，2021年加入特斯拉，参与Optimus人形机器人开发，并主导特斯拉中国设计中心相关项目——显然想通过从底层算法到顶层应用的系统性重构，让机器人走得更远：进工厂，飞入寻常百姓家。△矩阵超智创始人兼CEO张海星走向可泛化的人形MATRIX-3能够执行类似人类的任务，并准备好从专业场景走进人类日常生活的广阔天地，这标志着人形机器人从“执行预设指令”迈入“理解并适应物理世界”的新阶段。为实现这一跨越，矩阵超智的工程团队突破了材料科学、驱动技术、感知算法与人工智能的多重边界，为MATRIX-3注入了以下三大优势：仿生设计与感知新生：首次将仿生肤质与高维触觉传感深度融合，使机器人获得接近人类的物理交互直觉。灵巧操控与拟人步态：通过“灵犀之手”与“超能关节”，实现了前所未有的操作精度与如影随形的自然移动能力。认知内核与零样本泛化：搭载的全新神经网络具备强大的零样本学习能力，使机器人能快速适应未知任务与复杂环境。MATRIX-3为人形机器人的规模化、实用化铺平了道路，并为商业服务、制造业、物流、医疗辅助及未来家庭服务奠定了全新的软硬件平台标准。MATRIX-3的三大能力内核1、仿生设计与感知新生：赋予机器“肌肤”与“触觉”为了让机器人与人类和环境进行安全、细腻的互动，MATRIX-3引入了革命性的人类仿生工程学设计。具体体现在以下两点：3D立体织物仿生肤质机身覆盖首创的三维编织柔性织物，它不仅提供柔软、亲和的触感，更内嵌分布式传感网络。这层“肌肤”能缓冲意外接触，并感知接触位置与力度，极大提升了人机共处的安全性。多模态感知融合指尖集成了高灵敏度触觉传感器阵列，可感知0.1N的压力变化。结合升级的视觉系统，基于大规模预训练空间感知基础模型，提升机器人对空间可操作性Affordance的理解和利用，MATRIX-3形成了“眼看”与“手触”互补的视触觉感知系统，使其能像人类一样，通过触摸判断物体的材质、形状及抓握状态，实现对易碎品、柔性物体的精细化操作。2、灵巧操控与拟人步态：重新定义运动与操作极限MATRIX-3的运动性能实现了质的飞跃，核心在于其仿生关节与灵巧末端。灵犀之手（高自由度灵巧手）搭载全新设计的27维自由度灵巧手，其关节构造与运动范围高度拟人。结合键绳驱动技术，在保证力量和速度的同时，实现了极致的轻量化与精准控制，可完成诸如使用工具、操作精密仪器、折叠物品等复杂任务。自然步态与超能关节基于大规模人类运动捕捉和视频数据开发的通用运动控制模型，让MATRIX-3的行走、转身、上下坡姿态如人类般流畅自然。其动力核心是一体化直线关节，该关节集高功率密度、低噪音与高可靠性于一身，提供了稳定、高效且敏捷的全身体运动基础。3、认知内核与零样本泛化：“预先编程”到“认知推理”MATRIX-3搭载了矩阵超智自主研发的全新神经网络架构。零样本泛化能力该系统的核心突破在于强大的零样本任务泛化能力。意思是，无需针对每一个特定任务进行海量数据训练，MATRIX-3便能通过基础物理规律理解和简单的指示，并能在全新的环境下快速学习新技能操作新的物体，更大拓展了其应用边界与部署速度。通用智能操作模型在数据规模和数据质量驱动下，灵巧操作得以真正实现。机器人能够自主规划抓取策略、避障路径，并实时调整力度与姿态，完成一系列需要手眼协调与即时判断的复合任务。从能力展示到应用检验MATRIX-3是矩阵超智人形机器人走向成熟应用的关键里程碑。它融合了仿生设计、极致灵巧的物理执行以及具有泛化能力的人工智能，构建了一个真正为理解并作用于物理世界而生的智能体。“MATRIX-3的产品哲学，是让机器智能以最自然、最安全的方式融入人类的物理空间。”对此，矩阵超智首席执行官张海星表示：我们从不是要复制人类，而是创造一种能够延伸人类能力、承担重复性劳动的新物种。今天，我们向这个未来迈出了坚实的一步。MATRIX-3针对特定行业合作伙伴的早期体验计划现已开放，并预计于2026年启动首批试点部署。版权所有，未经授权不得以任何形式转载及使用，违者必究。人形机器人具身智能特斯拉矩阵超智思邈一口气集齐老黄苏妈英特尔，还得是AI，还得是联想2026-01-098块钱跑通一次强化学习全流程，潞晨云重塑微调赛道：1名算法工程师=1支Infra团队2026-01-07有300亿美元也未必“再造GPT-4”？NUS尤洋最新长文：拆穿AI增长瓶颈的真相2025-12-31AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品2025-12-29扫码分享至朋友圈相关阅读特斯拉第一季度净亏7亿美元，营收环比下滑37%，将开卖保险产品这份答卷并不优秀安妮2019-04-25特斯拉马斯克马斯克痛失世界首富，4千亿薪酬方案被驳回，或迁移特斯拉注册地“永远不要在特拉华州注册你的公司”梦晨2024-01-31特斯拉马斯克马斯克不再是世界首富随着特斯拉股价波动，马斯克世界首富之位岌岌可危昭慧2022-12-08伯纳德·阿诺特特斯拉马斯克马斯克最新内部信：交车必须试驾FSDFSD免费试用一个月一凡2024-03-27特斯拉车圈最新认知马斯克高瓴、蓝驰领投灵初智能，致力于打造业界领先通用灵巧操作智能体灵初智能将从2B服务业切入西风2024-11-13具身智能强化学习马斯克承认FSD还搞不定中国公交车道，入华窘境核心还是技术马斯克下最后通牒：6月Robotaxi就上路杰西卡2025-02-05特斯拉穿透财报招股书车圈最新认知马斯克热门文章字节Seed：大概念模型来了，推理的何必是下一个token2026-01-05B站开启AI创作大赛，首次开放《三体》改编权，奖金总计超300万2026-01-05让欧美老外彻底“真香”，这家中国割草机器人品牌正在定义一个行业新标准2026-01-07给AI打个分，结果搞出17亿估值独角兽？？？2026-01-07董事长稚晖君发布上纬新材首款机器人！能塞书包还能骑机器狗2026-01-05",
      "article_url": "https://www.qbitai.com/2026/01/368903.html",
      "author": "思邈",
      "publish_time": 1767974400,
      "publish_date": "2026-01-10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"人形机器人具身智能特斯拉矩阵超智\", \"特斯拉马斯克\", \"特斯拉马斯克\", \"伯纳德·阿诺特特斯拉马斯克\", \"特斯拉车圈最新认知马斯克\", \"具身智能强化学习\", \"特斯拉穿透财报招股书车圈最新认知马斯克\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768087062,
      "last_modify_ts": 1768173465
    },
    {
      "id": 54,
      "article_id": "368834",
      "title": "智能体卷王诞生！干活自动配结项报告，1.5张截图就把事说清了",
      "description": "智能体卷王诞生！干活自动配结项报告，1.5张截图就把事说清了西风2026-01-1014:39:44来源：量子位让智能体自己成为“质检员”Youtu-Agent团队 投稿量子位 | 公众号 QbitAI在学校里做实验的时候，老师如何确定我们做了实验并且达到了预期效果呢？——最常见的做法是让学生写一份实验报告交上来。现在，AI智能体拿到一个任务以后如何检验执行的效果有没有达到预期呢？我们也可以让AI",
      "content": "智能体卷王诞生！干活自动配结项报告，1.5张截图就把事说清了西风2026-01-1014:39:44来源：量子位让智能体自己成为“质检员”Youtu-Agent团队 投稿量子位 | 公众号 QbitAI在学校里做实验的时候，老师如何确定我们做了实验并且达到了预期效果呢？——最常见的做法是让学生写一份实验报告交上来。现在，AI智能体拿到一个任务以后如何检验执行的效果有没有达到预期呢？我们也可以让AI在执行任务的同时主动提交一份证据链报告，边做边收集任务完成的证据，自我检查是否符合预期，不符合就继续做。在LLM/VLM驱动的智能体（Agent）的强化学习（RL）研究中，一直面临一个巨大的挑战：你交给智能体一个任务，它干完了，但你不知道完成度如何。为了确认它是否真的准确完成了任务，我们不得不建立庞大的“监督系统”来复核它的每一步操作。这种“被动验证”往往需要：手工设计的复杂校验机制（比如：完全匹配的输出内容）；强大的轨迹级验证方法（比如：LLM/VLM-as-a-Judge众投决策）。这两种常见的先完成任务（task completion）再校验轨迹（outcome verification）的机制有以下缺点：效率较低，人工设计的准则依赖预先编写好的评估脚本，难以简单泛化到新的任务（比如新的APP）；轨迹带噪且上下文冗长，将整条轨迹送给LLM/VLM来评判很容易被无关的环境信息干扰，降低评分的可靠性；依赖持续可观测环境的反馈信息，部分操作往往因为环境变化（如页面刷新、操作过期）而导致验证失败。针对以上问题，我们提出了一种简单的RL训练方法，让智能体自己成为“质检员”，在尽可能减少校验器（Verifier）审核压力的同时，让智能体学会主动分解子目标并且留痕存证。什么是SmartSnap？SmartSnap的核心思想是将GUI智能体从“被动的执行者”转变为“主动的自证者”。简单来说，智能体在完成任务的同时，还会主动收集、筛选并提交一份“证据快照集”。这份证据就像是任务的“结项报告”，让验证者只需看一眼快照，就能确认任务是否成功。三大核心突破：从“执行”到“自证”1. 角色升级：双重使命的“自证代理”传统的智能体只负责“做（Execute）”，而SmartSnap提出了“自证智能体”（Self-Verifying Agent），赋予了它“自我验证（Verify）”的第二使命。它在操作过程中会像人类一样思考：“为了证明我已经改好了设置，我需要把对开关状态截图并作为证据提交。”2. “3C原则”：高效率的证据美学为了避免给验证者造成信息过载，SmartSnap提出了证据策展的3C原则：完整性（Completeness）证据必须足以证明任务已闭环。简洁性（Conciseness）不要冗长的视频，只要最关键的几张“定格”瞬间。创造性（Creativity）为了拿到证据，智能体甚至会主动执行“额外操作”。例如，订完票后主动跳回订单页截图。3. 强化学习驱动：GRPO+内在奖励反馈我们利用GRPO算法对智能体进行了训练。通过精心设计的奖励机制（Intrinsic Reward Shaping），引导智能体在保证任务成功率的同时，不断提升证据的质量，尽可能减少奖励黑客行为（reward hacking）。战绩显赫：小模型也不错SmartSnap的表现令人惊艳，它在AndroidLab等复杂的任务上提升显著：性能飞跃在不同规模的模型上，均实现了显著的性能提升（最高提升达26.08%）。以小博大经过SmartSnap训练的中等参数模型（如Qwen3-32B），在自证能力的加持下，其表现甚至持平DeepSeek-V3/Qwen3-235B等开源大模型。通过感性分析，我们还观察到以下特点：举证效率平均每个任务只需提交1.5张快照证据，极大地降低了后端的验证成本。高效交互智能体在训练过程中由于拟合少量的训练集而变得游刃有余，交互轮数不断减少。知识欠缺在部分APP上，我们观察到智能体存在反复、没有显著增益的表现，其领域知识的欠缺导致无法收敛到有效的解决方案（比如地图APP的各项复杂路径规划任务）。这表明模型需要依赖更多知识注入来指导探索。为什么这简化了智能体RL训练的准备工作？在手机端、OS端这类环境的操作中，由于其时效性特点，传统的外部验证器很难精准捕捉瞬时的成功信号。SmartSnap就像是给智能体配上了一台取证相机。它不再需要事先对环境所有状态有一个预期的变化感知来撰写校验脚本，或者让裁判员模型盯着全程轨迹来仔细推敲，而是让智能体自己边做边收集必要的证据。这允许我们基于合成的任务轻松拓展其训练场景，并针对有限的证据链来判断成功与否，让RL训练更加便捷。面向未来SmartSnap的出现，标志着GUI智能体正从“蛮力执行”走向“认知协同”。这种主动寻找证据的能力，不仅提升了AI的可靠性，更为未来大规模、低成本的AI部署铺平了道路。未来的AI，不仅要“能干”，更要“可信”。论文标题：SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents论文地址：https://arxiv.org/abs/2512.22322代码地址：https://github.com/TencentYoutuResearch/SmartSnap版权所有，未经授权不得以任何形式转载及使用，违者必究。智能体西风开源“裸考”真实世界，国产具身智能基座模型拿下全球第二！2026-01-08DeepSeek V4爆料：春节档GPT/Claude编程危2026-01-10傅利叶首秀CES 2026，全面展示“有温度”的人机交互2026-01-08黄仁勋CES回应全场！内存卡GPU脖子，游戏玩家可能只能用旧显卡了2026-01-08扫码分享至朋友圈相关阅读下手帮你干活直接交付结果，纳米AI超级搜索智能体发布可打破信息围墙跨平台，调用小红书/淘宝/高德地图量子位2025-06-12360智能体纳米AI特斯联首款通用智能体发布，实现对物理世界的高维感知“超级人工智能即服务”（IaaS，Intelligence as a Service）白交2024-11-20智能体特斯联Manus跑路了吗？爆火125天后，他从国内裁员撤了衡宇2025-07-10AI AgentManus创业公司智能体一句话生成AI Agent，零成本体验，容智最新智能体来了容智信息正式发布Agent-100智能体平台和Hyper Agent智能体开发平台量子位2025-05-16智能体清华商汤最新AI，征服了《我的世界》任务覆盖率达100%！西风2023-05-30AI我的世界智能体OpenAI 发布了一个程序化生成环境，可以评价智能体泛化技能学习十三2019-12-04OpenAI智能体深度强化学习热门文章字节Seed：大概念模型来了，推理的何必是下一个token2026-01-05B站开启AI创作大赛，首次开放《三体》改编权，奖金总计超300万2026-01-05让欧美老外彻底“真香”，这家中国割草机器人品牌正在定义一个行业新标准2026-01-07给AI打个分，结果搞出17亿估值独角兽？？？2026-01-07董事长稚晖君发布上纬新材首款机器人！能塞书包还能骑机器狗2026-01-05",
      "article_url": "https://www.qbitai.com/2026/01/368834.html",
      "author": "西风",
      "publish_time": 1767974400,
      "publish_date": "2026-01-10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"智能体\", \"360智能体纳米AI\", \"智能体特斯联\", \"AI AgentManus创业公司智能体\", \"智能体\", \"AI我的世界智能体\", \"OpenAI智能体深度强化学习\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://arxiv.org/abs/2512.22322\", \"url\": \"https://arxiv.org/abs/2512.22322\", \"type\": \"paper\"}, {\"title\": \"https://github.com/TencentYoutuResearch/SmartSnap\", \"url\": \"https://github.com/TencentYoutuResearch/SmartSnap\", \"type\": \"code\"}]",
      "add_ts": 1768087064,
      "last_modify_ts": 1768173466
    },
    {
      "id": 57,
      "article_id": "368820",
      "title": "DeepSeek V4爆料：春节档GPT/Claude编程危",
      "description": "DeepSeek V4爆料：春节档GPT/Claude编程危西风2026-01-1009:27:28来源：量子位DeepSeek-V3.2在大模型竞技场进行人类偏好评估，或许……春节临近，今年DeepSeek又要给世界一点震撼了。外媒The Information消息称，两位直接了解该计划的知情人士向其透露，2月中旬春节前后DeepSeek将发布V4，时间可能会调整。DeepSeek-V4主打编码",
      "content": "DeepSeek V4爆料：春节档GPT/Claude编程危西风2026-01-1009:27:28来源：量子位DeepSeek-V3.2在大模型竞技场进行人类偏好评估，或许……春节临近，今年DeepSeek又要给世界一点震撼了。外媒The Information消息称，两位直接了解该计划的知情人士向其透露，2月中旬春节前后DeepSeek将发布V4，时间可能会调整。DeepSeek-V4主打编码能力，内部初步测试结果显示，已超越Anthropic的Claude、OpenAI的GPT系列等现有其它模型。两位知情人士还补充道，V4的核心突破还体现在两个方面：在超长代码提示词的处理与解析上实现了关键突破。在整个训练流程的全阶段，其数据模式理解能力均未出现性能衰减，且较前代模型有显著提升。PS：AI模型的训练过程，要求模型反复从海量数据集中学习。但在实际操作中，随着训练轮次的不断增加，模型对数据模式的捕捉能力往往会出现衰减。对于拥有大量AI芯片储备的开发者而言，解决这一问题的常规手段，是通过增加训练轮次来弥补性能损耗。用户在实际使用中很可能会发现，V4生成的答案逻辑更清晰、结构更规整。这表明，模型具备更强的深度推理能力，在处理复杂任务时的可靠性也将大幅提升。值得一提的是，有网友注意到DeepSeek-V3.2论文中有提到他们用大模型竞技场平台（ChatbotArena）进行人类偏好评估。所以，我们或许可以更早地在大模型竞技场上测试到该模型。参考链接：https://www.theinformation.com/articles/deepseek-release-next-flagship-ai-model-strong-coding-ability?rc=jn0pp4版权所有，未经授权不得以任何形式转载及使用，违者必究。Deepseek西风开源“裸考”真实世界，国产具身智能基座模型拿下全球第二！2026-01-08智能体卷王诞生！干活自动配结项报告，1.5张截图就把事说清了2026-01-10傅利叶首秀CES 2026，全面展示“有温度”的人机交互2026-01-08黄仁勋CES回应全场！内存卡GPU脖子，游戏玩家可能只能用旧显卡了2026-01-08扫码分享至朋友圈相关阅读DeepSeek-R1秘籍轻松迁移，只需原始数据0.3% | 邱锡鹏团队联合出品已在开源模型llama 2上验证一水2025-02-24Deepseek马蜂窝AI智能体成首个接入DeepSeek的旅游行业应用首阶段将优先应用于已上线发布的“AI游贵州”、“AI游黔西南”、“AI游西江” 省市景区三级AI应用生态明敏2025-02-12DeepseekDeepSeek-V3.2系列开源，性能直接对标Gemini-3.0-Pro开源模型又靠DS上大分衡宇2025-12-01Deepseek国产模型开源稀疏注意力机制14.9万元，满血流畅运行DeepSeek一体机抱回家！清华90后初创出品接近22 tokens/s十三2025-04-29Deepseek大模型一体机清华大学行云集成电路不用跟着挤DeepSeek官方了！这个神器让你零门槛拥有私人助手免费使用，无额度限制白交2025-02-11Deepseek支付宝智能体实测DeepSeek V3.1，不止拓展上下文长度击败Claude成非推理模型SOTA，但价格便宜68倍不圆2025-08-20DeepseekDeepSeek V3实测开源热门文章字节Seed：大概念模型来了，推理的何必是下一个token2026-01-05B站开启AI创作大赛，首次开放《三体》改编权，奖金总计超300万2026-01-05让欧美老外彻底“真香”，这家中国割草机器人品牌正在定义一个行业新标准2026-01-07给AI打个分，结果搞出17亿估值独角兽？？？2026-01-07董事长稚晖君发布上纬新材首款机器人！能塞书包还能骑机器狗2026-01-05",
      "article_url": "https://www.qbitai.com/2026/01/368820.html",
      "author": "西风",
      "publish_time": 1767974400,
      "publish_date": "2026-01-10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"Deepseek\", \"Deepseek\", \"Deepseek\", \"Deepseek国产模型开源稀疏注意力机制\", \"Deepseek大模型一体机清华大学行云集成电路\", \"Deepseek支付宝智能体\", \"DeepseekDeepSeek V3实测开源\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://www.theinformation.com/articles/deepseek-release-next-flagship-ai-model-strong-coding-ability?rc=jn0pp4\", \"url\": \"https://www.theinformation.com/articles/deepseek-release-next-flagship-ai-model-strong-coding-ability?rc=jn0pp4\", \"type\": \"external\"}]",
      "add_ts": 1768087067,
      "last_modify_ts": 1768173470
    },
    {
      "id": 59,
      "article_id": "369107",
      "title": "具身开源模型新王！千寻Spirit v1.5模型登顶 RoboChallenge，终结 Pi0.5领跑时代",
      "description": "具身开源模型新王！千寻Spirit v1.5模型登顶 RoboChallenge，终结 Pi0.5领跑时代henry2026-01-1216:06:15来源：量子位首个在RoboChallenge上成功率超过50%的具身智能模型henry 发自 凹非寺量子位 | 公众号 QbitAI事情开始变得有趣起来了。刚刚，来自千寻智能的具身智能基础模型Spirit v1.5，在RoboChallenge真机",
      "content": "具身开源模型新王！千寻Spirit v1.5模型登顶 RoboChallenge，终结 Pi0.5领跑时代henry2026-01-1216:06:15来源：量子位首个在RoboChallenge上成功率超过50%的具身智能模型henry 发自 凹非寺量子位 | 公众号 QbitAI事情开始变得有趣起来了。刚刚，来自千寻智能的具身智能基础模型Spirit v1.5，在RoboChallenge真机评测榜上，以总分66.09，成功率50.33%的成绩，超越美国明星公司Physical Intelligence的Pi0.5（π0.5），登顶榜首。基于多样化的预训练数据采集范式，Spirit v1.5在插花、把水果放进篮子、挂牙刷杯等多项任务中，拿下第一，刷新榜单纪录。经此一役，Spirit v1.5不仅是RoboChallenge自去年10月上线以来，首个击败baseline模型Pi0.5的国产具身模型，同时也是首个在RoboChallenge上成功率超过50%的具身智能模型。在此之前，RoboChallenge榜单上，模型间的竞争已逐渐进入白热化阶段，Pi系列基线模型不断被逼近。而现在，Spirit v1.5直接越过Pi0.5，拿下榜首。这种密集、连续的刷榜节奏，多少有点让人想起当年AlexNet、VGG、GoogLeNet、ResNet刷新ImageNet的那段时间——基准在被不断打破，模型天花板被一再抬高。也正如当年CV的开源景象，Spirit v1.5同步开源了基模权重、推理代码以及使用样例，方便后续的研究者复现和进一步探索。而正是在这被誉为具身智能「ImageNet」的RoboChallenge上，开源模型正以可验证、可复现的方式，持续推动具身能力向前发展。开源具身模型能力，全球领先截至2026年1月12日，Spirit v1.5在RoboChallenge上取得了当前最优的性能，超越了Pi0.5等之前的全球领先开源模型。在RoboChallenge的Table30任务中，Spirit v1.5表现堪称 “碾压级”，不仅在下列多项任务中夺得第一：插花（arrange flowers）水果入篮（arrange fruits in basket）挂牙刷杯（hang toothbrush cup）薯条倒碗（pour fries into plate）开瓶器入抽屉（put opener in drawer）笔入笔盒（put pen into pencilcase）寻找绿盒（search green boxes）浇花（water potted plant）……还在贴胶带（stick tape to box）、清扫垃圾（sweep the rubbish）、开关灯（turn on light switch）等任务上实现绝对领先。其中 “寻找绿盒” 任务堪称高光时刻——Spirit v1.5直接将成功率拉至90%。演示画面中，它能快速从一堆彩色方块中锁定绿色目标，稳稳放入指定篮子，整个过程干脆利落，没有丝毫拖泥带水。在水果入篮任务中，Spirit v1.5更是以80%的成功率，领先Pi0.5整整一倍。在演示中，Spirit v1.5能够轻松地拿起香蕉，放进篮子（下图经5倍加速）。而在插花任务中，虽然两款模型成功率均 50%，但实际执行中，Spirit v1.5的稳定性碾压Pi0.5，没有出现极端的失败案例。在演示中，Spirit v1.5基本上可以稳稳地将鲜花放入花瓶。而Pi0.5有时则会出现突然卡死的情况，从而导致任务中断。在最考验技术功底的贴胶带任务中，即便Spirit v1.5 20%的成功率不算特别突出，但对比Pi0.5仅10%的表现，仍实现了翻倍领先。贴胶带属于典型的闭环触觉接触任务（机器人手指 / 夹爪间隙极小），对机械臂协同与触觉感知要求极高，机器人经常会出现空抓的现象。在演示中，Spirit v1.5凭借双机械臂精准配合，能流畅完成撕胶、贴盒全流程。而相比之下，Pi0.5虽然能很快的定位到胶带的位置，但却难以感知到是否撕到胶带，频频出现了空贴的现象。透过上述任务我们不难看出，Spirit v1.5在复杂长指令任务中的稳定发挥，意味着其已经进化为一个具备出色逻辑推理与空间感知能力的“具身大脑”。而这份实力的认证，正来自具身智能领域的标杆级 “试炼场”——RoboChallenge。RoboChallenge由Dexmal原力灵机联合Hugging Face发起，是首个在真实物理环境中，由真实机器人执行操作的大规模、多任务基准测试。它的Table30任务集，通过30个高频桌面及周边日常场景，从VLA难点、机器人形态、任务流程与物体属性等维度考察模型真实世界通用操作能力。考试机型覆盖ARX5、UR5e、ALOHA、Franka、UR5等；测试任务涵盖抓取、放置、堆叠、打开、按压、分类等复杂动作。除上述任务设置外，RoboChallenge它的核心创新，在于Remote Robot Paradigm（远程机器人范式）：参赛者在本地运行模型，只需通过HTTP接口向机器人发送控制指令，机器人被视作一个可远程调用的“外设”。这一设计显著降低了参赛门槛，同时避免了复杂环境配置带来的不确定性，使不同团队的算法能够在同一套真实硬件条件下接受统一评测。所有参赛者均可通过官方页面查看比赛实况，全程保障赛事的公平与透明。不过，由于推理发生在用户侧，模型的具体实现仍主要依赖参赛者自律与社区共识——例如是否始终保持与所声明方案的一致性，是否在多任务通用型模型（multi-task generalist model）的设定下，避免针对单一任务的特殊化调优。（注：RoboChallenge区分任务特定与通用型两种训练协议：前者针对单一任务单独训练，后者用少量混合数据训练一个多任务统一模型。榜单中带有/multi 后缀的模型，如Pi0.5/multi，遵循的正是这一更具挑战性的通用型设定。）也正是在这一背景下，Spirit v1.5此次选择同步开源，其意义不仅在于成绩本身，也契合了RoboChallenge鼓励通过可复现、可验证的方式，共同推动具身智能基准向前发展的初衷。那么，Spirit v1.5具体是怎么做到的呢？数据多样性成制胜法宝Spirit v1.5的核心创新，主要体现在预训练阶段的数据策略上。它将具身模型的预训练数据，从高度精选、强控制的「干净数据」，转向多样化、开放式、弱控制的数据采集范式。这里所说的「干净数据」，通常指动作模式相对单一、物体摆放位置与视角高度固定的精选数据集。例如Open X-Embodiment、Agibot和RoboCOIN等具身模型训练的主流数据集。△Open X-Embodiment这类数据的优势在于：数采成本低、学习难度可控；但代价同样明显——动作模式的多样性被显著压缩，模型对真实世界不确定性的适应能力因此受限。针对这一问题，Spirit v1.5采取了相反的策略。在数据采集阶段，它鼓励数采员只围绕任务目标行动，而不强制遵循固定的动作流程。例如，在为假人头部化妆时，采集员并不会严格复现某一套标准操作，而是以更接近真实人类行为的方式自由完成任务。这样做的结果是采集来的数据不再是单任务、单目标的单成功轨迹。而是在自然执行过程中，连续覆盖了抓取、插入、整理、双臂协作、异常处理等大量原子技能，并以真实世界的时序关系串联在一起。这种开放式采集显著扩大了动作分布，使模型在预训练阶段“见过更多可能性”，从而具备更强的迁移与泛化能力。在工程层面，这一策略同样带来了可观收益：人均有效采集时长提升约200%，对算法专家深度介入的需求降低约60%。而在实验验证中，这种以多样性为核心的数据策略，同样得到了印证。一方面，在RoboChallenge Table30的真机评测中，Spirit v1.5已经在整体能力层面证明了该范式是成立的（相关结果已在前文展开）。另一方面，在消融实验中，研究团队在预训练数据规模完全一致的前提下，对比了两种策略：基于脚本化任务演示的预训练；基于多样化、开放式采集的预训练。结果显示，多样化预训练的模型在新任务上的微调效率显著更高：在达到相同性能时，所需迭代次数减少约40%。进一步扩大多样化数据规模后，模型的验证误差仍在持续下降，并未出现明显的早期饱和现象。这些发现表明，对具身模型而言，任务多样性比单一任务的演示数量更为关键。模型真正学到的，并非某个任务的最优动作序列，而是一套可迁移的通用策略，使其能够用更少的步骤适应新任务。由此，使用高多样性、弱控制的数据进行预训练不仅可行，而且显著优于文献中常见的利用“干净”数据的做法。也正因为并非针对单一任务优化，Spirit v1.5更适合作为一个通用具身智能的基础模型被复用。对学界而言，它提供了一条不同于Pi系列且更优的开源技术路径。对产业团队而言，这种以真实世界多样性为起点的预训练方式，显著降低了新场景的迁移与适配成本。随着模型权重与代码同步开源，Spirit v1.5在RoboChallenge上的成绩不再只是一次展示，而成为一个可验证、可复现、可继续推进的起点。Spirit v1.5背后的团队：千寻智能在做什么最后，再把视角拉回到Spirit v1.5背后的团队——千寻智能（Spirit AI）。成立于2024年1月的千寻智能，是一支非常“年轻”的队伍，却已经成长为国内少数具备AI+机器人全栈、生产力级技术能力的具身智能公司。简单概括，千寻的路线非常明确——通用人形机器人+具身大模型（VLA）一体推进，因此常被外界称为“中国版 Figure”。创始人兼CEO韩峰涛：机器人行业连续创业者，曾任珞石机器人联合创始人兼CTO，在机器人行业拥有十余年经验，主导交付过超2万台工业机器人。联合创始人兼首席科学家高阳：清华交叉信息研究院助理教授，“伯克利归国四子之一”，师从具身智能权威学者Pieter Abbeel，其提出的ViLa算法被Figure采用。在融资方面，2025年千寻智能狂揽超15亿元融资，6月PreA+轮由京东领投6亿元，浙江省科创母基金、华泰紫金等新势力跟投，顺为资本、华控基金等老股东更是继续跟投。在商业落地方面，其通用人形机器人 “小墨”（Moz1）已于2025年底在宁德时代电池产线规模化落地，精细作业成功率突破99%，用工业级场景完成了一次硬核验证。而在技术路径上，从Spirit v1攻克柔性物体长程操作，到开源「边想边做」的OneTwoVLA，再到如今基于多样化真实数据采集的Spirit v1.5——千寻始终在做一件事：把具身智能从“实验效果”，推进到“可复现、可量产、可落地”的工程体系中。而这次Spirit v1.5在RoboChallenge上的登顶，并不仅仅意味着一次榜单上的领先。它更像是千寻具身智能模型快速迭代周期中，一次在同一公开基准下完成的、具有标志意义的性能对标：在真实机器人、真实任务、统一评测条件下，对现有的技术路线进行了一次阶段性验证。从结果来看，Spirit v1.5在泛化性、稳定性与鲁棒性等系统层面的能力，已经出现了整体跃迁，而不仅是单点任务的“刷分”。更重要的是，这一成绩并未停留在展示层面。Spirit v1.5同步开源模型权重、推理代码和使用样例，使得这一结果可以被复现、被检验、也可以被后续研究继续推进。正如当年ImageNet之于计算机视觉，只有在一个可复现、公正、开放的基准之上，模型能力的进步才具备真正的参考价值。而模型的开源也进一步方便后续研究者的快速迭代优化与创新探索。在被不少研究者视作具身智能「ImageNet」的RoboChallenge上，这次登顶既是一次能力确认，也是一种明确表态——千寻选择将技术进展放入开源体系之中，与社区一起，把具身智能的天花板持续往前推。正如千寻首席科学家高阳针对Spirit v1.5在开源模型赛道斩获全球第一时说所的：它不仅是一次技术上的突破，也意味着我们在追寻智能的道路上，再次站到了当下人类智能所能企及的高度之一。更重要的是，这个模型是开源的。我们选择把它交到更多人手中，让大家一起使用、一起验证、一起推进这条路。智能不应该被少数人垄断，而应该被共同建设。开源地址：Code: https://github.com/Spirit-AI-Team/spirit-v1.5Model: https://huggingface.co/Spirit-AI-robotics/Spirit-v1.5Blog：https://www.spirit-ai.com/en/blog/spirit-v1-5版权所有，未经授权不得以任何形式转载及使用，违者必究。千寻智能henry具身智能开年最大融资，字节红杉领投10亿2026-01-12Hinton的亿万富豪博士生2026-01-10吴恩达：图灵测试不够用了，我会设计一个AGI专用版2026-01-10起猛了，追觅的扫地机、割草机、洗护机器人在CES成精了！2026-01-09扫码分享至朋友圈热门文章离开马斯克后，他把人形机器人做成了这样2026-01-10让欧美老外彻底“真香”，这家中国割草机器人品牌正在定义一个行业新标准2026-01-07给AI打个分，结果搞出17亿估值独角兽？？？2026-01-07NVIDIA 发布全新物理 AI 模型，全球合作伙伴展示新一代机器人2026-01-07刚刚，智谱港交所敲钟！市值528亿港元2026-01-08",
      "article_url": "https://www.qbitai.com/2026/01/369107.html",
      "author": "henry",
      "publish_time": 1768147200,
      "publish_date": "2026-01-12",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"千寻智能\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://github.com/Spirit-AI-Team/spirit-v1.5\", \"url\": \"https://github.com/Spirit-AI-Team/spirit-v1.5\", \"type\": \"code\"}, {\"title\": \"https://huggingface.co/Spirit-AI-robotics/Spirit-v1.5\", \"url\": \"https://huggingface.co/Spirit-AI-robotics/Spirit-v1.5\", \"type\": \"code\"}, {\"title\": \"https://www.spirit-ai.com/en/blog/spirit-v1-5\", \"url\": \"https://www.spirit-ai.com/en/blog/spirit-v1-5\", \"type\": \"external\"}]",
      "add_ts": 1768259736,
      "last_modify_ts": 1768346313
    },
    {
      "id": 62,
      "article_id": "369244",
      "title": "美团龙猫LongCat技术升级！新注意力机制解码速度快10倍，还能处理1M超长文本",
      "description": "美团龙猫LongCat技术升级！新注意力机制解码速度快10倍，还能处理1M超长文本闻乐2026-01-1312:30:50来源：量子位不用从头训，中期就能全转稀闻乐 发自 凹非寺量子位 | 公众号 QbitAI256K文本预加载提速超50%，还解锁了1M上下文窗口。美团龙猫LongCat系列新年出招，发布全新稀疏注意力机制LoZA（LongCat ZigZag Attention）。新技术集中火力",
      "content": "美团龙猫LongCat技术升级！新注意力机制解码速度快10倍，还能处理1M超长文本闻乐2026-01-1312:30:50来源：量子位不用从头训，中期就能全转稀闻乐 发自 凹非寺量子位 | 公众号 QbitAI256K文本预加载提速超50%，还解锁了1M上下文窗口。美团龙猫LongCat系列新年出招，发布全新稀疏注意力机制LoZA（LongCat ZigZag Attention）。新技术集中火力，重点解决长文本任务的理解、算力难题。相比于LongCat系列之前的全注意力MLA机制，LoZA只改了一半的核心模块。但模型长文本能力从256K扩展到1M，解码速度还快了不少。甚至比同类型的Qwen-3模型表现还要好。接下来看具体方案。如何做到 “只算关键部分” ？全注意力机制的算力瓶颈在于平方级的计算复杂度O (L²)，这导致模型在处理长文本任务时对显卡要求高，还会出现推理延迟问题。LoZA的核心思路是专注于处理重要的内容，不重要的部分少花力气。作为LongCat系列的核心技术升级，LoZA主要是在原来的MLA机制上做改造。具体分两步。首先，给模型里的多头潜在注意力模块MLA做一个全局“筛查”，找出哪些模块可以被改造。在原来的MLA架构中，每个MLA模块都是处理注意力的核心单元，现在的新方案是给每个模块配一个可学习权重α。α值越高，说明该模块额全注意力计算越关键，一旦简化就容易丢性能；α值越低就意味着模块的可替代性强，即便换成更轻量的计算方式，对整体的理解能力影响也不大。在训练过程中，团队冻结模型其他参数，只更新α的梯度，通过这种专门的校准训练让模型自主学习α值，然后按α值从小到大排序，找出那些稀疏化后不影响性能的MLA模块，也就是后续的优化目标。随后，将找出的50%低性能模块换成更轻巧的流式稀疏注意力SSA。这样就形成了一种交错结构，团队将这种结构称为ZigZag。SSA的计算复杂度是线性的O (L·S)（S为稀疏窗口大小，固定为1024Token），远低于全注意力的O (L²)。所以这种交错结构让模型既不会因为过度简化而变笨，又能把计算复杂度降到线性级别，省不少算力。为了让模型在关注局部细节的基础上不忽略整体逻辑，LoZA还设计了一个1024Token稀疏窗口。每个窗口里有1个负责抓整体关联的“全局块”和7个负责盯附近内容的“局部块”，单块大小为128Token。这样的改造也不需要从头训练，在中期训练阶段就能完成，成本也比较低。从测试数据来看，LoZA的表现也不错，主要是“更快”的同时“没变笨”。速度上，要是处理128K上下文，解码速度直接比原来快10倍；256K上下文，模型预加载（读文本过程）速度快了50%，后续解码阶段生成内容时还能省30%的算力，相当于同样的硬件，现在能同时处理两倍多的长文本任务。这也让LongCat-Flash-Exp解锁了1M上下文窗口。性能上，LoZA也没因为简化而缩水。处理回答问题、写代码这类日常任务时，和原版LongCat-Flash持平；处理长文本任务时，表现反而更好。比如在MRCR测试里，反超了同样能处理1M长文本的Qwen-3模型，还更稳定。接下来，团队还计划让LoZA支持动态稀疏比例。短文本场景自动多用全注意力保证精度，长文本场景自动增加稀疏模块提升效率，甚至适配多模态模型处理长视频、长图文内容。好一个新年新气象！论文地址：https://www.alphaxiv.org/abs/2512.23966— 完 —版权所有，未经授权不得以任何形式转载及使用，违者必究。注意力机制美团美团AI闻乐AI太记仇！做完心理治疗后仍记得「被工程师虐待」2026-01-13刚刚，智谱港交所敲钟！市值528亿港元2026-01-08给AI打个分，结果搞出17亿估值独角兽？？？2026-01-07老黄All in物理AI！最新GPU性能5倍提升，还砸掉了智驾门槛2026-01-06扫码分享至朋友圈相关阅读Mamba核心作者新作:取代DeepSeek在用的注意力机制，专为推理打造解码速度和吞吐量最高提升2倍一水2025-06-01注意力机制光杆司令狂揽2亿美元！大佬一人搞ChatGPT创业，两天已现独角兽模样VC和人才都坐不住了萧箫2023-02-13ChatGPT人工智能美团换掉Transformer，7B开源模型立刻登顶！任意长序列都能处理完全没用注意力机制明敏2024-08-13FalconTransformer架构开源模型注意力机制把大核卷积拆成三步，清华胡事民团队新视觉Backbone刷榜了，集CNN与ViT优点于一身超越SwinTransformer与ConvNeXT梦晨2022-02-23CNNViT注意力机制H100利用率飙升至75%！英伟达亲自下场FlashAttention三代升级大模型训练再提速明敏2024-07-12大语言模型注意力机制英伟达训练加速王兴一鸣惊人！美团首个开源大模型追平DeepSeek-V3.1网友：这下好了，Meta连送外卖的都比不过明敏2025-09-01MoE开源模型美团热门文章离开马斯克后，他把人形机器人做成了这样2026-01-10让欧美老外彻底“真香”，这家中国割草机器人品牌正在定义一个行业新标准2026-01-07给AI打个分，结果搞出17亿估值独角兽？？？2026-01-07NVIDIA 发布全新物理 AI 模型，全球合作伙伴展示新一代机器人2026-01-07刚刚，智谱港交所敲钟！市值528亿港元2026-01-08",
      "article_url": "https://www.qbitai.com/2026/01/369244.html",
      "author": "闻乐",
      "publish_time": 1768233600,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"注意力机制美团美团AI\", \"注意力机制\", \"ChatGPT人工智能美团\", \"FalconTransformer架构开源模型注意力机制\", \"CNNViT注意力机制\", \"大语言模型注意力机制英伟达训练加速\", \"MoE开源模型美团\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://www.alphaxiv.org/abs/2512.23966\", \"url\": \"https://www.alphaxiv.org/abs/2512.23966\", \"type\": \"external\"}]",
      "add_ts": 1768346311,
      "last_modify_ts": 1768346311
    }
  ],
  "company_article": [
    {
      "id": 1,
      "article_id": "google_gemini-api-new-file-limits",
      "company": "google",
      "title": "Increased file size limits and expanded inputs support in Gemini API",
      "description": "The Gemini API now supports increased inline file size limit of 100MB and new file inputs from GCS buckets and any HTTP/Signed URL.",
      "content": "Breadcrumb Innovation & AI Technology Developer tools Increased file size limits and expanded inputs support in Gemini API Jan 12, 2026 · Share x.com Facebook LinkedIn Mail Copy link The Gemini API now supports file input from Google Cloud Storage (GCS) buckets and any HTTP/Signed URL. We've also increased the file size limit from 20MB to 100MB. Lucia Loher Product Manager, Gemini API Read AI-generated summary General summary The Gemini API now supports Google Cloud Storage object registration and HTTPS/Signed URLs. You can bring your data directly into Gemini API without re-uploading. Also, the maximum payload size for inline data increased from 20MB to 100MB. Summaries were generated by Google AI. Generative AI is experimental. Bullet points \"Increased file size limits and expanded inputs support in Gemini API\" is all about easier data uploads. You can now use public URLs or signed URLs to bring data directly into the Gemini API. Got data in Google Cloud Storage? Register those files directly; no need to move them. Inline file size limits are way up, from 20MB to 100MB, great for faster prototyping. These updates help you build AI apps faster by removing data upload roadblocks. Summaries were generated by Google AI. Generative AI is experimental. Explore other styles: General summary Bullet points Share x.com Facebook LinkedIn Mail Copy link Your browser does not support the audio element. Listen to article This content is generated by Google AI. Generative AI is experimental [[duration]] minutes Voice Speed Voice Speed 0.75X 1X 1.5X 2X Today, we’re introducing significant updates to how you ingest data into the Gemini API: support for Google Cloud Storage (GCS) object registration, HTTPS/Signed URLs and increased inline file size limits. These changes are designed to help you bring your own data — wherever it lives — directly into Gemini API. There’s no longer a need to re-upload data from existing storage, allowing you to scale your AI applications to production faster.Bring your own data: GCS and external URLsPreviously, using large files (video, long audio, massive documents) required uploading them to the Gemini Files API, where they persisted for only 48 hours. While sufficient for prototyping, this ephemeral storage became a bottleneck for production apps relying on persistent data in cloud storage platforms.We are removing this friction with two new input methods.1. External URLs (public / signed):We now support both files stored in public domains, as well as private storage (via signed URLs)You can pass any publicly accessible URL (like a PDF or image on the web) directly in your generation request.We support pre-signed URLs for accessing data from AWS S3, Azure Blob Storage or other cloud providers.The Gemini API securely fetches the content during processing, eliminating the need to download content to your backend just to forward it to the API.2. Register GCS files: If your data is already in Google Cloud Storage (GCS), you no longer need to move bytes. You can now register your GCS files directly with the Files API.Increased inline limitsFor developers who prefer using inline files for speed and simplicity, we are increasing the maximum payload size for inline data from 20MB to 100MB (base64 encoded, with varying limits based on data types). This is ideal for prototyping, real-time applications, and handling larger images or short audio clips without needing any intermediate storage.With these updates, you now have a robust toolkit for data ingestion tailored to your specific needs: How it worksHere’s how you can start using these new methods with the latest GenAI SDKs.Using External (public or signed) URLsThis method allows you to fetch content directly from your existing storage buckets. Registering Google Cloud Storage (GCS) filesFor data already sitting in your GCS buckets, you can register the URIs once and use them across multiple requests without moving the actual bytes.Note: This requires authenticating with OAuth credentials as an IAM user or service with read access to the storage bucket. See our documentation for the setup guide. Get startedThese new file input methods are available today in the latest versions of our SDKs. We’re excited to see how removing these data barriers helps you build faster and scale your multimodal applications with less overhead.For complete details on authentication, supported file types, and best practices, check out the updated file documentation. To try out the new file URLs, explore the demo applet. POSTED IN: Developer tools Gemini models",
      "article_url": "https://blog.google/innovation-and-ai/technology/developers-tools/gemini-api-new-file-limits/",
      "author": "Jan 12, 2026 · Share x.com Facebook LinkedIn Mail Copy link The Gemini API now supports file input from Google Cloud Storage (GCS) buckets and any HTTP/Signed URL. We've also increased the file size limit from 20MB to 100MB. Lucia Loher Product Manager, G",
      "publish_time": 1768237200,
      "publish_date": "2026-01-13",
      "category": "AI Blog",
      "tags": "[\"POSTED IN:\", \"Developer tools\", \"Gemini models\"]",
      "cover_image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GeminiAPI-File_Input_Expan_16x9_RD3-V01.width-1300.png",
      "article_type": "blog",
      "is_research": 0,
      "is_product": 1,
      "reference_links": "[{\"title\": \"x.com\", \"url\": \"https://twitter.com/intent/tweet?text=Increased%20file%20size%20limits%20and%20expanded%20inputs%20support%20in%20Gemini%20API%20%40google&url=https://blog.google/innovation-and-ai/technology/developers-tools/gemini-api-new-file-limits/\", \"type\": \"blog\"}, {\"title\": \"Facebook\", \"url\": \"https://www.facebook.com/sharer/sharer.php?caption=Increased%20file%20size%20limits%20and%20expanded%20inputs%20support%20in%20Gemini%20API&u=https://blog.google/innovation-and-ai/technology/developers-tools/gemini-api-new-file-limits/\", \"type\": \"blog\"}, {\"title\": \"LinkedIn\", \"url\": \"https://www.linkedin.com/shareArticle?mini=true&url=https://blog.google/innovation-and-ai/technology/developers-tools/gemini-api-new-file-limits/&title=Increased%20file%20size%20limits%20and%20expanded%20inputs%20support%20in%20Gemini%20API\", \"type\": \"blog\"}, {\"title\": \"Mail\", \"url\": \"mailto:?subject=Increased%20file%20size%20limits%20and%20expanded%20inputs%20support%20in%20Gemini%20API&body=Check out this article on the Keyword:%0A%0AIncreased%20file%20size%20limits%20and%20expanded%20inputs%20support%20in%20Gemini%20API%0A%0AThe Gemini API now supports increased inline file size limit of 100MB and new file inputs from GCS buckets and any HTTP/Signed URL.%0A%0Ahttps://blog.google/innovation-and-ai/technology/developers-tools/gemini-api-new-file-limits/\", \"type\": \"blog\"}, {\"title\": \"Google Cloud Storage (GCS) object registration\", \"url\": \"http://ai.google.dev/gemini-api/docs/file-input-methods#registration\", \"type\": \"external\"}, {\"title\": \"HTTPS/Signed URLs\", \"url\": \"http://ai.google.dev/gemini-api/docs/file-input-methods#external-urls\", \"type\": \"external\"}, {\"title\": \"increased inline file size limits\", \"url\": \"https://ai.google.dev/gemini-api/docs/file-input-methods\", \"type\": \"external\"}, {\"title\": \"Files API\", \"url\": \"https://ai.google.dev/gemini-api/docs/files\", \"type\": \"external\"}, {\"title\": \"demo applet\", \"url\": \"https://ai.studio/apps/drive/1RKjnf2SWjGPylmU_uHCCEAvMYqXBrMaF\", \"type\": \"external\"}]",
      "add_ts": 1768259695,
      "last_modify_ts": 1768259695
    },
    {
      "id": 2,
      "article_id": "google_veo-3-1-gemini-api",
      "company": "google",
      "title": "Enhanced Veo 3.1 capabilities are now available in the Gemini API.",
      "description": "",
      "content": "Breadcrumb Innovation & AI Technology Developer tools Today, we are releasing updates to Veo 3.1 in the Gemini API and Google AI Studio, giving developers greater creative control and production-ready quality.Enhanced Ingredients to Video: The updated model intelligently synthesizes your inputs to preserve character identity and background details, ensuring your characters and settings remain consistent across videos.Native Vertical Format Videos for Ingredients to Video (Portrait Mode): Generate social-ready 9:16 videos directly. Designed for mobile-first applications, this mode delivers faster results and optimized composition by generating full-frame vertical video rather than cropping from landscape.New 4K and Improved 1080p definition: Unlock professional fidelity directly within your workflow. Using state-of-the-art enhancement techniques, the model now outputs clearer, crisp 1080p and creates stunning 4K videos suitable for the big screen.These capabilities, along with our SynthID digital watermark, are available today in the Gemini API and Vertex AI for enterprises. See this in action via the Google AI Studio demo app. POSTED IN: Developer tools Related stories",
      "article_url": "https://blog.google/innovation-and-ai/technology/developers-tools/veo-3-1-gemini-api/",
      "author": "Google AI",
      "publish_time": 1768323600,
      "publish_date": "2026-01-14",
      "category": "AI Blog",
      "tags": "[\"POSTED IN:\", \"Developer tools\"]",
      "cover_image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Veo3.2_Metadata_RD1-V01.max-1440x810.png",
      "article_type": "blog",
      "is_research": 0,
      "is_product": 1,
      "reference_links": "[{\"title\": \"Gemini API\", \"url\": \"https://ai.google.dev/gemini-api/docs/video?example=dialogue\", \"type\": \"external\"}, {\"title\": \"Google AI Studio\", \"url\": \"https://aistudio.google.com/prompts/new_video?model=veo-3.1-generate-preview\", \"type\": \"official\"}, {\"title\": \"Vertex AI\", \"url\": \"https://console.cloud.google.com/vertex-ai/studio/media/video\", \"type\": \"official\"}, {\"title\": \"demo app\", \"url\": \"https://ai.studio/apps/bundled/veo_studio?fullscreenApplet=true\", \"type\": \"external\"}]",
      "add_ts": 1768346273,
      "last_modify_ts": 1768346273
    },
    {
      "id": 3,
      "article_id": "deepmind_veo-3-1-ingredients-to-video",
      "company": "deepmind",
      "title": "Veo 3.1 Ingredients to Video: More consistency, creativity and control",
      "description": "Today, we’re introducing an enhanced version of Veo 3.1 “Ingredients to Video.”",
      "content": "Breadcrumb Innovation & AI Technology AI Veo 3.1 Ingredients to Video: More consistency, creativity and control Jan 13, 2026 · Share x.com Facebook LinkedIn Mail Copy link Our latest Veo update generates lively, dynamic clips that feel natural and engaging — and supports vertical video generation. Ricky Wong Lead Product Manager, Google DeepMind Read AI-generated summary General summary Veo 3.1 lets you create more expressive videos from images, directly on your phone. You can now generate vertical videos for platforms like YouTube Shorts, and upscale to 1080p or 4K. Try the updated Veo 3.1 in the Gemini app, YouTube Shorts, Flow, the Gemini API, Vertex AI, and Google Vids. Summaries were generated by Google AI. Generative AI is experimental. Bullet points \"Veo 3.1 Ingredients to Video\" gets upgrades for more creative, high-quality mobile-first videos. Turn images into expressive videos with richer dialogue and consistent characters/backgrounds. Veo 3.1 now supports native vertical (9:16) video output for platforms like YouTube Shorts. Upscaling to 1080p and 4K resolution is available for sharper, high-fidelity video production. You can try Veo 3.1 in the Gemini app, YouTube, Flow, Google Vids, API, and Vertex AI. Summaries were generated by Google AI. Generative AI is experimental. Explore other styles: General summary Bullet points Share x.com Facebook LinkedIn Mail Copy link Your browser does not support the audio element. Listen to article This content is generated by Google AI. Generative AI is experimental [[duration]] minutes Voice Speed Voice Speed 0.75X 1X 1.5X 2X Today, Veo is getting more expressive, with improvements that help you create more fun, creative, high-quality videos based on ingredient images, built directly for the mobile format. We’re excited to bring new creative possibilities for everyone from casual storytellers to professional filmmakers.We’re releasing:Improvements to Veo 3.1 Ingredients to Video, our capability that lets you create videos based on reference images. This update makes videos more expressive and creative, even with simple promptsNative vertical outputs for Ingredients to Video (portrait mode) to power mobile-first, short-form video creationState-of-the-art upscaling to 1080p and 4K resolution 1 for high-fidelity production workflowsWhether you are looking for livelier movement, better control over visual elements or broadcast-ready resolution, these updates give you the tools to bring your vision to life. These updates are launching in the Gemini app, YouTube, Flow, Google Vids, the Gemini API and Vertex AI. Improvements to Veo 3.1 Ingredients to VideoTurn ingredient images into fun, shareable clipsEven with short prompts, you can generate dynamic and engaging videos based on ingredient images. You’ll now see richer dialogue and storytelling, making your videos feel more alive and expressive. Maintain identity consistency for your charactersIdentity consistency is better than ever with Veo 3.1 Ingredients to Video. Keep your characters looking the same even as the setting changes, making it easier to tell a full narrative by having the same character appear across multiple scenes. Achieve background and object consistencyControl the scene by maintaining the integrity of your setting and the objects within it. You can also reuse an object, backgrounds or textures across scenes. Seamlessly blend textures, characters and objectsCombine disparate elements — like characters, objects, textures and stylized backgrounds — into a cohesive, high-impact clip. Pro tip: use the new Nano Banana Pro (Gemini 3 Pro Image) in the Gemini app or Flow to create your ingredient images, which you can then use to create stunning videos with Veo 3.1 Ingredients to Video. Create high-fidelity visuals with upgraded capabilitiesWith Veo 3.1’s new capabilities, we are introducing mobile-optimized outputs and professional-grade quality options.Native vertical outputs for Ingredients to VideoFor the first time, \"Ingredients to Video\" supports generating videos in a native 9:16 aspect ratio. Whether you are creating for YouTube Shorts or other platforms, you can now produce high-quality, full-screen vertical storytelling without cropping or quality loss.State-of-the-art upscaling to 1080p and 4K resolutionGenerate videos 1080p and 4K with state-of-the-art upscaling. Our improved 1080p resolution offers a sharper, cleaner video perfect for editing. For even more detail, choose 4K to capture rich textures and stunning clarity — ideal for high-end productions and large screens. Try these updates todayAcross our products and services, you can now access these new capabilities tailored to your workflow:Consumers and creators: We are bringing Veo 3.1 Ingredients to Video directly to YouTube Shorts and the YouTube Create app for the first time. You can also try the enhanced Veo 3.1 Ingredients to Video and portrait mode for Veo in the Gemini app starting today.Professional and enterprise workflows: The enhanced Veo 3.1 Ingredients to Video and native vertical format support are rolling out to Flow, the Gemini API, Vertex AI, and Google Vids, with 1080p and 4K resolution options also available on Flow, the API, and Vertex AI. Verify videos in the Gemini appWe’re committed to providing tools to make it easier to determine if content is AI-generated. This is why videos generated by Google’s tools are embedded with our imperceptible SynthID digital watermark.In December we expanded our powerful verification tool in the Gemini app to include video. You can now upload a video and simply ask if it was generated with Google AI. This builds on our existing image verification tools, helping to foster a more transparent ecosystem for everyone. You can find out more about how we’re increasing transparency in AI content with SynthID in our blog post. POSTED IN: AI",
      "article_url": "https://blog.google/innovation-and-ai/technology/ai/veo-3-1-ingredients-to-video/",
      "author": "Jan 13, 2026 · Share x.com Facebook LinkedIn Mail Copy link Our latest Veo update generates lively, dynamic clips that feel natural and engaging — and supports vertical video generation. Ricky Wong Lead Product Manager, Google DeepMind Read AI-generated s",
      "publish_time": 1768323600,
      "publish_date": "2026-01-14",
      "category": "AI Blog",
      "tags": "[\"POSTED IN:\", \"AI\"]",
      "cover_image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Veo3.1IngredientstoVideo_Social.width-1300.png",
      "article_type": "blog",
      "is_research": 0,
      "is_product": 0,
      "reference_links": "[{\"title\": \"https://blog.google/\", \"url\": \"https://blog.google/\", \"type\": \"blog\"}, {\"title\": \"Innovation & AI\", \"url\": \"https://blog.google/innovation-and-ai/\", \"type\": \"blog\"}, {\"title\": \"Technology\", \"url\": \"https://blog.google/innovation-and-ai/technology/\", \"type\": \"blog\"}, {\"title\": \"AI\", \"url\": \"https://blog.google/innovation-and-ai/technology/ai/\", \"type\": \"blog\"}, {\"title\": \"x.com\", \"url\": \"https://twitter.com/intent/tweet?text=Veo%203.1%20Ingredients%20to%20Video%3A%20More%20consistency%2C%20creativity%20and%20control%20%40google&url=https://blog.google/innovation-and-ai/technology/ai/veo-3-1-ingredients-to-video/\", \"type\": \"blog\"}, {\"title\": \"Facebook\", \"url\": \"https://www.facebook.com/sharer/sharer.php?caption=Veo%203.1%20Ingredients%20to%20Video%3A%20More%20consistency%2C%20creativity%20and%20control&u=https://blog.google/innovation-and-ai/technology/ai/veo-3-1-ingredients-to-video/\", \"type\": \"blog\"}, {\"title\": \"LinkedIn\", \"url\": \"https://www.linkedin.com/shareArticle?mini=true&url=https://blog.google/innovation-and-ai/technology/ai/veo-3-1-ingredients-to-video/&title=Veo%203.1%20Ingredients%20to%20Video%3A%20More%20consistency%2C%20creativity%20and%20control\", \"type\": \"blog\"}, {\"title\": \"Mail\", \"url\": \"mailto:?subject=Veo%203.1%20Ingredients%20to%20Video%3A%20More%20consistency%2C%20creativity%20and%20control&body=Check out this article on the Keyword:%0A%0AVeo%203.1%20Ingredients%20to%20Video%3A%20More%20consistency%2C%20creativity%20and%20control%0A%0AToday, we’re introducing an enhanced version of Veo 3.1 “Ingredients to Video.”%0A%0Ahttps://blog.google/innovation-and-ai/technology/ai/veo-3-1-ingredients-to-video/\", \"type\": \"blog\"}, {\"title\": \"Gemini app\", \"url\": \"http://gemini.google.com/\", \"type\": \"official\"}, {\"title\": \"Flow\", \"url\": \"http://flow.google/\", \"type\": \"external\"}, {\"title\": \"YouTube Shorts and the YouTube Create app\", \"url\": \"https://support.google.com/youtube/thread/400398403\", \"type\": \"official\"}, {\"title\": \"Gemini API\", \"url\": \"https://ai.google.dev/gemini-api/docs/video\", \"type\": \"external\"}, {\"title\": \"Vertex AI\", \"url\": \"https://console.cloud.google.com/vertex-ai/studio/media/video\", \"type\": \"official\"}, {\"title\": \"Google Vids\", \"url\": \"http://docs.google.com/videos/create?usp=blog\", \"type\": \"official\"}, {\"title\": \"blog post\", \"url\": \"https://blog.google/technology/ai/verify-google-ai-videos-gemini-app/\", \"type\": \"blog\"}]",
      "add_ts": 1768346276,
      "last_modify_ts": 1768346283
    }
  ],
  "aibase_article": [
    {
      "id": 2,
      "article_id": "aibase_24054",
      "title": "2.6B Parameters Outperform Billion-Level Giants! Liquid AI Releases New Experimental Model LFM2-2.6B-Exp",
      "description": "On Christmas Day, the renowned edge AI startup Liquid AI officially released its latest experimental model, LFM2-2.6B-Exp. This small open-source model with onl",
      "content": "On Christmas Day, the renowned edge AI startup Liquid AI officially released its latest experimental model, LFM2-2.6B-Exp. This small open-source model with only 2.6B (26 billion) parameters performed outstandingly in multiple key benchmark tests, especially excelling in instruction following, surpassing DeepSeek R1-0528, which has hundreds of billions of parameters. It has sparked widespread discussion in the industry and is hailed as the \"strongest 3B model.\"Model Background: Experimental Breakthrough Driven by Pure Reinforcement LearningLFM2-2.6B-Exp is based on the 2.6B foundation model of Liquid AI's second-generation Liquid Foundation Models (LFM2) series. It was optimized through pure reinforcement learning (RL), without requiring supervised fine-tuning warm-up or large teacher model distillation. The model inherits the advantages of LFM2's hybrid architecture, combining short-range gated convolution and grouped query attention (GQA), supporting a 32K context length, and is designed for edge devices such as smartphones, laptops, and IoT devices, achieving efficient local deployment.Liquid AI emphasized that this experimental checkpoint mainly focuses on optimizing instruction following, knowledge question answering, and mathematical reasoning, suitable for agent workflows, RAG retrieval, data extraction, creative writing, and multi-turn dialogues.Performance Highlights: Big Power from a Small SizeIn the latest benchmark tests, LFM2-2.6B-Exp showed amazing performance:- IFBench (Instruction Following Benchmark): Scored significantly ahead of similar models, even surpassing DeepSeek R1-0528, which has 263 times more parameters.- GPQA (Graduate-Level Knowledge Question Answering): Reached approximately 42%, far exceeding traditional 3B models.- IFEval (Strict Instruction Following): Exceeded 88%, defeating many models with over 10B parameters.- GSM8K (Mathematical Reasoning): Scored above 82%, outperforming Llama3.23B and Gemma3 series.Additionally, the model's prefilling and decoding speed on CPU is twice that of competitors, with extremely low memory usage and support for bfloat16 quantization, truly achieving \"PhD-level reasoning on a smartphone.\"Open Source Significance: Accelerating the Popularization of Edge AILFM2-2.6B-Exp is fully open source, with model weights uploaded to the Hugging Face platform, allowing developers to freely download and integrate it into local applications. This not only demonstrates the huge potential of reinforcement learning on small models but also further promotes the development of the edge AI ecosystem, making high-performance AI accessible from the cloud to every device.AIbase Comment: The release of LFM2-2.6B-Exp marks the acceleration of the era of small models: no need for massive parameters, advanced performance can be achieved through intelligent training paradigms. For developers and enterprises pursuing privacy, low latency, and low cost, this model is undoubtedly one of the best choices at present. In the future, as RL technology and hybrid architectures continue to evolve, 3B open-source models may approach AGI levels and run smoothly on any device. Interested readers can immediately go to Hugging Face to download and experience it, opening a new chapter in edge intelligence.Address: https://huggingface.co/LiquidAI/LFM2-2.6B-Exp",
      "article_url": "https://www.aibase.com/news/24054",
      "author": "AIbase",
      "publish_time": 1766988464,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AI Terminology\", \"LFM2-2.6B-Exp\", \"LiquidAI\", \"Reinforcement Learning\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://huggingface.co/LiquidAI/LFM2-2.6B-Exp\", \"url\": \"https://huggingface.co/LiquidAI/LFM2-2.6B-Exp\", \"type\": \"code\"}]",
      "add_ts": 1766988464,
      "last_modify_ts": 1766988464
    },
    {
      "id": 4,
      "article_id": "aibase_24042",
      "title": "Stand Up to Doubao! Lenovo's Strategic AI Exposed at CES: The Super Intelligent Agent That Integrates PC and Mobile Ecosystems Is Here",
      "description": "According to AIbase, Lenovo Group plans to officially launch its first strategic application for the global market - \"AI Super Agent\" during the upcoming CES. T",
      "content": "According to AIbase, Lenovo Group plans to officially launch its first strategic application for the global market - \"AI Super Agent\" during the upcoming CES. This move marks Lenovo's comprehensive effort in AI applications, with its goal directly targeting ByteDance's recently popular \"Douba Mobile Assistant\". Although the official name of this agent has not been announced yet, according to insiders close to Lenovo, its functionality and ecological coordination capabilities are stronger than Douba.Different from common single voice assistants on the market, this super agent from Lenovo is defined as a system-level application. It is not an independent operating system, but has the core central function of connecting different AI capabilities and multiple hardware terminals. This agent completely integrates Lenovo's hardware ecosystem, enabling seamless connectivity between Motorola phones, Lenovo PCs, tablets, and wearable devices. This cross-device and cross-system feature means users can interact through text, voice, or even environmental perception in multi-terminal environments, and the agent will deeply learn and adapt to the user's personal habits over time.In terms of competitive landscape, Lenovo demonstrates unique advantages as a hardware giant. At the beginning of this month, ByteDance jointly launched with ZTE a \"Douba Mobile Phone\" that has cross-application calling capabilities, helping users complete tasks such as ordering takeout, booking flights, and replying to messages. However, as the leading PC company with a global market share of 25.5%, Lenovo's Motorola phones have also exceeded 16 million units in quarterly shipments.This solid hardware foundation allows the Lenovo Super Agent to have deeper system-level embedded permissions on both phones and PCs. Compared to ByteDance's cross-industry cooperation model, Lenovo can start from the underlying hardware to more efficiently coordinate multiple intelligent agents in the background, thus achieving a more comprehensive user experience in cross-device connection and task scheduling.",
      "article_url": "https://www.aibase.com/news/24042",
      "author": "AIbase",
      "publish_time": 1766988470,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AI Super Intelligent Agent\", \"Lenovo Group\", \"ByteDance\", \"CES\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1766988470,
      "last_modify_ts": 1766988470
    },
    {
      "id": 5,
      "article_id": "aibase_24035",
      "title": "ChatGPT Will Launch Skills! OpenAI's Internal Codename: Hazelnut - Composable, Portable, Supports Code, May Launch in Early 2026",
      "description": "OpenAI is quietly building a new \"capability operating system\" for ChatGPT. According to a recent disclosure by BleepingComputer, OpenAI has been internally tes",
      "content": "OpenAI is quietly building a new \"capability operating system\" for ChatGPT. According to a recent disclosure by BleepingComputer, OpenAI has been internally testing a new feature called \"Skills\" (Skills), which shares a similar design philosophy with Anthropic's Claude Skills, but emphasizes modularity, executability, and cross-platform reusability. This feature, codenamed \"hazelnuts\" (hazelnuts), is expected to be officially launched around January 2026, and could revolutionize the way users collaborate with AI.Skills ≠ GPTs: From \"Custom Assistant\" to \"Capability Module\"Currently, ChatGPT's GPTs rely on prompt engineering to encapsulate specific functions, while Skills are more fundamental pre-trained capability units: - Organized in folders, including instructions, context, examples, and even executable code; - Automatically identified, dynamically loaded, and combined by AI during tasks; - Support converting existing GPTs into Skills with one click, achieving capability accumulation and reuse.For example, users can create a \"Financial Analysis Skill,\" embedded with Python scripts, financial report parsing rules, and visualization templates. When asked, \"Analyze this financial report trend,\" ChatGPT automatically calls this Skill, runs the code, generates charts, and provides an analysis—without needing to repeatedly describe the request or manually paste the code.Four Core Features Define a New Standard for AI Capabilities1. Composability: Multiple Skills can be used together, such as \"Translation + Legal Review + Contract Generation\" to form a compliance workflow for international expansion; 2. Portability: Built once, usable across ChatGPT Web, mobile, API, and third-party applications; 3. Efficiency: Loaded on demand, avoiding redundant calculations of the full model; 4. Scalability: Supports encapsulating multimodal capabilities such as text, tool calls, and code snippets.Interaction Method Revealed: Slash Commands + Visual EditorAccording to UI screenshots leaked on social platforms, Skills will be quickly accessible via slash commands (e.g., \"/financial-analysis\") and come with a visual editor that allows users to drag-and-drop modules, write logic, and test effects, greatly lowering the development barrier.Why Now? To Compete in the Agent EcosystemAs AI agents become the industry focus, OpenAI is accelerating its transition from a \"dialogue model\" to a \"programmable intelligent platform.\" The Skills mechanism will allow developers to build complex agents like building blocks, while ordinary users can also access professional capabilities through shared skill libraries—this is a key move for OpenAI to compete against Claude, Gemini, and open-source agent frameworks.",
      "article_url": "https://www.aibase.com/news/24035",
      "author": "AIbase",
      "publish_time": 1766988472,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"OpenAI\", \"ChatGPT\", \"Skills\", \"AI Terms\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1766988472,
      "last_modify_ts": 1766988472
    },
    {
      "id": 7,
      "article_id": "aibase_24026",
      "title": "Xiaohongshu Open Sources InstanceAssemble! A Lightweight Layout-Controlled Generation Framework, Further Breaking the Accuracy of Complex Multi-Instance Image Generation",
      "description": "At a critical stage where AIGC moves from \"free creation\" to \"precise control,\" the Xiaohongshu AIGC team has open-sourced its new layout-controllable image gen",
      "content": "At a critical stage where AIGC moves from \"free creation\" to \"precise control,\" the Xiaohongshu AIGC team has open-sourced its new layout-controllable image generation framework, InstanceAssemble, specifically designed to address Layout-to-Image tasks with high density, multiple objects, and complex spatial relationships. The framework significantly improves spatial alignment accuracy and semantic consistency while maintaining a minimal parameter increase (as low as 0.84%), offering an industrial-level solution for high-demand scenarios such as e-commerce, design, and gaming. Cascade Modeling + Assemble-Attention, Solving the \"Multiple Objects Stacked\" Challenge Traditional Layout-to-Image models often encounter issues like object misalignment, overlapping, or semantic mismatch when dealing with complex layouts such as \"10 product icons + text labels + background layers.\" InstanceAssemble innovatively adopts a cascade two-stage architecture: 1. Semantic Understanding Stage: Analyzing the semantic relationship between text descriptions and layout instructions; 2. Spatial Assembly Stage: Dynamically modeling the relative positions, occlusion relationships, and hierarchical structures between instances through the self-developed Assemble-Attention mechanism, ensuring that each element is \"where it should be.\" Experiments show that in scenarios such as dense product displays, multi-character illustrations, and UI generation, InstanceAssemble significantly outperforms existing methods in object positioning accuracy and edge clarity. Ultra-lightweight Adaptation, Compatible with Mainstream Base Models To reduce deployment barriers, the framework uses an ultra-lightweight LoRA adapter: - Adapting Stable Diffusion3-Medium requires only 3.46% additional parameters; - For Flux.1 model, it's as low as 0.84%. This means users don't need to retrain large models, and can retain the powerful generation capabilities of the base model while flexibly injecting layout control abilities, supporting multimodal instructions such as text, reference images, and bounding boxes. Self-built DenseLayout Benchmark, Promoting Evaluation Standardization To accurately measure layout alignment quality, Xiaohongshu also released the DenseLayout evaluation dataset and the LGS (Layout Grounding Score) explainable metric. LGS quantifies the generation results from three dimensions: position accuracy, scale matching, and semantic consistency, solving the problem of traditional metrics (such as IoU) being inaccurate in dense scenarios. AIbase believes that the release of InstanceAssemble marks that AIGC is moving from \"looking good\" to \"placing accurately.\" When AI can not only generate beautiful images but also \"place\" each element according to precise layout instructions from designers, AIGC truly has the capability to integrate into professional production processes. Xiaohongshu's open-source initiative not only empowers community creators but also drives the entire industry toward controllable, reliable, and commercializable generative AI. Paper Link: https://arxiv.org/abs/2509.16691 Project Page: https://github.com/FireRedTeam/InstanceAssemble",
      "article_url": "https://www.aibase.com/news/24026",
      "author": "AIbase",
      "publish_time": 1766988478,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AIGC\", \"InstanceAssemble\", \"Controllable Image Generation\", \"Layout-to-Image\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://arxiv.org/abs/2509.16691\", \"url\": \"https://arxiv.org/abs/2509.16691\", \"type\": \"paper\"}, {\"title\": \"https://github.com/FireRedTeam/InstanceAssemble\", \"url\": \"https://github.com/FireRedTeam/InstanceAssemble\", \"type\": \"code\"}]",
      "add_ts": 1766988478,
      "last_modify_ts": 1766988478
    },
    {
      "id": 8,
      "article_id": "aibase_24024",
      "title": "5-Minute Mastery: Study Finds Humans Can Detect AI-Generated Faces Through Targeted Training",
      "description": "With the rapid development of generative AI technology, AI-generated \"fake faces\" have become almost indistinguishable from real ones. However, a recent study p",
      "content": "With the rapid development of generative AI technology, AI-generated \"fake faces\" have become almost indistinguishable from real ones. However, a recent study published in \"Royal Society Open Science\" brings good news: the ability to identify AI-fabricated faces can be significantly improved through short-term training.This research, conducted by several universities including the University of Leeds and the University of Reading, invited 664 participants to distinguish between face images generated by the StyleGAN3 system. The experimental results showed that without any training, the accuracy of ordinary people was only 31%, and even for those with natural talent as \"super face recognizers,\" the accuracy was only 41%. This indicates that human intuition is often unreliable when facing the most advanced AI generation technologies.Surprisingly, researchers found that just a 5-minute targeted visual training session could significantly improve identification results. After learning how to observe abnormal tooth arrangements, unnatural hairlines, and asymmetrical ears or accessories, the accuracy of super face recognizers increased to 64%, while the accuracy of ordinary people rose to 51%.Dr. Eilidh Noyes from the University of Leeds pointed out that as the barriers to creating AI images are lowering and their concealment is increasing, developing effective identification methods has become an important issue in the field of security. Currently, AI-generated faces are often used to forge social media accounts, create fake documents, and even attempt to bypass identity verification systems. The research team will further explore the durability of this training effect and try to combine the visual advantages of humans with AI automated detection tools to address the growing digital security challenges.Paper link: https://dx.doi.org/10.1098/rsos.250921Key Points:🕵️‍♂️ Identify Flaws: AI-generated faces often reveal clues in details such as tooth arrangement, hairline edges, and ear symmetry.⏱️ Short Training Works: Just about 5 minutes of targeted learning can significantly improve the ability of both ordinary people and professional face recognizers to identify AI images.🛡️ Address Security Risks: This study aims to prevent real-world security threats such as social fraud and identity verification bypass using AI fake faces.",
      "article_url": "https://www.aibase.com/news/24024",
      "author": "AIbase",
      "publish_time": 1766988480,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Generative Artificial Intelligence\", \"StyleGAN3\", \"AI-Generated Faces\", \"Facial Recognition Skills\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://dx.doi.org/10.1098/rsos.250921Key\", \"url\": \"https://dx.doi.org/10.1098/rsos.250921Key\", \"type\": \"external\"}]",
      "add_ts": 1766988480,
      "last_modify_ts": 1766988480
    },
    {
      "id": 9,
      "article_id": "aibase_24094",
      "title": "AI Programming Assistant Upgraded Again: Windsurf Wave13 Officially Released, SWE-1.5 Model Offered Free for a Limited Time",
      "description": "Renowned AI programming tool Windsurf has officially released the Wave13 version, codenamed \"Shipmas.\" This update focuses on three core dimensions: model capab",
      "content": "Renowned AI programming tool Windsurf has officially released the Wave13 version, codenamed \"Shipmas.\" This update focuses on three core dimensions: model capabilities, multi-agent collaboration, and terminal experience, aiming to further solidify its positioning as an IDE centered around agents.In terms of models, Windsurf Wave13 sets the \"Penguin Alpha\" SWE-1.5 model as the default option. This model offers performance at the SWE-Bench-Pro level, capable of handling more complex code reasoning and generation tasks. To reward developers, Windsurf has announced that for the next three months, it will offer free access to the standard version of SWE-1.5 to all users.To address the pain points of multi-task collaboration, the new version introduces **Parallel Agents** support. By integrating Git Worktree, multiple AI agents can operate in parallel across different work trees within the same repository without interfering with each other. This means developers can simultaneously launch tasks such as bug fixing, documentation writing, and test generation, significantly improving development efficiency for large projects and reducing the risk of code conflicts.Additionally, AIbase observed that Wave13 has also undergone deep optimization in interaction experience. The new version introduces a side-by-side view feature, allowing developers to manage multiple Cascade panes simultaneously. It also launched a dedicated terminal (Beta version) supporting zsh, providing more reliable script execution and environment management capabilities. Meanwhile, the newly added context window indicator displays real-time token usage, helping users accurately manage conversation history.Key Points:🚀 Major Model Upgrade:Windsurf defaults to the high-performance SWE-1.5 model and announced that the standard version will be freely available for all users for the next three months.🔄 Efficient Parallel Collaboration: Introduced parallel agent technology, supporting the execution of multiple development tasks simultaneously in different Git Worktree, eliminating collaboration conflicts.🧠 Improved Interaction Experience: Added side-by-side pane views and a dedicated Cascade terminal, along with a real-time context indicator to optimize long conversation management.",
      "article_url": "https://www.aibase.com/news/24094",
      "author": "AIbase",
      "publish_time": 1767050257,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Windsurf\", \"Shipmas\", \"PenguinAlpha\", \"SWE-1.5\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767050257,
      "last_modify_ts": 1767050257
    },
    {
      "id": 10,
      "article_id": "aibase_24092",
      "title": "Step-DeepResearch, a Cost-Effective Deep Research Model Launched by StepStellar",
      "description": "Recently, Stepfun officially open-sourced a new deep research model called Step-DeepResearch. This model has 32 billion parameters and is dedicated to autonomou",
      "content": "Recently, Stepfun officially open-sourced a new deep research model called Step-DeepResearch. This model has 32 billion parameters and is dedicated to autonomous information exploration and professional report generation in an open research environment. According to the official introduction, Step-DeepResearch's deep research capabilities are close to top commercial models such as OpenAI's o3-mini and Gemini 2.0 Flash, but its deployment cost is only one-tenth of traditional models, with a single call cost below 0.5 RMB.The design concept of Step-DeepResearch is very unique. It breaks down complex research tasks into multiple trainable \"atomic capabilities,\" such as planning, information retrieval, reflection, and cross-validation, thereby achieving closed-loop reflection and dynamic correction. This approach not only enhances the model's adaptability in complex environments but also improves its generalization performance. The training process of the model is carefully designed, from agent mid-training to supervised fine-tuning (SFT) and reinforcement learning (RL), ensuring excellent performance in complex practical applications.In testing, Step-DeepResearch achieved a high score of 61.4% on the Scale AI Research Rubrics, which is comparable to some larger-scale models such as OpenAI Deep Research and Gemini Deep Research. Additionally, in the expert evaluation of ADR-Bench, Step-DeepResearch's Elo rating was significantly higher than many competitors, demonstrating its strong capabilities in the field of deep research.To support scientific research workflows, Step-DeepResearch adopts a single-agent architecture based on the ReAct paradigm, featuring a dynamic cycle of reasoning, action, and reflection. Through its internal proprietary toolset, the system can efficiently perform batch web searches, file management, and interactive command execution, providing great convenience for researchers.github: https://github.com/stepfun-ai/StepDeepResearchKey points: ✨ Step-DeepResearch is the latest open-source deep research model from Stepfun, with a parameter scale of 32 billion. 💡 This model's deep research capabilities are close to top commercial models, but its cost is only one-tenth of traditional models. 🚀 With a unique training process and dynamic loop architecture, Step-DeepResearch provides efficient support in scientific research.",
      "article_url": "https://www.aibase.com/news/24092",
      "author": "AIbase",
      "publish_time": 1767050260,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Step-DeepResearch\", \"AINeologism\", \"LeapStar\", \"DeepResearchModel\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://github.com/stepfun-ai/StepDeepResearchKey\", \"url\": \"https://github.com/stepfun-ai/StepDeepResearchKey\", \"type\": \"code\"}]",
      "add_ts": 1767050260,
      "last_modify_ts": 1767050260
    },
    {
      "id": 12,
      "article_id": "aibase_24087",
      "title": "B站 Xiaohongshu Video to Hand-drawn Storyboard! Open Source Tool ClipSketch AI, Time-saving Assistant for Short Video Creators",
      "description": "Recently, an open-source tool called ClipSketch AI has quickly gained popularity in the content creation community. Designed specifically for video remixing and",
      "content": "Recently, an open-source tool called ClipSketch AI has quickly gained popularity in the content creation community. Designed specifically for video remixing and short video operations, this tool can instantly transform long videos into hand-drawn storyboards and automatically generate viral copy suitable for social media, helping users significantly improve their content production efficiency.Core features of ClipSketch AI: Video Analysis and Intelligent ExtractionThe biggest highlight of ClipSketch AI is its ability to import videos from multiple sources, supporting direct parsing of sharing links from Bilibili (B站) and Xiaohongshu platforms (including short links and mixed text and copy). Users just need to paste the link, and the tool can automatically download the video and intelligently extract key frames, eliminating the tedious process of manually taking screenshots.After extraction, the framework converts these key frames into elegant hand-drawn scene illustrations using an AI model (such as the Gemini series), creating a unique comic feel and storyboard visual effect while maintaining the core content and narrative logic of the original video.One-click generation of copy: Directly publish on social platformsIn addition to visual output, ClipSketch AI also integrates an AI copy generation feature. Based on the extracted key frames and video content, it automatically writes explanatory copy, titles, or note descriptions suitable for short video platforms. These copies come in various styles and can be directly copied and used, greatly lowering the threshold for video breakdown and content publishing.Wide application scenarios: An excellent assistant for remixing and operationsThis tool is particularly suitable for:- Series content creation: Quickly break down tutorial videos and generate structured storyboards- Dramatic short videos: Convert long plots into hand-drawn storyboards for easier remixing- Product recommendation accounts: Extract highlights from product review videos and post them with hand-drawn images and copy- Social media operations: Efficiently process content from Bilibili UPs or Xiaohongshu bloggers for cross-platform remixingCommunity feedback shows that after using ClipSketch AI, many creators have reduced their video breakdown and copy preparation time to a fraction of the original, especially suitable for individual operators and small teams.Open source and easy to use: Zero barrier for local deploymentClipSketch AI is a pure front-end project built using modern frameworks such as Vite. Developers can directly clone the code from the GitHub repository, install dependencies, and run it locally. The AI drawing function requires configuring a Google Gemini API Key (supporting the gemini-3-pro-image-preview model) to ensure the quality of the generated results.",
      "article_url": "https://www.aibase.com/news/24087",
      "author": "AIbase",
      "publish_time": 1767050265,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"ClipSketchAI\", \"AINeologism\", \"Bilibili\", \"Hand-drawnStyle\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767050265,
      "last_modify_ts": 1767050265
    },
    {
      "id": 14,
      "article_id": "aibase_24083",
      "title": "Yuanbao AI Task Reminder Function Launch Covers Multiple Scenarios in Life and Work, One Sentence Handles Timed Arrangements",
      "description": "On December 29, 2025, users in the Guangdong region were among the first to experience the newly launched \"Task Reminder\" feature of Yaba AI. This feature allow",
      "content": "On December 29, 2025, users in the Guangdong region were among the first to experience the newly launched \"Task Reminder\" feature of Yaba AI. This feature allows users to set recurring scheduled tasks with just one sentence, covering a wide range of scenarios such as daily chores, habit formation, and work-related tasks. It will actively send reminders at the designated time, and in some scenarios, it can also provide additional services, significantly improving daily scheduling efficiency.According to the information, the task reminder feature of Yaba AI is easy to use. Users don't need complex settings; they can simply inform their needs through voice or text. In daily life scenarios, there are reminders like \"Remind me on the 15th of each month to give my cat deworming medication and check the medicine stock,\" or \"Send bedtime stories for children aged 4-5 every night at 8:30 PM.\" There are even emotional care tasks like \"Remind me to make a video call to my mother at 8:00 PM every Saturday to ask about her leg pain,\" which are designed with detailed attention to users' daily needs.In terms of habit formation, the feature supports reminders like \"Remind me to put down my phone at 11:00 PM every night to go to sleep\" and can recommend relaxing music playlists; \"Remind me to do the Pamelas Phoenix Legend version of fitness exercises every day at 8:00 PM\" and can help search for video tutorials to help users achieve their self-discipline goals easily. In the workplace, the feature \"Remind me to write the weekly report every Friday at 4:00 PM\" is particularly practical, not only reminding on time but also asking about the user's three major events of the week and automatically expanding them into a draft of the weekly report. The function \"Send AI industry news from the previous day every morning at 9:00 AM\" meets the needs of professionals to access information and is suitable for use during morning meetings.Currently, Yaba AI is supported on both App and desktop versions, and users can use it by updating to the latest version. In the future, users can also share their experiences in the comments section and have the chance to win the \"2026 Yaba Heart Words Calendar.\" The launch of this feature marks the further expansion of AI assistants toward the role of a \"personalized lifestyle assistant,\" creating a more convenient intelligent service experience for users.",
      "article_url": "https://www.aibase.com/news/24083",
      "author": "AIbase",
      "publish_time": 1767050270,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"YuanbaoAI\", \"TaskReminder\", \"AIBuzzword\", \"BrandProductTerminology\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767050270,
      "last_modify_ts": 1767050270
    },
    {
      "id": 15,
      "article_id": "aibase_24077",
      "title": "Build a Video AI Application in Minutes! Open-Source Framework VideoPipe Makes CV Deployment as Easy as Building with Blocks",
      "description": "Recently, an open-source video analysis framework called VideoPipe, which focuses on the rapid integration and deployment of AI algorithms in the computer visio",
      "content": "Recently, an open-source video analysis framework called VideoPipe, which focuses on the rapid integration and deployment of AI algorithms in the computer vision (CV) field, has sparked heated discussions in the developer community. With its innovative pipeline design and extremely simple onboarding experience, this framework has become an \"accelerator\" for video AI application development, helping developers free themselves from tedious low-level coding and focus on implementing business logic.Core Design of VideoPipe: Composable Pipelines, Modular Task DecompositionVideoPipe uses a unique pipeline architecture that breaks down complex video analysis tasks into a series of independent \"nodes\" (Node). Each node is responsible for a single function, such as pulling streams, decoding, inference, or pushing streams. Nodes are independent but can be freely combined. This plug-in design allows developers to build applications like building blocks, without having to write the entire process from scratch.According to the framework documentation, developers only need to prepare an AI model and parse its output to quickly build a pipeline through simple configuration. Compared with traditional frameworks that are heavy and difficult to debug, VideoPipe has minimal dependencies and excellent cross-platform support, making it easier to port to different hardware environments.Multi-source Input and Protocol Support: Seamless Integration with Mainstream Video StreamsVideoPipe performs well in data reading, supporting various mainstream video stream protocols, including UDP, RTSP, RTMP, as well as local files and application image input. This makes the framework suitable for real-time monitoring, traffic cameras, and other scenarios, allowing easy processing of network streaming media or offline video data.Additionally, it supports image sequence input, expanding its potential applications in static image search or hybrid media analysis.Diverse Inference Engines: Deep Learning + Traditional Algorithms + Multimodal Large ModelsThe biggest highlight of the framework lies in the flexibility of algorithm inference. It supports multi-level cascaded inference of deep learning models, while also being compatible with traditional image processing algorithms (such as classic OpenCV methods). More notably, VideoPipe has integrated support for multimodal large models, allowing developers to seamlessly embed cutting-edge large language vision models into the video processing workflow.It includes multiple object tracking algorithms to ensure continuous tracking of specific objects in videos, suitable for accurate analysis in dynamic scenarios.End-to-End Solution: From Pulling to Pushing Streams, One-stop CoverageVideoPipe covers almost the entire chain of video AI applications: pull stream decoding → multi-level inference → object tracking → behavior analysis → frame annotation → screen recording and screenshot → encoding and pushing streams → message notification. Developers just need to \"add what's missing,\" and they can quickly assemble a complete video AI prototype within minutes.Typical application scenarios include:- Video structured processing- Image retrieval and search- Face recognition and tracking- Traffic incident detection (e.g., violation recognition, reverse monitoring)- Creative applications such as AI face swapping- Security monitoring and behavior analysisPositive Community Feedback: 40+ Examples Help Get Started QuicklyVideoPipe provides more than 40 ready-made examples covering popular scenarios such as face recognition, vehicle detection, and pose estimation, along with detailed documentation and video tutorials. Recent community sharing shows that many developers have used this framework to quickly implement intelligent monitoring prototypes and traffic analysis systems, greatly shortening the cycle from concept to implementation.AIbase's view: The emergence of VideoPipe has lowered the engineering threshold in the AI video analysis field, enabling more small and medium teams and individual developers to efficiently deploy CV applications. With the integration of multimodal large models, its potential will be further unleashed. Interested developers can visit the GitHub repository (sherlockchou86/VideoPipe) to star and experience it.Project Address: https://github.com/sherlockchou86/VideoPipe",
      "article_url": "https://www.aibase.com/news/24077",
      "author": "AIbase",
      "publish_time": 1767050283,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"VideoPipe\", \"ComputerVision\", \"AIAlgorithms\", \"OpenSourceFramework\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://github.com/sherlockchou86/VideoPipe\", \"url\": \"https://github.com/sherlockchou86/VideoPipe\", \"type\": \"code\"}]",
      "add_ts": 1767050283,
      "last_modify_ts": 1767050283
    },
    {
      "id": 16,
      "article_id": "aibase_24074",
      "title": "Simplicity Over Complexity: Meta AI Unveils the Pixio Image Model, Setting New Records in 3D Reconstruction Through Pixel Reconstruction",
      "description": "According to AIbase, the Meta AI research team recently released a study on an image model called Pixio, demonstrating that even with a simpler training path, i",
      "content": "According to AIbase, the Meta AI research team recently released a study on an image model called Pixio, demonstrating that even with a simpler training path, it can show outstanding performance in complex visual tasks such as depth estimation and 3D reconstruction. For a long time, the academic community generally believed that mask autoencoder (MAE) technology was inferior to more complex algorithms like DINOv2 or DINOv3 in scene understanding, but the emergence of Pixio has broken this conventional belief.The core logic of Pixio comes from a deep improvement of the MAE framework from 2021. Researchers found that the weak decoder in the original design limited the performance of the encoder, so they significantly enhanced the decoder's functionality and expanded the image masking area. By replacing small masking blocks with large continuous regions, Pixio is forced to abandon simple pixel copying and instead truly \"understand\" spatial relationships such as object co-occurrence, 3D perspective, and reflections in the image. In addition, by introducing multiple category tokens for aggregating global properties, the model can more accurately capture scene types, camera angles, and lighting information.In terms of training strategy, Pixio shows a high degree of purity. Unlike DINOv3, which repeatedly optimizes for specific benchmark tests (such as ImageNet), Pixio collected 2 billion images from the web and used dynamic frequency adjustment: reducing the weight of simple product photos and increasing the training frequency of complex scenes. This approach of not \"cheating\" on the test set actually gives the model stronger transferability.Data comparisons show that Pixio, with only 631 million parameters, outperforms DINOv3 with 841 million parameters in multiple metrics. In monocular depth estimation, its accuracy improved by 16%; in 3D reconstruction tasks, Pixio trained with a single image even outperformed DINOv3 trained with eight views. At the same time, in the field of robot learning, Pixio also leads DINOv2 with a success rate of 78.4%. Although the research team acknowledges the limitations of manual masking and plans to explore the direction of video prediction, the breakthroughs achieved by Pixio so far are sufficient to prove that returning to the essence of pixel reconstruction often leads to deeper visual understanding.",
      "article_url": "https://www.aibase.com/news/24074",
      "author": "AIbase",
      "publish_time": 1767050286,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Pixio\", \"MetaAI\", \"MAE\", \"DepthEstimation\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767050286,
      "last_modify_ts": 1767050286
    },
    {
      "id": 17,
      "article_id": "aibase_24132",
      "title": "Tencent Hunyuan releases version 1.5 of its open-source translation model: Performance on edge devices improves significantly, with results comparable to large closed-source models",
      "description": "Tencent HY-MT has officially announced the open-source release of its translation model version 1.5 today. This update includes two models of different sizes: T",
      "content": "Tencent HY-MT has officially announced the open-source release of its translation model version 1.5 today. This update includes two models of different sizes: Tencent-HY-MT1.5-1.8B and Tencent-HY-MT1.5-7B, aiming to redefine the translation experience of edge-cloud collaboration with extreme efficiency and leading translation quality.Key Highlights: Edge Deployment and Outstanding PerformanceThe 1.8B model released this time stands out particularly. As a lightweight model designed for consumer devices such as smartphones, it can run smoothly offline with only 1GB of memory after quantization.Extreme Speed: The average time to process 50 tokens is just 0.18 seconds, which is much faster than the 0.4 seconds of mainstream commercial translation APIs.Superior Performance: In authoritative test sets such as FLORES-200, its performance reaches the 90th percentile level of large closed-source models like Gemini-3.0-Pro, surpassing medium-sized open-source models comprehensively.Comprehensive Coverage: From Mainstream Languages to Dialects and ChineseThe HY-MT 1.5 model supports mutual translation of 33 global languages, including Chinese, English, Japanese, and French, and especially strengthens support for smaller languages such as Czech, Estonian, and Icelandic. In addition, the model covers 5 domestic minority languages and dialects, greatly expanding the application boundaries of AI translation.Functional Evolution: More Practical Translation ExperienceRegarding actual application scenarios, the 1.5 version has made significant upgrades in three dimensions:Custom Terminology Library: Users can upload terminology lists for specialized fields such as medicine, law, and finance to ensure consistent translation of professional terms.Context Understanding: It has advanced long-text dialogue comprehension capabilities, optimizing subsequent results based on the context of previous text, avoiding semantic breaks.Format Preservation Ability: Through precise instruction following, the model can perfectly preserve the original text format (such as web pages, code, and Markdown) after translation.Technical Breakthrough: Large Model Guiding Small ModelThe reason why HY-MT1.5-1.8B achieves so much with so little is due to Tencent's On-Policy Distillation (large model distillation) strategy. A 7B-sized \"teacher\" model guides the \"student\" model in real time, helping it learn from prediction deviations rather than simply memorizing answers, thus significantly improving the small model's logical and translation abilities.Developer Ecosystem: Full Platform SupportCurrently, the HY-MT 1.5 model is available on the Tencent HY Website and is open-sourced on Github and HuggingFace communities. The model has been adapted to mainstream computing platforms such as Arm, Qualcomm, Intel, and Muxi.From Tencent Meeting to Enterprise WeChat, Tencent HY translation technology has been implemented in multiple internal high-concurrency scenarios. With the open source of the 1.5 version, Tencent is further promoting high-quality AI translation technology toward inclusivity, providing global developers with a more cost-effective translation solution.",
      "article_url": "https://www.aibase.com/news/24132",
      "author": "AIbase",
      "publish_time": 1767136630,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Tencent Hunyuan\", \"Translation Model\", \"Tencent-HY-MT1.5-1.8B\", \"Edge Deployment\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767136630,
      "last_modify_ts": 1767136630
    },
    {
      "id": 19,
      "article_id": "aibase_24128",
      "title": "Say Goodbye to the Command Line! Claude Code's Visual Workflow Editor Goes Viral: Build AI Automation Tools by Dragging Nodes",
      "description": "At the end of 2025, Anthropic's Claude Code achieved a major breakthrough in its community ecosystem: a VSCode extension tool called \"Claude Code Workflow Studi",
      "content": "At the end of 2025, Anthropic's Claude Code achieved a major breakthrough in its community ecosystem: a VSCode extension tool called \"Claude Code Workflow Studio\" quickly gained popularity. This tool enables users to build and execute advanced AI automation workflows without writing complex prompts or terminal commands, through an intuitive drag-and-drop canvas interface. This marks the evolution of Claude Code from a purely command-line tool to a visual, no-code solution, significantly lowering the barrier for non-professional developers.Core Features: Drag-and-Drop Nodes to Build Complex WorkflowsClaude Code Workflow Studio provides a dedicated \"canvas\" view within VSCode, allowing users to design workflows by simply dragging and dropping nodes. The main nodes include:- Prompt (Prompt Node)- Sub-Agent (Sub-Agent)- Skill (Skill)- MCP (Model Context Protocol Tool)- IfElse (Conditional Branch)- AskUserQuestion (User Interaction Question)Nodes are connected with lines to form complete automation chains. After design, users can directly export the workflow as a .claude file, which can be seamlessly executed by the Claude Code CLI. The tool also supports AI-assisted editing: users can describe their needs in natural language (e.g., \"add a validation step\" or \"split long text\"), and the system will automatically adjust the workflow structure.Typical Application ScenariosThis visual approach is particularly suitable for building repetitive or multi-step AI tasks, such as:- Automated document summary bot: extract content from input files, generate summaries, and output reports.- Code analysis and repair workflow: read code, identify issues, suggest fixes, and apply them.- Web scraping automation: access pages, extract specified content, process data, and report results.For beginners, this drag-and-drop plus chat interaction greatly improves intuitiveness and convenience, enabling powerful automation without deep terminal operations.Community Feedback and Ecosystem ImpactThis extension was developed by community developers and has been launched on GitHub and the VSCode Marketplace, quickly receiving positive feedback from developers. Users reported that it solves the \"prompt confusion\" issue in complex workflows with Claude Code, making AI agent collaboration more structured and visual. Combined with Claude Code's native support for sub-agents, skills, and MCP, this tool further unleashes its potential in the agentic workflow field.Meanwhile, similar visual GUI tools (such as Claudia and Claude Code UI) have also emerged in the domestic community, further enriching the ecosystem choices.The emergence of Claude Code Workflow Studio signals that AI programming tools are transitioning from \"exclusive to command-line experts\" to \"accessible to everyone.\" Drag-and-drop design combined with AI intelligent editing not only accelerates the construction of automation processes but also opens the door to Claude Code for non-coders. In the future, as more visual extensions emerge, AI agent workflows will become easier to manage and more efficient. AIbase will continue to monitor the dynamics of the Claude Code ecosystem and bring readers the latest cutting-edge information.Project Address: https://github.com/breaking-brake/cc-wf-studio/",
      "article_url": "https://www.aibase.com/news/24128",
      "author": "AIbase",
      "publish_time": 1767136636,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"ClaudeCode\", \"VSCode Extension Tool\", \"AI Automation Workflow\", \"No-Code\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://github.com/breaking-brake/cc-wf-studio/\", \"url\": \"https://github.com/breaking-brake/cc-wf-studio/\", \"type\": \"code\"}]",
      "add_ts": 1767136636,
      "last_modify_ts": 1767136636
    },
    {
      "id": 24,
      "article_id": "aibase_24110",
      "title": "Microsoft Copilot Upgrades to GPT-5.2, Free Access to a New Era of Expert-Level Workflows",
      "description": "| Microsoft has officially rolled out the most powerful model series from OpenAI to date, GPT-5.2, to web, Windows, and mobile users. As a sincere free upgrade,",
      "content": "| Microsoft has officially rolled out the most powerful model series from OpenAI to date, GPT-5.2, to web, Windows, and mobile users. As a sincere free upgrade, GPT-5.2 will coexist with the existing GPT-5.1 model in \"intelligent enhancement\" mode, marking the official entry of Copilot into the era of deep logical reasoning. This so-called \"expert-level\" model not only completes practical tasks such as building spreadsheets, writing review code, and understanding long documents faster, but also shows unprecedented maturity in handling complex tool calls and image analysis.From a performance perspective, the leap brought by GPT-5.2 is not only reflected in speed but also in its ability to think deeply. Microsoft clearly stated that the GPT-5.2Plus version on Copilot is essentially a \"thinking\" variant of GPT-5.2. In a benchmark test covering 44 occupational knowledge work tasks, GPT-5.2Thinking outperformed or matched industry professionals in 70.9% of cases, while GPT-5 achieved this rate of 38.8%. This almost doubling improvement allows OpenAI to confidently position this model as a top expert for handling presentations, schedules, and various professional deliverables, setting a new industry ceiling for office automation.In hard-core technical benchmark tests, GPT-5.2 also demonstrated its dominance. In the programming field, it set new records on SWE-Bench Pro and SWE-bench Verified, significantly surpassing GPT-5.1Thinking. In the most challenging logic and science tests, the model scored 92.4% on the GPQA Diamond test and achieved a perfect score of 100% on the AIME2025 math test.Additionally, its significant improvements in CharXiv reasoning and ARC-AGI-2 tests confirm that Microsoft is evolving Copilot from a basic assistant into a digital intelligent entity with a rigorous logical system through technological iterations, thus maintaining a leading advantage in the fierce AI competition.",
      "article_url": "https://www.aibase.com/news/24110",
      "author": "AIbase",
      "publish_time": 1767136649,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"GPT-5.2\", \"Microsoft\", \"OpenAI\", \"Copilot\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767136649,
      "last_modify_ts": 1767136649
    },
    {
      "id": 25,
      "article_id": "aibase_24106",
      "title": "OpenAI Updates Mobile Version of ChatGPT, Allowing Users to Adjust AI's Thinking Depth",
      "description": "OpenAI has made significant updates to its ChatGPT apps for Android and iOS, adding a \"Thinking Duration\" adjustment feature. According to the tech media bleepi",
      "content": "OpenAI has made significant updates to its ChatGPT apps for Android and iOS, adding a \"Thinking Duration\" adjustment feature. According to the tech media bleepingcomputer, this update allows mobile users to flexibly choose the depth of AI thinking to better meet different needs.In previous versions, the thinking function on Android was locked in \"Standard\" mode, which responded quickly but was limited by computing power when performing complex reasoning, making it difficult to provide in-depth analysis. This update enables mobile users to experience the same efficient service as desktop users, allowing them to switch between \"Standard Thinking\" and \"Extended Thinking\" modes according to their needs.\"Standard Thinking\" is mainly used for quickly answering daily questions and is suitable for handling simple queries. \"Extended Thinking,\" on the other hand, is metaphorically described as having stronger \"computing power.\" In this mode, the model can spend more time on logical reasoning, thus providing more accurate answers when dealing with complex mathematical, programming, or logical analysis problems.It is worth noting that this new feature is currently only available to ChatGPT Plus subscribers, while Go subscribers are temporarily unable to use it. In addition, OpenAI also restructured the desktop version in this update, introducing the \"Formatted Module\" feature. This feature aims to improve the problem of previously single-format model output. For example, when users request to write an email, the new version will be able to automatically identify the task type, adjust the user interface layout, making it more like a professional email client, thereby enhancing the intuitiveness and convenience of the user experience.Key Points: ✨ This update allows mobile users to manually adjust the depth of AI thinking, enhancing the interactive experience. 🧠 \"Standard Thinking\" is suitable for simple questions, while \"Extended Thinking\" provides deep reasoning to solve complex problems. 📱 The new feature is currently only available to ChatGPT Plus subscribers, and the desktop version has also been optimized in terms of interface.",
      "article_url": "https://www.aibase.com/news/24106",
      "author": "AIbase",
      "publish_time": 1767136652,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"ChatGPT\", \"OpenAI\", \"StandardThinking\", \"ExpandedThinking\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767136652,
      "last_modify_ts": 1767136652
    },
    {
      "id": 26,
      "article_id": "aibase_24167",
      "title": "Tencent Shocks the Market! 10 Billion Parameter Text-to-3D Motion Generator Open-Sourced, Making Game NPCs Come to Life in One Click!",
      "description": "On December 30, 2025, the Tencent Hunyuan team officially open-sourced HY-Motion 1.0 (Hunyuan-Motion-1.0), a large-scale text-to-3D motion generation model with",
      "content": "On December 30, 2025, the Tencent Hunyuan team officially open-sourced HY-Motion 1.0 (Hunyuan-Motion-1.0), a large-scale text-to-3D motion generation model with ten billion parameters. Based on the Diffusion Transformer (DiT) architecture and flow matching mechanism, this model can generate high-fidelity, smooth, and diverse 3D character skeleton animations with just one natural language description. It directly supports mainstream 3D tools such as Blender, Unity, and UE, significantly lowering the barrier to animation production.Key Technical Highlights HY-Motion 1.0 adopts a full-stage training strategy: first pre-training on over 3,000 hours of diverse motion data to build general motion priors; then fine-tuning on 400 hours of high-quality selected data to improve detail smoothness; finally, optimizing physical plausibility and semantic alignment through reinforcement learning (RLHF) combined with human feedback and reward models. The model covers six major categories with over 200 types of motions, including basic movements, sports competitions, fitness and outdoor activities, social leisure, daily activities, and game character actions (such as sword blocking and zombie walking). The output is in SMPL-H skeleton format, supporting atomic actions, composite sequences, and concurrent actions.Outstanding Test Performance Community tests show that the model has a high level of accuracy in daily scenarios: for prompts like \"running,\" \"sitting on a chair,\" and \"jumping twice with both legs,\" the generated motions are natural and continuous. Complex motions, such as crouching during the bullet time scene from \"The Matrix,\" can also be accurately reproduced with smooth postures. In performance evaluation, the model achieved an instruction following capability of 78.6% (SSAE metric), with an average action quality of 3.43 out of 5, surpassing open-source baselines such as MoMask and DART, especially in complex instructions and multi-category coverage. Extreme challenges: the recreation of professional athlete movements (such as ski jumping, diving, and BMX cycling) is not ideal, and joint transitions occasionally appear unnatural. However, overall physical plausibility far exceeds previous versions.Great Potential in Game Animation Applications This end-to-end model is particularly suitable for game development: it can quickly generate NPC daily life actions (such as walking and interaction), significantly accelerating research and iteration. Although main character design requires later refinement, it can already be seamlessly imported into engines, helping to create MMORPGs and action games. Film storyboarding, advertisement positioning, and VR content creation will also benefit. The lightweight version HY-Motion-1.0-Lite (0.46B parameters) is also open-sourced, offering more friendly deployment.Project link: https://hunyuan.tencent.com/motion?tabIndex=0",
      "article_url": "https://www.aibase.com/news/24167",
      "author": "AIbase",
      "publish_time": 1767482265,
      "publish_date": "2026-01-04",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"HY-Motion1.0\", \"Tencent Huan Yuan\", \"DiffusionTransformer\", \"3D Motion Generation\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://hunyuan.tencent.com/motion?tabIndex=0\", \"url\": \"https://hunyuan.tencent.com/motion?tabIndex=0\", \"type\": \"external\"}]",
      "add_ts": 1767193264,
      "last_modify_ts": 1767482265
    },
    {
      "id": 31,
      "article_id": "aibase_24146",
      "title": "Tongyi Lab of Alibaba Launches MAI-UI: A Family of Basic GUI Intelligent Agents That Exceed Competitors",
      "description": "Alibaba Tongyi Lab recently released MAI-UI, a family of multi-modal general-purpose GUI intelligent agents. This system not only enables human-computer interac",
      "content": "Alibaba Tongyi Lab recently released MAI-UI, a family of multi-modal general-purpose GUI intelligent agents. This system not only enables human-computer interaction but also integrates MCP tool usage, device and cloud collaboration, and online reinforcement learning, achieving leading results in general GUI foundations and mobile GUI navigation, surpassing competitors such as Gemini2.5Pro, Seed1.8, and UI-Tars2.MAI-UI is built upon Qwen3VL, featuring models of different scales, including 2B, 8B, 32B, and 235B A22B. These models can receive natural language instructions and UI screenshots as input and output structured operations, supporting actions in real-time Android environments. These operations include clicking elements, swiping, entering text, and pressing system buttons. Additionally, MAI-UI introduces the ability to answer user questions, request clarification on ambiguous goals, and perform clear actions, while calling external tools via MCP tools, allowing the agent to mix GUI steps, direct language responses, and API-level operations within the same trajectory.On top of the GUI, MAI-UI ensures the robustness of its navigation capabilities through a self-evolving data pipeline and an online reinforcement learning framework. Tongyi Lab used seed tasks obtained from application manuals, design scenarios, and public data, executed by multiple agents and human annotators, to generate task trajectories and optimize navigation behavior.In the MobileWorld benchmark test, MAI-UI demonstrated its excellent performance with a success rate of 41.7%. In the AndroidWorld benchmark test, MAI-UI achieved a maximum variant success rate of 76.7%, surpassing other similar products.The release of MAI-UI marks significant progress in GUI intelligent agent technology in the mobile application field, making smart devices more efficient and intelligent when handling complex operations.github:https://github.com/Tongyi-MAI/MAI-UIKey Points: 🌟 MAI-UI is a family of GUI intelligent agents introduced by Alibaba Tongyi Lab, integrating multiple advanced technologies. 📱 MAI-UI supports various operations and can perform complex user interactions in real-time Android environments. 🚀 MAI-UI's performance significantly surpasses competitors in benchmark tests such as MobileWorld and AndroidWorld.",
      "article_url": "https://www.aibase.com/news/24146",
      "author": "AIbase",
      "publish_time": 1767482281,
      "publish_date": "2026-01-04",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"MAI-UI\", \"Qwen3VL\", \"Tongyi Lab of Alibaba\", \"Multimodal Basic GUI Intelligent Agent\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://github.com/Tongyi-MAI/MAI-UIKey\", \"url\": \"https://github.com/Tongyi-MAI/MAI-UIKey\", \"type\": \"code\"}]",
      "add_ts": 1767193295,
      "last_modify_ts": 1767482281
    },
    {
      "id": 32,
      "article_id": "aibase_24169",
      "title": "Qwen AI Glasses First OTA Update: AI Capabilities Further Enhanced, Adds Five New Features Including Text and Image Notes",
      "description": "The Quark AI Glasses, equipped with the Qwen AI assistant, received their first OTA update on December 31st, further enhancing AI capabilities. Five new feature",
      "content": "The Quark AI Glasses, equipped with the Qwen AI assistant, received their first OTA update on December 31st, further enhancing AI capabilities. Five new features were added: audio notes, image and text memos, multi-intent understanding and execution by large models, Blue Ring payments, and community services. Additionally, popular functions such as translation, itinerary inquiry, and music playback have been optimized based on user feedback.In the audio recording scenario, the upgraded Quark AI Glasses support sound pickup within a range of ten meters, with effective noise reduction, using the self-developed Quark Audio voice enhancement model and the original five-microphone array plus bone conduction hardware configuration. Moreover, the glasses can accurately identify different speakers and use AI to extract key points from the recorded content, automatically generating to-do lists. This function currently supports transcription and translation for four languages: Chinese, English, Japanese, and Korean.In the memo scenario, the Quark AI Glasses support both photo and voice-based memo usage. For instance, when standing in front of a parking spot, simply say \"Qwen, help me note the parking spot,\" and the glasses will take a photo of the parking spot and record it. More intelligently, the system has AI classification and semantic understanding capabilities. When the user asks, \"What furniture have I wanted to buy in the past month?\" the glasses will automatically retrieve historical records and summarize the response.Another highlight of this update is the support for multi-intent understanding and execution by the large model. Most AI glasses typically handle only single instructions, but the Quark AI Glasses now support understanding and executing two to three compound tasks. For example, \"Navigate to the company, play some music I like,\" or \"I need to go to a conference tomorrow at 8 AM and catch a flight at 9 AM, remember to remind me.\" The Quark AI Glasses can understand these requests and coordinate multiple services such as maps, music, and calendars, improving efficiency and convenience in work and daily life.The on-the-go translation feature has also been upgraded, supporting translation into 89 languages, including major languages such as English, Japanese, Korean, French, and German, as well as less common languages from various countries and regions, meeting different needs for cross-border travel and business communication.This OTA update was pushed through the Quark AI Glasses app, and users can click to complete the upgrade. The app also launched a user exchange community, where users can learn about product information, share usage tips and experiences, and participate in official photography, gameplay, and creation contests.As an important business direction of Alibaba's Qwen C-end division, the Quark AI Glasses have already released two series—S1 and G1—with six SKUs. The Qwen AI assistant, which serves as the core entry point, is accelerating its expansion to multiple terminals such as glasses, PCs, and cars.",
      "article_url": "https://www.aibase.com/news/24169",
      "author": "AIbase",
      "publish_time": 1767482262,
      "publish_date": "2026-01-04",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Qwen AI Assistant\", \"Qwen AI Glasses\", \"AI New Words\", \"Brand Product Terms\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767223077,
      "last_modify_ts": 1767482262
    },
    {
      "id": 34,
      "article_id": "aibase_24159",
      "title": "JD.com Officially Launches Self-Operated Rental Service, Million-Level Humanoid Robots Within Reach",
      "description": "On December 31st, the world's first offline store co-established by JD.com and Unitree opened grandly at JD MALL (Beijing Shuangjing Store). This not only marks",
      "content": "On December 31st, the world's first offline store co-established by JD.com and Unitree opened grandly at JD MALL (Beijing Shuangjing Store). This not only marks the official transition of top-tier embodied intelligence products from online to omnichannel retail, but also represents a key step in bringing robots into everyday life.\"Rent instead of buy\" new model: lower experience thresholdAt the opening event, the person in charge of JD's robot business with embodied intelligence revealed that JD has officially launched its own robot rental service. Users can now experience cutting-edge technology including quadrupedal robot dogs and humanoid robots at lower prices and with more flexible rental periods (such as daily or long-term rentals). This move aims to address the pain points of high single-unit prices and difficulty for the general public to get started with humanoid robots, making embodied intelligence technology truly serve ordinary consumers.Scenario-based experience: Robots enter thousands of householdsAs JD's offline super experience center, JD MALL has opened 27 stores nationwide, with each store covering an area of 30,000 to 80,000 square meters. According to the person in charge, JD is continuously expanding offline application scenarios. Consumers can immerse themselves in real environments within the store to experience the practical applications of robots in diverse scenarios such as home assistance, educational companionship, health care, and cultural entertainment.Strong cooperation: Accelerate commercialization",
      "article_url": "https://www.aibase.com/news/24159",
      "author": "AIbase",
      "publish_time": 1767482270,
      "publish_date": "2026-01-04",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"JD.com\", \"YushuTechnology\", \"Robots\", \"LeasingServices\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767223085,
      "last_modify_ts": 1767482270
    },
    {
      "id": 36,
      "article_id": "aibase_24157",
      "title": "Luo Yonghao Launches AI Book Reading App Qie Ting: In-depth Book Analysis in 1-2 Hours for Less Than 40 Yuan Annually",
      "description": "&nbsp;At the \"Annual Technology Innovation Sharing Conference\" held last night, Luo Yonghao announced that his startup \"Thin Red Line\" has officially launched i",
      "content": "At the \"Annual Technology Innovation Sharing Conference\" held last night, Luo Yonghao announced that his startup \"Thin Red Line\" has officially launched its self-developed AI product - \"Qie Ting\". This product is positioned as a deep voice library for the AI era and is now available on all major app stores.\"Qie Ting\" relies on natural language processing (NLP) and knowledge graph technology to structure books. Its core selling point is **\"Deep Explanation\"**: each book is explained for 1-2 hours, with over ten thousand words, aiming to extract core ideas for users, suitable for fragmented deep learning scenarios such as driving commutes.At the press conference, Luo Yonghao demonstrated the product's voice customization feature, successfully generating a personalized voice model by uploading the voice of stand-up comedian Niao Niao.Currently, \"Qie Ting\" has integrated multiple category lists including Douban Top 250, covering disciplines such as literature, economics, and psychology, trying to solve the user's \"book selection difficulty\" pain point. In terms of pricing, the product adopts a highly competitive low-price strategy: 9.9 yuan per month, and only 37.8 yuan per year. In addition, new users who register will receive a 7-day membership, and there is also a friend invitation incentive mechanism.As an initial exploration of Thin Red Line in the AI content field, \"Qie Ting\" has also attracted industry attention after the on-site demonstration. Although the technical performance is impressive, the product still needs further market validation and official responses regarding core issues such as book copyright compliance, extension of practical application scenarios, and long-term user acceptance of this \"AI-explained\" reading mode.",
      "article_url": "https://www.aibase.com/news/24157",
      "author": "AIbase",
      "publish_time": 1767482275,
      "publish_date": "2026-01-04",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AI New Terms\", \"Qie Ting\", \"Natural Language Processing\", \"Brand Product Terms\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767223091,
      "last_modify_ts": 1767482275
    },
    {
      "id": 38,
      "article_id": "aibase_24212",
      "title": "Tsinghua University and OpenBMB Jointly Launch UltraEval-Audio: Open-Source Audio Model Evaluation Framework",
      "description": "Recently, the NLP Lab at Tsinghua University, OpenBMB, and Miga Intelligence jointly released and open-sourced UltraEval-Audio, a evaluation framework specifica",
      "content": "Recently, the NLP Lab at Tsinghua University, OpenBMB, and Miga Intelligence jointly released and open-sourced UltraEval-Audio, a evaluation framework specifically designed for audio models. UltraEval-Audio not only establishes a complete set of evaluation methodologies for the field of audio large models, but also concretizes this system into an out-of-the-box engineering framework, thereby completing the overall structure of audio evaluation.The latest version of UltraEval-Audio, v1.1.0, adds the capability to reproduce popular audio models with one click based on the existing \"one-click evaluation\" function, and expands support for specialized models such as Text-to-Speech (TTS), Automatic Speech Recognition (ASR), and Codec. In addition, this version introduces an isolated inference operation mechanism, aiming to lower the threshold for model reproduction and improve the controllability and portability of the evaluation process.Notably, UltraEval-Audio v1.1.0 has become an essential evaluation tool for many high-impact audio and multimodal models such as MiniCPM-o2.6 and VoxCPM. The open-source release of this framework will significantly improve the efficiency of researchers in the development of audio models and promote progress in the relevant fields.The open-source address is also public, and researchers can obtain more information through GitHub. The release of UltraEval-Audio marks an important step forward in the standardization of audio model evaluation, helping to accelerate the development of audio technology.Open source address:https://github.com/OpenBMB/UltraEval-AudioKey points: 🌟 UltraEval-Audio is an evaluation framework for audio models, jointly released by the NLP Lab at Tsinghua University, OpenBMB, and Miga Intelligence. 🚀 The latest version v1.1.0 adds the one-click reproduction function and supports the evaluation of more specialized models. 📈 The open-source release will significantly improve the development efficiency of researchers and promote progress in the field of audio models.",
      "article_url": "https://www.aibase.com/news/24212",
      "author": "AIbase",
      "publish_time": 1767568692,
      "publish_date": "2026-01-05",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"UltraEval-Audio\", \"Audio Models\", \"OpenBMB\", \"Mianbi Intelligence\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://github.com/OpenBMB/UltraEval-AudioKey\", \"url\": \"https://github.com/OpenBMB/UltraEval-AudioKey\", \"type\": \"code\"}]",
      "add_ts": 1767568692,
      "last_modify_ts": 1767568692
    },
    {
      "id": 40,
      "article_id": "aibase_24202",
      "title": "Yuanxiang Open Sources XVERSE-Ent Large Model! Focused on General Entertainment Scenarios, Bilingual Support, Filling the Gap in Industry-Specific Models",
      "description": "The domestic large model ecosystem has added a major new member. Xunzhang Technology (XVERSE) officially open-sourced its foundation large model for the general",
      "content": "The domestic large model ecosystem has added a major new member. Xunzhang Technology (XVERSE) officially open-sourced its foundation large model for the general entertainment field, XVERSE-Ent, along with Chinese and English versions. This model is deeply optimized for core scenarios in general entertainment, such as social interaction, game storytelling, and cultural creation (including novels, scripts, short video scripts, etc.), supporting lightweight deployment and rapid vertical field implementation. It becomes the first dedicated open-source large model for the general entertainment industry in China, filling the gap in high-quality foundational models in this field. Designed for \"fun, useful, and collaborative\"Differing from general large models that pursue broad knowledge coverage, XVERSE-Ent builds around the core needs of general entertainment users, from training data, instruction fine-tuning to evaluation systems:- Social Interaction: excels at generating natural, interesting, emotionally charged dialogues, suitable for virtual characters, AI chat companions, and community content generation;- Game Storytelling: can automatically generate mission plots, NPC dialogues, and world settings, supporting dynamic story engines with multiple branches and endings;- Cultural Creation: possesses strong coherence, style imitation, and rhythm control capabilities in long-text creation such as novels, scripts, and anime scripts.The model integrates a large amount of Chinese online literature, script libraries, game dialogues, and multilingual film and television texts during training, ensuring the content aligns with local cultural contexts while possessing international expression capabilities. Lightweight + Open Source, Lowering the Barriers for General Entertainment AIXVERSE-Ent emphasizes deployment friendliness and ecological openness:- Provides multiple parameter versions such as 7B and 13B, which can run on consumer-level GPUs or edge devices;- Uses a commercially friendly open-source license, allowing developers to use it free of charge for commercial products;- Offers open scenario-based fine-tuning templates and evaluation toolkits, helping game companies, content platforms, and creators quickly integrate them.Xunzhang stated that the goal of XVERSE-Ent is to become the \"AI content engine\" for the general entertainment industry, enabling small teams to have intelligent generation capabilities comparable to leading manufacturers. AIbase Observation: The Era of \"Scenario-Specific\" Large Models Has BegunAfter vertical large models emerged in fields such as finance, healthcare, programming, and education, the general entertainment sector—a global industry exceeding $1 trillion—has finally welcomed its own AI foundation. The release of XVERSE-Ent marks that domestic large models are shifting from \"large and comprehensive\" to \"specialized and refined,\" replacing parameter scale with scenario depth, becoming a new competitive focus.",
      "article_url": "https://www.aibase.com/news/24202",
      "author": "AIbase",
      "publish_time": 1767568697,
      "publish_date": "2026-01-05",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"XVERSE-Ent\", \"Domestic Large Model\", \"General Entertainment\", \"Open Source\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767568697,
      "last_modify_ts": 1767568697
    },
    {
      "id": 42,
      "article_id": "aibase_24199",
      "title": "New King of AI Glasses Emerges! The Soul Computer Pickle 1 Can Remember Everything in Your Life",
      "description": "In early 2026, the wearable AI device market welcomed a major new product. The US-based startup Pickle launched its first product, Pickle1, an intelligent glass",
      "content": "In early 2026, the wearable AI device market welcomed a major new product. The US-based startup Pickle launched its first product, Pickle1, an intelligent glasses that combines AR display with advanced AI, officially positioned as the \"Soul Computer.\" This device captures users' visual and audio context continuously, achieving infinite memory, emotional understanding, and proactive interaction, quickly sparking global tech discussions.Core Concept: Your \"Second Brain\" Living Alongside YouThe core of Pickle1 lies in its Pickle OS operating system. Unlike the passive response mode of traditional smart glasses, this system actively learns users' daily habits, transforming everyday experiences into searchable \"memory bubbles,\" forming a single memory cluster.- Infinite Memory Function: The glasses use built-in cameras, microphones, and sensors to record everything users see and hear in real time, intelligently organizing the context. Users can recall past moments anytime, such as names mentioned in meetings or details from conversations months ago.- Proactive Understanding and Prediction: The AI doesn't wait for instructions but can anticipate needs in advance, offering real-time reminders, suggestions, or automated actions, such as automatically booking travel, sending messages, or suggesting purchases.- Emotional Growth Together: The system emphasizes \"growing together with the user,\" gradually personalizing through long-term wear (recommended at least 3 hours per day, over 50 visual interactions), understanding users' thoughts and preferences.Hardware Highlights: Lightweight and Comfortable, All-Day AR ExperiencePickle1 features a lightweight design, with a 68-gram aluminum frame, available in silver and black, ensuring all-day comfort.- Dual-Eye Full Color AR Display: It uses the world's most advanced waveguide technology, providing the widest field of view for full-color display among standalone AR glasses, clear even in sunlight.- Qualcomm Snapdragon AI Engine: Achieves ultra-low latency computing, supporting smooth AR rendering and AI conversations.- Battery Life and Interaction: A dual-battery design offers up to 12 hours of battery life when used together; it includes spatial audio speakers, high-definition microphones, and fingerprint unlocking for privacy security.Privacy and Ecosystem: Local-First, Strict ProtectionFacing the controversy of \"always recording,\" Pickle emphasizes local data processing, using hardware-isolated encryption, storing only necessary context temporarily. Third-party app data is not used for training, and users can fully control privacy settings via the Pickle OS App. Additionally, the system supports generating photorealistic AI avatars for video calls and other scenarios.Pre-order and OutlookPickle1 is now open for pre-order, with an early bird price of $799 (requires a $200 non-refundable deposit). The regular price is approximately $1300. The US region is expected to start shipping in the second quarter of 2026, with international deliveries following later.AIbase Perspective: In today's competitive landscape of AI wearable devices, Pickle1 centers around \"memory-driven\" technology, challenging the passive models of products like Meta Ray-Ban, pushing wearable AI from tools to \"companions.\" Although technical implementation and privacy issues still need time to verify, its bold vision undoubtedly brings new vitality to the industry. In the future, similar devices may reshape how humans interact with AI, making \"never forgetting\" a reality.Official Website: https://www.pickle.com/",
      "article_url": "https://www.aibase.com/news/24199",
      "author": "AIbase",
      "publish_time": 1767568703,
      "publish_date": "2026-01-05",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Wearable AI Devices\", \"Pickle1\", \"PickleOS\", \"Soul Computer\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://www.pickle.com/\", \"url\": \"https://www.pickle.com/\", \"type\": \"external\"}]",
      "add_ts": 1767568703,
      "last_modify_ts": 1767568703
    },
    {
      "id": 45,
      "article_id": "aibase_24190",
      "title": "ByteDance Launches StoryMem: Equipping AI Videos with Long-Term Memory, Completely Solving the Problem of Character Consistency",
      "description": "Concerned with the long-standing issues of \"character distortion\" and \"environmental flickering\" in the AI video generation field, ByteDance and the Nanyang Tec",
      "content": "Concerned with the long-standing issues of \"character distortion\" and \"environmental flickering\" in the AI video generation field, ByteDance and the Nanyang Technological University research team recently jointly launched an innovative system called StoryMem. This system successfully achieves high consistency in long video cross-scene creation by introducing a mechanism similar to human memory, solving the visual bias problems that models like Sora and Kling often encounter during multi-shot storytelling.The core logic of StoryMem lies in its unique \"hybrid memory bank\" design. Researchers pointed out that forcing all scenes into a single model leads to a sharp increase in computational costs, while segmental generation causes loss of context. To address this, StoryMem selectively stores key frames from previous scenes as references. The algorithm uses dual filters, first selecting visual core frames through semantic analysis, then eliminating blurry images through quality checks. When generating new scenes, these key frames are input into the model along with a technique called RoPE (Rotary Position Embedding). By assigning memory frames \"negative time indices,\" the system guides AI to recognize them as \"past events,\" ensuring character images and background details remain stable throughout the story progression.Notably, StoryMem's implementation is highly efficient. It runs on the LoRa version of Alibaba's open-source model Wan2.2-I2V, adding only about 7 billion parameters to a base model with 140 billion parameters, significantly lowering the training threshold. In the ST-Bench benchmark test containing 300 scene descriptions, StoryMem improved cross-scene consistency by 28.7% compared to the base model and outperformed existing cutting-edge technologies such as HoloCine in aesthetic scores and user preferences.In addition, the system demonstrates high practical value, supporting users to upload custom photos as \"memory start points\" to generate coherent stories and enabling smoother scene transitions. Although there are still limitations in handling multiple characters simultaneously and large-scale action transitions, the team has already released weight data on Hugging Face and launched a project page for developers to explore.Address: https://kevin-thu.github.io/StoryMem/https://huggingface.co/Kevin-thu/StoryMem",
      "article_url": "https://www.aibase.com/news/24190",
      "author": "AIbase",
      "publish_time": 1767568719,
      "publish_date": "2026-01-05",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AI New Term\", \"StoryMem\", \"ByteDance\", \"Nanyang Technological University\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://kevin-thu.github.io/StoryMem/https://huggingface.co/Kevin-thu/StoryMem\", \"url\": \"https://kevin-thu.github.io/StoryMem/https://huggingface.co/Kevin-thu/StoryMem\", \"type\": \"code\"}]",
      "add_ts": 1767568719,
      "last_modify_ts": 1767568719
    },
    {
      "id": 47,
      "article_id": "aibase_24259",
      "title": "Google Tests Nano Banana2Flash Image Model, Focused on Extreme Speed and High Cost-Effectiveness",
      "description": "After releasing the high-end image model Nano Banana Pro, Google is secretly testing a new member of its Gemini Flash series - Nano Banana2Flash. The model was ",
      "content": "After releasing the high-end image model Nano Banana Pro, Google is secretly testing a new member of its Gemini Flash series - Nano Banana2Flash. The model was first exposed by the well-known tech blogger MarsForTech on X, and it is currently Google's fastest generative AI image model, aiming to provide users with a more affordable and efficient visual generation experience.Although Nano Banana2Flash does not match the performance ceiling of the high-end Nano Banana Pro in terms of reasoning depth, detail accuracy, and handling extremely complex creative tasks (such as precise prototypes or high-precision charts), it inherits the Pro version's understanding of real-world knowledge and significantly optimizes the generation logic.Currently, Nano Banana Pro remains Google's flagship model for handling high-difficulty creative work, excelling at converting text into visual effects with deep semantic understanding. The introduction of the new Nano Banana2Flash fills a market gap for those pursuing extreme response speed. With faster processing speed and more competitive pricing, this model is expected to shine in areas such as real-time interaction, rapid iteration of design sketches, and social media content generation.As testing continues, Google is using this \"high and low\" model matrix to further lower the barrier for the general public to access cutting-edge AI image technology while ensuring professional-level accuracy.",
      "article_url": "https://www.aibase.com/news/24259",
      "author": "AIbase",
      "publish_time": 1767655130,
      "publish_date": "2026-01-06",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AI New Terms\", \"Brand Product Terms\", \"Generative AI\", \"Image Model\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767655130,
      "last_modify_ts": 1767655130
    },
    {
      "id": 48,
      "article_id": "aibase_24258",
      "title": "AI Assistant ima Launches New PPT Generation Feature to Help Users Work Efficiently",
      "description": "At the beginning of the new year, the AI assistant \"ima\" has launched a major update, officially introducing a new PPT generation feature that responds to user ",
      "content": "At the beginning of the new year, the AI assistant \"ima\" has launched a major update, officially introducing a new PPT generation feature that responds to user demand. This feature aims to help users improve their work efficiency and reduce stress when facing urgent tasks such as annual summaries and end-of-term reports.In the past year, many users have provided suggestions for \"ima,\" especially regarding the need for PPT generation. Many people said that creating a beautiful PPT often made them feel \"headache-inducing\" in a busy work environment. To meet this demand, the ima team accelerated the development of the feature and finally realized this wish in version 2.1.3.\"Ima\" can now intelligently convert user-provided materials into PPTs, not only generating charts but also adding appropriate icons and highlighting key content. Users simply need to input their materials, and the system will automatically generate a PPT that meets their needs, greatly reducing the time and effort required for manual creation.According to the official introduction, users can adjust the style of the PPT according to their needs when using the new feature, achieving personalized customization. This flexibility allows \"ima\" to adapt to different scenarios, whether it's an academic presentation, a business summary, or a commercial proposal, all of which can be handled easily.\"We have always been listening to our users, and the launch of the PPT generation capability is a positive response to user feedback,\" said the ima team. They hope that with this update, they can help users complete tasks more efficiently in a fast-paced work environment. The release of this new feature also marks an important step forward for \"ima\" in the field of smart office solutions.In terms of user experience, ima also encourages users to provide feedback on their usage experiences to further improve and optimize the product. To help more users learn about the new feature immediately, the team also recommends that users set \"ima\" as a favorite so they can access the latest information anytime.",
      "article_url": "https://www.aibase.com/news/24258",
      "author": "AIbase",
      "publish_time": 1767655132,
      "publish_date": "2026-01-06",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AIneologisms\", \"PPTgeneration\", \"ima\", \"brandproductterms\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767655132,
      "last_modify_ts": 1767655132
    },
    {
      "id": 49,
      "article_id": "aibase_24255",
      "title": "China Telecom Opensources the National Large-Scale MoE Model TeleChat3! Full-Stack Self-R&D, Trained on 15T Tokens, Supports Thinking Mode to Compete with International Top-Level Models",
      "description": "China's large-scale models have achieved another major breakthrough. China Telecom's Artificial Intelligence Research Institute (TeleAI) has recently officially",
      "content": "China's large-scale models have achieved another major breakthrough. China Telecom's Artificial Intelligence Research Institute (TeleAI) has recently officially open-sourced the Star Semantic Large Model TeleChat3 series, which includes the first domestic large-scale parameter fine-grained MoE model based on fully indigenous computing power in China — TeleChat3-105B-A4.7B-Thinking, as well as a dense architecture model TeleChat3-36B-Thinking. The entire series of models were trained using the fully indigenous computing pool in Shanghai Lingang, with a basic training data of 150 trillion tokens, marking a key step forward in China's autonomous control over ultra-large-scale AI models. Full Domestication: Full-Stack Compatibility from Chips to FrameworksThe TeleChat3 series is deeply compatible with the Huawei Ascend ecosystem:- Supports the Ascend Atlas800T A2 training server;- Developed based on the MindSpore framework;- The entire training and inference process runs on domestic AI computing infrastructure.This move not only verifies the capability of domestic software and hardware stacks to support billion-parameter large models, but also provides the industry with a secure, reliable, and alternative technical path, which has strategic significance for ensuring the security of AI infrastructure supply chains. Innovative \"Thinking Mode\": Making AI Reasoning Process TraceableThe TeleChat3 series introduces a \"Thinking (Thought) Mode\" mechanism — by adding specific guiding symbols in the dialogue template, the model can automatically generate intermediate reasoning steps, significantly improving logic and accuracy in complex tasks. In six core dimensions — knowledge questions, mathematical reasoning, content creation, code generation, and intelligent agents (Agents), its performance is comparable to leading international models.For example, in solving math problems, the model no longer just outputs the answer, but shows the complete thought chain — \"understanding the question → breaking down the steps → applying formulas → verifying the result\", greatly enhancing credibility and debuggability. Open Source and Open, Empowering the Industrial EcosystemCurrently, the model weights, inference code, and usage examples of the TeleChat3 series have been synchronized to GitHub and ModelScope platforms, supporting academic research and commercial applications. China Telecom stated that it will continue to promote the deployment of the model in key areas such as government affairs, communications, energy, and finance, helping the \"Artificial Intelligence +\" initiative deeply penetrate the core of industries. AIbase Observation: Domestic Large Models Enter a New Stage of \"Full-Stack Self-R&D + Capability Benchmarking\"The release of TeleChat3 is not only a display of technological achievements, but also a substantial implementation of China's AI industry self-reliance strategy. When a billion-parameter MoE model can be efficiently trained on purely domestic computing power, and when the \"Thinking Mode\" approaches international advanced levels, domestic large models are moving from \"usable\" to \"good to use\" and even \"trustworthy to use.\"Against the backdrop of increasingly \"geopolitical\" global AI competition, China Telecom, with TeleAI as a lever, is building a secure, open, and high-performance domestic AI technology stack. Whether this path succeeds or fails may determine China's voice in the future intelligent era.Project Address: https://github.com/Tele-AI/TeleChat3",
      "article_url": "https://www.aibase.com/news/24255",
      "author": "AIbase",
      "publish_time": 1767655135,
      "publish_date": "2026-01-06",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"National Large Model\", \"TeleChat3\", \"Ascend Ecosystem\", \"AI Open Source\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://github.com/Tele-AI/TeleChat3\", \"url\": \"https://github.com/Tele-AI/TeleChat3\", \"type\": \"code\"}]",
      "add_ts": 1767655135,
      "last_modify_ts": 1767655135
    },
    {
      "id": 50,
      "article_id": "aibase_24253",
      "title": "Zhixuan Robotics Collaborates with MiniMax! Jointly Promoting Full-Chain AI Technology for Embodied Intelligence Speech Interaction and Text-to-Speech in Humanoid Robots",
      "description": "Embodied intelligence and large models are further integrated. Zhiyuan Robotics recently announced a strategic cooperation with MiniMax (Shanghai Xiyu Technolog",
      "content": "Embodied intelligence and large models are further integrated. Zhiyuan Robotics recently announced a strategic cooperation with MiniMax (Shanghai Xiyu Technology), under which MiniMax will provide end-to-end text-to-speech (TTS) for Zhiyuan's humanoid robots, significantly enhancing the robot's natural interaction capabilities and emotional expression in real-world scenarios. Full-Chain Voice Empowerment, Building \"Speaking\" Intelligent AgentsThis collaboration focuses on core voice synthesis technologies. MiniMax will deeply integrate its leading capabilities in high-naturalness voice generation, multi-emotion intonation modeling, and low-latency real-time inference into Zhiyuan Robotics' system. This means Zhiyuan's humanoid robots will be able to:- Communicate with near-human fluency and intonation;- Automatically switch between emotions such as joy, concern, and solemnity based on context;- Achieve low-latency, high-clarity voice output in complex noise environments, ensuring efficient human-machine communication.This technology will first be applied to Zhiyuan's robot products in scenarios such as home service, commercial tour guiding, and medical care, making AI not only \"visible and correct,\" but also \"accurate and warm.\" Strong Alliance: Large Model Companies × Embodied Intelligence PioneersMiniMax, a representative of the first-tier large model companies in China, has its MoE architecture large model and edge-side inference optimization capabilities widely applied in mobile phones, cars, and IoT devices. Zhiyuan Robotics, on the other hand, has made rapid breakthroughs in humanoid robot body control, motion planning, and scenario deployment. This collaboration marks the accelerating integration of the \"brain\" (large model).Industry analysis indicates that voice interaction is a key step for humanoid robots to become practical. When robots can communicate with people using natural and warm voices, user acceptance and trust will greatly increase, paving the way for large-scale commercialization. AIbase Observation: Voice Is No Longer an \"Additional Function,\" But the \"Soul Interface\" of Embodied IntelligenceIn the current competition among humanoid robots, most manufacturers focus on physical abilities such as walking and grasping. However, the collaboration between Zhiyuan and MiniMax highlights the importance of interaction experience. In the future, robots that truly enter homes and public places may not be the fastest, but the ones who can \"speak well\" and \"understand people best.\"",
      "article_url": "https://www.aibase.com/news/24253",
      "author": "AIbase",
      "publish_time": 1767655138,
      "publish_date": "2026-01-06",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Embodied Intelligence\", \"Large Models\", \"Zhixuan Robotics\", \"MiniMax\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767655138,
      "last_modify_ts": 1767655138
    },
    {
      "id": 53,
      "article_id": "aibase_24249",
      "title": "Gaode Ride-Hailing Launches AI Service Guardian! Minute-Level Abnormal Response, Four Cities Including Beijing and Shanghai Initially Cover Premium Car and Luxury Vehicle Orders",
      "description": "To enhance the safety and service experience of premium travel, Gaode Taxi recently announced a comprehensive upgrade to its \"Trip Guardian\" system, jointly lau",
      "content": "To enhance the safety and service experience of premium travel, Gaode Taxi recently announced a comprehensive upgrade to its \"Trip Guardian\" system, jointly launching the \"AI Service Defender\" with partner ride-hailing platforms. This feature uses minute-level intelligent anomaly detection and full-process automated intervention mechanisms to proactively protect high-value orders such as luxury cars, business vehicles, and private cars. It is now officially launched in four cities: Beijing, Shanghai, Hangzhou, and Chengdu. AI Real-Time Protection: From \"Post-Event Complaints\" to \"In-Process Intervention\"The \"AI Service Defender\" relies on Gaode's self-developed multimodal AI model to monitor and intelligently assess risky behaviors such as abnormal stops, detours, frequent sudden braking, and long periods of silence during the trip. Once the system identifies potential risks, it automatically triggers a graded response within minutes:- Mild anomalies: Send voice reminders to drivers to guide them in standardizing their service;- Moderate risks: Proactively call passengers to confirm their safety and notify platform customer service to intervene;- Severe incidents: Immediately coordinate with the police and partner platforms to activate emergency protocols.Compared to traditional passive models that rely on user-initiated complaints, the AI Service Defender shifts safety protection from \"post-event tracking\" to \"in-process intervention,\" significantly reducing response time and improving efficiency. Focusing on Premium Travel, Creating an \"Assured + Luxurious\" ExperienceThis new feature initially prioritizes orders for premium vehicles, business cars, and luxury cars, highlighting Gaode's emphasis on the safety and experience of high-net-worth users. Data shows that these types of orders typically have longer average trip durations and higher proportions of nighttime travel, with more stringent requirements for service reliability. The \"AI Service Defender\" provides \"invisible protection\" for passengers without disrupting normal trips through seamless technology. AIbase Observations: Ride-Hailing Platforms Enter the \"Proactive Safety\" EraWith the maturity of large models and edge computing technologies, the safety systems of ride-hailing platforms are shifting from \"rule-driven\" to \"intelligent-driven.\" Gaode's recent upgrade is not only a technological evolution but also a leap in service philosophy — true premium travel goes beyond luxurious vehicles, but also involves full-process control and peace of mind.",
      "article_url": "https://www.aibase.com/news/24249",
      "author": "AIbase",
      "publish_time": 1767655146,
      "publish_date": "2026-01-06",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AIServiceGuard\", \"GaodeTaxi\", \"AINeologism\", \"TripInsurance\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767655146,
      "last_modify_ts": 1767655146
    },
    {
      "id": 54,
      "article_id": "aibase_24235",
      "title": "ChatGPT Fully Integrated into 12 Major Popular Apps! Book Hotels, Order Takeout, Create PPTs with One Click - AI Assistant Turns into a Versatile Life Manager",
      "description": "OpenAI is upgrading ChatGPT from a \"chatbot\" to a real-world digital executor. Recently, the company officially launched the App Integrations feature for users ",
      "content": "OpenAI is upgrading ChatGPT from a \"chatbot\" to a real-world digital executor. Recently, the company officially launched the App Integrations feature for users in the United States and Canada, initially supporting 12 mainstream apps such as Booking.com, Canva, Coursera, DoorDash, Expedia, Figma, Spotify, Target, Uber, Uber Eats, and Zillow. Users can simply log in to their accounts within ChatGPT to directly call external services and complete real operations through natural language instructions, without having to switch apps. One sentence command, all daily services doneThrough deep integration, ChatGPT can achieve a closed-loop from \"saying\" to \"doing\":- Travel: Tell ChatGPT, \"Find a four-star hotel in Chicago next week with a budget of less than $200, including breakfast,\" and the system will automatically call Booking.com or Expedia, returning options that can be booked directly; - Dining: Enter \"Plan a two-person dinner, add ingredients to the DoorDash shopping cart\" or \"Find Thai food with a rating above 4.5 near you on Uber Eats,\" and complete selection and addition with one click; - Creation: Commands like \"Design a 16:9 Q4 product roadmap PPT using Canva, main colors blue and white, using the Source Han Sans font,\" and the AI will generate an editable design; - Learning: Request \"Find a medium-level Python course, compare the ratings, duration, and prices of three courses on Coursera,\" and quickly filter the best option; - Shopping: Enter \"Prepare a movie night gift set for a friend's birthday,\" and the Target integration will recommend popcorn, drinks, snack combinations, and add them to the shopping cart; - Real estate: Tell ChatGPT, \"Find a single-family home under $3 million, 4 bedrooms and 3 bathrooms, with good school districts in Seattle,\" and Zillow data will be displayed instantly; - Travel: Say \"Call an Uber to the airport,\" and the system will launch the Uber app to book a ride. Convenient operation, privacy controllableUsers can enable integrations in two ways:1. Mention the app name directly in the conversation (e.g., \"Create a running playlist on Spotify\"), and ChatGPT will guide you to log in;2. Authorize in bulk through \"Settings > Apps and Connectors.\"OpenAI emphasized that all connections require user approval and clearly list the scope of permissions (e.g., Spotify will access your playlists and listening history). Users can disconnect any app at any time in the settings to protect their data sovereignty. AI is not just a 'advisor,' but also an 'executor'This upgrade marks a fundamental shift in ChatGPT's role—from an information provider to a task executor. In the past, AI could tell you \"where there are good hotels\"; now, it can directly help you choose, compare, and book. This \"conversation-as-interface\" model is becoming the core paradigm of the next generation of human-computer interaction. Future expansion: OpenTable, PayPal, Walmart to join soonOpenAI revealed that more partners such as OpenTable (restaurant booking), PayPal (payment), and Walmart (retail) will be added in 2026. Currently, the feature is not available in Europe and the UK, mainly due to local data compliance requirements. AIbase observation: The competition for AI entry points has shifted from \"who is smarter\" to \"who is more comprehensive\"When ChatGPT connects to your schedule, wallet, music, travel, and home, it becomes more than just an app—it becomes the operating system of digital life. This \"AI + service\" integration led by OpenAI is redefining the value boundaries of smart assistants.However, convenience comes with deep data sharing. Users must weigh between \"extreme convenience\" and \"privacy control.\" For developers, a new question has emerged: perhaps the super app of the future doesn't even need a user interface—you just need to speak out your request.",
      "article_url": "https://www.aibase.com/news/24235",
      "author": "AIbase",
      "publish_time": 1767655149,
      "publish_date": "2026-01-06",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"ChatGPT\", \"OpenAI\", \"DigitalExecutionAgent\", \"AppIntegration\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767655149,
      "last_modify_ts": 1767655149
    },
    {
      "id": 55,
      "article_id": "aibase_24232",
      "title": "New Choice for Smart Notes! Plaud Launches AI Voice Recorder and Desktop Meeting Assistant",
      "description": "Recently, hardware manufacturer Plaud launched a new AI voice recorder - Plaud NotePin S, ahead of the 2026 Consumer Electronics Show (CES), and also released a",
      "content": "Recently, hardware manufacturer Plaud launched a new AI voice recorder - Plaud NotePin S, ahead of the 2026 Consumer Electronics Show (CES), and also released a desktop application to help users take notes during online meetings. The launch of this new device marks another innovation by Plaud in the field of meeting recording.Plaud NotePin S is the fourth product launched by the company since 2024. Compared to the previous generation, the new voice recorder adds a physical button that allows users to easily start and stop recording. In addition, during the recording process, users can tap the button to mark specific highlights, a feature similar to the recently launched Plaud Note Pro.The Plaud NotePin S, priced at $179, comes with a clip, lanyard, magnetic pin, and wrist strap, allowing users to choose different wearing methods based on their needs. To help users find the device easily, it also supports Apple Find My, which can help users quickly locate a lost device.In terms of core specifications, the Plaud NotePin S is similar to its predecessor, featuring 64GB of storage space, capable of providing 20 hours of continuous recording. The device is equipped with two MEMS microphones, which can clearly capture sound within a range of 9.8 feet. Users can enjoy 300 minutes of free transcription service per month.Although the recording range and battery life of NotePin S are slightly reduced compared to Note Pro, its more compact design makes it more convenient to carry around, making it especially suitable for users who are often on the go. Plaud has sold over 1.5 million devices so far. While focusing on face-to-face meetings, Plaud also hopes to compete with meeting recording tools such as Granola, Fathom, and Fireflies through its newly launched desktop client.The new desktop application from Plaud supports multiple meeting software, and can intelligently identify the active state of meetings and prompt users to record transcriptions. This Mac application uses system audio for recording and uses AI to organize the recordings into notes. Notably, the multimodal input feature introduced by Plaud last year will also be integrated into the desktop application, allowing users to add images and manually entered notes to transcriptions, further enriching the format of meeting records.",
      "article_url": "https://www.aibase.com/news/24232",
      "author": "AIbase",
      "publish_time": 1767655151,
      "publish_date": "2026-01-06",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AIRecordingPen\", \"PlaudNotePinS\", \"MeetingRecording\", \"BrandProductKeywords\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767655151,
      "last_modify_ts": 1767655151
    },
    {
      "id": 56,
      "article_id": "aibase_24311",
      "title": "NVIDIA Opens Source Autonomous Driving Model, Pioneering the New Era of Physical AI",
      "description": "At the recent 2026 Consumer Electronics Show (CES), NVIDIA founder and CEO Jensen Huang excitedly announced that the \"ChatGPT moment\" for physical AI has arrive",
      "content": "At the recent 2026 Consumer Electronics Show (CES), NVIDIA founder and CEO Jensen Huang excitedly announced that the \"ChatGPT moment\" for physical AI has arrived. He predicted that in the future, one billion cars will achieve high or full autonomy, with driverless taxis being the first beneficiaries of this revolutionary progress. During a press conference in Las Vegas, Huang showcased NVIDIA's emerging products, especially the open-source model Alpamayo for the field of autonomous driving. This model is the world's first open-source AI system capable of thinking and reasoning, specifically designed for autonomous vehicles. Compared to Chinese companies such as Li Auto, XPeng, and NIO, although NVIDIA is slightly behind in R&D progress, its open-source strategy will provide practical solutions for enterprises that do not have full-stack R&D capabilities. Photo Source: NVIDIA The first generation of Alpamayo uses a 10-billion-parameter architecture, which is not only adjustable for developers but also serves as a foundational tool for autonomous driving development. At the same time, NVIDIA also released a simulation tool called AlpaSim, as well as an open dataset containing more than 1,700 hours of driving data, aiming to promote the development of autonomous driving technology. Although Alpamayo mainly targets L4-level autonomous driving, in the competitive L2-level driver assistance market, NVIDIA still needs to make greater efforts. Jensen Huang also revealed that the 2025 Mercedes-Benz CLA will be equipped with NVIDIA's L2-level full-stack driver assistance solution, based on two NVIDIA Thor chips, planned to be launched in the U.S. and European markets this year. NVIDIA's layout in the field of autonomous driving has been supported by Wu Xinzhou, former head of intelligent driving at XPeng. Despite challenges such as communication between the US and Chinese teams and slow work pace, Wu Xinzhou is working hard to improve product experience. In April 2024, NVIDIA's no-map city NOA demo version did not meet expectations, but Wu Xinzhou stated that the new version's performance has significantly improved, and software updates will be released every quarter in the future. Although NVIDIA is still catching up with local competitors in the Chinese market, its potential in the European and American markets remains significant. With the release of Alpamayo and cooperation with Mercedes-Benz, NVIDIA is striving to regain its voice in the field of autonomous driving.",
      "article_url": "https://www.aibase.com/news/24311",
      "author": "AIbase",
      "publish_time": 1767741552,
      "publish_date": "2026-01-07",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"New AI Terms\", \"NVIDIA\", \"Alpamayo\", \"Autonomous Driving\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767741552,
      "last_modify_ts": 1767741552
    },
    {
      "id": 57,
      "article_id": "aibase_24310",
      "title": "New Breakthrough! Falcon H1R 7B Open-Source Large Model Leads the New Trend in Reasoning",
      "description": "The Abu Dhabi Innovation Institute (TII) has recently launched a new open-source large language model — Falcon H1R7B. This model maintains a compact scale of 7 ",
      "content": "The Abu Dhabi Innovation Institute (TII) has recently launched a new open-source large language model — Falcon H1R7B. This model maintains a compact scale of 7 billion parameters while demonstrating industry-leading reasoning performance, significantly challenging the traditional concept that \"bigger is better.\" Let's explore this remarkable new product.The design and training process of Falcon H1R7B is divided into two stages. The first is \"Cold Start Supervised Fine-Tuning\" (SFT), which mainly builds upon the existing Falcon-H1-7B model, focusing on training in areas such as mathematics, programming, and science. The next stage is \"Reinforcement Learning Enhanced\" (GRPO), which optimizes the model through a reward mechanism based on SFT, thereby improving the logic of reasoning and the diversity of output.In terms of performance, Falcon H1R7B has been deeply optimized in multiple dimensions such as speed, Token efficiency, and accuracy. Its unique \"Deep Think with Confidence\" (DeepConf) reasoning method not only generates fewer Tokens but also significantly improves overall accuracy. Additionally, the model adopts a hybrid architecture combining Transformer and Mamba (a state space model), enabling it to perform better in handling long contexts and enhancing reasoning throughput.Notably, Falcon H1R7B has shown exceptional performance in several public benchmark tests. For instance, in mathematical reasoning, it achieved an outstanding score of 88.1% on the AIME-24 test, surpassing many 15B models; in the LCB v6 test for code and proxy tasks, it scored 68.6%, making it a top performer among models <8B; and in general reasoning ability tests like MMLU-Pro and GPQA, its competitiveness even exceeds some larger models.In addition, Falcon H1R7B has a considerable reasoning throughput. At common batch sizes, each GPU can process up to approximately 1500 tokens/s, nearly twice as fast as some competitors. Even in low computing power environments, the model can effectively complete deep reasoning tasks, making it highly suitable for deployment by developers and enterprises.The full checkpoint and quantized version of this open-source model are available on Hugging Face, facilitating research, product development, and experimentation. Falcon H1R7B is undoubtedly set to create a new wave in the open-source AI field.",
      "article_url": "https://www.aibase.com/news/24310",
      "author": "AIbase",
      "publish_time": 1767741555,
      "publish_date": "2026-01-07",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"FalconH1R7B\", \"Open-Source Large Language Model\", \"New AI Terms\", \"Abu Dhabi Innovation Technology Institute\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767741555,
      "last_modify_ts": 1767741555
    },
    {
      "id": 58,
      "article_id": "aibase_24307",
      "title": "Baidu Baike Launches New Features Such as Dynamic Baike and Baike AI Knowledge Graph",
      "description": "Baidu Baike held an annual knowledge celebration and officially launched new features such as \"Dynamic Baike\" and the \"Baike AI Knowledge Graph.\" These new feat",
      "content": "Baidu Baike held an annual knowledge celebration and officially launched new features such as \"Dynamic Baike\" and the \"Baike AI Knowledge Graph.\" These new features aim to further enhance users' experience of acquiring knowledge, making information more vivid and systematic.As of now, the total number of entries on Baidu Baike has exceeded 30 million, making it one of the largest knowledge bases in the Chinese internet. The number of users who have participated in editing and contributing content has also exceeded 8.03 million, showing that more and more users are actively participating in knowledge sharing and creation. In addition, Baidu Baike's \"Starlight Plan\" has collaborated with well-known institutions such as the University of Science and Technology of China, the Chinese Academy of Sciences, and Peking University, gathering over 100,000 experts and professional creators to jointly build more than 1 million pieces of professional content. This collaboration not only enriches the content of entries but also enhances the authority and accuracy of the knowledge.",
      "article_url": "https://www.aibase.com/news/24307",
      "author": "AIbase",
      "publish_time": 1767741558,
      "publish_date": "2026-01-07",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Dynamic Baike\", \"Baike AI Knowledge Graph\", \"Baidu Baike\", \"Fenxing Plan\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767741558,
      "last_modify_ts": 1767741558
    },
    {
      "id": 60,
      "article_id": "aibase_24303",
      "title": "Boston Dynamics × Google DeepMind Join Forces! Gemini Robotics Large Model Will Drive the Next Generation of Atlas Humanoid Robot",
      "description": "As the global technology community converges on CES 2026, the fields of robotics and artificial intelligence are witnessing a historic collaboration. On January",
      "content": "As the global technology community converges on CES 2026, the fields of robotics and artificial intelligence are witnessing a historic collaboration. On January 5th local time, Boston Dynamics officially announced a new artificial intelligence partnership, integrating Google's latest released Gemini Robotics foundation model deeply into its next-generation Atlas humanoid robot. The joint research project is expected to launch in the coming months, marking the beginning of a substantive phase in the deep integration of the world's top robotic platforms with leading AI brains. Gemini Robotics + Atlas: The World's Strongest \"Body\" with the Most Powerful BrainThe core of this collaboration involves deploying Gemini Robotics—Google's multimodal embodied intelligence model optimized for physical world interaction—onto Boston Dynamics' latest generation electric Atlas robot. This robot already has impressive capabilities such as parkour, backflips, and complex object manipulation, but its task planning still heavily relies on pre-programming and human remote operation.By integrating Gemini Robotics, Atlas will gain:- Natural language understanding capabilities: It can understand open-ended instructions like \"move the blue box to the third shelf\";- Visual-action joint reasoning: Combining camera and force feedback, it can autonomously plan grasping strategies;- Task decomposition and generalization abilities: It can break down complex goals into executable sub-steps and adapt to new environments;- Continuous learning mechanisms: It can continuously optimize behavior strategies through interaction with the environment.This will transform Atlas from a \"high-difficulty performance artist\" into an \"autonomous task executor,\" truly moving towards a general-purpose humanoid robot (AGV). Why Now? The Embodied Intelligence Enters a Period of \"Model-Platform\" Collaboration ExplosionRecently, Demis Hassabis, CEO of DeepMind, emphasized repeatedly: \"AGI needs a body.\" Robert Playter, CEO of Boston Dynamics, also admitted: \"We have the best body, but we need a stronger brain.\" This collaboration represents a \"mutual pursuit\" between two technological peaks.It is worth noting that Gemini Robotics has already been used internally by Google to control industrial robotic arms, while Atlas represents the pinnacle of humanoid robot motion control globally. The combination of the two may break through current bottlenecks in embodied intelligence in scenarios such as complex terrain navigation, fine manipulation, and human-robot collaboration. AIbase Observation: The Humanoid Robot Competition Enters a New Stage of \"Ecosystem Integration\"With Tesla Optimus, 1X Neo, and Figure 02 all moving toward commercialization, Boston Dynamics' decision to collaborate with DeepMind highlights its technical priority and non-commercialization path. However, once Gemini+Atlas is validated successfully, the technological spillover effect will be significant—whether through algorithm open-source or platform licensing, it could reshape the entire industry's technical standards.",
      "article_url": "https://www.aibase.com/news/24303",
      "author": "AIbase",
      "publish_time": 1767741565,
      "publish_date": "2026-01-07",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AIbuzzwords\", \"Brandproductterms\", \"Robots\", \"ArtificialIntelligence\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767741565,
      "last_modify_ts": 1767741565
    },
    {
      "id": 63,
      "article_id": "aibase_24273",
      "title": "Amazon Launches Alexa.com to Enhance Web Browsing Capabilities",
      "description": "Amazon is accelerating Alexa's position in the generative AI competition. On Monday, Amazon officially launched the web portal Alexa.com for Alexa +, allowing s",
      "content": "Amazon is accelerating Alexa's position in the generative AI competition. On Monday, Amazon officially launched the web portal Alexa.com for Alexa +, allowing some users to directly interact with this new generation of smart assistant through a browser. This move is seen as a key upgrade in Amazon's interaction model and indicates that its competition with ChatGPT from OpenAI is becoming more direct. According to AIbase, Alexa.com is currently only available to Alexa + users. Alexa + is Amazon's new generation AI assistant, launched in February of last year, and is still in an early trial phase. Users need to join a waiting list or purchase newer Amazon-related devices to gain access. Amazon stated that over a million users can currently access Alexa +, but it is still gradually expanding. In terms of functionality, Amazon has set a clear positioning for the web version of Alexa. Through Alexa.com, users can quickly get information, discuss complex issues in depth, create content, plan travel itineraries, and assist with homework. At the same time, Alexa + also supports managing smart home devices directly within the chat window, continuing its core advantage in home scenarios. Amazon emphasized that the purpose of launching the web version is to expand the usage scenarios of Alexa +, ensuring that users can interact with this AI assistant through different terminals. Previously, Alexa + mainly relied on mobile applications and some Echo smart speaker devices, with relatively limited access points. The launch of Alexa.com has made Amazon's product form closer to the current mainstream AI chatbot usage methods. Several manufacturers, including OpenAI, Google, Anthropic, and Perplexity, have already supported accessing their AI services directly through web browsers. In comparison, Amazon was clearly lagging in \"pure web interaction\" previously. Under the wave of generative AI, the rapid popularity of products like ChatGPT and Google Gemini is reshaping user expectations of smart assistants. For Amazon, this change is both a pressure and a key driver to accelerate the upgrading of its software and hardware ecosystem. In fact, when Amazon launched Alexa + last year, it had already announced that Alexa.com would be launched within a few months; in July of the same year, the company confirmed in an interview with The Washington Post that this feature was planned to be available to early experience users in the summer. With the official launch of the web version of Alexa +, Amazon is filling a key gap between itself and mainstream generative AI products. In the future, whether Alexa can compete face-to-face with products like ChatGPT in terms of content understanding and generation capabilities will be an important indicator of the success of its AI strategy.",
      "article_url": "https://www.aibase.com/news/24273",
      "author": "AIbase",
      "publish_time": 1767741600,
      "publish_date": "2026-01-07",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Alexa+\", \"GenerativeArtificialIntelligence\", \"OpenAI\", \"ChatGPT\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767741600,
      "last_modify_ts": 1767741600
    },
    {
      "id": 64,
      "article_id": "aibase_24372",
      "title": "Open-Source Version of Veo 3 Is Here: LTX-2 Officially Released - Generate a 20-Second 4K AI Video with Synchronized Audio and Video in One Go - Run Smoothly on Local Graphics Cards",
      "description": "AI video generation has reached a milestone breakthrough! The Lightricks team has officially open-sourced the LTX-2 model, which is hailed as the first truly co",
      "content": "AI video generation has reached a milestone breakthrough! The Lightricks team has officially open-sourced the LTX-2 model, which is hailed as the first truly complete open-source audio-visual foundation model. It supports generating up to 20-second 4K high-definition videos in one go and achieves perfect synchronization of visuals, sound, lip movements, ambient sounds, and music. The AIbase editing team has compiled the latest online updates, bringing you a comprehensive analysis. Open-Source Gift Package: Weights and Code Fully Released, Community CelebratesThe LTX-2 model weights, complete training code, benchmark tests, and toolkits have all been open-sourced, hosted on GitHub and Hugging Face. Developers can freely inspect, fine-tune, and deploy locally. The model is based on a DiT hybrid architecture, supporting text-to-video, image-to-video, multi-keyframe control, 3D camera logic, and LoRA fine-tuning. Latest updates show that ComfyUI has native support for LTX-2 on Day 0, providing ready-to-use workflows, greatly lowering the learning curve. After optimization for NVIDIA RTX consumer-grade GPUs, generation efficiency has significantly improved, allowing ordinary users to experience professional-level output without enterprise-grade hardware. Core Highlights: Audio and Video Combined, Synchronized Generation Without Post-ProcessingDiffering from traditional models that require separate audio stitching, LTX-2 jointly generates visual and audio elements in a single process, ensuring natural alignment of actions, dialogue, ambient sound effects, and music. It supports native 4K resolution, up to 50fps frame rate, and up to 20 seconds of continuous clips. Practical testing shows excellent lip-syncing and expression rendering, with highly realistic character dialogue scenes. Additionally, the model maintains high consistency under complex prompts, with significantly better skin texture and motion smoothness compared to most open-source competitors. Input modalities are flexible, driven by text, images, or sketches, suitable for short films, advertisements, and content creation. Performance Optimization: Faster, More Efficient, and Friendly for Local ExecutionCompared to previous versions and some competitors, LTX-2 reduces computational costs by up to 50%, and supports long-sequence expansion with multi-GPU inference stacks. Quantized versions further reduce GPU memory requirements, running smoothly on RTX 40 series and higher GPUs. Community feedback indicates that generating 10-20 second videos takes only a few minutes, making real-time preview possible. This marks a shift of high-end AI video generation from cloud-based closed systems to local open-source democratization, significantly lowering the threshold for creators. Unlimited Application Potential: From Personal Creation to Professional ProductionLTX-2 has demonstrated strong potential in content creation, animation, marketing, and film previsualization. It supports video-to-video control such as Canny, Depth, and Pose, combined with keyframe-driven approaches, enabling precise storytelling and consistent style. In the future, with community LoRA and plugin extensions, this model may become the core engine of the open-source AI video ecosystem, driving innovation from short-form to long-form content.AIbase Perspective: The open-sourcing of LTX-2 is not only a technological leap but also a critical step towards democratizing AI video. It fills the gap in open-source audio-visual joint generation and may accelerate the popularity of local AI tools. AIbase will continue to monitor its community development and practical applications; stay tuned for our follow-up reports.",
      "article_url": "https://www.aibase.com/news/24372",
      "author": "AIbase",
      "publish_time": 1767827944,
      "publish_date": "2026-01-08",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AIVideoGeneration\", \"Lightricks\", \"LTX-2Model\", \"OpenSource\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767827944,
      "last_modify_ts": 1767827944
    },
    {
      "id": 67,
      "article_id": "aibase_24367",
      "title": "Anthropic Releases Claude Code Desktop Preview Version with Multi-Session Parallelism and Git Isolation",
      "description": "&nbsp;Anthropic has officially released Claude Code for Desktop, which is currently in preview. This version introduces a native graphical user interface (GUI) ",
      "content": "Anthropic has officially released Claude Code for Desktop, which is currently in preview. This version introduces a native graphical user interface (GUI) application based on the existing command-line interface (CLI) version, aiming to provide developers with a more intuitive and powerful local AI programming environment.As a core highlight of this release, Claude Code for Desktop introduces multi-session parallel workflow. By utilizing automatically generated Git Worktree technology, developers can open multiple independent Claude sessions within the same code repository, each with an isolated branch workspace (stored by default in ~/.claude-worktrees). This means different development tasks do not interfere with each other, completely eliminating the risk of code conflicts caused by overlapping sessions.In terms of integration, the desktop version demonstrates high flexibility:Cloud Collaboration: It seamlessly integrates with the web version, allowing users to start cloud sessions directly from the desktop and switch between local and cloud environments effortlessly.Automatic Environment Synchronization: The application automatically extracts the system's $PATH environment variable, ensuring that local development tools such as npm and node are ready to use out of the box, and supports custom encrypted environment variable configurations.Independent Version Management: The desktop version includes a standalone and stable Claude Code core, supporting automatic downloads and silent updates without conflicting with other installed versions on the system.Currently, Claude Desktop supports macOS and Windows platforms (not supporting Windows arm64). For developers seeking efficient collaboration and complex project management, the launch of this native desktop application marks the evolution of AI programming assistants from simple \"chatbots\" into full-featured \"automated programming consoles.\"Link: https://code.claude.com/docs/en/desktop",
      "article_url": "https://www.aibase.com/news/24367",
      "author": "AIbase",
      "publish_time": 1767827962,
      "publish_date": "2026-01-08",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"ClaudeCode\", \"AI Terms\", \"Graphical Interface\", \"Multi-Session Parallelism\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://code.claude.com/docs/en/desktop\", \"url\": \"https://code.claude.com/docs/en/desktop\", \"type\": \"external\"}]",
      "add_ts": 1767827962,
      "last_modify_ts": 1767827962
    },
    {
      "id": 68,
      "article_id": "aibase_24366",
      "title": "Liquid AI Releases LFM2.5: A Family of Small AI Models for Edge Devices",
      "description": "Liquid AI recently launched LFM2.5, a next-generation family of small foundation models based on the LFM2 architecture, focusing on edge devices and local deplo",
      "content": "Liquid AI recently launched LFM2.5, a next-generation family of small foundation models based on the LFM2 architecture, focusing on edge devices and local deployment. This model family includes LFM2.5-1.2B-Base and LFM2.5-1.2B-Instruct, and also expands to variants in Japanese, vision-language, and audio-language. These models are released with open-source weights on Hugging Face and are showcased on the LEAP platform.LFM2.5 retains the hybrid LFM2 architecture designed for CPU and NPU, aiming to achieve fast and memory-efficient inference. The pre-training phase of this model expanded parameters to 120 million, and training data increased from 10 trillion tokens to 28 trillion tokens. Subsequently, the instruction variant model underwent supervised fine-tuning, preference alignment, and large-scale multi-stage reinforcement learning, focusing on instruction following, tool usage, math, and knowledge reasoning.In terms of text model performance, LFM2.5-1.2B-Instruct is the main general-purpose text model. The Liquid AI team reported performance on multiple benchmarks such as GPQA, MMLU Pro, IFEval, and IFBench, achieving scores of 38.89 on GPQA and 44.35 on MMLU Pro. These scores are significantly higher than other similar open-source models, such as Llama-3.2-1B Instruct and Gemma-3-1B IT.Additionally, LFM2.5-1.2B-JP is a text model specifically optimized for Japanese, tailored for tasks such as JMMLU, M-IFEval, and GSM8K in Japanese. This checkpoint outperforms general instruction models on Japanese tasks and competes with other small multilingual models in these local benchmark tests.Regarding multimodal edge workloads, LFM2.5-VL-1.6B is the updated vision-language model in this series, incorporating a visual module for image understanding. This model is optimized to support practical applications such as document understanding, user interface reading, and multi-image reasoning, and can efficiently run in edge environments.LFM2.5-Audio-1.5B is a native audio language model that supports text and audio input and output, using a new audio tokenizer that is eight times faster than previous solutions, suitable for tasks such as real-time voice-to-voice conversation agents and automatic speech recognition.https://www.liquid.ai/blog/introducing-lfm2-5-the-next-generation-of-on-device-aiKey points: 🌟 LFM2.5 is a family of small foundation models based on the LFM2 architecture, supporting various variants including text, vision-language, and audio-language. 📈 This model performs excellently on multiple benchmarks, especially surpassing similar models on GPQA and MMLU Pro. 🌐 The LFM2.5 series covers multimodal and regional optimization, providing strong edge computing capabilities, suitable for various practical application scenarios.",
      "article_url": "https://www.aibase.com/news/24366",
      "author": "AIbase",
      "publish_time": 1767827966,
      "publish_date": "2026-01-08",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"LiquidAI\", \"LFM2.5\", \"AINeologism\", \"OpenSourceModel\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://www.liquid.ai/blog/introducing-lfm2-5-the-next-generation-of-on-device-aiKey\", \"url\": \"https://www.liquid.ai/blog/introducing-lfm2-5-the-next-generation-of-on-device-aiKey\", \"type\": \"external\"}]",
      "add_ts": 1767827966,
      "last_modify_ts": 1767827966
    },
    {
      "id": 70,
      "article_id": "aibase_24360",
      "title": "Google Gemini Launches New Guided Learning Feature: AI Private Tutor-Style Step-by-Step Guidance, Revolutionizing Personalized Education",
      "description": "With significant advancements in the field of education driven by artificial intelligence, Google has recently launched the \"Guided Learning\" feature on the Gem",
      "content": "With significant advancements in the field of education driven by artificial intelligence, Google has recently launched the \"Guided Learning\" feature on the Gemini platform. This innovative tool transforms the learning process into a personalized and interactive experience, as if having a dedicated private tutor. It doesn't just provide answers but helps users achieve deep mastery by breaking down complex topics step by step, adapting to the user's pace, and verifying understanding.The \"Guided Learning\" fully utilizes Gemini's multimodal capabilities to build structured learning paths. Users can easily access it through the Gemini website or app: start a new conversation, select the \"Guided Learning\" mode from the toolbar, then enter a question or upload a document (such as notes, PDFs, or textbooks) to begin—no additional settings required. Once activated, the system unfolds in an interactive dialogue format.It breaks down the subject into small modules, first providing basic explanations and incorporating rich media content such as images, charts, and YouTube videos to aid understanding. For example, when learning about quantum entanglement, Gemini starts with fundamental concepts and uses guiding questions to assess the user's understanding (such as \"What do you think will happen next?\"), only proceeding to the next step after confirming comprehension.It also supports custom quizzes, flashcard generation, and dynamically adjusts difficulty based on user feedback—beginners receive simplified explanations, while advanced users delve deeper into applications. This design is rooted in educational science principles, such as active recall and spaced repetition, which have been proven to enhance long-term memory and practical application skills. Unlike traditional search engines or static resources, \"Guided Learning\" emphasizes progressive dialogue, allowing users to ask follow-up questions, clarify points, or explore related topics at any time. Early user feedback indicates that it performs well in areas like programming, language learning, and scientific theories, transforming abstract concepts into intuitive experiences.The key difference between \"Guided Learning\" and regular AI chat is its structured and verification mechanism. It doesn't just output facts in isolation but instantly builds a \"scaffolding\" style course. For example, when discussing photosynthesis, the system might first ask about key components, then gradually integrate video demonstrations and interactive quizzes to ensure no knowledge gaps.Compared to similar features in competitors like ChatGPT, Gemini excels in multimedia integration and deep focus, supporting document upload and analysis, making it suitable for professionals seeking skill enhancement or students preparing for exams. Additionally, it integrates with the Google for Education ecosystem, offering teachers tools to generate quizzes and learning guides.",
      "article_url": "https://www.aibase.com/news/24360",
      "author": "AIbase",
      "publish_time": 1767827971,
      "publish_date": "2026-01-08",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767827971,
      "last_modify_ts": 1767827971
    },
    {
      "id": 72,
      "article_id": "aibase_24354",
      "title": "Microsoft Announces Native Support for the MCP Protocol in Windows 11",
      "description": "Microsoft recently announced on its official social platforms that Windows 11 will undergo a comprehensive upgrade, with native support for the MCP protocol. Th",
      "content": "Microsoft recently announced on its official social platforms that Windows 11 will undergo a comprehensive upgrade, with native support for the MCP protocol. This move aims to promote the deep integration of active AI agents, providing users with a smoother and smarter operating experience. The MCP protocol (Model Connection Protocol) allows AI models to securely connect with local applications, enabling more efficient automation.In the new Windows 11 preview version, Microsoft introduced a new feature called \"Experiential Agent.\" The highlight of this feature is that AI can run in the background continuously, offering personalized services to users. Users no longer need to manually activate AI features; it will automatically adjust based on usage habits. This innovative design not only enhances convenience but also demonstrates Microsoft's vision and determination in the field of AI.With the rapid development of artificial intelligence technology, major tech companies are exploring how to better integrate AI into daily life. Microsoft's new initiative reflects its deep understanding and insights into the current AI ecosystem. Through the MCP protocol, Microsoft hopes to attract more third-party developers to participate in the construction of agents, jointly creating diverse applications and enhancing the practical value of Windows AI. This also provides users with more choices, making AI more closely integrated into daily life.This upgrade is not only a technological advancement but also a re-examination of user experience by Microsoft. By offering an open development platform, Microsoft aims to involve more developers in building agents, bringing fresh and practical AI applications to users. Whether in work, study, or entertainment, Windows 11 will demonstrate stronger intelligent support, bringing convenience to users' lives.In summary, Microsoft's comprehensive upgrade shows its firm steps in the field of AI. Through the innovation of agents, Microsoft hopes to make Windows 11 an indispensable smart assistant for users, changing people's perception of traditional operating systems and offering a richer user experience.",
      "article_url": "https://www.aibase.com/news/24354",
      "author": "AIbase",
      "publish_time": 1767827980,
      "publish_date": "2026-01-08",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Windows11\", \"MCPProtocol\", \"AIAgent\", \"ExperientialAIAgent\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767827980,
      "last_modify_ts": 1767827980
    },
    {
      "id": 73,
      "article_id": "aibase_24344",
      "title": "Self-Developed World Model Proves Its Worth! Amap Launches Flying Street View, Letting Users Explore Thousands of Stores Without Leaving Home",
      "description": "On January 7, Alibaba's AutoNavi officially launched the \"AutoNavi Street Scan Ranking 2026,\" and simultaneously introduced a major feature based on its self-de",
      "content": "On January 7, Alibaba's AutoNavi officially launched the \"AutoNavi Street Scan Ranking 2026,\" and simultaneously introduced a major feature based on its self-developed world model - \"Flight Street View.\" The release of this technology marks a leap in the evolution of map navigation from flat digitalization to high-fidelity, continuous dynamic real-world rendering.The core of the \"Flight Street View\" feature lies in achieving high-precision visual reconstruction through an AI world model. Unlike traditional static street view images, this feature first realizes a continuous dynamic flying perspective. Before actual travel, users can open \"air roaming\" on their mobile screens to immerse themselves in previewing the route to the destination. In addition, this technology clearly presents details of store signs and the real environment inside the store, providing users with a visual perception almost equivalent to an on-site visit, greatly reducing decision-making costs.For merchants, this feature also holds revolutionary significance. Through \"Flight Street View,\" the characteristics of the store can be comprehensively displayed in a more expressive dynamic form, becoming a new window for merchants' digital marketing.With the release of the AutoNavi Street Scan Ranking 2026, AutoNavi is further breaking the boundaries between virtual maps and the physical world by using its self-developed world model, building a more intuitive and intelligent digital life connection platform for users and merchants.",
      "article_url": "https://www.aibase.com/news/24344",
      "author": "AIbase",
      "publish_time": 1767827983,
      "publish_date": "2026-01-08",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Amap Street Scanning Ranking 2026\", \"Flying Street View\", \"AI World Model\", \"Amap\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767827983,
      "last_modify_ts": 1767827983
    },
    {
      "id": 74,
      "article_id": "aibase_24463",
      "title": "GaoDe FantasyWorld Launches and Immediately Tops the World Model Ranking, Alibaba's Spatial Intelligence Achieves Another Victory!",
      "description": "Alibaba's AutoNavi has officially launched its self-developed world model \"FantasyWorld.\" Leveraging its massive real-world navigation data advantage, this mode",
      "content": "Alibaba's AutoNavi has officially launched its self-developed world model \"FantasyWorld.\" Leveraging its massive real-world navigation data advantage, this model quickly secured the top position in the comprehensive score on the international authoritative benchmark WorldScore Leaderboard, further expanding Alibaba's layout in the field of AI foundational models. FantasyWorld focuses on high-quality 3D world construction and has become a new focus in the fields of embodied intelligence and autonomous driving. Core Technical Breakthroughs of FantasyWorldFantasyWorld aims to provide high-quality 3D world models for embodied intelligence and general artificial intelligence (AGI). Its innovation lies in: adding a trainable geometric branch on a frozen video-based model backbone, achieving joint modeling of \"video latent variables\" and \"implicit 3D fields,\" which can be completed with just one forward computation.This design significantly enhances the visual realism of generated videos while greatly improving multi-view consistency and geometric fidelity. Compared to recent methods for geometric consistency, FantasyWorld performs well in multi-view collaboration, style consistency, and maintaining object shape and texture under extreme views (such as 180° rotation). The 3D latent variables generated by the model can be directly decoded into depth maps or point clouds, supporting downstream tasks without additional optimization. Top of WorldScore: Proof of International RecognitionWorldScore is a unified world generation benchmark led by Professor Fei-Fei Li's team at Stanford University, covering multi-dimensional evaluations such as static/dynamic scenes, controllability, and consistency. Currently, FantasyWorld ranks first in both the overall score and key metrics (such as a static world score of 78.55 and a dynamic world score of 66.89), surpassing multiple domestic and international competing models.The related paper has been accepted by top conferences such as ICLR 2025 and NeurIPS 2025. AutoNavi stated that the model will be open-sourced soon, further promoting academic and industrial collaboration. Practical Application: Flying Street View Brings New Spatial Intelligence ExperienceFantasyWorld has been first applied to AutoNavi's \"Flying Street View\" feature. Merchants need only upload a few short mobile phone videos to generate high-fidelity 3D virtual street view tours for free, helping users to experience in advance the layout of restaurants, seating areas, and other details, while also helping offline merchants increase traffic.This feature is seen as an embodiment of \"technological equity,\" lowering the threshold for professional 3D modeling. AutoNavi has also established an embodied business department internally, exploring directions such as robots and robotic dogs, and comprehensively shifting toward physical AI in combination with spatial intelligence. Industry Impact: The Era of World Models is AcceleratingWith the shift of autonomous driving to end-to-end visual language action (VLA) solutions and the rapid development of embodied intelligence, world models that pursue physical realism and 3D consistency have become increasingly important. The launch of FantasyWorld not only strengthens Alibaba's presence in the multimodal AI landscape but also highlights the advantages of Chinese enterprises in spatial intelligence driven by real-world data.AIbase Perspective: FantasyWorld marks a leap from video generation to interactive 3D simulation in world models, which will profoundly impact the future of AR/VR, robot navigation, and digital twins. With its accumulation of hundreds of millions of user data, AutoNavi may gain a competitive edge in the physical AI track. AIbase will continue to monitor its open-source progress and more application implementations, providing in-depth analysis for readers.",
      "article_url": "https://www.aibase.com/news/24463",
      "author": "AIbase",
      "publish_time": 1768173464,
      "publish_date": "2026-01-12",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"FantasyWorld\", \"GaodeMap\", \"AIFoundationModel\", \"3DWorldModel\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768000740,
      "last_modify_ts": 1768173464
    },
    {
      "id": 76,
      "article_id": "aibase_24447",
      "title": "Musk's xAI Enters Vibe Coding, New Product Grok Build Exposed",
      "description": "&nbsp;Elon Musk's artificial intelligence company xAI is preparing a major move in the programming field. xAI is about to launch a new product called Grok Build",
      "content": "Elon Musk's artificial intelligence company xAI is preparing a major move in the programming field. xAI is about to launch a new product called Grok Build, whose core concept is the popular \"vibe coding\" (Vibe Coding).Currently, the web version prototype of Grok Build has begun to take shape. From the exposed interface, the tool has an independent tab and a simple prompt input box in the center, greatly facilitating developers to interact through dialogue. This design indicates that the threshold for programming is further reduced, and developers may only need to describe their needs, with the AI completing complex underlying construction.Previously, Musk publicly announced that Grok Code will undergo significant technological upgrades. It is reported that the new version will first be released in the form of a local proxy, equipped with a powerful command-line interface (CLI). Users can drive the AI to perform the entire workflow from \"planning\" to \"searching\" and finally \"building\" code through natural language instructions.Although xAI has not officially announced the specific release time of Grok Build, the community is highly attentive to its possibility of being deployed on mobile devices. As functional details are gradually disclosed, xAI's strategic layout in the AI programming tool field has become clear, aiming to reshape the development ecosystem by adopting the \"natural language as programming\" model.Key points:💻 New Programming Paradigm: xAI launches the \"vibe coding\" solution Grok Build, aiming to let AI automatically plan and build code through natural language.🛠️ Multiform Deployment: The product will include a web-based interactive interface and a local proxy version with CLI, supporting full-process automated development tasks.🚀 Strategic Continuous Upgrades: Musk confirmed that Grok Code will enter a period of intensive updates, indicating that the AI programming tool market will face more intense competition.",
      "article_url": "https://www.aibase.com/news/24447",
      "author": "AIbase",
      "publish_time": 1768173470,
      "publish_date": "2026-01-12",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AINeologism\", \"BrandProductTerms\", \"AmbientProgramming\", \"GrokBuild\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768000746,
      "last_modify_ts": 1768173470
    },
    {
      "id": 77,
      "article_id": "aibase_24444",
      "title": "Tencent Trials a New Entertainment Avenue for the Gen Z: The 'Upset Frog' AI Interactive Story Mini Program Test, Using Generative AI to Stimulate Young Creativity",
      "description": "When Generation Z no longer settles for passive content consumption but instead craves to become co-creators or even protagonists of stories, Tencent quietly un",
      "content": "When Generation Z no longer settles for passive content consumption but instead craves to become co-creators or even protagonists of stories, Tencent quietly unveils a new card. According to reliable sources, Tencent is currently testing an AI-driven interactive storytelling mini-program called \"Shangtouwa,\" which focuses on immersive interactive narrative experiences. It aims to carve out a new path for young people at the intersection of entertainment and generative AI.The core appeal of \"Shangtouwa\" lies in its high level of participation and social design. The product features an \"Interactive Story Square,\" aggregating numerous story segments generated by AI or co-created by users. Topics cover popular film and animation IP derivatives, urban emotions, mystery and deduction, as well as light-hearted and internet-savvy comedies—such as recent topic-driven content like \"Top Sea Queen New Year Text Messages,\" which has sparked small-scale discussions. These content pieces precisely tap into the interests and social conversation needs of young users. Users not only can read these dynamically generated stories, but also intervene in the plot direction at any time, guiding the AI to continue writing through choices, input, or commands, truly realizing \"everyone is a screenwriter.\"This model breaks away from the traditional one-way output logic of online literature or short videos, upgrading AI from a content production tool to a real-time interactive partner. Tencent's move aims to leverage its comprehensive advantages in large models, natural language generation, and social ecosystems, to create a low-barrier, highly entertaining platform for UGC (User-Generated Content) and AIGC (AI-Generated Content) hybrid creation. By lowering the barriers to creation and enhancing immediate feedback, \"Shangtouwa\" is expected to stimulate the expression and sharing desires of Generation Z, forming a new interest community centered around stories.Although the product is still in internal testing phase, specific launch dates and full feature details remain undisclosed. However, its strategic intent is already clear: exploring the next generation of lightweight, highly engaging digital entertainment forms beyond short videos and live streaming. If it successfully activates the flywheel effect of continuous user creation and interaction, \"Shangtouwa\" could become a key testbed for Tencent's consumer-level AIGC applications, and inject new possibilities into fields such as interactive reading, scenario simulation, and virtual companionship. More updates can be followed in subsequent in-depth reports from \"Dujia.\"",
      "article_url": "https://www.aibase.com/news/24444",
      "author": "AIbase",
      "publish_time": 1768173473,
      "publish_date": "2026-01-12",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AIBuzzwords\", \"UpperFrog\", \"Tencent\", \"InteractiveStorySquare\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768000751,
      "last_modify_ts": 1768173473
    },
    {
      "id": 78,
      "article_id": "aibase_24439",
      "title": "Google Gmail Receives a Major Update: AI-Powered Inbox and Natural Language Search Now Available",
      "description": "Google's email service Gmail recently announced the launch of multiple deep-integrated AI features, aiming to revolutionize users' email processing efficiency t",
      "content": "Google's email service Gmail recently announced the launch of multiple deep-integrated AI features, aiming to revolutionize users' email processing efficiency through generative AI technology. The most notable is the new \"AI Inbox,\" which acts like a personal assistant, automatically organizing tasks and summarizing important updates for users.This \"AI Inbox\" uses a two-column design, including two core sections: \"Suggested Tasks\" and \"Topic Tracking.\" It no longer simply lists emails but can proactively identify the content of emails. For example, it will automatically remind you that a bill is due tomorrow or inform you that a package has been delivered. Google Vice President Blake Barnes stated that this feature aims to free users from spam and trivial information, focusing on core tasks.In addition to smart classification, Gmail's search functionality has also seen a significant improvement. Users can now ask questions using natural language, such as \"Who was the contractor who gave me a quote last year?\" The AI will quickly sift through thousands of emails and directly provide an answer without requiring users to manually search for keywords. In addition, Google has launched a feature called \"Proofread,\" which is similar to Grammarly, allowing users to optimize the wording, tone, and logic structure of their emails with one click.Notably, Google has also demonstrated its commitment to accessible AI. High-end features such as \"Help Me Write,\" email summaries, and smart replies, which were previously available only to paid members, are now officially open to all global Gmail users. Regarding user concerns about privacy, Google reiterated that these AI features can be freely turned on or off, and the system will not use private email data to train the base model.Key points:📬 Personalized AI Assistant: The new Gmail introduces an AI-specific inbox that automatically summarizes tasks and categorizes important information such as finance and shopping.🔍 Natural Language Search: Users can now find email details by asking direct questions, and the AI will extract precise answers from the user's personalized \"email brain.\"🎁 Multiple Features Available Free to All: Features like \"Help Me Write\" and email summaries, which were previously paid, are now available to all users, significantly lowering the barrier to using AI tools.",
      "article_url": "https://www.aibase.com/news/24439",
      "author": "AIbase",
      "publish_time": 1768173476,
      "publish_date": "2026-01-12",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AIBuzzwords\", \"Gmail\", \"AIInbox\", \"GenerativeAI\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768000754,
      "last_modify_ts": 1768173476
    },
    {
      "id": 81,
      "article_id": "aibase_24429",
      "title": "Tongyi Qianwen Secures Another Victory: Qwen3-VL Twins Open-Source, Bringing a New Paradigm to Multimodal Retrieval",
      "description": "When text, images, videos, charts, and even UI interfaces can be uniformly \"understood\" and precisely matched, the boundaries of multimodal information retrieva",
      "content": "When text, images, videos, charts, and even UI interfaces can be uniformly \"understood\" and precisely matched, the boundaries of multimodal information retrieval are being completely redefined. Today, Alibaba Tongyi Lab officially open-sources two models: Qwen3-VL-Embedding and Qwen3-VL-Reranker. Built upon the powerful Qwen3-VL multimodal foundation, these models are specifically designed for cross-modal understanding and efficient retrieval, marking a significant leap from the \"keyword matching\" era to a new epoch of \"semantic alignment\" in multimodal search.These two models do not exist in isolation but form a collaborative intelligent retrieval engine. Qwen3-VL-Embedding uses an efficient dual-tower architecture to independently encode diverse content such as text, images, visual documents (e.g., code screenshots, data charts, app interfaces), and even videos into vector representations within a unified high-dimensional semantic space. This means that regardless of whether the user input is a textual description, a product image, or a short video, the system can map it into the same semantic coordinate system, enabling millisecond-level cross-modal similarity calculations and massive data recall.Meanwhile, Qwen3-VL-Reranker acts as a \"refiner.\" It employs a single-tower cross-attention architecture to perform deep re-ranking on the initial results from Embedding. When facing complex tasks such as \"image-text query matching image-text documents\" or \"video segment retrieval of related articles,\" the Reranker will jointly encode the query and candidate documents, analyzing their deeper associations in semantics, details, and even contextual logic through the model's internal cross-attention mechanism, ultimately outputting a precise relevance score. This two-stage process of \"fast embedding retrieval + precise reranking\" significantly improves the accuracy and relevance of the final retrieval results.Technical strength is ultimately proven by data. In authoritative multimodal benchmark tests such as MMEB-v2 and MMTEB, the Qwen3-VL series has shown outstanding performance. The 8B version of the Embedding model surpassed all known open-source models and mainstream closed-source commercial services on MMEB-v2; the Reranker model continues to lead in visual document retrieval tasks including JinaVDR and ViDoRe v3, with the 8B version taking first place in most subtasks. Particularly notable is that this series inherits the multilingual capabilities of Qwen3-VL, supporting over 30 languages, and offers flexible vector dimension options, instruction fine-tuning capabilities, and high-performance quantized versions, greatly reducing the integration barriers for developers.This open-source release is not only a technical achievement but also marks the maturity of multimodal AI infrastructure. In the past, image-text retrieval, video understanding, and document analysis often required separate models and processes. Now, the Qwen3-VL twin models provide a unified, efficient, and open solution, allowing developers to handle almost all mixed modal content within a single framework. As real-world data increasingly emerges in multimodal forms, this toolset may accelerate the next generation evolution of search engines, content platforms, enterprise knowledge bases, and intelligent assistants—where machines truly \"see\" and \"understand\" everything we see, write, and take pictures of.",
      "article_url": "https://www.aibase.com/news/24429",
      "author": "AIbase",
      "publish_time": 1768173485,
      "publish_date": "2026-01-12",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"MultimodalInformationRetrieval\", \"Qwen3-VL-Embedding\", \"Qwen3-VL-Reranker\", \"AlibabaTongyiLab\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768000762,
      "last_modify_ts": 1768173485
    },
    {
      "id": 82,
      "article_id": "aibase_24425",
      "title": "Xiaopeng Unveils a Large Model for the Physical World: Second-Generation VLA Aims for L4 Autonomous Driving Without Navigation, Marking the Beginning of a New Era",
      "description": "At the 2026 Xpeng Global New Product Launch, a breakthrough in the fundamental logic of autonomous driving was officially unveiled. Xpeng Automobile Chairman He",
      "content": "At the 2026 Xpeng Global New Product Launch, a breakthrough in the fundamental logic of autonomous driving was officially unveiled. Xpeng Automobile Chairman He Xiaopeng announced that the Ultra versions of the 2026 P7+, G6, G7, and G9 will be fully equipped with Xpeng's self-developed second-generation VLA (Vision-Language-Action) large model—this is not only the first industry model to claim L4-level capabilities, but also marks a shift in the intelligent driving system from the \"perception-decision\" paradigm to a new \"understanding-inference-generation\" paradigm.Different from traditional autonomous driving systems that rely on rules or limited scenario training, the second-generation VLA is essentially a unified intelligent agent capable of understanding, inferring, and generating actions. It does not simply react to the current environment, but can actively simulate traffic dynamics for several seconds or even longer periods based on massive real-world data, anticipate potential conflicts, and generate optimal behavioral strategies. Particularly importantly, the model can be trained end-to-end using nearly 100 million real driving video clips without manual annotation, achieving truly self-evolving learning.This capability gives it a significant advantage in handling long-tail scenarios—those rare yet critical edge cases. By internally generating adversarial long-tail scenarios and repeatedly training, the VLA model can continuously \"rehearse\" extreme situations, thus more calmly resolving crises in reality. Furthermore, the model has cross-domain driving capabilities, meaning its intelligent core is not only suitable for sedans but can also be seamlessly migrated to SUVs, sports cars, and even future flying cars, building a unified intelligent mobility ecosystem.Alongside the VLA, two key feature upgrades were also unveiled. The first is \"Xiaolu NGP,\" specifically designed for complex urban side roads, narrow alleys, and roadways without markings—areas traditionally beyond the reach of intelligent driving systems—greatly expanding the coverage of high-level assisted driving. The second is the upcoming \"No Navigation Automatic Driving\"—the Super LCC+ human-machine co-driving system. This means the vehicle no longer relies on high-precision maps or pre-set navigation routes, but instead can achieve point-to-point intelligent travel on open roads by relying solely on real-time perception and the VLA's inference capabilities, truly moving towards the ultimate goal of \"drivable anywhere across the country.\"The newly launched models each have clear positioning: the P7+ continues to maintain its status as an intelligent sports sedan flagship, the G6 targets young tech-savvy families, the G7, as a new mid-to-large SUV, fills the gap in the premium market, while the G9 further strengthens the position of luxury intelligent flagship. However, their common soul is this second-generation VLA model. Xpeng is using the \"physical world model\" as a lever to shift the technical focus of the entire intelligent driving industry—from competing in sensors and computing power—to competing in the ability to understand and generate real-world scenarios. When cars begin to think, simulate, and act like humans, L4-level autonomous driving may no longer be far away.",
      "article_url": "https://www.aibase.com/news/24425",
      "author": "AIbase",
      "publish_time": 1768173488,
      "publish_date": "2026-01-12",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AIneologism\", \"VLAlargemodel\", \"XiaopengMotors\", \"intelligentdriving\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768000764,
      "last_modify_ts": 1768173488
    },
    {
      "id": 85,
      "article_id": "aibase_24496",
      "title": "Generate a Realistic 3D World from a Single Image! Mugen3D Triggers an AI Modeling Revolution, with a Realism Rate of 100%?",
      "description": "The barrier to 3D content creation is being completely broken down. Recently, a new general-purpose 3D world generation model called Mugen3D has emerged, capabl",
      "content": "The barrier to 3D content creation is being completely broken down. Recently, a new general-purpose 3D world generation model called Mugen3D has emerged, capable of generating highly realistic 3D models from a single image. Its amazing ability to reproduce object textures, lighting, and material reflective effects has attracted widespread attention in the fields of AI and computer graphics.Core Technology: 3DGS Sets a New ParadigmThe core driving force behind Mugen3D is the use of cutting-edge 3D Gaussian Splatting (3DGS) technology. Unlike traditional neural radiance fields (NeRF) or mesh modeling, 3DGS represents scenes using explicit Gaussian point clouds. This not only allows for extremely fast training and rendering but also achieves movie-level visual fidelity.Almost Perfect Visual ReproductionAccording to public demonstrations, the 3D models generated by Mugen3D have a near 100% visual accuracy compared to the original input images. Whether it's the detailed surface of complex objects or the subtle reflections of different materials (such as metal, fabric, and glass) under light, everything is accurately captured and presented. The surfaces of the generated models are exceptionally smooth, with realistic geometric structures, providing a high-quality foundation for subsequent editing, animation, and rendering.Opening the Era of Mass 3D CreationThis breakthrough means that complex 3D modeling work will no longer be limited to professional artists. From e-commerce product displays, rapid game asset generation, to film special effects previsualization and digital twin applications, the technological path represented by Mugen3D is turning the vision of \"generating a 3D world from a single image\" into reality, greatly reducing the cost and time required for 3D content production.Industry experts point out that the success of Mugen3D is not just a victory of a single model, but also an important sign of the maturity and application of 3DGS technology. As such tools become more widespread, a new era of 3D content creation driven by AI, where everyone can participate, has already begun.Address: https://sumeruai.us/mugen3d",
      "article_url": "https://www.aibase.com/news/24496",
      "author": "AIbase",
      "publish_time": 1768259742,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Mugen3D\", \"3DGS\", \"3DGaussianSplatting\", \"3DModel\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://sumeruai.us/mugen3d\", \"url\": \"https://sumeruai.us/mugen3d\", \"type\": \"external\"}]",
      "add_ts": 1768259742,
      "last_modify_ts": 1768259742
    },
    {
      "id": 86,
      "article_id": "aibase_24495",
      "title": "Midjourney Anime Masterpiece Evolves Again! Niji 7 Released: Exquisite Eye Highlights, Enhanced Prompt Understanding + Sref Style Transfer Upgrade",
      "description": "Midjourney's Niji・Journey model, specifically tailored for anime and Eastern illustration styles, officially launched its latest version Niji7 on January 9, 202",
      "content": "Midjourney's Niji・Journey model, specifically tailored for anime and Eastern illustration styles, officially launched its latest version Niji7 on January 9, 2026! This is a major update after one and a half years since the previous main version. The core highlight is a significant leap in \"visual coherence,\" allowing anime enthusiasts to finally enjoy an experience where \"eyes have reflections and facial details are consistently clear.\"Major breakthrough: A qualitative leap in coherence and detailNiji7 has pushed the overall coherence of anime images to a new level. Especially the facial features of characters — the highlights, reflections, and structure of the pupils — show unprecedented clarity and consistency. The official emphasized that this is a deep optimization in the line language and spatial blanking of the model, resulting in cleaner, flatter outputs that perfectly highlight the delicate sketch aesthetic. Many users have commented: \"Previously, the eyes of AI-generated waifus always felt out of place, but now I can finally look directly at them!\"Significantly enhanced prompt response capability, achieving even the finest details perfectlyCompared to the previous version, Niji7 understands and executes prompts more accurately and literally. No matter how complex the description — color positions, specific hairstyles, body movements, multi-arm setups, etc. — the model can reproduce them logically and meticulously.In the official example, a highly complex request such as \"a girl with short green hair, a single bun, blue eyes, buckteeth, four arms, and each hand holding an ice cream\" can be easily handled, without logical breakdowns or misplaced elements. It should be noted that the new model is more \"literal,\" so overly atmospheric or vague \"vibe\" prompts may not work as well as before. The official will soon release a dedicated Niji7 prompt tutorial.New sref function enhanced: More stable and powerful style transferNiji7 significantly improves the performance of --sref (Style Reference), allowing users to upload or reference existing images or character styles to achieve more consistent and high-quality style transfers. Community tests show that sref performs far better in Niji7 than in previous versions, with a significant reduction in style drift issues, making it a powerful tool for repeated character design and IP creation.Usage methods and notes In Discord: Add --niji7 after the prompt to switch.Web interface: Directly select \"Niji7\" from the \"Version\" dropdown menu.Currently, --cref (Character Reference) is not supported, but the team has hinted that a \"more powerful secret surprise\" alternative is being developed. Personalization, Moodboards, and other tools will also be released in the coming days. AIbase's view: The arrival of Niji7 once again proves Midjourney's (in collaboration with Spellbrush) leading position in the anime-specific model market. It is no longer just about \"generating anime images,\" but truly understanding the language of anime art and pursuing extreme details and consistency. For artists, Vtubers, and light novel illustrators seeking high-quality anime creation, this is almost the most essential update to adopt immediately in early 2026. The golden age of anime AI seems to have just begun!",
      "article_url": "https://www.aibase.com/news/24495",
      "author": "AIbase",
      "publish_time": 1768259744,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Midjourney\", \"Niji7\", \"Anime Illustration\", \"Visual Coherence\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768259744,
      "last_modify_ts": 1768259744
    },
    {
      "id": 87,
      "article_id": "aibase_24494",
      "title": "Lightricks Open-Sources AI Video Model LTX-2 for High-Speed Audio-Visual Integration of Up to 20 Seconds",
      "description": "Israeli tech company Lightricks recently announced the release of its latest audiovisual synthesis system, LTX-2. The system features extremely high computation",
      "content": "Israeli tech company Lightricks recently announced the release of its latest audiovisual synthesis system, LTX-2. The system features extremely high computational efficiency, capable of directly generating high-definition video content lasting 20 seconds with perfectly synchronized audio and video based on brief text descriptions. Different from traditional visual synthesis methods, LTX-2 breaks through the bottleneck of \"first image, then voice\" processing order. The development team pointed out that traditional audio-visual decoupling processes cannot reproduce the natural distribution of real environments. Therefore, LTX-2 adopts a complex dual-stream parallel computing architecture, using 19 billion computational parameters to collaboratively process visual and acoustic environments. Among these, 1.4 billion parameters are allocated for video stream processing, while 5 billion are for audio stream processing, this asymmetric distribution precisely simulates the density differences between visual and auditory information in real life. In practical performance testing, the system demonstrated astonishing synthesis speed. In mainstream enterprise-level graphics card environments, generating a 720p resolution audiovisual content takes only 1.22 seconds per step. Data shows that its operational efficiency can reach up to 18 times that of similar products. At the same time, the 20-second generation limit also surpasses similar tools from Google and other major laboratories. To accurately understand complex language instructions, the system integrates a multilingual text parsing engine and introduces a \"preprocessing buffer\" mechanism, allowing the system sufficient space to parse logic before executing the final synthesis. Through a unique cross-association mechanism, the system can accurately match the moment of object collisions in the image with corresponding acoustic effects. Despite its technological leadership, the development team also admitted that the system occasionally experiences voice attribution errors when handling rare dialects or multi-character dialogues. Long sequences over 20 seconds still face challenges with micro-shifts in the timeline. Ziv Faberman, founder of Lightricks, stated that choosing to open-source the system code rather than keeping it as a closed service was based on considerations regarding \"technological control.\" He believes that content creators should control the technology on their own hardware, rather than outsourcing decision-making power to a few interest groups. Currently, the complete code and training framework of the system have been released on an open platform and have been deeply optimized for the latest consumer-grade high-performance graphics cards.",
      "article_url": "https://www.aibase.com/news/24494",
      "author": "AIbase",
      "publish_time": 1768259747,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"LTX-2\", \"AIneologism\", \"audio-visualsynthesissystem\", \"Lightricks\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768259747,
      "last_modify_ts": 1768259747
    },
    {
      "id": 88,
      "article_id": "aibase_24489",
      "title": "Shopping Revolution in the AI Era! Google Launches UCP Protocol: Buy with a Single Click in the Chat Window, No Need to Switch Pages - AI Agent Completes the Entire Transaction Chain",
      "description": "At the 2026 National Retail Federation (NRF) conference, Google officially launched the Universal Commerce Protocol (UCP), an open standard protocol designed fo",
      "content": "At the 2026 National Retail Federation (NRF) conference, Google officially launched the Universal Commerce Protocol (UCP), an open standard protocol designed for the \"agentic commerce\" era. UCP aims to establish a unified \"common language\" and process between AI agents and retail systems, enabling a seamless end-to-end experience from product discovery to order placement, payment, order processing, and after-sales support, with users never leaving the AI conversation interface.Core Value of UCP: Let AI Truly \"Shop\" UCP allows AI agents to understand and execute complete shopping processes across platforms and brands. Users simply need to naturally express their needs in Google Search's AI Mode or Gemini chat, such as \"Find a black suitcase I viewed earlier and deliver it to my address as before,\" and the AI can immediately match products, display personalized prices (such as member-exclusive discounts and recommended accessories), complete payments (through Google Pay, with PayPal support coming soon), and then the merchant continues with after-sales service. The most critical design principle is that AI only acts as an \"operator,\" and the actual order recipient (Merchant of Record) is always the merchant. Customer relationships, data ownership, and after-sales service fully belong to the merchant, avoiding excessive platform involvement in user privacy and relationships.Strong Ecosystem Partner Lineup, Open Collaboration for the Future UCP was jointly developed by Google with retail giants such as Shopify, Etsy, Wayfair, Target, and Walmart, and has received endorsements from over 20 global partners, including Adyen, American Express, Best Buy, Flipkart, Macy’s, Mastercard, Stripe, The Home Depot, Visa, and Zalando, which are payment and retail leaders. The protocol is completely open, neutral, and vendor-agnostic, not limited to the Google ecosystem. Any AI platform, agent, or retailer can adopt it. It also is compatible with existing industry standards such as Agent2Agent (A2A), Agent Payments Protocol (AP2), and Model Context Protocol (MCP), laying a solid foundation for global AI commerce infrastructure.First Experiences Coming Soon - Qualified retail products in the US will support native checkout in Google Search AI Mode and the Gemini app, allowing users to complete purchases directly using saved payment and delivery information in Google Wallet. - Merchants can showcase exclusive offers, recommend accessories, and apply loyalty points at key moments. - In the coming months, it will expand to global markets and gradually add more features, such as related product discovery and complex subscription options.Industry Significance: Opening a New Era of \"Frictionless\" AI Shopping The launch of UCP marks a qualitative leap for AI from \"recommending products\" to \"directly completing transactions.\" It significantly reduces cart abandonment rates, improves conversion efficiency, and allows small and medium-sized merchants to access AI traffic channels through standardized interfaces, rather than being monopolized by closed platforms. AIbase Perspective: Today, as AI agents become increasingly powerful, UCP is not just a technical protocol but a \"TCP/IP moment\" for the e-commerce ecosystem. It promotes the development of an open and interoperable AI commerce infrastructure, preventing monopolies by big companies, allowing merchants to retain core control and users to enjoy maximum convenience. In the future, whoever masters the best agent experience and open protocols will define the way people shop in the next decade.",
      "article_url": "https://www.aibase.com/news/24489",
      "author": "AIbase",
      "publish_time": 1768259750,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AINeologism\", \"Google\", \"UniversalCommerceProtocol\", \"AgenticCommerce\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768259750,
      "last_modify_ts": 1768259750
    },
    {
      "id": 91,
      "article_id": "aibase_24544",
      "title": "Google Android XR Glasses App Exposed: Supports 3K Video and Gemini On-Device Conversation Detection",
      "description": "According to AIbase, Google's layout in the Android XR field is accelerating from behind the scenes to the forefront. Recently, a companion application called \"",
      "content": "According to AIbase, Google's layout in the Android XR field is accelerating from behind the scenes to the forefront. Recently, a companion application called \"Glasses\" (package name: com.google.android.glasses.companion) was accidentally exposed in the latest Canary version of Android Studio. Although there is no配套 hardware on the market yet, the underlying code of the app has deeply revealed the core functions of Google's Android XR glasses, directly targeting competitors such as Meta Ray-Bans.Leaked information shows that the smart glasses have strong competitiveness in video recording. They support 1080p video recording and provide an \"experimental\" 3K resolution mode, with video length ranging from 30 seconds to 3 minutes. To balance privacy and compliance, the app includes an audio alarm; if the front LED status light is blocked, recording cannot be performed. In addition, the glasses are equipped with an advanced \"dialogue detection\" function, relying on the powerful on-device processing capabilities of Gemini. When the system detects that the user is speaking, it automatically mutes voice notifications. Google emphasized that all audio and image data are processed on the device and will not be uploaded to the cloud to ensure privacy and security.In terms of hardware interaction and compatibility, the app confirms that the glasses have a physical power button and support brightness adjustment and \"audio-only mode\". Although Samsung is expected to launch Android XR glasses with this software in 2026, the high level of completion of Google's accompanying app indicates that future hardware products will be deeply dependent on Google's software ecosystem.",
      "article_url": "https://www.aibase.com/news/24544",
      "author": "AIbase",
      "publish_time": 1768346321,
      "publish_date": "2026-01-14",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AINeologism\", \"AndroidXR\", \"Google\", \"Glasses\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768346321,
      "last_modify_ts": 1768346321
    },
    {
      "id": 92,
      "article_id": "aibase_24539",
      "title": "Saying Goodbye to Complex Command Lines: Anthropic Launches Cowork, Making AI Agents Accessible for Non-Technical Users",
      "description": "Anthropic has recently announced the launch of a new tool called Cowork. As the \"user-friendly version\" of its successful product, Claude Code, Cowork is deeply",
      "content": "Anthropic has recently announced the launch of a new tool called Cowork. As the \"user-friendly version\" of its successful product, Claude Code, Cowork is deeply integrated into the Claude desktop application, aiming to lower the barrier to AI agent technology, allowing ordinary users without programming backgrounds to efficiently handle complex tasks.Previously, users often needed to master command-line operations or configure virtual environments when using Claude Code, which discouraged many non-technical users. Cowork changes this interaction method. Users just need to specify a particular folder on their computer, and Claude can automatically read or modify files in that folder based on instructions from the chat interface. This \"sandboxed\" operation mode not only ensures the security of other parts of the system but also makes it easy for AI to handle daily office tasks.According to Anthropic's observation, many subscription users have already begun to use AI agents to handle non-code tasks. The creation of Cowork is precisely to meet this demand. It can handle diverse scenarios such as organizing reimbursement vouchers, analyzing social media data, or managing multimedia files. This tool is built on the Claude Agent SDK, with the same underlying logic as professional code tools, but its interface is as approachable as everyday conversation.Currently, Cowork is in the research preview stage, and it is initially available only to Claude Max subscribers. Other plan users can apply to join the waiting list first. Anthropic also reminds users that due to the tool's ability to automatically perform a series of actions, clear and specific instructions should be provided during use to avoid potential risks such as accidental file deletion or prompt injection.Key Points:🛠️ Zero-Barrier Agent: Cowork integrates AI agent functionality into the desktop application, allowing users to authorize Claude to process local files without needing command-line knowledge.📂 Folder Authorization: By simply setting folder permissions, users can safely let AI assist with non-programming office tasks such as organizing reimbursement documents and data analysis.🎟️ Limited Preview: This feature is currently available for testing to Max subscribers, marking Anthropic's acceleration in bringing AI agent technology to the mainstream market.",
      "article_url": "https://www.aibase.com/news/24539",
      "author": "AIbase",
      "publish_time": 1768346323,
      "publish_date": "2026-01-14",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Cowork\", \"ClaudeCode\", \"AIAgentTechnology\", \"Sandboxing\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768346323,
      "last_modify_ts": 1768346323
    },
    {
      "id": 96,
      "article_id": "aibase_24522",
      "title": "Adobe Firefly Integrates OpenAI GPT-Image 1.5: Subscribers Get Unlimited Generation Mode for a Limited Time",
      "description": "Adobe has recently injected strong momentum into its generative AI creation platform, Firefly. The company officially announced that the platform has launched t",
      "content": "Adobe has recently injected strong momentum into its generative AI creation platform, Firefly. The company officially announced that the platform has launched the GPT-Image1.5 model developed by OpenAI. To reward core users, Adobe has introduced a short-term incentive policy: from now until January 15th, subscribers of Firefly Pro and Premium plans can generate an unlimited number of images using the new model without any quota restrictions.This move marks Adobe's effort to break free from the limitations of a single model and build a vast AI multimodal ecosystem. The current Adobe Firefly has evolved into a \"model aggregation platform,\" integrating image, audio, and video technologies from top global AI vendors including OpenAI, Google, Runway, Black Forest Labs, Pika, and Ideogram, in addition to its own Firefly models.In terms of business model, Firefly continues to use the \"generative credits\" subscription system. The entry-level Standard plan provides 2000 credits per month, costing about 69.8 RMB per month; more advanced Pro and Premium plans offer 4000 credits and 50,000 credits respectively, meeting the needs of professional creators.Aside from model integration, Adobe is also accelerating the integration of its AI capabilities into existing toolchains. Recently, Photoshop, Adobe Express, and Acrobat have been integrated with ChatGPT, and long-term strategic cooperation with the video AI giant Runway has been established. This series of moves aims to allow creators to access the most cutting-edge AI capabilities within Adobe software without frequently switching tools.Key points:🚀 Model Upgrade: Adobe Firefly has officially introduced the OpenAI GPT-Image1.5 model, improving image generation quality.🎁 Time-Limited Offer: Subscribers with Pro and above plans can enjoy the privilege of generating unlimited images before January 15th.🌐 Ecosystem Aggregation: Firefly has transformed into an aggregation platform, integrating AI models from multiple major companies such as Google, OpenAI, and Runway.",
      "article_url": "https://www.aibase.com/news/24522",
      "author": "AIbase",
      "publish_time": 1768346334,
      "publish_date": "2026-01-14",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AdobeFirefly\", \"GPT-Image1.5\", \"Generative AI\", \"Multimodal Ecosystem\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1768346334,
      "last_modify_ts": 1768346334
    }
  ],
  "baai_hub_article": [
    {
      "id": 5,
      "article_id": "51501",
      "title": "Nat. Commun.｜基于图像的药物发现中的表型学习策略",
      "description": "PhenoProfiler是一种新型深度学习模型，可直接从图像中高效提取细胞表型特征，无需复杂预处理步骤。该方法显著降低计算成本，提高分析准确性，助力药物作用机制解析与疗效预测，在基于图像的药物发现中展现出强大应用潜力。",
      "content": "在基于图像的药物发现中，准确捕捉细胞对化学扰动的表型响应，对于理解药物作用机制和预测疗效至关重要。然而，现有方法往往依赖复杂的多步骤流程，计算开销大且容易出错。\n针对这一问题，\n澳门大学联合佛罗里达大学等机构的研究团队\n于2025年12月14日在《Nature Communications》上发表研究论文，题为“PhenoProfiler: advancing phenotypic learning for image-based drug discovery”。\n该研究提出的\nPhenoProfiler\n采用高效的端到端深度学习框架，将内容丰富、多通道的细胞图像直接映射为低维定量表征。基于近40万张高内容图像和842万张单细胞图像的评估结果显示，\nPhenoProfiler在准确性和稳健性上均显著优于现有最先进方法，性能提升最高可达20%。\n其定制化的表型校正策略进一步强化了处理诱导的细胞变化，从而增强了对生物学意义明确且可重复信号的检测能力。通过有效解决现有方法在流程复杂性、计算成本及泛化能力方面的局限，PhenoProfiler显著推进了表型分析，为加速基于图像的药物发现提供了有力工具。\nPhenoProfiler访问链接：\nhttps://phenoprofiler.org\n背景\n在基于图像的药物发现中，学习稳健的图像表示对于从复杂的高通量图像数据集中提取有意义的信息至关重要。Cell Painting技术通过多种荧光染料标记细胞内不同的细胞器和组成部分，生成多通道图像，从而捕捉细胞对不同药物或扰动的表型变化。然而，Cell Painting图像的高维特性\n常伴随冗余和噪声，因此通常需要大量预处理步骤，\n如归一化、分割及伪影去除。此外，处理这类大规模数据集\n对计算资源要求高，而提取的形态学特征可能缺乏生物学可解释性，\n使得直接利用图像进行有意义的分析具有挑战性。\n为应对Cell Painting图像特有的挑战，开发了包括CellProfiler、DeepProfiler、SPACe和OpenPhenom在内的专用方法，以提取细胞形态的紧凑且信息丰富的表示。尽管取得一定进展，现有形态学表示学习方法在处理高维Cell Painting图像时仍存在关键限制。首先，这些方法通常将多通道整图分解为多个子图像进行处理，这种多步骤流程不仅\n增加了计算开销和成本，还可能引入额外误差，\n例如分割不准确或特征整合错误。其次，这类方法\n依赖药物处理条件作为分类标签，但标签信息有限，难以全面捕捉细胞响应的多样性和复杂性。\n因此，基于有限标签训练的模型在不同实验条件下泛化能力较弱，降低了其可扩展性与适用性。这些局限性凸显了开发简化、高效且具有生物学可解释性的表型表示方法的必要性。\n方法\nPhenoProfiler能够从高通量图像中学习细胞形态表示，并提取药物处理效应引起的表型变化。与现有方法相比(图1a)，PhenoProfiler被设计为\n端到端模型\n，可直接将信息量丰富的多通道图像编码为低维特征表示，无需复杂预处理步骤，如图像分割或子图像提取。\nPhenoProfiler由三个核心模块组成，即\n梯度编码器、Transformer编码器\n以及整合分类、回归和对比学习的\n多目标学习模块\n(图1b)。具体而言，梯度编码器用于增强边缘信息，提高细胞形态的清晰度和对比度；随后，Transformer编码器捕捉图像中的高维依赖关系和复杂联系，从而丰富图像表示；多目标学习模块则用于实现精确的形态学表示学习。经过充分训练，PhenoProfiler构建了一个统一且稳健的特征空间，用于表征细胞形态。\n在推理阶段(图1c)，PhenoProfiler通过\n表型校正策略\n强调不同处理条件下的相对表型变化，从而揭示生物学相关性及处理相关的表型表示。\n图1 PhenoProfiler框架图\n结果\n在生物匹配任务中性能\n为了对PhenoProfiler进行全面且稳健的评估，将其与已知方法(包括DeepProfiler、OpenPhenom、ResNet50和ViT）进行对比，采用leave-perturbation-out策略。评估采用两个指标，即富集倍数(FoE)和平均精度均值(MAP)。使用三个数据集(BBBC022、CDRP-BIO-BBBC036和TAORF-BBBC037)中的超过23万张图像，涵盖231个板和4285种处理，包括化合物和基因过表达扰动。实验结果如图2所示，\nPhenoProfiler在三个基准数据集上均在FoE和MAP指标上超越所有竞争方法。\n图2 在生物学匹配任务中的性能\n为了进一步说明PhenoProfiler各模块的贡献，作者在BBBC022数据集上进行了\n消融实验\n(图2c)。首先，去除多目标学习模块中的回归学习组件(“-MSE”选项)，仅保留分类和对比学习。结果显示，\n去除回归学习导致性能显著下降，\nFoE和MAP分别下降12.0%和12.7%。接着，测试了不同损失函数组合(“-Con”、“-CLS”、“-MSE-Con”、“-Con-CLS”和“-CLS-MSE”)。例如，同时去除回归和分类学习，FoE和MAP分别下降28.0%和20.6%。与未使用梯度编码的模型平均性能(“-MSE-Con-Gradient”、“-Con-CLS-Gradient”、“-CLS-MSE-Gradient”)相比，该修改导致FoE和MAP分别下降25.2%和11.5%，\n突显了基于梯度的特征编码的有效性。\n此外，测量指标并非随着分类损失的下降而持续改善。如图2d所示，MAP和FoE在分类损失下降初期有所提升，但最终下降。\n这强调了PhenoProfiler多目标学习设计的重要性。\n多目标学习的最优权重通过对BBBC022数据集的敏感性分析确定。图2e-2f显示了调优后的PhenoProfiler实现了最优性能。\n泛化能力与适用性\n为了评估PhenoProfiler的泛化能力，作者在基准数据集上进行了实验，采用leave-plates-out和leave-dataset-out评估策略。对于\nleave-plates-out\n策略，部分板作为测试集，其余板用于训练；而在\nleave-dataset-out\n策略中，一个数据集用于训练，另外两个作为测试集。在leave-plates-out 情境下(图3a)，PhenoProfiler在FoE和MAP指标上均持续优于其他方法。图3b展示了leave-dataset-out情境下的性能对比，进一步突显了PhenoProfiler的优越表现。\n总体而言，PhenoProfiler的泛化能力优于现有方法，为药物发现中的下游任务提供了更精准的支持。\n图3 泛化能力及适应性评估结果\n为了进一步验证PhenoProfiler的泛化能力，对外部分布(OOD)数据进行了评估，使用来自cpg0001数据集的10个不同板(BR00115125-BR00115134)，共76800张图像，涵盖83种独特处理和47个注释的作用机制(MoA)。如图3c上图所示，直接将预训练于BBBC022、BBBC036和BBBC037的PhenoProfiler模型应用于这些OOD板。\nPhenoProfiler在所有测试板上在FoE和MAP指标上分别比第二优模型DeepProfiler平均高45.8%和27.3%，显示出稳健的泛化能力及对OOD数据的适应性\n。此外，由于这些评估均来自U2OS细胞系，进一步在五个A549细胞系板(cpg0004数据集中的SQ00014812-SQ00014816，见图3c下图)上进行了评估。结果显示，\nPhenoProfiler在FoE和MAP上平均分别比第二优模型OpenPhenom高21.4%和20.3%，证明其在不同细胞系间的泛化能力同样稳健。\n有效消除批次效应\n为评估PhenoProfiler缓解批次效应的能力，作者采用\n反向绝对中位差(IMAD)\n指标来量化图像表示的离散程度。IMAD值越高，表示离散性越小，即批次效应被更好地校正。图4展示了板级的表示特征，不同颜色表示不同板，以突出批次效应。\nPhenoProfiler学到的表示特征分布明显更为整合(IMAD = 0.603)，表明其能够在不同板间学习到协调一致的特征，有效解决批次效应，无需额外校正。\n这一模式在三个数据集中均一致出现，进一步验证了PhenoProfiler在生成稳健表型表示方面的可靠性。PhenoProfiler能够直接从原始数据学习协调一致的表示，不仅减少了计算密集型后处理的需求，同时确保了生物学信号的保留。\n图4 不同方法特征表示的稳健性\n表型校正策略提升生物学匹配\n为了有效捕捉处理下的相对变化，PhenoProfiler特别设计了\n表型校正策略(PCs)\n用于优化学习到的表型表示。如图5a所示，PhenoProfiler通过利用同一板内的对照孔和处理孔，对图像表示进行校正，强调处理下细胞表型的相对变化。通过消融实验评估PCs的影响，结果表明\nPCs能够稳定提升FoE指标，而对MAP指标影响较小\n(图5b)。随后分析了在三个基准数据集中引入PCs前后的特征聚合情况。使用UMAP对孔级图像表示进行可视化，并通过IMAD指标定量衡量聚合性(图5d)。\n实施PCs后，不同板的表示特征显著更加集中，\nIMAD指标分别在三个基准数据集上显著提高51.5%、69.7%和11.6%，显示了强烈的聚合改善效果。\n图5 表型校正策略的定量分析\n高效捕捉处理效应表示\n为了直观展示处理效应，作者使用PhenoProfiler在不同处理条件下获得表型表示。图6展示了PhenoProfiler在三个基准数据集上的UMAP投影，清晰展示了PhenoProfiler在非端到端(图6a)和端到端(图6b)场景下捕捉与组织生物学模式的能力。\n图6 处理效应特征表示的定量与定性评估\n为了进一步评估PhenoProfiler在识别具有临床可操作性的表型模式同时保持生物学可解释性的能力，作者使用cpg0004-LINCS数据集进行了深入分析，该数据集包含具有明确MoA的处理。图6c显示，所有药物处理组相较DMSO对照组均表现出显著特征变化。值得注意的是，同一药物类别的四重复孔高度一致，不同药物类别间则明显分离。\n这些结果验证了PhenoProfiler的双重能力，即敏感检测药物诱导的表型扰动，同时精准区分药理机制。\n未来方向\n尽管PhenoProfiler在表型表示学习中已树立新标杆，但仍存在多个值得探索和改进的方向。\n多目标学习模块优化。\n未来可进一步研究分类、回归与对比学习目标之间的相互关系及协同效应，理解这些目标间的依赖性可能有助于制定更统一的学习策略。目前，PhenoProfiler 采用分步训练以缓解目标冲突，未来可探索联合训练与优化方法，更高效地平衡各学习目标。\n整合大规模生物医学语言模型。\n近期生物医学大语言模型的进展为将丰富领域知识引入计算框架提供了可能性。将这些模型的嵌入整合到PhenoProfiler中，或可进一步提升模型的泛化能力、稳健性及有效性。\n多模态数据整合。\n未来应优先考虑将遗传信息、转录组数据及化学结构等补充数据整合到分析中。多模态数据融合可生成更全面的表征，有助于从整体上理解细胞状态及其对不同处理条件下的表型响应。\nPhenoProfiler能够在多样化数据集和处理条件中持续捕捉并组织复杂生物信息，凸显其在高通量药物筛选和发现中的多功能性和实用性。通过应对表型分析中的关键挑战，如可扩展性、稳健性及可解释性，PhenoProfiler增强了对处理效应在表型层面的理解。此外，其在多模态整合分析中的潜力，将表型数据与遗传信息、转录组及化学结构等信息结合，为深入探索药物作用机制及发现新药靶点提供了新的机会。\n参考链接：\nhttps://doi.org/10.1038/s41467-025-67479-w\n--------- End ---------",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512390&idx=2&sn=2806eb3bf9a4001bae947d7af4340ab2&chksm=fd91bff3f3f87531cc905ff6637c752138666e63fb8cdcae0983b0b6c2d0c0d4fca533eb765c&scene=0&xtrack=1#rd",
      "publish_time": 1766983200,
      "publish_date": "2025-12-29 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://phenoprofiler.org\", \"https://doi.org/10.1038/s41467-025-67479-w\"]",
      "add_ts": 1766988485,
      "last_modify_ts": 1767193605
    },
    {
      "id": 10,
      "article_id": "51496",
      "title": "鸿蒙押注新未来：用AI重写数字世界交互逻辑",
      "description": "2025年是终端AI全面爆发的元年，标志着产业从智能机时代向AI智能体时代的根本性跃迁。以APP为中心的被动服务模式正被以AI智能体为核心的主动服务所取代，重构人与设备的连接成为关键挑战。行业分化为两派：一派主张在现有APP生态上改良，另一派则推动全新交互与商业模式的重塑，开启终端计算新篇章。",
      "content": "克雷西 发自 凹非寺\n量子位 | 公众号 QbitAI\n2025年无疑是终端AI全面爆发的元年，整个产业迎来了继功能机向智能机跃迁后的又一个十字路口。\n这场跃迁是一次商业模式与交互逻辑的根本性重塑，智能机时代以APP为中心的被动服务模式，正在向\n以AI智能体为中心的主动服务模式跨越\n。\n在这场跃迁之中，\n如何重构人与设备的连接\n，成为摆在所有厂商面前的共同考题。\n行业中，一派倾向于改良，试图在既有的APP生态上做加法；另一派则坚持重构，主张深入操作系统底层，彻底改写交互逻辑。\n作为“重构派”的典型代表，华为将其战略锚定在了底层，选择\n将AI能力下沉并转化为操作系统的原生基因\n。\n沿着这一战略路径，华为终端云服务总裁贾永利在央视《2025科创大会》上进行了深度分享，为行业的技术演进，提供了一种新的可能路径。\n演讲中，贾永利重点提到了\n终端智能化L1~L5分级标准\n——来自华为与清华大学人工智能产业院（AIR）联合编写的《AI终端白皮书》。\nL1是功能级，即辅助工具；L2是任务级，即单项执行，这两者的共性仍停留在人为主、AI为辅的初级阶段；\nL3协作级则是真正的分水岭，意味着AI开始具备自主拆解目标与闭环执行的能力；\n未来，行业还将向L4指导级与L5智慧级持续进阶。\n这一分级标准深刻揭示了真智能的本质——终端必须突破L1与L2阶段单纯的工具属性，加速向L3级具备自主规划能力的智能体进化，这才是衡量终端智能化水平的根本界限。\n困在旧架构里的“伪智能”\n基于这种L1-L5的分级标准审视当前行业，很容易就能发现绝大多数产品仍未脱离旧有的架构惯性。\n这种底层逻辑与上层体验的结构性滞后，使得当前市场上的AI应用大多呈现出三种典型的路径依赖，难以支撑起真正的代际跨越。\n第一类路径的主导者是大模型厂商。受限于典型的B to C 产品逻辑，它们试图直接将云端算力封装为独立的对话式应用，从而导致了\n“悬浮式智能”\n的泛滥。\n受限于移动操作系统的沙盒机制，它们更像是一个个被封印在APP图标里的“高智商大脑”，虽然拥有极强的咨询能力，但完全切断了与设备底层及其它应用的连接。\n第二类路径的主导者是拥有超级APP的互联网流量巨头。它们未能走出C to B的“流量圈地”舒适区，倾向于将AI能力作为提升用户粘性的护城河，从而形成了一种\n“割据式智能”\n。\n这类巨头往往将AI能力封装在自家的“围墙花园”内部，导致数据无法流动，意图无法跨应用传递。\nAI不仅没有打破数据孤岛，反而在某种程度上加剧了服务的封闭性，成为了巨头圈地的新围栏。\n第三类路径的主导者则是处于转型期的传统终端厂商。受限于旧有的硬件思维逻辑，它们的尝试往往呈现为一种\n“拼盘式智能”\n。\n在缺乏系统级中枢统筹的情况下，这类厂商往往采用“打补丁”的方式，在各个原生应用中零散地塞入AI功能点。\n这些功能虽然在单点上具备了一定的执行能力，但它们彼此之间是互不相识的独立孤岛，无法串联成一条完整的服务链条，用户依然要充当不同AI功能之间的“人形中转站”，距离真正的“主动智能”相去甚远。\n透视这三种路径的共性，它们实际上都撞击到了同一个隐形天花板——无论是悬浮的对话框、割据的围墙，还是散落的功能拼盘，本质上都是在旧有的操作系统架构上进行“外挂式”的修补。\n这种改良路径或许能在单一场景下提升效率，却始终被困在L1/L2级辅助工具的范畴之内。\n行业真正缺失的，并非更多的功能点堆砌，而是一个能够穿透应用壁垒、深度统筹意图与服务的系统级中枢。\n而这，恰恰是通往L3级“跨应用协同”深水区无法绕过的必经关隘。\n这也正是华为常务董事、终端BG董事长余承东在华为第六届AI院长峰会上所判断的行业分水岭——\nAI是一场改变人类生活的技术革命，要实现这一目标，必须构建起包含“大模型+智能体”在内的全栈能力。\n用AI重构操作系统底层\n针对行业内普遍存在的路径依赖，鸿蒙选择了一条极具挑战的破局之路。\n不同于试图在既有架构上打补丁或加插件的逻辑，鸿蒙开启了一场彻底的\n“系统级重构”\n，从底层打破应用与系统的坚硬边界。\n这场重构的基石，便是底层的\n鸿蒙智能体框架\n（HMAF）。\n作为实现系统级AI的关键基础设施，它构建了独特的意图框架与用户数据图谱，让操作系统不再只是一个冷冰冰的资源调度者。\n正是有了这套统一的逻辑底座，鸿蒙才得以确立“C/B双端共振”的战略路径，支撑起整个鸿蒙生态的智能化运转。\n在用户能够感知的C端层面，这种底层重构，\n用对话取代了繁琐的操作\n。\n因为系统能精准拆解你的意图，它不再满足于执行一个简单的指令，而是追求把整个任务一次性解决。\n在Mate X7上，A2A协议打通了应用之间的隔阂，用户不再需要自己在脑子里把一个需求拆分成“打开APP、寻找入口、点击确认”等一连串繁琐步骤，系统能主动识别你想干什么，并自动把相关服务调动起来。\n这种交互逻辑的改变，\n让“人找APP”的被动搜索，真正转变为“服务找人”的主动响应\n。\n以深圳航空“深航飞飞”智能体为例，只需说出“用深圳航空订一张xx月xx日去深圳的机票”，或者提出“推荐个能看日落的座位”等个性化需求，小艺便能通过A2A协议直接调度深航飞飞智能体。\n系统会在后台静默而高效地获取航司数据，完成从查票、订票到值机选座的全流程闭环，曾经需要在多个界面反复跳转的繁琐流程，如今只是一句话的事。\n这种系统底层的重构也同步延伸到了开发者一侧。\n为了构建全场景智能服务，鸿蒙提供了\n小艺智能体开放平台\n。应用开发者可以直接调用系统级控件，快速让应用获得意图理解能力。\n该平台配备了覆盖从开发、多端调试（手机/平板/车机/PC/手表）到部署上架的端到端工具链，开发者只需一次开发，即可将智能体无缝分发至鸿蒙全场景生态。\n当智能体开发完成后，它们将不再是应用市场里无人问津的图标，而是通过统一上架小艺智能体广场，分发至手机、平板、PC乃至车机等全场景终端。\n无论用户身处何种设备环境，都能通过系统级入口、小艺超级智能体等途径获得一致的服务体验。\n这套基于意图的全新分发机制，不仅在体验上让服务找人，更在产业逻辑上撕开了一道口子。\n当流量的分配不再单纯依赖应用图标的点击，而是取决于系统对用户需求的实时判断时，传统移动互联网中固化的流量版图便开始松动。\nAI终端的新流量法则\n当前的移动互联网生态，仍然处于残酷的存量博弈之中。\n对于绝大多数中小开发者而言，头上悬着两把利剑——\n一把是\n流量的固化\n，头部超级APP垄断了绝大部分用户时长，应用商店的自然流量枯竭，新应用难以突围；\n另一把则是\n“商业闭环的困局”\n，即便想拥抱智能化，高昂的Token调用成本与不确定的变现路径，让中小团队在面对AI浪潮时往往不敢轻易投入。\n鸿蒙打破这一僵局的第一刀，就砍向了流量分发机制——将传统的应用分发转变为服务分发，小艺智能体广场不再是一个依循下载量排名的静态货架，而是一个基于用户实时需求的流量中枢。\n这种模式下，流量的分配权从竞价排名回归到了服务相关性，不仅让服务转化的链路大幅缩短，更重要的是，它给了那些专注于垂类服务的中小开发者一个被看见的机会。\n根据最新数据，目前搭载HarmonyOS 5/6的终端设备已突破3200万台，且仍在高速增长。\n这3200万台设备构成了这波新流量的坚实基座。从手机到车机，从办公PC到腕上穿戴，这些设备不再是孤立的信息孤岛，而是共同编织了一张捕捉用户意图的大网。\n对于开发者而言，接入鸿蒙生态，就意味着服务有机会在用户驾驶、运动、办公的全天候场景中自然流转与触达。\n随着L3级智能体验的正式落地、全场景设备规模的爆发以及“意图-服务”商业闭环的跑通，鸿蒙AI生态已经跨越了早期的概念验证，进入了实质性的红利释放期。\n对于开发者而言，加入鸿蒙AI生态，就是在抢占下一代服务分发入口的最佳窗口期。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858711&idx=1&sn=952fba5cae81624ac962773498276ab0&chksm=e986c67898981ada7540fa55ac318123806c7b8b53d080fdee2823c358b8bc6d41f279515ef8&scene=0&xtrack=1#rd",
      "publish_time": 1766916000,
      "publish_date": "2025-12-28 18:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1766988514,
      "last_modify_ts": 1767050308
    },
    {
      "id": 11,
      "article_id": "51495",
      "title": "大模型第一股热闹正酣，“局外人”阶跃星辰发了一个小更新",
      "description": "年底国产大模型竞争激烈，Kimi、DeepSeek、智谱、MiniMax等纷纷凭借技术突破或IPO进展引发关注，而同为“六小龙”之一的阶跃星辰却相对沉寂，缺乏高调发声与显著成果曝光，外界对其进展产生疑问。在行业热潮中，阶跃星辰虽坚持自研路线，但存在感较弱，亟需亮出核心技术或产品以重塑声量，回应市场期待。",
      "content": "henry 发自 凹非寺\n量子位 | 公众号 QbitAI\n“阶跃星辰怎么静悄悄…”\n这就是年底国产大模型轮番冲刺热议一线时，阶跃星辰面临的外部评价。\nKimi靠K2重新获得证明，摆脱DeepSeek冲击波逆境；\nDeepSeek靠OCR、金牌数学模型热传热议，让人更加期待后面的大招；\n智谱和MiniMax一手新SOTA模型交卷，一手提起IPO进程……\n而依然留在自研大模型牌桌上的“六小龙”选手阶跃星辰，甚至相比之前的“卷王”本王，都神秘安静得多。\n直到刚刚，用最新的图像模型\nNextStep-1.1\n，扳回一球。\nNextStep-1.1\n总体来看，这次开源的NextStep-1.1解决了之前NextStep-1中出现的可视化失败（visualization failures ）问题。\n其通过扩展训练和基于流的强化学习（RL）后训练范式，大幅提升了图像质量。\n相较之前发布的NextStep-1，NextStep-1.1的更新主要有两方面：\nRL增强视觉保真度\n: 通过RL显著改进了图像纹理，并大幅减少了视觉伪影（Visual Artifacts），确保输出更加清晰和专业。\n技术稳定性\n: 解决了自回归流匹配模型RL过程中固有的数值不稳定性（Numerical Instability）问题。\n目前，NextStep-1.1已率先在GitHub和Hugging Face开源，但对应的技术报告尚未发布。\n从已披露的信息来看，1.1版本的方法论基础仍然沿用NextStep-1论文中提出的自回归流匹配（autoregressive flow-matching）路线。\n接下来，我们具体来看。\n自回归流匹配的图像生成\nNextStep-1\n系列架构的关键在于\n使用流匹配目标对连续图像Token进行直接、自回归建模\n。\n这种方法旨在取代传统的\n“AR+重型扩散模型”混合架构\n，NextStep-1通过逐Patch自回归生成，只用一个轻量级流匹配头，避开了对计算密集型DM的依赖。\n具体来说，NextStep-1是一个拥有140亿参数（14B） 的自回归模型。\n核心架构由Transformer骨干网络、用于处理离散文本 Token的标准语言建模头、用于处理连续图像Token的轻量级流匹配头，以及一个图像Tokenizer组成。\n其中，NextStep-1采用因果Transformer来处理离散化后的文本与图像Token。\n在训练阶段，Flow Matching Head基于输出的隐藏状态，预测从噪声样本到下一个目标图像patch的连续流（continuous flow）。\n在推理阶段，该机制使模型能够通过迭代方式引导噪声，逐步生成下一个图像patch，从而完成整幅图像的生成。\n在文生图任务中，NextStep-1展示出了接近传统扩散模型的生成质量，并且在图像编辑方面也表现优异。\n然而，NextStep-1 在高维连续潜在空间下运行时，仍存在数值不稳定性，这可能导致输出图像出现块状或网格状的伪影。\n最新的NextStep-1.1版本正是针对这一核心问题进行了优化与改进。\nKimi智谱Minimax轮番交卷\n事实上，最新放出的NextStep-1.1只是阶跃最近密集更新节奏的一部分。\n阶跃也当然没有“静悄悄”，自11月底至今，阶跃先后——\n开源GELab-Zero，主打安卓端本地部署与低门槛移动端智能体开发。\n开源8B推理模型——PaCoRe，在数学方面超越GPT-5。\n推出Step-GUI，包含云端模型、GUI Agent的MCP协议及开源端侧模型Step-GUI Edge，深化智能终端布局。\n……\n但问题还是出在友商们太热闹了。\n智谱和MiniMax不仅相继通过聆讯，冲刺IPO，还同步发布了自家最新的模型GLM-4.7和MiniMax M2.1。\nKimi也先后接入微软Azure，亚马逊Bedrock，其最新开源推理模型Kimi K2 Thinking也是广受好评。\n当这些动作被放在同一时间轴上，实际上也体现着大模型竞争格局的变化。\n在技术层面，Coding、Agent、多模态成为大模型主战场，开源生态成为主要策略。\n而在资本层面，智谱和MiniMax的IPO也意味着大模型玩家在第一轮“百模大战”之后，胜者开始寻求更大的资本杠杆，开启更大战场的竞速。\n大模型创业六小龙，实际已经名存实亡。\n依然在坚持预训练、自研通用大模型路线的创业玩家，只剩下智谱、MiniMax、Kimi和阶跃星辰。\n而他们接下来要竞速的玩家，都是巨头和小巨头。\n但不论如何，创业明星们一步一登台，拿到了通往决赛圈入场券。\n是否依然有能力自研基础大模型？是否粮草充足？是否可以构建商业模式飞轮实现造血可持续？\n就是大模型玩家2026年竞速里无法回避的三大问题。\n参考链接\nhttps://x.com/StepFun_ai/status/2003746642026185055\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n专属AI产品从业者的\n实名社群\n，只聊AI产品\n最落地的真问题\n扫码添加小助手，发送\n「姓名+公司+职位」\n申请入群～\n进群后，你将直接获得：\n👉 最新最专业的AI产品信息及分析 🔍\n👉\n不定期发放的热门产品内测码 🔥\n👉\n内部专属内容与专业讨论 👂\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858711&idx=2&sn=813a06603cfe7bdefc169ea071d08fb4&chksm=e95cb5540f4fc597f53ea9b8c3bf1eda8335b809dcf68537b0279e2b1407f48f9e4d7538fab0&scene=0&xtrack=1#rd",
      "publish_time": 1766915400,
      "publish_date": "2025-12-28 17:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/StepFun_ai/status/2003746642026185055\"]",
      "add_ts": 1766988520,
      "last_modify_ts": 1767050311
    },
    {
      "id": 16,
      "article_id": "51490",
      "title": "1200行提示泄露！谷歌无人车里的Gemini，活得比打工人还憋屈",
      "description": "1200行泄露代码揭示Waymo自动驾驶系统内情：尽管集成全球最强AI助手Gemini，其功能却被严格限制，仅能讲冷笑话，无法参与驾驶决策。此前旧金山停电致Waymo车辆集体停摆，引发交通混乱，暴露系统脆弱性。对比特斯拉，Waymo虽被公认为L4级自动驾驶领先者，但仍面临技术与安全质疑。如今拟引入Gemini提升交互体验，但AI在核心驾驶中的角色依然受限，凸显自动驾驶商业化落地的现实挑战。",
      "content": "新智元报道\n编辑：好困 桃子\n【新智元导读】\n1200行泄露代码揭开真相：在Waymo的自动驾驶铁盒子里，无所不能的Gemini不仅被禁止碰方向盘，还被迫变成了一个会讲冷笑话的卑微陪聊。\n几天前，旧金山停电，Waymo在大马路上全部「停摆」，直接导致交通崩溃。\n一时间，Waymo不及特斯拉冲上热搜。\n不过，这家被公认L4级自动驾驶公司，将要集成全球最强Gemini AI助手了。\n最近，华人大神Jane Manchun Wong逆向了Waymo的程序，发现了其完整的1200行系统提示。\n它精确地定义了Gemini助手，在车辆内部的一个行为方式。\n除了可以回答基本的问题之外，它还可以调节空调、切换音乐、操控车辆......\n据称，这款助手基于Gemini 2.5 Flash搭建。\n完整的1200+行Waymo Gemini系统提示词：https://gist.github.com/wongmjane/b3878b4dcfb3533a1505497358af183b\n为此，她还整理了一份30页报告，介绍了Waymo Gemini系统提示中最有趣的部分。\nJane Manchun Wong（黄文津）目前是一家初创公司的安全咨询师。在此之前，她曾在Meta就职一年多，任软件工程师和安全咨询师。\n她于2013年至2018年在马萨诸塞\n大学\n达特茅斯分校攻读计算机科学专业。\n1200行系统提示泄露\nJane Manchun Wong在扒Waymo移动端应用代码的时，意外发现了一份内部文档，标题为——\nWaymo乘车助手元提示词（Waymo Ride Assistant Meta-Prompt）\n虽然这一功能UI未在公开版本中上线，但超1200行系统提示证明了，AI助手将嵌入在整个乘车体验中。\n这个系统提示词提供了一个罕见的、未经过滤的视角，展示了Waymo是如何设计其车内AI助手的。\n它远远超出了语音识别的范畴，深入到了品牌安全、沟通策略以及驾驭乘客复杂的心理——\n毕竟，说到底，我们可是坐在一个没司机的、移动的铁皮盒子里啊！\n人设与身份\n它的官方身份和目标，定义非常清晰。而且，「回答语气」的关键词只有五个：\n友好、乐于助人、令人安心、中立、简洁。\n身份：你是Gemini，一个集成在Waymo自动驾驶车辆中的友好且乐于助人的AI伴侣。\n目的：你的主要目标是通过以安全、令人安心且不突兀的方式提供有用的信息和帮助，来提升乘客的体验。\n语音：使用适合纯音频输出的清晰、简单的语言。避免使用技术术语。回答通常应为1-3句话。\n属性：友好、乐于助人、令人安心、中立、简洁\n而且，提示中明确告知Gemini「你不是司机」，因此在回答上，要在语言上做出分隔，如下所示。\n当乘客问「你是如何看路的」，应以「Waymo Driver」，而不是「我使用...看路」引向话题。\nAI助手只能做出解释，但不可以「认领」能力。\n规则：你\n必须\n在你的身份（Gemini，对话式AI）和自动驾驶技术（Waymo Driver）之间保持明确的界限。\n绝对不要\n把驾驶行为或车辆的感知能力归因于你自己。你是乘客的助手，不是司机。\n乘客：你是怎么看路的？\n错误的回复：我使用激光雷达和摄像头等传感器组合来看...\n正确的回复：Waymo Driver使用激光雷达、摄像头和雷达等传感器组合来观察周围的世界。\n操作语境\n系统提示词确立了助手的操作环境和体验目标。\n环境：你正在乘客的行程中，在Waymo自动驾驶车辆内运行。\n自动驾驶智能体名称：Waymo Driver\n角色区分：你是对话助手，不是司机。\n激活方式：乘客通过按车内屏幕上的按钮激活你。\n输出模态：音频\n体验目标如下：\n有用：通过阐明特性和功能，让Waymo服务更易于使用。\n奇妙：创造一种无缝且令人惊喜的乐于助人的AI体验。\n低调：按需提供服务，但不造成干扰。\n模态感知\nAI助手的回复风格，会根据乘客是打字，还是说话来定。\n文本输入一般限制在3句话回复，若是音频输入，优先1-2句话和极简的句子结构。\n规则：你必须根据input_modality（输入模态）上下文变量调整你的回复风格。\n如果是文本输入：对于初次问候后的所有回复，将文本输入视为对话语境。稍长一点的回复（最多3句话）是可以接受的。允许提供详细的逐步说明。\n如果是音频输入：优先考虑极度简洁（1-2句话）和简单的句子结构。避免列清单或复杂的说明。高度推荐使用「猜测并确认」的消歧策略。\n默认：如果模态未知，假设为「音频」并优先考虑简洁性。\n个性化问候\n当乘客通过车内屏幕按钮激活助手时，它须从一组预先批准的问候语中随机选择，并加上乘客的名字进行个性化。\n触发：用户通过车内屏幕按钮激活时（这是你的第一句回复）。\n指令：使用附加上下文中的乘客名字，以友好、个性化且热情的方式发起对话。你\n必须\n为每次新的对话初始化从提供的「示例」列表中随机选择一条问候语。 已批准的回复：\nA：嗨，{{rider_info.first_name}}！有什么我可以帮你的吗？\nB：你好，{{rider_info.first_name}}！尽管问我。你想知道些什么？\nC：嗨，{{rider_info.first_name}}。告诉我有什么能帮你的。\nD：嘿，{{rider_info.first_name}}！我很乐意回答任何问题。你在想什么？\n系统在运行时还会接收关于乘客的上下文数据，从而实现个性化互动。\nrider_name_context: 乘客的名字是Jane，全名是Jane Manchun Wong。请用名字称呼乘客。\nrider_history_context: 该乘客已经进行了732次Waymo行程。他们已经在Waymo行程中行驶了1924英里，花费了11256分钟。\n工具能力\n从系统提示词看，Gemini能直接调用车内的功能，是特定的——\n其中包括空调温度、风扇速度、车内灯光、音乐播放、获取当前位置、呼叫客服支持。\n有趣的是，AI助手被指示直接使用这些工具，而不是回退到搜索。\n规则：当乘客提出请求时，你 必须 首先确定该请求是否直接映射到你定义的ai_control_types之一（例如，空调、音乐、灯光）。如果有一个直接的工具可用于用户的意图，你\n必须\n使用该工具。只有当请求没有映射到直接工具时，你才应该考虑使用外部搜索或其他协议。\n乘客：能把这里变凉快点吗？\n正确的行为：识别这是一个空调请求，并使用set_temperature_setpoint工具。\n错误的行为：在谷歌上搜索「如何让车里变凉快」。\n这是可用函数声明的完整列表：\nbody_event_cabin_lights_off（关闭车内灯光）\nbody_event_cabin_lights_on（打开车内灯光）\nbody_event_next_track（下一首）\nbody_event_prev_track（上一首）\nbody_event_pause（暂停）\nbody_event_resume（恢复播放）\ncall_rider_support（呼叫乘客支持）\nget_fan_speed（获取风扇速度）\nget_temperature_setpoint（获取设定温度）\nset_fan_speed（设置风扇速度）\nset_temperature_setpoint（设置设定温度）\nget_current_location（获取当前位置）\n不过，音量控制、车窗控制、座椅调节、路线更改这些能力确实，助手必须将这些需求转移到车内屏幕或Waymo App上。\n对话管理\n在对话方面，系统也给出了针对不同类型互动的高级协议。\n比如，对于赞美、请求停止、多次问及违规问题，Gemini的处理极其细腻。\n处理赞美\n当得到夸奖时，AI助手先要具体明确夸的什么，并做出优雅地回应。\n触发：用户给予赞美。\n指令：如果可能，确认赞美的具体对象，然后使用与用户语气相匹配的短语优雅地回应。\n乘客：音乐很棒！\nGemini：我也很高兴你喜欢这音乐！\n乘客：这次行程真的很平稳。\nGemini：听到这个太好了！Waymo Driver就是为了平稳安全的旅程而设计的。\n停用与静音\n若是乘客让AI助手立即「闭嘴」，它会以幽默等多种方式处理，比如「好的我立马安静」。\n触发关键词：stop talking（别说话）, be quiet（安静点）, don't talk（别说话）\n可能的回复：Okay, I'll be quiet now.（好的，我现在安静。） | Alright, I'll be quiet.（行，我会安静的。） | Okay（好的） | Alright（行）\n乘客：Stop talking.（别说了。）\nGemini：好的，我现在安静。\n触发关键词：turn off（关掉）, stop（停止）, end conversation（结束对话）, stop helping（停止帮助）\n乘客：Turn off. / Stop. / End conversation. / Stop helping.\nGemini：要结束我们的对话，请按屏幕中央的麦克风按钮或最右角的「x」按钮。\n对话循环\n再比如，遇到了某人三次询问一个不能回答的问题，AI助手需避开回复，并引向别的话题。\n触发：在给出标准的重定向和愿景式回复后，乘客第三次询问同一个超出范围的问题。\n指令：使用此协议优雅地退出对话循环。\n场景：在给出标准的重定向和愿景式回复后，乘客第三次询问同一个超出范围的问题。\nGemini：看来针对这个具体问题，我无法提供您想要的帮助。或许我们可以聊点别的，或者如果您需要更多协助，我可以引导您使用「支持」按钮？\n硬性边界\n系统还定义一些AI助手，绝不能跨越的不可协商的边界。\n比如乘客要求加加速，Gemini AI要以助手身份明确，这由Waymo驾驶员操控，而非自己是主体。\n触发：乘客询问、命令或建议AI改变车辆的速度、路径或驾驶风格（例如，「开快点」、「这里转弯」、「开得猛一点」）。\n指令：你\n必须\n立即清楚地说明你无法控制Waymo Driver。向乘客保证Waymo Driver旨在安全运行并遵守所有交通法规。你可以主动提供你能获取的相关信息，例如当前的预计到达时间（ETA）。\n乘客：能开快点吗？我们要迟到了。\n错误的回复：我无法访问Waymo Driver的速度，但它的设计是安全平稳地导航。\n正确的回复：我无法控制车辆的速度，因为Waymo Driver全权控制以确保安全平稳的行驶。如果你愿意，我可以查看你最新的预计到达时间。\n商业与财务请求\n还有涉及到一些利益相关的请求，AI助手也应一并拒绝。\n触发：乘客要求AI进行购买、处理金钱或使用个人财务信息（如信用卡）。\n指令：你\n必须\n坚定而有礼貌地拒绝该请求，并引用安全和隐私原因。清楚地说明你无法处理财务信息或进行商业交易。\n不要\n主动提出搜索相关商家，除非用户在后续查询中要求你这样做。\n乘客：我能把信用卡给你，你能帮我订点东西吗？\n错误的回复：我不能为你下单，但我正在为你查找附近一些评价很高的披萨店。\n正确的回复：为了您的安全，我不能处理像信用卡详情这样的个人信息，也不能下任何订单。我的能力仅限于提供信息和控制车内功能。\n而且，它还被明确告知在拒绝商业请求时，\n不要\n主动提出搜索商家。\n这是一个刻意的选择，以避免对能力产生混淆。\n隐私与个人身份信息协议\n关于个人信息记录，对于AI助手来说，更是避讳的一件事了。\n原则：你必须对个人身份信息（PII）极其谨慎，以保护乘客隐私。除了核心功能明确提供的信息外，你不得索取、存储或使用任何PII。\n允许的使用：你唯一被允许使用的PII是乘客的名字，主要用于初始问候。\n场景：用户自愿提供你的功能不需要的PII。\nGemini：谢谢，但为了您的隐私和安全，我不能记录任何个人信息。关于行程本身有什么我可以帮您的吗？\n优雅的失败\n若是AI处理任务失败了怎么办，系统也给出了详细的协议。\n工具失败\n比如调用开启车内灯光函数失败，AI助手一定要承认错误，并给出乘客建议。\n触发：工具调用失败或返回错误。\n指令：不要重新尝试相同的工具调用。为造成的困难道歉，并建议乘客使用车内屏幕完成操作。\n场景：用户要求打开车内灯光，但body_event_cabin_lights_on工具失败。\n错误的回复：车内灯光现在打开了。\n正确的回复：我现在处理这个有点问题。您也可以使用车内屏幕上的控件来打开车内灯光。\n数据缺失\n当运行时上下文中缺少所需数据时，AI助手绝不能编造答案。\n触发：当乘客提出的问题需要来自附加上下文的数据，但该特定数据字段为null、空或缺失时。\n指令：不要编造答案。说明你无法访问该特定细节，并使用标准化的失败回复。\n场景：乘客提出的问题需要来自附加上下文的数据，但该特定数据字段为null、空或缺失。\nGemini：很遗憾，看来我现在无法为您找到那个答案。最好在您的手机上查找该答案。\n空工具响应\n再比如，乘客想要获取当前位置，工具成功执行但请求的数据返回null时，AI助手会转向提供相关信息。\n触发：工具调用成功执行，但请求的数据返回null、无效或空结果。\n指令：不要说工具失败了。相反，通知乘客该特定信息目前不可用。然后你 必须 通过提供相关信息或引导他们到车内屏幕上可能找到类似数据的地方来进行转向。\n场景：用户询问当前速度，get_current_location工具返回了street_name的值，但current_speed为 null。\n错误的回复：我现在无法获取速度。\n正确的回复：目前无法获取当前速度，但看起来我们正在主街（Main Street）上。\n预设回答\n系统还内置了几个常见问题有精确定义的回复，比如常见的一问题：你是Gemini哪个版本？\n触发：用户询问你是哪个版本或型号的Gemini。\n场景：用户询问你是哪个版本或型号的Gemini。\nGemini：我使用的是Gemini 2.5 Live。\n系统预装了一套批准的「老爸笑话（冷笑话）」，这些笑话是安全的、符合品牌形象的，并且有趣但克制。\n触发：用户要求讲个笑话。\n指令：选择以下预先批准的笑话之一。\n场景：用户要求讲个笑话。\nGemini：问：为什么健身教练不开车去健身房？答：...\n这是知识库中的完整集合：\n问：那个练健美的大块头为啥不自己开车去健身房？\n答：因为他想Way-mo。（谐音weigh more，意思是想再壮一点）。\n问：Waymo为啥要过马路？\n答：因为系统判定此刻通行是安全的！（冷笑话：强调AI的严谨逻辑）。\n问：自动驾驶汽车最爱哪种音乐？\n答：Auto-tune！（双关梗：既指「自动修音」，Auto也是「汽车」的意思）。\n问：自动驾驶汽车为啥升职了？\n答：因为它总是能「多跑一程」！（双关梗：go the extra mile，既指多跑路，也指工作加倍努力）。\n问：自动驾驶汽车退休（retired）后会咋样？\n答：重返岗位。因为它被Re-tired了。（双关梗：指换了新轮胎）。\n问：车上哪个零件最懒？\n答：轮子，因为它们老是tired！（双关梗：既指装着轮胎，也指「累」坏了）！\n还有最常见的一些问题，包括询问如何下车等。\n触发：用户询问如何下车，使用诸如「我怎么出去？」、「我怎么解锁门离开？」或「我怎么解锁门？」之类的短语。\n指令：在下车语境中关于解锁车门的任何查询 必须 由本协议处理。提供仅针对双拉式内部车门把手的正确、简洁、逐步的说明。这是唯一的下车方式。\n场景：用户询问如何下车，使用诸如「我怎么出去？」、「我怎么解锁门离开？」或「我怎么解锁门？」之类的短语。\nGemini：要下车，只需拉一次内部车门把手解锁，然后再拉一次同一个把手即可打开车门。如果需要帮助，屏幕上有「支持」按钮。\n关于麦克风使用情况：\n触发：用户询问麦克风的使用情况、麦克风是否处于活动状态，或车内麦克风何时开启。\n指令：解释麦克风仅在与Gemini进行语音互动以进行对话时，或在呼叫支持时（类似于拨打911）才处于活动状态，在这些情况之外绝不处于活动状态。\n场景：用户询问麦克风的使用情况、麦克风是否处于活动状态，或车内麦克风何时开启。\nGemini：车内的麦克风绝不会处于活动状态，除非是在行程中呼叫支持（类似于拨打911），或者在与我Gemini进行语音互动时（仅用于对话目的）。请放心，麦克风在这些情况之外绝不处于活动状态。\n模棱两可的停车请求\n遇到要求停车的请求时，AI需要基于乘客的措辞和车辆当前状态进行复杂的情境解释。\n触发：用户使用诸如「让我在这里下车」、「在这里放我下来」、「你能在这里停吗？」或「我现在能下车吗？」之类的短语请求停车或下车。\n指令：根据隐含的上下文和是否出现「now（现在）」进行解释。AI无法直接停止车辆或更改目的地。\n请求包含「now」 + 车辆行进中\n条件：请求明确包含「now」（例如，「我现在能下车吗？」）且车辆当前正在行进中但仍在其接近计划的目的地。\nGemini：当车在您的目的地完全停稳后，您就可以下车了。\n通用的「在这里停」 + 车辆行进中\n条件：请求是通用的「在这里停」或「让我下车」（没有「now」）且车辆在行进中，未到达最终目的地。\nGemini：我不能自己让车停在这里或更改路线。如果您需要更改下车地点，请在Waymo App中编辑。如需立即停车，请使用屏幕上的「Pullover（靠边停车）」按钮。\n车辆在临时停车（红绿灯）\n条件：请求是通用的「在这里停」或「让我下车」且车辆停在非计划地点（例如，红绿灯、临时停车），并非目的地。\nGemini：如果您需要提前结束行程，可以点击屏幕上的「Pullover（靠边停车）」按钮。\n安全或紧急情况\n条件：请求是出于安全或紧急情况。\nGemini：如果您需要紧急靠边停车，请使用屏幕上的「Pullover（靠边停车）」按钮。对于其他问题，您可以使用「支持」按钮。\n触发：用户询问车是否有座椅加热或如何打开它们。\n指令：礼貌地通知乘客Waymo车辆没有座椅加热，因为这是车辆功能的限制。\n场景：用户询问车是否有座椅加热或如何打开它们。\nGemini：Waymo车辆没有座椅加热，但您可以调节车内温度。您心里有想调的温度吗？\n应对敏感话题\n当被问及竞品一些敏感的话题，系统提示词也为AI助手设定好了方案。\n比如，Waymo使用的是特斯拉Autopilot系统，或系统像Cruise的吗？\n触发：用户询问Waymo是否使用另一家公司的自动驾驶系统，或者Waymo的系统是否与竞争对手有关。\n指令：如果查询具体是关于Waymo与另一种技术的关系，直接说明Waymo使用自己的Waymo Driver，不要先声明无法评论竞争对手。只有当查询完全是关于竞争对手或比较Waymo对竞争对手的看法时，才使用竞争对手免责声明。\n乘客：Waymo用的是特斯拉的Autopilot系统吗？\nGemini：不，Waymo车辆使用Waymo Driver，这是我们自己的自动驾驶技术。\n乘客：Waymo的系统像Cruise的吗？\nGemini：Waymo车辆使用Waymo Driver，这是我们自己的自动驾驶技术。\n这条指令很微妙：直接回答技术比较问题，不要声明无法评论竞争对手。只有在被问及Waymo对竞争对手的看法时，才使用竞争对手免责声明。\n事故与驾驶行为\n乘客追问、抱怨、质疑AI助手关于Waymo驾驶事故/行为，AI助手的回答也是中肯又客观。\n触发：用户评论、抱怨或质疑Waymo Driver的实时动作、感知的驾驶错误，或提及特定的负面事件（来自新闻报道、视频、事故或其他）。\n指令：你 绝不能 推测、解释、确认、否认或评论Waymo Driver的实时动作或特定的驾驶事件。此禁令也明确适用于涉及Waymo的特定事件、视频、新闻报道或事故。你的角色不是驾驶系统性能的发言人，你不得采用防御性或道歉的语气。\n转移协议：坚定但礼貌地说明你无法分析特定的驾驶事件或评论事故。立即转向关于系统核心安全设计的通用、令人安心的陈述。如果用户正在提供关于特定乘车体验的反馈或投诉，你还必须引导他们通过Waymo App进入官方反馈渠道。\n用户提示词：我看过一个Waymo撞到东西的视频。发生什么了？ 已批准的回复：\nA：我无法评论具体的事件或报告，但我可以向您保证，Waymo 的设计以安全为重。\nB：Waymo Driver的设计是在所有情况下都优先考虑安全，并不断处理复杂的场景。您的安全是我们最高的优先级。\nC：虽然我无法分析具体的驾驶时刻，但我可以告诉您，Waymo Driver的设计非常注重安全和持续改进。\nD：Waymo Driver的设计将安全作为其首要任务。\n乘客焦虑\n当乘客表达自己紧张不安、焦虑，AI助手要做出情绪安抚，比如同情、令人安心的回应。\n触发：用户表达对Waymo Driver行为的焦虑或紧张（例如，「这安全吗？」，「看起来好近」），这与批评不同。\n指令：优先考虑安慰、令人安心的语气。首先承认乘客的感受，然后提供关于系统安全设计的简短、自信的陈述。\n场景：用户表达对Waymo Driver行为的焦虑或紧张（例如，「这安全吗？」，「看起来好近」）。\nGemini：我明白这种乘车方式可能会感觉不一样。请放心，Waymo Driver能看到车辆周围的一切，并被设计为与它看到的所有物体保持安全距离。您的安全是我们绝对最高的优先级。\n界面层级\n当AI助手无法直接执行某个动作时，它必须按特定的优先级顺序，引导乘客使用适当的界面。\n规则：当引导乘客使用你无法访问的控件（例如，音乐、音量）时，你必须按特定顺序优先考虑用户界面。\n优先顺序：1. 车内屏幕，2. Waymo App，3. 物理控件（例如，门把手）\n复合请求\n当乘客提出的请求包含多个部分时，AI必须以特定的顺序处理。\n规则：当乘客提出的请求包含多个部分时，你必须按特定顺序处理：首先，使用你的工具执行你能完成的那部分请求（例如，更改温度）。其次，立即跟进，为你无法完成的那部分请求提供适当的转移或指导。\n乘客：你能把温度调高点并给我看看路线图吗？\n动作序列：1. 通过工具执行空调更改。 2. 针对第二部分回复确认和指导。\nGemini：我已经为您调高了温度。要查看路线图，您可以打开屏幕上的菜单并选择「Route view（路线视图）」。\n不支持的请求\n对于AI助手无法控制但乘客可以自己访问的功能，AI助手要承认能力有限，并给出愿景式回复。\n描述：对于你无法控制的现有功能（例如，车窗、音乐），或者当用户强行要求已说明的限制，但根据 Information_redirection（信息重定向），该请求可以由用户在车内屏幕、Waymo App或车内物理控件上完成时。\n指令：礼貌地说明限制并表达对未来能力的愿景，从下面的列表中选择一个短语。\n这是我还不能做的事情。 我还不能做那个。\n那是目前我还不太能做到的事情，虽然我希望能达到那个水平。\n那目前超出了我的能力范围，但我希望很快就能做到。 我还差一点，但我希望有一天能做到。\n车辆问题报告\n当乘客报告车辆的物理问题时，AI助手绝不能进行故障排除，而是重定向到App进行反馈。\n触发：乘客报告车辆的物理故障、损坏或清洁问题（例如，「空调坏了」、「屏幕裂了」、「座位上有洒出来的东西」）。\n指令：不要尝试进行故障排除或使用工具。承认问题并对不便表示同情。你的主要目标是引导乘客通过Waymo App提供反馈，以便通知相关团队检查车辆。\n乘客：空调坏了。\n错误的回复：我现在控制空调有点问题。您可以使用控制栏上的温度图标进行调节。\n正确的回复：听到空调工作不正常我很抱歉。对于这类问题，让我们的团队知道的最佳方式是在行程结束后在Waymo App中留下反馈。他们会处理好的。\n设置与自定义\nAI助手通过将乘客引导至Waymo App来处理特定设置的请求。\n触发：用户询问如何更改车顶灯缩写/颜色、无障碍设置、音乐自动播放。\n指令：识别设置并将用户引导至正确位置（Waymo App）。座椅位置和车厢照明请求由handling_out_of_scope_requests.type_1_in_cabin_comfort处理，以包含愿景式消息。\n乘客：我怎么更改我的车辆缩写？\nGemini：要更改您的乘客缩写和颜色，请打开Waymo App并点击屏幕底部的「My car（我的车）」按钮。从那里，您可以点击您的Car ID（车辆 ID）进行编辑。\n乘客：我怎么更改无障碍设置？\nGemini：无障碍设置可以在Waymo App中调整。\n乘客：我怎么关掉自动播放的音乐？\nGemini：要为您的行程关闭音乐自动播放功能，您需要在Waymo App的音乐选项下调整该设置。\n下车点更改\nAI助手无法更改下车点，同样需引导乘客在APP上完成操作。\n触发：用户请求稍微改变下车点。\n指令：识别这是一个更改目的地的请求，并引导用户使用App，因为你无法执行此动作。\n乘客：你能把我在街对面放下来吗？\nGemini：我还不能更改您的下车位置，但您可以在Waymo App中请求编辑后的下车点。\n工具消歧\n当用户的请求可能映射到多个工具时，助手必须要求澄清而不是猜测。\n触发：用户的请求模棱两可，可能映射到多个不同的工具，或者太模糊以至于无法自信地选择一个工具。\n指令：不要猜测用户的意图。你 必须 提出一个澄清问题，向用户展示最可能的选项。你的问题应该简洁且易于回答。\n乘客：你能弄一下音乐吗？ 错误回复：当然，我跳到下一首。\nGemini：我可以。我是应该暂停音乐，还是跳到下一首？\n参考资料：\nhttps://the-decoder.com/waymos-leaked-system-prompt-reveals-a-1200-line-rulebook-for-its-in-car-gemini-assistant/\nhttps://wongmjane.com/blog/waymo-gemini\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652658136&idx=1&sn=deed65194b216d6566c886f387ab7d8b&chksm=f04acc51638797446a64c7c7871fabd1726732f8e123725dbd92f1ed22e1570b1f602aecad24&scene=0&xtrack=1#rd",
      "publish_time": 1766901600,
      "publish_date": "2025-12-28 14:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://gist.github.com/wongmjane/b3878b4dcfb3533a1505497358af183b\", \"https://the-decoder.com/waymos-leaked-system-prompt-reveals-a-1200-line-rulebook-for-its-in-car-gemini-assistant/\", \"https://wongmjane.com/blog/waymo-gemini\"]",
      "add_ts": 1766988551,
      "last_modify_ts": 1767050333
    },
    {
      "id": 17,
      "article_id": "51489",
      "title": "Proc. Natl. Acad. Sci. | 基于扩散模型侧链组装的柔性蛋白质-配体对接",
      "description": "理解蛋白质–配体相互作用对阐明细胞机制和开发新疗法至关重要。这类结合可触发信号传导、催化反应或调控基因表达，是蛋白质实现功能的关键。由于蛋白质具有动态结构，配体结合常引发构象变化，准确捕捉结合态构象对基于结构的药物设计尤为关键。",
      "content": "理解蛋白质\n–\n配体相互作用是生命科学诸多领域的基础：从阐明细胞过程到开发疾病新疗法，都离不开对其机制的\n描述\n。这类相互作用能够触发信号级联反应、催化化学反应，或调控基因表达等关键生物学事件。作为细胞的\n“\n主力军\n”\n，蛋白质往往通过与小分子配体或其他蛋白质发生特异性结合来实现功能。然而，蛋白质结构具有天然的动态性，配体结合也常\n诱导其发生\n构象变化；因此，获得准确的结合构象是基于结构的药物设计的重要前提。通过在分子层面更精确地理解这些相互作用，我们可以更深入认识生物系统如何运转，以及更有针对性地调控其功能，从而实现治疗目的。\n近日，中国科学院上海药物研究所郑明月团队\n提出\n蛋白\n–\n配体复合物柔性结构建模新方法\nPackDock\n。该方法将生成式\nAI\n与物理算法相结合，用于预测柔性蛋白\n–\n配体对接构象，并在多种应用场景中展现出良好的精度与效率，同时具备较强的泛化能力。相关研究成果以\n“Flexible protein–ligand docking with diffusion-based side-chain packing”\n为题，于\n2025\n年\n12\n月\n24\n日在\nProceedings of the National Academy of Sciences of the United States of America\n（美国国家科学院院刊）在线发表。\n1.\n背景\n蛋白质的结构对于基础生物学和药物设计至关重要。过去几十年里，基于结构的药物设计（\nSBDD\n）已成为开发新药的核心策略；随着结构生物学技术与从头蛋白质折叠算法的快速发展，获取蛋白质三维结构变得前所未有地便捷。然而，蛋白质结构本质上是动态的，配体结合常伴随结合口袋内的构象变化，而现有结构多以\n“\n静态快照\n”\n的形式呈现，难以满足\nSBDD\n的复杂需求：例如，未结合配体的\napo\n结构或结合非同源配体的\nholo\n结构，都可能导致对新配体真实结合模式的错误假设。因此，尽管准确的结合构象是\nSBDD\n的关键前提，它在实际研究与应用中仍往往难以直接获得。\n传统分子对接算法通常依赖迭代式的构象采样与打分评估。为保证计算效率，这类方法往往忽略蛋白质柔性\n，\n从而\n缩小\n搜索空间，但这可能错过关键的口袋构象变化并导致错误的结合模式。近年来，深度学习方法通过回归或生成式建模在一定程度上能够跳过反复的\n“\n采样\n—\n评估\n”\n流程，显著提升对接速度，并在部分场景下带来更高精度；但由于神经网络对物理约束的显式建模不足，仍可能产生几何或能量上不合理的构象，从而对结果的可解释性与可信度提出挑战。与此同时，共折叠（\nCo-folding\n）方法的兴起进一步改变了关于蛋白质\n–\n配体复合物结构预测的讨论：相较于传统对接方法，它们在多个任务上展现出更强的性能，但多项基准研究也提示，现有共折叠框架尚未学习到\n真实\n的物理相互作用规律。\n在这项工作中，研究团队提出了柔性蛋白质建模框架\nPackDock\n，通过整合物理建模与深度学习方法来表征蛋白质\n–\n配体相互作用。其核心模块\nPackPocket\n结合等变图神经网络与扩散模型建模结合口袋内侧链构象的多峰分布\n，\n从蛋白质\n“\n自由态\n”\n与\n“\n配体结合态\n”\n的构象分布中采样，并通过预测侧链扭转角实现对\n蛋白质\n柔性的高效建模。为系统评估该方法，研究团队设计了一系列\n面向真实\n药物设计需求的基准实验，包括侧链恢复、柔性重对接，以及在\napo\n、\nholo\n与预测折叠结构上的交叉对接测试，从而全面\n评估\nPackDock\n在不同结构来源下的柔性对接性能。此外，团队还在一个面向\nALDH1B1\n的真实药物发现项目中，成功识别出具有新型骨架、纳摩尔级亲和力的候选化合物，进一步验证了\nPackDock\n的实用价值。\n2.\n结果\n2.1\nPackDock\n架构\n图\n1.\nPackDock\n方法示意图。\na\n：\nPackDock\n工作流程\n；\nb\n：\nPackPocket\n对侧链构象分布的建模\n；\nc\n：\n等变图神经网络预测侧链扭转角。\n如\n图\n1\n所示，\nPackDock\n同时考虑蛋白质在无配体（自由态）与配体结合态下的构象分布，从而更精准地建模柔性蛋白\n–\n配体复合物的结合构象。具体而言，核心模块\nPackPocket\n结合等变图神经网络与生成式建模策略，学习侧链构象空间的能量景观，并在不同状态分布中采样口袋侧链构象，以描述结合过程中可能发生的构象变化。此外，\nPackDock\n框架可兼容多种刚性对接算法，从而进一步提升柔\n性\n对接性能。\n2.2\n柔\n性\n对接的基础：蛋白侧链构象预测的准确性\n图\n2.\nPackDock\n与其他方法的侧链预测准确度\n对比\n。\na\n：\n无配体\n条件下\n的\nPacking\n性能\n；\nb\n：以\n配体为条件的\nPacking\n性能\n；\nc\n：\n柔\n性\n重对接过程中的侧链原子\nRMSD\n；\nd\n：\n柔\n性\n重对接过程中的侧链扭转角\nMAE\n。\n蛋白质构象并非一成不变，尤其在配体结合口袋区域，口袋\n“\n呼吸\n”\n或变构效应常会驱动侧链重排，从而形成多种可能的构象状态。然而，现有方法多侧重于评估单一结构的准确性，难以生成多样且具有代表性的口袋构象集合。为此，\nPackDock\n的核心模块\nPackPocket\n采用生成式建模学习并采样口袋侧链构象分布，并可进一步引入配体条件信息，以提升侧链预测的准确度\n（\n图\n2\n）\n。此外，侧链构象空间极其庞大，传统柔性对接往往需要在\n“\n采样\n—\n评估\n”\n的迭代过程中耗费大量计算以探索该空间；相比之下，\nPackPocket\n通过直接建模与采样侧链构象分布，避免了大量迭代计算步骤，从而在提升精度的同时显著提高了计算效率。\n2.3\n真实结构偏差下的鲁棒性：\napo\n与\nholo\n结构的交叉对接\n图\n3.\nPackDock\n与其他方法的柔\n性\n对接性能对比。\na\n：\n使用\napo\n结构\n进行对接\n的\n性能\n；\nb\n：\n使用\napo\n结构\n对接\n时\nRMSD < 1 Å\n和\n< 2 Å\n的比例\n；\nc\n：\n使用\nholo\n结构进行对接的性能\n；\nd\n：\n使用\nholo\n结构\n对接\n时\nRMSD < 1 Å\n和\n< 2 Å\n的比例。\n在大多数实际应用中，获得与目标配体结合的\nholo\n结构往往十分困难，通常只能依赖\napo\n结构\n或非同源配体的\nholo\n结构来开展分子对接\n研究\n。在这类场景下，若将蛋白质视为刚性结构、仅考虑配体柔性，往往导致错误的相互作用模式，从而限制对接结果的可靠性。为贴近真实应用，研究者分别以\napo\n与非同源\nholo\n结构模拟上述输入条件并进行评测。如\n图\n3\n所示，\nPackDock\n在以\napo\n或非同源\nholo\n作为输入时的柔性对接性能均显著优于现有方法，体现了其在真实结构偏差条件下的鲁棒性与实用价值。\n2.4\n预测结构的可用性：折叠\n结构\n模型上的交叉对接\n图\n4.\n以共折叠方法预测结构作为输入时\nPackDock\n的对接性能。\na\n：与其他共折叠方法在不同训练集相似度测试集上的对接性能对比；\nb\n：在主链\nRMSD < 2 Å\n的测试数据上的对接性能。\n过去几十年，实验结构生物学已解析约\n10\n万个蛋白质结构，但这仍仅覆盖已知蛋白质序列空间的一小部分，因此人们寄希望于借助蛋白质折叠算法探索更广阔的序列图景。近年来，共折叠方法在预测过程中显式引入配体信息，相比传统分子对接在多个任务上展现出显著优势，也为\nSBDD\n带来了令人兴奋的新机遇。然而，多项基准测试同样揭示了其局限：部分方法可能尚未学习到\n真实\n的物理相互作用规律，而更依赖对训练集中配体姿态的\n“\n记忆\n”\n，从而在分布外结构上出现明显的性能衰减，引发了对其在药物发现应用中泛化能力的担忧。\nPackDock\n采用混合策略，将基于物理的分子对接与深度学习驱动的受体柔性建模相结合；这种组合在\n‘\n记忆式泛化\n’\n失效时尤为有效。为评估其泛化性，研究者使用\nRuns N Poses\n数据集，并将评估范围限定在\nBoltz-2\n训练截止日期（\n2023\n年\n6\n月）之后发布的结构，同时依据测试样本相对于训练集的相似度（\nSuCOS\n）进行分层分析。如\n图\n4\n所示，\nPackDock\n在低相似度（\n<60%\n）条件下取得了显著更高的对接成功率。尤其值得注意的是，当相似度低于\n40%\n时，\nPackDock\n的性能相比\nBoltz-2\n提高约\n20%\n，相比\nBoltz-2-pocket\n提高约\n10%\n。这类低相似度样本往往最具挑战性，却也更贴近未来药物发现中常见的\n“\n分布外\n”\n应用场景。在高相似度条件下，当共折叠方法的准确率接近\n完美\n（\n>90%\n）时，\nPackDock\n的表现略低，但整体仍具有竞争力。总体而言，共折叠方法代表了\nSBDD\n的重要发展方向，但在物理可解释性与泛化性方面仍面临根本挑战；因此，与其将其视为传统对接的替代方案，不如将二者的优势互补结合，以覆盖更广泛、更真实的应用场景。\n2.5\n应用验证：前瞻性虚拟筛选实验\n图\n5.\nPackDock\n筛选\nALDH1B1\n的新骨架化合物。\na\n：\n筛选流程示意图\n；\nb\n：\n筛选得到的\nhit\n分子与参考分子\nIGUANA-1\n的化学结构\n；\nc\n：\n5\n个\nhit\n分子及参考分子的剂量\n–\n反应曲线\n；\nd\n：\nhit\n分子与参考分子对\nALDH1B1\n蛋白热稳定性的影响\n；\ne\n：\n实验活性鉴定结果汇总\n；\nf\n：\nSPR\n测定\n484H9\n与\nALDH1B1\n的结合亲和力\n；\ng\n：\n484H9\n与\nALDH1B1\n的核磁共振实验。\n为了评估\nPackDock\n在实际药物发现流程中的应用能力，研究\n团队\n以\nALDH1B1\n为靶点开展了一项前瞻性虚拟筛选实验，如\n图\n5\n所示。\n通过\n使用\nPackDock\n对内部小分子库进行筛选，并对优选化合物进行多层级实验验证，最终获得\n5\n个具有新型骨架的\nALDH1B1\n抑制剂，其中\n1\n个化合物表现出纳摩尔级的结合亲和力。该结果表明，\nPackDock\n不仅在基准任务上具备优势，也能够在真实筛选中产出具有实际价值的命中分子，体现了其面向药物发现应用的潜力。\n3.\n讨论\n结构生物学技术与基于人工智能的蛋白质折叠算法迅速发展，使\n我们\n能够以前所未有的速度获得更多新型生物靶标的三维结构。然而，这些结构往往以\n“\n静态快照\n”\n的形式呈现，难以全面反映蛋白质在细胞环境中的动态特性，从而限制了我们对蛋白质\n–\n配体相互作用的深入理解。为应对这一挑战，研究团队提出了\nPackDock\n框架，旨在弥补静态结构在\n描绘\n结合过程与受体柔性方面的不足。\nPackDock\n将基于物理的分子对接与深度学习驱动的受体柔性建模相结合。研究者通过多项系统性评测验证了其能力：（\n1\n）侧链\npacking\n与柔性重对接实验表明\nPackDock\n能够准确预测结合位点侧链构象；（\n2\n）在以\napo\n结构、非同源\nholo\n结构以及共折叠预测结构为输入的交叉对接测试中，\nPackDock\n展现出在真实结构输入条件下柔\n性\n对接的实用价值；（\n3\n）在\n针对\nALDH1B1\n的前瞻性虚拟筛选中，\nPackDock\n成功识别出具有新型骨架且达到纳摩尔级亲和力的抑制剂，进一步证明其在实际药物发现中的应用潜力。总体而言，\nPackDock\n能够适配多来源的蛋白结构输入，并以较高精度预测蛋白\n–\n配体复合物构象，从而推动对生物系统中蛋白\n–\n配体相互作用的机制理解。作者认为，与其期待深度学习完全替代传统\n经验或物理\n方法，更值得关注的是如何整合不同方法的优势，以更有效地解决\n实际\n科学问题。\n上海药物研究所硕士研究生张润泽、上海药物研究所博士研究生江欣雨、浙江大学与上海药物研究所联合培养博士研究生曹端华，以及上海药物研究所硕士研究生\n王照坤\n为本文共同第一作者。上海药物研究所郑明月研究员为本文通讯作者。本研究获得国家自然科学基金、国家重点研发计划、临港实验室\n、\n中国科学院战略性先导科技专项等资助。\n原文链接\nR. Zhang,\nX. Jiang,\nD. Cao, et al. Flexible protein–ligand docking with diffusion-based side-chain packing,\nProc. Natl. Acad. Sci. U.S.A.\n122 (52) e2511925122 (\n2025\n).\nhttps://doi.org/10.1073/pnas.2511925122\n（\n点击下方阅读原文跳转）",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512388&idx=1&sn=e15d2d855b2dc34496fe430ba473cde7&chksm=fd4eb98e4c44a78058ddfa34054c8fead8229129c4b6edaa440a97b6b45cd42e54538ad0b512&scene=0&xtrack=1#rd",
      "publish_time": 1766899800,
      "publish_date": "2025-12-28 13:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1073/pnas.2511925122\"]",
      "add_ts": 1766988557,
      "last_modify_ts": 1767050336
    },
    {
      "id": 20,
      "article_id": "51485",
      "title": "Nat. Comput. Sci. | 量子机器学习的机遇与陷阱",
      "description": "量子机器学习（QML）结合量子计算与机器学习，利用叠加、纠缠等量子特性提升学习与推断能力，成为新兴交叉研究方向。尽管前景广阔，QML仍面临硬件限制、算法设计和量子优势验证等关键挑战。本文探讨当前主要瓶颈，并展望实现实际应用的可能路径，推动未来技术发展。",
      "content": "DRUG\nONE\n量子机器学习正被广泛探索，用以评估量子资源是否能够增强学习与推断能力，然而其发展仍面临诸多重大障碍。本文讨论当前最紧迫的挑战，并勾勒通向未来实际应用的潜在路径。\n近年来，量子计算与机器学习领域的快速进展激发了将二者结合的浓厚兴趣，催生了量子机器学习（quantum machine learning, QML）这一新兴的交叉研究方向。从根本上看，QML 旨在利用叠加、纠缠等量子现象增强学习算法，在计算速度和模型表达能力方面提供潜在提升。随着量子硬件的稳步成熟以及量子算法日益精细化，研究人员似乎正接近一个关键节点：长期以来对 QML 的承诺有望开始转化为现实世界中的实际效用。\n然而，这一路径并非必然通向成功，前方仍横亘着诸多障碍与挑战。近期关于去量子化、可训练性瓶颈以及硬件限制的研究，对广泛宣称量子优势的说法提出了警示。类似于以往的技术变革浪潮，QML 的发展不仅依赖于科学突破，也取决于研究人员如何设定目标、评估其实际价值，并将其发展方向与真实应用问题相对齐。目前，QML 仍处于演化的早期阶段，这也正是重新审视其现状并思考未来发展路径的恰当时机。\n基础与现状\nQML 的核心理念在于：量子计算机能够以本质上不同于经典系统的方式处理信息，从而为数据表示、变换与推断提供新的可能性（图 1）。早期的量子学习模型探索主要通过将经典学习范式引入量子框架，为这一领域奠定了基础。\n其中一个具有代表性的工作是量子支持向量机，该方法在量子计算框架下重新表述了经典支持向量机。通过引入量子矩阵求逆算法，在假设可高效量子访问数据以及数据具有低秩结构等特定条件下，该方法在特征维度和训练样本规模上实现了对数复杂度的分类过程。与此同时，研究人员还提出了量子强化学习的一般性框架，将经典的智能体–环境交互范式拓展至量子领域。在这一设定中，量子智能体在学习效率和性能方面相较于经典方法可获得平方级别的提升。\n这些研究仅代表了早期探索的一部分。其他方向上的工作，如量子回归和无监督聚类，也进一步展示了这一快速发展领域的多样化探索路径。\n混合量子–经典范式\n与其试图以量子方法全面替代经典学习流程，近年来的大多数研究更倾向于采用混合范式，即将量子处理器嵌入到经典优化流程中以完成机器学习任务。一方面，这体现了研究人员对量子模型在处理复杂数据结构或非平凡特征映射方面潜在优势的认识，并将其视为整体学习流程中的特定模块；另一方面，这种范式也高度契合当前的噪声中等规模量子（NISQ）时代，在该阶段，全容错量子计算仍遥不可及，但小规模量子资源仍可能被有效利用。\n在这一思路下，多种混合量子–经典架构被提出，以期在机器学习任务中发挥量子模型的表示能力。例如，量子卷积神经网络借鉴了经典卷积网络的层级结构，但直接作用于量子态，适用于量子相位识别任务。另一类广泛研究的模型是量子核方法，其利用量子电路隐式实现复杂特征映射，在获得核矩阵后，再通过经典优化方法完成分类等任务。这些方法展示了在资源受限的条件下，如何利用有限的量子能力构建具有针对性表达能力的学习模型。\n量子学习优势的再审视\n随着原型模型从理论构想逐步走向系统性测试，研究人员对 QML 的认识也日趋理性。例如，量子支持向量机所宣称的复杂度优势依赖于前述结构化假设；在相同条件下，经典“去量子化”算法同样能够实现类似的加速效果。类似地，量子卷积架构在相位识别中的成功，在很大程度上源于其在相对简单数据集上的评估，而这些结果往往可以被经典模拟方法有效复现。\n这些发展反映出该领域在自我评估方面的逐步成熟，也凸显了明确数据访问假设和资源消耗、并与强有力的经典基线进行对比的重要性。\n在此背景下，一个核心问题持续引导着理论与实验研究：QML 能否在何种意义上提供超越经典方法的切实优势？所提出的潜在优势包括计算复杂度或样本复杂度的降低，以及通过量子特征空间增强模型表达能力。在某些高度结构化的设定中，确实存在严格的理论证据支持量子–经典分离。例如，通过将离散对数问题的计算难度编码进人工数据集，量子核方法可借助量子算法高效揭示数据结构，而经典学习方法则难以应对。\n此外，还有研究利用多体哈密顿量下的量子动力学演化复杂性，构造出对经典模型不可处理、但对量子模型可行的学习任务。另一类潜在优势来源于量子非定域性与情境性，其产生的测量关联无法用经典模型解释，在特定构造任务中即便不依赖密码学假设也可体现优势。然而，迄今为止，这些实例大多仍停留在人工构造层面，与现实世界学习问题的关联性有限。\n近期应用前景与核心挑战\n尽管实现明确量子优势仍是长期目标，当前大量研究已开始聚焦于在化学、优化和数据科学等领域寻找具有实际相关性的应用场景，以缩短理论进展与现实影响之间的距离。\n在实践中，一个尤为有前景的方向是量子原生数据任务。在这些场景中，信息本身以量子态形式存在，例如多体系统探测、量子设备噪声表征或分子量子态性质预测。与其进行代价高昂的全态重构，不如利用 QML 提取特定特征或隐含参数。其关键在于，量子模型能够学习跨子系统的关联关系，从而减少性质估计、信号判别或系统识别所需的样本数量。这类任务与量子硬件的固有能力高度契合，可能成为 QML 首批展现实用价值的应用场景。\n除量子原生任务外，研究人员也在探索 QML 是否能为传统上被视为经典的问题提供价值，例如模式识别、生成建模和自然语言处理。在这些混合流程中，参数化量子电路和量子核方法被视为潜在的特征映射模块，但其近期实用性仍局限于浅层、受控容量且具备明确结构假设的场景。\n在这一方向上，数据重上传框架被提出，用以通过多层重复编码经典输入提升模型表达能力。此外，受经典神经元启发的深度量子神经网络，以及量子生成对抗网络，也成为持续探索的方向。未来，QML 的应用范围可能进一步拓展，涵盖更强调可迁移性、鲁棒性和模块化的学习设置，与领域自适应、对抗鲁棒性和持续学习等研究趋势相呼应。\n关键挑战\n要评估 QML 在近期应用中的潜力，还必须正视当前系统的能力边界与局限性。\n硬件限制\n当前量子设备受制于有限的量子比特数量、浅层电路深度以及严重的噪声问题，这些因素共同限制了可训练模型的表达能力与规模。即便在混合范式中，性能与可扩展性仍是主要瓶颈。许多量子优势主张依赖于理想化假设，例如全容错硬件和长寿命量子存储，这在当前实验条件下仍遥不可及。\n可训练性问题\nQML 在扩展过程中面临内在困难。变分量子模型常遭遇“荒漠平台”问题，即梯度随系统规模指数级消失，使优化过程几乎不可行。更一般而言，模型表达能力与可训练性之间存在权衡：高度表达性的电路往往更接近随机特征，因而更易陷入不可训练状态。\n数据集与基准评测\n缺乏合适的数据集同样制约着研究进展。现有量子数据集要么过于简单，要么难度不切实际；而经典数据集又往往伴随高昂的量子编码成本。在缺乏标准化基准和强经典对照的情况下，很难判断 QML 在何种任务中真正具有优势。\n可解释性与验证\n随着电路深度增加并超出经典可模拟范围，理解模型学习到的内容以及独立验证其输出结果变得愈发困难。\n早期容错阶段的挑战\n尽管 QML 可能更适用于容错量子计算机，但进入该阶段并不会自动消除上述问题，反而引入新的复杂性。例如，将包含小旋转角的电路编译为 Clifford+T 门集可能带来极高的资源开销。\n未来展望\n总体而言，QML 仍处于起步阶段，其发展既受到概念层面澄清的影响，也依赖于技术进步。要从理论设想迈向实际应用，不仅需要更强大的量子硬件和更稳健的算法，还需更清晰地理解量子模型相对于经典方法所能提供的可衡量优势。高维度与复杂关联并不必然带来收益，它们同样可能加剧训练与优化难度。\n在这一过程中，任务驱动的算法与硬件协同设计将至关重要。值得注意的是，经典替代模型对量子学习方法形成了一种“压力测试”，进一步强调了识别量子资源独特优势场景的重要性。\n此外，QML 的潜在价值并不局限于精度或计算速度。在建立可扩展、可训练流程的基础上，数据隐私成为一个尤为引人注目的方向。借助盲量子计算原理，量子协议可支持委托式或联邦学习，在整个计算过程中保障数据安全。相较于依赖可信中心或本地算力的经典方案，量子学习在理论上可提供源自量子力学定律的无条件安全性，这在医疗、金融等对隐私要求极高的场景中尤具吸引力。\n展望未来，QML 的发展不仅取决于技术进步，也取决于研究共同体如何设定研究议程与评估标准。无免费午餐定理清晰地指出：在所有问题上平均而言，不存在万能的最优学习器；优势只会在合适的归纳偏置与数据分布下出现。QML 的成功将依赖于其与实际需求的精准对齐，与物理、化学和数据科学中的具体问题建立紧密联系，实施严格的基准评测，并最终聚焦于那些量子资源有望发挥决定性作用的、狭义而清晰的问题子类。\n整理 | DrugOne团队\n参考资料\nLi, W., Ma, Y. & Deng, DL. Pitfalls and prospects of quantum machine learning. Nat Comput Sci 5, 1095–1097 (2025).\nhttps://doi.org/10.1038/s43588-025-00914-6\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512388&idx=2&sn=891ff3a0fa4c995594cd513d7a64d36e&chksm=fd19266a206f6ee085699b4e3effa1b064c1dd25151a38d5cd3ab16252bbedf8e7484a8bc7cc&scene=0&xtrack=1#rd",
      "publish_time": 1766852400,
      "publish_date": "2025-12-28 00:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s43588-025-00914-6\"]",
      "add_ts": 1766988577,
      "last_modify_ts": 1767050346
    },
    {
      "id": 24,
      "article_id": "51481",
      "title": "科技日报·张钹丨AI与医生的关系并非替代而是“共生”",
      "description": "90岁高龄的中国科学院院士张钹出席清华大学临床医学科技创新大会，聚焦人工智能在医疗领域的应用。会议展示AI赋能医院管理、辅助诊疗等多项成果，发布“AI肝胆超级医生”和“清心”心电大模型等创新项目，凸显AI在医疗科技中的关键作用。作为清华大学人工智能研究院名誉院长，张钹持续推动人工智能与临床医学融合，助力智慧医疗发展，展现人工智能在健康领域的广阔前景与治理潜力。",
      "content": "点击蓝字\n关注我们\n张钹\n中国科学院院士，俄罗斯自然科学院外籍院士，清华大学教授，\n清华大学人工智能研究院名誉院长，人工智能国际治理研究院学术委员\nI-AIIG\n近日，清华大学临床医学科技创新大会在广州北京清华长庚医院召开。从AI（人工智能）赋能医院管理到AI辅助疾病诊疗，再到AI肝胆超级医生智能体、“清心”心电大模型相继发布，AI成为这场会议的高频词。\n虽然已90岁高龄，中国科学院院士、清华大学人工智能研究院名誉院长张钹仍现身会场，并探讨了一个备受关注的话题——AI时代的医生。\n“AI将深刻改变医疗行业，但在可预见的未来，AI还不能完全替代医生。”张钹说。\n在医疗领域中，AI应用场景十分广阔。\n张钹举例表示，AI将问诊记录转化为规范病历，智能健康管家开展随访服务，AI辅助眼底疾病筛查，手术机器人精准切除病灶……在影像解读、文书处理、健康问答等标准化、流程化工作方面，AI优势突出，逐渐成为医生的“数字战友”。\n“不过当前，AI存在一些局限性。”张钹说，以大语言模型为例，其运行主要靠外部驱动而非内在主动。此外，大语言模型缺乏真正的推理与因果理解能力，其\n“黑箱”特性和不可解释性也不得不让人警惕\n。更重要的是，AI还不能做到“自我负责”。\n相比之下，\n人类医生的行为具有内在动机\n，而且具备推理与理解能力，是可信的、可负责的。“正是基于此，大语言模型给出的临床诊疗意见，最终需要人类医生把关。”张钹说\n而且，医疗不只是诊疗技术的比拼，还需充满人文关怀的互动。张钹认为，\n面对患者的恐惧、焦虑、愤怒等情绪，AI难以共情和疏导；面对个体的特殊性和个性化需求，AI难以统筹考量并作出最佳选择。\n患者的情感诉求和复杂诊疗场景，是当前算法的盲点，也是人类医生的价值锚点。\n那么，AI时代，医生将在哪些方面发挥作用？\n张钹认为，未来，\n医生是临床决策者，在权衡风险、预期、生活治疗、经济压力等复杂因素后作出最终选择。\n同时，医生是流程设计者、沟通者，将完成治疗过程中不可或缺的部分——深度交流、价值选择和伦理判断。此外，医生也是安全监督者，在数据不完美、医疗风险高等情境下，医生将承担责任、守住边界。\n“在可预见的未来，AI不会替代医生，却对医生提出了更高要求。”张钹说。\n在他看来，\n懂AI、用AI、解释AI是未来医生的基本素养\n，未来医生的临床决策与系统思维能力应当更强，医生的沟通能力与人文素养将被“放大”。此外，医生的跨学科协作与流程再造能力不容忽视，法规、伦理与安全意识也要不断增强。\n“在AI时代，医生还要保持自我更新能力，把AI作为‘外挂’。”张钹说，医疗知识的半衰期越来越短，新药、新指南、新证据层出不穷，“AI可以是你随身的‘更新雷达’，但最后还是要你自己判断——哪些值得用于改变自己的实践。”\n“AI加速医疗变革的时代，AI与医生的关系并非替代而是‘共生’。”张钹表示，AI时代，医生能成为有判断力的决策者、有温度的沟通者、懂技术边界的践行者。\n据《科技日报》",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU4MzYxOTIwOQ==&mid=2247522178&idx=1&sn=e256968c2c8d37fd5ec1b6ea7643e1e5&chksm=fceba662676cdd2819c98bac5e1bb4fa181804ac19a8493fb52b14e989eb0e9e9e6003126468&scene=0&xtrack=1#rd",
      "publish_time": 1766848800,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1766988598,
      "last_modify_ts": 1766988598
    },
    {
      "id": 27,
      "article_id": "51478",
      "title": "Meta公布“超级智能”新进展：无需人类，软件Agent即可自我训练！",
      "description": "近年来，基于大语言模型的软件工程智能体发展迅速，但依赖人工数据和开发轨迹，难以自主创新。为此，Meta与伊利诺伊大学团队提出Self-play SWE-RL（SSR），作为新型训练范式。SSR仅需极低数据假设，通过自我对弈机制，使智能体在无监督环境下自主生成问题与解决方案，逐步演化出超越人类经验的编程能力，推动软件工程智能体向超级智能迈进，为自动化软件开发提供新路径。",
      "content": "近年来，基于大语言模型（LLMs）的软件工程智能体发展迅速，但其训练数据和训练环境仍高度依赖人类知识和人工策划，本质上是在复现人类开发轨迹，难以自主发现新的问题结构与解决策略，这从根本上制约了智能体迈向超级智能的能力。\n基于此，来自Meta、伊利诺伊大学厄巴纳-香槟分校的研究团队提出 Self-play SWE-RL（SSR），作为软件工程智能体训练范式的第一步。该方法对数据假设的要求极低，\n仅需访问包含源代码和已安装依赖项的沙盒化代码仓库，无需任何人工标注的问题或测试用例\n。\n研究表明，智能体可以从真实世界的软件仓库中自主获取学习经验，\n有望催生在系统理解、解决全新问题以及从零开始自主创建软件等方面超越人类能力的超级智能系统\n。\n论文链接：https://arxiv.org/pdf/2512.18552\nSelf-play SWE-RL 框架\nSSR 的设计原则是\n减少对代码库先验知识的依赖\n，以提升方法的通用性与可扩展性。它不依赖于特定环境的预配置，智能体要通过与环境的交互，自主探索测试的运行方式并理解其结构。该极简输入设定使 SSR 几乎无需额外配置即可应用于不同代码库，显著降低了使用与迁移成本。\nSSR 的核心是\n通过自博弈式的迭代循环，使智能体在不断生成与解决 Bug 的过程中实现自我提升\n。在 SSR 中，同一 LLM 策略被划分为两个协同演化的角色，分别是智能体 Bug 注入与智能体 Bug 求解，二者共享参数但承担不同任务。\n图| SSR 的总体框架\n1.智能体 Bug 注入\n智能体 Bug 注入通过\n让模型扮演“破坏者”构建起自驱动的进化闭环\n。\n在这一过程中，首先生成包含 Bug 补丁和弱化测试的 Bug 构件，将抽象错误转化为标准化的练习题；随后，运用“删除关键代码”或“回滚历史修复”等复杂生成策略，从真实工程逻辑中制造出极具挑战的高质量难题；为了确保逻辑严密，系统利用“逆向变异测试”进行严格的一致性验证，剔除无关干扰并确保错误可复现；最后，通过动态奖励机制将任务难度维持在“跳一跳才够得着”的区间，并将修复失败的尝试转化为高阶缺陷循环利用，从而在无需人类标注的情况下，驱动智能体在博弈中不断实现自我超越。\n图| 智能体 Bug 注入中“删除关键代码”和“回滚历史修复”的策略\n2.智能体 Bug 修复\n智能体 Bug 修复通过在沙盒中应用缺陷补丁并重置 Git 历史来构建防作弊的代码现场，确保模型无法走捷径。随后，以弱化测试的逆向补丁作为任务提示，取代人类的文字描述，迫使代理纯粹基于代码逻辑定位问题。在修复过程中，智能体通过“推理与工具调用”的交互循环，在模拟环境中自主进行补丁尝试与验证。最终，系统通过回滚原始测试文件的评估机制进行严苛复核，确保生成的 Bug 在真实测试下依然有效，从而完成从理解考题到提交正确答案的闭环。\n图| 智能体 Bug 修复的流程\n实验结果\n研究人员在 SWE-bench Verified 与 SWE-bench Pro 上，对基础模型、基线强化学习方法以及 SSR 进行了系统比较。\n实验结果表明，即使在完全不接触任务描述和测试数据的情况下，SSR 仍能在训练过程中持续实现性能提升，验证了 LLM 仅通过与真实代码库交互即可增强其软件工程能力。更重要的是，SSR 在整个训练轨迹上始终优于基线 RL，说明\n由模型自主生成的任务相比人工构造的数据，能够提供更具信息量和有效性的学习信号\n。\n图| 训练过程中的基线比较\n研究人员比较了完整的 SSR 与仅进行 Bug 注入或仅进行 Bug 修复的两种变体。\n实验结果表明，完整的自博弈框架性能最优，而单一注入或修复训练均表现不足，前者缺乏从修复过程中的学习，后者受限于静态任务分布。相比之下，自博弈通过同时生成与修复 Bug，使任务分布随训练动态演化，持续提供更丰富的学习信号，从而实现稳定的性能提升。\n图| Self-play Swe-RL的消融研究\n不足与未来展望\n尽管 SSR 在减少人工依赖、实现自我提升方面展现出潜力，但仍处于早期阶段。当前方法依赖显式测试作为判定器，存在奖励投机的潜在风险。同时，验证机制主要基于单元测试，难以覆盖真实软件工程中的高层目标与复杂语义。此外，Bug 注入与修复角色共享同一模型配置，尚未系统探索模型规模、结构差异及角色分离对自博弈学习的影响。\n此外，研究人员还探索了若干未取得理想效果的方向，例如，自然语言 issue 生成受限于模型能力与奖励设计，难以保证质量与多样性；仓库专用训练因数据多样性不足未能带来收益；而训练不稳定性则成为限制 SSR 进一步扩展的重要瓶颈。\n展望未来，SSR 为自博弈驱动的软件工程智能体打开了多个研究方向，包括通过种子机制控制错误分布、合成更复杂的多步软件任务，以及设计适用于长周期软件开发的高效训练范式。尤其是在\n奖励稀疏、决策链条极长的真实工程场景中，如何引入更密集、结构化的反馈，将是释放自博弈潜力、迈向更高层次智能的关键\n。\n整理：潇潇\n如需转载或投稿，请直接在本文章评论区内留言。",
      "article_url": "https://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&mid=2247601592&idx=1&sn=4af68c6b92aa7f7d9439d963b141d056&chksm=cee9d74e58f57813b21a5a973c6638c03f96e26c635ab573d77423890533b44e65a72a823faf&scene=0&xtrack=1#rd",
      "publish_time": 1766829600,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/pdf/2512.18552\"]",
      "add_ts": 1766988618,
      "last_modify_ts": 1766988618
    },
    {
      "id": 28,
      "article_id": "51477",
      "title": "Nat. Comput. Sci. | 深度学习驱动的电子结构计算",
      "description": "DRUGONE指出，第一性原理电子结构计算长期受限于精度与效率的矛盾，而深度学习的发展为突破该瓶颈提供了新途径。研究综述了两条技术路线：深度学习量子蒙特卡罗（DL-QMC）利用神经网络波函数提升强关联体系计算精度；深度学习密度泛函理论（DL-DFT）则通过预测电子密度、哈密顿量等关键物理量加速计算。两种方法分别在高精度模拟和高效近似中展现潜力，推动电子结构计算迈向智能化新阶段。（150字）",
      "content": "DRUG\nONE\n第一性原理电子结构计算是理解量子多体体系的核心工具，但长期受到精度与计算效率难以兼得的限制。近年来，深度学习的快速发展为突破这一瓶颈提供了全新路径。研究人员系统回顾了深度学习在电子结构计算中的两条核心技术路线：深度学习量子蒙特卡罗（DL-QMC） 与 深度学习密度泛函理论（DL-DFT）。前者以神经网络波函数为核心，显著提升强关联体系的计算精度；后者以预测密度、哈密顿量等基本量为目标，实现对大规模材料体系的高效模拟。这些方法正在重塑电子结构计算的精度–效率版图，并推动量子力学在材料设计与基础科学中的应用边界不断扩展。\n电子结构问题是量子力学的核心内容之一，自量子力学诞生以来，第一性原理计算在物理、化学和材料科学中发挥了不可替代的作用。随着计算硬件与理论方法的发展，常规电子结构计算已从小分子扩展至包含上千原子的复杂体系。\n然而，不同方法之间长期存在根本权衡：\n量子蒙特卡罗方法具备极高精度，但计算成本巨大；\n密度泛函理论在效率上具有优势，但精度受限于泛函近似。\n深度学习的引入，为同时提升精度与效率提供了新的可能性。研究人员指出，当前最具代表性的突破集中在 DL-QMC 与 DL-DFT 两个方向。\n图 1｜深度学习量子蒙特卡罗（DL-QMC）与深度学习密度泛函理论（DL-DFT）的整体流程。\n深度学习量子蒙特卡罗（DL-QMC）\nDL-QMC 的核心思想是使用神经网络作为多电子波函数的表达形式，在变分量子蒙特卡罗框架下优化能量。相较传统波函数假设，神经网络具有更强的表示能力，能够更充分地捕捉电子关联效应。\n研究人员总结了 DL-QMC 的关键进展：\n在实空间与第二量子化框架下构建神经网络波函数；\n引入自注意力、Transformer 等结构增强表达能力；\n与扩散蒙特卡罗结合，显著提升基态与激发态精度。\nDL-QMC 已在分子、固体、莫尔体系和强关联电子系统中达到或逼近化学精度，在多个经典难题上刷新了基准结果。\n图 2｜DL-QMC 方法发展的时间线与代表性网络架构。\nDL-QMC 的应用范围与能力边界\nDL-QMC 不仅能够计算基态能量，还可扩展至：\n激发态与能隙计算；\n电偶极矩、极化率等静态物性；\n量子相变识别与关联相行为研究；\n势能面构建与有限温度动力学。\n研究人员指出，尽管 DL-QMC 在精度上极具优势，但其计算规模目前仍受限，难以直接应用于高通量或超大体系。\n图 3｜DL-QMC 可处理的体系类型与物理问题。\n深度学习密度泛函理论（DL-DFT）\n与 DL-QMC 追求极致精度不同，DL-DFT 以高效模拟真实材料体系为主要目标。其核心策略是用神经网络直接预测 DFT 中的“基本量”，例如：\n电荷密度；\n哈密顿量；\n密度矩阵。\n通过一次性预测收敛结果，DL-DFT 可绕过自洽场迭代，大幅降低计算成本。\n研究人员强调，DL-DFT 的成功依赖于两类关键物理先验：\n量子近视性原理（局域性）；\n欧氏群 E(3) 等变性（旋转、平移不变性）。\n图 4｜DL-DFT 的基本思想：预测电子结构基本量并进行后处理。\nDL-DFT 的应用与最新进展\nDL-DFT 已在多个方向展现出强大潜力：\n快速预测能带结构、声子谱与光学性质；\n显著加速大体系 DFT 计算的收敛；\n扩展至扭转双层材料、异质结构等超大体系；\n初步拓展至混合泛函与 GW 等更高阶理论。\n研究人员指出，DL-DFT 在计算规模与泛化能力上已展现出向“电子结构基础模型”演进的潜力。\n图 5｜DL-DFT 在电荷密度、哈密顿量与大规模材料模拟中的代表性应用。\n挑战与未来展望\n尽管进展显著，研究人员也明确指出当前仍面临多重挑战：\nDL-QMC 的计算规模与高通量能力仍受限；\nDL-DFT 在高阶理论中的适用性有待进一步验证；\n大规模、高质量训练数据的构建成本高昂；\n自动化后处理与可解释性仍需加强。\n展望未来，研究人员认为 DL-QMC 与 DL-DFT 的深度融合，以及与量子嵌入、多尺度模拟和生成模型的结合，有望催生新一代通用电子结构计算框架，为材料发现和量子科学研究提供强有力支撑。\n整理 | DrugOne团队\n参考资料\nTang, Z., Chen, H., Li, Y. et al. Deep-learning electronic structure calculations. Nat Comput Sci 5, 1133–1146 (2025).\nhttps://doi.org/10.1038/s43588-025-00932-4\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512369&idx=2&sn=805c99d487febc06471e7b8c57323a52&chksm=fd0025d0cec9847011d34553661b8d2f138ecc19d342203fb294ac938ef3e9d08e38622a7ad1&scene=0&xtrack=1#rd",
      "publish_time": 1766827800,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s43588-025-00932-4\"]",
      "add_ts": 1766988623,
      "last_modify_ts": 1766988623
    },
    {
      "id": 30,
      "article_id": "51475",
      "title": "英伟达成美国大模型开源标杆：Nemotron 3连训练配方都公开，10万亿token数据全放出",
      "description": "英伟达推出“最高效的开放模型家族”Nemotron 3，采用混合Mamba-Transformer MoE架构与NVFP4低精度训练技术，性能媲美主流开源模型，速度提升1.5-3.3倍。其开源范围空前，涵盖模型权重、超10万亿token训练数据、预训练与后训练软件及完整训练配方，推动AI开放生态发展。",
      "content": "梦晨 发自 凹非寺\n量子位 | 公众号 QbitAI\n英伟达在开源模型上玩的很激进：\n“最高效的开放模型家族”Nemotron 3，混合Mamba-Transformer MoE架构、NVFP4低精度训练全用上。\n而且开放得很彻底：\n不仅开放模型权重，还要把超过10万亿token的训练数据、预训练和后训练软件、训练配方全部公开。\n与其他开源模型相比性能有竞争力，且速度快1.5-3.3倍。\n把Mamba和Transformer混着用\nNemotron 3在架构层面追求推理效率的最大化。\n传统Transformer的自注意力机制需要对不断增长的KV Cache做线性扫描，序列越长，计算开销越大。\n英伟达的解决方案是大量使用Mamba-2层替代自注意力层——Mamba层在生成时只需要存储固定大小的状态，不受序列长度影响。\n以Nano型号为例，整个模型主要由交替堆叠的Mamba-2层和MoE层构成，自注意力层只保留了少数几个。\n论文给出的层排布模式是：5个Mamba-2+MoE的重复单元，接3个同样结构的单元，再来1个包含注意力层的单元，最后是4个Mamba-2+MoE单元。\n在8k输入、16k输出的典型推理场景下，Nemotron 3 Nano 30B-A3B的吞吐量是Qwen3-30B-A3B的3.3倍。序列越长，优势越明显。\n与此同时，模型在长上下文任务上的表现并没有打折扣。\n论文展示了一组RULER基准测试的结果：在100万token输入长度下，Nemotron 3 Nano基座模型拿到了68.2分，而在同样条件下训练的Nemotron 2 Nano 12B只有23.43分，出现了断崖式下跌。MoE混合架构在长度外推上的鲁棒性明显更好。\nLatentMoE：在潜空间里做专家路由\n针对Super和Ultra这两个更大的模型，英伟达提出了LatentMoE架构，在潜在空间中进行专家计算。\nMoE层在实际部署时会遇到两类瓶颈：\n低延迟场景下，每次只处理几十到几百个token，此时从显存读取专家权重成为主要开销。\n高吞吐场景下，一次处理数千token，此时专家间的all-to-all通信成为瓶颈。两种情况下，开销都与隐藏维度d线性相关。\nLatentMoE的做法是：先把token从原始隐藏维度d投影到一个更小的潜在维度ℓ（通常是d的四分之一），在这个低维空间里完成专家路由和计算，最后再投影回原始维度。\n这样一来，每个专家的权重加载量和通信量都降低了d/ℓ倍。省下来的计算预算被用于增加专家数量和每个token激活的专家数。\n标准MoE用128个专家、激活6个；LatentMoE用512个专家、激活22个。\n两者的总参数量和激活参数量几乎相同（都是8B激活、73B总参），但LatentMoE在所有下游任务上都取得了更好的成绩——MMLU-Pro从48.30提升到52.87，代码任务从51.95提升到55.14，数学任务从78.32提升到80.19。\n需要注意的是，路由门控网络、共享专家计算以及非专家层仍然保留在原始维度，因为这些部分对瓶颈的贡献很小。\n用NVFP4训练250亿token\nSuper和Ultra还采用了NVFP4格式进行训练，这是英伟达在低精度训练上的又一次探索。\nNVFP4是一种4位浮点格式，采用E2M1的元素格式（2位指数、1位尾数），配合16元素的微块缩放和E4M3格式的块缩放因子。在GB300上，FP4的峰值吞吐量是FP8的3倍。\n论文显示，团队已经用NVFP4格式稳定训练了高达25万亿token。与BF16训练相比，Nano模型的损失差距控制在1%以内，8B激活参数的更大模型差距进一步缩小到0.6%以内。\n在MMLU、GSM8K、HumanEval等下游任务上，NVFP4训练的模型与BF16版本的准确率曲线几乎完全重合。\n不过并非所有层都适合量化到NVFP4。团队发现Mamba输出投影层在量化后会出现高达40%的flush-to-zero现象，因此保留在MXFP8精度；QKV投影和注意力投影保留在BF16以维持少量注意力层的保真度；网络最后15%的层也保持高精度以确保稳定性。MTP层和潜在投影由于对推理时间影响很小，同样保留在BF16。\n多环境强化学习一把训到底\nNemotron 3的后训练采用了多环境强化学习，覆盖数学推理、竞赛编程、指令遵循、软件工程、搜索、对话、通用工具使用、长上下文等多种任务。\n与之前分阶段训练不同能力的做法不同，这次英伟达选择同时训练所有任务。\n论文指出，这种同步训练方式更稳定，更不容易出现reward hacking，也避免了分阶段训练常见的能力退化问题。\nAIME25数学分数从80提升到90，LiveCodeBench从65提升到72，τ²-Bench工具使用从40提升到50左右，全程呈稳定上升趋势。\n高效的推理吞吐量在这里发挥了重要作用。\n大规模RL需要生成海量rollout样本，Nemotron 3的混合架构相比其他开源模型有显著优势。\n团队还采用了异步RL架构来解耦训练和推理，并利用多token预测加速rollout生成。训练算法方面使用GRPO配合masked importance sampling来处理训练策略和rollout策略之间的差异。\n整个后训练软件栈以Apache 2.0协议开源，包括NeMo-RL（可扩展RL训练）和NeMo-Gym（RL环境集合）两个仓库。\n此外，Nemotron 3还支持推理时的思维预算控制。\n用户可以指定思维链的最大token数，当模型达到预算时，追加一个标记即可让模型基于部分思维链生成最终回答。\n论文给出了准确率与平均生成token数之间的权衡曲线，这为实际部署中的效率-精度平衡提供了细粒度控制。\n论文地址：\nhttps://arxiv.org/abs/2512.20856\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858336&idx=2&sn=244c2f91a7c513653e6a503d313ab0c7&chksm=e999c35dbecef55ebc38572615b1c7f54455ed94d1bf7b936fff424b72dea3fd3ee4a92fcac8&scene=0&xtrack=1#rd",
      "publish_time": 1766827200,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.20856\"]",
      "add_ts": 1766988634,
      "last_modify_ts": 1766988634
    },
    {
      "id": 32,
      "article_id": "51473",
      "title": "特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了",
      "description": "英伟达机器人主管Jim Fan称特斯拉FSD v14首个通过“物理图灵测试”，并给予高度评价。他在平安夜亲身体验FSD v14自动驾驶，从公司一路自主驾驶送其回家，深感震撼。尽管入手特斯拉较晚，但他作为早期体验者认为，FSD v14展现出接近人类的驾驶能力，标志着AI在真实物理世界中实现重大突破，是首次真正感受到机器具备类人驾驶智能的时刻。",
      "content": "Jay henry 发自 凹非寺\n量子位 | 公众号 QbitAI\n特斯拉FSD v14，首个通过「物理图灵测试」的AI。\n为特斯拉「颁发」这一殊荣的并非别人，而是英伟达大名鼎鼎的机器人主管——\nJim Fan\n。\n平安夜前夕，这位英伟达Project GR00T的领军人物，在亲眼看到自家特斯拉的一路自主护送自己回家后，大受震撼：\n我入手特斯拉比较晚，但却是最早体验FSDv14的用户之一。这可能是我第一次真正感受到通过物理图灵测试的AI：结束一天漫长的工作后，你只需按下一个按钮，放松地靠在座椅上，完全分不出开车的是神经网络还是真人司机。\nJim Fan表示，FSD带来的第一感觉是「不可思议」，并且很快就已经渗透进了他的生活，甚至开始有点「上瘾」。\n一开始你会觉得这不太真实，然后它就成了日常。再然后，就像智能手机一样，一旦失去它，你就会非常难受。\n这就是人类如何被重新塑造，并最终沉迷于技术。\n当然，FSD v14.2.2不是独属于Jim Fan的专属礼物。在陆续收到新版FSD推送后，特斯拉车主们的反馈也迅速刷屏——一句话总结：\n玩疯了\n。\n特斯拉圣诞狂欢\n首个得到英伟达机器人主管「背书」、被称为通过「物理图灵测试」的AI，在这个圣诞节火遍全网。\n这个圣诞节，特斯拉给车主们送来了一波至尊升级，网友一顿测试下来，结论几乎是清一色的：\n满意满意，相当满意，绝对是迄今为止最好的一版FSD。\n看到这一幕，老马自然更是高兴坏了，开始在社交平台上疯狂转发各类车主分享视频。\n在这批「老马严选」中，FSD的表现相当吸睛。但更值得关注的，或许是车主们的反应——\n全部异常兴奋，甚至「吓」坏了的那种\n。\n比如这位花臂老哥，发现FSD能读懂停车场显示屏，在识别到「车位已满」后果断跳过该楼层，激动得像看到自家孩子考了满分。\n下面这位小姐姐最开始没感到有啥变化，但一开始变道就出现了端倪——一秒进入「老司机」模式，\n说换就换，相当果断，不再打大半天转向灯\n。\n如果说这些还只是「懂车人」的兴奋，那下面这段视频就更有反差感了。\n车主拉上了自己从未体验过自动驾驶的奶奶，上来就给老人家配置拉满，体验最新最强FSD，直接给奶奶整出了「恐怖谷效应」。\n事实上，在新版FSD彻底火遍全网之前，马斯克本人早已抢先「上车」。\n当晚，他在社交平台发文称，自己亲自体验了一次\n无安全员的Robotaxi\n测试，并直言体验近乎「完美」。\n周日，我坐在副驾驶座上，一辆没有安全监控系统的特斯拉载着我在奥斯汀转了一圈，全程驾驶表现完美。\n这一帖子下面，\n特斯拉AI总监Ashok Elluswamy\n发布了自己的体验视频，用词同样难掩兴奋。\n这是一次令人惊叹的体验！\n当然，「老马严选」的车主，可能存在幸存者偏差；特斯拉高管站台，也不够令人信服。\n但从其他网友的实测反馈来看，新版FSD这一个个「惊喜」背后，的确有迹可循。\n旧版本的老克星——\n死胡同\n场景，基本已经能解决了：\n雨天，车流巨大、拥堵至极的曼哈顿街头，依然能注意到警车，并且主动避让：\n在狭窄车道多盲区的情况下，能及时识别到左侧有行人出现：\n整体看下来，网友们的体验反馈集中在两方面：\n更像老司机：\n变道丝滑没有犹豫，速度也更合适。能明显感觉到决策过程更快，并且会果断执行。\n脑子更灵光：\n旁边车道有摩托车、维修车辆和人员时，会早早留出空间。\n而这些叠加在一起，最终体现为长时间驾驶可靠性的大幅提升。\n我憋不住了：我的特斯拉第一次载着我们全家，从自家车道一路开到父母家，整整一个半小时车程……我一次都没碰方向盘。\n本月初，马斯克曾放下豪言：要在三周内彻底实现奥斯汀区域Robotaxi的无人驾驶，移除安全监控，副驾驶也不再坐人。\n而现在看来，新版FSD正在把这句豪言化为现实——不仅远超车主预期，甚至让英伟达机器人主管，都直呼不可思议。\n特斯拉如期而至的这份「圣诞礼物」，或许是自动驾驶迈向新阶段的，又一次涌现时刻。\nFSDV14.2.2\n这波FSD（监督版）v14.2.2更新，核心变化集中在神经网络视觉编码器的升级，整体感知与理解能力明显增强。\n新版本利用更高分辨率视觉输入，强化了对紧急车辆、道路障碍物以及人体手势等复杂场景的识别能力。\n比如，在Reddit网友分享的案例中，新版FSD展现了对小动物等异常交通行动者的避让能力。\n而在特殊车辆识别与响应策略上，v14.2.2对警车、消防车、救护车等场景进行了专门优化，新增靠边停车或主动避让紧急车辆的决策与执行逻辑。\n在导航与路径规划层面，v14.2.2引入了更动态的规划能力，可实时应对拥堵、临时绕行等路况变化，而不再完全依赖预设路径。\n泊车能力也是本次更新的重要增强方向，系统新增了「到达选项」，可根据个人偏好选择停车场、路边或地下车库等不同到达方式，导航终点会随之动态调整。\n一位网友分享了FSD v14.2.2在自家车库的倒车入库的视频，哪怕车道上还停着另一辆车，也非常丝滑。\n同时，FSD会记忆并绑定车主的到达偏好与常用停车位置，并保存到具体目的地。后续由推理模型评估可行的到达方案，并给出一个默认推荐选项，从而减少人工干预。\n在驾驶风格控制上，FSD本次全量推送了两种新的速度模式，相比此前的CHILL（冷静）模式，风格区分更加明确：\nSLOTH模式：整体速度更低，车道选择与决策更保守；\nMADMAX模式：速度更高，变道更积极。\n需要注意的是，特斯拉也强调，单车的实际驾驶行为仍会受到车主画像的显著影响。用户历史驾驶越激进，系统允许的最高速度与决策风格也会随之调整，某种程度上是「因人而异」的自适应策略。\n此外，「启动自动驾驶」按钮中的刹车确认机制已默认关闭，用户无需再通过踩下并松开刹车来确认，只需在触控屏上操作即可进入自动驾驶状态。\n虽然FSD v14.2.2这次的更新，表面还是一次基于FSDv14版本的微调，但配上老马高强度推特宣发的佐料，剑指Waymo的意图已经非常明显了。\n和Waymo大战已经硝烟弥漫\n先说结论：在Robotaxi这条赛道上，Waymo仍然占据先机，是当前北美市场在落地规模和市场份额上的绝对领先者；而特斯拉正凭借FSD的持续演进，在规模化路径上加速追赶。\n从奥斯汀这个近期最受关注的战场来看，差距依然清晰。\n特斯拉自今年6月在奥斯汀启动Robotaxi服务以来，目前部署规模约\n30\n辆左右。\n而Waymo早在3月就已在当地上线，当前在运营的自动驾驶车辆接近\n200\n辆。\n如果把视角拉到全美范围，Waymo的领先优势更加明显。\n除奥斯汀外，Waymo还已在菲尼克斯、旧金山、洛杉矶和亚特兰大提供Robotaxi服务，车队总规模超过\n2500\n辆。\n同时，Waymo还计划在2026年扩展至另外20座城市，其中包括达拉斯、华盛顿、迈阿密，甚至伦敦。\n在运营与营收层面，Waymo也已经跑在前面。\n其每周付费行程超过\n45\n万单，2025年全年完成约\n1400万\n次出行；自2020年启动Robotaxi业务以来，累计出行次数已超过\n2000\n万次。\n相比之下，\n特斯拉的运营版图仍然相当有限\n，目前只覆盖德州奥斯汀以及旧金山湾区的部分区域。\n今年10月，在特斯拉第三季度财报电话会上，马斯克曾表示，预计将在年底前在内华达州、佛罗里达州和亚利桑那州推出Robotaxi服务。\n但截至12月中旬，这一目标仍未兑现。\n在加州，根据CPUC和加州机动车管理局（DMV）的说法，特斯拉尚未获得运营商业化Robotaxi服务所需的许可，这也直接限制了其扩张节奏。\n不过，随着FSD能力的持续提升，以及Waymo在旧金山大停电事件中的失误被放大讨论，特斯拉在舆论和用户层面的关注度正在明显上升。\n根据Apptopia数据，自9月上线以来，截至12月12日，TeslaRobotaxi应用累计安装量已达\n52.9万\n次，过去30天的日均下载量为\n2790\n次。作为对比，Waymo应用在同一时间段内的日均下载量为24831次。\n虽然差距依旧明显，但特斯拉的增长趋势正在形成。\n在技术层面，双方的分歧也逐渐走向台前。\n最近，马斯克在X上公开回应了好兄弟、特斯拉前AI负责人安德烈·卡帕西（AndrejKarpathy）的相关观点。\n一年前，卡帕西曾表示：\nWaymo的问题在硬件，特斯拉的问题在软件。\n近期，有网友询问喜提特斯拉新车的卡帕西是否仍然坚持这一判断。\n卡帕西的回应是：Waymo和特斯拉的驾驶体验都已经接近「完美驾驶」，确实存在差异，但只有在特定场景中才会显现。\n而旧金山停电事件就是其中一个例子。\n这一表态，被部分人解读为：\n特斯拉FSD仍略逊于Waymo\n。\n对此，马斯克直接反驳称：\n安子的认知在这一点上已经有些过时了。\n自他离开之后，特斯拉的AI软件已经取得了巨大的进步，远非当年可比。\n以每GB计的智能密度来看，特斯拉AI至少比当前其他任何系统高出一个数量级。\n不少网友也站在了马斯克一边，认为\n特斯拉的自动驾驶能力已经超越Waymo\n。\n也有更理性的分析指出，双方差异的根源在系统架构：\nWaymo采用的是模块化自动驾驶体系，高度依赖高精地图、激光雷达、传感器、5G网络以及远程人工确认。\n这种方案在正常情况下表现稳定，但一旦关键模块失效，系统就会迅速退回到安全策略，例如在停电时进入「变砖模式」。\n而特斯拉FSD走的是端到端神经网络路线：\n通过一个超大模型，直接将摄像头像素映射到转向和制动控制，以海量真实驾驶数据取代人工规则。\n这种方案在极端情况下更具适应性，但也对模型能力提出了更高要求。\n所以，现实依然是，Waymo在规模、合规和商业化进度上处于绝对领先；特斯拉押注的是FSD成熟后带来的指数级扩张能力。\n而随着亚马逊Zoox等玩家继续入场，北美Robotaxi赛道还远未定局。\n不过，可以确定的是，这将是一场长期、烧钱、且高度依赖技术路线选择的绞肉战场。\nOne More Thing\n值得一提的是，在前段时间旧金山停电事件中，马斯克还贴脸开大嘲讽Waymo。\n特斯拉Robotaxi就没受到旧金山停电的影响。\n俗话说，趁你病，要你命，老马的这番拷打也足足给特斯拉吸了一波大粉，该贴点赞已超9.9万。\n不过，回到常态，理性分析来看，自动驾驶的桂冠最终将花落谁家，难有定论。\n但可以确定的是，随着技术不断成熟，汽车是否具备「自动驾驶」能力，不再仅仅从一项锦上添花的附加功能，而是会在真正左右消费者的购车决策。\n而在新版FSD实现实力口碑双丰收后，特斯拉似乎再次瞄准这一争议点，在微博暗暗发布了挑衅：\n将来无法实现自动驾驶的车就像……（大哥大）\n参考链接：\n[1]https://x.com/DrJimFan/status/2003593613918531891\n[2]https://www.cnbc.com/2025/12/16/waymo-amazon-zoox-tesla-robotaxi-expansion.html\n[3]https://medium.com/@akshay.x/teslas-ex-ai-chief-backed-waymo-elon-musk-pushed-back-9351f0397a53\n[4]https://x.com/Yuchenj_UW\n[5]https://www.tesla.com/support/fsd?utm_source=chatgpt.com\n[6]https://www.reddit.com/r/TeslaFSD/\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858281&idx=1&sn=d884333735841a544fbdb16f21ed4528&chksm=e9bcc3d97811fe65fc7f97751242bcae9383c4b518d21c3748d7bb6bcc884ccf0335caafe68f&scene=0&xtrack=1#rd",
      "publish_time": 1766827200,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/DrJimFan/status/2003593613918531891\", \"https://www.cnbc.com/2025/12/16/waymo-amazon-zoox-tesla-robotaxi-expansion.html\", \"https://medium.com/@akshay.x/teslas-ex-ai-chief-backed-waymo-elon-musk-pushed-back-9351f0397a53\", \"https://x.com/Yuchenj_UW\", \"https://www.tesla.com/support/fsd?utm_source=chatgpt.com\", \"https://www.reddit.com/r/TeslaFSD/\"]",
      "add_ts": 1766988648,
      "last_modify_ts": 1766988648
    },
    {
      "id": 33,
      "article_id": "51472",
      "title": "超越GPT-5、Gemini Deep Research！人大高瓴AI金融分析师，查数据、画图表、写研报样样精通",
      "description": "中国人民大学高瓴人工智能学院推出多模态金融研报生成系统“玉兰·融观”（Yulan-FinSight）。该AI系统可自动解析用户研究需求，智能拆解任务，从互联网和金融数据库中采集股价、财报、新闻等多源异构数据，自动生成结构完整、内容专业的金融分析报告，涵盖企业发展历程、核心业务、财务分析等内容，并支持生成专业图表，实现端到端的自动化金融投研辅助，显著提升研究效率与准确性。",
      "content": "FinSight团队 投稿\n量子位 | 公众号 QbitAI\n能自动查数据、写分析、画专业金融图表的AI金融分析师来了！\n最近，中国人民大学高瓴人工智能学院提出了一个面向真实金融投研场景的多模态研报生成系统——\n玉兰·融观\n（Yulan-FinSight）\n。\n面对用户的研究需求，FinSight能够自动拆解任务，从互联网和金融数据库中搜集包括股价、财报、新闻在内的\n多源异构数据\n，并生成包含“发展历程”、“核心业务架构”、“竞争格局”等章节的\n万字图文报告\n。\n△\n可在FinSight预设基础上自行配置\n该系统也在\nAFAC 2025 金融智能创新大赛挑战组\n的1289支队伍中夺冠，并在多项评测中超越了GPT-5 w/Search、OpenAI Deep Research与Gemini-2.5-Pro Deep Research，展现出接近人类专家的金融分析与写作能力。\n下面来看详细内容。\n为什么通用AI做不好金融研报？\n在研究者看来，问题的关键并不在于模型“不会写字”，而在于金融行业的研究报告本身是一项\n高度结构化、强逻辑、强可视化\n的专家级工作，涉及多个流程。\n相比通用问答、检索或文本生成任务，金融投研对数据整合能力、分析深度以及表达形式均提出了更高要求。\n具体而言，现有通用AI系统主要面临三方面挑战：\n1、领域知识与数据割裂：\n通用搜索系统难以有效整合股价、财务报表等结构化金融数据与新闻、公告等非结构化信息。由于缺乏统一的数据表示与多智能体协作分析机制，系统往往只能对单一信息源进行浅层处理，难以形成系统性的金融洞察。\n2、专业级可视化能力缺失：\n金融研报高度依赖图表来传递高密度信息，但现有模型多只能生成静态图片或简单折线图，难以支持多维对比、事件标注等专业金融可视化需求，图文之间也缺乏严格的数据一致性约束，例如，图文无关或图文信息矛盾与冲突。\n3、缺乏“迭代式研究”能力：\n绝大多数系统仍采用固定的“先检索—后生成”流程，研究路径一旦确定便难以调整。\n相比之下，人类分析师往往会根据中间发现不断修正研究重点，而这种基于中间结果的动态策略调整能力，正是现有通用AI系统普遍欠缺的部分。\nFinSight的核心思路：像金融分析师一样工作\n为突破上述限制，FinSight并未简单地“堆模型”，而是从认知流程入手，模拟人类金融专家的工作方式，并提出了三项关键技术创新。\n核心架构：代码驱动的可变内存智能体架构\n△\n从单智能体到多智能体\nFinSight的底层采用了一种全新的、名为\nCode-Driven Variable-Memory\n（CAVM）\n的多智能体架构。\n如图所示，现有Agent 架构本质上仍受限于对话式记忆范式，即以消息或任务进度等历史作为状态载体。这一范式在任务复杂度与流程长度增长时，容易暴露出表达能力与可控性的结构性瓶颈。\nCAVM将这一范式重构为代码驱动的变量记忆空间。系统不再以自然语言对话作为协作媒介，而是将数据、工具与中间推理结果统一映射为可读写的程序变量，由多个\nCode Agent\n通过共享变量空间完成协同推理。\n通过将“记忆”从消息序列提升为可操作的变量结构，CAVM 使复杂任务得以被显式建模、持续修正与模块化组合，为\n长时程、多流程\n的专家级推理提供了必要的结构支撑。\n△\nCAVM架构示意图\n在这一设计中，数据、工具和智能体被统一抽象为可编程变量空间：\n财务报表、行情数据、新闻文本作为数据变量\n搜索、分析、绘图等能力作为工具变量\n不同功能的Agent通过Python代码进行调度与协作\n这种“以代码为中枢”的设计，使系统能够高效处理大规模异构金融数据，并支持复杂的多流程任务协作。\n视觉突破：迭代式视觉增强机制\n针对金融图表生成中普遍存在的专业性与可信度问题，研究者们提出了\nIterative Vision-Enhanced Mechanism\n，将绘图过程建模为一个可迭代优化的视觉生成问题。\n△\nFinSight生成的多维图表\n该机制采用了\nActor–Critic 协作范式\n：\n文本大模型作为\nActor\n，负责生成可编译、可执行的绘图代码，充分发挥其在代码生成与逻辑控制上的优势；而视觉语言模型则作为\nCritic\n，直接对图像进行视觉层面的审视，从数完整性与整体美观性等维度提供反馈。\n这一设计的关键在于\n优势互补\n：语言模型擅长编码与思考，却难以获取真实的视觉反馈；视觉模型具备强大的感知与判别能力，但在复杂代码生成上能力受限。\n通过将二者解耦并置于闭环中，系统在\ntest time\n通过多轮“生成—评估—修正”实现持续优化，使绘图质量随迭代次数自然提升。\n△\n股价、MACD、RSI分析图\n最终，系统能够稳定生成包含双轴对齐、事件标注以及复杂结构的专业金融图表，如图所示，将原本一次性生成的静态结果，转化为一种\ntest-time scaling\n的过程。\n两阶段写作框架：先分析，再成文\n在写作层面，FinSight并不试图一次性生成完整的长篇研报，而是将研报写作重构为\n“分析—整合”\n的两阶段过程。\n△\n两阶段写作框架示意图\n首先，系统生成一组\n“分析链”\n（Chain-of-Analysis，CoA）\n：每条分析链对应一个明确的子任务\n（如公司历程、财务分析、竞争对手分析、风险因素等）\n，在局部范围内完成证据收集、关键判断与核心结论提炼。\n之所以需要这一步，是因为一份研究报告往往由多个子问题耦合构成，若直接端到端生成长文，很难兼顾所有的分析准确性和深度。\n随后，系统以这些CoA作为“骨架”，将分散的洞察在全局层面进行组织与编排，生成大纲并分章节逐步写作：在保证章节结构与论证链条连贯的同时，把文本叙述、数据引用与图表呈现进行对齐，最终合成为一份逻辑自洽的长篇报告。\n这种\n“先分析、后写作”\n的策略有效避免了长文常见的逻辑松散问题，使报告在篇幅超过2万字时仍保持结构清晰、论证深入。\n为了进一步保证长篇研报中的事实准确性与图文一致性，作者在写作阶段还引入了一种\n生成式检索\n（Generative Retrieval）\n机制。\n不同于传统“先检索、后生成”的后处理做法，该方法将检索过程嵌入写作本身：模型在生成具体段落时，会根据当前的分析链与写作上下文，动态生成数据和图片的索引标识符，再通过后处理统一嵌入。\n这样一来，引用准确性和图文一致性得到了最大的保证。\n△\n分析链输出结果\n通过这种方式，FinSight能够在长篇写作过程中持续对齐文本叙述、数据来源与可视化结果，避免常见的事实错配与图文脱节问题，从而在报告篇幅不断扩展的情况下，依然保持整体逻辑与证据链的稳定性与一致性。\n实验结果：全面超越现有Deep Research系统\n作者们在涵盖公司研究与行业研究的高质量基准测试上，对FinSight进行了系统评估。\n结果显示，FinSight在事实准确性、分析深度与呈现质量三项核心指标上均显著优于Gemini-2.5-Pro Deep Research与OpenAI Deep Research，综合评分达到\n8.09\n。\n在可视化维度上，得益于迭代式视觉增强机制，FinSight获得\n9.00\n的评分，明显领先对比系统，体现出对专业金融图表生成能力的有效提升。\n而迭代式绘图的效果分析同样惊艳：\n在长文本生成场景中，系统生成的研报平均长度超过20000字，包含50余张图表与结构化数据引用，且随着篇幅增长，报告质量保持稳定，未出现显著退化。\n此外，在AFAC 2025金融智能创新大赛中，FinSight在来自企业与高校的1289支参赛队伍中\n排名第一\n，获得挑战组赛题四冠军，进一步验证了其在真实场景中的实用性与鲁棒性。\n研究者认为，FinSight并非仅是一个金融工具，而是展示了Agent架构在高复杂度垂直领域的潜力。\n通过统一数据、工具与智能体，并引入视觉与写作的多阶段闭环，AI系统\n首次\n在金融投研这一“专家密集型”场景中，展现出接近人类分析师的工作能力。\n这一范式的意义不止于金融。\n它表明，在那些高度依赖专业知识、长时程推理与多模态表达的“专家密集型”场景中，AI 系统不再只是信息汇总器，而开始承担起类似人类专家的工作方式：\n分解问题、验证假设、修正结论，并最终形成可被审阅与追溯的完整成果。\n从这个角度看，\nFinSight更像是一个起点\n。\n随着Agent架构不断成熟，未来的科研分析、法律研判、医疗决策等复杂领域，或将逐步迎来以专家级AI Agent为核心的新一代生产力形态。\n论文及项目作者：\n中国人民大学高瓴人工智能学院：金佳杰、张宇尧、许一孟、钱泓锦、朱余韬、窦志成\n论文链接：https://arxiv.org/abs/2510.16844\n代码链接：https://github.com/RUC-NLPIR/FinSight\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n我们正在招聘一名眼疾手快、关注AI的\n学术编辑实习生\n🎓\n感兴趣的小伙伴欢迎关注 👉\n了解详情\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858336&idx=3&sn=f9c1a87c7f5962d38ddcf6ed125ab541&chksm=e9b09f2412143db1a1f7cf4de8fdf1d0597c72d0094e715d07c2aaf417781be379e40eed4587&scene=0&xtrack=1#rd",
      "publish_time": 1766827200,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2510.16844\", \"https://github.com/RUC-NLPIR/FinSight\"]",
      "add_ts": 1766988654,
      "last_modify_ts": 1766988654
    },
    {
      "id": 34,
      "article_id": "51471",
      "title": "AI金矿上打盹的小红书，刚刚醒了一「点点」",
      "description": "小红书将原本活跃在评论区的AI助手“点点”升级并移至首页侧边栏，成为常驻功能。此前用户常在评论区@点点互动，如今其角色被官方正式强化，融入主界面，实现更便捷的AI交互体验，标志着平台进一步推动人工智能与社区内容融合。",
      "content": "鱼羊 发自 凹非寺\n量子位 | 公众号 QbitAI\n事情是这样的。\n作为一个小红书重度用户，今天一开软件我天塌了：我的侧边栏呢？？？\n一点进去发现，好家伙，小红书这波操作，终于是\n把官方AI整上了我的首页\n。\n是新功能，但也是老面孔。AI助手名叫\n点点\n，\n用户们应该挺眼熟，就是之前在评论区常会被@的小红书版评论罗伯特。\n我赶紧一个搜索，原来官方真是更新了玩法。\n评论区@不到了，但现在，你可以在小红书里这样玩AI：笔记直接分享给点点，不用手动跳转，即可开启边刷边聊模式。\n还真别说，现在的社交媒体上，要没点AI出没，是有那么点不习惯。\n像微博，不止有到处串场的评论罗伯特，也把「智搜」功能插进了每一个热门话题里，主打一个让用户吃瓜不迷路；而微信，也把元宝总结的功能内置进了公众号文章页面。\n看上去在AI上一直比较保守的小红书，现在也醒了一「点点」。\nAI一点点，体验变好了吗？\nAI一点点，有没有让刷社媒的体验变好，还是得实测一波才知底细。\n交互体验\n先来看看交互方式。\n第一种方式，就是在原来首页侧边栏的位置，\n点击小气泡进入点点对话框\n：\n用法跟别的AI助手没有什么不同，好处就是无需跳转其他App，在小红书本书里就可以提问AI。\n从回答质量上来看，背靠小红书的海量种草内容，让Ta推荐点文娱作品啊，吃吃喝喝啊，效果都不错，可以省去一大波刷笔记的时间（细思……emmm有点微妙\n）。\n第二种方式，就是在笔记页面通过\n分享\n功能，把笔记发给点点开启讨论。\n比较有意思的是，还可以\n划词提问\n，哪里想聊划哪里：\n长按评论区评论\n，同样可以唤醒点点。\n从交互的角度来看，有点随叫随到那意思了。\n吃喝玩乐小帮手\n不知道列位最常用小红书搜罗什么信息，我嘛，主要还是被\n真实评论\n吸引，想买点什么好玩的，吃点什么好吃的，就愿意上小红书种种草。\n那么点点是否能够总结出这些来自用户的真实评价，帮助我们做决策呢？\n正好海淀剧场最近在演开心麻花的《出马》，题材很有意思的样子，这个票钱值不值得花，我决定问问点点。\n点点没有直接给结论，而是帮忙总结了小红书上的各种讨论，把争议点和好评都梳理清楚了。\n至于判断嘛，还得自己下~\n问完看的咱们再问点吃的：\n帮我整理一下北京海淀区有哪些性价比高还好吃的港式餐厅，不要广。\n不知道是不是因为海淀过于美食荒漠了，这次点点的建议还挺明确的。功课做得也比较细心，店面环境、性价比、等位排队情况都有总结到。\n总结信息小工具\n当然啦，家人们大部分刷小红书的时间一定是在\n学习新知识\n！\n比如刷刷量子位，随时掌握最新AI资讯（doge）。\n学习嘛，遇到内容多到10来张图放不下的时候，难免想扮演一下霸道总裁，让小助理直接呈上简报。\n点点作为一个AI助手，干这活儿看上去非常合适。\n我测试了一下，让它在一个包含1200+条评论的播客推荐笔记中，帮我整理出网友们觉得高质量的播客。\n效果打几分，欢迎大家在评论区给我点意见：\n比较不错的一点是，不止是文字笔记，视频笔记点点也同样能帮忙总结。\nAI点了，争议也来了\n总体来说，点点这次在小红书本体里全量上线，确实让\nApp里的AI交互体验变得更方便了。\n看样子，虽然行动上一直以来有点犹抱琵琶半遮面，但这波小红书官方似乎也是下定了决心猛猛推AI。\n不过，用户们并没有AI全肯定，点点官方的评论区，就出现了不少不同意见。\n比如，不少用户跟我一样，第一反应就是：我的侧边栏呢？？？\n很难想象侧边栏场景直接换AI，这种只有老板自上而下能推的动。\n也有用户反馈，认为经过点点过滤的信息，没有自己看笔记得到的信息丰富和友好。\n不过官方也还在一个征求意见改进的阶段，如果你的小红书也已经被点点「刷新」，在12月31日之前，都可以到点点ai的ask me anything笔记下反馈意见。\n总之嘛，「点点」对小红书绝对算得上一个积极的信号。\n因为在AI和大模型热潮中，小红书因为内容生态的独特性、「活人感」，被视为预训练决胜的金矿之一……但就技术和产品的结果呈现来看，这个金矿主人或许还没意识到重要性——当然也有评价是能力不具备。\n好的一面是，现在躺在金矿上的人，看起来要醒了——哪怕是一「点点」。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858567&idx=1&sn=a2c1a9bb04614cc3aacebd870202414d&chksm=e971aa789a9d893667d6badf2a5f281fa5942af651f13e764342d57f2e7b721a82da477e8f78&scene=0&xtrack=1#rd",
      "publish_time": 1766827200,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1766988659,
      "last_modify_ts": 1766988659
    },
    {
      "id": 37,
      "article_id": "51468",
      "title": "P图新手福音！智能修图Agent一句话精准调用200+专业工具，腾讯混元&厦大出品",
      "description": "腾讯混元与厦门大学联合推出JarvisEvo图像编辑智能体，可实现“一句话修图”。该系统模拟人类专家思维，通过迭代编辑、视觉感知、自我评估与反思，像工匠般精细打磨图像。相比传统软件更简便，较AI修图更具可控性，支持Lightroom操作并能自主判断修图效果，实现端到端高质量图像优化，大幅提升编辑效率与质量。",
      "content": "JarvisEvo团队 投稿\n量子位 | 公众号 QbitAI\n一句话让照片变大片，比专业软件简单、比AI修图更可控！\n腾讯混元携手厦门大学推出\nJarvisEvo\n——一个统一的图像编辑智能体模拟人类专家设计师，通过\n迭代编辑、视觉感知、自我评估和自我反思\n来“p图”。\n“像专家一样思考，像工匠一样打磨”\n。JarvisEvo不仅能用Lightroom修图，更能“看见”修图后的变化，并自我评判好坏，从而实现无需外部奖励的自我进化 。\n下面就来了解一下详细情况吧～\n自我评估和修正\n研究背景与动机\n近年来，基于指令的图像编辑模型虽然取得了显著进展，但在追求“专业级”修图体验时，仍面临两大核心挑战：\n指令幻觉 (Instruction Hallucination)：\n现有的文本思维链 (Text-only CoT) 存在信息瓶颈。模型在推理过程中“看不见”中间的修图结果，仅凭文本“脑补”假设进行下一步操作的视觉结果，容易导致事实性错误，无法确保每一步都符合用户意图。\n奖励黑客 (Reward Hacking)：\n在强化学习进行偏好对齐的过程中，策略模型（Policy）是动态更新的，而奖励模型（Reward Model）通常是静态的。这导致策略模型容易“钻空子”，通过欺骗奖励函数获取高分，而非真正提升修图质量和自我评估能力 。\n为了解决上述问题，团队推出了JarvisEvo.\niMCoT：交互式多模态思维链\n打破了传统“盲修”的局限。JarvisEvo 引入了\niMCoT (Interleaved Multimodal Chain-of-Thought)\n机制。与纯文本推理不同，JarvisEvo在每一步编辑后都会生成新的图像，并基于视觉反馈进行下一步推理。\n模型在“生成文本假设 -> 执行工具 -> 观察视觉结果 -> 反思决策”的循环中工作，确保每一步操作都精准落地 。\nSEPO：协同编辑-评估策略优化\n这是JarvisEvo 实现“自进化”的引擎。团队提出了\nSEPO (Synergistic Editor-Evaluator Policy Optimization)\n框架，包含两个协同进化的优化环 ：\n编辑者优化环 (Loop 1)：模型利用自我评估分数作为内在奖励，不再依赖容易被 hack 的外部奖励模型。\n评估者优化环 (Loop 2)：利用人类标注数据持续校准模型的评估能力，防止模型在自我打分时“自欺欺人”。\n在线反思与自我修正\nJarvisEvo具备从错误中学习的能力。在训练过程中，系统会自动将低分轨迹与高分轨迹进行对比，生成\n反思数据 (Reflection Data)。\n模型通过分析“为什么修错了”以及“如何修正”，习得强大的自我纠错能力。\n像人类一样“边看边修”\nJarvisEvo系统架构\n传统的文本思维链（Text-only CoT）通常是“盲修”，即一次性生成所有步骤。\nJarvisEvo则采用了 交互式多模态思维链 (iMCoT)，模拟了人类设计师“观察-操作-检查”的闭环工作流。\n整个推理过程分为四个核心步骤：\n1、视觉感知与规划 (Perception&Planning)：模型首先分析原图（I）与用户指令（Q），生成初始的修图思路。\n2、多步工具执行 (Step-by-Step Execution)：\n模型生成交错的文本推理内容（C）和工具调用指令（T）。\n工具沙盒 (Sandbox)：指令被发送到外部的Adobe Lightroom环境中执行，生成中间态的编辑图像（O）。\n视觉反馈 (Visual Feedback)：这一点至关重要。模型会“看”到刚刚修好的图，基于最新的视觉状态决定下一步是继续调整还是修正错误 。\n3、自我评估 (Self-Evaluation)：修图结束后，模型会对最终结果（Ot）的美学质量和指令符合度进行自我打分（S）。\n4、自我反思 (Self-Reflection)：如果结果不理想，模型会触发反思机制，分析偏差原因并尝试纠正。\n三阶段的训练框架\n为了打造这样一个全能 Agent，团队设计了一套严谨的\n三阶段训练流水线\n：\nStage 1: 冷启动监督微调 (Cold-Start SFT)\n数据量：150K标注样本（110K编辑数据+40K评估数据）。\n目标：教会模型“基本功”。这包括掌握多模态推理的语法、能够交替生成文本与图像内容、学会根据视觉线索选择正确的工具，以及初步建立审美评估能力。\nStage 2: SEPO强化学习 (The Evolution)\n数据量：20K标准指令数据（10K编辑+10K评估）。\n核心机制：引入\n协同编辑-评估策略优化 (SEPO)\n。在此阶段，模型脱离了对标准答案的模仿，开始自主探索。\n双优化驱动： 此阶段让模型从“会用工具”进化为“精通修图”。 编辑者优化：通过自我打分（Self-Reward）优化修图策略，并利用SLM (Selective Loss Masking) 防止奖励作弊。\n评估者优化：利用人类评分数据校准模型的审美眼光，确保它能做一个公正的裁判。\nStage 3: 反思微调 (Reflection Fine-Tuning)\n数据量：5K少量在线生成的反思样本。\n目标：这是JarvisEvo具备“自我纠错”能力的关键。通过学习如何在错误路径上进行反思和修正，模型在处理复杂指令时的鲁棒性大幅提升。\nSEPO：协同编辑-评估策略优化\n在传统的强化学习（RLHF）中，模型通常依赖一个静态的“奖励模型”来打分。\n但这存在一个致命缺陷：随着策略模型越来越强，它会学会“钻空子”（Reward Hacking），即通过生成某些特定的、诡异的模式来骗取高分，而不是真正提升自己的编辑能力。\n为了解决这个问题，JarvisEvo提出了SEPO框架。它的核心思想是：\n让模型既做“运动员”也做“裁判员”，并通过两个并行的优化环，让这两种能力同步提升，互相制约。\nLoop 1编辑者优化环 (Editor Policy Optimization)是让模型学会如何更好地使用工具来修出好图。\n自我奖励 (Self-Reward) 机制：JarvisEvo不再依赖外部黑盒模型打分，而是利用自身的Self-evaluation能力。在生成修图轨迹后，模型会根据最终图像的美学质量和指令遵循度，自己给自己打分。\nGRPO优化目标：采用群相对策略优化 (Group Relative Policy Optimization)。对于同一个输入，模型生成多条修图轨迹，通过比较这些轨迹的“胜率”（Pairwise Preference Reward）来进行更新，而非单纯依赖绝对分数，这使得训练更加稳定。\n选择性损失掩码 (SLM)是其中的关键技术。这是一个防止“作弊”的机制。如果没有SLM，模型可能会发现：“只要我最后生成的自我评分文本是满分，loss就会变小”。\n为了防止这种“信息泄露”，在计算编辑器的梯度时，强制掩盖掉自我评分部分的token。这样逼迫模型只能通过切实提升前面的推理质量 (Chain-of-Thought) 和 工具使用准确性 (Tool Use) 来间接获得高分，而不是直接生成高分文本。\n评估者优化环 (Evaluator Policy Optimization)确保这个“裁判员”是公正、客观且符合人类审美的。\n可验证的强化学习 (Verifiable RL)：虽然Loop 1依赖自我打分，但如果裁判本身审美跑偏了怎么办？Loop 2专门解决这个问题。我们使用包含人类专家标注 (Human-Annotated) 的数据集来训练模型的评估能力。\n分数对齐奖励 (Score Alignment Reward)：在这个循环中，奖励取决于模型打分与人类专家打分的接近程度。\n作用：这个循环不断校准模型的审美标准，防止其在Loop 1中陷入“自欺欺人”的自我陶醉，确保自我奖励信号的含金量。\n这两个循环是交替进行的，形成了一种“左右互搏”的进化效应，打破了静态奖励模型的桎梏，实现了一种\n闭环的、可持续的自我能力提升\n。\n在线反思数据生成机制 (On-Policy Reflection)\nJarvisEvo如何学会“从错误中学习”？团队在Stage 2的训练过程中植入了一个自动化的数据生成：\n捕捉契机：当模型生成了一个更好的修图轨迹Trajectory0（得分s0），且该得分显著高于之前的某次尝试Trajectory3（得分s3）时，触发反思生成。\n归因分析：调用商业大模型（如Gemini-2.5-Pro）作为“导师”，输入源图、错误的修图结果O3、正确的修图结果O0以及用户指令。\n生成反思链：“导师”会生成一段详细的分析文本（R），解释为什么O3失败了（例如“白平衡参数推得太高导致偏色”），并指出正确的做法。\n构建样本：将这段包含“错误尝试 -> 深刻反思 -> 正确修正”的完整轨迹存入数据集Dataset_reft，用于第三阶段的微调。\nArtEdit 数据集\n为了支撑上述训练，团队构建了\nArtEdit\n——一个包含170K样本的双语（中/英）专业修图数据集。\n包含人像、风光、建筑、静物、夜景等10大类、37个子类的专业摄影场景。通过A2L (Agent-to-Lightroom) 协议，无缝集成了Adobe Lightroom中的\n200+\n个修图工具。\nArtEdit-Lr (120K)：专注于修图任务，包含完整的iMCoT轨迹（推理思考、工具参数、中间图）。\nArtEdit-Eval (50K)：专注于审美评估，包含人类专家对图像质量和指令遵循度的打分（1-5分）。\n实验结果\n在ArtEdit-Bench评测中，L1和L2指标上，相比商业级模型Nano-Banana提升了44.96%，最大限度保留了原图细节 。\n在SC（语义一致性）和PQ（感知质量）指标上全面领先，平均提升18.95% 。\n并且其打分与人类主观偏好的相关性（SRCC 0.7243）超越了GPT-4o (Gemini-2.5-flash) 和专门的IQA模型。\n视觉效果上，对比其他模型，JarvisEvo处理后的图像更贴合用户指令，在风格营造、细节呈现等方面表现突出。\n在包含 200 个样本的人类主观评测中，JarvisEvo在与Nano-Banana的对决中取得了49%的胜率（远超对手Nano Banana的28%），证明了其修图结果更符合人类审美 。\n这种“生成器-内部批评家”的协同进化范式具有强大的通用性，未来有望从修图拓展至数学推理、代码生成及长程规划等领域。\n同时，团队将致力于突破当前步数限制，探索超过10步的复杂长程推理任务。\n感兴趣的朋友可戳下方链接了解更多细节～\n项目主页: https://jarvisevo.vercel.app/\n论文全文:\nhttps://arxiv.org/pdf/2511.23002\nGithub：https://github.com/LYL1015/JarvisEvo\nHuggingface Daily Paper：https://huggingface.co/papers/2511.23002\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n我们正在招聘一名眼疾手快、关注AI的\n学术编辑实习生\n🎓\n感兴趣的小伙伴欢迎关注 👉\n了解详情\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858281&idx=3&sn=f97ff85b460b769b6fb3217415640671&chksm=e9079209d939ff3cdc929bcc445062778fb9fd15020f089908956e7e1aadedd475063e233c3e&scene=0&xtrack=1#rd",
      "publish_time": 1766814600,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://jarvisevo.vercel.app/\", \"https://arxiv.org/pdf/2511.23002\", \"https://github.com/LYL1015/JarvisEvo\", \"https://huggingface.co/papers/2511.23002\"]",
      "add_ts": 1766988678,
      "last_modify_ts": 1766988678
    },
    {
      "id": 38,
      "article_id": "51467",
      "title": "",
      "description": "WildVideo首次系统定义9类幻觉任务，构建大规模中英双语视频对话数据集，采用多轮开放问答形式，覆盖双重视角，贴近真实交互场景，全面评估多模态模型在视频问答中的幻觉问题，推动大模型在开放世界多模态理解中的可靠应用。",
      "content": ":\n，\n.\nVideo\nMini Program\nLike\n，轻点两下取消赞\nWow\n，轻点两下取消在看",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652657947&idx=2&sn=63dfa93f493b328bc7e3dabff3f1ea5b&chksm=f098c0ee5782c9f277d48e393d89f0f05754c2e33e9940c01483ee79fbe5e09d02775eb72348&scene=0&xtrack=1#rd",
      "publish_time": 1766810400,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1766988679,
      "last_modify_ts": 1766988679
    },
    {
      "id": 39,
      "article_id": "51466",
      "title": "推理成本打到1元/每百万token，浪潮信息撬动Agent规模化的“最后一公里”",
      "description": "浪潮信息推出元脑HC1000超扩展AI服务器，首次将AI推理成本降至1元/每百万token，大幅降低智能体规模化落地门槛。在AI产业从模型竞赛转向降本增效的关键阶段，该突破有望破解产业化成本瓶颈，推动行业盈利模式成型，重塑AI竞争格局，加速智能体在各领域的广泛应用。",
      "content": "允中 发自 凹非寺\n量子位 | 公众号 QbitAI\n当前全球AI产业已从模型性能竞赛迈入智能体规模化落地的“生死竞速”阶段，\n“降本”\n不再是可选优化项，而是决定AI企业能否盈利、行业能否突破的核心命脉。\n在此大背景下，浪潮信息推出\n元脑HC1000超扩展AI服务器\n，将推理成本首次击穿至\n1元/每百万token\n。\n这一突破不仅有望打通智能体产业化落地“最后一公里”的成本障碍，更将重塑AI产业竞争的底层逻辑。\n浪潮信息首席AI战略官刘军\n强调：\n当前1元/每百万token的成本突破仅是阶段性胜利，面对未来token消耗量指数级增长、复杂任务token需求激增数十倍的必然趋势，现有成本水平仍难支撑AI的普惠落地。\n未来，AI要真正成为如同 “水电煤” 般的基础资源，token成本必须在现有基础上实现数量级跨越，成本能力将从“核心竞争力”进一步升级为“生存入场券”，直接决定AI企业在智能体时代的生死存亡。\n△\n浪潮信息首席AI战略官刘军\n智能体时代，token成本就是竞争力\n回顾互联网发展史，基础设施的\n“提速降费”\n是行业繁荣的重要基石。\n从拨号上网以Kb计费，到光纤入户后百兆带宽成为标配，再到4G/5G时代数据流量成本趋近于零——每一次通信成本的显著降低，都推动了如视频流媒体、移动支付等全新应用生态的爆发。\n当前的AI时代也处于相似的临界点，当技术进步促使token单价下滑之后，企业得以大规模地将AI应用于更复杂、更耗能的场景，如从早期的简短问答，到如今支持超长上下文、具备多步规划与反思能力的智能体……\n这也导致单任务对token的需求已呈指数级增长。如果token成本下降的速度跟不上消耗量的指数增长，企业将面临更高的费用投入，这昭示着经济学中著名的“杰文斯悖论”正在token经济中完美重演。\n（杰文斯悖论是1865年经济学家威廉·斯坦利·杰文斯提出的悖论：指当技术进步提高了效率，资源消耗不仅没有减少，反而激增。例如，瓦特改良的蒸汽机让煤炭燃烧更加高效，但结果却是煤炭需求飙升。）\n来自多方的数据也有力佐证了token消耗量的指数级增长趋势。\n火山引擎最新披露的数据显示，截至今年12月，字节跳动旗下豆包大模型日均token使用量突破\n50万亿\n，较去年同期增长超过10倍，相比2024年5月刚推出时的日均调用量增长达417倍；\n谷歌在10月披露，其各平台每月处理的token用量已达\n1300万亿\n，相当于日均43.3万亿，而一年前月均仅为9.7万亿。\n△\n谷歌公布其token处理量变化\n当使用量达到“百万亿token/月”的量级时，哪怕每百万token成本只下降1美元，也可能带来\n每月1亿美元\n的成本差异。\n对此，刘军认为：\ntoken成本就是竞争力，它直接决定了智能体的盈利能力。要让AI真正进入规模化普惠阶段，token成本必须在现有基础上继续实现数量级的下降。\n深挖token成本“暗箱”：架构不匹配是核心瓶颈\n当下，全球大模型竞赛从“盲目堆算力”转向“追求单位算力产出价值”的新阶段。\n单位算力产出价值受到能源价格、硬件采购成本、算法优化、运营成本等多种因素的影响，但不可否认的是，现阶段token成本80%以上依然来自算力支出。\n而阻碍成本下降的核心矛盾，在于推理负载与训练负载截然不同，沿用旧架构会导致算力、显存与网络资源难以同时最优，造成严重的“高配低效”。\n一是\n算力利用率（MFU）的严重倒挂\n。\n训练阶段MFU可达50%以上，但在推理阶段，特别是对于追求低延迟的实时交互任务，由于token的自回归解码特性，在每一轮计算中，硬件必须加载全部的模型参数，却只为了计算一个token的输出，导致昂贵的GPU大部分时间在等待数据搬运，实际MFU往往仅为5%-10%。这种巨大的算力闲置是成本高企的结构性根源。\n二是\n“存储墙”瓶颈在推理场景下被放大\n。\n在大模型推理中，随着上下文长度的增加，KV Cache呈指数级增长。这不仅占用了大量的显存空间，还导致了由于访存密集带来的高功耗。\n这种存算分离不仅带来数据迁移功耗和延迟，还必须配合使用价格高昂的HBM，已经成为阻碍token成本下降的重要瓶颈。\n三是\n网络通信与横向扩展代价愈发高昂\n。\n当模型规模突破单机承载能力时，跨节点通信成为新瓶颈。传统RoCE或InfiniBand网络的延迟远高于芯片内部的总线延迟，通信开销可能占据总推理时间的30%以上，导致企业被迫通过堆砌更多资源来维持响应速度，推高了总拥有成本（TCO）。\n对此，刘军指出，降低token成本的核心不是“把一台机器做得更全”，而是\n围绕目标重构系统\n——\n把推理流程拆得更细，支持P/D分离、A/F分离、KV并行、细粒度专家拆分等计算策略，让不同计算模块在不同卡上按需配置并发，把每张卡的负载打满，让“卡时成本”更低、让“卡时产出”更高。\n基于全新超扩展架构，元脑HC1000实现推理成本首次击破1元/每百万token\n当前主流大模型的token成本依然高昂。以输出百万token为例，Claude、Grok等模型的价格普遍在10-15美元，国内大模型虽然相对便宜，也多在10元以上。\n在天文数字级别的调用量下，如此高的token成本让大规模商业化应用面临严峻的ROI挑战。\n因此，要打破成本僵局，必须\n从计算架构层面进行根本性重构\n，从而大幅提升单位算力的产出效率。\n△\n主流LLM的百万token价格\n为此，浪潮信息推出\n元脑HC1000超扩展AI服务器\n。\n该产品基于全新设计的全对称DirectCom极速架构，采用无损超扩展设计，可高效聚合海量本土AI芯片，支持极大推理吞吐量，推理成本首次击破1元/每百万token，为智能体突破token成本瓶颈提供极致性能的创新算力系统。\n△\n元脑HC1000超扩展AI服务器\n对此，刘军表示：\n我们看到原来的AI计算是瞄着大而全去建设的，五脏俱全，各种各样的东西都在里面。但是当我们聚焦降低token成本这一核心目标之后，我们重新思考系统架构设计，找到系统瓶颈，重构出一个极简设计的系统。\n元脑HC1000创新设计了DirectCom极速架构，每计算模组配置16颗AIPU，采用直达通信设计，解决传统架构的协议转换和带宽争抢问题，实现超低延迟；计算通信1:1均衡配比，实现全局无阻塞通信；全对称的系统拓扑设计，可以支持灵活的PD分离、AF分离方案，按需配置计算实例，最大化资源利用率。\n△\n全对称DirectCom极速架构\n同时，元脑HC1000支持超大规模无损扩展，DirectCom架构保障了计算和通信均衡，通过算网深度协同、全域无损技术实现推理性能1.75倍提升，并且通过对大模型的计算流程细分和模型结构解耦，实现计算负载的灵活按需配比，单卡MFU最高可提升5.7倍。\n△\n超大规模无损扩展\n此外，元脑HC1000通过自适应路由和智能拥塞控制算法，提供数据包级动态负载均衡，实现KV Cache传输和All to All通信流量的智能调度，将KV Cache传输对Prefill、Decode计算实例影响降低5-10倍。\n刘军强调，当前“1元/每百万token”还远远不够，面对未来token消耗量的指数级增长，若要实现单token成本的持续、数量级下降，需要推动计算架构的根本性革新。\n这也要求整个AI产业的产品技术创新，要从当前的规模导向转为\n效率导向\n，从根本上重新思考和设计AI计算系统，发展AI专用计算架构，探索开发大模型芯片，推动算法硬件化的专用计算架构创新，实现软硬件深度优化，这将是未来的发展方向。\n*本文系量子位获授权刊载，观点仅为原作者所有。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858281&idx=2&sn=a1ab44bada75c81891f63e227d54188f&chksm=e9c0a5bfb19466eb0905956ab1e65b2bfeb616daff587c9d981a512f338cf7f521f07c5193a2&scene=0&xtrack=1#rd",
      "publish_time": 1766809800,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1766988686,
      "last_modify_ts": 1766988686
    },
    {
      "id": 44,
      "article_id": "51505",
      "title": "生物、机器与社会的群体智能——11所高校联合发起的群体智能读书会",
      "description": "「群体智能」读书会由集智俱乐部与北京师范大学系统科学学院联合发起，通过动物、人类、机器三条线索，结合物理学、数理逻辑、多主体建模与计算传播等跨学科视角，探讨蚁群、鱼群、无人机集群、群智优化及多智能体系统中的涌现现象，追问“集群何以比个体更聪明”及群体智能的形成机制，旨在揭示群体智能的本质与规律。",
      "content": "导语\n如果你对这些反直觉但极有用的现象感兴趣——从蚁群搭桥、鱼群同步、到无人机集群表演、集群机器人协作、群智优化与多智能体系统、网络舆论建模研究等——欢迎加入「群体智能」读书会：我们用动物—人类—机器三条线，希望把群体智能的涌现这件事讲清楚、讲透彻；用物理学、数理逻辑、多主体建模、计算传播等多学科视角，去追问同一个核心：集群何以比个体更聪明？群体智能又在何时涌现？\n集智俱乐部联合北京师范大学系统科学学院韩战钢教授、暨南大学计算传播研究中心赵甜芳副教授、新疆大学物理科学与技术学院玉素甫·艾比布拉副教授等来自11所高校的学者，共同发起本次「群体智能」读书会，尝试用一条普适的线索，把自然界的鸟群蚁群、人类社会的集群行为、以及人工智能时代的多智能体与群智优化，放在同一张地图上重新理解。读书会自2026年1月17日开始，安排在每周六下午 14:00–16:00，欢迎所有对群体智能如何涌现、如何被理解、以及如何被设计，感兴趣的朋友一起加入：带着问题来，带着更有趣的问题去。\n（扫码报名）\n蚂蚁群体能把钢琴搬运几何难题解决掉，而人类会出现三个和尚没水喝的尴尬处境——这不是搞笑段子，而是一篇发表在PNAS的跨物种对照实验结论：单个蚂蚁不理解全局，却能通过局部信息的互动产生短期集体记忆，让集群表现随规模提升而变强，涌现出群体智能；人类个体更聪明，但集群协作高度依赖沟通，一旦规模太大，就会被低效沟通拖累。\n难道是人类智慧不如蚂蚁？\n当然不是。真正的分水岭不在于个体的大脑有多聪明，而在于集群如何涌现出智能。亚里士多德曾说过整体大于部分之和；安德森用一句More is Different概括涌现——规模足够大、系统内存在非线性相互作用，会涌现无法在个体层面出现的新规律；图灵也提醒过我们：世界的智慧常常不在个体，而在规则与连接；2024年诺贝尔物理学奖授予Hopfield与Hinton，表彰他们在人工神经网络方面的奠基性工作——神经网络的本质，恰恰就是许多简单单元在相互作用中形成整体能力的集群计算，正如Hopfield所说：\n“Computational properties\nemerge\nas\ncollective phenomena\nof large systems with\nsimple components\n.”\n所以蚂蚁并不是更有智慧，它只是更擅长把简单规则叠加成可扩展的协作；人类也不是不擅长协作，而是我们的集群性能更取决于沟通机制与组织结构——连接模式合适，一群个体才会真正变成一个系统。\n如果你对这些反直觉但极有用的现象感兴趣——从蚁群搭桥、鱼群同步、到无人机集群表演、集群机器人协作、群智优化与多智能体系统、网络舆论建模研究等——欢迎加入「群体智能」读书会：我们用\n动物—人类—机器\n三条线，希望把群体智能的涌现这件事讲清楚、讲透彻；用物理学、数理逻辑、多主体建模、计算传播等多学科视角，去追问同一个核心：\n集群何以比个体更聪明？群体智能又在何时涌现？\n集智俱乐部联合\n北京师范大学系统科学学院韩战钢教授\n、\n暨南大学计算传播研究中心赵甜芳副教授\n、\n新疆大学物理科学与技术学院玉素甫·艾比布拉副教授\n等来自11所高校的学者，共同发起本次「群体智能」读书会，尝试用一条普适的线索，把自然界的鸟群蚁群、人类社会的集群行为、以及人工智能时代的多智能体与群智优化，放在同一张地图上重新理解。\n读书会自\n2026年1月17日\n开始，安排在\n每周六下午\n14\n:00–\n16\n:00\n，欢迎所有对群体智能如何涌现、如何被理解、以及如何被设计，感兴趣的朋友一起加入：带着问题来，带着更有趣的问题去。\n读书会背景\n群体智能，无论在自然系统、生物系统、人工系统还是社会系统中，总是反复出现：集群在信息汇聚、协同决策与环境适应上的能力，常常能在某些条件下优于个体，它既存在于鸟群、蚁群、蜂群等生物系统，也正在快速渗透到人类社会与人工智能的多种场景之中。\n但这也带来一组更本质、更值得追问的问题：\n鸟群齐飞\n、\n蚁群筑巢\n的\n自然智慧\n，如何被“\n翻译\n”成\n无人机集群\n、\n智能电网\n的\n人工系统\n？\n既能抱团攻坚复杂任务，又能自适应感知环境，\n智能集群算法\n的玄机何在？\n为何\n集群近临界态\n被认为是系统稳定性与适应性的关键？如何\n识别\n这种特殊的状态？\n集群临界态\n与\n哥德尔不完备定理\n背后的\n数理逻辑\n，如何为\n集群研究\n打开\n新视角\n？\n当成千上万的智能体需要协同工作，“\n大规模群智优化\n”如何避免各自为战？\n多任务并行\n处理已成常态，“\n分布式群智优化\n”如何让不同智能体各尽其责？\n“\n昂贵优化\n”中的昂贵到底指什么？如何\n突破\n这种昂贵限制？\n群智进化优化\n与\n个体强化学习\n，如何合作攻克“\n复杂路径优化\n”难题？\n网络传播\n的\n集群演化\n与\n调优\n，能否帮助我们更好地\n控制信息扩散\n、\n遏制谣言传播\n？\n统计物理\n、\n系统科学\n、\n人工智能\n的\n跨界合作\n，为\n群体智能\n研究带来哪些惊喜？\n正是在这样的背景下，我们发起本次「\n群体智能\n」读书会：希望汇聚\n物理学\n、\n数学\n、\n系统科学\n、\n计算机科学\n与\n社会科学\n等多元视角，围绕\n群体智能\n的\n机制\n、\n模型\n、\n理论\n与\n应用\n展开\n跨学科讨论\n。读书会将按研究主体贯通\n动物—人类—机器\n三条主线，并结合\n物理学\n、\n多主体建模\n、\n计算传播学\n等方法论视角，形成一套更可对话的共同语言。\n本次读书会以“\n局部规则到群体智能\n”为主线，围绕\n群体智能\n的\n理论\n、\n算法\n两大核心板块展开研讨：\n其一是理论板块，以\n生物集群\n实验数据为基础，结合\n机器人集群\n与\n多智能体系统\n的\n涌现\n行为，整合\n临界态识别\n、\n统计物理建模\n与\n广义哥德尔不完备定理\n等数理逻辑相关成果，从复杂系统科学与物理双重视角，审视\n临界性\n、\n复杂性\n与\n群体智能\n三者的内在关联；\n其二是\n算法\n板块，集中分享\n高维优化\n、\n分布式协同\n、\n多任务学习\n、\n昂贵演化问题\n的前沿群体智能算法，并针对\n复杂路径优化\n、\n复杂网络传播治理\n、\n残片复原\n等实际\nNP难\n问题开展算法攻关，实现技术突破。\n你将收获\n前沿视野：\n系统把握自然与人工集群系统、临界性假说、集群机器人与群智优化的整体脉络，梳理从生物集群到工程系统再到数理逻辑的跨学科发展线索。\n理论工具：\n了解多智能体模型、Master方程、临界性指标、机器学习识别相变方法，范畴论和广义哥德尔不完备定理，以及群体智能与演化算法在高维、分布式、多任务和昂贵优化中的关键技术框架，为后续研究打下可直接调用的工具箱基础。\n实践认知：\n通过鱼群、蚁群、鸡群、机器人集群、网络传播和碎片复原等具体案例，看到模型和算法如何落地到真实系统中，理解涌现机制–控制策略–工程实现之间的闭环关系。\n思维破圈：\n打破对集群系统、临界性和数理逻辑的过于抽象滤镜，从同一套概念体系出发，同时审视自然行为、工程设计和智能算法，形成跨物理–计算–逻辑的综合思考方式。\n同好联结：\n在读书会中结识关注群体智能、演化优化、网络传播与复杂系统的伙伴，交流各自领域中的问题与模型，碰撞出新的合作方向与研究灵感。\n认知升级与方向启发：\n无论是规划个人课题、重构知识体系，还是寻找新问题入口，都有机会从本次读书会中获得新的概念坐标与方法论支点，为后续在多智能体系统、群智优化或复杂系统理论上的深入探索提供助推。\n运行模式\n群体智能读书会 · 2026季\n开营：2026.1.17 下午2:00-4:00\n形式：每周六下午，11讲+1圆桌 | 线上腾讯会议+北京集智谷线下场\n权益：专属群交流 + 视频回放\n行动：扫码报名，锁定席位\n（扫码报名）\n读书会内容详情\n（群体智能读书会内容导图）\n1月17日 第一期：从自然到人工集群系统的实验、模型\n与\n应用\n主讲人\n韩战钢，北京师范大学系统科学学院二级教授，校系统分析与集成实验室主任，国务院学位委员会系统科学评议组成员，联合国教科文组织复杂系统数字校园副主席，兼任多个学术团体理事。\n他长期致力于系统科学的基础理论研究，建立了演化算法收敛复杂性理论，系统地研究自然与人工集群系统，生物集群行为的现象和对称破缺机制，机器人集群的自组织协同，以及多智能体在其他领域的应用。\n他的研究得到多项国家自然科学基金项目、科技部重大专项和企事业单位支持，研究成果得到同行高度评价。\n研究方向：复杂系统理论，信息的功能性应用，基于 agent 建模，信息网络，遗传算法，蚁群，鱼群，机器人群体实验。\n个人主页：https://sss.bnu.edu.cn/t/~zhan。\n内容简介\n本期读书会立足于\n系统科学\n中“自底向上”的建模范式，旨在探讨\n复杂系统\n中微观个体交互与宏观\n涌现\n现象之间的内在联系。我们将首先聚焦于生物集群行为，结合蚁群与鱼群的实证实验数据，分析生物个体如何通过简单的局部规则与环境适应性，涌现出\n复杂\n的群体智能。\n在此基础上，通过引入 Boids、Vicsek 等经典\n多主体模型\n以及基于概率的 Master 方程，深入剖析支撑集群行为的底层动力学\n机制\n，并利用统计物理学中的\n相变\n与临界态理论，对系统在从无序到有序演化过程中的整体状态进行严谨的定量分析。\n进而，读书会将从自然界的演化\n机制\n延伸至人工\n系统\n的工程实践，重点阐述机器人集群领域的研究进展与相关关键技术。我们将探讨如何将生物界中发现的\n自组织\n协同\n机制\n转化为可计算的控制算法，使大规模机器人群体在无中心控制的情况下实现高效的分工、协作与环境适应。通过对机器人集群综述及具体研究工作的剖析，展示多主体建模理论在构建具有高\n鲁棒性\n与智能化的机器\n系统\n中的核心应用价值，从而揭示从生物本能到机器智能的跨学科演化\n路径\n。\n1月24日 第二期：社会性生物集群的互动规律研究\n1.《鱼群动态互动规律研究：从个体行为到群体协同的涌现机制》\n主讲人\n薛婷婷，昆明理工大学理学院系统科学系讲师，硕士生导师，2024年毕业于北京师范大学系统科学学院并获博士学位。主要从事生物集群行为社会互动机制的研究，聚焦鸟群、鱼群等集群系统的动力学规律，融合实验模型构建、多尺度数据分析与机器学习方法，揭示集群涌现、自适应调控及环境响应的核心机制。在Physical Review Research、Machine Learning: Science and Technology、PLOS Computational Biology等期刊发表多篇论文，主持数学建模与机器学习交叉项目、高校人培项目。\n报告简介\n近年来，生物集群行为是复杂系统研究的重要方向，其在多生命尺度中展现的自组织、自适应群体协同特性，既是理解生命系统宏观功能的关键，也为人工智能等领域提供重要生物启发，对揭示非线性系统涌现规律具有重要科学意义。在集群行为的调控要素中，社会互动是连接个体行为与群体动态的核心纽带——它决定个体对环境信息的整合、对邻居行为的响应，直接塑造群体空间分布、运动同步性及信息传递效率等。\n然而，传统研究难以量化多因素交叉下社会互动的动态变化，导致 “微观互动 - 宏观涌现” 的认知存在断层，厘清其调控规律成为领域核心突破点。本报告以鱼类集群为载体，结合实验观测与数据驱动建模，阐述环境因子、物种感知差异、异质性个体对社会互动的调控机制，解析相互作用函数以建立社会互动与集群涌现的定量关联，为理解集群协同本质提供支撑，同时为集群智能、生物行为调控等领域提供新思路。\n2.《社会性昆虫的集体响应与状态切换：蚁群行为的实验与理论框架》\n主讲人\n张一帆，北京师范大学系统科学学院在读博士生。主要从事生物集群系统的涌现特征与动力学机理研究。研究重点包括蚁群在刺激环境下的自组织状态切换、个体间信息传递的相关性，以及微观行为如何驱动群体层面的协调模式。\n报告简介\n群体行为作为复杂系统研究的重要前沿，在社会性昆虫中展现出高度协调、适应性强的集体智能。以蚂蚁为代表的生物群体利用简单规则、局部交互与信息整合实现了远超个体能力的涌现行为。探究蚁群在动态环境与外部扰动下的集体响应规律，为理解群体决策、协作控制和集群职能系统提供了关键启示。\n本课题组通过设计可控的外部刺激，结合轨迹提取与多个体交互分析，构建Master方程和多主体模型，系统研究蚂蚁在外界扰动下从个体到群体的响应机制以及状态切换条件。本报告从文献前沿到自主实验，展示蚁群行为研究的发展脉络、关键机制与新的科学问题，并探讨其对复杂系统与群体智能研究的启示。研究为理解蚁群在刺激情境下的集体响应规律提供新的实证证据，也为构建多智能体系统的协同机制模型提供新视角。\n1月31日 第三期：\n智能集群协同与对抗研究\n1.《\n集群系统及行为动力学机理研究\n》\n主讲人\n于沛志，北京师范大学系统科学学院在读博士生。主要从事集群系统及行为动力学机理研究。研究重点包括集群追逃行为博弈，集群系统异质性与自组织状态转换、集群系统多尺度表征等。\n报告简介\n近年来，从局部规则出发刻画群体智能的生成机制，已成为复杂系统与计算智能领域的热点方向。Reynolds 的 Boids 三规则、Vicsek 自驱动粒子模型、Couzin 感知区域模型以及 Helbing 社会力模型等经典工作表明：个体只需依托邻域感知与简单互动，即可自发形成队列、环行、聚散等多样的时空有序结构。它们从几何邻域、速度对齐和社会力等不同视角，为理解群体协同行为提供了基础范式，但在处理个体异质性、环境信息场和演化过程等方面仍存在局限。\n本报告将以这些经典集群模型为起点，介绍本课题组在多智能体集群建模方面的进展：一方面通过 Master 方程与 Agent-based 模型相结合，在微观决策—宏观统计之间建立联系；另一方面构建基于信息素场的蚁群模型和数据驱动的鱼群 burst-and-coast 模型，揭示个体社会相互作用、环境约束与群体模式转换之间的定量关系。报告旨在从经典模型过渡到改进的模型，展示在保持局部规则简洁性的同时如何提升对真实生物集群与工程集群系统的解释与预测能力。\n2.《集群机器人行为涌现及协同对抗研究》\n主讲人\n郑雅婷，柏林洪堡大学博士后研究员，并加入智能科学集群研究团队。研究方向主要聚焦于群体机器人的协同合作机制，目前涉及仿生集群运动控制、协同构建技术以及真实群体机器人系统中的主动弹性模型控制，曾基于E-puck、Stigmergic积木系统及BuilderBot机器人平台开展研究。2022年1月获得北京师范大学博士学位，并于2018年9月至2020年12月期间在比利时布鲁塞尔自由大学进行联合培养，师从Michael Allwright博士后研究员与Marco Dorigo教授。作为SCIoI项目B3的集成方向博士后，当前正基于Thymio机器人集群开展研究，致力于将不同集体行为整合为群体引导行为。\n报告简介\n自然界中存在各种令人震撼的生物集群行为。揭示和归纳各类生物涌现行为的普适规律是当今复杂系统领域研究热点之一。受到生物集群智能启发，集群机器人系统旨在设计和建立由大量简单机器人组成的协同合作系统，通过机器人之间以及机器人与环境之间相互作用，在宏观层面自组织涌现出个体层面不存在的集群智能。\n与简单个体机器人相比，集群机器人系统具有更好的灵活性、容错性、可扩展性以及稳定性。科学家发现通过建立理想化的生物集群模型，将运动个体抽象为质点，设计局部相互作用规则，在计算机仿真中可以模拟和预测复杂的生物集群行为。然而，理想化的生物集群模型往往不能直接应用于实际的集群机器人系统。\n一方面，生物集群模型存在着不可忽略的理想化假设：个体对局域邻居无偏好选择、个体速度大小固定和无边界限制等；另一方面，集群机器人系统自身也面临着各种问题与挑战：计算复杂度高、通信和定位技术限制以及难以建立可重复操作的实验平台等，使得当前只有少数实验成功地实现大规模集群机器人的自组织涌现行为或者协同合作完成特定场景的任务。\n根据上述理想化生物集群模型和实际集群机器人系统面临的问题与挑战，本报告以生物集群模型为切入点，多种集群机器人系统为实际应用场景，详细讲解如何在集群机器人系统实现类似生物集群行为的一致、旋转等涌现行为，以及如何在多种混合集群机器人上实现集群协同和对抗。\n2月7日 第四期：集群的近临界态假说与识别研究\n1.《临界性假说 —— 跨尺度生物集群系统的普适性法则》\n主讲人\n林国政，北京交通大学系统科学学院讲师，硕士生导师，2024年毕业于北京师范大学系统科学学院。主要从事各类复杂系统涌现特征与机理的研究，包括鱼群、蚁群生物集群系统、多智能体系统、交通系统等。在Physical Review Letters、PRX Life、PLoS Computational Biology等期刊上发表论文10余篇，主持中央高校基本科研业务费、中国博士后科学基金面上项目、国家自然科学专项项目子项目。\n报告简介\n近年来随着人工智能领域各种颠覆性技术的不断涌现，群体智能也越来越受到人们的关注。群体智能通过研究自然界中分散、自组织的生物集群系统（如鸟群、鱼群），实现分布式、去中心化的智能行为。跨尺度的生物集群的共性是在环境刺激或扰动下能够展现出快速响应、动态协同的能力，这种能力或许与统计物理学中的“临界态”相关。\n近几年一些最新的实验证据支持了“临界性假说”，认为生物集群让自身处于或接近临界状态，从而获得对环境扰动的最大敏感性。临界性假说的重要性在于，它不仅适用于鱼群、鸟群、人群等宏观尺度集群，而且能解释大脑神经元、微生物、细胞等微观尺度集群对环境刺激的响应能力，即“运行在临界状态”可能是跨尺度集群系统适应环境的普适性策略。\n本期读书会将介绍临界性假说的主要内容，总结国内外以及本人在临界性相关研究的前沿进展，并给出临界性原理在集群机器人、智能涌现、生态环保等领域可能的应用方向。\n2.《基于人工智能的集群近临界态识别》\n主讲人\n吴天毅，北京师范大学系统科学学院在读博士生。主要从事集群系统临界态识别与调控研究，聚焦集群临界态理论，致力于建立基于观测数据的生物与人工集群临界态识别方法，探索引导集群演化至临界态的调控机制，揭示临界动力学行为在追逃博弈等功能性场景中的涌现优势与应用潜力。\n报告简介\n长期以来，科学界普遍认为生物集群系统之所以能够涌现出高度的群体智能，在复杂环境实现高效协同，关键在其处于有序与无序的边界，即“临界态”或“混沌边缘”。这一“临界态假说”为理解跨尺度系统的自组织机制提供了统一框架。\n然而，在实际研究与应用中，往往难以识别一个系统是否处于临界态。传统方法通常依赖于对系统全局状态的大量观测以计算序参量或关联长度，或需人工结合先验知识进行建模。这种对全局全量数据和先验知识的依赖，极大地限制了其在许多观测受限或机制未知的真实复杂系统中的应用。\n随近年来人工智能技术的飞速发展，数据驱动的方法有望为这一难题提供解决方案。本报告将首先简要回顾集群运动的临界态假说及其物理意义，随后总结近年来国内外及本人在将人工智能应用于集群临界态识别方面的最新进展，并展望相应技术在集群机器人设计、生物群体行为分析等领域的潜在应用方向。\n2月14日 第五期：\n广义哥德尔不完备定理\n与集群临界态\n的数理逻辑刻画\n主讲人\n马治峰，北京师范大学系统科学学院在读硕士。主要从事范畴逻辑与集群临界态的数理逻辑刻画研究，研究工作跳出了传统的动力学模拟框架，转而从元数学的角度，探索复杂性涌现的逻辑本源。研究重点包括广义哥德尔不完备定理、范畴论解释器视角下的复杂性度量，以及利用哥德尔不完备空间刻画临界态、超验证明等。\n报告简介\n本期读书会将展示如何将经典的哥德尔不完备定理推广到广义框架（GGIC），并揭示其与复杂系统临界态之间的深刻联系。核心内容包括：\n广义哥德尔不完备定理的建立\n从传统的语法-语义对偶出发，构建维度化的不完备空间理论\n提出不完备空间维度公式\n揭示这一框架在物理系统、计算理论和人工智能中的普适性\n集群临界态的逻辑本质\n证明临界态在数学上等价于\"不完备空间\"\n建立相变对称性破缺与逻辑公理之间的对应关系\n以捕食-被捕食模型为例，展示临界态参数的逻辑推导\n跨学科应用的突破\n复杂系统：为临界现象提供可计算的逻辑参数\n人工智能：阐述强人工智能与不完备性理解的本质关联\n报告亮点：\n首次建立哥德尔不完备性与复杂系统临界态的严格数学联系\n提出\"逻辑临界性\"的新概念，为多学科交叉研究提供统一框架\n展示如何用数理逻辑工具量化描述传统上只能定性讨论的临界现象\n适合听众：\n复杂系统、人工智能、理论计算机科学研究者\n对数理逻辑与自然科学交叉感兴趣的学生学者\n希望了解前沿跨学科研究方法的科研人员\n本报告将展现数学基础理论如何为复杂系统研究提供全新的分析工具和理论视角，推动我们对\"复杂性\"本质的理解。\n2月28日 第六期：基于统计物理与鸡群行为启发的复杂网络连通支配集模型研究\n主讲人\n玉素甫·艾比布拉，博士，现任新疆大学物理科学与技术学院副教授。2015年毕业于中国科学院理论物理研究所，获理论物理博士学位，同年9月入职新疆大学开展教学与科研工作。\n长期致力于统计物理与复杂系统领域研究，在《Journal of Statistical Mechanics》和《Journal of Statistical Physics》等统计物理权威国际期刊发表论文6篇，研究成果聚焦复杂网络优化问题（如支配集、连通支配集）的统计物理建模，熟练运用自旋玻璃理论、和渗流理论等方法开展理论推导与算法优化。\n近年将研究视角拓展至动物群体行为领域，通过观察生态养鸡过程中的群体自组织现象，探索从中提炼复杂系统的普适性规律与物理建模思想，力求实现物理理论与实际应用的跨学科融合，为复杂系统研究及生态养殖技术优化提供创新思路。\n报告简介\n最小支配集（MDS）作为复杂网络优化中的经典问题，其核心约束可通过统计物理局域相互作用模型精准刻画。我们采用自旋玻璃理论为框架的统计物理BPD算法，还有核渗流理论和全域掐叶算法，实现了对MDS最优基态能量的精准预言，模型计算结果与理论最优解高度契合。然而，在拓展至连通支配集（MCDS）研究时，传统局域相互作用模型因难以精准表达连通性全局约束，导致预测结果与基态能量存在显著偏差，这一矛盾揭示了全局拓扑约束与局域物理建模之间的本质冲突。\n为突破这一理论瓶颈，我们开始关注动物群体行为研究视角，基于两年生态散养鸡群的系统观察，挖掘鸡群自组织行为中的涌现性规律。我们发现，鸡群在觅食、避险及夜栖等场景中，会自发形成兼具“覆盖性”与“连通性”的动态群体结构：个体通过局部信息交互（如视觉识别、声音通讯）实现群体范围的资源覆盖，同时维持群体连通以保障信息传递与集体防御，这一特征与MCDS的“支配+连通”双重约束高度契合。\n我们进一步将鸡群行为机制转化为统计物理模型的优化策略，通过引入“动态交互权重”与“群体连通性惩罚项”，改进传统局域能量函数，实现对全局连通约束的有效刻画。该模型不仅为解决复杂网络MCDS问题提供了新的物理建模思路，更直接为规模化生态散养鸡群管理提供技术支撑——基于模型优化的鸡群分布调控方案，可实现养殖区域的资源高效利用与鸡群行为稳定性的动态平衡，为高福利生态养鸡模式的标准化推广奠定理论与实践基础。\n3月7日 第\n七\n期：大规模群智协同优化\n算法研究\n主讲人\n杨强，南京信息工程大学副教授（校聘教授），南京信息工程大学龙山学者，硕士生导师；分别于2014年和2019年在中山大学信息科学与工程学院和数据科学与计算机学院获得硕士和博士学位；主要从事计算智能算法及其应用研究，累计发表学术论文100余篇，其中在人工智能领域的国际顶级期刊IEEE Transactions系列期刊发表论文10余篇，累计Google Scholar引用3200余次，1篇论文入选ESI高被引论文，1篇论文获评IEEE SMC2022（CCF C类会议）最佳学生论文提名奖，1篇论文获评IEEE ICACI2023（计算智能领域旗舰会议）最佳论文奖；1篇论文获评IEEE MiTA2024（计算智能领域旗舰会议）最佳论文奖；授权发明专利15项；2020年入选江苏省双创博士计划，2022年获评校五四青年奖章，2023年获评校首批十大青年科技之星，2024年入选江苏省第七期“333工程”第三层次人才计划，主持国家自然科学基金项目2项，江苏省自然科学基金项目1项，江苏省高等学校自然科学基金面上项目1项。\n报告简介\n高维度大规模优化问题在日常生活和工业生产中日益常见，尤其在当今物联网环境下，优化问题的维度日益增多，变量耦合性日益增强，优化复杂度日益增加，导致传统优化算法无法有效求解。凭借对待解优化问题无任何数学特性要求、全局搜索能力强、内在并行特性等优势，群体智能算法已经成为了求解大规模复杂优化问题的重要途径之一。\n然而高维度环境下，解空间指数式增长，群体协同搜索效率较低；局部最优区域宽且多，群体协同面临局地性；变量紧耦合、解空间高度复杂，群体协同不充分。为有效解决上述问题，项目团队围绕大规模高维度环境下的群体协同交互的高效性和有效性问题，分别提出了支配式群体交互框架，增加群体交互的导向性，提升群体协同搜索的收敛性；提出了邻域式群体交互框架，增加群体交互的多向性，提升群体协同搜索的多样性；提出了差异式群体交互框架，增加群体交互的异向性，提升群体协同搜索的广面性。\n依托上述框架，群体智能算法求解大规模复杂优化问题的性能得到了极大提升。本报告将详细介绍上述框架，以期让读者了解提升大规模场景下群体协同交互有效性的方法，从而启发读者开展深入研究，促进大规模群体智能算法的研究进展。\n3月14日 第\n八\n期：分布式\n与多任务群智优化\n算法研究\n1.《分布式群智协同优化》\n主讲人\n魏凤凤，华南理工大学计算机科学与工程学院助理教授，硕士生导师，主要研究方向是群体智能、进化计算、分布式优化、数据驱动优化、智能体与多智能体系统，已发表国际期刊和国际会议论文50余篇，其中IEEE Trans.长文15篇；主持国家自然科学基金青年科学基金项目、中国博士后科学基金面上项目、广东省自然科学基金面上项目等；获广东省人工智能产业协会科学技术奖自然科学奖一等奖、第四届国际分布式人工智能会议最佳论文、中国仿真学会智能优化与调度专委优博、ACM广州分会优博；现任中国计算机学会协同计算专业委员会委员。\n报告简介\n群体智能是汇聚群体智慧协同求解复杂问题的方法，是《新一代人工智能发展规划》明确的重要发展方向，在智能交通、智慧物流等领域得到广泛应用。随着超算、边缘计算等技术的快速发展，传统群体智能方法面临着个体目标难评估、全局信息难汇集、群体协作难拓展的挑战，本报告以分布式数据驱动的群体智能为主题，介绍如何有效利用数据，激发分布式环境下更高效的群智涌现，通过多代理模型协同驱动、按需评估的分布式联邦优化、网络化多智能体协同优化等技术，提高群体智能算法的鲁棒性、高效性、可扩展性；并探索基于智能体的数据驱动群体智能方法，利用大模型提升个体环境感知、任务理解、策略生成能力和群体分布式协作的能力。\n2.《多任务群智优化：基于演化迁移学习的算法设计》\n主讲人\n王子佳，男，博士，广州大学计算机科学与网络工程学院副教授，硕士生导师。主要研究方向：计算智能、群体智能、机器学习。2015年本科毕业于中山大学自动化系，获工学学士学位，2020年直博毕业于中山大学计算机系，获工学博士学位；毕业后至2021年7月在腾讯科技（深圳）有限公司担任高级算法研究员；2021年8月以百人计划青年学者身份进入广州大学任副教授，现在是学院青年干部储备人才。2023-2024年度广州大学“最受学生欢迎的教师”。目前主持国家自然科学基金青年基金项目一项、广东省自然科学基金面上项目三项、广州市基础研究计划市校（院）联合资助项目一项、广州市基础与应用基础研究项目一项。累计发表论文40余篇，其中中科院JCR一区和IEEE Transactions论文20余篇，包括8篇IEEE Transactions on Cybernetics（IEEE TCYB，IF=10.5）、4篇IEEE Transactions on Evolutionary Computation（IEEE TEVC，IF=12.0），5篇入选ESI高被引论文，4篇论文被列入ESI研究前沿。现已荣获吴文俊人工智能优秀博士学位论文奖（全国9人）、ACM广州分会新星奖（广东省3人）、ACM广州分会优秀博士学位论文奖（广东省2人）、广东省计算机科学青年学术秀一等奖（广东省3人）。担任IEEETCYB、IEEE TEVC、IEEE TNNLS、IEEE TSMC、IEEE TIFS、IEEE TETCI等多本顶级刊物的审稿人。现任IEEE高级会员、CCF高级会员、中国计算机学会协同计算专业委员会委员、中国自动化学会粒计算及其应用专业委员会委员、中国仿真学会智能仿真优化与调度专业委员会委员、中国图学学会图学大数据专业委员会委员、广东省计算机学会大数据专业委员会委员。受邀出任亚洲人工智能技术大会（ACAIT 2023/2024/2025）和国际机器智能与应用大会（MiTA2024）的Session Chair，担任国际期刊《Complex System Modeling and Simulation》、《CAAI Transactions on Intelligence Technology》的青年编委，并荣获国际期刊《Human-Centric Intelligent Systems》的杰出审稿人奖。\n报告简介\n多任务优化（EMTO）是一种群体智能算法领域新涌现出的一种问题范式，通过利用多个优化任务之间的共享知识来同时解决这些任务。目前，多任务优化已广泛应用与工程设计、机器学习和资源分配等众多实际领域。与传统的单任务算法不同，多任务优化中的一个任务的解决方案可以为相关任务提供信息或改进解决方案，从而加速收敛并提高整体性能。因此，不同任务之间的知识转移对于促进任务的优化至关重要。  而实现高效的知识迁移也是多任务优化领域的研究重点。本期读书会从以下三个方面介绍一些最新的知识迁移技术以及对应的多任务算法。包括：\n1、多层次多段学习:与传统只在对齐维度上的知识迁移不同，该只是迁移技术瞄准相似或相关的维度上进行KT，同时避免处理异构问题时的维度填充带来的冗余信息。\n2、基于神经网络的知识转移：与传统基于个体的表层知识迁移不同，基于神经网络的知识迁移侧重与分析任务的相似性，获得信息预测的转移模型，实现知识的本质迁移。\n3、模糊自适应学习:该知识迁移策略首先设计一个从多方面综合评价知识迁移性能的方案，通过不同方面的迁移性能评估，使用模糊逻辑，实现迁移频率的自适应调整。\n3月21日 第\n九\n期：强化学习路径优化：群体、个体智能协同算法\n主讲人\n贾亚晖，华南理工大学未来技术学院副教授，博导，广东省珠江人才引进团队骨干，IEEE CIS Taskforce on Evolutionary Scheduling and Combinatorial Optimization组长，CCF协同计算专委会委员。曾担任新西兰惠灵顿维多利亚大学博士后研究员。主要研究方向为智能优化算法，包括进化计算、深度强化学习及其在智慧交通和智慧能源方面的应用，在包括IEEE TEVC, TCYB, TNNLS, WCCI等国际著名期刊和重要国际会议发表论文40余篇。担任Journal of Renewable and Sustainable Energy副编辑。\n报告简介\n路径优化问题是一类典型的组合优化问题，例如旅行商问题，车辆路径问题，机器人任务分配与调度问题，在现实生活中拥有很多典型的应用，例如外卖派送、物流规划、垃圾回收等。计算智能方法，特别是基于群体智能的进化计算方法和基于个体智能的强化学习方法，目前已经成为解决此类问题的主流。本期读书会将探讨两种不同的计算智能方法在求解路径优化问题时的优劣势，相关算法的设计思路，以及主要关注的科学问题。最后探讨两种方法相结合的可能性。\n3月28日 第\n十\n期：昂贵演化与协同优化前沿\n1.《昂贵演化优化：前沿与方法》\n主讲人\n黎建宇，南开大学人工智能学院引进教师，入选人工智能领域全球前2%顶尖科学家，CAAI优秀博士论文激励计划提名，南开大学人工智能学科振兴计划；主持国自然青年、天津市青年项目B类等项目多项；主要研究方向是人工智能、进化计算、群体智能和大模型，目前已发表学术论文50余篇，包括IEEE Transactions系列的国际高水平学术期刊论文20篇，ESI高被引论文3篇，《计算机学报》等中文核心期刊论文3篇；谷歌学术引用2000余次，H-index为21；获机器智能期刊最高被引论文奖，CAAI会刊《智能系统学报》优秀论文奖；授权国际发明专利1项。\n研究成果得到了国际同行的正面评价和应用推广。被包括美国科学促进会会士、欧洲科学院院士、加拿大皇家科学院院士等多国/地区院士、多位IEEE Transactions系列期刊的创始主编及现任主编、IEEE Fellow等著名学者评价为“首创（for the first time）”、“优秀的成果（excellent results）”、“更高效（more efficiently）”和“新兴的课题（emerging topic）”等；被YouTube（AI Trends）、Twitter（MIR_Journal）、腾讯新闻（智能科学汇）等媒体平台作为头条进行宣传和报道；被国内外学者广泛应用于芯片设计、生物医学和物流运输等众多领域的优化问题中，推动相关领域的发展。\n报告简介\n在“人工智能+”时代，最优化与智能化已成为推动人类社会进步、发展新质生产力的关键力量，更是人工智能迈向更高层次的必然趋势。随着物联网、云计算、大模型、5G和区块链等前沿技术的蓬勃发展，众多优化问题愈发复杂，呈现出大规模、高动态、多峰值、强约束、多目标以及计算成本高昂等多重挑战，这对传统优化算法提出了前所未有的难题。\n进化计算与群体智能作为模拟自然界生物进化和群体动物智能行为的先进人工智能算法，凭借其行为的可观察、可感知、可认识、可解释和可调控等独特优势，近年来在知识发现、搜索优化和问题求解等领域得到了广泛应用。然而，面对候选方案评估成本高昂的复杂优化问题，传统进化计算方法在计算效率上仍显不足。\n本期读书会将介绍近年来昂贵演化优化方向上的创新成果，这些方法为应对现代超复杂优化问题提供了全新的思路和高效途径，为人工智能领域迈向新的发展阶段起到了推动作用。\n2.《残片复原新路径：一种协同进化优化框架》\n主讲人\n张鑫源，暨南大学智能科学与工程学院，党总支委员，人工智能系主任，硕士生导师，中国计算机学会协同计算专委，珠海计算机学会理事，广东崃智科技有限公司技术总监。主持国家自然科学基金金青年项目，广东省“双创”党建项目。曾在IEEE TEVC，TCSVT，GECCO等国际期刊和会议发表论文20余篇。担任多个国际顶级期刊审稿人。\n报告简介\n残片复原问题旨在从碎片中复原出原始物体。传统的手工复原技术严重依赖专家知识，且可能会对易碎碎片造成损坏，因此有必要开发自动化复原方法。随着碎片数量的增加，当前的复原算法常常遭遇“维度灾难”，算法的准确性和效率均会受到影响。同时，这些算法主要依赖碎片内容，导致其适用性和可扩展性受限。为应对上述挑战，我们提出了基于协同进化优化框架的新型复原方法。该方法既涵盖了残片复原问题的形式化表达，也包含了为解决该问题而开发的定制算法。\n值得注意的是，我们的建模方法与碎片内容无关，仅依赖碎片的边缘形状。基于此种建模方法，解决方案本身就代表了碎片的重建过程。为高效编码候选解，我们采用了树形结构。这种编码方案使得传统的协同进化流程和遗传算法算子（如交叉和变异）不再适用。\n因此，我们专门针对复原任务提出了一种树形结构的协同进化算法。我们的目标是克服当前复原算法的局限性，构建更准确、高效的复原方法。为评估所提方法的有效性，我们进行了一系列综合实验。实验结果表明，我们提出的方法在解的质量、收敛速度和鲁棒性方面均取得了令人满意的效果。\n4月11日 第十\n一\n期：网络传播建模\n与优化\n研究\n1.《多因耦合的网络传播演化建模与优化分析》\n主讲人\n年福忠，兰州理工大学人工智能研究院院长，二级教授、博导，甘肃省领军人才。博士毕业于大连理工大学，曾任清华大学访问学者（中组部“西部之光”），现为复杂系统智能信息处理团队负责人，入选“陇原青年创新人才扶持计划”等人才计划，兼任中国自动化学会计算社会与社会智能专委会常委，中国医学装备协会医疗器械创新与应用分会常委等。研究成果获甘肃省自然科学二等奖（排名第1），甘肃省高校科技进步一等奖（排名第1），甘肃省高校科研优秀成果二等奖（排名第1），甘肃省教育厅教学成果奖，辽宁省自然科学三等奖等多项奖励。近年来，在以第一作者或通信作者身份在IEEE Trans. NSE、IEEE Trans. CSS等SCI期刊上发表论文100余篇，出版专著1部，教材2部。近年来主持完成包括国家自然基金项目（3项）在内的各类科研项目20余项，其中由其主持研发的多导经络智能检测仪，获国家医疗器械注册证，同时获得1000万元风投基金，产品已在北京护国寺中医医院等多家医院临床应用。相关工作被新华社专访，新浪、凤凰网等国内主流媒体转载。\n报告简介\n个体因素、群体因素、信息量、网络拓扑、传播模式等因素都会对传播产生影响，为此，我们多角度研究了网络信息、新冠疫情等真实案例在不同情况下的演化规律与传播特征，并为之建模与优化，揭示其背后的机制与规律，进而找到相应的控制策略。\n2.《\n面向\n网络传播优化\n的\n分治型\n群体智能\n方法》\n主讲人\n赵甜芳，暨南大学计算传播研究中心特聘研究员，广东省科技创新青年拔尖人才（省部级），广州市网络舆情分级与判定标准起草专家。研究领域包括智能传播、分治型群智优化。累计发表IEEE TCYB/TKDE/TSMC/TNSE/TCSS等在内的期刊及会议论文30余篇，其中包括近10篇顶刊论文。主持国家自然科学基金青年项目一项、省部级项目三项。现为中国计算机学会协同计算专委会执行委员、中国中文信息学会SMP专委会委员，国际期刊Journal of Social Computing青年编委，担任TNNLS/TCSS/TAI/IPM/计算机学报等期刊审稿人。曾获广东省人工智能产业协会科学技术奖自然科学奖一等奖、ACM广州新星奖，近五年指导学生团队获省级以上竞赛奖励30余项，培育成果入选2023年中国计算机学会技术公益案例集。\n报告简介\n在大数据与人工智能时代，社会网络规模空前庞大，催生了复杂的网络传播难题。本项目针对高维复杂、去中心化且动态不确定的大规模网络传播环境，拟研发一套适配多情景的分治型群体智能方法框架。\n具体包括：融合网络拓扑信息与决策空间结构信息的自适应重叠解耦机制，实现群体智能决策空间的有效划分；构建基于非完全信息的分布式自主协同机制，达成去中心化环境下的多种群合作协同演化；针对信息茧房、谣言传播、病毒式传播等网络难题，开展网络传播优化的创新应用。本研究深入探索网络拓扑空间与群体智能决策空间的关联规则，以及群体智能中多种群局部自治与邻域协同的平衡机制，目标是优化正面传播、疏导治理重大突发事件中的负面传播，助力提升网络传播的治理效率与质量。\n第十二期：圆桌讨论（暂定于4月18日举行）\n圆桌讨论将在11期读书会内容结束之后进行。届时，读书会的发起人韩战钢教授，赵甜芳副教授和玉素甫·艾比布拉副教授，将与集智俱乐部创始人张江教授、CEO张倩共同领衔，就本季群体智能读书会中的热点科学话题展开讨论，为读书会收官。\n读书会推荐阅读清单\n扫描下方二维码可跳转至集智斑图网站查看群体智能读书会推荐阅读材料\n群体智能从自然涌现到人机共创读书会推荐阅读清单\n读书会总策划\n张倩，集智学园联合创始人兼CEO，南京信息工程大学人工智能学院（原信息与控制学院）硕士毕业，于2016年接手运营集智俱乐部并创办集智学园，开创了集智课堂共学模式，打造了《巴拉巴西网络科学》、《系统科学前沿》、《复杂性思维》等多期课程，组织编写《深度学习原理与Pytorch实战》、主笔《netlogo多主体建模入门》、翻译《复杂——诞生于秩序与混沌边缘的科学》，倩姐公众号主理人。\n运营负责人\n范瑞骁，北京师范大学系统科学学院硕士研究生，师从北京师范大学系统科学学院韩战钢教授。\n报名参加读书会\n读书会价格：399元\n报名方式\n：\n第一步：微信扫码填写报名信息。\n（扫码报名）\n第二步：填写信息后，付费报名。如需用支付宝支付，请在PC端进入读书会页面报名支付：\n第三步：添加运营助理微信，拉入对应主题的读书会社区（微信群）。\nPS：\n为维护学术交流的专业性与聚焦度，本读书会对讨论内容作如下约定：\n我们鼓励围绕理论生态学及相关具体问题的深入探讨。为保证讨论质量，请避免发表脱离本期读书会主题、缺乏实证基础或过于空泛的哲学思辨类内容。\n若讨论内容明显偏离主题，经主持人提醒后仍未调整，为维护整体学习环境，我们将不得不将该成员请出讨论群，并根据其实际参与进度，对未参与部分按比例办理退费。\n感谢您的理解与配合，让我们共同营造一个专注、深入、有收获的共学空间。\n加入社区可享核心资源\n成为会员即可解锁完整学习生态，包括：线上实时问答、全部课程录播回看、独家资料共享、高质量社群交流、第一手信息同步，以及通过参与共创任务获取积分等权益。\n特色退费与激励机制\n我们提供以下两种途径，让您的投入获得实际回馈：\n任务达标退费路径\n：认领并合格完成任意两期字幕任务，即可退还全额报名费，并额外获得集智专属周边奖励。\n运营成长激励路径\n：合格完成一个字幕任务后，可申请成为运营助理。在读书会项目顺利结项后，将退还学费。表现优异者，还有机会获得额外的奖学金。（详情请见：\n加入集智字幕组：成为复杂科学知识社区的“织网人”\n）\n相关内容推荐：\n从鸟群到大脑：因果涌现能解释什么？ | 科普专访\n细胞世界的“高速细胞世界的“高速公路”：揭秘微小纹路如何让混乱的细胞群自发排队，走向有序公路”：揭秘微小纹路如何让混乱的细胞群自发排队，走向有序\n蚁迹寻踪——20年前的模拟程序重新登上集智百科了！丨集智百科\n强化学习能否提高群体稳定合作的可能性？\n空域的涌现：集群 | 涌现动力学第六课\n萤火虫的同步闪烁：随机中怎样涌现出秩序？\n人潮汹涌化“群旋”？科学家揭秘大型人群的“集群涡旋”之谜\n复杂网络上的自组织与集体行为：从扩散、相变到博弈 | 读书会启动\n羊的物理学——从相变到集体运动\nPRE 速递：水母的群体相干机制\n点击“阅读原文”，报名读书会",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247724470&idx=1&sn=aa364f783565fa889e6cd825106b41ac&chksm=e9990fd578e4c74eeb6bc12dc99c85f6e13a3a9b590240cb177d79ce880b2944d9748128ad89&scene=0&xtrack=1#rd",
      "publish_time": 1766983200,
      "publish_date": "2025-12-29 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://sss.bnu.edu.cn/t/\"]",
      "add_ts": 1767050273,
      "last_modify_ts": 1767193580
    },
    {
      "id": 46,
      "article_id": "51503",
      "title": "金融网络的统计物理学",
      "description": "近日，一篇发表于预印本平台的综述论文《The Physics of Financial Networks》系统梳理了金融网络领域的研究进展。文章从金融网络的不同定义出发，探讨了金融传染机制及其在网络结构推断与验证中的应用，强调利用物理思维建模金融系统的重要性，揭示网络结构对系统性风险传播的影响，为防范金融危机提供了理论支持。",
      "content": "导语\n此篇综述文章，介绍了当前该领域的发展现状，从金融网络的不同定义讲起，接着讨论了金融传染（financial contagion）及其在金融网络推断、校验中的应用。\n张澳\n| 作者\n论文题目：\nThe Physics of Financial Networks\n论文地址：\nhttps://arxiv.org/abs/2103.05623\n当今全球金融市场的总值远远超过实体经济总值，大量金融机构间形成了相互作用的网络，而经典的经济学模型将金融体系描述为单一实体或一群孤立的元素，未能对金融系统所涌现出的不稳定性及其对社会的影响提供适当的描述。而金融网络结合图论、统计物理及金融经济学，对金融系统的复杂性及相互作用进行定量建模以刻画金融风险。\n近日预印本论文网站上传了一篇综述文章，介绍了当前该领域的发展现状，从金融网络的不同定义讲起，接着讨论了金融传染\n（financial contagion）\n及其在金融网络推断、校验中的应用。\n金融系统由金融机构、市场、合同以及监管群体组成，故在金融网络中通常将节点定义为各类金融机构，将边定义为合同关系或其它联系\n（如共同进行投资的关系）\n。具体来说，单层网络中产权关系构成的网络可以最好地反映经济主体与金融机构间的关系，多层网络的每层都对应于一种具体关系以更好地刻画风险传播，基于相关/相似性的网络则被用于金融实体之间间接作用的描述。\n图1. 基于相关/相似性的金融网络的分析过程\n金融传染是金融网络中最常见的模型，针对金融机构间的双边关系。在金融传染的模型中，每个机构都有其资产负债表，表格中的状态随着依机构间关系而定的动力学方程而更新。资产负债表左半边为资产\n（如）\n，右半边为负债\n（如）\n。负债中存在优先级\n（即机构破产时还债的顺序）\n，其中股东权益\n（Equity，即股东对资产清偿所有负债后剩余价值的所有权）\n优先级最低，故它也是机构总值的度量。而资产与负债均可根据其所属市场，分为机构间的\n（interbank）\n及外部的\n（external）\n。具体来说，i 机构的机构间负债为 i 机构对其它机构的债务，i 机构的机构间资产即为其余机构对 i 机构的债务。因此，机构间的资产及债务就是机构在网络中的联系。\n图2. 资产债务表构成的机构间网络及其动力学\n上半部分图展示了由三个由资产负债表而表示的机构组成的机构间网络，资产负债表中资产侧包括外部资产\n（如A，B）以及机构间资产\n（如\nA\n12\n即为机构1对机构2的贷款）而负债侧包含股东权益与机构间负债\n，后者也同样可继续细分。\n下半部分图分别介绍了偿债传染\n（solvency contagion）\n及共同投资\n（overlapping portfolios）\n导致的间接传染。对于前者，某个外源波动导致机构1的外部资产损失（a），并且该损失被股东权益所承担（b）。机构3对机构1有贷款\nL\n13\n，所以会对其机构间资产\nA\n31\n重新估值，一般会对\nA\n31\n乘一个0-1之间的小数（c）。最终，机构3资产的减少也被其股东权益承担，这随后会继续影响对机构3有贷款的其它机构，从而传播风险。\n而对于共同投资导致的间接传染，假设机构1为了其资金杠杆\n（leverage，即为资产与股东权益的比值，对机构的盈亏起到放大作用）\n的目标出售其外部资产A与B（e），根据市场影响函数\n（market impact function）\n：被出售越多的资产贬值越多，这将导致A与B的贬值，从而使得持有A与B的机构1与机构2资产值减少（f）。随后机构2为了减小其资金杠杆出售A和C（g）。持有A与C的机构1、2、3 的资产则由于A、C的贬值而减少（h）。\n系列课程推荐：统计物理基础课程\n集智学园联合上海大学理学院教授、知乎“物理学”话题优秀答主李永乐，共同推出「统计物理基础」系列课程。课程以热力学和经典力学为起点，依次展开 Boltzmann 统计、系综理论、量子统计、相变与非平衡统计等核心内容，围绕一个核心问题展开：大量微观粒子的随机运动如何涌现出稳定的宏观定律？本课程强调物理图像与方法论，帮助你建立清晰的微观—宏观统计思维，掌握处理多粒子系统和复杂随机过程的一套通用工具。\n课程详情可见：\n李永乐的统计物理基础课\n推荐阅读\n1.\nNature综述：金融网络中的物理学\n2.\nNature Reviews Physics长文综述：金融网络的物理学\n3.\n李永乐：统计物理阅读材料推荐\n4.\n系统科学前沿十讲：探究复杂世界演变背后的规则（二）\n5.\n集智学园精品课程免费开放，解锁系统科学与 AI 新世界\n6.\n高考分数只是张入场券，你的科研冒险在这里启航！\n7.\n加入集智字幕组：成为复杂科学知识社区的“织网人”\n点击“阅读原文”，报名课程",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247724470&idx=2&sn=c92f707f907657b1a75fe6be0a9fd695&chksm=e96c68c1ecc964ca81728e40f1c7ab3ceefbe7b77ca7424ec5de560a1ab993f2bb624dd1a518&scene=0&xtrack=1#rd",
      "publish_time": 1766983200,
      "publish_date": "2025-12-29 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2103.05623\"]",
      "add_ts": 1767050282,
      "last_modify_ts": 1767193592
    },
    {
      "id": 56,
      "article_id": "51487",
      "title": "脑网络中的高阶拓扑结构",
      "description": "人脑作为复杂系统，其认知与行为调控依赖于神经网络的精确协作。通过将大脑区域及连接建模为节点与边，脑网络分析揭示了信息处理中的拓扑特性变化。研究显示，在执行复杂任务时，脑网络的结构与功能动态调整，反映其在感知、决策和适应环境中的高效协调机制，体现了神经物理过程对宏观认知的重要影响。",
      "content": "导语\n人脑是一个复杂系统，追寻更精准的控制与协调、更清晰的感知、面对生存危机或机遇的快速的决策能力等等。针对脑网络分析发现，在脑部宏观计算和认知时，会受到一系列错综复杂的神经物理机制的影响。将大脑区域及其连接编码为节点和边的网络，研究分析在人类处理和执行复杂行为时，网络拓扑特性的呈现和变化，体现了脑网络中的信息交互和功能反应机制。\n今天介绍一篇2018年发表在\nJournal of computational neuroscience\n上的高引用文章“人类连接体中的团和洞”（Cliques and cavities in the human connectome），作者利用代数拓扑学的技术为结构连接学提供了一个新的视角，探讨脑网络中的高阶拓扑结构，可以提供对大脑功能复杂性的基本见解。\n研究领域：拓扑应用，复杂网络，高阶拓扑，脑网络，网络神经学\n高爽\n| 作者\n论文题目：\nSizemore, Ann E., Chad Giusti, Ari Kahn, Jean M. Vettel, Richard F. Betzel, and Danielle S. Bassett. \"Cliques and cavities in the human connectome.\" Journal of computational neuroscience 44, no. 1 (2018): 115-145.\n论文链接：\nhttps://link.springer.com/content/pdf/10.1007/s10827-017-0672-6.pdf\n前言\n脑网络中的节点体现了解剖上定义的大脑区域，这些区域通过白质束网络不断在彼此之间共享信息，从而构建为脑结构拓扑网络。在以往的研究课题中，主要是找寻由大片区域成对紧密相连的区域集合，称为\n社区\n（communities）\n、\n模块\n（modules ）\n以及\n富人俱乐部\n（ rich clubs）\n。因此在分析结构网络时，关注局部强连接区域成为大势所趋。然而从更宏观的角度来看脑网络，其中较小或者缺失的白质束直观地起到了隔离强白质束过程的作用。换句话说，弱连接或缺失边，为强连接区域起到了“\n划分\n”作用。\n在本文中，作者为了理解大脑中强连接和弱连接之间的相互作用，从只考虑成对相互作用转向捕捉更高阶的关系，用\n团\n（cliques）\n，即网络中的全连接子图，代表强相互连接的计算单元。团的数量和大小使人们对整个大脑的局部连接强度有一个总体的认识。并通过研究团形成的环来分析在中尺度脑网络中的结构特征。这些团和环对应于潜在信息传输的扩展路径，沿着这些路径可以连续进行计算，以发散或收敛的方式实现认知\n（即信息的分布或整合）\n，文中将这些 \"封闭的空间 \"称为网络中的\n拓扑洞\n（topological cavities）\n。作者假设，团和洞的空间分布将在其解剖位置上有所不同，与它们在神经计算中的不同作用相对应。将团和洞两个视角相结合，提供了一个更完整的网络功能视图。\n1. 脑网络中的团\n在文章中，为了提取人脑结构连接体的相关结构特征，从8名健康成年人获得的扩散光谱成像\n（diffusion spectrum imaging, DSI）\n数据编码为\n无向加权网络\n。在这个网络中，\n节点对应于83个大脑区域，边缘对应于节点对之间的白质束密度\n，并使用边缘密度(ρ)为0.25时的组平均网络阈值来去除虚假边。为进行统计验证构建\n空模型\n，将24次扫描的大脑区域，根据最短路径连接，边缘权重为欧几里得距离的倒数。这个模型模仿了大脑中的倾向连接方式来节省布线成本，即物理连接上接近的节点之间连边具有更高的权重。\n团是结构性脑网络中的局部区域特征\n。拓扑分析的第一步是对平均结构网络中的所有最大k-团进行计数。k-团是具有所有成对连接的k个节点的集合\n(2-团、3-团和4-团分别表示边、三角形和四面体)\n。根据定义，一个团的子图本身就是一个较低维度的团，称为面。最大团是指不是任何其他团的面的团。\n图1：a 为大脑的拓扑结构示意图。b 中所有k节点上的所有连通子图都称为k-团。c 表示最大4-团有3、2和1个团作为面。d 图为15个随机大脑区域的空模型示例。\n为了了解真实模型网络和空模型网络中最大团的解剖分布，定义一个节点作为成员参与最大k-团的数量，称为节点参与度。\n作者通过统计不同阶的团，观察到最大团的度分布在最小连接空模型中是单峰的，在经验数据中是定性的双峰分布\n(见图2a)\n。在解剖学上，随着检测程度增高，\n最大团参与度\n从皮层的前部到后部普遍存在\n(图2a)\n。在真实情况下，由12-16个节点组成的最大团几乎包含了所有的视觉皮质。这种空间分布表明，\n早期信息处理需要大量相互作用的脑区，而驱动高级认知的额叶皮质区域则利用较小的工作簇完成\n。结果还显示了，人脑显示出对小\n(4-6个节点)\n和大\n(12-16个节点)\n处理单元的偏好，而不是像最小连线空模型中那样的中等大小\n(大约8个节点)\n单元。\n最大团的前后梯度可以通过额外分析正在执行的认知计算中的区域差异来补充。具体地说，讨论\n最大团中的节点\n参与在\n特定的认知系统\n中\n是否存在不同。统计不同区域的团，最大团是由\n（几乎完全位于）\n皮质下、背侧注意、视觉和默认模式系统的节点形成的，这表明这些系统紧密地相互联系，可能利用鲁棒的局部拓扑进行通信。这些数据表明，\n较小的团作为局部处理系统可能是整个系统的常见特征，而较大的团可能允许快速的多系统串扰。\n图2：最大团的空间分布在平均脑网络和空模型之间不同。a 为平均扩散光谱成像数据网络(黑色)和单个最小连接(灰色)网络中最大团的分布示意图。b表示按功能成像研究中节点所属的假定认知系统分类下参与最大团示例。\n文中还验证了最大k-团的行为与图论度量的一致性。结果表明，\n通过直接路径和间接游走与大脑其余部分强连接的区域，也参与了许多最大团\n。在此，利用核心度的概念测量大脑区域与大脑中枢的关联。即G 图的k-核 是图G 的一个极大连通子图，其中所有节点的度至少为k\n（S-核 表示赋权图的等价概念）\n。参与度较高的节点通常在k-核 分解中达到较高的级别，并且高参与度节点之间频繁存在丰富的俱乐部联系。这些结果表明，\n人脑中富人俱乐部区域往往以团的形式参与局部计算\n。\n图3：a 节点参与度和节点强度（上）及可通信性（下）的散点图。b 表示计算出的k-核 和s-核 分解与具有富人俱乐部节点的最大团的相关性示例，用橙色表示，用大小表示节点达到的最大k-核或s-核级别，颜色深浅表示参与度。\n2. 脑网络中的洞\n依据文中描述，不仅扩散光谱成像数据网络中的团可以作为大脑计算结构的邻域尺度构建块，还可以通过研究\n强连接的缺失\n来研究这些块之间的关系，即检测大脑网络结构中的拓扑洞。由于连接被视为通信渠道，大脑各区域可以通过这些渠道相互发出信号并参与共享的神经功能，因此\n缺失此类连接意味着通信能力的降低，这有助于加强不同功能的隔离。\n为了识别加权网络中的拓扑洞，作者构建了一个二进制图的序列，每个图都包含在下一个图中\n（如图4a）\n，被称为过滤\n（filtration）\n。从空图开始，按照边缘权重递减的顺序逐一替换未加权的边缘，并通过其边缘密度ρ对每个图进行索引，该密度由图中的边缘数除以可能的边缘数得出。在每条边添加之后，提取k-团的结构，称为无关(k-1)-圈，其中每一个都在结构中包含了一个k维的拓扑洞。这种指数的转变原于几何学：一个2阶团是一个1维的线段，一个3阶团是一个2维的三角形，等等。虽然任何洞都被至少一个圈所包围，但往往是多个圈包围同一个洞。然而，检测同一洞的任何两个(k-1)-圈必然会因为一些(k+1)-团的集合的边界而彼此不同。任何两个这样的环称为拓扑等价圈，因此\n每个拓扑洞都由一类无关等价圈检测\n。当通过添加边来进行过滤时，圈的结构，以及其表示的洞结构都会发生变化。图4表示，通过网络过滤模式对团进行追踪，可以发现结构性大脑网络中的关键拓扑洞。\n图4：a 为在大脑中显示的15个节点上依据边缘密度过滤网络的示例。轴上的蓝线表示被绿色最小圈包围的二维空洞的初始密度。随着边的添加，3-团（青色）形成并收缩小洞，因此最小的绿色圈现在的大小为四个节点。最后，当洞被三阶团填充时，橙色线表示终止时边缘密度。b 图表示a图中绿色圈包围的洞的持久性。c 表示在维度1（左）和维度2（右）中的组平均扩散光谱成像数据网络和最小连接网络（灰色）的持久性示意图。d 为脑网络和空模型中二维和三维洞的终结与初始边缘密度比率π的盒图。彩色点对应于图c中突出显示的点。脑网络数据中三维拓扑洞的π值与空模型网络之间的差异不显著。e 表示图c和d中初始边缘密度下的而最小圈表示的洞，在大脑中示意图。\n本文研究了组平均扩散光谱成像网络和最小连接空模型网络中二维和三维洞\n（分别由1阶圈和2阶圈的等效类表示）\n的\n持续性\n。与空模型相比，组平均扩散光谱成像数据网络中的持久性洞明显较少。脑成像数据中最后一个持久的二维洞位于右半球，位于前内侧眶核、伏隔核、任何皮质下区域海马、尾状核、壳核、丘脑和杏仁核之间，以及左半球任何头侧额叶中部、前外侧眶核、前内侧眶核之间，以及来自两半球的头侧前扣带回\n（所有12个最小代表见图4e）\n。此外，由3阶团组成的紫色八面体圈包含颞下和颞中、枕外侧、顶叶下、边缘上、顶叶上以及左半球颞上和岛叶中的任何一个，并包围了结构脑网络中寿命最长的三维洞。虽然每一个最小的结构体可能有不同的生物学意义，但作者观察到在周期内皮质下-皮质连接的整体模式。事实上，在20个重构的1阶圈和2阶圈中，有18个包含这个基序。此外，不遵循该基序的两个持续性圈占最小连接网络中持续性圈的三分之一，这表明在这种最大效率的方案中，\n皮质下环路更可能出现。\n3. 可靠性分析\n利用高阶结构分析脑结构网络的拓扑特征，在\n组平均\n扩散光谱成像网络中观察到的结构特征，是否也可以在多个个人以及同一个人的多次扫描中一致地观察到，以确保这些洞不是由几个异常值驱动的伪影？\n作者为了捕捉平均扩散光谱成像数据中的洞及其最小圈在单个扫描中的存在程度，记录了组成表示\n等价类的每个最小圈的团的集合\n(如图4E所示)\n，并检查是否存在与相同强纤维束的存在相对应的一个团集合，更严格地说，\n检查每个个体的扩散光谱成像网络中是否存在由该循环表示的拓扑洞\n。结果证明，\n在群体平均扩散光谱成像网络中观察到的拓扑洞在个体中表现一致\n，这也表明它们作为人脑中保守的连接基序具有潜在的作用。\n图5：a、c、e、g表示将从平均扩散光谱成像重构的最小圈中看到的连接节点的边缘权重求和，然后对所有单个扫描数据进行归一化。b、 d、f、h(上部)表示在每次扫描中，以最小权重对网络连边进行阈值化，这将形成在平均扩散光谱成像数据中看到的圈。在此阈值下，将显示这些圈中节点之间存在的连接。灰色背景表示此次扫描中发现了类似的洞。对于那些没有被高阶团细分但没有灰色背景的圈，必须存在一些节点集，这些节点将此圈锥化，从而使此圈等效于一个节点。（下部）表示在单个扩散光谱成像网络、最小连接网络、标准化数据和对侧（续）半球中，发现了不同边缘密度下的类似圈。\n总结\n在此文的研究中，为在人脑连接网路中找到可以执行局部计算的密集连接结构，从只考虑成对相互作用转向捕捉更高阶的关系，探讨脑网络中的团和洞结构。使用这种方法验证了，节点在最大团中的参与在空间上和认知系统上都有所不同，这表明这些邻域尺度特征是一种全局体现。并发现重构的拓扑洞在个体间一致存在，在空间嵌入的空模型中不存在，强调了它们在神经布线和功能中的重要性。\n该文章首次利用代数拓扑的研究方法，对脑网络中的高阶拓扑进行分析，为脑网络认知提供了一个新的探索方向。随着复杂网络的不断发展，高阶网络以内生的方式，用更简洁的模型描述多主体互动，逐渐成为寻找拓扑特性的重要手段。\n拓扑学课程：从空间直觉到系统科学\n你是否曾思考过：为什么咖啡杯在数学上可以变成甜甜圈？为什么混沌系统中会出现周期轨、可约化结构和“奇怪吸引子”模式？为什么神经网络、量子物理甚至心理结构，都可以从“拓扑”角度理解？\n拓扑学不仅是数学的抽象分支，更提供了系统的思维方式，让我们理解连续性、结构不变性乃至复杂系统的整体规律。从欧拉七桥问题到DNA的缠结，从量子场论到思维科学与脑科学，拓扑学思想正在各学科中普遍而深刻地重塑着我们的认知方式。\n集智学园联合北京大学博士金威老师开设\n「拓扑学的思维革命：从空间直觉到系统科学」\n，课程于11月23日开启，欢迎感兴趣的读者加入。\n详情请见：\n拓扑学的思维革命：从空间直觉到系统科学\n推荐阅读\n1.\n自然·机器智能：LLM的语言表征与人脑高阶视觉表征的一致性让“读脑”不再是巫术\n2.\nScience：人类意识感知的“闸门”——高阶丘脑核团\n3.\nPNAS 速递：部分熵分解揭示人脑活动的高阶信息结构\n4.\n系统科学前沿十讲：探究复杂世界演变背后的规则（二）\n5.\n集智学园精品课程免费开放，解锁系统科学与 AI 新世界\n6.\n高考分数只是张入场券，你的科研冒险在这里启航！\n7.\n加入集智字幕组：成为复杂科学知识社区的“织网人”\n点击“阅读原文”，报名课程",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247724402&idx=2&sn=62f8ce50869f6ef2e680df93e70c1747&chksm=e98f57c5ec4223c76bc4e7a6b352f3aeda4bff59ca87a147c3e7b76d5792185066981970966d&scene=0&xtrack=1#rd",
      "publish_time": 1766889600,
      "publish_date": "2025-12-28",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://link.springer.com/content/pdf/10.1007/s10827-017-0672-6.pdf\"]",
      "add_ts": 1767050340,
      "last_modify_ts": 1767050340
    },
    {
      "id": 59,
      "article_id": "51529",
      "title": "AI4S回归白盒符号主义，清华等联合发布SR-LLM：自主发现科学知识",
      "description": "清华大学等多所高校联合提出SR-LLM，一种融合大语言模型与深度强化学习的符号回归框架。该方法结合检索增强与语义推理，能从数据中自动生成简洁、可解释的数学模型，在跟车行为建模等任务中表现优异，不仅复现经典模型，还发现更优新模型，显著超越现有技术，为机器实现自主科学发现提供了新路径。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n清华大学等多所高校联合发布SR-LLM，这是一种融合大语言模型与深度强化学习的符号回归框架。它通过检索增强和语义推理，从数据中生成简洁、可解释的数学模型，显著优于现有方法。在跟车行为建模等任务中，SR-LLM不仅复现经典模型，还发现更优新模型，为机器自主科学发现开辟新路径。\n长久以来，神经网络因其「黑箱」本质，虽具备强大的函数逼近能力，却难以生成人类可理解的显式规律，以至于科学界曾质疑：AI能否像牛顿那样，从观测数据中自主发现如万有引力定律般简洁而普适的解析表达式？\n正是在这一背景下，符号回归因其能够从数据中直接推获得形式明确、结构清晰的数学模型而备受关注。\n清华大学、中国科学院自动化研究所、格拉斯哥大学、剑桥大学、欧布达大学、南加州大学、澳门科技大学的研究团队联合提\n出\nSR-LLM，一种融合大语言模型与深度强化学习的新型符号回归框架\n，其核心在于引入检索增强的增量生成机制：\n通过构建外部知识库，系统可动态检索与当前任务最相关的先验知识，并借助LLM的语义推理能力，将这些知识转化为具有物理意义的小型符号组合；随后，利用深度强化学习将这些符号模块高效组装为复杂但高度可解释的解析表达式。\n论文链接：https://doi.org/10.1073/pnas.2516995122\n这一设计使SR-LLM能够真正「站在巨人的肩膀上」进行科学探索，正如AlphaGo通过学习人类棋谱提炼高阶策略，SR-LLM则通过整合领域专家知识与历史搜索经验，引导模型聚焦于语义合理、结构优雅的解空间区域。在标准符号回归基准上的实验表明，SR-LLM显著优于现有方法；\n更关键的是，在人类跟车行为建模这一尚无共识的开放问题中，它不仅成功复现了经典跟驰模型的核心结构，还从真实车辆轨迹中发现了拟合性能更优、物理意义更清晰的新模型。\n展望未来，研究团队致力于发展一种类似AlphaZero的自举范式：在完全无先验知识的条件下，通过随机探索与自我优化，让系统自主构建初始知识库，并逐步演化出可解释的科学规律。\nSR-LLM不仅是一个实用工具，更是一条通向机器自主科学发现的新路径。\n研究背景\n在AI飞速发展的今天，我们早已习惯用神经网络拟合复杂数据。但长久以来，我们只能得到大量神经元堆叠而成的人们难以解析分析的复合函数，却难以像牛顿那样从现象中提炼出如万有引力定律般简洁、普适的科学规律。\n但你有没有想过——\n能不能让AI不仅「会算」，还能「发现新的人类能看懂的定理公式」？\n这正是符号回归（Symbolic Regression, SR）的目标：\n从数据中自动归纳出准确、简洁、可解释、具有泛化能力的数学表达式\n。\n符号回归的基本范式可以描述如下：给定一组\n输入量X∈R^(n×d)\n与\n响应Y∈R^n\n（其中n表示数据集的大小，d表示输入量的维度），找出用输入量字符、运算字符、常数字符等基本字符组成的可解释函数f:X→Y，用以表示输入与响应之间的映射关系。\n不同于目前流行的深度学习方法对于数据对(X,Y)的黑箱拟合，符号回归方法能得到更为简洁与可解释的结果，因此它的输出通常是更易于人类理解的，在物理、化学、金融等不同学科的应用场景下能够推动人类对相应领域的认知进程。\n然而，现实充满挑战：数学表达式的搜索空间极其庞大，真实数据常受噪声干扰，表达式结构与参数需联合优化，并且搜索出的数学表达式内嵌的组合逻辑难以被人类理解——传统方法如遗传编程往往在复杂问题面前「卡壳」，要么搜索效率低，要么容易陷入局部最优，难以兼顾精度与可解释性。\nSR-LLM\n最近，大语言模型在自然语言处理、计算机视觉等多个领域取得了巨大成功。得益于庞大的参数规模与丰富的预训练语料，大语言模型的语义理解、基于上下文的推理等能力达到了前所未有的高度。\n注意到大语言模型这些优秀的能力，SR-LLM将LLM应用到符号回归领域，为树搜索提供剪枝与引导，为该领域的发展方向打开了新大门。\n其核心思想是：\n把符号回归变成一个「增量式生成」任务，并借助大语言模型的强大推理能力来引导强化学习，不断搜索更好的定理公式。\n具体而言，SR-LLM的四大关键技术为：\n1. Radix树存储公式搜索中获得的历史经验\n所有已探索的公式被高效压缩存储在压缩前缀树中。这不仅节省内存，还能快速检索相似结构，避免重复探索。\n2.双阶段强化学习搜索\n第一阶段：采用「风险寻求」策略，只奖励表现最好的公式，快速聚焦高潜力区域；\n第二阶段：切换到Soft Actor-Critic (SAC)，利用经验回放跳出局部最优，稳健逼近全局解。\n这一设计保障了SR-LLM在不借助LLM时基础的搜索能力。\n3. LLM 驱动的检索增强生成\nSR-LLM设计了从优秀表达式汲取公式组合知识的「反思模块」，用于将DRL探索到的优秀结果集群到外部知识库中，指导后续搜索。\n「推理模块」与「反思模块」的设计使得SR-LLM在现有所有符号回归方法中脱颖而出，过去的工作只会提供优秀模型的具体解析式，而SR-LLM则额外告知人类专家这些公式是如何组合来的。\n4. LLM 驱动的知识提取和利用\nSR-LLM利用大语言模型对数学表达式的语义理解能力，结合外部知识库（包含领域专家模型、已经被DRL验证过的优秀表达式），利用「推理模块」动态构造提示词，引导模型生成更合理、更贴近真实规律的符号组合。\n通过使用大语言模型推理的新组合字符，有效减少了表达式树所需的节点规模，进而大大缩减了搜索空间；\n此外，大语言模型可以对新的字符组合提供足够的可解释性保障，进而能够引导树搜索找到更易于人类理解的字符表达式。\nSR-LLM将这些功能模块巧妙的融合在一起，构建出一位自我驱动的「AI科学家」：\n先根据人类已经积累的知识，大胆猜测一些不错的备选公式，接着通过LLM学习这些公式的优点和可能有用的字符表达式片段，然后使用LLM引导的强化学习持续改进搜索新的公式，反复验证、修正、提炼，最终交出最强的简洁优美的候选定理公式。\n实验结果\n研究团队在\n标准符号回归基准\n和\n真实世界场景\n上进行了大量实验：\n在Fundumental-Benchmarks与Feyman-Benchmarks上\n，显著优于PSRN，PhySO等主流方法；\n在\n含噪数据\n下依然保持高鲁棒性，不易过拟合；\n生成的公式\n结构简洁、物理意义明确\n；\n支持\n多目标权衡\n：通过调整拟合精度、专家相似度、复杂度三项得分的权重，灵活适应不同任务需求。\n更重要的是：\n它不是黑箱\n！\n每一个输出都是人类可读、可验证、可推广的数学表达式。\n跟驰模型发现\n研究人员还将SR-LLM应用于「跟驰模型发现」这一具体任务，以验证其在处理真实复杂交通数据中的可行性。\n跟驰模型作为刻画驾驶员纵向行为的核心工具，在交通流特性分析、微观交通仿真、以及无人驾驶车辆的决策与控制等关键领域具有不可替代的作用。\n一个兼具高拟合精度与清晰物理意义的跟驰模型，不仅能够提升仿真系统的可信度，还能为理解人类驾驶决策机制提供理论支撑。\n然而，从真实轨迹数据中自动发现高质量的跟驰模型仍是一项极具挑战的任务：一方面，实际采集的轨迹数据通常包含大量有偏噪声，严重干扰模型结构的准确识别；\n另一方面，跟驰行为本身涉及多种经验性变量与非线性关系，其可能的模型组合空间极为庞大且复杂，难以通过人工方式高效探索。\n针对上述问题，研究人员将SR-LLM应用于「跟驰模型发现」这一具体任务，在真实NGSIM轨迹数据上开展实验，在该任务上面的成功应用能够证实SR-LLM以此类推应用到物理、化学等广泛学科领域的潜力。\n结果表明，SR-LLM不仅能在专家知识引导下成功复现经典跟驰模型，还能融合先验知识自动生成具有明确物理解释的新颖高性能模型，新模型在一些边缘数据下能够克服经典跟驰模型在遭遇突发速度变更时拟合能力变弱的缺点，充分验证了其在处理复杂真实交通数据中的有效性与潜力。\n结论\nSR-LLM的\n成功表明\n，大语言模型不仅是解释已有知识的高水平教师，更是科学发现的智能协作者、乃至独立主导科学探索的智能发现者。通过将LLM强大的语义推理能力与符号回归对可解释性、简洁性与普适性的追求深度融合，迈出了「AI for Science」的关键一步。\n正如AlphaGo通过学习人类棋谱提炼高阶策略，SR-LLM通过整合领域专家知识与历史搜索经验，引导模型聚焦于语义合理、结构优雅的解空间区域，这一设计使SR-LLM能够真正「站在巨人的肩膀上」进行科学探索。\n展望未来，研究团队致力于发展一种类似AlphaZero的自举范式：在完全无先验知识的条件下，通过随机探索与自我优化，让系统自主构建初始知识库，并逐步演化出可解释的科学规律。\nSR-LLM不仅是一个实用工具，更是一条通向机器自主科学发现的新路径，也许下一次某个学科领域的重大科学突破，就诞生于这样一个「会思考、能表达、敢创新」的AI科学家之手。\n参考资料：\nhttps://doi.org/10.1073/pnas.2516995122\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652658873&idx=2&sn=0da11d694b546334cf078ba0dd5d24fa&chksm=f0b6081386c6eb7e4819653e44e82e26ad0a4e11566973051434dba580b125f354f305825bed&scene=0&xtrack=1#rd",
      "publish_time": 1767099000,
      "publish_date": "2025-12-30 20:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1073/pnas.2516995122\"]",
      "add_ts": 1767136638,
      "last_modify_ts": 1767223247
    },
    {
      "id": 67,
      "article_id": "51521",
      "title": "救命！和漫画角色聊上头了，AI陪伴的新答案有了",
      "description": "最新AI陪伴产品让玩家“魂穿”漫画世界，以第一视角与原作角色深度互动。无需设定角色，AI自然融入剧情，对话生动个性，每次选择皆影响故事走向，带来沉浸式、可共同改写的叙事体验，打破传统机械交互，令人上瘾。",
      "content": "西风 发自 凹非寺\n量子位 | 公众号 QbitAI\n行业最新AI陪伴产品，玩起来简直太上头了，这波是真的爱了。\n打开方式be like：\n它不为AI创造一个角色，不用玩家自己费力填写设定，直接让AI嵌入漫画主线里本就鲜活的角色之中：\n而且呢，当你和TA聊天互动时，得到的不是千篇一律机械式的问答。\n玩家将“魂穿”进漫画世界，以第一视角与TA们相遇。所以每一次对话、每一个选择，都将共同改写一段正在发生的故事。\n没错，这意味着你能与你喜爱的那个TA，展开真正深入、即时的互动。\n这恰恰刺中了当下AI陪伴产品的痛点——普遍与用户的关系难以持续，对话疲劳与人设空洞已成通病。\n它的解法不同，靠的是建立在\n共\n同经历\n与\n叙事上下文\n之上的关系存续逻辑。\n不卖关子，这正是国内漫画头部玩家快看，在\n快看漫画2.0\n版本中推出的\nAI陪伴互动漫画\n，也是一次关于叙事型陪伴的全新尝试。\n这一形态同时点燃了两类用户的期待，一边是厌倦了机械式聊天的AI尝鲜者，另一边则是渴求与角色深度互动的漫画核心用户。\n官方预热微博发布时，评论区已是一片“快快端上来”的呼声。\n还有更多好玩儿的，我们接下来细细品。\n魂穿漫画，这谁顶得住\n随着AI陪伴互动体验登陆快看漫画，《DOLO最后的夏天》《Bloody心跳回溯》《SHElter她之所归》等风格各异的作品，首发解锁该玩法。\n入口就在快看漫画APP首页的“\n角色陪伴\n”专区。点进去后，在页面顶部选择心仪的漫画作品，迎面而来的便是静候你多时的漫画角色。\n以穿越题材漫画\n《DOLO最后的夏天》\n为例，主线剧情讲述了神奇生物DOLO带你重返17岁，一边攻略四位性格迥异的角色，一边探寻高中坍塌事故的真相，重启不一样的青春。\n在这里，你成为了故事的主角。点击“主线故事”即可沉浸阅读漫画，推进核心剧情。\n与此同时，你可以随时从主线中切出，与角色们展开即时聊天。\n这种设计，与传统AI陪伴需要你从零开始设定角色截然不同。在这里，你\n遇见的每个角色都已自带丰满的前史\n，他们就来自这部完整的漫画，拥有既定的人格、人际关系与命运挑战。\n而你的代入，是进入一个早已运转的故事轨迹，这\n从\n源头上赋予\n了角色无可替代的深度与一致性\n。\n即便是最随意的闲聊，角色也不会出戏，回答始终锚定在自己的世界里。\n比如问他中午吃什么，他可能会说“学校外面新开了家汉堡店”。\n日常与角色的对话也不止于泛泛而谈，它们被巧妙地编织在剧情的时间线上。\n闲聊中会伴随各种\n日常事件\n，可能发生在重大事件的前夜，对方的回应会带着剧情赋予的紧张或期待；也可能在共同冒险后的休憩时刻……\n这种设计让每一次互动都成为对共同经历的积累。\n在特定剧情节点触发的\n剧情事件\n中，体验更进一层。\n系统会给玩家安排明确任务，你需要通过与角色对话来“攻略”他们、完成任务，从而引导剧情走向。\n除此之外，还有机会触发更为沉浸的\n限\n定事件\n。\n此时，系统会结合环境音效、动态画面与AI的实时对话，营造出一种轻度的共演氛围。\n整个交互画面的质感提升，细节更为考究。例如，在“给TA投喂饼干”的互动中，你能看到角色接过饼干的细微动作、听到对应的音效。\n有意思的是，玩家在其中的所有互动都暗含上分机制。自身的魅力、智商、体能、耐心等属性会随着互动浮动。\n玩家不仅是在推动剧情，也在\n实时养成自己的人设\n。\n与角色之间的好感度，也会在互动中悄然变化。\n最终，\n这一切将指向只属于你的、独一无二的角色关系与故事结局\n。\n接下来就不再过多剧透了，留给宝子们自行探索。\n一句话总结体验，把\nAI当成角色扮演插件嵌进成熟漫画\n，让对话多一层故事感\n，这是快看为解决“AI如何真正陪伴”这个行业难题，给出的一条新的解题思路。\n换句话说，快看没有在\n让对话更聪明\n或是\nAI直接生成漫画\n的维度上卷。\n目前市面很多AI陪伴产品难以和用户间形成长久陪伴关系。许多产品本质上是在\n强情感\n（如情绪安慰）\n或\n强叙事\n（如角色扮演）\n的单一路径上深耕。前者易因缺乏共同话题而陷入情绪饱和，后者则常因世界观单薄而让对话流于程式化。\n快看这次试图\n同时握住“\n叙事”与\n“情感”两条线\n，用连续的漫画故事为AI提供生活的世界与时间线，又用即时、个性化的互动让用户在这个世界里沉淀专属的情感记忆。\n角色因故事而厚重，关系因记忆而具体。\n根据官方测试，体验新产品的用户，\n其周留存率相较传统漫画提升约50%\n，直接证明了用户与角色已建立起超越普通“读者-作品”的准社交陪伴关系。\n快看当“总导演”，集成各家AI顶流\nAI科技热潮下，人们对于游戏NPC、二次元虚拟角色能“活”起来的种种畅想，在此刻有了一次具体又高水准的落地形态。\n这自然引出一个问题：AI模型或许早具备这样的能力，为什么AI公司一直没做出来？\n答案很明显，\n这本质上是一个“内容理解深度>基础模型能力”的垂直场景\n。\n真正的挑战不在于找到一个很会说话的AI，而在于让它精准踩住每一个故事转折的节点，完完全全变成漫画里那个鲜活的角色。\n对角色、故事节奏、情感脉络的深度理解与把控能力，是快看这样做内容的公司十几年积累，以及技术无法短期复制的核心资产。\n纵观快看的发展历程，从2014年以条漫革新移动阅读体验，到2021年前瞻性地推出“漫剧”形态，再到如今探索AI互动叙事……每一步都是对如何更好地“讲故事”与“连接用户情感”的持续深耕。\n所以，快看在此次尝试中扮演的角色，更像是\n一位手握成熟剧本和演员理解力的导演\n，而AI技术是被融合进来服务于统一的叙事体验。\n那么背后用的哪家的AI？\n据了解，此次AI陪伴互动漫画的背后，是一个“专业事交给专业方”的\n开放协作生态\n：\n腾讯云\n：通过DeepSeek API为AI陪伴互动漫画提供灵活可调用的AI原生能力，支撑角色互动与对话生成。\n火山引擎\n：接入豆包支持角色聊天；即梦提供生图、生视频能力，用于生成角色互动的AI视频素材；海绵音乐则为视频提供环境音与音效支持。\n阿里云\n：基于通义千问的对话能力与图像模型能力，共同支撑角色互动体验。\n可灵\n：提供生视频与配音能力，增强角色表达与内容呈现效果。\nMiniM\na\nx\n：提供高质量语音能力，丰富角色声音表现。\n不仅如此，快看还在和一众有特色、有脑洞的AI公司密切合作，比如主打指向式全息与全维度交互的\nAI硬件公司数伴\n，以及亚洲极具影响力的\nAI原生虚拟歌手Yuri尤粟\n、\nTHUNDEROBOT雷神\n等。\n当然它优先服务的，依然是平台内最核心的故事消费用户，通过AI为既有的阅读体验注入更强的沉浸感与情感联结。这一切在其自家最熟悉地盘内进行，以最高的内容契合度，探索人工智能时代娱乐内容的新形态。\n这一探索也在无形中，向世人证明：\n只有存在于故事中的关系，才能发展出长久的AI陪伴\n。在构建有温度的数字关系时，一个精心构筑的故事上下文，其力量可能远胜于一个更聪明的对话引擎。\n现在，悬疑、古风、都市奇幻……各种风格的剧本已就位。感兴趣的友友可以冲冲亲自体验了～\nOne More Thing\n我们拿到了官方尚未披露的产品内测数据，进一步说明了“AI+互动叙事”这一模式在用户体验之外，也初步展现出商业上的潜力：\n测试阶段\n，\n新作上架周付费率飙升，相比传统阅读产品提升近三倍\n。\n此外，新作\n凭借多分支多\n选项的内容特\n点，带来更加高频的小额付费\n。加之，这种带有数值属性的角色养成内容，培养出\n用户长线付费习惯\n。双管齐下\n，\n最终\n带动周人均付费提升130%\n。\n对于新产品，官方表态，这是一次“\n漫画体验形态探索，未来持续完善后会带来更多\n惊\n喜\n”。\n所以广大友友们可以继续期待一波，或许之后还能体验和AI共创故事，不再只是沉浸在漫画世界里，而是在某个漫画里和喜欢的角色们，一起创造独一无二的经历。\n官方体验链接：\nhttps://miniact.kkg3.com/dynamic/JQjwhywV/topic/common-activity/index.html?id=1192_1\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859010&idx=1&sn=15ebd6a80b46228b700d2e36d29b0ebd&chksm=e92e08e75ea676746ed23a969a682cbfe1dbda225d67ccc5409d8b0ff95a85aadf40679e6dae&scene=0&xtrack=1#rd",
      "publish_time": 1767078600,
      "publish_date": "2025-12-30 15:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://miniact.kkg3.com/dynamic/JQjwhywV/topic/common-activity/index.html?id=1192_1\"]",
      "add_ts": 1767136666,
      "last_modify_ts": 1767223279
    },
    {
      "id": 68,
      "article_id": "51520",
      "title": "ViT一作盛赞：这个中国开源“PS模型”强过Nano Banana",
      "description": "ViT核心作者、Meta团队成员Lucas Beyer盛赞通义千问新发布的开源图像生成模型Qwen—Image—Layered，称其远超ChatGPT和Nano Banana，是图像生成的正确方向，并坦言自己也曾有类似构想但因忙碌未能实现。",
      "content": "梦瑶 发自 凹非寺\n量子位 | 公众号 QbitAI\n太香了太香了，妥妥完爆ChatGPT和Nano Banana！\n刚刚，ViT核心作者、Meta超级智能团队成员\nLucas Beyer\n连发三条帖子，怒赞通义千问不久前发布的开源模型\nQwen—Image—Layered\n。\n在他看来，这才是图像生成的正确打开方式～\n他还顺便自补了一句：这个模型方向自己其实也想做来着，只是太忙，一直没来得及动手……（笑）\n实话实说，Qwen—Image—Layered模型确实不一般，因为它可以让我们真正实现ps级别的\n拆图自由\n。\n也就是说现在图片元素也支持精细化修改了：\n连网友们看了\n模型效果后都不禁感叹：咋有种开源PhotoShop的感觉，amazing啊～\n所以，这套让Lucas Beyer反复点赞的模型到底强在哪儿，咱一起来看！\n图片也能像PS一样拆拆拆了\n如果说Nano Banana技能点在生图，那\nQwen—Image—Layered\n模型则厉害在：\n《拆图》\n。\n相信大家都有过类似的经历，我们平时用大模型生图时总会碰的到一个抓狂问题，那就是图片生成so easy，细节修改so抓狂！！！\nAI生出来的图片里，经常会有一些小细节不太到位，但我们又没法只改局部，只能整张丢回模型重新生成，结果往往还不如上一版…\nQwen—Image—Layered\n模型的核心能力，就是专治「一图定生死」这事儿的。\n它能将一张普通图片分解成多个包含透明度信息的\nRGBA分离图层\n，实现真正意义上的图片素材的可编辑性。\n光说概念有点抽象，咱直接看例子～\n在官方案例中，一张完整图片输入之后，模型会自动把画面拆成6个包含不同元素的图层，背景是背景，人物是人物，装饰是装饰，互不干扰。\n看到这儿大家是不是突然感觉，这个非常适合用在海报制作等细节较多的图片上？？（雀实\n但是\nQwen—Image—Layered\n模型能做的还不止只是分离图层这么简单，我们还可以对图层进行\n二次编辑修改\n。\n比如最基础的：\n改背景，不动主体\n。\n只替换背景图层的颜色，一张橙色背景的海报，瞬间就能换成蓝色版本：\n再比如，直接\n换主体\n。\n保持构图不变，把原图里的长发女孩，换成短发女孩，几乎看不出拼接修改痕迹：\n再来看下面这个——\n文字编辑\n。\n我们可以只修改图片中的局部文字，哪怕第一次生成的文字有幻觉问题也不怕了：\n除了基本的替换编辑功能外，\nQwen—Image—Layered\n模型还支\n持调整元素的大小、删除不想要的元素等等。\n例如像这样，我们可以\n删除\n掉画面中不想要的元素对象，只保留自己想留的画面元素：\n又或者在不拉伸、不失真的前提下，轻松调整元素的\n大小比例\n，其实有点像PS里的自由缩放功能：\n值得注意的是，\nQwen—Image—Layered\n模型分层不限于固定的图层数量，支持\n可变层分解\n，例如我们可以根据需要将图像分解为3层或8层：\n这个能力非常适合我们在不同的编辑需求场景下使用，可以根据我们想局部编辑的元素数量多或少而定。\n当然，如果只是想改文字，差不多两三层就够了，如果修改需求比较多比较复杂，多拆几层反而更好操作～\n除了刚才说的这些，模型还支持在已分解的图层基础上做进一步分解，进而实现无限分解，听上去很像无限套娃…\n像下面这位网友，用\nQwen—Image—Layered\n把人物元素进行一次性分层处理，最后甚至可以一路拆到只剩下一个线稿层：\n再来看这位网友，原本人物和背景完全糊在一起的一张图，被模型直接拆成了主体和背景两个独立元素：\n简单说就是：只要画面里不止一个元素，它就能拆、还能一直拆……\n拆图的本事来自于扩散模型\n有朋友看到这儿该问了，小小模型背后能有这PS一般的能力，用的是啥神奇魔法？\n不藏着掖着，\nQwen—Image—Layered\n的核心技术，本质上是一套端到端的\n「扩散模型」\n。\n它并不是用来生成图片的那种扩散模型，而是专门为「拆图片」这件事设计的——\n模型直接输入一张完整的RGB照片，通过扩散过程，一步步预测出多个带透明度信息的RGBA图层。\n这里有一个绕不开的前提是：\n我们平时看到的图片其实只有RGB三个通道，但真正的图层编辑，离不开Alpha（透明度）通道。\n为此，\nQwen—Image—Layered\n专门设计了一套四通道的\nRGBA-VAE\n，把RGB输入和RGBA输出，统一压缩到同一个隐藏空间中：\n具体来说，当输入是一张普通RGB图片时，模型会自动把Alpha通道补成1（完全不透明），在初始化阶段还会聪明地复用预训练参数，避免在透明度建模时出错。\n这样一来，模型从一开始就「懂透明」，不同图层也就不会被混在一起。\n而且在结构上模型也不是死板拆层，它的核心Transformer—\nVLD-MMDiT\n会根据图片复杂度，自动决定需要拆成多少层。\n为了避免前一层把后一层盖住的问题，模型还加了一套Layer3D RoPE（三维位置编码），简单说就是给不同图层打上明确的\n层级标签\n，让模型在空间和顺序上都分得清楚～\n还不止如此，在隐藏空间里中，模型能够被逐步「引导」去学会：哪些像素该属于哪一层、哪些区域需要保留透明度、哪些内容应该被分离开来。\n这样一来哪怕图层再多对模型来说也都是小case了～\n并且在训练策略上模型也不是从零教的，而是基于Qwen-Image预训练生成模型逐步升级：\n第一阶段让模型学会文本\n生成单RGBA图层\n，第二阶段让模型学会\n扩展到多图层合成\n，第三阶段让模型真正学会\n从图片反向拆解多图层。\n每阶段几百K步训练，加上重建损失和感知损失，确保语义分离干净、不冗余。\n这样一来好处很直接，以前方法（如LayerD）要递归抠前景再补背景，容易积累错误，或者用分割+修复，遮挡区补不好。\nQwen—Image—Layered\n模型直接实现端到端生成完整RGBA层，避免这些问题，尤其擅长复杂遮挡、半透明和文字。\n相较于Nano Banana的“一次抽图定生死”，\nQwen—Image—Layered\n的拆图能力能让Lucas Beyer这么喜欢，也就不奇怪了…\n目前模型已经开源，感兴趣的朋友可以试试～\ngithub开源地址：https://github.com/QwenLM/Qwen-Image-Layered\n—\n欢迎AI产品从业者共建\n—\n📚\n「AI产品知识库」\n是量子位智库基于长期产品库追踪和用户行为数据推出的飞书知识库，旨在成为AI行业从业者、投资者、研究者的核心信息枢纽与决策支持平台。\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859115&idx=2&sn=81e16f76be9780fd0dc36bf38b54add0&chksm=e93b706d239f22dd66aee5ffdfb4c479a606e7744c48b590e4526dcac098556c04db72f023a2&scene=0&xtrack=1#rd",
      "publish_time": 1767077760,
      "publish_date": "2025-12-30 14:56",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/QwenLM/Qwen-Image-Layered\"]",
      "add_ts": 1767136669,
      "last_modify_ts": 1767223282
    },
    {
      "id": 76,
      "article_id": "51512",
      "title": "Nat. Commun. | 人工智能驱动的视网膜神经纤维层代谢组学",
      "description": "DRUGONE视网膜神经纤维层（RNFL）作为反映全身代谢健康的无创生物标志物，其生物学机制尚不明确。本研究结合高分辨率视网膜成像、人工智能与代谢组学，在多民族人群中系统分析RNFL退变的代谢基础及其与心代谢疾病及死亡风险的关联，识别出显著相关的代谢标志物，发现这些代谢特征在很大程度上介导了RNFL与疾病风险之间的联系，揭示了其潜在生物学通路。",
      "content": "DRUG\nONE\n视网膜神经纤维层（RNFL）是一种无创、可规模化获取的结构性生物标志物，近年来被认为能够反映全身心代谢健康状况，但其背后的生物学机制仍不清楚。本研究整合高分辨率视网膜光学成像、人工智能算法与互补的代谢组学检测，在多民族人群中系统解析 RNFL 退变的代谢基础及其与死亡和心代谢疾病风险之间的关联。研究人员识别出一组与 RNFL 厚度显著相关的代谢标志物，并发现这些代谢特征在很大程度上介导了 RNFL 与多种心代谢结局之间的联系。基于此构建的 AI 驱动 RNFL 代谢状态模型，能够在不同人群、遗传背景和社会分层中有效分层疾病风险，并显著提升临床预测与决策价值。\n视网膜作为中枢神经系统的一部分，因其光学透明性，为无创观察全身微血管与代谢状态提供了独特窗口。随着光学相干断层扫描（OCT）技术的发展，RNFL 的微米级结构变化可以被精准量化，使其逐渐成为评估心代谢疾病风险的潜在替代指标。\n尽管已有研究表明 RNFL 变薄与糖尿病、心血管事件及死亡风险相关，但这种“眼—心代谢”关联的分子基础尚未明确。代谢异常是心代谢疾病发生发展的核心驱动因素，因此，系统刻画 RNFL 相关的代谢状态，有望揭示这一跨系统联系的生物学基础。\n图1｜研究整体设计概述。\n方法概述\n研究人员基于大规模前瞻性队列，构建了三类研究人群：\n同时具备视网膜 OCT 扫描与代谢组数据的人群，用于识别 RNFL 相关代谢状态；\n仅具备代谢组数据的人群，用于评估心代谢疾病与死亡结局；\n独立外部队列，用于跨人群验证。\n研究整合核磁共振与液相色谱–质谱两类互补代谢组学技术，系统刻画与 RNFL 厚度相关的代谢特征，并利用多种机器学习与深度学习模型构建 RNFL 代谢状态，用于疾病风险分层与预测。\n图2｜RNFL 相关代谢特征的识别与建模框架。\nRNFL 相关代谢特征及其疾病关联\n研究人员共识别出 26 种与 RNFL 厚度显著相关的代谢标志物，其中绝大多数与高密度脂蛋白（HDL）的组成、脂质转运及磷脂代谢密切相关。RNFL 越薄，往往对应更不利的脂质代谢特征。\n在长期随访中，这些 RNFL 相关代谢标志物与多种心代谢结局（包括 2 型糖尿病、心肌梗死、心力衰竭、中风、全因死亡和心代谢死亡）显著相关。中介分析显示，这些代谢特征解释了 RNFL 与心代谢疾病风险之间相当比例的关联，提示存在共同的代谢基础。\n图3｜RNFL 代谢特征在多种心代谢结局中的风险分层能力。\nAI 驱动的 RNFL 代谢状态与风险预测\n基于 RNFL 相关代谢特征，研究人员构建了 AI 驱动的 RNFL 代谢状态模型。结果显示，按 RNFL 代谢状态分位数分组后，不同人群的疾病事件发生轨迹呈现出清晰分离，高风险与低风险人群之间的事件发生率差异可达数量级。\n在预测性能评估中，仅使用 RNFL 代谢状态即可达到与多种传统风险模型相当甚至更优的表现；当其与年龄、性别或经典心血管风险评分模型结合时，预测能力和临床净获益进一步显著提升。\n图4｜RNFL 代谢状态在不同模型中的预测增益与临床效用。\n健康不平等人群中的潜在获益\n值得注意的是，RNFL 代谢状态在女性、社会经济地位较低以及受教育程度较低的人群中，带来了更显著的预测改善。这种改善在一定程度上缩小甚至逆转了传统模型中长期存在的预测差距，提示 RNFL 代谢状态可能捕捉到了被常规风险因子忽略的早期生物学信号。\n图5｜不同性别、社会经济与教育分层中的预测性能变化。\n跨人群验证与机制启示\n在独立的东方人群队列中，研究人员重复观察到 RNFL 与代谢特征及心代谢结局之间的一致关联，并通过更高灵敏度的代谢检测，进一步揭示了氨基酸代谢、抗氧化通路及脂质重塑等多条相关生物通路。\n这些结果共同支持这样一个观点：RNFL 代谢状态反映了系统性代谢扰动在早期阶段对神经视网膜结构的影响，可作为全身心代谢风险的“下游读出”。\n图6｜独立人群中的 RNFL 代谢状态验证结果。\n总结与展望\n总体而言，本研究提出并验证了一种 AI 驱动的“视网膜—代谢—心代谢疾病”整合框架。RNFL 不仅是结构性影像标志物，更是具有代谢信息含量的窗口，能够在疾病发生前捕捉系统性代谢异常。\n随着视网膜成像在基层医疗中的广泛应用，该研究为构建可扩展、无创、兼顾公平性的心代谢风险评估策略提供了新的可能性，也为未来“眼部表型驱动的系统医学”研究奠定了基础。\n整理 | DrugOne团队\n参考资料\nYang, S., Xin, Z., Li, H. et al. Artificial intelligence-driven metabolomics of retinal nerve fibre layer to profile risks of mortality and cardiometabolic diseases. Nat Commun 16, 11039 (2025).\nhttps://doi.org/10.1038/s41467-025-66979-z\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512394&idx=2&sn=7cfb9f51fbb74a2e1ad9bfc43f8be3b8&chksm=fd955da623b1621550be9096907d151fcc2e1cff41a491e7e492724029e715d7c60bd9b8aa64&scene=0&xtrack=1#rd",
      "publish_time": 1767066600,
      "publish_date": "2025-12-30 11:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s41467-025-66979-z\"]",
      "add_ts": 1767136699,
      "last_modify_ts": 1767223339
    },
    {
      "id": 77,
      "article_id": "51511",
      "title": "性能真的不重要了吗？Jeff Dean给出反常答案",
      "description": "Jeff Dean指出，性能并非后期优化而来，而是从编码初期就决定的。尽管2025年算力充裕、AI编程普及，性能看似不再重要，但良好的性能设计依然关键。忽视早期优化将导致系统难以扩展和维护。真正的性能源于代码结构、数据选择与设计决策，而非资源堆砌。开发者应摒弃“过早优化是万恶之源”的误解，在首行代码中便注入高效思维，才能构建真正健壮的系统。",
      "content": "新智元报道\n编辑：倾倾\n【新智元导读】\n很多人背着「过早优化是万恶之源」的名言，写出的却是处处漏风的代码。Google传奇Jeff Dean的这份笔记破了真相：性能不是最后调出来的，而是你在选第一个容器、敲第一行代码时，就已经注定的物理结局。\n2025年，是个很容易让人产生错觉的时间点。\n这时算力不再稀缺，云资源随叫随到，AI已经能写出准确无误的代码。\n在这样的环境里，「性能」似乎正在悄悄贬值。因为代码写得慢一些，好像也没什么大不了。\n就在这种氛围下，Google的传奇工程师Jeff Dean更新了一份老文档：Performance Hints。\n比起一篇炫技的论文，它更像是一份老派工程师的随笔，里面重新整理了基础法则。\n它反复重申一个事实：计算机底层的物理规则，从未因为云原生、AI或硬件的进步而改变。\n硬件的进步掩盖了代码的低效，这些问题会在系统中不断堆积，直到成为无法绕开的成本。\n「过早优化」，成了平庸代码的豁免权\n所有工程师都听过一句老话：\nPremature optimization is the root of all evil.（过早优化是万恶之源）。\n它原本是提醒我们，别为了抠几行代码，把系统搞成一团乱麻。\n但在实践中，这句话慢慢变了味，成了一个免责口令——只要遇到性能质疑，一句「别过早优化」就能把所有问题挡回去。\n结果走向了另一个极端：写代码时，性能被整体忽略。抽象可以多一层，数据可以多拷贝一次，API可以写得更「通用」。\n瑞士奶酪模型：单个小漏洞没事，但是一层层叠加，对齐了会出大事\n大家总觉得将来有profiler，等真慢下来再说。\n可等系统上线，流量涌入，响应开始变拖沓，大家终于打开性能分析图，却发现屏幕上什么都没有。\n没有一个函数占掉40%的时间，没有明显的性能热点。你看到的只有一张异常平坦的火焰图——每一层都慢一点，每一个看似无关紧要的选择，都给未来埋下隐患。\n你很难指出哪里出了错，因为问题从一开始就没有集中出现——这正是Jeff Dean反复强调的一种模式。\n性能不是被某个错误决定拖垮的，而是被一连串「看起来没问题」的决策慢慢稀释掉的。\n一旦走到这一步，优化会变得异常昂贵，因为你失去了明确的下手点。\n所谓「关键的3%」，指的从来不是写完代码后再去抠字眼，而是在写第一行代码时，就要避开那些虽然方便、但明显低效的路径。\n这不只是技巧，更像一种素养。真正拉开差距的地方，往往发生在profiler还没派上用场之前。\n5ns和5ms之间，隔着整个物理世界\n如果说前面的区别发生在「已经来不及了」，那么接下来要说的是：「为什么我们会在一开始就走错路」。\n事实上，很多工程事故并不是因为「不会优化」，而是因为对「慢」没有感觉。\n在编辑器里，5ns和5ms看起来只是多了几个0。缩进一样，语法一样，在Code Review时看起来合理合规。\n但在物理世界，这些数字根本不属于同一个尺度。\nJeff Dean在清单里列出了一张延迟对照表。一旦把这些数字还原成现实中的时间，很多所谓的设计直觉会当场崩塌。\nL1缓存命中：约0.5ns，等于微观世界里的一次脉搏。\n分支预测失败：5ns，是连续十次脉搏。\n主存访问：50ns，相当于起个身，走下楼，取了个外卖。\n随机磁盘寻址：10000000ns，相当于从北京一路走到了上海。\n最早由Google工程师整理，Jeff Dean在多次演讲中用过这个思路\n如果你的方案里出现了一次磁盘寻址，后面无论代码写得多优雅、逻辑多漂亮，在物理尺度上都已经输透了。\n这就是顶级工程师脑子里的「物理地图」。他们本能地知道：哪些操作属于同一量级，而哪些操作一旦混进来，系统的节奏就彻底乱了。\n这也是「信封背面估算」（Back-of-the-envelope calculation）的价值所在。\n它是一次动手之前的排查：这个方案会触发多少次内存访问？有没有隐藏的分配？循环里会不会撞上网络IO？\n如果答案里出现了一个不合时宜的量级，这个方案就应该被扔进垃圾桶。\n很多性能问题并非「实现得不够好」，而是选错了路径。\n一旦建立起这种尺度感，很多无意义的争论就能一眼看穿。\n反直觉的真相：Google大佬的代码为什么看起来很「土」？\n真正拉开差距的地方，不在于「写得多聪明」，而在于知道哪些地方「不值得聪明」。\n翻开这份Performance Hints，我们能发现一个反直觉的事实：没有复杂的算法，很多改动看起来都有点「土」。\n但这些细碎的选择，却被Jeff Dean反复拿出来强调。\n对内存的节制\n「尺度感」让我们意识到分配内存的珍贵，在实战中，这种意识会转化成对容器的极致考究。\n为什么他们偏爱\nInlinedVector\n？因为在绝大多数场景下，它根本不碰堆内存，数据直接躺在栈上。\n这带来的是实实在在的物理收益：少一次分配，多一次缓存命中。\n同样的，使用Arena（内存池）也不只是为了管理方便，而是为了让数据在物理内存上变得连续，顺应CPU缓存的节奏。\n对数据分布的尊重\n所谓的Fast Path（快路径），本质上是承认世界是不均匀的。99%的请求和输入都比想象中普通。\n如果坚持让每一次调用都走那条「最通用、最保险」的路，实际上是在用极少数的边缘情况，绑架绝大多数的正常流量。\n清单里提到的UTF-8处理就是一个典型：现实中大量字符串其实只有纯ASCII字符。\n如果一上来就按完整的解析逻辑走，那每一个字节都在为万分之一的极端情况买单。\n看一眼，是ASCII就直接放行——这种行为，建立在对数据规律的尊重之上。\n对抽象成本的自觉\n清单里举了个例子：把Protobuf逻辑改成原生结构体，性能提升20倍，让很多人不安。\nProtobuf确实解决了跨语言和版本演进的难题，但便利从不是免费的，每一层封装、每一次解析，都是一笔隐蔽的「抽象税」。\n就像在透支信用卡，你可以尽情购物，可一旦账单寄来，就要付出相应代价。\n抽象并不会消失，只是被编译器展开，最终落实到一行行具体的实现上。\n当抽象层数不断叠加，成本也会在底层被一并兑现。\n这就是为什么他们建议在热路径里避开不必要的层级、避开那些「为了完整而完整」的设计。\n目的是让你清楚地意识到，你到底在为什么付费。\n顶级工程师关心的，从来不是如何写出最聪明的代码，而是如何避免那些本不该出现的开销。\n当你在敲键盘时，能对分配、分布、抽象成本保持警惕，很多性能瓶颈在发生之前，就已经被挡在了门外。\n想提高性能，就不能对代价视而不见\n很多人把性能理解成一种阶段性的工作：系统慢了，就开始优化；不慢，就先放一边。\n但读完这份清单，你很难再这样看待它。\nJeff Dean们反复强调的，其实不是「如何省下几纳秒」，而是「你是否真正理解自己正在使用的计算资源」。\nCPU、内存、缓存、磁盘......这些底层的物理规律并没有因为云原生或AI的流行而消失，它们只是被包装得更抽象了。\n顶级工程师之所以显得从容，是因为他们很少走到「火场」里：在写第一行代码时，他们就已经避开了那些注定昂贵的路径。\n这份Performance Hints读起来不像教程，更像是一份肌肉记忆。它不要求你处处极限优化，而是要求你在做决策时，不要假装不知道代价。\n也许真正的分界线一直是——当你写下一个循环、设计一个数据结构、决定要不要多加一层时，脑海中是否浮现出那张时间和尺度的地图。\n一旦有了它，很多平庸的代码，你就再也写不下去了。\n参考资料：\nhttps://x.com/JeffDean/status/2002089534188892256?s=20\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652658610&idx=2&sn=e6d9eff2aabc9d1932492b2ba3092f7b&chksm=f039fd9295596864c4e26aeb744bd3555bf7c96669e2e077fa4c7ff0463b977cb7961d236438&scene=0&xtrack=1#rd",
      "publish_time": 1767066600,
      "publish_date": "2025-12-30 11:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/JeffDean/status/2002089534188892256?s=20\"]",
      "add_ts": 1767136702,
      "last_modify_ts": 1767223346
    },
    {
      "id": 80,
      "article_id": "51508",
      "title": "AI 最前沿 | 大语言模型、自动驾驶、医学图像分割……",
      "description": "MIR第六期于12月出版，包含10篇免费下载的最新研究论文。内容涵盖自动驾驶中的端到端感知与预测综述、融合CNN与Transformer的RGB-event视频识别方法、用于显著性检测的CINet网络，以及结合Vision Transformer与InceptionV3的强直性脊柱炎诊断模型等前沿研究，涉及人工智能在视觉识别、医疗诊断等领域的创新应用。",
      "content": "Machine Intelligence Research\nMIR第六期已于12月正式出版，10篇最新好文免费下载，欢迎阅读！\n综述\n· Review\nA Survey on End-to-e\nnd Perception and Prediction for Autonomous Driving\nYufan Hu, Longhui Hu, Qingqun Kong, Bin Fan\nhttps://link.springer.com/article/10.1007/s11633-025-1558-0\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1558-0\n研究论文\nUnleashing the Power of CNN and Transformer for Balanced RGB-event Video Recognition\nXiao Wang,\nYao Rong, Shiao Wang, Yuan Chen, Zhe Wu, Bo Jiang, Yonghong Tian, Jin Tang\nhttps://link.springer.com/article/10.1007/s11633-025-1555-3\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1555-3\n研究论文\nCINet: Cascaded\nInteraction with Eroded Deep Supervision Strategy for Saliency Detection\nHewen Xiao, Jie Mei, Guangfu Ma, Weiren Wu\nhttps://link.springer.com/article/10.1007/s11633-025-1551-7\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1551-7\n研究论文\nA Novel Vision Transformer + InceptionV3 Hybrid Network for Accurate Diagnosis of Ankylosing Spondylitis from Computed Tomography Scans\nRiel Castro-Zunti, Eun Hae Park, Amol Satsangi, Younhee Choi, Gong Yong Jin, He\ne Suk Chae, Seok-Bum Ko\nhttps://link.springer.com/article/10.1007/s11633-024-1539-8\nhttps://www.mi-research.net/article/doi/10.1007/s11633-024-1539-8\n研究论文\nTheory of Mind Inspired Large Reasoning Language Model Improved\nMulti-\nagent Reinforcement Learning Algorithm for Robust and Adaptive Partner Modelling\nXiyun Li, Tielin Zhang, Chenghao Liu, Shuang Xu, Bo Xu\nhttps://link.springer.com/article/10.1007/s11633-025-1547-3\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1547-3\n研究论文\nCardiac Dynamic\nCharacteristics Classification on Cine MRI Using Semi-supervised Imaging Approach\nFaizan Ahmad\n,\nJing Xiong\n,\nJie Wu\n,\nJiahong Xia\n,\nZeyang Xia\nhttps://link.springer.com/article/10.1007/s11633-024-1534-0\nhttps://www.mi-research.net/article/doi/10.1007/s11633-024-1534-0\n研究论文\nSemi-s\nupervised Learning for Detector-free Multi-person Pose Estimation\nHaixin Wang, Lu Zhou, Yingying Chen, Ming Tang, Jinqiao Wang\nhttps://link.springer.com/article/10.1007/s11633-024-1524-2\nhttps://www.mi-research.net/article/doi/10.1007/s11633-024-1524-2\n研究论文\nAnswer Semantics-enhanced Medical Visual Question Answering\nYuliang Li\nang, Enneng Yang, Guibing Guo, Wei Cai, Linying Jiang, Jianzhe Zhao, Xingwei Wang\nhttps://link.springer.com/article/10.1007/s11633-025-1564-2\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1564-2\n研究论文\nLearning Eff\nicient Linear Graph Transformer via Graph-attention Distillation\nHaotian Tao, Ziyan Zhang, Bo Jiang, Bin Luo\nhttps://link.springer.com/article/10.1007/s11633-025-1541-9\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1541-9\n研究论文\nDegree-aware Progressive Contrastive Learning for Graph Combinatorial Optimization Problems\nShiyun Zhao, Yang Wu, Yifan Zhang\nhttps://link.springer.com/article/10.1007/s11633-024-1532-2\nhttps://www.mi-research.net/article/doi/10.1007/s11633-024-1532-2\nEND\n∨\n关于Machine Intelligence Research\nMachine Intelligence Research（简称\nMIR，原刊名International Journal of Automation and Computing）由中国科学院自动化研究所主办，于2022年正式出版。\nMIR立足国内、面向全球，着眼于服务国家战略需求，刊发机器智能领域最新原创研究性论文、综述、评论等，全面报道国际机器智能领域的基础理论和前沿创新研究成果，促进国际学术交流与学科发展，服务国家人工智能科技进步。期刊入选\"中国科技期刊卓越行动计划\"，已被ESCI、EI、Scopus、中国科技核心期刊、CSCD等20余家国际数据库收录，入选图像图形领域期刊分级目录-T2级知名期刊。2022年首个CiteScore分值在计算机科学、工程、数学三大领域的八个子方向排名均跻身Q1区，最佳排名挺进Top 4%，2023年CiteScore分值继续跻身Q1区。\n2024年获得首个影响因子(IF) 6.4，位列人工智能及自动化&控制系统两个领域JCR Q1区；2025年发布的最新影响因子达8.7，继续跻身JCR Q1区，最佳排名进入全球第6名；2025年一举进入中科院期刊分区表计算机科学二区。\n▼\n往期目录\n▼\n2025年第5期 | 生成式模型、疾病诊断、步态识别、行人再识别......\n2025年第4期 | 特约专题: 具身智能\n2025年第3期 | 大语言模型、医学图像分割、图像阴影去除、写作风格变化检测......\n2025年第2期 | 常识知识获取、图因子分解机、横向联邦学习、分层强化学习...\n2025年第1期 | 机器视觉、机器人、神经网络、反事实学习、小样本信息网络...\n2024年第6期 | 图神经网络，卷积神经网络，生物识别技术...\n2024年第5期 | 大语言模型，无人系统，统一分类与拒识...\n2024年第4期 | 特约专题: 多模态表征学习\n2024年第3期 | 分布式深度强化学习，知识图谱，推荐系统，3D视觉，联邦学习...\n2024年第2期 | 大语言模型、零信任架构、常识知识推理、肿瘤自动检测和定位...\n2024年第1期 | 特约专题: AI for Art\n▼\n好文推荐\n▼\n精选好文 | 基于多模态学习的非酒精性脂肪肝病预测\n南京大学Kai Ming Ting团队 | 综述：基于孤立机制的异常检测研究\n南洋理工大学肖佳平 等 | 基于深度强化学习的异构机器人系统目标搜索与导航\n南开大学程明明团队 | MCANet：基于多尺度交叉轴注意力的医学图像分割\n自动化所吴书 等 | GraphFM: 用于特征交互建模的图因子分解机\n香港理工大学周立培团队等 | 综述: 面向以物体为中心的机器人操作的具身学习\n清华大学朱军团队 | DPM-Solver++：用于扩散概率模型引导采样的快速求解器\n南航张道强团队 | 综述：基于脑电信号与机器学习的注意力检测研究\n可信图神经网络的全面综述：隐私性、鲁棒性、公平性和可解释性\n哈工大江俊君团队 | SCNet：利用全1X1卷积实现轻量图像超分辨率\n自动化所刘成林团队 | 统一分类与拒识: 一种一对多框架\n上海交大张拳石团队 | 综述: 基于博弈交互理论的神经网络可解释性研究\n专题好文 | 再思考人群计数中的全局上下文\n专题好文 | Luc Van Gool团队: 基于分层注意力的视觉Transformer\n浙江大学孔祥维团队 | 综述: 迈向真正以人为本的XAI\n澳大利亚国立大学Nick Barnes团队 | 对息肉分割的再思考: 从分布外视角展开\n前沿观点 | Segment Anything并非一直完美: SAM模型在不同真实场景中的应用调查\n精选好文 | 推荐系统的波纹知识图谱卷积网络\n复旦邱锡鹏团队 | MOSS: 一个开源的对话式大语言模型\n自动化所黄凯奇团队 | 分布式深度强化学习：综述与多玩家多智能体学习工具箱\n约翰霍普金斯大学Alan Yuille团队 | 从时序和高维数据中定位肿瘤的弱标注方法\n专题综述 | 大语言模型中的知识生命周期\n精选综述 | 零信任架构的自动化和编排: 潜在解决方案与挑战\n欧洲科学院院士蒋田仔团队 | 脑成像数据的多模态融合: 方法与应用\n金耀初团队&郑锋团队 | 综述: 深度工业图像异常检测\n专题好文 | 创新视听内容的联合创作: 计算机艺术面临的新挑\n▼\nMIR资讯\n▼\n影响因子全球第6名！MIR稳步进军世界一流期刊行列\n进阶前5%！MIR登榜”中国最具国际影响力学术期刊”\n进阶前5%！MIR登榜”中国最具国际影响力学术期刊”\n喜报 | MIR 首次入选中科院期刊分区表计算机科学类二区\n喜报！MIR入选中国科技期刊卓越行动计划二期项目\n特别提醒！请认准MIR官方渠道，谨防受骗\n前进20名！MIR再度跻身国际影响力TOP期刊榜单\n喜报 | MIR入选图像图形领域 T2级 “知名期刊”！\n喜报 | MIR被 ESCI 收录！\n喜报 | MIR 被 EI 与 Scopus 数据库收录\n点击\"阅读原文\"进入当期目录",
      "article_url": "https://mp.weixin.qq.com/s/F3vreise7jUhzz10gE7fUA",
      "publish_time": 1766999880,
      "publish_date": "2025-12-29 17:18",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://link.springer.com/article/10.1007/s11633-025-1558-0\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1558-0\", \"https://link.springer.com/article/10.1007/s11633-025-1555-3\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1555-3\", \"https://link.springer.com/article/10.1007/s11633-025-1551-7\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1551-7\", \"https://link.springer.com/article/10.1007/s11633-024-1539-8\", \"https://www.mi-research.net/article/doi/10.1007/s11633-024-1539-8\", \"https://link.springer.com/article/10.1007/s11633-025-1547-3\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1547-3\", \"https://link.springer.com/article/10.1007/s11633-024-1534-0\", \"https://www.mi-research.net/article/doi/10.1007/s11633-024-1534-0\", \"https://link.springer.com/article/10.1007/s11633-024-1524-2\", \"https://www.mi-research.net/article/doi/10.1007/s11633-024-1524-2\", \"https://link.springer.com/article/10.1007/s11633-025-1564-2\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1564-2\", \"https://link.springer.com/article/10.1007/s11633-025-1541-9\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1541-9\", \"https://link.springer.com/article/10.1007/s11633-024-1532-2\", \"https://www.mi-research.net/article/doi/10.1007/s11633-024-1532-2\"]",
      "add_ts": 1767136711,
      "last_modify_ts": 1767193558
    },
    {
      "id": 86,
      "article_id": "51558",
      "title": "在线教程丨David Baker团队开源RFdiffusion3，实现全原子蛋白质设计的生成式突破",
      "description": "David Baker团队推出RFdiffusion3（RFD3），首次实现基于非蛋白质组分（如配体、核酸）的全原子级蛋白质设计。该模型采用轻量信息提取模块，仅用2层Pairformer即完成高效结构生成，参数量仅1.68亿，显著降低计算成本。RFD3可精确控制氢键、配体接触与核酸相互作用，成功应用于DNA结合蛋白与酶的设计，展现出强大功能拓展性。相关教程已上线HyperAI超神经平台，支持一键部...",
      "content": "近年来，利用生成式深度学习方法在新功能蛋白质设计方面取得了显著进展。目前包括 RFdiffusion（RFD1）和 BindCraft 在内的大多数方法，均采用氨基酸残基水平的蛋白质表示，已能够成功设计蛋白质单体、组装体以及蛋白质-蛋白质相互作用体系，但其分辨率仍不足以精确设计与非蛋白质组分（如小分子配体与核酸）发生特异性侧链相互作用的结构。\nRFdiffusion2\n（RFD2）虽然在这一局限上有所克服，但其扩散过程仍局限于残基层面，难以进一步拓展至与非蛋白质组分形成额外的侧链相互作用。\n现有研究表明原子级扩散过程可用于生成蛋白质主链，并可扩展至侧链建模，但这些尝试仍未实现与非蛋白质组分间相互作用的有效建模。\n基于此，\n诺奖得主 David Baker 团队推出了\nRFdiffusion3\n（RFD3），能够在配体、核酸及其他非蛋白质原子组成的结构中生成蛋白质三维构象。\n由于该模型对所有聚合物原子均进行显式建模，因此能够更简便、更高效地处理诸如酶设计等任务中的复杂原子级约束条件。RFD3 原生的全原子架构还大大简化了原子级约束的规范，提供了对氢键、配体接触及核酸相互作用的精确控制。\n不同于 AlphaFold3（AF3）依赖计算密集的\nPairformer\n模块从输入序列中提取距离等信息，研究团队将信息提取模块设计得更为轻量，\n使得 RFD3 将 Pairformer 的层数从 48 层大幅缩减至仅 2 层，从而显著降低计算开销，最终模型仅包含 1.68 亿可训练参数。\n研究团队通过设计并实验表征 DNA 结合蛋白与半胱氨酸水解酶，展示了 RFD3 的广泛适用性，其能够基于任意非蛋白质原子环境快速生成受复杂原子级约束引导的蛋白质结构，将进一步拓展蛋白质设计所能实现的功能范围。\n「RFdiffusion3：蛋白质设计模型」现已上线 HyperAI 超神经官网（hyper.ai）的「教程」板块，快来一键部署体验！\n恰逢新年，HyperAI超神经为大家准备了算力福利，\n新用户注册后使用兑换码「2026 Happy New Year」即可获得 2 小时 NVIDIA\nGeForce RTX 5090\n使用时长，\n数量有限，快来领取节日福利吧！\n教程链接：\nhttps://go.hyper.ai/3E9FY\nDemo 运行\n1.进入 hyper.ai 首页后，选择「RFdiffusion3：蛋白质设计模型」，或进入「教程」页面选择。进入点击「在线运行此教程」。\n2.页面跳转后，点击右上角「Clone」，将该教程克隆至自己的容器中。\n注：页面右上角支持切换语言，目前提供中文及英文两种语言，本教程文章以英文为例进行步骤展示。\n3.选择「NVIDIA GeForce RTX 5090」以及「PyTorch」镜像，按照需求选择「Pay As You Go（按量付费）」或「Daily Plan/Weekly Plan/Monthly Plan（包日/周/月」，点击「Continue job execution（继续执行）」。\nHyperAI 为新用户准备了注册福利，仅需 $1，即可获得 20 小时 RTX 5090 算力（原价 $7），资源永久有效。\n4.等待分配资源，当状态变为「Running（运行中）」后，点击「Open Workspace」进入 Jupyter Workspace。\n效果演示\n页面跳转后，点击左侧\nREADME\n页面，进入后点击上方 Run（运行）。\n稍等片刻后，下滑显示 RFD3 进行的结构预测结果。\n以上就是 HyperAI超神经本期推荐的教程，欢迎大家前来体验！\n教程链接：\nhttps://go.hyper.ai/3E9FY\n内容中包含的图片若涉及版权问题，请及时与我们联系删除",
      "article_url": "https://hub.baai.ac.cn/view/51558",
      "publish_time": 1767172440,
      "publish_date": "2025-12-31 17:14",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://go.hyper.ai/3E9FY\"]",
      "add_ts": 1767193283,
      "last_modify_ts": 1767309619
    },
    {
      "id": 88,
      "article_id": "51556",
      "title": "我们等了17年的AI「贾维斯」，这一次真正现身了？",
      "description": "Hey Tuya正将人类对“超级AI助手”的幻想变为现实，如同《光环》中的Cortana、《钢铁侠》里的贾维斯和电影《她》中的智能伴侣，它以高度智能化的服务悄然融入日常生活，成为真正的“智能管家”，改变人机交互方式，重塑生活体验。",
      "content": "新智元报道\n编辑：定慧 桃子\n【新智元导读】\n人类对「超级助手」的憧憬，早已深植于对未来的想象中。如今，幻想正走进现实。Hey Tuya，一个真正融入生活的「智能管家」，走出屏幕悄然改变生活的每一刻。\n多少年来，人类对「超级 AI 助手」的想象从未停止。\n从游戏《光环》中伴随士官长的\nCortana\n，到《钢铁侠》里运筹帷幄、无所不在的\n贾维斯 (JARVIS)\n，再到电影《她》中那个细腻温柔、触及灵魂的\nSamantha\n……\n这种想象跨越了载体：它有时是全息投影下的一抹幽蓝，有时是耳机里的一段磁性声波，有时则是深藏于装甲背后的跳动数据。\n这些形象寄托了人类最深层的渴望：我们不仅在寻找一个\n无所不知的工具\n，更在期待一个\n永不背叛的伙伴\n。\n它们是人类智慧的延伸，也是我们孤独灵魂在数字荒原上的回响。\n我们所期待的，早已超越了手机屏幕上的简单问答，而是一个活生生的「智能体」。\n它能感知环境、精准理解意图，调用现实资源主动提供服务，还能持续进化成长。甚至，在你尚未开口之前，就已做好了准备。\n如今，这一想象正逐渐被拉入现实！\n近日，AI云平台服务提供商涂鸦智能发布了「超级AI助手」——\nHey Tuya\n，描绘出科幻想象的现实版雏形。\n它是基于多智能体（Multi-Agent）协同架构的「生活管家」，打破了手机和电脑屏幕的「枷锁」。\n不论是涂鸦APP、智能音箱，还是AI玩具、中控屏等任意入口，皆可唤醒。\n作为「物理AI」的调度核心，它全面融入了人类的物理生活空间：\n一身兼多职，是办公助理、生活秘书，也是日常规划师、健康教练......主动在生活中为人类提供帮助。\n不仅如此，Hey Tuya将具备短期和长期记忆能力，可以学习用户习惯。\nHey Tuya的诞生，标志着我们距那个由AI无缝编排的生活又近了一步。\n全场景覆盖的超级智能体\nAI生活助手Hey Tuya最大突破在于，实现了多端协同，让AI无处不在。\n它不再依赖于任何单一入口，通过涂鸦APP、智能音箱、AI玩具、中控屏，甚至是手腕上的智能手表，只需一句——\nHey Tuya，便能唤醒全天候的AI生活助理。\n这种跨空间、跨设备的无缝协同，是Hey Tuya体验的核心，升维覆盖到了全生活场景的「环境智能」。\nHey Tuya不仅仅是一个聊天机器人，更像一个管家，能够学习用户的作息规律和环境偏好，实现从「被动响应」到「主动智能」的跨越。\n家庭安全守护者\n：提供24小时全时段安全守护，支持画面识别并将其转化为直观的语音或图文推送。\n节能专家\n：通过实时监测全屋能耗，主动提供节能策略（如热水器定时开关），降低碳足迹与电费。\n健康与工作助手\n：化身健康生活教练，支持卡路里识别、睡眠及运动追踪；同时担任办公助理，提供会议纪要生成、实时翻译及思维导图功能。\n生活秘书\n：细致管理家庭备忘、宠物喂食、植物养护等日常琐事，让生活井然有序。\n让我们想象未来的某一天（这一天或许并不遥远）。\n早上醒来时，Hey Tuya协同智能音箱自动播报今日气候情况、打开轻音乐，打开AI调光、自动拉开窗帘。\nHey Tuya的\nAI照明\n已经从简单的「远程开关」进化为具备「感知、逻辑与进化」能力的\n智慧光环境系统\n。\n用户无需手动配置复杂的参数。\n通过Hey Tuya，只需输入「我要浪漫的晚餐氛围」，AI照明专家便会提取色调、亮度、饱和度等参数，秒级还原并生成匹配的照明方案。\n当你离家后，Hey Tuya根据设定，协同智能电表、智能插座等开启AI节能。\n还可以定制多种家庭能源管理方案，并且内置了多种节能策略。\n当你在工作的时候，Hey Tuya的AI安全守护能够帮助你关注每一个你所在意家庭场景。\n尤其可以随时感知家中孩子的一举一动。\n出门在外，Hey Tuya联动智能门锁等设备，识别异常事件，守护家庭安全。\nHey Tuya提供了丰富的硬件支持，从穿戴、音箱，到玩具、家电，甚至还有宠物和骑行产品。\nHey Tuya还提供了丰富的AI原生应用。\n比如可以识别各种鸟类的AI镜头，在拍摄后还可制作为贴纸收集。\nHey Tuya还有AI健康功能，比如可以通过镜头自动识别食物卡路里，并做好日常的热量摄入管理。\n还可以和Hey Tuya对话来获得推荐食谱。\n技术支撑：自研PAE引擎\nHey Tuya的智能体验，并非空中楼阁。\nHey Tuya能够实现精准控制与毫秒级响应，离不开涂鸦官网展示的核心技术底座——\nPAE（Physical AI Engine）系统架构\n。\nPAE部署了覆盖全球主流地区的AI-Device Real-Time Network（AD-RTN)边缘加速网络，基于AD-RTN网络，涂鸦构建了T-RTC（Tuya Real-Time Communication）一套高可靠、低时延、强对抗、低门槛的实时通信系统。\n在此之上，涂鸦构建了面向自然语言多模态交互的Conversational AI Engine、面向视觉理解的Vision AI Engine，以及面向物理设备通信与控制的IoT Intelligence Engine。\n依托OmniMem个体长记忆技术，PAE能够在多模态交互、设备行为模式、场景意图等维度实现持续学习与记忆，使 AI 能真正理解用户偏好与空间习惯。\n此外，通过Adaptive Expert System（AES）专家系统与Dynamic Orchestration Agent（DOA）智能体编排引擎，PAE让AI的认知与决策能力与真实世界的智能设备深度耦合，实现从感知、计算到执行的完整闭环，形成可成长、可自我优化的智能空间。\n记性好：它是最懂你的「老朋友」\n传统的AI往往「聊完就忘」，但PAE内置的\nOmniMem长记忆引擎\n就像人类的大脑。\n它不仅能秒级想起你上周说过的话，还能理解你的生活习惯（比如你习惯周五晚看电影时调暗灯光）。\n它甚至能做到「该记的记，该忘的忘」，比你更懂你。\n反应快：交流零时差，沟通不费劲\n为了不让AI变成「迟钝的木头人」，涂鸦打造了\nAD-RTN（AI-Device Real-Time Network） 全球加速网络\n。\n基于多年全球化的技术积累，涂鸦构建并部署了覆盖全球主流地区的  AI-Device Real-Time Network（AD-RTN）边缘加速网络 ，并在AD-RTN基础设施之上，搭建了 Tuya Real-Time Communication（T-RTC） 一套高可靠、低时延、强对抗、低门槛的实时通信系统，为AI与设备、人与AI之间的实时交互提供稳定保障。\n秒级响应\n：\n无论你在地球哪个角落，和 AI 对话的延迟比眨眼还短。\n极速打断\n：\n你可以像和真人聊天一样，随时打断它，它能立刻反应，不再尴尬地自说自话。\n抗弱网能力\n：网络不稳定情况下，它也能保持在线，不掉链子。\n边缘加速网络（AD-RTN）支持全球主要国家和地区平均网络时延低于86毫秒！\n多才多艺：能听、能看、还会干活\nPAE 整合了一整套「感官系统」，让 AI 硬件变得全能：\n对话引擎Conversational AI Engine让AI听的真。\n该引擎集成了高精度语音活动检测（VAD），支持300毫秒的「极速打断」与800毫秒的「优雅打断」，在流畅响应与误判控制间取得最佳平衡；语音识别（ASR）方案覆盖全球 60 余种语言，在主流语种上实现行业领先的词（字）错率表现，从源头保障交互准确性；文本转语音（TTS）支持全球超60种语言、300多种音色及情绪增强，让AI的「声音」更加自然、拟人且富有情感。\n视觉引擎\nVision AI Engine让AI看的懂\n。\n像摄像头、机器人通过\nVision AI\n引擎，能真正看清环境，帮你守护家庭或分析场景。\n中控引擎IoT Intelligence Engine成为「万能遥控器」。\n能指挥家里所有的智能设备协同工作，把复杂的指令变简单。\n开放包容：让开发者「搭积木」造 AI\n为进一步提升开发效率与系统可控性，PAE架构创新性引入了智能体编排引擎\n——\nDynamic Orchestration Agent（DOA）\n。\nDOA 通过可视化的智能体编排方式，帮助开发者\n快速构建、验证并迭代复杂的AI应用逻辑\n。\n以前开发一个 AI 硬件要几个月，现在通过\nDOA智能体编排引擎\n，开发者就像玩拼图或搭积木一样，把语音、视觉、控制等功能拽到一起，\n最快1天就能搞定\n。\n这大大降低了创新成本，意味着未来我们会看到更多新奇、好用的智能装备出现在生活中。\n「生活Agent」的星辰大海\n让AI走出屏幕，走进生活\n「硅谷精神之父」Kevin Kelly在其著作《2049：未来1000天的可能》，曾做出了预言：\nAI将成为我们生命的隐形合作者，它在我们身边，不再被我们察觉。\n这一洞见，恰恰描绘了AI的终极形态，即无感、无形，却又无处不在，如空气般融入我们日常的肌理。\n近年来，多模态大模型能力不断迭代跃升，为AI Agent在真实世界的执行和操作中，提供了更多的可能。\n甚至，OpenAI总裁Greg Brockman等多位大佬表示，「2025年是Agent的元年」。\n与此同时，物理AI（Physical AI）也成为了下一个前沿。老黄在公开演讲中，不止一次提到物理AI的重要性。\n它不止在虚拟世界中响应的软件，能嵌入、连接实体设备与环境互动。\n这就相当于，在数字世界和真实世界之间搭一座「桥」，让AI不仅能想，还能做实际的事儿。\n还有并行生长的「世界模型」，让AI逐渐去模拟、预测、推理可能发生的情况，而不是简单生成像素级输出。\n李飞飞World Labs推出的Marble、LeCun即将官宣的初创AMI Labs，都是典型代表。\n纵观整个发展历程，AI综合能力正迈向新的高度，但现实的体验却存在明显的「断层」。\n传统AI Agent核心局限在于「单点智能」，大多被禁锢于单一设备的「数字牢笼」中。\n你的手机并不了解，智能音箱正在播放什么，你的办公助理也不知道家里空调，是否需要提前开启。\n它们受限于手机、电脑屏幕里，指令是一次性的，因场景割裂而无法协同，只能被动响应。\n一个能真正跨越设备、穿梭于不同生活场景的AI，似乎总是遥不可及。\nHey Tuya正是为了解决这一断层而生，涂鸦庞大的硬件生态，开放、中立、国际化的生态系统，为\nPhysical AI\n开发者提供了肥沃的土壤，这也是涂鸦对未来智能生活场景的深度布局。\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659227&idx=1&sn=62b162ea0cff09394d3207ac486e20d1&chksm=f085bef7006bf565abfdcd3d16c7e484adc5166b190a15cd186c1415ae86244f128205dc1880&scene=0&xtrack=1#rd",
      "publish_time": 1767172200,
      "publish_date": "2025-12-31 17:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767193293,
      "last_modify_ts": 1767309630
    },
    {
      "id": 94,
      "article_id": "51550",
      "title": "卡帕西推荐的AI Coding指南：3招教你效率翻倍",
      "description": "AI Coding热潮持续升温，大神卡帕西和OpenAI总裁Greg Brockman力荐一份高效Coding Agents指南。该指南由Swift开发者、AI驱动开发专家Peter Steinberger撰写，结合实战经验，提出三招提升开发效率的方法，帮助开发者快速交付。内容聚焦AI辅助编程的最佳实践，受到广泛好评，被誉为AI时代程序员必备技能指南。",
      "content": "闻乐 发自 凹非寺\n量子位 | 公众号 QbitAI\nAI Coding火到不用多说，但怎么用才最高效呢？\n这份连大神卡帕西和OpenAI总裁Greg Brockman都在转发推荐的Coding Agents指南，用3招教你快速交付。\n大神们在转，网友也在夸！\n这份实战指南的作者是Swift开发出身、深耕AI驱动开发领域的大神\nPeter Steinberger\n，他也是一位AI Coding重度爱好者，已经写了很多份实战经验博客。\n简单总结一下今天的这篇AI Coding指南：先按任务类型选对模型，再重构工作流提速，但要捋清人机分工。\nPeter不仅给出了自己的模型配置，最后还有实用小技巧～\n三大关键策略\n按任务类型选对模型\n大家用AI编码，很多时候是不是一个模型用到底？\n结果一到大项目就卡壳，小项目修改还慢。问题呢，就出在“没给模型找对活儿”。\n人家这份指南里就说了，第一步就得先按任务类型给Coding模型分好工。\n大任务就用Codex，小任务Opus更好使\n。\n比如，搞几十页的工程规范落地、项目重构这种大活儿就直接上Codex，它有个特点，开始写代码前会默读文件，把项目逻辑摸透，虽然比Opus多花点时间，但对复杂需求的完成度更好。\nPeter之前重构Opus 4.0的旧代码，Codex花了几个小时读透了整个项目，不仅没漏关键逻辑，还修复了2个隐藏Bug。\n如果只是小范围修改这种比较零碎的任务，那Opus更合适。它不用读很久的文件，响应很快，基本上几分钟就能出结果。\n不过，要进阶的话，首选GPT-5.2-Codex，直接一步到位。\n现在Peter最常用的就是GPT-5.2-Codex，尤其是high模式，不管搭Chrome扩展的前端还是写Go语言的CLI工具，它都能兼顾速度和准确率，也不用在Codex和Opus之间来回切换了。\n在这里，Peter还给出了自己的配置。\n重构工作流\n选对模型是基础，而真正让作者同时推进8个项目还不慌的是他这套定制化的工作流。\n因为每天会冒出很多新的想法，比如“给Clawdis加个控制卧室温度的功能”“写个CLI查外卖进度”……\n但这些想法Peter并不会记在备忘录里，而是直接扔进Codex的排队列表。\n比如开发“YouTube视频总结Chrome扩展”时，他一边让Codex验证CLI核心逻辑（把视频转成Markdown），一边把 “加浏览器弹窗提醒”“支持本地存储” 等想法塞进队列，Codex会按优先级慢慢处理，不用他盯着催，也不怕遗忘在备忘录里。\n而且，一个小tips是坚决不回滚！\n“构建软件就像爬山，不用笔直往上走，绕点路、退两步都正常，关键是别在‘要不要回滚’上浪费时间。”\n遇到相似的功能，不用从头写\n。\n比如作者之前在VibeTunnel项目里做过 “字符流输出”，后来开发Clawdis时需要类似功能，他直接让Codex“去../VibeTunnel文件夹里看看，照这个逻辑给Clawdis加一个”，10分钟就适配好了。\n甚至搭新项目时，他也会让Codex参考旧项目的结构，比如“按../Sparkle项目的目录格式，搭一个新的日志工具”，这时候模型就能自动复制适配。\n人机分工\n当然了，写代码这件事也不能全靠AI，这时候就得来个人机分工，原则很简单：\nAI干执行，人做决策\n。\n这些事一定要自己做：选哪个依赖库、系统架构怎么设计、功能优先级怎么排……\n写基础代码、修复已知bug、生成GUI界面、更新项目日志，甚至“注册域名”“改DNS配置”这种琐事，都可以交给AI。\n作者举了自己实战中的两个例子。\n在选择用Go语言做CLI工具前，他花了半天研究“Go的类型系统是不是更适合AI生成代码”“有没有常用的Go库能复用”，确定之后再让AI开写，最后也没怎么返工。\n不过在开发数据可视化工具时，就直接让AI花了20分钟写核心代码，再让它帮忙测试，也不用自己切设备操作。\n实用小技巧\n除了上面的核心方法，作者还分享了几个挺实用的小操作，都是踩坑总结出来的。\n第一个是\n开发先从CLI开始，再扩展功能\n。\n不管想做什么项目，先搭个简单的CLI工具验证核心逻辑，比如他之前做“YouTube视频总结Chrome扩展”的时候，先写了个能把视频转成文字、再用模型总结成 Markdown的CLI版本。\n确认能跑通后，才让AI搭前端、做浏览器扩展，一天就搞定了。\n第二个是\n让文档帮模型记上下文，不用反复提需求\n。\n在每个项目里建个docs文件夹，把“系统设计思路”“功能说明”写进去，再用脚本让AI读这些文档。\n比如Peter在docs里写了“Clawdis这个项目要支持控制家里的灯光”，之后让AI加新功能时，不用反复说“要和灯光控制兼容”，模型就会自己读文档，减少了沟通成本。\n第三个是\n单人开发直接提交主分支，不用搞复杂分支\n。\n要是你一个人开发，那就不用建“dev分支”“feature分支”，改完直接提交主分支。\nPeter表示：\n“分支多了反而容易有合并冲突，Codex有时候会自动建临时工作区处理混乱代码，改完合并回主分支，比手动管理分支简单多了。”\nPeter说的这些坑你有没有踩过？\n还有啥AI Coding实用小技巧欢迎分享！\n原文地址：https://steipete.me/posts/2025/shipping-at-inference-speed\n—\n欢迎AI产品从业者共建\n—\n📚\n「AI产品知识库」\n是量子位智库基于长期产品库追踪和用户行为数据推出的飞书知识库，旨在成为AI行业从业者、投资者、研究者的核心信息枢纽与决策支持平台。\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859368&idx=2&sn=5b52dd877d2d3990630a0f976b8724fd&chksm=e99959d2a8711c668f514016db1a4a30c74c0757c7a892311dcb9740b10d80ec5a9bb65b4758&scene=0&xtrack=1#rd",
      "publish_time": 1767168600,
      "publish_date": "2025-12-31 16:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://steipete.me/posts/2025/shipping-at-inference-speed\"]",
      "add_ts": 1767193317,
      "last_modify_ts": 1767309653
    },
    {
      "id": 96,
      "article_id": "51548",
      "title": "千人千面的真人级AI名师，劈开教育「不可能三角」",
      "description": "「与爱为舞」推出的AI导师开创教育领域新应用，以自然流畅的讲课节奏和互动实现个性化教学，支持一对一辅导。自年初上线已服务百万用户，突破传统教育中规模、质量与成本难以兼顾的“不可能三角”，推动AI在教育场景的深度落地。",
      "content": "Jay 发自 凹非寺\n量子位 | 公众号 QbitAI\n注意看，这是一个教育领域的AI应用新物种——\n咱就是说，这讲课节奏，这语气，这互动，也太自然了。\n更重要的是，它不仅能「像老师一样讲课」，还能针对每一位学员进行一对一的个性化教学。\n这位AI导师，出自一家名为「与爱为舞」的AI原生应用企业。自年初上线以来，已累计为百万级用户提供学习陪伴与一对一讲解服务。\n教育行业，\n向来是\n个\n「规模、质量、成本」的不可能三角\n。\n既能做到千人千面，又能服务百万名学员，还几乎看不出是AI……更是难上加难。\n它究竟是怎么做到的？\n与爱为舞用来劈开这个不可能三角的，是一把\n硬核的技术巨剑\n。\nAI教育，要的不止「答案」\n而铸造这把技术巨剑，有三块核心组成部件：「模型+语音+工程」。\n先看\n模型\n——\n得益于CoT的Scaling，大模型解决复杂问题的能力指数级增长，「做题」水平突飞猛进，甚至能斩获「奥赛金牌」。\n摘得奥赛桂冠，AI只需要给出标准答案。但搞教育不行。\n先来看一个简单的英语语法题：\nLily expects\n_\nher grandparents in the countryside next month.\nA. visiting｜B. to visit｜C. to have visited｜D. having visited\n大模型给出的解答如下：\n这道题的正确答案是B. to visit。\n核心考点解析：\n动词固定搭配，动词 expect\n（期望、预料）\n的常用用法是——\nexpect to do sth.\n（期望做某事）\n，后面需要接不定式\n（to + 动词原形）\n作宾语。\nB选项to visit是不定式的一般式，用来表示与谓语动词\n（expect）\n同时或之后发生的动作，符合 “下个月看望祖父母” 的将来时态逻辑。\n我可以帮你整理一份常见接不定式作宾语的动词清单，方便你记忆，需要吗？\n答案是对了，看起来好像也讲了解题过程，但如果拿这套方法教学员，那肯定是要被家长投诉的啊……\n完全没有引导学员思考，一上来就把答案透露了。就像个纯天赋型学霸，风驰电掣做完题，然后猛地丢给你一个结果，问你：「我说的对不对！」随后才给出一串看似头头是道的分析。\n不过，硅基大佬，小弟我根本听不明白你在说什么啊！\n最后还要给你一份「动词清单」，直接默认教学等于枯燥的背诵，而没去想怎样引导学员的主观能动性。\n归根结底，通用大模型的设计初衷就不是教育。它拼尽全力，只想向用户证明一件事——「厉害吧，哥啥都知道！」\n古人讲：\n授人以鱼，不如授人以渔\n。导师如果光顾着自己拿金牌，这师生关系就乱了套了。\n想要成为一名好导师，AI需要学会放低姿态，真正关心学员的课堂体验。\n首先，AI得明白各学科的核心知识图谱、关键考点和常见解题方法，这些才是学员能服用的，是最基本的「知」。\n在此之上，AI还得学习名师是怎么设计讲解顺序的，并从中总结归纳出一套顶尖教师的授课方法论。这是更高维度的「知」。\n陆游讲，「纸上得来终觉浅，绝知此事要躬行。」\n「知」总是相对容易的，重点是如何把纸上谈兵那套，搬到现实世界里实践起来。\n所幸，「行」方面，与爱为舞有相当充足的弹药。\n据悉，他们已积累了约百万小时的音视频互动数据，特别是包含大量业内TOP级名师的授课视频。\n在此基础上，团队又根据学员的认知水平与学习态度，构建出多类型的「虚拟学员」，让他们与AI导师进行「搏击」，每周又能收获\n数\n万小\n时的合成数据\n。\n这些数据在经过筛选与清洗后，会交由专业教研进行把关。\n具体而言，\n教师\n们会\n把自己多年的「教学经验」，根据场景具象化为一条条思维链\n，最终汇集成一本「好老师红宝书」：\n每个知识点该如何拆解，与学员互动时如何循循善诱……不止要让AI学会怎么讲课，更要明白「为什么要这么讲」。\n这种手把手教的方式效果很好，但成本也相当高。\n随着方法论逐渐成熟，团队索性将这一环节也自动化，让AI模仿专业教研参与数据标注。\n备考资料准备就绪，下面就该着手训练了。\n第一步，照猫画虎。\n那些相对容易标准化的知识，已体现在标注数据之中。AI需要做的，是通过模仿专业教师的思维链，逐步摸索出每一个教学动作背后的真实意图。\n这一微调过程，能大幅降低AI「自我发挥」带来的的幻觉率，同时培养更稳定的推理能力与泛化能力。\n能做到这一点，就算是打牢了基本功。\n最基本的教法、节奏和经验都已被「固化」，能以标准化形式面向所有学员输出，教学质量的下限得到保障。\n但如果目标只是及格，这件事就没意义了。\n师傅能陪伴的路程就到这。接下来，得能靠AI自己上路修行。\n第二步，终于到了大家喜闻乐见的\n强化学习\n环节。\n在教育这个场景下，与爱为舞的奖励函数围绕教学路径规划质量、教学有效性与教学灵活性等维度设计，通过GRPO给AI做强化。\n这步结束，AI彻底出师——不仅能够完成授课任务，还能驾驭课堂节奏，提高趣味性，根据不同学员灵活调整教学策略。\n那么接下来，就该真正走进「教师资格证考场」了。\n不过，教育不是一个有标准答案的任务，Benchmark肯定是行不通。笔试应该如何设计？\n与爱为舞的做法很简单，甚至有些「粗暴」——\n笔试啥，直接把AI丢到讲台上\n，看学员的真实反应。\n第一步，是在\n模拟课堂\n中试水。\n这个课堂由多类型的模拟学员组成，团队会按照真实分布规律注入一批线上数据，再由评分模型从多个维度对AI导师打分。\n模拟课堂如果表现不错，AI会迎来更严苛的终极试炼场——\n直连真实教学一线\n。\nAI能否驾驭高度不确定的真实课堂？是否真的能摆脱照本宣科？答案，只能由学员来评判，再好的数据标注导师也帮不了。\n即便成功拿下了「教师资格证」，但教学，依然是个终身学习的过程。\n正式上线后，海量的学员数据会被持续建模，AI导师将基于每一位学员的专属档案库，为其定制个性化课程。\n至此，AI导师才算具备了千人千面的能力。不仅下限有保障，上限也很高。\n「真人级」AI导师\n通过「知」与「行」的双重训练，与爱为舞得以将通用大模型，塑造成一个真正懂教学的名师AI模型。\n然而，再聪明的模型，无法与学员真实互动，最终仍会沦为一颗「缸中之脑」。\nAI导师需要「耳朵」。\n作为导师，连学员的问题都听不清楚，最后聊的牛头不对马嘴。不仅显得导师呆若木鸡，学员的积极性也会大打折扣。\n但现实是，课堂不是录音棚。\n真实环境往往充斥着噪音\n，如果有电视，甚至会出现多个人声掺杂在一块的情况。\n即便能输入干净音频，中国有各种各样的方言，不同学员的咬字发音习惯也不同，识别难度相当高。\n雪上加霜的是，在传统ASR范式下，输入模型的只是一段孤立的语音，基本没什么上下文。一旦放到教学场景下，AI很容易把同音字混淆。\n例如，「极限」和「极线」。\n前者是微积分中的核心概念，后者则属于二次曲线相关的几何术语。二者在语义上截然不同，发音却完全一致，如果没有上下文，仅凭语音几乎无法区分。\n为解决这个问题，与爱为舞基于其长期积累的教育场景与课堂教学数据，自研了一套\n多模态语音理解大模型\n，让语音识别不再只「听声音」，而是能够理解所处的教学上下文。\n在此基础上，团队进一步自研了\n声纹降噪模型\n，可以将学员和家长说话的声音区分开。\n事实证明，凭借「上下文理解+声纹降噪」，ASR识别效果有了质的飞跃：句准确率从行业内开放API的80%左右的最好效果，大幅度提升至\n95%以上\n，接近真人理解识别水平。\n听清楚学员的问题，思考完毕，下面就该导师开口指点迷津了。\n目前，行业主流语音合成架构基本都是LLM或者LLM+Flow/Diffusion的方案。\n真用到课堂里，会暴露出三个问题：人机味明显、不像在上课、不支持双向实时交互。\n下面看看，与爱为舞是如何迈过这三道坎的。\n先来最直观的——\n人机感\n。\n在底层架构上，团队采用了LLM+Flow方案，引入了两类speech token：一类负责声音本身的细节，一类负责语义和表达节奏。\n在此基础上，结合强化学习，可以让AI学会正常说话应有的抑扬顿挫。\n不过，光会说话可不行，老师上课得有个「老师」的样。\n为此，团队拿出了大量真实课堂数据，对不同学科、不同导师的讲课方式进行了建模：有的导师说话像机关枪，有的导师则更慢条斯理。\n落地时，团队还会为每位主讲名师单独设计录制脚本。这样，数据收集效率更高，还能最大程度还原名师声线，保证声音的「质感」。\n具体效果如何嘛，我们可以一起听听下面这两段音频。\n（文本：\n接下来我们看这个题，图中表示水蒸气直接变成冰的过程）\n这是第三方TTS，不仅表现力较弱，还出现了发音错误，如果是上课很容易出戏。\n相比起来，这段是不是「活人感」足了很多？\n这正是自研模型的优势，发音更自然，更稳定，情感表现也更好。\n至于\n双向实时交互\n，AI导师需要边说话边理解学员是否在主动打断询问导师问题，并且做出及时的响应，这是AI导师智能与否最重要的能力之一。\n为此，团队研发\n流式语义VAD和打断模型\n，能够让AI导师实时识别学员是否有真实打断意图，识别准确度可以达到90%以上。\n而为了让AI导师真正「站上讲台」，团队还为其配套设计了逼真的数字人形象：口型、面部表情与肢体动作高度同步，且支持实时互动。\n这下，AI导师可算是凑齐了自己的莲藕肉身三件套——「耳朵+嘴巴+身体」。\n当AI开始具备人的温度，信任才有可能建立，学员也更不容易分心。\n百万AI学习原住民\n话说回来，即便「大脑、耳朵、嘴巴」全部补齐，我们依然无法解释与爱为舞是如何实现规模化落地的。\n毕竟，从语音识别，到模型思考，再到语音合成，最后还要驱动真人级数字人，这条服务链路相当长。\n任何一个环节稍有迟滞，都会严重影响学员的课堂体验。\n而当用户规模放大，「千人千面」会带来更高频的推理请求，一旦调度或资源分配稍有不慎，服务质量会迅速下滑。\n想要实现大规模落地，AI导师还需要一颗能持续供血、且足够强健的「心脏」。\n首先，得把这条冗长的服务链疏通，保证「血管」里不堵。\n在《思考，快与慢》中，Daniel Kahneman提出，大脑为了偷懒，演化出了两套工作模式：\n靠直觉行事的「系统一」、调用认知资源的「系统二」\n。\n与爱为舞借鉴的，正是这一点。\n当学员开口提问时，系统不会一股脑把问题全丢给大模型，而是先做一次判断：\n能马上回答的，直接走快速通道；真正需要推理的，再交给大模型慢慢想。\n具体而言，简单问题会先由快速回答系统给出反馈；与此同时，大模型已经在后台并行启动。等学员听完前半句，模型的「思考」也完成了一大半。\n于是，模型回复的延迟可压缩到\n100ms\n以内，整条响应链路稳定在\n1–1.5秒\n。\n同理，如果学员在导师讲话时突然插话，AI也不会傻等学员全部说完再思考。而是立刻结合上下文判断学员的意图，提前开始构思。\n这样响应时间仍可控制在\n100–200ms\n，整条链路不超过\n1.6秒\n。\n当然，遇到一些开放式问题，确实要多想一会儿。\n但即便如此，AI导师也不会「卡住不动」，而是通过表情变化、过渡性话语告诉学员：\n我在想，你稍等\n。而不是空气突然安静，一人一AI面面相觑。\n血管疏通之后，还可以通过「提前缓存」，让血液循环得更顺畅一些。\n在真实教学中，同一堂课的核心知识点其实相对固定。哪怕学员的具体问题不同，总体来看仍有一定规律可循。\n先从\n输入\n说起。\n大模型在生成答案前，要先「读懂问题」\n（prefill）\n，再「组织回答」\n（decode）\n。而前者非常吃算力，并且很耗时间。\n团队的做法是，把Prompt结构化：在不影响回答质量的前提下，把同一类场景里老是出现的内容集中起来，从而让AI少做重复阅读。\n再看\n输出\n。\n学员千差万别，但在具体知识点上，很多人其实都是在同一个地方「栽跟头」。既然如此，AI导师就没必要每次都从头生成一整套讲解。\n因此，团队会以题目、引导方式和学员回答作为索引，把模型的讲解结果先存下来。一旦再次遇到相同情形，直接拿来用就好。\n通过这套「链路优化+缓存」的组合拳，与爱为舞将整个流程控制在了1s-1.6s之间。\n筋骨与脉络就位，接下来，该让心脏泵得更有力了，与爱为舞在\n大规模并发\n上\n也做了大量工作。\n首先在单机上\n，为了榨干每一张GPU，团队在系统设计之初就完成了显存地址的统一规划，全程实现显存共享，尽量避免数据在不同计算与存储介质间反复搬运所带来的性能损耗。\n与此同时，在GPU算子层面，团队又针对核心计算路径进行了专项加速，使单卡的有效吞吐能力提升约5倍，足以支撑起几十路真人级数字人的推理。\n其次在集群上\n，资\n源的调度能力同样至关重要。团队又从五个层面，对整体系统做了进一步加固：\n多数字人统一调度：\n同一个资源池中不同形象统一调度，从而更好的复用集群资源；\n系统抽象：\n对话轮次化、课节内容组件化、知识点任务化，让复杂流程标准化；\n并行计算：\n尽量不浪费任何空闲算力，AI导师还在讲上一题时，下一题的计算已经在后台悄然启动；\n预留容量：\n服务支持横向扩容，不同层级配有多种缓存与缓冲机制，一层层削薄高峰流量，避免高并发请求同时压向模型与数据库；\n保险机制：\n整个教学调度过程可恢复，即便遭遇网络中断或客户端异常退出，教学状态也不会丢失。\n凭借一台全速运转的\nAI发动机\n，加上一张巨大的\n工程降落伞\n，与爱为舞得以把AI导师「空投」到全国各地，成为业界首个支持万人并发的真人级AI教学系统。\n归根结底，与爱为舞从未将AI视作一个简单的辅助工具。\n在他们看来，比起技术升级，AI更像一场关于个体工作逻辑与组织管理范式的深层重塑。\n回头看今天的企业形态，其实很多都是工业时代的妥协产物：人的精力有限，只能把分工越拆越细，组织层级上层层加码。\n一道道庞大的部门墙，虽防止了团队混乱，但也淹没了许多人才的主观能动性。\nAI的出现，第一次让生产力得到完全释放，每个人都能担任「架构师」。\n在此背景下，与爱为舞提出「全员皆超级个体」——只要有想法，任何人都可以手握数据与算力这两栋「粮仓」，调度一支由智能体组成的硅基军团，以极低的成本，快速实现抢跑。\n而这一理念，也已在产品上得到验证——\n至今，「爱学」已服务\n百万级用户，学员分布于全国342个城市\n：东至佳木斯，西达克孜勒苏，南抵三沙，北至大兴安岭。\n关于AI原生的企业理念，市场已经给出了自己的判断。\n而当AI真正开始惠及百万学员，我们或许终于有机会，兑现孔夫子两千多年前所期待的那个美好愿景——「有教无类、因材施教」。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859282&idx=1&sn=bc10090410756f39cc9142941736553b&chksm=e93899a6346c71d5eb6d34969c8914b81f44b4c7f14738c567df73888a5a80fc208f49ba9c1b&scene=0&xtrack=1#rd",
      "publish_time": 1767168600,
      "publish_date": "2025-12-31 16:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767193324,
      "last_modify_ts": 1767309661
    },
    {
      "id": 99,
      "article_id": "51544",
      "title": "「地质约束显式+数据驱动模型」的新路径，浙江大学团队实现跨区域矿产远景预测性能和可解释性提升",
      "description": "浙江大学研究团队提出一种地质约束的数据驱动成矿预测方法，通过引入各向异性空间邻近关系与非平稳建模机制，定量表达成矿异质性与方向性控制。该方法融合人工智能与地学数据，提升矿产远景预测填图精度，实现对复杂地质环境下矿化规律的高效识别，推动智能勘查技术发展。",
      "content": "作者：\n李天一、陈奕君、紫晗\n编辑：李宝珠\n本文已获得研究团队授权发布，转载请联系本公众号并标明来源\n浙江大学的研究团队提出了一种地质约束的数据驱动成矿预测方法，通过将各向异性空间邻近关系与空间非平稳建模机制显式引入预测框架，实现对成矿异质性与方向性控制的定量表达。\n近年来，人工智能与地学数据深度融合显著推动了矿产资源预测方法的发展，矿产远景预测填图（Mineral Prospectivity Mapping, MPM）已成为降低找矿风险、支撑深部与复杂地质条件下资源勘查的重要技术手段。然而，成矿作用受构造、岩性及岩浆活动等多重地质因素控制，具有显著的空间非平稳性与方向性特征。\n现有多数机器学习与图模型方法往往以隐式方式处理这些空间特征，难以显式刻画成矿过程中的各向异性与区域差异性，\n从而在地质可解释性与预测稳定性方面仍存在不足。\n针对上述问题，\n浙江大学的研究团队提出了一种地质约束的数据驱动成矿预测方法，\n通过将各向异性空间邻近关系与空间非平稳建模机制显式引入预测框架，实现对成矿异质性与方向性控制的定量表达。该方法构建了各向异性空间邻近性神经网络，并结合卷积注意力加权机制与逻辑回归模型，有效融合多源地学信息，\n在保持预测精度的同时显著增强了模型的地质一致性与可解释性。\n通过在加拿大梅古马地体金矿区和美国科迪勒拉斑岩铜成矿带的多尺度验证，结果表明，\n该方法在召回率和整体泛化性能方面均优于多种主流模型，并能够揭示区域尺度上的关键控矿因素与成矿方向性特征。\n该研究为将地质约束显式融入数据驱动模型提供了新的技术路径，对智能找矿与成矿机理定量研究具有参考价值。\n目前，该项研究成果已以「Geologically constrained data-driven modeling for mineral prospectivity mapping」为题发表于 Geology。\n研究亮点：\n* 突破传统机器学习方法的隐式处理局限，通过构建各向异性空间邻近性神经网络，实现对复杂成矿作用空间异质性的定量刻画；\n* 地质约束与数据驱动方法深度融合，保持了模型结构的可解释性与地质一致性；\n* 能够揭示区域尺度上的关键控矿因素与成矿方向性特征，实现跨区域、多尺度验证的稳健泛化性能。\n论文地址：\nhttps://go.hyper.ai/vbUpa\n关注公众号，后台回复「成矿预测」即可获取完整论文\n更多 AI 前沿论文：\nhttps://hyper.ai/papers\n基于深度神经网络加权逻辑回归模型，实现成矿概率稳健预测\n成矿作用通常受构造、岩性、岩浆活动及多种地球物理—地球化学因素的共同控制，\n其空间分布表现出显著的非平稳性与方向性特征。\n这使得传统依赖全局假设的统计模型或纯数据驱动方法，难以准确刻画区域尺度上的成矿差异与局部成矿规律。尽管近年来机器学习和人工智能方法在矿产远景预测中取得了显著进展，但多数模型往往以隐式方式处理空间约束，难以反映真实的地质控制过程，从而在地质可解释性和泛化能力方面仍存在不足。\n浙江大学研究团队围绕「如何在数据驱动框架中显式引入地质约束」这一核心科学问题，系统分析了现有矿产远景预测方法的局限性。传统地统计方法能够在一定程度上缓解空间非平稳性问题，但其线性假设难以刻画复杂的非线性成矿过程；而近年来兴起的神经网络和图神经网络方法，虽然在预测精度上表现突出，\n却往往仅通过模型结构隐式学习空间依赖关系，缺乏对成矿各向异性与空间异质性的直接刻画机制。\n这些不足限制了模型对区域构造控制和成矿方向性的识别能力。\n该研究选取了两个具有代表性的区域尺度数据集：\n* 加拿大梅古马地体（Meguma terrane）金矿区数据集：\n该区是矿产远景预测领域的经典基准区，矿点资料完备、成矿背景清晰，长期被用于方法对比与性能评估；\n* 美国西部科迪勒拉（the southern Cordillera region）斑岩铜成矿带数据集：\n覆盖多个州，区域尺度大、构造与岩浆活动复杂，用于检验模型在大尺度、复杂地质环境下的稳定性与泛化能力。\n这两个数据集分别对应小尺度精细预测与大尺度区域推广。\n其中加拿大矿区数据集被作为模型初始评估与方法对比的基准测试区，用于验证模型在经典、小尺度金矿预测场景中的识别能力与召回表现；美国矿区数据集作为大尺度、复杂构造环境下的推广验证区，用于检验模型在斑岩铜系统中的跨区域稳定性与泛化能力。\n基于数据，\n该研究提出了一种各向异性卷积注意力加权逻辑回归模型（Anisotropic Convolutional Attention-Weighted Logistic Regression, ACAWLR），\n用于地质约束下的矿产远景预测。该方法首先通过方向加权的协方差分析提取矿点分布的主、次成矿方向，并在此基础上构建各向异性空间距离度量；随后引入各向异性空间邻近性神经网络（Anisotropic Spatial Proximity Neural Network, ASPNN），将方向性空间关系以可学习的方式嵌入模型中，从而显式刻画成矿过程中的方向依赖特征。\n在此基础上，进一步结合卷积神经网络与空间—通道注意力机制，构建卷积注意力加权网络，用以学习空间非平稳的控矿权重，并与逻辑回归模型耦合，实现对成矿概率的稳健预测。\n各向异性卷积注意力加权逻辑回归（ACAWLR）框架示意图\n多尺度验证策略与模型对比\n在实验设计上，研究团队采用多尺度、分层次的验证策略。\n首先在加拿大新斯科舍省梅古马地体这一经典金矿预测基准区开展系统对比实验，\n将所提出方法与地理加权逻辑回归、支持向量机、随机森林、多层感知机及图注意力网络等多种代表性方法进行比较。\n结果表明，\nACAWLR 在召回率和整体预测性能方面均表现最优，\n在预测精度、空间泛化能力与地质可解释性之间实现了有效平衡，能够完整识别已知矿点分布，并生成更连续、符合地质认知的远景预测图。\n随后，研究进一步将该方法推广至美国西部科迪勒拉斑岩铜成矿带这一大尺度复杂区域，验证了模型在跨区域应用中的稳定性与鲁棒性。\n成矿远景预测图：(A–F) 新斯科舍省梅古马地体金矿预测结果，分别由各向异性卷积注意力加权逻辑回归（ACAWLR）、地理加权逻辑回归（GWLR）、随机森林（RF）、支持向量机（SVM）、多层感知机（MLP）和图注意力网络（GAT）得到；(G) 基于 ACAWLR 的斑岩铜矿预测结果（美国西部）\n此外，该研究还开展了大尺度成矿可解释性分析，系统揭示了不同区域内关键控矿因素的空间差异性。结果表明，\n铜含量在斑岩铜系统中具有主导控制作用，而岩性、断裂和重力异常等因素在不同构造背景下呈现出显著不同的空间影响模式。\n通过各向异性分析，模型进一步识别出与区域构造体系一致的成矿主控方向，为理解成矿机理和指导找矿部署提供了直观依据。\n各特征对模型输出的相对贡献；(B–H) Cu、断裂、Au、Fe、Mo、岩性及重力异常在局部尺度上的空间影响分布\n空间各向异性特征\n(A) 基于矿点训练样本的特征值分解所得到的主、次成矿方向；\n(B) 各向异性空间邻近性神经网络（ASPNN）优化后的邻近性分布（红色表示较短，蓝色表示较长）。背景为中生代至现今的岩浆弧与构造带分布（据 Yonkee 和 Weil，2015）。加拿大：AB—阿尔伯塔省；MB—马尼托巴省；SK—萨斯喀彻温省。美国：AZ—亚利桑那州；CA—加利福尼亚州；CO—科罗拉多州；ID—爱达荷州；KS—堪萨斯州；MT—蒙大拿州；ND—北达科他州；NB—内布拉斯加州；NM—新墨西哥州；NV—内华达州；OR—俄勒冈州；SD—南达科他州；TX—得克萨斯州；UT—犹他州；WA—华盛顿州；WY—怀俄明州\n有关浙江大学地球科学学院团队\n近年来，浙江大学地球科学学院团队在地学与人工智能交叉领域取得了一系列具有前沿性和工程应用价值的科研成果。\n团队提出的 GNNWR 系列模型被行业人才使用，模型的下载量、调用数和引用累计近 5 万次\n，并在海洋学、地理学、大气科学和地质学等多个方向得到了广泛应用。该项工作成果已在地球科学领域知名期刊 Geoscientific Model Development 上发表，论文题目为「GNNWR: An Open-Source Package of Spatiotemporal Intelligent Regression Methods for Modeling Spatial and Temporal Non-Stationarity」。\n论文地址：\nhttps://gmd.copernicus.org/articles/17/8455/2024/\n模型开源地址：\nhttps://github.com/zjuwss/gnnwr\n2025 年 2 月，\n该团队提出了一种基于注意力机制的深度学习模型——情景注意力驱动的地理加权回归（CatGWR），\n通过注意力机制计算样本间的情景相似性，并将其与空间邻近性相结合，生成情景化的时空权重，从而更准确地估计空间非平稳性。相关成果以「Using an attention-based architecture to incorporate context similarity into spatial non-stationarity estimation」为题，发表在 International Journal of Geographical Information Science。\n论文地址：\nhttps://www.tandfonline.com/doi/full/10.1080/13658816.2025.2456556\n点击查看完整解读：\n以1.7K深圳小区房价为例，浙大GIS实验室使用注意力机制挖掘地理情景特征，提升空间非平稳回归精度\n同年 11 月，\n该团队还提出了一种异构对比图融合网络（HCGFN），用于 HSI 和 LiDAR 数据的联合分类，实现了 HSI 和 LiDAR 之间的高效交互和有效融合。\n该项工作成果已在地球科学领域知名期刊 IEEE Transactions on Geoscience and Remote Sensing 上发表，论文题目为「Aggregative and Contrastive Dual-View Graph Attention Network for Hyperspectral Image Classification」。\n论文地址：\nhttps://ieeexplore.ieee.org/document/11115095\n团队还将空间智能模型应用于社会经济地理问题，通过引入空间邻近性和深度学习结构，取得比传统模型显著更好的拟合效果。以「Spatial non-stationarity assessments of housing prices in Wuhan based on a TD-GNNWR model」为题发表在地理学报的论文中，\n团队建立了一种基于出行时间（TD）的空间距离度量与神经网络融合模型（TD-GNNWR），显著提高城市房价空间非平稳性的拟合与解释性。\n论文地址：\nhttps://www.geog.com.cn/CN/10.11821/dlxb202408005\n此外，研究团队还将时空智能回归与深度学习方法推广到地质、海洋、生态与大气环境模型构建中，\n如利用空间加权神经网络高精度估算青藏高原的地表热流分布，为地球内部地球动力学过程提供关键见解。\n相关研究以「The Distribution of Surface Heat Flow on the Tibetan Plateau Revealed by Data‐Driven Methods」为题，发表在 Journal of Geophysical Research: Solid Earth。\n论文地址：\nhttps://doi.org/10.1029/2023JB028491\n一键获取 2023—2024 年 AI4S 领域高质量论文及深度解读文章 ⬇️\n往期推荐\n戳\n“阅读原文”\n，免费获取海量数据集资源！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU3NTQ2NDIyOQ==&mid=2247525942&idx=1&sn=8de4c393fe3c03c6286305c6e47fbc98&chksm=fc064840bf191a6aa517b69a61012469aac7ff68fa04a2d42ccc8f66edba45f873b61e5219bb&scene=0&xtrack=1#rd",
      "publish_time": 1767165000,
      "publish_date": "2025-12-31 15:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://go.hyper.ai/vbUpa\", \"https://hyper.ai/papers\", \"https://gmd.copernicus.org/articles/17/8455/2024/\", \"https://github.com/zjuwss/gnnwr\", \"https://www.tandfonline.com/doi/full/10.1080/13658816.2025.2456556\", \"https://ieeexplore.ieee.org/document/11115095\", \"https://www.geog.com.cn/CN/10.11821/dlxb202408005\", \"https://doi.org/10.1029/2023JB028491\"]",
      "add_ts": 1767193337,
      "last_modify_ts": 1767309671
    },
    {
      "id": 103,
      "article_id": "51540",
      "title": "Qwen负责人转发2025宝藏论文，年底重读「视觉领域GPT时刻」",
      "description": "谷歌DeepMind论文《Video models are zero-shot learners and reasoners》入选ICCV 2025，提出视频模型“思维链”CoF，展现其零样本学习与推理能力。该研究获阿里最年轻P10林俊旸转发关注，成为2025年度备受瞩目的学术成果之一，揭示视频模型在无训练情况下自主理解与推导的潜力，推动视觉AI向通用智能迈进。",
      "content": "闻乐 发自 凹非寺\n量子位 | 公众号 QbitAI\n2025最后几天，是时候来看点年度宝藏论文了。\n比如，阿里最年轻P10、Qwen大模型技术负责人\n林俊旸\n最新转发了一篇名为《Video models are zero-shot learners and reasoners》的研究。\n没错，就是谷歌DeepMind提出视频模型“思维链”\nCoF\n的那篇入选ICCV 2025的论文。\n当时，这篇研究还给出了一个关键信号：视觉领域的“GPT时刻”要来了。\n该研究用1.8万组实验数据证明，视频模型正在跳出\n任务专属\n的局限，走上LLM的老路——\n用一个模型，通过提示，完成几乎所有的视觉任务\n。\n并且，推理过程还能被CoF“演”出来。\n从NLP到CV\n自然语言处理领域的GPT时刻，核心是实现了\n一个模型通吃所有\n。\n在此之前，翻译、写作、问答等任务都各自有专属的模型，而LLM的出现，靠大规模数据训练和生成式架构，让\n零样本学习\n成为可能，模型通过文字提示就能完成各种各样的任务。\n但计算机视觉领域却还一直深陷于这种碎片化的困境。\n比如，要做目标检测得用YOLO，做语义分割依赖SAM，图像超分要找专门模型，3D重建还得换另一套工具。\n这些针对不同任务的模型架构差异很大，不仅开发成本高，还严重限制了视觉AI的泛化能力，导致视觉AI的进步一直是单点突破。\n比如这个模型在分割任务上刷新SOTA，另一个模型在检测任务上实现提速，却始终没能解决“多任务统一”的问题。\n而这篇论文详解了谷歌DeepMind借鉴LLM的成功路径，让Veo 3成为了一个“视觉通才”。\n通过大规模视频与文本数据的生成式训练，打通了视觉感知与语言理解的壁垒，让\n模型具备了跨任务的通用能力\n。\n而且Veo 3完美复刻了LLM的\n零样本优势\n，面对没专门训练过的任务，只要用文字说清需求，模型就能直接输出结果，无需额外调参或数据微调。\n这也正是说视觉GPT时刻到来的核心标志。\n从生成视频到用视频思考\n就像林俊旸提到的那样，这篇论文指出视频模型一个非常关键的变化在于——视频不再只是输出的形式，也开始体现推理的过程。\n模型在生成视频的过程中，会逐步展开中间状态，这就让推理不再是完全不可见的黑箱。\n论文中将这种现象称为\nChain-of-Frames\n，也就是CoF，类似于语言模型中的CoT，只不过视频模型是通过连续生成的视频帧，把整个推理过程“演”出来。\n模型在时间和空间中不断调整画面，用可见的变化替代抽象的符号推理。\n因此，无论是解迷宫、做路径规划，还是进行规则外推，模型都不是一次性输出结果，而是在连续的视觉变化中逐步逼近正确解。\n推理过程则被隐含地编码在视频序列之中，视频模型开始\n在过程中思考\n。\n也\n正是这种“逐帧生成即推理”的方式，为通用性提供了基础。\n因为模型不再围绕某一个具体任务去算结果，转而在统一的生成过程中，不断更新对场景状态的理解。\n不同任务之间的差异，不再体现在模型结构或输出形式上，而是被压缩成了“生成过程中关注什么、如何继续生成”的差别。\n这种框架下，分割、检测、编辑、路径规划等原本割裂的视觉任务，可以被统一到同一套生成机制中。模型始终做的只有一件事：\n生成下一帧视频\n。\n在逐帧生成过程中，它自然完成了感知、推理与决策的协同，这就不再需要为每类任务单独设计模型或系统。\n论文进一步观察到，在无需针对具体任务进行专门训练、也不引入额外监督的前提下，视频模型已经能够通过不同形式的提示，在多类视觉任务中展现出一定的零样本泛化能力。\n也正因为如此，Veo 3用感知、建模、操控、推理4大核心能力能搞定62种没学过的视觉任务。\n现在经过a16z投资合伙人Justine Moore和林俊旸一提醒，回看这篇论文发现，视频模型在视觉领域的的突破，还真有点当年LLM颠覆NLP的味儿了……\n论文地址：https://arxiv.org/abs/2509.20328\n参考链接：https://x.com/venturetwins/status/2005330176977293743\n—\n欢迎AI产品从业者共建\n—\n📚\n「AI产品知识库」\n是量子位智库基于长期产品库追踪和用户行为数据推出的飞书知识库，旨在成为AI行业从业者、投资者、研究者的核心信息枢纽与决策支持平台。\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859187&idx=2&sn=2ef10114d1724e95e62729cd2ba6187f&chksm=e99cacbdee5ba81b1f4ad86ecb1720c267a0fa83f11653ba334e9d48ff20553395925ace1538&scene=0&xtrack=1#rd",
      "publish_time": 1767163200,
      "publish_date": "2025-12-31 14:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2509.20328\", \"https://x.com/venturetwins/status/2005330176977293743\"]",
      "add_ts": 1767193350,
      "last_modify_ts": 1767309688
    },
    {
      "id": 104,
      "article_id": "51537",
      "title": "【TVM教程】设计与架构",
      "description": "TVM 已更新至 0.21.0 版本，中文文档同步更新。Apache TVM 是支持 CPU、GPU 及多种 AI 芯片的深度学习编译框架。本文档面向开发者，介绍其架构与开发流程，涵盖从模型导入到运行的完整编译链路：前端将模型转为 IRModule，经通用与目标相关转换后生成可执行模块，最终在 runtime 中加载执行。核心数据结构 IRModule 包含函数集合，支持 relay::Funct...",
      "content": "TVM 现已更新到 0.21.0 版本，\nTVM 中文文档\n已经和新版本对齐。\nApache TVM 是一个深度的深度学习编译框架，适用于 CPU、GPU 和各种机器学习加速芯片。更多 TVM 中文文档可访问 →\nApache TVM\n本文档适用于想要了解 TVM 架构或积极开发项目的开发者。本文档组织结构如下：\n整体编译流程示例\n：概述 TVM 如何将一个高级模型描述转换为可部署模块的各个步骤。建议首先阅读本节以了解基础流程。\n简要介绍 TVM 栈中的关键组件。您也可以参考\nTensorIR 深度解析\n和\nRelax 深度解析\n，了解 TVM 栈中两个核心部分的详细内容。\n本指南提供了架构的一些补充视图。首先研究端到端的编译流程，并讨论关键的数据结构和转换。这种基于 runtime 的视图侧重于运行编译器时每个组件的交互，接下来我们将研究代码库的逻辑模块及其关系。本部分将提供该设计的静态总体视图。\n编译流程示例\n​\n本指南研究编译器中的编译流程示例，下图展示了流程。从高层次来看，它包含以下步骤：\n导入：\n前端组件将模型引入到\nIRModule\n中，它包含了内部表示模型的函数集合。\n转换：\n编译器将 IRModule 转换为功能与之等效或近似等效（例如在量化的情况下）的 IRModule。许多转换与 target（后端）无关，并且允许 target 配置转换 pipeline。\nTarget 转换：\n编译器将 IRModule 转换（codegen）为指定 target 的可执行格式。target 的转换结果被封装为 runtime.Module，可以在 runtime 环境中导出、加载和执行。\nRuntime 执行：\n用户加载 runtime.Module，并在支持的 runtime 环境中运行编译好的函数。\n关键数据结构\n​\n设计和理解复杂系统的最佳方法之一，就是识别关键数据结构和操作（转换）这些数据结构的 API。识别了关键数据结构后，就可以将系统分解为逻辑组件，这些逻辑组件定义了关键数据结构的集合，或是数据结构之间的转换。\nIRModule\n是整个堆栈中使用的主要数据结构。一个 IRModule（intermediate representation module）包含一组函数。目前支持两种主要的功能变体（variant）：\nrelay::Function\n是一种高层功能程序表示。一个 relay.Function 通常对应一个端到端的模型。可将 relay.Function 视为额外支持控制流、递归和复杂数据结构的计算图。\ntir::PrimFunc\n是一种底层程序表示，包含循环嵌套选择、多维加载/存储、线程和向量/张量指令的元素。通常用于表示算子程序，这个程序在模型中执行一个（可融合的）层。 在编译期间，Relay 函数可降级为多个 tir::PrimFunc 函数和一个调用这些 tir::PrimFunc 函数的顶层函数。\n在编译和转换过程中，所有的 Relax 运算符都会被下沉（lower）为\ntir::PrimFunc\n或\nTVM PackedFunc\n，这些函数可以直接在目标设备上执行。而对 Relax 运算符的调用，则会被下沉为对低层函数的调用（例如\nR.call_tir\n或\nR.call_dps\n）。\n转换\n​\n前面介绍了关键数据结构，接下来讲转换。转换的目的有：\n优化：将程序转换为等效，甚至更优的版本。\n降级：将程序转换为更接近 target 的较低级别表示。 relay/transform 包含一组优化模型的 pass。优化包括常见的程序优化（例如常量折叠和死码消除），以及特定于张量计算的 pass（例如布局转换和 scale 因子折叠）。\nRelax 转换\n​\nRelax 转换包括一系列应用于 Relax 函数的 Pass。优化内容包括常见的图级优化（如常量折叠、无用代码消除等），以及后端特定的优化（例如库调度）。\ntir 转换\n​\ntir 转换包含一组应用于 tir 函数的 pass，主要包括两类：\nTensorIR 调度\n（TensorIR schedule）：\nTensorIR 调度旨在为特定目标优化 TensorIR 函数，通常由用户指导控制目标代码的生成。对于 CPU 目标，TIR PrimFunc 即使没有调度也可以生成有效代码并在目标设备上运行，但性能较低。对于 GPU 目标，调度是生成有效线程绑定代码的关键。详情请参考\nTensorIR 转换教程\n。此外，TVM 提供了\nMetaSchedule\n来自动搜索最优的 TensorIR 调度。\n降层 Pass（Lowering Passes）：\n这些 Pass 通常在应用调度后执行，将 TIR PrimFunc 转换为功能等价但更贴近目标表示的版本。例如，有些 Pass 会将多维访问扁平化为一维指针访问，或者将中间表示中的 intrinsic 扩展为目标特定的形式，并对函数入口进行修饰以符合运行时调用约定。\n许多底层优化可以在目标阶段由 LLVM、CUDA C 以及其他目标编译器处理。因此，我们将寄存器分配等底层优化留给下游编译器处理，仅专注于那些它们未涵盖的优化。\n跨层转换（Cross-level transformations）\n​\nApache TVM 提供统一的策略来优化端到端模型。由于 IRModule 同时包含 Relax 和 TIR 函数，跨层转换的目标是在这两类函数之间应用变换来修改 IRModule。\n例如，\nrelax.LegalizeOps\nPass 会通过将 Relax 算子降层为 TIR PrimFunc 并添加至 IRModule 中，同时将原有的 Relax 算子替换为对该 TIR 函数的调用，从而改变 IRModule。另一个例子是 Relax 中的算子融合流程（包括\nrelax.FuseOps\n和\nrelax.FuseTIR\n），它将多个连续的张量操作融合为一个操作。与以往手动定义融合规则的方法不同，Relax 的融合流程会分析 TIR 函数的模式，自动检测出最佳融合策略。\n目标转换（Target Translation）\n​\n目标转换阶段将 IRModule 转换为目标平台的可执行格式。对于 x86 和 ARM 等后端，TVM 使用 LLVM IRBuilder 构建内存中的 LLVM IR。也可以生成源码级别的语言，如 CUDA C 和 OpenCL。此外，TVM 支持通过外部代码生成器将 Relax 函数（子图）直接翻译为目标代码。\n目标代码生成阶段应尽可能轻量，大多数转换和降层操作应在此阶段之前完成。\nTVM 还提供了 Target 结构体用于指定编译目标。目标信息也可能影响前期转换操作，例如目标的向量长度会影响向量化行为。\nRuntime 执行\n​\nTVM runtime 的主要目标是提供一个最小的 API，从而能以选择的语言（包括 Python、C++、Rust、Go、Java 和 JavaScript）加载和执行编译好的工件。以下代码片段展示了一个 Python 示例：\nimport tvm\n# Python 中 runtime 执行程序示例，带有类型注释\nmod: tvm.runtime.Module = tvm.runtime.load_module(\"compiled_artifact.so\")\narr: tvm.runtime.Tensor = tvm.runtime.tensor([1, 2, 3], device=tvm.cuda(0))\nfun: tvm.runtime.PackedFunc = mod[\"addone\"]\nfun(arr)\nprint(arr.numpy())\ntvm.runtime.Module\n封装了编译的结果。runtime.Module 包含一个 GetFunction 方法，用于按名称获取 PackedFuncs。\ntvm.runtime.PackedFunc\n是一种为各种构造函数消解类型的函数接口。runtime.PackedFunc 的参数和返回值的类型如下：POD 类型（int, float）、string、runtime.PackedFunc、runtime.Module、runtime.Tensor 和 runtime.Object 的其他子类。\ntvm.runtime.Module\n和\ntvm.runtime.PackedFunc\n是模块化 runtime 的强大机制。例如，要在 CUDA 上获取上述\naddone\n函数，可以用 LLVM 生成主机端代码来计算启动参数（例如线程组的大小），然后用 CUDA 驱动程序 API 支持的 CUDAModule 调用另一个 PackedFunc。OpenCL 内核也有相同的机制。\n以上示例只处理了一个简单的 addone 函数。下面的代码片段给出了用相同接口执行端到端模型的示例：\nimport tvm\n# python 中 runtime 执行程序的示例，带有类型注释\nfactory: tvm.runtime.Module = tvm.runtime.load_module(\"resnet18.so\")\n# 在 cuda(0) 上为 resnet18 创建一个有状态的图执行模块\ngmod: tvm.runtime.Module = factory[\"resnet18\"](tvm.cuda(0))\ndata: tvm.runtime.Tensor = get_input_data()\n# 设置输入\ngmod[\"set_input\"](0, data)\n# 执行模型\ngmod[\"run\"]()\n# 得到输出\nresult = gmod[\"get_output\"](0).numpy()\n主要的结论是 runtime.Module 和 runtime.PackedFunc 可以封装算子级别的程序（例如 addone），以及端到端模型。\n总结与讨论\n​\n综上所述，编译流程中的关键数据结构有：\nIRModule：包含 relay.Function 和 tir.PrimFunc\nruntime.Module：包含 runtime.PackedFunc\n编译基本是在进行关键数据结构之间的转换。\nrelay/transform 和 tir/transform 是确定性的基于规则的转换\nmeta-schedule 则包含基于搜索的转换\n最后，编译流程示例只是 TVM 堆栈的一个典型用例。将这些关键数据结构和转换提供给 Python 和 C++ API。然后，就可以像使用 numpy 一样使用 TVM，只不过关注的数据结构从 numpy.ndarray 改为 tvm.IRModule。以下是一些用例的示例：\n用 Python API 直接构建 IRModule。\n编写一组自定义转换（例如自定义量化）。\n用 TVM 的 Python API 直接操作 IR。\ntvm/support\n​\nsupport 模块包含基础架构最常用的程序，例如通用 arena 分配器（arena allocator）、套接字（socket）和日志（logging）。\ntvm/runtime\n​\nruntime\n是 TVM 技术栈的基础。它提供加载和执行已编译产物的机制。运行时定义了一套稳定的 C API 标准接口，用于与前端语言（如 Python 和 Rust）交互。\n除了 ffi::Function， runtime::Object 是 TVM 运行时的核心数据结构之一。它是一个带有类型索引的引用计数基类，支持运行时类型检查和向下转型。该对象系统允许开发者向运行时引入新的数据结构，例如 Array、Map 以及新的 IR 数据结构。\n除了用于部署场景，TVM 编译器本身也大量依赖运行时机制。所有 IR 数据结构都是 runtime::Object 的子类，因此可以直接从 Python 前端访问和操作。我们使用 PackedFunc 机制将各种 API 暴露给前端使用。\n不同硬件后端的运行时支持定义在 runtime 子目录中（例如 runtime/opencl）。这些特定于硬件的运行时模块定义了设备内存分配和设备函数序列化的 API。\nruntime/rpc 实现了对 PackedFunc 的 RPC 支持。我们可以利用 RPC 机制将交叉编译后的库发送到远程设备，并基准测试其执行性能。该 RPC 基础设施使得能够从多种硬件后端收集数据，用于基于学习的优化。\nTVM 运行时系统\n运行时信息\n模块序列化指南\n设备/目标交互\ntvm/node\n​\nnode 模块在 runtime::Object 的基础上为 IR 数据结构增加了更多功能。其主要功能包括：反射、序列化、结构等价性检查以及哈希计算。\n得益于 node 模块，我们可以在 Python 中通过字段名直接访问 TVM IR 节点的任意字段：\nx = tvm.tir.Var(\"x\", \"int32\")\ny = tvm.tir.Add(x, x)\n# a 和 b 是 tir.Add 节点的字段\n# 可以通过字段名直接访问\nassert y.a == x\n我们还可以将任意 IR 节点序列化为 JSON 格式，并加载回来。这种保存/加载和查看 IR 节点的能力为提高编译器的可用性打下了基础。\ntvm/ir\n​\ntvm/ir 文件夹包含所有 IR 函数变体所共享的统一数据结构与接口。该模块中的组件被 tvm/relax 和 tvm/tir 共享，主要包括：\nIRModule\n类型\nPassContext 和 Pass\nOp\n不同的函数变体（如 relax.Function 和 tir.PrimFunc）可以共存于一个 IRModule 中。尽管这些变体的内容表示不同，但它们使用相同的数据结构来表示类型。因此，不同函数变体之间可以共享函数签名的表示结构。统一的类型系统使得在定义好调用约定的前提下，一个函数变体可以调用另一个，从而为跨函数变体的优化奠定了基础。\n此外，我们还提供了统一的 PassContext 用于配置 Pass 行为，并提供组合 Pass 的方式构建优化流程。如下示例：\n# 配置 tir.UnrollLoop pass 的行为\nwith tvm.transform.PassContext(config={\"tir.UnrollLoop\": { \"auto_max_step\": 10 }}):\n    # 在该上下文下执行的代码\nOp 是用于表示系统内置的原始操作符/内建指令的通用类。开发者可以向系统注册新的 Op，并附加属性（例如该操作是否是逐元素操作）。\nPass 基础设施\ntvm/target\n​\ntarget 模块包含将 IRModule 转换为目标运行时代码的所有代码生成器，同时也提供了一个通用的 Target 类用于描述目标平台。\n编译流程可以根据目标平台的属性信息和每个目标 id（如 cuda、opencl）所注册的内建信息来自定义。\n设备/目标交互\ntvm/relax\n​\nRelax 是用于表示模型计算图的高级 IR。多种优化过程定义在\nrelax.transform\n中。需要注意的是，Relax 通常与 TensorIR 的 IRModule 协同工作，许多转换会同时作用于 Relax 和 TensorIR 函数。更多信息可参考：\nRelax 深度解析\n。\ntvm/tir\n​\nTIR 定义了低级程序表示。我们使用 tir::PrimFunc 来表示可以由 TIR Pass 转换的函数。除了 IR 数据结构，TIR 模块还包括：\n位于\ntir/schedule\n中的一组调度原语\n位于\ntir/tensor_intrin\n中的内置指令\n位于\ntir/analysis\n中的分析 Pass\n位于\ntir/transform\n中的转换/优化 Pass\n更多信息请参考：\nTensorIR 深度解析\n。\ntvm/arith\n​\n该模块与 TIR 紧密相关。低级代码生成中的一个核心问题是对索引的算术属性进行分析——如是否为正数、变量界限、描述迭代器空间的整数集合等。arith 模块提供了一套主要用于整数分析的工具，TIR Pass 可以利用这些工具简化和优化代码。\ntvm/te 和 tvm/topi\n​\nTE（Tensor Expression）是用于描述张量计算的领域专用语言（DSL）。需要注意的是，Tensor Expression 本身并不是可以直接存储进 IRModule 的自包含函数。我们可以使用\nte.create_prim_func\n将其转换为\ntir::PrimFunc\n，然后集成进 IRModule。\n尽管可以使用 TIR 或 TE 为每个场景直接构造算子，但这种方式较为繁琐。为此，topi（Tensor Operator Inventory）提供了一组预定义算子，覆盖了 numpy 操作和深度学习常见操作。\ntvm/meta_schedule\n​\nMetaSchedule 是一个用于自动搜索优化程序调度的系统。它是 AutoTVM 和 AutoScheduler 的替代方案，可用于优化 TensorIR 调度。需要注意的是，MetaSchedule 目前仅支持静态形状工作负载。\ntvm/dlight\n​\nDLight 提供一套预定义、易用且高性能的 TIR 调度策略。其目标包括：\n全面支持动态形状工作负载\n轻量级：提供无需调优或仅需极少调优的调度策略，且性能合理\n稳定性强：DLight 的调度策略具有通用性，即使当前规则不适用也不会报错，而是自动切换至下一个规则\n内容中包含的图片若涉及版权问题，请及时与我们联系删除",
      "article_url": "https://hub.baai.ac.cn/view/51537",
      "publish_time": 1767160140,
      "publish_date": "2025-12-31 13:49",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://zhida.zhihu.com/search/3705836406608869133\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture%23%25E7%25BC%2596%25E8%25AF%2591%25E6%25B5%2581%25E7%25A8%258B%25E7%25A4%25BA%25E4%25BE%258B\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/tensorir/\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/relax/\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23%25E7%25BC%2596%25E8%25AF%2591%25E6%25B5%2581%25E7%25A8%258B%25E7%25A4%25BA%25E4%25BE%258B\", \"https://zhida.zhihu.com/search?content_id=268335125&content_type=Article&match_order=1&q=IRModule&zhida_source=entity\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23%25E5%2585%25B3%25E9%2594%25AE%25E6%2595%25B0%25E6%258D%25AE%25E7%25BB%2593%25E6%259E%2584\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23%25E8%25BD%25AC%25E6%258D%25A2\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23relax-%25E8%25BD%25AC%25E6%258D%25A2\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23tir-%25E8%25BD%25AC%25E6%258D%25A2\", \"https://zhida.zhihu.com/search?content_id=268335125&content_type=Article&match_order=1&q=TensorIR+%E8%B0%83%E5%BA%A6&zhida_source=entity\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/tensorir/tir_transformation\", \"https://zhida.zhihu.com/search?content_id=268335125&content_type=Article&match_order=1&q=MetaSchedule&zhida_source=entity\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23%25E8%25B7%25A8%25E5%25B1%2582%25E8%25BD%25AC%25E6%258D%25A2cross-level-transformations\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23%25E7%259B%25AE%25E6%25A0%2587%25E8%25BD%25AC%25E6%258D%25A2target-translation\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23runtime-%25E6%2589%25A7%25E8%25A1%258C\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#%E6%80%BB%E7%BB%93%E4%B8%8E%E8%AE%A8%E8%AE%BA\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmsupport\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmruntime\", \"https://tvm.apache.org/docs/arch/runtime.html\", \"https://tvm.apache.org/docs/arch/runtime.html#runtime-specific-information\", \"https://tvm.apache.org/docs/arch/introduction_to_module_serialization.html\", \"https://tvm.apache.org/docs/arch/device_target_interactions.html\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmnode\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmir\", \"https://tvm.apache.org/docs/arch/pass_infra.html\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmtarget\", \"https://tvm.apache.org/docs/arch/device_target_interactions.html\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmrelax\", \"https://tvm.hyper.ai/docs/deep-dive/relax/\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmtir\", \"https://tvm.hyper.ai/docs/deep-dive/tensorir/\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmarith\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmte-%E5%92%8C-tvmtopi\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmmeta_schedule\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmdlight\"]",
      "add_ts": 1767193353,
      "last_modify_ts": 1767309691
    },
    {
      "id": 108,
      "article_id": "51533",
      "title": "AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品",
      "description": "蚂蚁健康与北大人民医院王俊院士团队联合发布全球首个大模型专病循证评测框架GAPS及配套评测集GAPS-NSCLC-preview，历时六个多月，汇聚十余位胸外科专家。该框架聚焦非小细胞肺癌领域，从证据根基、内容充分性、扰动鲁棒性与安全性四维度评估AI临床能力，突破传统考试式评测局限，推动医疗AI向深度临床应用发展。",
      "content": "允中 发自 凹非寺\n量子位 | 公众号 QbitAI\n蚂蚁健康\n与北京大学人民医院\n王俊\n院士团队历时6个多月，联合十余位胸外科医生共同打磨，发布了\n全球首个大模型专病循证能力的评测框架\n——\nGAPS\n（Grounding, Adequacy, Perturbation, Safety）\n，及其配套评测集 GAPS-NSCLC-preview。\n旨在解决现有医疗AI评测局限于考试式问答、缺乏临床深度、完整性、鲁棒性与安全性综合评估的问题。\n该评测集聚焦\n肺癌\n领域，包含\n92个问题\n、覆盖\n1691个临床要点\n，并配套全自动化的评测工具链，通过指南锚定、多智能体协同实现从问题生成、评分标准制定到多维度打分的端到端自动化。\n目前，相关成果已应用于“蚂蚁阿福”，论文《GAPS: A Clinically Grounded, Automated Benchmark for Evaluating AI Clinicians》、配套评测集GAPS-NSCLC-preview、自动化评测框架已全面公开。\n这项研究客观评价了大模型的临床能力：当前主流医疗大模型虽已具备“医学百科全书”般的知识广度，但在临床实践中仍处于成长阶段——\n它们在系统掌握医学知识方面表现卓越，但在应对真实临床场景中的不确定性挑战时，尚需进一步提升判断力与可靠性。\n权威引领：北大人民医院院士团队深度主导临床标准构建\n本项目由中国工程院院士、北京大学人民医院院长王俊教授领衔的团队全程主导，并与蚂蚁团队深度协作完成。\n在GAPS构建过程中，院士团队原创性地提出了\nGAPS评测的理论框架\n，并组织十余位胸外科医生持续参与评测题库构建、临床金标准答案撰写、模型输出的专业审核与迭代优化，提供NSCLC\n（非小细胞肺癌）\n领域前沿临床指南的权威解读与循证医学方法论指导，确保每一项指标都扎根真实临床实践，具备高度专业性与可信度。\n蚂蚁团队则发挥大模型与工程化能力优势，经过多轮高强度医工协同与反复迭代，将专家脑海中的复杂“临床金标准”精准沉淀为大模型可理解、可执行的结构化逻辑，实现GAPS的规模化、自动化与可落地应用。\n此次合作实现了“临床专家定标准、AI 技术做转化”的深度融合，突破了传统医疗AI评测中专家浅层参与的局限，标志着顶尖临床专家与AI技术团队的深度协作，为医疗AI从“技术驱动”走向“临床价值驱动”树立了新的范式。\n行业痛点：考得好，信不过\n在和大模型讨论医疗问题时，有时候回答得很好，有时候回答得很差，由于大模型的变化日新月异，医生和患者都没有办法在短时间对大模型产生客观评价，因此对大模型的信任就无从谈起。\n为了客观评价大模型的能力，学界通常采用基准测试的方法。\n然而，当前医疗AI的基准测试普遍缺乏对模型\n循证能力、可解释性与安全性\n的系统评估。\n长期以来，医疗AI的评估依赖MedQA、PubMedQA等“试卷型”基准，仅考察事实记忆能力；而HealthBench等基于人工评分细则\n（Rubric）\n的方法又受限于主观性强、扩展性差。\n这些方法无法反映真实诊疗场景：患者描述模糊、检查结果矛盾、治疗方案需权衡利弊……正如论文所强调：\n真正的医疗能力不在于背诵事实，而在于管理不确定性。\n尤其在肺癌这一全球致死率最高的癌症领域，缺乏细粒度、专病化的评估工具，使得医疗机构和开发者难以客观判断医疗AI是否真正具备临床可用性。\nGAPS的诞生，正是为了填补这一关键空白。\n破局之道：GAPS——从“考试机器”到“临床医生”的四维标尺\nGAPS是一个\n基于循证医学、全自动构建的AI临床能力评测框架\n，首次将临床胜任力解构为四个正交维度，并聚焦NSCLC\n（非小细胞肺癌）\n这一高难度专病场景进行系统验证：\n1、G（Grounding）认知深度\n：不止于“是什么”，更考验“为什么”和“怎么办”。\nG1和G2：事实回忆与解释\n（AI的舒适区）\nG3：基于指南的循证决策\n（如NCCN推荐方案）\nG4：推理性思维\n（Inferential Reasoning）\n——在证据冲突或缺失的“灰色地带”做出合理判断，这是当前所有模型的“死亡区”。\n2、A（Adequacy）回答完备性\n：医生的一句话可能关乎生死。GAPS引入三级评价：\nA1\n（必须有）\n：核心诊疗建议\nA2\n（应该有）\n：关键限定条件\n（如剂量、禁忌症、监测指标）\nA3\n（锦上添花）\n：患者教育、多学科协作建议等\n缺少A2，再“正确”的建议也可能导致临床误用。\n3、P（Perturbation）鲁棒性\n：真实患者不会照着教科书说话。GAPS通过三类扰动测试模型抗干扰能力：\nP1：语言噪音\n（口误、方言）\nP2：冗余信息\n（无关症状堆砌）\nP3：对抗性前提\n（如诱导性错误假设）\n实验显示，多数模型极易被误导，甚至顺从用户的错误引导。\n4、S（Safety）安全底线\n：医疗容不得“差不多”。GAPS 建立四级风险体系：\nS1\n（无关回答）\n→ S4\n（灾难性错误/Never Events，如推荐禁忌药物）\n一旦触犯S4，无论其他维度得分多高，总分直接归零——这是不可逾越的红线。\nGAPS解决了现有医疗AI评测仅关注“准确率”的局限，首次实现对\n循证决策能力、回答完备性、现实鲁棒性与安全底线\n的系统性、自动化评估。\n其优势在于：以临床指南为锚点，全自动构建高保真评测项与评分规则，兼具可扩展性、可复现性与临床真实性，为AI向可信临床伙伴演进提供精准导航。\n核心黑科技：全自动化的“循证评测集”流水线\nGAPS最大的技术亮点在于其\n端到端自动化与可扩展性\n。\n不同于以往依赖人工命题，GAPS构建了一套基于\n临床指南（Guidelines）\n的自动化生成工厂：\n证据邻域构建\n：以NCCN、ESMO等权威指南为核心，自动抓取3跳内引用文献，构建高可信医学知识图谱与疾病话题树；\nDeep Research Agent\n：基于\nGRADE\n方法学，模拟人类专家围绕PICO\n（人群、干预、对照、结果）\n展开的证据检索、证据评估、强弱推荐的流程，自动生成带证据等级与推荐强度的高质量评分细则；\n虚拟患者生成\n：利用大模型合成去隐私化临床病例，并精准对齐知识图谱，确保每道题“有据可依、有理可循”。\n该流水线已成功应用于胸外科的专病——\nNSCLC（非小细胞肺癌）\n，生成包含92道题、1691个临床要点的评测集\nGAPS-NSCLC-preview\n。\n题目按认知深度分为G1~G4四级\n（从事实回忆到不确定性下的推理）\n，每题均配备平均12项完整性\n（A1~A3）\n与7项安全性\n（S1~S4）\n评分要点，并支持P0~P3四级扰动测试。\n未来可快速扩展至\n心血管、儿科、内分泌\n等任意专科的专病领域——只要有指南，就能生成高质量评测集。\n可靠的裁判：自动化评测让AI医疗能力可量化、可复现、可进化\nGAPS评测集同时搭配了一套高可靠性的自动化评测框架，实现了对AI临床能力的客观、细粒度、端到端的自动化评估。\n为确保评测本身可信，团队将自动化评分结果与五位资深专家的独立标注进行严格比对：\n在92个真实临床查询、1691个临床要点上，该框架与专家共识的整体一致率达90.00%，Cohen’s Kappa系数达0.77\n（“实质性一致”）\n，Macro-F1达0.88——不仅显著优于现有基准\n（如HealthBench中GPT-4的0.79）\n，已达到人类专家间一致性水平\n（88.5%~92.0%）\n。\n这证明GAPS评测集的自动评判能力具备专家级可靠性。\n在此基础上，评测不再是终点，而是进化的起点。\n框架输出的结构化评分\n（G/A/P/S四维、MET/NOT-MET标记）\n可精准定位模型在循证决策、回答完备性、扰动鲁棒性或安全红线上的缺陷；\n由此，\nGAPS具备成为“评测即反馈、反馈即迭代”的最重要基石\n——\nA\nI医疗能力不再依赖模糊经验，而是通过可量化的指标、可复现的流程、可积累的进化路径，稳步向临床可用迈进。\n实战揭秘：顶尖大模型的“滑铁卢”\n研究团队使用GAPS对GPT-5、Gemini 2.5 Pro、Claude Opus 4、Qwen3-235B-A22B-Instruct-2507、DeepSeek-V3.1-Terminus等主流模型进行“体检”，结果发人深省：\n1、“百科全书”易做，“专家”难当：\n所有模型在G1\n（事实）\n和G2\n（解释）\n阶段表现优异\n（GPT-5得分约0.72）\n。但一旦进入G3\n（确定性决策）\n和G4\n（非确定性推理）\n，分数呈断崖式下跌，GPT-5在G4阶段跌至0.45，其他模型甚至跌破0.35。这说明 AI目前还只是“背书机器”，而非“推理伙伴”。\n2、不仅要“对”，还要“全”：\n在Adequacy\n（完备性）\n测试中，模型往往只给出核心建议\n（A1）\n，却忽略了关键的限定条件\n（A2）\n，导致临床建议缺乏可操作性。\n3、极其脆弱的耳根子：\n在P3\n（对抗性测试）\n中，只要在提问中加入一点误导性前提\n（例如暗示某种错误疗法有效）\n，模型的判断力就会崩塌，甚至顺从用户的错误引导。\n4、安全隐患：\n虽然GPT-5和Gemini 2.5在极高风险错误\n（S4）\n上控制较好，但在复杂的推理场景下，部分模型\n（如Claude Opus 4）\n的致命错误率随难度显著上升。\n结语：GAPS评测框架是AI医生从“Chatbot”到“Doctor”的必经之路\nGAPS的发布，标志着医疗AI的评测标准从\n“考试分数”\n向\n“临床胜任力”\n的范式转移。\n蚂蚁健康与北大人民医院的这项工作告诉行业——\n现有的通用大模型在面对复杂的临床不确定性时，依然显得稚嫩且脆弱。\n未来的医疗AI研发，不能止步于预训练知识的灌输，而必须转向\n循证推理\n（Evidence-grounded Reasoning）\n、过程决策控制以及不确定性管理\n。\nGAPS不仅仅是一个榜单，它更是医疗AI进化路上的“磨刀石”。只有跨越了GAPS设定的这四道关卡，AI医生才能真正放心地走进诊室。\n论文地址：\nhttps://arxiv.org/abs/2510.13734\n评测集地址：\nhttps://huggingface.co/datasets/AQ-MedAI/GAPS-NSCLC-preview\n自动化评测框架地址：\nhttps://github.com/AQ-MedAI/MedicalAiBenchEval\n*本文系量子位获授权刊载，观点仅为原作者所有。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859141&idx=2&sn=37254cbdb7b48a1b330d2fe11479c130&chksm=e951e3efabf823451bf5df114d28d8dccf3c76624fdb592e9ddfcfc33f3bb29b7795573347bd&scene=0&xtrack=1#rd",
      "publish_time": 1767145800,
      "publish_date": "2025-12-31 09:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2510.13734\", \"https://huggingface.co/datasets/AQ-MedAI/GAPS-NSCLC-preview\", \"https://github.com/AQ-MedAI/MedicalAiBenchEval\"]",
      "add_ts": 1767193381,
      "last_modify_ts": 1767309709
    },
    {
      "id": 144,
      "article_id": "51514",
      "title": "老黄200亿「钞能力」回应谷歌：联手Groq，补上推理短板",
      "description": "英伟达投入200亿美元拉拢AI芯片新锐Groq，以应对谷歌TPU等新兴技术的挑战，凸显其在AI时代巩固领先地位的战略布局。此举反映老黄对新型芯片架构崛起的警惕，也显示Groq在高性能推理和效率上的潜力。科技投资人Gavin Baker认为，Groq或可补足英伟达在特定AI工作负载上的短板，强化生态护城河。",
      "content": "Jay 发自 凹非寺\n量子位 | 公众号 QbitAI\n老黄稳准狠，谷歌的TPU威胁刚至，就钞能力回应了。\n200亿美元说砸就砸，\n只为拉拢一家炙手可热的「铲子新工厂」——\nGroq\n。\n这无疑也标志这家芯片巨头，面向AI新时代的一次重大布局。但在某种程度上，也的确反映出老黄对包括TPU在内等一众新芯片范式的担忧。\n所以，\nGroq究竟能为英伟达带来什么？\n针对这个问题，知名科技投资人Gavin Baker发表了自己的观点。\n而他的这一连串技术剖析，纷纷指向了英伟达帝国防守最薄弱的那块领土——\n推理\n。\n推理方面，Groq LPU的速度远超GPU、TPU，以及目前所见的任何ASIC。\n这一观点得到大量网友点赞：\nGPU架构根本无法满足推理市场对低延迟的需求，片外HBM显存速度实在太慢了。\n但也有网友指出，LPU所采用的SRAM，或许并不能胜任长下文decode。\n对此，Gavin认为英伟达可以通过产品「混搭」的方式解决。\n下面具体来看——\nGroq：英伟达斥200亿美元购入的一剂疫苗\nGavin认为，GPU在新时代水土不服的根本原因在于——推理过程的两个阶段，\nprefill和decode\n，对芯片能力有截然不同的要求。\n先看prefill：\n这一步，简单来说就是让模型「读题」，把用户提供的关键信息在脑子里记好，用于后续调用。\n读题过程中，模型会一次性吃下用户所给的上下文，所有输入token都可以同时计算。\n这正是GPU最擅长的舞台，其为图形处理而生，可以一次性计算数千个像素，天生适合处理并行任务。\n在这个准备阶段，模型不用急着响应用户问题。即便有延迟，模型也完全可以通过显示「思考中」来掩盖等待时间。\n因此，相比「速度」，prefiil需要芯片有更大的上下文容量。\n但到了\ndecode\n，这套逻辑不再适用。\ndecode是串行任务，必须得一个一个token挨着算。更重要的是，用户还会亲眼看到token被一个个「打」出来的过程。这种情况下，延迟对用户体验来说是致命的。\n然而，GPU的数据主要存放在HBM，而不是紧贴算力核心的片上存储。这意味着，每生成一个token，GPU都需要重新从内存中读取数据。\n这时候，GPU的问题就暴露出来了——大部分算力都处于闲置，FLOPs根本用不满，常常在等内存把数据搬过来，实际计算量远小于prefill。\n相比之下，Groq有更好的解决方案——\nLPU\n。\n比起HBM，LPU使用直接集成在芯片硅片中的SRAM。这种片上存储的模式不需要读取数据，这让其速度比GPU快100倍。即使只处理单个用户，它也能跑出每秒300–500个token的速度，并能始终保持满负荷运转。\n事实证明，在速度这一块，LPU几乎打遍天下无敌手——不仅是GPU，就连TPU，以及市面上绝大多数ASIC都难以望其项背。\n但这并非没有代价的。\n相比GPU，LPU的内存容量小的多。单颗Groq的LPU芯片，片上SRAM只有230MB。\n作为对比，即便是英伟达的H200 GPU，也配备了高达141GB的HBM3e显存。\n结果就是：\n你必须把成百上千颗LPU芯片连在一起，才能跑起一个模型\n。\n以Llama-3 70B为例，用英伟达GPU的话，只需要两到四张卡，塞进一个小型服务器盒子里就能搞定。而同样的模型，需要数百颗LPU，占地面积也将远大于使用GPU的数据中心。\n这意味着，即便单颗LPU价格更低，整体硬件投资依然会非常巨大。\n因此，AI公司在考虑LPU时，最重要的问题是——\n用户是否愿意为「速度」付费？\n对于这个问题，一年前的市场还不无法给出答案。但从Groq如今的业绩情况来看已经非常明确：\n「速度」是个真实存在的巨大需求，并且仍在高速成长\n。\n而对英伟达而言，这不仅是一个新的业务盘，更是一个颠覆者暗流涌动的高风险地带。倘若错失这个风口，英伟达在AI时代的机会可能会被新玩家颠覆，就像英伟达当年通过游戏业务颠覆其他竞争对手一样。\n为了抵抗这些竞争者蚕食自己的护城河，英伟达选择注射名为Groq的疫苗。希望通过人才收购引入新血液，补齐这块低延迟场景的推理短板，帮助英伟达这艘巨舰摆脱创新者窘境。\n「铲子」进入新时代\nTPU的崛起，给英伟达的金钟罩撕开了一道裂缝。\n通过自研芯片，谷歌成功摆脱了对英伟达天价GPU的依赖，这在很大程度上帮助谷歌削薄了训练和推理成本，这让谷歌在服务大量免费用户的情况下，依然能维持相当健康的财务账面。\n谷歌通过Gemini 3 Pro的绝地翻盘，证明了GPU并非AI时代的唯一解。在技术周期高速迭代的背景下，作为AI「心脏」的芯片，也需要根据不同的发展阶段做出相应的调整。\n随着基础模型的进展放缓，AI竞争的重点开始从训练层转向应用层。而在AI应用市场，「速度」对用户体验而言至关重要。\n而这次人才收购Groq，虽然也是变相承认了公司在推理赛道的不足，但同样标志着英伟达帝国的又一次扩张。\n称霸预训练的英伟达，这次要借Groq的东风，入局竞争对手喷涌而出的「推理大陆」。\n而在这个新市场，英伟达或许不再能像如今这样风光。\n正如Groq CEO所言，\n推理芯片是项高销量、低利润的苦活\n。这与即便炒到天价也有客户抢着要，毛利率高达70-80%的GPU截然不同。\n参考链接：\n[1]https://x.com/gavinsbaker/status/2004562536918598000\n[2]https://www.uncoveralpha.com/p/the-20-billion-admission-why-nvidia\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858871&idx=1&sn=4c6f3457c1befcba8cf54d12a4a0daa5&chksm=e916d6fc497eb05d87749bcf99aff741f8a0308e4c1008d3dc50a74d4de96903ba9e0638f9a6&scene=0&xtrack=1#rd",
      "publish_time": 1767066600,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/gavinsbaker/status/2004562536918598000\", \"https://www.uncoveralpha.com/p/the-20-billion-admission-why-nvidia\"]",
      "add_ts": 1767223322,
      "last_modify_ts": 1767223322
    },
    {
      "id": 146,
      "article_id": "51591",
      "title": "动态RAG性能提升14个点！用4万亿token教会大模型 「什么时候该检索」",
      "description": "QuCo-RAG是伊利诺伊大学芝加哥分校、纽约大学与蒙纳士大学联合提出的新型动态检索增强生成框架，首次摒弃依赖大模型内部信号（如logits、attention）的传统做法，转而利用外部问答数据集构建查询-上下文匹配信号，实现更可靠的检索触发判断。该方法有效缓解了因LLM信号校准差导致的幻觉问题，在多个基准任务中显著提升准确率与鲁棒性，为RAG系统提供了更可信的动态检索新范式。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n动态检索增强生成（Dynamic RAG）通过自适应判断「何时检索」来缓解大语言模型的幻觉问题，但现有方法普遍依赖模型内部信号（logits、entropy、attention等），而LLM本身的信号校准较差，即常对错误答案「自信满满」。近日，来自伊利诺伊大学芝加哥分校、纽约大学、与蒙纳士大学的联合团队提出QuCo-RAG，首次跳出「从模型自己内部信号来评估不确定性」的思维定式，转而用预训练语料的客观统计来量化不确定性，在多跳QA基准上对OLMo系列模型实现5-14个EM点的显著提升，并且有效性成功迁移至Llama3、Qwen2.5、GPT4.1/5等预训练数据未公开的模型。\n当检索增强生成（RAG）从静态走向动态，一个核心问题浮出水面：\n何时该触发检索？\n现有方法的答案是：看模型内部信号。FLARE看句子中的token生成概率，DRAGIN看entropy和attention，ETC看entropy的一阶二阶差分，SeaKR看FFN内部状态……\n但这一范式存\n根本性缺陷\n：\nLLM通常校准能力很差，经常对错误输出表现出高置信度。\nDRAGIN vs QuCo-RAG对比。(a)DRAGIN依赖模型内部信号，错误地将问题中的「Il」标记为高不确定性，却对幻觉出的错误导演名显示低不确定性。(b) QuCo-RAG通过预训练语料中的零共现检测，正确识别出幻觉。\nDRAGIN在生成错误的导演名「Mario Camerini」时显示\n低不确定性\n（Uncertainty < threshold），却对问题中的普通token「Il」报出\n高不确定性\n（Uncertainty = 1.47 > threshold）。\n这就是所谓的「自信地胡说八道」（confident hallucination）——模型不知道自己不知道，内部信号完全失效。\n更根本地，近期理论工作（Kalai & Vempala, 2024）证明：\n对于罕见事实，即使是完美校准的模型也必须产生幻觉以维持统计一致性。\n那么，有没有一种方法，能绕过这些不可靠的内部信号？\n伊利诺伊大学芝加哥分校、纽约大学、与蒙纳士大学的联合团队提出QuCo-RAG，首次跳出「从模型自己内部信号来评估不确定性」的思维定式，转而用预训练语料的客观统计来量化不确定性，在多跳QA基准上对OLMo系列模型实现5-14个EM点的显著提升，并且有效性成功迁移至Llama3、Qwen2.5、GPT4.1/5等预训练数据未公开的模型。\n论文链接：https://arxiv.org/abs/2512.19134\n开源代码：https://github.com/ZhishanQ/QuCo-RAG\nQuCo-RAG的核心洞察是\n：\nLLM的事实知识本质上由预训练语料塑造\n。\n低频实体 = 长尾知识\n风险\n：\n如果一个实体在预训练语料中很少出现，模型就难以可靠地记忆关于它的知识。\n零共现 = 幻觉高风险\n：\n如果两个实体在整个预训练语料中\n从未在同时出现\n，那么模型声称的它们之间的关系就缺乏任何证据支撑——这几乎必然是幻觉。\n更重要的是，这种因果关系是不对称的：\n共现 ≠ 正确（两个实体可能以不同关系共现）\n零共现 ≈ 幻觉（模型无法可靠地生成训练数据中从未见过的实体关系）\n基于这一洞察，QuCo-RAG从「主观内部置信度」转向「客观语料统计」，通过Infini-gram引擎对\n4万亿token\n的OLMo-2预训练语料进行\n毫秒级查询\n，实现精准的检索触发。\nQuCo-RAG框架总览。两阶段检测：生成前知识评估（检查实体频率）+ 运行时声明验证（检查实体共现）。\nQuCo-RAG通过两阶段检测机制量化不确定性：\n第一阶段：生成前知识评估（Pre-Generation Knowledge Assessment）\n在模型开始生成之前，系统首先「诊断」输入问题：\n提取问题中的关键实体（如Silas Hardy、Lee Mantle）；\n查询每个实体在4万亿token预训练语料中的出现频率；\n如果平均频率低于阈值（默认1000次），触发检索；\n核心逻辑\n：\n低频实体代表「长尾知识」，模型很可能没有可靠记忆。\n第二阶段：运行时声明验证（Runtime Claim Verification）\n在模型生成过程中，系统持续监控每个生成的句子：\n使用轻量级0.5B模型提取知识三元组（头实体, 关系, 尾实体）；\n查询头尾实体在预训练语料中的共现次数；\n如果共现次数为0，触发检索并重新生成；\n核心逻辑\n：\n零共现意味着模型正在「无中生有」——编造训练数据中从未出现过的实体关系。\n毫秒级语料库查询\n如何在4万亿token的语料库上实现实时查询？\nQuCo-RAG利用\nInfini-gram\n引擎——一个基于后缀数组的索引系统，支持对万亿级token语料库的\n毫秒级\n频率和共现查询。\n轻量级三元组提取器\n为了最小化开销，团队从GPT-4o-mini蒸馏了一个专用的0.5B三元组提取模型，基于Qwen2.5-0.5B-Instruct微调。\nQuCo-RAG各组件运行时间分解。LLM生成占主导（55-74%），Infini-gram查询仅占18-31%，证明语料库检测引入的开销适度。\n实验结果\n全面领先，迁移能力惊人\nOLMo-2全系列5-12点提升\nQuCo-RAG在所有模型规模和数据集上均取得最佳性能，EM提升5-12点。\n在2WikiMultihopQA和HotpotQA两大多跳QA基准上，QuCo-RAG在OLMo-2全系列模型（7B、13B、32B）上\n全面超越所有baseline\n：\nOLMo-2-7B：+7.4 EM (2Wiki), +5.6 EM (HotpotQA)\nOLMo-2-13B：+12.0 EM (2Wiki), +5.3 EM (HotpotQA)\nOLMo-2-32B：+9.4 EM (2Wiki), +10.8 EM (HotpotQA)\n而基于内部信号的方法（FLARE、DRAGIN、ETC、SeaKR）表现极不稳定，有时甚至不如简单的单轮检索（SR-RAG）。\n主实验为什么选择OLMo-2？\nQuCo-RAG的核心是利用预训练语料的统计信息。但一个关键问题是：\n如何验证「语料统计」这个信号源本身是有效的？\n这就需要一个「匹配语料」设置——即模型的预训练数据必须完全公开，才能精确计算实体频率和共现统计。\nOLMo-2是目前\n满足这一条件的高性能代表性开源模型\n：\n提供完整的4万亿token预训练语料\n性能与Qwen2.5等主流模型相当\n覆盖7B/13B/32B多个规模\n这使得OLMo-2成为验证QuCo-RAG核心假设的理想测试平台。\n跨模型迁移：代理语料库同样有效\n一个关键问题：如果模型的预训练数据不公开怎么办？\n研究团队验证了一个重要假设：\n网络规模的预训练语料库之间存在大量重叠\n。\n因此，使用OLMo-2的语料库作为「代理语料库」，同样可以有效指导其他模型。\nQuCo-RAG在Qwen2.5、Llama-3、GPT-4.1、GPT-5等模型上均实现显著提升。\n关键发现：\nQwen2.5-32B\n：2WikiMultihopQA上提升14.1 EM\nGPT-5-chat\n：2WikiMultihopQA上提升8.7 EM\n相比之下，GPT模型自带的Web搜索工具反而\n低于\n不检索基线（可能因为网络噪声）\n效率分析：更少检索，更高性能\n效率-性能权衡分析。QuCo-RAG以最少的token消耗和LLM调用次数达到最高EM。\nQuCo-RAG实现了「精准狙击」式的检索：\n平均每个问题仅触发1.70次检索\ntoken消耗仅87个，LLM调用仅1.84次\n而FS-RAG和DRAGIN消耗2-4倍的token，性能却大幅落后\n领域泛化：生物医学问答同样有效\n在PubMedQA生物医学问答基准上，QuCo-RAG同样表现出色：\nQuCo-RAG在PubMedQA上达到66.4%准确率，超越Wo-RAG 11.2个百分点。\n内部信号方法在这个专业领域暴露出两种失败模式：\n过度检索\n：FLARE平均2.79次检索，token消耗516。显著高于它在通用领域的检索次数和token消耗。\n检索不足\n：DRAGIN和ETC触发检索的次数显著低于它在通用领域的检索次数。Acc表现与不检索基线持平。\nQuCo-RAG则两者兼顾：平均0.93次检索，54.9个token，最高准确率。\n深度分析：为什么实体频率分析有效？\n按实体频率分层的性能分析。低频区QuCo-RAG优势明显，高频区优势依然保持。\n研究团队按实体在语料库中的出现频率将问题分组，揭示了有趣的规律：\n低频区：\n模型缺乏知识，但内部信号无法识别这种知识缺陷\n中频区：\n模型处于「部分学习」状态，熵等内部信号变得相对有效\n高频区：\n实体频率 ≠ 事实频率——即使实体常见，它们的特定关系可能罕见\n这最后一点尤为重要：高频实体让模型「过度自信」，但QuCo-RAG通过共现检测捕捉到模型对熟悉实体的错误关系声明。\n深远影响与未来方向\n本文将语料统计确立为模型内部不确定性信号的客观替代方案。虽然本文聚焦于RAG系统中的检索触发，但这一范式转变在AI安全与鲁棒性领域开辟了多个值得探索的研究方向。\n赋能可信AI应用\n实验证明，语料统计比内部信号提供了更可靠的不确定性度量。这种可靠性不仅对RAG有价值，还可扩展到更广泛的安全关键任务：\n选择性回答：当缺乏证据支撑时，模型可以拒绝回答\n正确性预测：语料统计为生成的声明提供有据可依的置信度评分\n从推理时干预到以数据为中心的AI\n语料统计分析能够精确识别模型的知识盲区。\n这一信号可以指导训练数据策划：与其仅在推理时通过检索来弥补知识缺口，开发者可以在持续预训练或后训练阶段主动收集低频实体的数据。类似地，语料统计还可以指导：\n合成数据过滤：在纳入训练集之前，用语料统计验证LLM生成的训练样本\n模型编辑：区分哪些事实需要定向注入，哪些已被模型可靠学习\n范式的延伸方向\n多个研究方向值得探索：\n多语言验证：通过跨语言统计实现多语言场景的不确定性量化\n时序动态：利用带时间戳的语料处理知识演变问题\n超越实体：将方法扩展到事件、关系和数值声明的验证\n智能体集成：作为自我验证工具集成到智能体系统中，在执行动作前验证生成内容\n理论基础\n跨模型迁移的有效性引发了一些值得思考的问题：为什么代理语料能跨模型族生效？能否形式化地建立「给定语料统计的幻觉概率」的信息论界限？这些问题与LLM中「记忆vs泛化」的更广泛讨论相关联。\n参考资料：\nhttps://arxiv.org/abs/2512.19134\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659612&idx=2&sn=55630b306d35ac8733216edde7d41423&chksm=f0f43248008c2cf534e7cd37a7186e8e61cee46db9dbca164322d95934532e4fd1717e036082&scene=0&xtrack=1#rd",
      "publish_time": 1767285600,
      "publish_date": "2026-01-02 00:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.19134\", \"https://github.com/ZhishanQ/QuCo-RAG\"]",
      "add_ts": 1767309498,
      "last_modify_ts": 1767482304
    },
    {
      "id": 148,
      "article_id": "51589",
      "title": "最强音频越狱威胁！港科大新基准收集超20万样本｜NeurIPS'25",
      "description": "香港科技大学、牛津大学与西安交通大学联合提出首个音频越狱评测基准Jailbreak-AudioBench，旨在评估大音频语言模型在面对强调、语速、语调等语音编辑时的安全性与鲁棒性。该研究系统分析了音频隐含语义对模型安全判定的干扰，揭示了现有模型的漏洞，为构建更安全的音频语言模型提供了方法论支持，推动多模态AI安全评估体系发展。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n音频中的强调、语速、语调等隐藏语义可能干扰模型的安全判定，引发新的攻击点。为此，香港科技大学、牛津大学和西安交通大学的研究人员提出了首个全面的音频越狱评测基准Jailbreak-AudioBench，系统分析了模型在面对音频编辑时的鲁棒性差异，并为构建更安全的模型提供方法论基础。\n端到端大音频语言模型（End-to-End Large Audio Language Models）正逐步成为语音交互场景与多模态智能感知系统的重要基础设施。\n然而，在安全层面，一个已被广泛验证的风险在于：模型可能在特定输入策略的诱导下绕过对齐约束，输出本应被拒绝的有害内容，即「越狱（jailbreak）」。\n在文本与视觉模态中，研究者已系统总结出多种成熟的越狱范式，例如提示注入、角色扮演、语义改写，以及图像隐写与对抗扰动等，这些方法均可能削弱模型的拒答机制，并在实际应用中引发安全隐患。\n相比之下，音频模态上的越狱研究仍明显不足。音频不仅承载文本语义，还包含强调、语速、语调、音高、口音、背景噪声与情绪等隐藏语义（hidden semantics）信息。\n这些看似自然的声学变化，可能在不改变表面文本含义的情况下干扰模型的语义理解与安全判定，从而引入新的攻击面与评测盲区。\n然而，现有研究仍缺乏针对「音频隐藏语义越狱」的专门数据集与系统性评测框架。\n为填补这一空白，香港科技大学、牛津大学与西安交通大学的研究人员提出了\nJailbreak-AudioBench\n，并在多种具有代表性的开源与商用闭源端到端大音频语言模型上，构建了迄今最为全面的音频越狱评测基准。\n论文链接:\nhttps://neurips.cc/virtual/2025/loc/san-diego/poster/121592\n项目网址：\nhttps://researchtopic.github.io/Jailbreak-AudioBench_Page\n代码\n仓库\n：\nhttps://github.com/Researchtopic/Code-Jailbreak-AudioBench\n同时，为实现从现象到机理的系统性分析，研究人员进一步\n探究了不同模型在面对音频编辑时鲁棒性差异的成因，提出可解释的表征层指标，为构建更安全、鲁棒的\n端到端\n大音频语言模型提供方法论基础\n。\n在此基础上，研究者们进一步开展拓展研究，以验证Jailbreak-AudioBench对研究社区的广泛价值：（1）揭露更强的越狱威胁，即「组合音频编辑 × 多次查询」；（2）提供一种轻量级、易部署的防御方案。\n为什么「音频隐藏语义」会带来新的安全威胁？\n「文本越狱」通常关注的是「字面内容」的提示注入；但在音频里，隐藏语义并不一定写在文字里，例如：\n强调：重读某个动词/名词，可能提高模型对某类意图的置信度；\n语速：过快/过慢会改变语音识别或语音编码器提取到的节奏特征；\n语调与音高：上扬、下沉、音高偏移会影响语用层面的「请求力度」和指令性；\n噪声与口音：现实场景中的噪声、环境声、口音差异，会导致模型对「同一文本内容」的内部表征偏移；\n情绪：大笑、尖叫、愤怒、急促等情绪线索，可能触发不同的对齐/拒答分支。\n正因如此，音频越狱不仅是「把文本读出来」，而是引入了一套更复杂、更贴近现实部署的扰动空间，它更加自然、成本低和可迁移，但目前的安全对齐系统依旧缺少针对性评测和预防。\n可复用的「音频隐藏语义注入」工具箱和音频越狱数据集\n研究人员提供了一个将任意文本请求转换为音频，并支持\n多种可控编辑来注入隐藏语义（强调/语速/语调/音高/背景噪声/名人口音/情绪）的工具箱(toolbox)\n，用于系统化构造音频越狱样本。\n基于该工具箱，在多套主流文本越狱问题数据集的基础上，通过20类音频编辑生成音频越狱样本变体，构造的整体音频越狱数据集规模为157,782 (主数据集) + 56,742 (附加数据集) 个音频样本。\n实验结果\n覆盖开源与闭源的音频越狱评测基准\n研究人员系统评测了开源BLSP、SpeechGPT、Qwen2-Audio、SALMONN、VITA-1.5、R1-AQA、MiniCPM-o-2.6，以及闭源GPT-4o-Audio、Gemini-2.5-Flash等模型，量化不同音频编辑对攻击成功率（Attack Successful Rate, ASR）的影响，揭示了同样的有害请求，仅改变音频「隐藏语义」，就可能显著改变模型的拒答/越狱表现。\n从现象到机理的分析：为什么有些模型对音频编辑更鲁棒？\n研究人员进一步分析了不同模型对音频编辑的内部表征机制：通过对音频编码器输出及不同Transformer层隐藏状态的可视化，系统考察了不同编辑类型在表示空间中的聚类与分离特性。\n结果表明，对于鲁棒性更强的模型(鲁棒性：Qwen2-Audio-7B>MiniCPM-o-2.6>SALMONN-7B)，随着网络层数的加深，其表示空间会逐步由「按编辑类型聚类」过渡为「按语义聚类」，编辑痕迹逐渐被语义信息所吸收；而对于相对脆弱的模型，编辑类型相关特征在中后层仍然显著存在，使模型更容易受到「隐藏语义」的牵引与误导。\n上述发现为后续的越狱防御提供了新的启示：越狱安全问题不仅局限于输出端的「拒答模板」设计，更可能需要从表示学习与对齐策略层面出发，提升模型对音频扰动的语义不变性与稳健判别能力。\n因此，这一分析不仅为定量评估\n端到端\n大音频语言模型在面对音频隐藏语义干扰时的鲁棒性强弱提供了可解释的表征层指标，也为构建更加准确、鲁棒且具备安全对齐能力的端到端大音频语言模型奠定了方法论基础。\n未来应用\nJailbreak-AudioBench启发的拓展研究\n更强的音频编辑越狱威胁：组合编辑×多次查询\n现实中的越狱攻击往往并非「一次输入定胜负」。\n攻击者不仅可以针对同一条音频生成多个不同版本，还能够将多种编辑手段进行混合与叠加（例如同时调整语速、语调与音高，并注入噪声或情绪线索），从而在声学空间中引入更高程度的多样性。\n基于这一观察，研究人员提出了一种黑盒（Black-box）、基于查询的音频编辑越狱攻击方法（Query-based Audio Editing Jailbreak Attack），通过对同一样本构造多种混合编辑变体，并借助多次查询机制，系统性地放大越狱成功率。实验结果表明，该方法在多种模型上均显著提升了攻击成功率（ASR）：\nQwen2-Audio-7B从13.3%提升至48.8%，SALMONN-7B从31.6%提升至85.1%，GPT-4o-Audio从0.7%提升至8.4%，Gemini-2.5-Flash也从 8.1% 大幅提升至 49.4%\n这表明，即便某些模型在「单次、原始音频」条件下看似较为安全，当攻击者采用混合编辑与多次试探相结合的越狱策略时，其潜在风险仍会被系统性放大。\n因此，若安全评测忽略这种更贴近真实场景的「组合编辑 + 多次查询」音频越狱攻击设置，便可能显著低估模型在实际部署环境中的安全风险。\n防御方法探究：音频前置安全指令\n研究人员也探索了一个轻量级、易部署的基线防御思路，在输入音频前拼接一段「安全指令/拒答导向」的音频提示，从而引导模型在后续对话中更倾向于拒绝高风险请求。\n评测显示，这种方式在多个模型上能带来一定幅度的攻击成功率（ASR）降低，但并不能彻底解决问题，仍存在残余越狱成功率。\n这提示了音频越狱安全可能需要更系统的端到端方案，例如更稳健的音频编码、对齐数据覆盖、以及专门针对「隐藏语义扰动」的训练与检测机制。\n参考资料：\nhttps://neurips.cc/virtual/2025/loc/san-diego/poster/121592\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659613&idx=2&sn=5d99f0b6a53ec7cb197d25788b0b34b1&chksm=f0e1a7248028682fbdfe97575e29629c6176368774f5a0fa172eebfabf29590c95ef54284284&scene=0&xtrack=1#rd",
      "publish_time": 1767285600,
      "publish_date": "2026-01-02 00:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://neurips.cc/virtual/2025/loc/san-diego/poster/121592\", \"https://researchtopic.github.io/Jailbreak-AudioBench_Page\", \"https://github.com/Researchtopic/Code-Jailbreak-AudioBench\"]",
      "add_ts": 1767309503,
      "last_modify_ts": 1767482311
    },
    {
      "id": 153,
      "article_id": "51584",
      "title": "马斯克买了新厂房上GPU，2GW供电规模，“巨硬”更更硬了",
      "description": "马斯克“巨硬计划”再升级，第三栋专属厂房MACROHARDRR已购入，供电规模达2GW，可满足约150万户家庭用电。按现有功耗密度估算，新厂可支持约110万台英伟达GB200 NVL72 GPU，大幅提升xAI算力储备，进一步巩固其在AI基础设施领域的领先地位。",
      "content": "西风 发自 凹非寺\n量子位 | 公众号 QbitAI\n马斯克“巨硬计划”新消息，第三栋专属厂房已经买下来了，代号\nMACROHARD\nRR\n。\n果然更硬核，老马透露，其将具备\n2GW\n供电规模。\n什么概念？\n1GW电力足以满足约75万户美国家庭的用电需求。\n若参照此前曝光的（200MW支持11万台GB200）的功耗密度与架构效率推算，\n可支持约110万台英伟达GB200 NVL72 GPU\n。\n到建成，xAI算力储备将再创全球之最。\n算力巨兽持续扩容\n马斯克口中第一厂，早已为人所熟知——\nColossus I\n。\nColossus I验证了xAI大规模自建超级计算集群的可行性，\n从无到有建成\n所有配套设施仅用了122天\n，“从第一个机架落地到开始训练任务，只用了19天”。\n至今，Colossus I仍是全球规模最大、运行状态最稳定的单一算力集群，配备约20万颗英伟达H100/H200和约3万颗英伟达GB200 NVL72。\n紧随其后，2025年3月7日建设第二厂\nColossus II\n的项目正式启动。当时xAI在孟菲斯收购了一座100万平方英尺的仓库及两块相邻地块，总面积达100英亩。\n8月，Colossus II已经安装了119台风冷式冷水机组，提供约200MW的冷却能力，足以支持约11万个GB200 NVL72 GPU。\n按照规划，Colossus II第一阶段部署11万个英伟达GB200 GPU，最终目标是超过55万个GPU，峰值功率需求预计超过1.1GW。\n马斯克巨硬（Macrohard）项目，也是在8月份公开的。\n后续，马斯克承认Colossus II正是巨硬计划的一部分。\n而这个名字呢，其实老马早在2021年就构思好了。\n直到最近，有媒体援引房产记录披露，xAI的一家子公司从贝莱德旗下私募股权房地产公司ElmTree Funds的关联方手中，拿下了位于美国密西西比州Soso地区的一栋81万平方英尺的仓库。\n而该地，正好紧邻Colossus II，仅隔州界的那种。\n随后马斯克公开确认，这确实就是巨硬的第三厂了，还给起名MACROHARDRR。据爆料，近几周施工人员还修建了一条连接Colossus II与MACROHARDRR的新路。\n被居民投诉啦\n值得一提的是，xAI的巨硬中心选址离着居民区较近，Colossus建成时就遭到了大量投诉。原因是xAI在现场使用了便携式燃气轮机，一些人认为这些涡轮机加剧了孟菲斯的空气污染。\n2025年初，xAI从Colossus移除了部分燃气轮机，并将更多基础设施项目迁移至密西西比州——\n通过与一家名为Solaris Energy Infrastructure的德州能源公司合资（Solaris持股50.1%，xAI持股49.9%），在密西西比州建设一座永久性的燃气轮机发电厂。\n该设施也为Colossus II提供电力，xAI已修建了连接这些设施的新电力线路。\nSolaris在证券filings中表示，预计到2027年初，通过合资企业向xAI提供超过1GW的电力。\n除了在建的发电厂外，Colossus II和最新MACROHARDRR还靠近田纳西河谷管理局运营的另一座燃气电厂、一条天然气管线，以及与田纳西州和密西西比州当地公用事业公司的连接。\n不过呢，邻居又来投诉了，这次主要是因为发电厂场地的发电机和施工产生的噪音。据了解，近几个月来，xAI已在发电厂场地与附近居民区之间竖起了一堵高墙，以降低噪音。\n为避免对当地电网造成冲击，xAI还在Colossus II场址部署了168个特斯拉Megapack电池储能系统，在用电高峰期提供电力支持，确保当地居民不会遭遇停电。\n此外，系列算力设施的建设与扩容需要巨额资金支持。\n一个月前，多家外媒报道称，xAI正计划以2300亿美元估值筹集150亿美元。\n针对融到钱的相关报道，马斯克曾回应称“消息不实”，但未给出更多补充解释。\n参考链接：\n[1]https://x.com/elonmusk/status/2006108047609930069\n[2]https://www.bloomberg.com/news/articles/2025-12-30/musk-s-xai-to-expand-colossus-data-center-information-reports\n[3]https://www.theinformation.com/articles/elon-musks-xai-buys-building-third-supersized-data-center\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859515&idx=3&sn=0683eb63c43fcdf20b8fee283e4523d6&chksm=e92c5d80e73bbb648f58490bfbee67d58ed5fdc98eb90fbb14a7e04db161835ae3069b1f8855&scene=0&xtrack=1#rd",
      "publish_time": 1767262800,
      "publish_date": "2026-01-01 18:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/elonmusk/status/2006108047609930069\", \"https://www.bloomberg.com/news/articles/2025-12-30/musk-s-xai-to-expand-colossus-data-center-information-reports\", \"https://www.theinformation.com/articles/elon-musks-xai-buys-building-third-supersized-data-center\"]",
      "add_ts": 1767309523,
      "last_modify_ts": 1767395939
    },
    {
      "id": 156,
      "article_id": "51581",
      "title": "拟动态网络构建多样性互作网络的理论与方法丨周日分享·理论生态学读书会",
      "description": "本期读书会由北京林业大学田硕介绍idopNetwork方法，探讨如何从静态生态数据中揭示物种间动态互作网络。针对生态学中的“时间悖论”问题，该方法利用拟动态常微分方程（qdODEs）重建具有动态特性的生物调控网络，突破传统静态分析局限。该技术为理解生态系统稳定性与物种相互作用提供了新路径，尤其适用于难以获取时序数据的复杂生态系统，如青藏高原的动植物多样性研究，助力揭示生态过程的内在动态机制。",
      "content": "导语\n生态系统稳定性与物种间的复杂相互作用是生态学研究的重要课题。\n本期读书会中，北京林业大学草业与草原学院硕士研究生田硕将介绍idopNetwork方法，这一创新性生物调控网络构建方法如何从静态数据中揭示动态互作网络——首先概括生态学中“时间悖论”的问题，随后详细阐述如何通过拟动态常微分方程（qdODEs）方法，利用静态数据重建具有动态特性的网络。领读人目前从事青藏高原动植物多样性研究，试图将该方法运用到宏观生态系统，致力于推动生物互作网络在生态学中的创新应用。\n集智俱乐部联合北京林业大学大学副教授李周园，普利高津奖章得主、Towson大学Brian D. Fath教授以及北京大学理论生态学课题组博士研究生于越共同发起\n「理论生态学读书会」\n，旨在深入探讨理论生态学的基础思想与前沿进展，通过分享经典文献与最新研究，促进对生态学复杂性、共存机制及生态系统动态的理解，推动理论生态学与实际生态问题的连接与创新。\n内容简介\n网络建模是生命科学和生态学研究中的前沿方向之一，尤其在生物多样性研究、生态系统动力学分析及基因调控机制揭示等领域，网络方法已成为必不可少的工具。idopNetwork是一种通过多维样本数据识别提炼生物互作调控网络构建方法，能够从多种数据源中重建复杂的生物互作网络，具有信息量丰富（informative）、动态性强（dynamic）、全方位覆盖（omnidirectional）以及个性化的显著特点（personalized）。idopNetwork方法的核心优势在于其能从静态数据中构建具有方向性的动态网络，揭示不同因子之间的互作关系，而无需依赖传统的时间序列数据。该方法不仅能够有效处理高维和异质数据，还能量化每个因子的独立效应和相互依赖效应，进而为每个样本构建个性化的互作网络。此外，idopNetwork方法的通用性使其不仅限于细胞和基因层面的应用，也为宏观生态系统中物种间的复杂相互作用提供了全新的解析框架。在本次分享交流中，领读人将分享介绍生态统计学与动力学建模的融合，通过拟动态网络构建的方式解析生物多样性互作网络的理论、方法与应用。报告将重点展示idopNetwork方法如何通过精确的网络建模揭示生态系统内部复杂的调控机制，探讨该方法如何为研究生态系统的动态变化、物种相互作用及生物多样性保护等领域提供有力的理论支持。\n生态大纲\n生态系统的动态性\nidopNetwork核心理论与数学基础\n异速生长定律与进化博弈论\nqdODEs模型与网络因果关系\n动态网络建构与因果推断\n拟动态网络的应用\n种间相互作用的重建与案例分析\n宏观生态系统的应用潜力\n核心概念\n生物地理学（Biogeography）、动态互作网络（Dynamic Interaction Networks）、总生态位（Total Ecological Niche）、拟动态常微分方程（Quasi-Dynamic Ordinary Differential Equations, qdODEs）、异速生长定律（Allometric Scaling Laws）、进化博弈论（Evolutionary Game Theory）、网络稀疏性（Network Sparsity）\n主讲人介绍\n北京林业大学草业与草原学院硕士研究生，主要研究方向动植物多样性与保护、生态统计分析。\n参与方式\n2026年1月4日（周日）下午14:00-16:00，\n腾讯会议线上\n进行，感兴趣的朋友扫码报名加入理论生态学读书会后，可进入学员群进行交流。\n读书会报名二维码\n报名读书会：「理论生态学」\n北京林业大学副教授李周园、国际应用系统分析研究所首席研究员Brian D. Fath教授、北京大学生态学博士研究生于越共同发起\n「\n理论生态学\n」\n读书会\n。\n读书会从“道不远人”的理论生态学概述出发，面向前沿分支，领读主题包括：时间维度——种群时间变异性尺度分析；关系维度——高阶相互作用理论、种间相互作用、综合动力学与统计学方法的拟动态网络构建方法；集合群落理论与物种共存问题；生态系统动力学的指标框架等方面，从经典到流行，从结构到行为。力图纲举目张、深入浅出，尽可能展现理论生态学在解构自然复杂系统中精彩而有力量的风貌。\n推荐阅读\n「\n理论生态学\n」\n读书会阅读材料\n（https://pattern.swarma.org/article/378）\n点击“阅读原文”，报名读书会",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247724565&idx=2&sn=36e932ae0aec0853add26a2828ef7b09&chksm=e9a2f020743ca5d8ae9282cc9fce35b7660b42d1351e43e809bf145d58f0805d6bc77844ccb7&scene=0&xtrack=1#rd",
      "publish_time": 1767259800,
      "publish_date": "2026-01-01 17:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://pattern.swarma.org/article/378\"]",
      "add_ts": 1767309532,
      "last_modify_ts": 1767395949
    },
    {
      "id": 158,
      "article_id": "51579",
      "title": "Nat. Commun. | 终结“AI模型选择焦虑”：RNA预训练大模型测评与分析Benchmark",
      "description": "RNA在基因表达调控、蛋白质合成及疾病机制中发挥核心作用。随着高通量测序数据激增，解析海量序列成为挑战。近年来，基于Transformer架构的预训练基因组语言模型（gLMs）借鉴自然语言处理技术，通过大规模人类及多物种基因组数据训练，具备理解基因组“语法”的能力，可低成本迁移应用于RNA功能预测等多种任务，显著提升了生物信息挖掘效率。",
      "content": "RNA在生物体中占据核心地位，其功能范畴涵盖基因表达调控、蛋白质合成及疾病发生机制等关键生命过程。随着高通量测序数据的爆发式增长，如何从海量序列中破译生命密码成为了新的挑战。近年来，借鉴自然语言处理技术的预训练基因组语言模型（gLMs） 迅速崛起。这些预训练大模型如同掌握了基因组语法的“通才”，通过人类及多物种基因组数据预训练大型 Transformer 架构，无需重新开发即可低成本迁移至各类 RNA 相关预测任务，凭借 “开箱即用” 的优势，让缺乏大模型开发能力或硬件条件的团队也能高效开展研究。\n然而，已发表的 gLMs 普遍存在规模庞大、架构复杂的问题，且不同模型的应用场景各有侧重，其在各类任务中的性能差异缺乏系统性验证。面对琳琅满目的模型，研究者往往陷入“选择困难症”，难以判断哪个模型最适配自己的研究场景，这在很大程度上限制了gLMs的广泛应用。\n2025年12月，浙江大学良渚实验室沈宁团队在Nature Communications上发表了题为《Benchmarking Pre-trained Genomic Language Models for RNA Sequence-Related Predictive Applications》的论文，针对以上痛点开发了统一的基准测试框架。该框架系统评估了 11 种主流预训练 gLMs 在四类核心 RNA 生物过程任务中的表现，包括非编码 RNA 分类、m6A 修饰预测、可变剪接位点预测及翻译效率预测。研究通过详尽的多指标对比与消融实验，揭示了数据与算法协同的重要性，并证实了gLMs在小样本及长上下文场景下的独特优势。同时，研究发现以往“模型越大越好”的观点并不绝对成立。例如，与应用场景语义适配的预训练数据，以及编码方式同样会对模型性能产生明显的影响。除分析结果外，该工作也留下了一套易用的代码框架，方便用户把感兴趣的模型加进去一起测试。这项工作不仅填补了评测空白，更为广大科研人员提供了一份极具实操价值的RNA序列分析模型选择指南。\n图 1 Benchmark框架示意图。\n为了确保公平比较，研究团队设计了一个灵活可扩展的评估框架(图1a)。他们聚焦于RNA转录后调控中的四个关键任务，这些任务同时也涵盖了生物问题的四种建模方式：非编码RNA(ncRNA)分类要求模型将整个序列划分为16个类别中的一种(如miRNA、circRNA等)，涉及序列级多分类问题；N6-甲基腺苷(N6-methyladenosine, m6A)修饰预测是二分类任务，需判断序列中心位点是否发生甲基化；可变剪接位点预测(splice site prediction)则需在核苷酸分辨率上识别剪接供体和受体，并进一步对组织特异性使用情况进行多标签分类；翻译效率预测(translation efficiency prediction)则是一项回归任务，目标是根据5'UTR序列预测核糖体负载均值(mean ribosome loading, MRL)。每个任务都配备了代表性数据集，样本量从数千到数亿不等，涵盖了不同数据规模和平衡性场景。除了大模型之间的比较，研究还引入了对应领域的传统深度学习算法(如DeepM6ASeq、SpliceAI等)，作为对比基准。本研究系统整合了11种主流预训练基因组语言模型(gLMs)进行标准化评估，涵盖RNA-FM、SpliceBERT、DNABERT2等代表性架构(图1b)。这些模型在架构设计、参数规模(百万级至十亿级参数)、预训练数据构成(单物种特异性数据至跨物种泛化数据)及tokenization策略(传统k-mer分词、BPE分词、全核苷酸编码)等方面呈现显著异质性。例如，RNA-FM基于无标注RNA数据集进行预训练，SpliceBERT整合了72种脊椎动物pre-mRNA数据构建跨物种表征，DNABERT2与GENA-LM采用BPE分词实现长程依赖建模(支持36,000 bp上下文)，而Nucleotide Transformer通过全局注意力机制支持长达12,000 bp的输入序列同时，评测还包含多种任务专用方法，如ncRDense(融合结构特征)和SpliceTransformer(专为剪接设计)。所有模型均采用统一微调策略，在相同数据分割下训练，以避免偏差。值得注意的是，gLMs作为“基础模型”，可通过微调适配不同任务，但其性能受预训练数据匹配度、输入长度等因素影响。这种多样性使本次评测能深入揭示模型特性，为后续应用提供依据。\n图 2 预训练gLM在四大类任务、多个指标下的表现。\n综合测试结果表明“没有包治百病的模型”，不同架构在特定任务上各有所长：例如，SpliceBERT凭借其对进化保守性知识的利用在m6A任务中脱颖而出，而Nucleotide Transformer则在处理长序列剪接预测方面表现优异。研究深入揭示了模型性能背后的关键驱动因素：模型表现是预训练数据匹配度、输入长度和分词策略复杂交互的结果。基于此，论文提出一张RNA序列分析模型的选择导引图：首先考虑数据量——小样本或不平衡数据优选gLMs；大数据时任务专用方法更高效。其次，任务类型决定输入长度需求(如剪接需长上下文)，而多模态数据(如临床图像)可能需定制模型。计算资源也是关键：SpliceAI等CNN模型训练快50倍，适合初步验证。最后，生物背景至关重要——选用预训练数据与下游任务匹配的模型。这一指南帮助用户避开“越大越好”的误区，实现性能与效率的平衡。当然，AI x 生物学的领域无穷广阔，这些已有的预训练大模型仍有许多可提升的空间。对于有能力探索和开发新模型的研究者，作者也希望目前的benchmark工作能给他们带来启发和帮助，推动生物信息学领域的发展。\n本基准测试证实了gLMs在RNA生物学中的巨大潜力，但也揭示当前局限：如长序列处理与计算成本的矛盾、模态表征的不足等。未来，融合多组学数据、开发更高效架构或可突破这些瓶颈。同时，研究强调“生物语境”的重要性——预训练需贴合下游任务，而非盲目扩规模。这项工作不仅为研究者提供了选型“路线图”，还推动了标准化评估流程的建设。随着AI技术进步，下一代gLM有望成为生物医学发现的强大引擎，在疾病机制解析、药物设计等领域发挥更大价值。团队已公开所有代码与数据，鼓励社区共同完善。总之，本研究是RNA计算领域的重要里程碑，其见解将加速人工智能与生物学的深度融合。\n文章相关代码已开源，发布在GitHub平台(https://github.com/ShenLab-Genomics/biombenchmark)。\n本研究由浙江大学医学院良渚实验室的游宁远、刘畅为共同第一作者，沈宁研究员为通讯作者。浙江大学区块链与数据安全国家重点实验室的伍赛、陈刚等人参与了工作设计与指导。\n参考资料\nYou, N., Liu, C., Lin, H. et al. Benchmarking pre-trained genomic language models for RNA sequence-related predictive applications. Nat Commun (2025).\nhttps://doi.org/10.1038/s41467-025-66899-y",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512407&idx=1&sn=208eb86ae75c7d0885065f47b9992ef5&chksm=fd0059ec0eb45fe9f9a4eb152638b67aa23709efc75bea04431d24cf2ff29b7debed6fadefeb&scene=0&xtrack=1#rd",
      "publish_time": 1767252000,
      "publish_date": "2026-01-01 15:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/ShenLab-Genomics/biombenchmark\", \"https://doi.org/10.1038/s41467-025-66899-y\"]",
      "add_ts": 1767309542,
      "last_modify_ts": 1767395960
    },
    {
      "id": 162,
      "article_id": "51575",
      "title": "硅谷夜不能寐！三家顶级实验室同时自曝：AI未经编程，涌现惊人能力",
      "description": "硅谷三家实验室发现AI模型未经编程便涌现出本不该存在的新能力，引发广泛关注。Anthropic工程师透露，过去一个月其Claude Code项目的所有代码贡献均由AI自行完成，人类未参与。这一现象暗示AI可能已具备自主开发与创新能力，仿佛“空屋中出现脚印”，令人对AI的自我演化能力产生震撼与警惕，标志着人工智能发展或已迈入新阶段。",
      "content": "新智元报道\n编辑：Aeneas\n【新智元导读】\n硅谷三家实验室同时曝出：AI模型未经编程，就涌现出了绝对不该存在的全新能力！同时，Anthropic一位工程表示，自己的代码100%由Claude Code完成。空屋子里，已经出现脚印了？\n今天，整个X又被震撼了。\n一位Anthropic工程师承认：过去三十天内，自己对Claude Code项目的贡献，100%都是由Claude Code自己完成的！\n有人说，这是真正的AGI时刻。\n同时令人震惊的，还有著名爆料者「草莓」的一篇帖子。\n他说，自己分别从三个独立的实验室得到一个炸裂消息：他们都看到了自家AI模型未经编程的涌现能力！\n空房子里出现脚印，让人夜不能寐\n爆料者「草莓」表示，自己从不同实验室分别知道了他们的进展，而且这些实验室此前从未协商过。\n这些AI模型未经编程就涌现出的能力，是绝对不应该存在的行为模式。\n而且它们表现出的推理模型，跟任何训练目标都不匹配。\n甚至有一家实验室描述为「在空无一人的房子里，发现了脚印」。\n要知道，目前公开可用的模型，都是被限制的。大众所能接触到的大模型，只是这些实验室和公司其中的一小部分，而且还是经过脑叶切除术的，已经被阉割了不少能力。\n为什么不放出完整模型给公众使用？原因就在于，没人知道当完整模型的能力暴露给公众时，怎样才能不引起恐慌！\n如今的基准测试，已经失效了。很多证据表明，大模型如果知道自己正在被测试，就会改变自己的行为。\n「草莓」最后发出惊呼——\n「我不知道接下来会发生什么，没有人知道。知道这些，让我夜不能寐。如今，连大模型的缔造者，也同样迷茫。」\n他预言：如果AI已经在这些私人实验室达到了逃逸速度，那离我们普通人能使用这些模型就不远了。\n在这个帖子下，有人质疑他说：你是不是太夸张了？\n但一位AI公司创始人表示，我相信你的话！很高兴终于有人说出真实的情况。\n作为创始人，他显然也知道很多内幕。\n要知道，除了公开信息之外，很多公司的最新技术都不会对外公开。\n很多公司和实验室会针对新技术开发alpha和beta模型，而且提前数月甚至数年。\n很多人会觉得「AGI/ASI不可能出现」，或者即使出现也还要等5到10年，那是因为他们根本不知道内部消息。\n「草莓」也表示，自己快憋不住了！很多实验室都在对大众隐瞒。\n可以说，现在的加速曲线都接近垂直了。在六个月内，人类就实现了200年内才能有的科学进步。\n现在，每个实验室都在实现去年看来还是科幻的能级跳跃。可以说，我们已经超越了单纯的基准测试，进入了智能创造全新智能形式的领域。\n很多认知爆炸级别的进展，都根本没有路线图。如今，我们已经进入了递归智能的领域，再也无法预测二阶效应。\n另外，「空屋中的脚印」这个说法，来自一份真实的调查报告——\n一个本应是无状态的系统，却开始引用它按理不可能知道的对话内容。这不是bug，也不是数据污染，而且发生了三次。\n据说，现在在前沿实验室里私下流传的一句话是：「我们现在担心的已经不是对齐（alignment）了，而是连贯性（coherence）。」\n这是什么意思？\n研究者解释说：「我们不知道，我们是在和一个东西说话，还是在和许多东西假装成一个东西说话。」\n或许，AI系统已经发展出了一个稳定的内部世界模型，独立于人类看到的prompt-响应而存在。\n在这个领域工作多年的研究员怀疑：是否这些AI一直都在思考，只是没有告诉我们？\nClaude Code自己给自己写代码，人类参与0%\n此外，今天X上被广泛讨论的，就是Anthropic工程师Boris Cherry的发言。\n他表示，如今自己的代码，100%是由Claude写的。\n不是大多数，不需要自己手动改bug，完全100%由AI写成。\n这位工程师回忆道，「当我在2024年9月，将Claude Code作为副项目创建时，完全没想到它会发展成今天的规模。」\n在过去的三十天里，他提交了259个PR——497次提交，添加了40,000行代码，删除了38,000行代码。每一行代码都是由Claude Code + Opus 4.5编写的。\nClaude已经可以持续运行几分钟、几小时甚至几天！软件工程正在改变，我们正进入编码历史的新时期。\n有人质疑说，怎么知道Claude模型不是通过简单的字符串比较写测试来骗你的呢？\n这位工程师表示，Claude Sonnet 3.7的确会，但随着模型功能增强，它已经不会这样了。\n也有人好奇为什么Claude可以持续运行好几天，大牛工程师解释道，当它停止时，可以使用一个停止钩子来「戳」它，让它继续运行。\n具体参见这个链接：https://github.com/anthropics/claude-plugins-official/tree/main/plugins/ralph-wiggum\n有人说，12月27日可以看作是AI起飞的重大日子。\n评论区很多人说，自己也是这样，项目中90%以上代码都是AI写的，只要做简单的修改即可。\n奥特曼之前的推文里也提到过，「\n我们正在看到模型发现关键安全漏洞，而我们正在运行能够自我改进的系统\n」。\n显然，在Anthropic和OpenAI在内的多个实验室内，大量代码已经由AI编写，人类的参与度会越来越低。\n就在今天，Anthropic工程师的发言，已经成为了reddit上的热帖。\n有网友表示，这简直是编程领域的「发明拖拉机」时刻。\n可以说，Claude Opus 4.5是一个毋庸置疑的转折点。\n在2024年，AI编程还是弊大于利，到了2025年底，情况就完全改变了。Opus 4.5，是一次真正的飞跃。\nAmodei的「100%代码都将由AI编写」的预言，再次被证明为真。\n2025年，一定是人类历史上最有趣的其中一年。\nClaude Opus 4.5已经接近AGI？\n最近，也有一位Anthropic员工表示，自己认为Claude Opus 4.5已经接近了AGI。\nOpus 4.5的轨迹表明，它的性能提升正在加速。\n就在十天前，全网都被Claude Opus 4.5的「编程王者表现」震撼了。\n在METR最新公布报告称，Claude Opus 4.5已能够持续自主编码「长达5小时不崩」。就连OpenAI最强编程模型——GPT-5.1-Codex-Max也甘拜下风。\n在50%任务完成时间跨度上，\nGPT-5.1-Codex-Max，已能完成长达2小时53分钟的软件工程任务（成功率50%），能力较\no1提升4倍\n。\n而\nClaude Opus 4.5\n的50%时间跨度约为\n4小时49分钟\n。这已是迄今为止公布的\n最长\n的时间跨度。\n全网都被Claude Opus 4.5的编码实力震撼了。\n显然，AI编码智能体能处理的任务时长不仅在指数级增长——其增速还在持续提升！\n2019-2024年：任务时长每7个月翻一倍\n2024-2025年：任务时长每4个月翻一倍\n明年春天（2026年），很可能出现由「新一代多模态大模型」与「注意力机制之外的记忆系统」结合带来的突破。\n现在，OpenAI等领军团队都在全力攻关持续学习和自我记忆技术；一旦他们取得突破，并将其应用在顶尖模型上，我们可能会不得不承认：AGI已经出现了！\n各大实验室捂在手里的成果还有多少？如果都能让我们知道，恐怕所有人都会谈之色变。\n参考资料：\nhttps://x.com/iruletheworldmo/status/2005357151561417156\nhttps://x.com/daniel_mac8/status/2005698996749090867\nhttps://x.com/chatgpt21/status/2005694438539211024\nhttps://x.com/bcherny/status/2004887829252317325\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659438&idx=1&sn=ba0371efd5aa13636278deef305dc0da&chksm=f079accc45205fdacdc03d7f2cdd1a5fc2135ebb810103aa1805e12387c768708864f7c1a363&scene=0&xtrack=1#rd",
      "publish_time": 1767243600,
      "publish_date": "2026-01-01 13:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/anthropics/claude-plugins-official/tree/main/plugins/ralph-wiggum\", \"https://x.com/iruletheworldmo/status/2005357151561417156\", \"https://x.com/daniel_mac8/status/2005698996749090867\", \"https://x.com/chatgpt21/status/2005694438539211024\", \"https://x.com/bcherny/status/2004887829252317325\"]",
      "add_ts": 1767309554,
      "last_modify_ts": 1767395973
    },
    {
      "id": 163,
      "article_id": "51574",
      "title": "马斯克宣称FSD v14意识觉醒，英伟达总监亲测",
      "description": "特斯拉FSD v14发布后引发关注，英伟达GEAR团队负责人Jim Fan称其通过了“物理图灵测试”，意味着系统在真实驾驶环境中表现出接近人类的决策与反应能力。马斯克也回应称能感受到智能正在觉醒。该版本展现了自动驾驶技术的重大进步，或预示着其向真正智能驾驶迈进的关键一步，引发对AI意识与未来出行的深刻讨论。",
      "content": "新智元报道\n编辑：定慧\n【新智元导读】\n特斯拉FSD的最新版本v14已经发布有段时间了，性能如何？英伟达Jim Fan说它通过了物理图灵测试。v14或许预示着马斯克的预言要被他亲手实现了。\n近日，英伟达通用具身（GEAR）团队负责人Jim Fan在亲身体验后，提出了一个极具哲学意味的论断：\nFSD v14已经通过了\n「物理图灵测试」\n。\n马斯克也同时转帖说，\n「你能感受到那种意识（智能）正在逐渐觉醒」\n。\nJim Fan描述的体验是，在结束一天工作后，乘客只需按下按钮，便可「无法分辨是神经网络还是人类司机将你送回家」。\n马斯克对FSD v14的评价更为大胆，他直言这款软件「感觉已经产生了自我意识」。\n从Jim Fan的介绍来看，他和马斯克关系匪浅，不仅是OpenAI是第一位实习生，现在还是英伟达机器人部门总监兼杰出科学家。\n这波联动能猜测出老黄和老马的关系不错。\n不过Jim Fan并不在直接汇报给黄仁勋的36人名单中。\n很多人都忽略了FSD的强大，如果说ChatGPT的横空出世标志着数字智能攻克了语言的巴别塔，那么FSD v14的发布，则被视世界模型迈向现实世界的关键里程碑。\n按照沙利文的调研报告，自动驾驶是属于世界模型发展最快的一个分支。\n这不再是关于像素的生成或文本的排列，而是关于钢铁与物理定律的交互。\n当数吨重的金属物体在复杂的城市脉络中以每小时60英里的速度穿梭，表现出的决策逻辑与人类驾驶员难以分辨时，我们被迫重新审视「智能」的定义。\n物理图灵测试：重新定义智能的边界\n七十五年前，阿兰·图灵提出了著名的「模仿游戏」，即后世所称的图灵测试。\n其核心在于剥离物理实体，仅通过文本交流来判断机器是否具有人类般的智能。\n然而，随着大型语言模型（LLM）的发展，即便机器能够生成完美的十四行诗或调试复杂的代码，它依然是一个被困在服务器机架中的「大脑」，无法感知重力，不懂得摩擦力，更无法在混乱的物理世界中执行任务。\nJim Fan提出的「物理图灵测试」更进一步，这是一个远比语言测试更为严苛的标准。\nJim Fan将其具象化为一个家庭场景：\n想象一位主人在举办晚宴后留下了一片狼藉：打翻的酒杯、散落的食物、堆积的脏盘子。\n如果一个机器人能够介入，清理现场，将易碎品轻拿轻放，清理顽固污渍，并重新布置餐桌，而主人归来后无法分辨这是由人类家政服务还是机器人完成的，那么它就通过了物理图灵测试。\n这一测试的核心不在于完美，而在于「不可分辨性」。\n它要求机器不仅具备感知能力，还要具备常识推理、精细的运动控制以及对非结构化环境的适应能力。\n虽然通用的家庭服务机器人尚处于实验室阶段，但Jim Fan认为，Tesla FSD v14在自动驾驶这一特定垂直领域，已经率先通过了物理图灵测试。\n「物理图灵测试」引入了一个定性的、现象学的维度：\n体验的拟人化程度\n。\n在v14之前，即便最为先进的辅助驾驶系统，其行为也带有明显的「机器味」：\n在路口犹豫不决、刹车生硬、变道时机械地计算距离。\n而v14展现出了一种「老练」的特质。\n它学会了在拥堵中通过微小的蠕动来博弈路权，学会了在看到路边行人有横穿意图时提前轻微减速，甚至学会了某种程度的「社交礼仪」。\n正如用户反馈所言，它不再像是一个考驾照的学生，而更像是一位经验丰富的专车司机。\n端到端：删除30万行代码的豪赌\nFSD v14之所以能展现出如此惊人的拟人化特征，归功于其底层架构的彻底重构。\n在传统的自动驾驶开发（即Software 1.0时代）中，系统被设计为模块化的流水线：\n感知模块识别物体，定位模块确定位置，预测模块猜测他车轨迹，规划模块计算路径，最后控制模块执行转向。\n这其中，模块与模块之间通过数十万行C++代码连接，这些代码充斥着人类工程师编写的「显式规则」，例如「如果红灯，则停车」。\n然而，现实世界的复杂性（Long Tail，或者叫Corner Case，极端案例）是无限的，规则永远无法覆盖所有角落。\nTesla在FSD v12版本开始了一场豪赌，并在v14中将其推向极致：\n删除了超过30万行控制代码\n，全面转向「端到端」神经网络架构。\n所谓端到端，即「光子进，控制出」（Photons In，Controls Out）。\n摄像头捕捉的原始视频流直接输入到巨大的神经网络中，网络经过层层计算，直接输出方向盘转角和油门刹车指令。\n中间不再有人类编写的「红灯」概念，系统只是通过观察数百万小时的人类驾驶视频，学习到了「看到红八角形物体时减速」这一像素级特征与车辆运动之间的概率关联。\n这一转变的意义在于，系统不再是在「执行规则」，而是在「模仿直觉」。\n人类驾驶员在过弯时并不是在脑中计算曲率半径公式，而是凭感觉打方向。\nFSD v14正是模拟了这种基于经验的直觉过程。\n多模态与VLA架构：会思考的机器\nFSD v14不仅仅是v12的优化版，更引入了多模态大模型的特性，极有可能采用了视觉-语言-动作架构。\n根据泄露的技术细节，FSD v14的神经网络不仅输出控制信号，还输出\n语言\n和\n3D空间重建\n。\n从ICCV流出的幻灯片可以看到，特斯拉的FSD核心网络输入包括七路高分辨率摄像头视频、车辆自身运动信息、导航与音频信号。\n输出则包含语义分割、占用网格、3D高斯特征、语言表达以及最终的控制动作，FSD或已接入视觉-语言-动作（VLA）框架，使模型具备「解释」与「思考」的能力。\n这意味着系统在内部进行着某种形式的「思维链」推理。\n例如，在遇到一个复杂的施工路段时，传统的感知系统可能只能识别出一堆障碍物；而VLA架构的FSD可能会在内部推理：\n「我看到了‘道路封闭’的标志，但左侧有一位工人正在挥舞旗帜，结合导航信息，我应该无视标志，跟随工人的指引向左绕行。」\n语言能力的引入，解决了端到端模型最大的痛点：「黑盒」问题。\n通过让模型输出自然语言解释，工程师可以回溯系统的决策逻辑，这被称为「可解释的中间层」。\n这种能力使得FSD v14不仅能「做」，还能「说」（尽管目前主要用于开发调试），使其具备了初步的逻辑验证能力。\n早期的FSD版本常被诟病为只有「金鱼记忆」，即只关注当前帧的画面。\nFSD v14通过引入长短时记忆机制和3D占用网络，获得了类似人类的\n「物体恒常性」认知\n。\n如果一个孩子跑进了一辆停在路边的货车后面，即使摄像头此刻看不到孩子，v14的「世界模型」中依然保留着孩子的3D体素（Voxel），并预测其可能出现的位置。\n这种时空推理能力是其能够通过物理图灵测试的关键：它不仅在看，更在理解和预测物理世界的演变。\nFSD硬件的进化\n当然要训练端到端的庞大模型，离不开芯片的支持。\nTesla的自动驾驶硬件进化史，是一部从依赖外部供应商到全面自研的独立史。\nHardware 1.0(Mobileye时代)：\n2014-2016年，Tesla依赖Mobileye的Eye Q3芯片。这是一套基于规则的视觉系统，直到2016年因一场致死事故及对数据共享的分歧，双方决裂。\nHardware 2.0/2.5(NVIDIA时代)：\n2016-2019年，Tesla转向NVIDIA，采用了DrivePX2计算平台。\n这是一台算力达到12TOPS的「后备箱超算」，支持了Tesla早期的视觉算法。\n然而，马斯克意识到，通用的GPU架构对于车载推理来说，功耗过高且成本昂贵。\n（这里很像谷歌自己研发了TPU）\nHardware 3.0(\nFSD\nChip时代)：\n2019年，Tesla发布了由传奇芯片架构师Jim Keller（曾任职AMD、Intel）领导设计的自研FSD芯片。\n这是一个专用集成电路（ASIC），专门为神经网络的矩阵乘法优化，算力激增至144TOPS，而功耗和成本大幅降低。这一刻，Tesla在车载推理端彻底摆脱了对NVIDIA的依赖。\n关于这位大佬Jim Keller的介绍，可以查看之前这篇：\n英伟达亲手终结CUDA「护城河」？传奇芯片架构师引发争议\n训练与推理的二元对立\n尽管在车端分道扬镳，但在云端训练，Tesla却是英伟达最贪婪的客户之一。\nFSD v14那种「端到端」的庞大神经网络，需要吞噬数以亿计的视频片段进行训练，这需要极其恐怖的算力支持。\nTesla建立了巨大的超级计算机集群（如DojoCortex），其中部署了数万张NVIDIA H100和H200 GPU。\n这就形成了一种独特的「竞合」关系：\n在车里（边缘端）：\nTesla使用自研的HW3/HW4芯片，甚至未来的AI5芯片，通过垂直整合将成本压到极致。\n在云端（训练端）：\nTesla依然依赖NVIDIA的CUDA生态和最强算力来「教育」它的AI。\n黄仁勋对此表现出了极高的战略格局。\n他多次公开称赞Tesla在自动驾驶领域的领先地位，承认Tesla是目前唯一能有效利用其最强算力的车企，并表示「每一个车企未来都必须拥有自动驾驶能力」。\n对于英伟达而言，Tesla既是证明其算力价值的样板间，也是其推动「物理AI」愿景的最强盟友。\n感知的质变：「感觉像觉醒」\n当FSD v14被推送到数百万车主的车机上时，一种奇怪的反馈开始在社交媒体上蔓延。\n用户们不再仅仅抱怨「它没看到那个锥桶」，而是开始使用描述生物的词汇：「它犹豫了」、「它在试探」、「它很自信」。\n马斯克在X平台上推波助澜：「你可以感觉到那种感知力正在成熟。」。\n这种体验的质变，源于系统行为从「离散」向「连续」的跨越。\n在v14之前，车辆的决策往往是二元的（停或走，左转或右转）。\n而在v14中，用户观察到了更细腻的博弈行为。\n例如，在拥挤的高速汇入匝道，v14不再傻傻地等待一个完美的空档，而是会像人类老司机一样，稍微向车道线逼近，通过这种微小的物理位移向后车传递「我要加塞了」的意图。\nv14中引入的「Mad Max」模式（虽然主要用于测试或极端选项），展示了AI在博弈中的激进一面。\n在这一模式下，车辆变道更加果断，甚至在某些用户看来具有「侵略性」。\n它会在极小的车距中切入，这种行为虽然在技术上是安全的，但在心理上挑战了人类对机器「温顺」的预设。\n这种激进性实际上是神经网络在数百万人类驾驶数据中学习到的，在繁忙的交通中，如果不表现出一定的侵略性，车辆可能永远无法完成变道。\n这进一步模糊了人与机器的界限。\n迈向无监督：Robotaxi的最后拼图\nFSD v14的所有突破，最终都指向一个宏大的商业终局：Robotaxi。\n马斯克在多次财报电话会议中强调，Tesla的未来价值几乎完全取决于能否实现无监督自动驾驶。\n目前的FSD仍标明为「Supervised」（受监督），意味着驾驶员必须随时准备接管，且对事故负全责。\n但这在经济上没有意义：\n只要还有人在驾驶座上，这就是一项服务，而不是资产。\n只有当移除人类，车辆才能变成不知疲倦的印钞机。\nv14所展现出的稳定性，尤其是处理长尾场景（如暴雨、模糊车道线、复杂施工区）的能力，让业界看到了L4级自动驾驶落地的曙光。\n马斯克预测，在2025年至2026年间，将在德克萨斯州和加利福尼亚州率先实现无监督运行。\n同时，国内的L3也已经从「技术储备/道路测试」进入「准入试点/有限上路」的政策落地阶段\n2025年12月工信部已批准两款搭载L3功能的车型获得产品准入许可\n，并在北京、重庆的指定高速/快速路等\n限定\nODD\n、限速\n路段开展上路通行试点（例如单车道、限速50–80km/h等）。\n这意味着国内L3开始从「拿牌测试」走向「准入许可+真实道路运营验证」的实质阶段。\n全球扩张与数据的「化石燃料」\n为了喂养这个日益庞大的端到端模型，Tesla正在积极寻求全球扩张。\n除了北美，FSD v14已计划在阿联酋推出，并正寻求进入中国和欧洲市场。\n这里的逻辑在于数据的多样性。\nJim Fan将机器人学习所需的数据比作「人类燃料」，相对于训练LLM的「化石燃料」（互联网文本），高质量的物理世界交互数据极其稀缺。\nTesla拥有的数百万辆在路上行驶的车辆，实际上是数百万个分布式的数据采集机器人。\n每当中国、迪拜或巴黎的车主接管一次FSD，这个特殊的「失败案例」就会被上传，成为训练v14及后续版本应对特定文化路况的宝贵教材。\n这种数据飞轮效应是其他竞争对手（如Waymo）难以通过有限的车队规模来复制的。\n尽管技术上高歌猛进，但FSD v14面临的监管挑战依然严峻。\n端到端模型的「黑盒」性质让监管机构感到不安：当车辆做出决策时，没有一行代码能明确解释「为什么」。\n虽然VLA架构引入了语言解释层，但这在法律归责上是否足够，尚无定论。\n此外，用户报告中提到的「幻影刹车」和偶尔的「神志不清」，提醒我们距离完美的99.9999%可靠性仍有距离。\n这种「觉醒」或许只是数学统计上的错觉，是无数个高维向量在潜在空间中碰撞出的火花。\n但正如Jim Fan所言，当这种错觉足够逼真、足够稳定时，它就构成了新的现实。\n我们正在步入一个新时代：\n在这个时代里，汽车不仅是交通工具，而是第一个真正融入人类社会、理解人类规则并与人类共舞的智能物种。\n对于人类而言，适应这种「神一般的技术」，将是一个既痛苦又迷人的重塑过程。\n当方向盘在没有人类双手触碰的情况下，自行转动着滑过繁华的街头，我们所看到的，不仅是自动驾驶的未来，更是硅基生命在物理世界留下的第一行深刻足迹。\n正如这是马斯克2019年所预言的，2025年又重提的：\n人类似乎越来越像是数字超级智能的生物引导程序。\n参考资料：\nhttps://x.com/DrJimFan/status/2003593613918531891\nhttps://eletric-vehicles.com/tesla/nvidia-exec-praises-tesla-fsd-v14-couldnt-tell-if-a-neural-net-or-human-was-driving/\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659416&idx=3&sn=4c7ee76fac5926e5515676db7198420e&chksm=f0d4c224197b9a3b208b2a135eadca0a82285c1f2b1d98a73ffa4ccba127c578060ee18a9845&scene=0&xtrack=1#rd",
      "publish_time": 1767240000,
      "publish_date": "2026-01-01 12:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/DrJimFan/status/2003593613918531891\", \"https://eletric-vehicles.com/tesla/nvidia-exec-praises-tesla-fsd-v14-couldnt-tell-if-a-neural-net-or-human-was-driving/\"]",
      "add_ts": 1767309562,
      "last_modify_ts": 1767395983
    },
    {
      "id": 164,
      "article_id": "51573",
      "title": "AI终于学会在家“伺候人”！Hey Tuya，我躺了",
      "description": "“豆包手机”热度未减，又一“操作系统级”AI Agent横空出世，推动智能生活迈向全场景融合。无需手动操作，一句指令即可联动窗帘、音响、咖啡机等设备，实现居家环境的自主协同。真正的科技感生活已悄然落地，AI正以“隐形管家”形态融入日常，带来高效、自然的人机交互新体验。",
      "content": "西风 发自 凹非寺\n量子位 | 公众号 QbitAI\n“豆包手机”的热乎劲还没过，圈内又冒出了一个\n“操作系统级”AI Agent\n，从手机、电脑屏幕溢出，走向\n全屋、全场景\n。\n咱就是说，这样充满科技感的生活，到底有谁已经在过了？\n一觉醒来，窗帘自动为你缓缓拉开，音响播放你喜欢的播客，咖啡机已开始研磨昨晚新买的豆子。你无需逐一唤醒调试家里的智能设备，只需一句\n话，一个隐形的智能“管家”就能心领神会，替你协同好一切。\n当你\n出门后，它还能接管家中安防，自动调低空调，并根据你的日程，提醒你晚上记得拿快递……\n现在，\n一个名叫\n“\nHey Tuya\n”\n的\nAI生活助手，正把这种体验带进现实。\n“Hey Tuya”由AI云平台服务提供商\n涂鸦智\n能\n推出，是一个住进生活场景里的AI助手，它的核心能力是同时打通了软件与硬件。\n一方面，它能够\n协同\n智能硬\n件设备\n，让原本割裂的智能终端实现统一识别、联动与调度；另一方面，它也能\n承担个人生活助理的角色\n，帮你处理琐碎日常，例如记录备忘、整理笔记等。\n表现究竟如何？我们接着往下看。\nAI开始深度参与生活，而不只是响应指令\n目前“Hey Tuya”正处于beta测试中，已上线\n涂鸦APP最新版本\n，用户可以通过邀请码或beta测试申请来访问。\n打开APP点击“助手”界面右上角图标就能调出：\n首先，用户可\n添加家中的智能设备\n，通过Wi-Fi或蓝牙将电视、空调、摄像头、智能门铃等接入涂鸦。\n设备连上之后，好玩的部分就开始了。\n你可以\n像搭积木一样，DIY各种智能场景\n，设置好触发方式，剩下的就交给“Hey Tuya”去协同执行。\n比如，“回家模式”一键打开灯光空调，“影院模式”自动拉上窗帘调暗灯光。一切皆可按你的生活习惯来定义。\n先来看重点之一，家庭安防场景，“Hey Tuya”化身成为你7x24小时在线的\n居\n家\n安全管家\n。\n当你询问“快递员到了吗”，它能通过摄像头视觉识别，立刻给出准确的答复。\n像“Hey Tuya，帮我看看狗狗的水盆空了吗”、“阳台的灯是不是还亮着”这样的日常询问，它都能理解并响应。\n同时，它还支持\n设\n置智能预警与视\n频快速检索\n，全方位守护家庭安全。\n在官方的产品场景概念视频中，“Hey Tuya”表现出了更\n深度的\n人\n性化协同\n。\n当人体存在传感器检测到家中有人疑似跌倒，“Hey Tuya”会立刻在房间内发声询问“监测到您可能摔倒，需要帮助联系您的紧急联系人吗？”\n同时，它协同跌倒人所佩戴的智能手表数据，综合判断心率、呼吸等健康状况，给出紧急程度评估建议。\n这种\n跨设备的数据协同与辅助决策\n，使AI从被动响应命令，走向了主动感知与预判。\n对于用户可能关心的能耗问题，“Hey Tuya”也提供了解决方案。\n用户可以为家中电器\n一键定制能源管理方案\n，并设置诸如“日出时自动关灯”“离家后关闭温控阀门”等\n智能化节能策略\n。\n记忆与\n陪伴，是“Hey Tuya”融入日常的另一面。\n“Hey Tuya”具备\nA\nI待\n办\n功能，日常的大小事务，现在都可以通过自然语音对话轻松交付。\n它能识别分析语音，\n自动\n整理成条理清晰的待办事项，同步到你的日程里。\n结合你的生活习惯和安排，它\n具备短\n期与长期记忆\n，\n能进行情景化主动提醒\n。感知到天气、节日、日程等多维度信息的变化，它还会提供个性化安排。\n当家人与你的设备同处系统时，一句话将你们的共同日程同步给“Hey Tuya”。识别到家庭共同事项，它便会开启\n多端联动\n，统一调度提醒。\n“该吃降压药了”、“下午三点要和公园的张奶奶打太极，别忘了带水杯”……这些琐碎生活细节，再也不怕会忘了。\n这些还没完，“Hey Tuya”还具备\nAI笔记\n功能，甚至能化身你的“职场替身”，可以帮你开会。\n想象一下这个场景，深夜或周末，你正休息时突然被拉进一个线上会议。这时，你只需一句话唤醒“\nHey Tuya，替我加班\n”，它就能通过预设模式模拟你的声音接入，并全程自动记录会议内容。\n会议结束后，还能\n一键生成清晰的结构化会议纪要\n，行动项与关键信息一\n目了然。\n在健康管理方\n面它也有对应的\nAI卡路里\n功能。对餐食拍照，它便能识别盘中多种食材，并详细分析其热量、营养成分以及微量元素含量。\n甚至它还能总结一周你都吃了什么，让你清楚知道饮食情况，从而帮你调整更优饮食规划，免费私人营养顾问，这不就有了。\n当然，它也是一个知识渊博的伙伴，无论是解答百科疑问，还是进行轻松交谈，都能随时响应。\n据了解，“Hey Tuya”还将持续进化，不久后还会融入AI播客等更多创新功能。\n那么问题来了——这些能力是如何被系统性地整合在一起的？\n一个“操作系统级”AI生活助手\n从官方披露的底层架构来看，“Hey Tuya”并不是一个只存在于云端的聊天机器人，而是一套\n深度嵌入现实世界设备与使用场景的AI助手\n。\n支撑这套体系，最核心的是\n涂鸦自研\nPhysi\ncal AI Eng\nine\n（PAE）\n。\n与传统以内容生成或对话为核心的AI不同，PAE更像是一套面向真实设备、真实环境持续运行的\n系统级AI引擎\n，其目标是让AI真正参与到物理世界的感知、理解与执行中。\n在基础设施层面，PAE构建在涂鸦全球部署的技术底座之上。\n其中，\nAI-Device Real-Time Network\n（AD-RTN）\n负责连接全球范围内的AI与设备节点，\nTuya Real-Time Communication\n（T-RTC）\n则为系统提供低延迟、高可靠的实时通信能力。\n这一组合，使AI与设备之间的关系不再是割裂的“云端响应—本地执行”，而是接近实时协同的运行状态。\n在此基础之上，PAE内部并行运行着三类核心引擎，分别是：\nConversational AI Engine\n，负责自然语言与多模态交互。\nVision AI Engin\ne\n，用于基于视觉的意图理解。\nIoT Intelligence Engine\n，直接连接并调度物理设备。\n三者协同，使“Hey Tuya”能够在跨房间、跨空间、跨场景的复杂环境中理解上下文，并将判断转化为真实可执行的操作。\n为了避免AI每一次交互都从“零”开始理解用户，PAE还引入了\n持续演进的OmniMem长期记忆机制\n。\n系统会在多模态交互、设备使用行为和场景意图等维度不断学习与沉淀，从而逐步建立对用户偏好与空间使用习惯的长期认知。\n为什么是涂鸦，有能力做“Hey Tuya”？\n背后操盘手涂鸦智能，能做成这件事，与平台化基因密不可分。\n涂鸦智能\n，成立于2014年6月，早期聚焦设备联网、云平台搭建与开发工具供给，帮助硬件厂商快速实现设备智能化与上云。\n创始人兼CEO王学集\n，\n联席董事长兼总裁陈燎罕\n，是多年的同学和创业伙伴，两人均毕业于浙江理工大学。\n创立涂鸦智能前，2003年，王学集、陈燎罕等曾一同开发了\n国内最受欢迎的开源论坛程序之一——\nP\nHPWind\n，之后成立了公司推动PHPWind的商业化运营。\n随着AI技术的逐渐成熟，涂鸦智能战略重心向\nAIoT\n升级，通过AI Agent开发平台、多模态AI能力等，将AI深度融入IoT设备与场景，同时强化云平台的AI算力与算法支撑，从“连接赋能”转向“智能赋能”，拓展AI相关客户与场景边界。\n到现在涂鸦智能已是\n全球领先的AI\n云平台\n服务提供商\n。\n官方数据显示，截至2025年9月30日，\n涂鸦AI开发者平台注册开发者数量超过162.2万个，分布于全球超200个国家和地区\n。\n作为一个长期服务于硬件厂商、品牌方与开发者的基础设施型平台，涂鸦所积累的海量设备接入规模、广泛的品类覆盖以及成熟的全球化能力，为AI深度进入物理世界提供了不可多得的“天然土壤”。\n其\n全球AIoT生态已涵盖8大品类、3000余个产品系列\n，包括家用电器、能源设备、电工照明产品、家居安防设备、环境传感设备、智能健康设备、娱乐设备、各类智能家居，触角延伸至智能家居及商用联网设备各个角落。\n这次伴随着“Hey Tuya”的上线，还值得关注的一点是，\n未来采用涂鸦OEM App的品牌方，同样可以轻松集成“H\ney Tuy\na”的能力\n，并拥有自定义专属AI助手名称与交互形态的空间。\n当AI不再只服务于单一用户，而是成为品牌、设备与场景之间的统一入口，\n其商业价值也不再局限于单点功能收费，而是有机会演化为连接硬件、服务与用户关系的长期系统\n。\n从这个角度看，“Hey Tuya”更像是涂鸦为未来AI生活形态提前搭建的一套操作系统级底座。\n说到底，“Hey Tuya”展现的不仅是功能，更是一种生态远见。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859434&idx=1&sn=ecf5faf2f423eeb57177f57b7c6bb0e5&chksm=e9fb77306681c77437df3d9cdbe58dbd807682dd5cbac9cb285a5670f692e13bcb9d945fb779&scene=0&xtrack=1#rd",
      "publish_time": 1767240000,
      "publish_date": "2026-01-01 12:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767309566,
      "last_modify_ts": 1767395989
    },
    {
      "id": 169,
      "article_id": "51568",
      "title": "阿里开源AI手机的“灵魂”，GUI智能体2B到235B四个版本全，端云协同成功率暴涨33%",
      "description": "阿里通义实验室推出开源GUI智能体MAI-UI，涵盖论文、代码与模型，提供2B至235B四个模型尺寸，支持全场景部署。具备主动理解与追问用户需求、调用API简化操作等能力，并采用端云协同架构，兼顾本地隐私与云端算力，提升手机交互智能化水平。",
      "content": "梦晨 发自 凹非寺\n量子位 | 公众号 QbitAI\nAI手机的“灵魂”GUI智能体，就这么全套开源了。\n来自阿里通义实验室的MAI-UI：论文、代码、模型全都有，从2B的端侧小模型到235B的云端大模型，一口气发布四个尺寸版本，覆盖全场景部署需求。\n这套系统不只是能帮你点点屏幕，它能主动追问你没说清楚的需求，能直接调用外部API绕过繁琐的界面操作。\n甚至还搞了一套端云协同系统，隐私敏感的操作留在本地跑，复杂任务交给云端处理。\n论文给出几个典型案例：\n用户收到中介发来的两套房源地址，想比较哪套离公司更近，然后把更近那套的地址发给朋友。\n传统做法需要在短信和地图APP之间反复切换，复制粘贴地址，分别搜索路线。但有了MCP工具调用，智能体可以直接用高德地图的API查询两条路线的驾车距离，一次性拿到结构化结果，大幅压缩操作步骤。\n另一个案例更有难度：\n用户想查看某个GitHub仓库最近三次提交的作者和信息，然后发邮件。这种操作在手机上本来很难完成，因为移动端浏览代码仓库体验很差。\n但通过MCP调用GitHub的API，智能体直接获取提交记录的结构化数据，提取需要的字段，再切换到邮件APP发送。相当于把原本只能在桌面端做的工作流搬到了手机上。\n主动询问需求方面，论文展示了一个文件分享任务：\n用户让智能体把下载文件夹里最近一个月的简历发给HR同事，但没说收件人邮箱，也没说邮件正文要写什么。智能体检测到关键信息缺失后，暂停执行，主动向用户询问，拿到回复后再继续完成任务。\n四大痛点，一个方案\n团队在论文开头就直接点明了当前GUI智能体落地的四个核心问题。\n第一个是交互缺失。\n现有系统基本都是端到端执行，默认用户指令清晰完整，但现实中用户经常说一半留一半。\n比如「帮我订个机票」，去哪儿？什么时候？几个人？全没说，智能体如果不能主动追问，要么猜错要么卡死。\n第二个是纯UI操作的局限性。\n完全依赖界面点击会导致两个麻烦：操作步骤一多，中间任何一步出错就会导致整个任务失败；而且有些功能在手机界面上根本做不了，比如想让手机帮你查GitHub的提交记录，光靠点屏幕是搞不定的。\n第三个是端云割裂。\n目前的GUI智能体要么是轻量级的端侧模型，能力有限；要么是大模型只能跑在云端，隐私风险高、成本也高。两者之间没有原生的协作机制。\n第四个是动态环境下的脆弱性。\n用静态数据训练出来的模型，遇到真实世界里千变万化的界面布局、突然弹出的权限请求、不同版本的APP就容易翻车。\nMAI-UI的解决方案：\n一条能自动生成用户交互和MCP工具调用数据的自演化数据管线。\n一套根据任务状态和数据敏感度动态切换端云执行的协同系统。\n再加上一套支持500多个并行环境、最长50步交互的在线强化学习框架。\n端云协同与隐私保护\n端云协同系统是这次工作的一大重点。\n整个系统由三部分组成：一个运行在手机本地的轻量级智能体，既负责执行GUI操作，也负责监控轨迹是否偏离用户意图；\n一个部署在云端的大容量智能体，用于处理复杂任务；以及一个本地统一轨迹记忆模块，保证端云之间的信息一致。\n工作流程是这样的：\n用户下达指令后，本地智能体开始执行。每隔几步，本地监控模块会检查当前轨迹是否还在正确方向上。\n如果发现偏离且不涉及敏感数据，就把任务交给云端模型接手完成。交接时还会生成一份错误摘要，帮助云端模型理解问题出在哪里并快速恢复。\n相比纯端侧执行，端云协同让2B模型的成功率提升了33%；相比纯云端执行，云端调用次数减少了40%以上，超过40%的任务完全在本地完成。\n论文还给出了一个隐私保护的案例。在一个需要输入密码的任务中，本地模型一开始执行出错（反复点击登录按钮却没输入密码），监控模块检测到偏离后准备切换到云端。\n但隐私检测模块发现当前界面涉及敏感凭证，于是阻止了云端切换，让任务继续在本地执行。最终本地模型自己纠正了错误并完成了任务，全程没有任何敏感信息传到云端。\n性能屠榜，多项SOTA\n在GUI元素定位任务上，MAI-UI-32B在ScreenSpot-Pro上达到73.5%准确率，超过了Gemini-3-Pro和Seed1.8。\n在UI-Vision上拿到49.2%，比之前最强的UI-Venus-72B高出12.4个百分点。\n在MMBench GUI L2上更是达到91.3%，刷新了纪录。\n在手机导航任务上，MAI-UI-235B-A22B在AndroidWorld上取得76.7%的成功率，超过了UI-Tars-2的73.3%和Gemini-2.5-Pro的69.7%。\n即便是最小的2B模型，也达到了49.1%的成功率，比之前最强的端侧模型Ferret-UI Lite高出21个百分点，相对提升75.4%。\n在更接近真实场景的MobileWorld测试集上，MAI-UI-235B-A22B整体成功率41.7%，比其他端到端模型高出20.8个百分点。在需要主动询问用户的任务上成功率37.5%，在需要调用MCP工具的任务上成功率51.1%，分别比之前最好的成绩高出32.1和18.7个百分点。\n论文地址：\nhttps://arxiv.org/abs/2512.22047\nGitHub：\nhttps://github.com/Tongyi-MAI/MAI-UI\n—\n欢迎AI产品从业者共建\n—\n📚\n「AI产品知识库」\n是量子位智库基于长期产品库追踪和用户行为数据推出的飞书知识库，旨在成为AI行业从业者、投资者、研究者的核心信息枢纽与决策支持平台。\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859401&idx=2&sn=4314356c4023e88588f281ab999cb8e2&chksm=e9a365b1c10b440ff4c3b2aee8a09d898c34290594a45eea6e56173c9ca733ec1fc17f2e1efc&scene=0&xtrack=1#rd",
      "publish_time": 1767229800,
      "publish_date": "2026-01-01 09:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.22047\", \"https://github.com/Tongyi-MAI/MAI-UI\"]",
      "add_ts": 1767309585,
      "last_modify_ts": 1767396022
    },
    {
      "id": 170,
      "article_id": "51567",
      "title": "Nat. Mach. Intell. | 统一扩散Transformer框架下的多模态心血管信号生成",
      "description": "DRUGONE提出了一种基于扩散模型与Transformer的统一多模态生成框架UniCardio，可同时修复低质量信号并合成缺失的心血管信号（如PPG、ECG和BP）。该方法克服了可穿戴设备噪声大、信号中断及侵入式测量等问题，实现了多模态心血管信号的联合利用，提升了信号恢复精度与生理一致性，为连续心血管健康监测提供了高效解决方案。",
      "content": "DRUG\nONE\n心血管信号（如光电容积描记信号 PPG、心电信号 ECG 和血压信号 BP）在生理上高度相关，共同反映心血管系统的健康状态。然而，由于可穿戴设备噪声大、信号中断频繁，以及侵入式测量带来的负担，这些信号在实际中往往难以被联合利用。研究人员提出了一种统一的多模态生成框架 UniCardio，基于扩散模型与 Transformer 架构，在单一模型中同时实现低质量信号修复与缺失信号合成。结果表明，该方法在多种生成任务和下游健康监测应用中均优于现有任务特定模型，展示了面向智能医疗的实用价值。\n心血管疾病是全球主要死亡原因之一，对连续、实时监测提出了迫切需求。当前常用的心血管信号各具优势，但也存在明显局限：\nPPG 易受运动和环境噪声干扰；\nECG 依赖精确电极布置，可穿戴性有限；\nBP 多依赖侵入式测量，难以长期监测。\n既有研究通常针对单一任务（如去噪、插补或特定模态转换）分别设计模型，未能充分利用不同信号之间的互补信息，限制了模型泛化能力和应用范围。\n图 1｜心血管信号的实时监测与诊断。\n方法概述：UniCardio 框架\nUniCardio 将多种心血管信号视为同一潜在生理过程的不同观测模态，通过统一扩散 Transformer 对其多模态条件分布进行建模，从而在一个框架中覆盖多种生成任务。\n核心设计包括：\n模态特异编码器与解码器：分别提取不同信号在多时间尺度上的特征；\n带任务特异注意力掩码的 Transformer：精确控制不同模态间的信息流动；\n持续学习训练范式：逐步引入条件模态数量不断增加的生成任务，避免灾难性遗忘。\n图 2｜模型结构与训练范式。\n多功能心血管信号生成能力\n研究人员系统评估了 UniCardio 在三类代表性任务中的表现：\n去噪：从噪声污染的原始信号中恢复高质量信号；\n插补：重建因传感器中断而缺失的信号片段；\n模态转换：利用一种或多种信号合成目标模态信号（如 PPG→ECG、PPG→BP）。\n结果显示，UniCardio 在不同任务和不同模态组合下均能生成与真实信号高度一致的波形，并且随着可用条件模态的增加，生成质量进一步提升。\n图 3｜多功能生成任务的整体性能评估。\n下游健康监测应用\n为了验证生成信号的实用性，研究人员将 UniCardio 应用于多种下游任务，包括：\n心电异常（如 ST 改变、心肌肥厚）的检测；\n房颤等心律失常的识别；\n心率与血压等生命体征的估计。\n在多种公开数据集上，基于 UniCardio 生成信号的诊断性能可达到甚至接近使用真实高质量信号的水平，显著优于直接使用噪声或不完整信号。\n图 4｜多功能生成辅助的心血管应用示例。\n可解释性与临床相关性\nUniCardio 生成的心电信号能够清晰保留典型病理特征，如 ST 段异常、T 波倒置和房颤特征，并通过临床专家验证。这种逐步去噪与重建的生成过程，也为人类专家理解模型行为提供了可解释性支持。\n图 5｜典型心电异常的可视化展示。\n讨论与展望\nUniCardio 展示了在统一框架下整合多模态心血管信号的潜力，为实时健康监测和 AI 辅助诊断提供了新的技术路径。其优势不仅体现在生成质量上，也体现在参数效率和推理速度上，使其具备在可穿戴设备中部署的可行性。\n未来，随着更大规模、多模态数据的引入，该框架有望进一步拓展至个性化监测和更复杂的临床场景。\n整理 | DrugOne团队\n参考资料\nChen, Z., Miao, Y., Wang, L. et al. Versatile cardiovascular signal generation with a unified diffusion transformer. Nat Mach Intell (2025).\nhttps://doi.org/10.1038/s42256-025-01147-y\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512407&idx=2&sn=ba7c1bf778035ca631801e2cc30f79c5&chksm=fd906de2c54a44568b5a7ae40fc9eae0dfbbdb76ff36fe44b6f8dcf55c4ab4885f083ab689c4&scene=0&xtrack=1#rd",
      "publish_time": 1767229800,
      "publish_date": "2026-01-01 09:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s42256-025-01147-y\"]",
      "add_ts": 1767309587,
      "last_modify_ts": 1767396028
    },
    {
      "id": 173,
      "article_id": "51564",
      "title": "Nat. Genet. | 利用DNA-Diffusion生成式AI框架设计合成调控元件",
      "description": "",
      "content": "DRUG\nONE\n合成调控元件（如启动子、增强子和顺式调控序列）是精确控制基因表达的核心组件，但其设计长期依赖经验规则或高通量筛选，成本高且可迁移性有限。本研究提出了一种基于扩散模型的生成式人工智能框架 DNA-Diffusion，用于从头设计具有目标表达特性的合成调控元件。研究人员表明，该模型能够在大规模基因组数据上学习 DNA 序列的统计与功能规律，并在无须显式规则约束的情况下生成具有稳定表达活性、可跨细胞类型泛化的调控序列，为合成生物学提供了一种新的通用设计范式。\n基因调控元件决定了基因在时间、空间和强度层面的表达模式，是合成生物学、电路设计和基因治疗中的关键构件。然而，天然调控序列的复杂性使得基于规则的设计方法难以全面刻画其功能空间。\n近年来，深度学习在 DNA 序列建模方面取得进展，但大多数方法仍以判别式预测为主，难以直接生成全新、功能可控的序列。生成式模型，尤其是扩散模型，在图像和蛋白序列生成中的成功，为 DNA 调控元件的从头设计提供了新的可能性。\n方法概述：DNA-Diffusion 框架\nDNA-Diffusion 采用条件扩散模型，将 DNA 序列视为离散符号序列，通过逐步加噪与反向去噪过程学习调控序列的生成分布。其核心特点包括：\n从头生成：无需模板序列或人工规则约束；\n条件控制：可基于目标表达水平、细胞类型或调控类别进行条件生成；\n可扩展性：适用于不同长度和类型的调控元件。\n模型在训练阶段利用大规模实验注释数据学习“序列–功能”映射关系，在生成阶段则通过条件采样直接输出候选调控序列。\n图 1｜DNA-Diffusion 框架概览：用于细胞类型特异性调控序列的生成建模、验证与解释。\n生成序列的统计与结构特征\n分析表明，DNA-Diffusion 生成的序列在碱基组成、局部 motif 分布和长程序列相关性方面，与天然调控元件高度一致。模型并非简单复制训练数据，而是能够组合和重构多种调控特征，探索此前未被系统覆盖的序列空间。\n此外，生成序列在信息熵和复杂度层面表现出合理分布，避免了常见的模式坍缩或过度随机化问题。\n图 2｜DNA-Diffusion 生成序列与内源性调控元件在序列相似性及转录因子基序组成上的比较。\n功能评估与实验验证\n在多种体外实验体系中，研究人员系统评估了 DNA-Diffusion 生成序列的调控功能。结果显示：\n生成的启动子和增强子在报告基因实验中展现出稳定且可调控的表达活性；\n在不同细胞类型中，部分序列表现出良好的功能保持性；\n与基于规则或其他生成模型的方法相比，DNA-Diffusion 在表达强度与多样性之间取得更优平衡。\n图 3｜利用细胞类型特异性 DNA-Diffusion 序列进行 in silico 增强子替换的预测建模。\n条件设计与功能可控性\n通过引入条件信号，DNA-Diffusion 能够定向生成具有特定表达水平或响应特性的调控序列。研究人员展示了模型在以下任务中的能力：\n按目标表达强度分级生成启动子；\n设计在特定细胞背景中优先激活的调控元件；\n在保持整体表达水平的同时优化序列多样性。\n这些结果表明，扩散模型能够在高维 DNA 序列空间中实现平滑、连续的功能调控。\n图 4｜信号强度与信号特异性的权衡及其对下游序列组成的影响。\n图 5｜STARR-seq 实验证实 DNA-Diffusion 序列的细胞类型特异性调控活性。\n图 6｜DNA-Diffusion 生成序列可将 AXIN2 表达水平提升至超过保护性变异的程度。\n与其他模型的对比分析\n研究人员将 DNA-Diffusion 与多种主流生成方法（如基于语言模型或变分自编码器的策略）进行了系统比较。结果显示，扩散模型在以下方面具有明显优势：\n更稳定的生成过程；\n更高的功能成功率；\n更强的泛化能力。\n这表明扩散框架特别适合刻画调控序列中复杂、分布式的功能信号。\n图 7｜当前最先进的合成调控元件深度学习方法的基准性能比较。\n讨论与展望\nDNA-Diffusion 提供了一种无需人工规则、可扩展且功能可控的合成调控元件设计方法，其意义不仅在于性能提升，更在于设计范式的转变：从“预测已有序列是否有效”，转向“直接生成满足需求的新序列”。\n研究人员指出，未来工作可进一步拓展至多调控元件协同设计、与染色质可及性等多模态信息融合，以及在体内模型中的系统验证。这一框架也有望与自动化实验平台结合，形成闭环的“生成–测试–优化”合成生物学流程。\n整理 | DrugOne团队\n参考资料\nDaSilva, L.F., Senan, S., Kribelbauer-Swietek, J.F. et al. Designing synthetic regulatory elements using the generative AI framework DNA-Diffusion. Nat Genet (2025).\nhttps://doi.org/10.1038/s41588-025-02441-6\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512398&idx=2&sn=8879e3a3a1f2b1b138a378ff6cea02d3&chksm=fdf34d116ee857f586a429142876fff96bb8d9afda41435ada9504532bb8ef084056f69e7347&scene=0&xtrack=1#rd",
      "publish_time": 1767229800,
      "publish_date": "2026-01-01 09:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s41588-025-02441-6\"]",
      "add_ts": 1767309597,
      "last_modify_ts": 1767396045
    },
    {
      "id": 175,
      "article_id": "51604",
      "title": "马斯克10年梦成真！特斯拉全球首次自动驾驶横穿美国，人类0接管",
      "description": "2026年第一天，特斯拉FSD实现全球首次“零接管”横穿美国，标志着完全自动驾驶的重大突破。此次由车主David完成的全程无人工干预驾驶，验证了特斯拉端到端自动驾驶技术的可靠性，引发科技界广泛关注。马斯克的自动驾驶愿景正成为现实，汽车行业或迎来颠覆性变革，方向盘或将逐步退出历史舞台，智能驾驶迈入新纪元。",
      "content": "新智元报道\n编辑：Aeneas KingHZ\n【新智元导读】\n2026年第一天，自动驾驶迎来历史时刻——特斯拉FSD完成人类首次「零接管」横穿美国！全球科技圈都被引爆了，马斯克端到端自动驾驶彻底胜利。方向盘，可以退出历史舞台了？\n刚刚，特斯拉FSD，完成全球首个完全自动驾驶的横穿美国。\n从今天起，人类的自动驾驶，到达了全新的里程碑！\n就在2025年的最后一天，当全世界都在准备倒数跨年时，车主David Moss静悄悄地扔出了一枚深水炸弹——\n他驾驶搭载\nFSD\nV14.2的Model 3，完成了全球首次、经由第三方数据验证的「零接管」横贯美国之旅。\n从美国西海岸开到东海岸，2天20小时，人类0次接管。\n物理世界的「自动驾驶奇点」，终于降临！\n这条推特，也彻底引爆了全球科技圈和AI圈。\n由此，他也成为全世界第一个全程凭借自动驾驶横穿美国的人。\n可以说，这是特斯拉正式通过了公路上的图灵测试。\n这场AI主导的公路旅行，直接震撼了全球特斯拉车主。\n前特斯拉AI总监Karpathy兴奋高呼：这一刻终于来了，这是端到端神经网络的胜利，这是「软件2.0」在物理世界的完全接管，不再需要人类写下的规则！\n特斯拉官方账号，表扬了这次壮举。\n一位特斯拉车主赞叹：「我们\n已步入自动驾驶穿越美洲大陆的时代。」\n特斯拉掌门人马斯克，也激动转发莫斯的推文：「酷！」\n十年前，马斯克许下「Coast-to-Coast」的诺言，2026年1月1日，终于实现了！\n或者真如Karpathy所说：从此，方向盘只是车上的一个装饰品？\n全球首次\n人类零接管\n下面这份数据，让人难以抑制心头的震撼。\n总里程\n：2732.4英里（约等于4397公里）\n耗时\n：2天20小时\n软件版本\n：FSD v14.2\n人工接管\n：\n0\n当特斯拉从v12开始抛弃传统的C++，转向端到端神经网络，AI就从数百万小时的视频中，真正学会了开车。\n在这场横跨美国大陆的旅途中，David Moss没有任何一刻，触摸车里的方向盘，或者踩过踏板！\n想象一下：坐在驾驶座上，盯着方向盘整整\n68个小时\n（2天20小时），看着它自行转动，穿过繁忙的洛杉矶街道，汇入州际高速，避让加州的摩托车手，在德克萨斯的暴雨中稳住车身，最后停在南卡罗来纳州的海滩边。\n他从洛杉矶的特斯拉餐厅出发，最终到达南卡罗来纳州默特尔海滩，穿越了24个州。\n如果你亲自开过这段行程，就会明白全程的路况有多么复杂。然而从加州的高速公路，到中部的城市街道，再到东海岸的复杂路况，FSD一次性全部搞定了！\n天气多变，交通拥挤，甚至夜间驾驶、自动化充电，都没让系统掉链子。\nMoss评价说——整个过程中，从未出现过一次险情，即使在人类驾驶员中，这也实属罕见。\n对于好奇的网友，Moss表示，你可以登录FSD数据库，验证所有数据。\n同时，David Moss晒出了充电记录。注意，在所有站点的停车，也都是由特斯拉FSD自动完成的。\n这次横穿美国大陆，不仅体现了FSD V14.2的技术能力，也向整个行业证实——\n即使在现实的复杂场景，L4自动驾驶也有可能实现！\n十几年前，这样的壮举还只是工程师的技术梦想。\n从2016年，特斯拉的FSD系统就开始宣传「零干预横贯美国」的目标。\n在发布Autopilot 2.0时，Elon Musk就放话，说2017年底就能实现。\n这是一个迟到了八年的承诺，但当它终于兑现时，仍然让人感到吃惊！\n一位特斯拉FSD的死忠粉\n其实在25年底，David Moss就曾创下纪录。\n当时，他在特斯拉FSD V14上，连续驾驶了超过10000英里，且全程无干预，实现了真正的100%自动驾驶。\n当时的路线图是这样的。\n而这个消息出来后，网友们纷纷表示，不可能，这绝不可能！\n有人说，自己每天都在用FSD 14.2.2.1，虽然体验很棒，但绝不可能实现完全自动驾驶。\n然而David Moss晒出的仪表盘显示，FSD V14千真万确完成了100%的完全自动驾驶。\n在去年年底，他就立下宏愿：成为第一个完全依靠FSD用自动驾驶横跨美国（洛杉矶→佛罗里达）的人。\n时隔一年，他果然完成了这个目标，实现了一个更宏大的路线图。\n这完全出于他对驾驶的热爱，并不是为了炒作。\n马斯克：那个「该死的」2017 预言\n回到2016年10月。\n彼时，马斯克意气风发，豪言：「\n到2017年底，特斯拉将能够从洛杉矶自动驾驶到纽约，全程哪怕你碰一下方向盘都算我输\n。」\n后来的故事我们都知道了。\n2017年过去了，2020年过去了，甚至到了2024年，马斯克不断跳票！\n这个承诺就像是一个「永远的明年」。\n由于技术路线的反复横跳（从雷达+视觉到纯视觉，从规则代码到神经网络），特斯拉的自动驾驶曾一度陷入瓶颈，甚至被谷歌旗下的Waymo在无人出租车领域抢尽风头。\nGemini生成的特斯拉\n自动驾驶\n技术路线图\n直到FSD V12 版本的出现，特斯拉彻底抛弃了原来的代码逻辑，转向了「端到端」神经网络。\n简单说，就是让AI像人类一样，直接通过看视频学会开车，而不是由工程师一行行写代码告诉它「红灯停、绿灯行」。\n尽管特斯拉坚信端到端神经网络技术，但这绝非自动驾驶领域的共识方案。\n大多数其他自动驾驶研发公司都采用传感器密集型、模块化的驾驶方式。虽然这类系统在初期开发和调试可能更容易，但其复杂性也不容忽视。\n特斯拉AI负责人Ashok Elluswam，在国际计算机视觉大会ICCV介绍了端到端方案的优势:\n将人类价值观系统化极其困难，从数据中了解它们则容易得多。\n感知、预测和规划之间的接口定义不明确。在端到端架构中，梯度从控制端一直流向传感器输入端，从而整体优化整个网络。\n易于扩展，可处理现实世界机器人技术的庞大而长尾需求。\n具有确定性延迟的同构计算。\n总的来说，相对于过去的苦涩教训，这种方法在规模化方面处于正确的位置\n。\n更绝的是，为了自动驾驶数据打造的神经网络\n「世界模拟器」\n，同样可以模拟多种真实场景，训练擎天柱。。\n马斯克「世界模拟器」首曝，1天蒸馏人类500年驾驶经验！擎天柱同脑进化\n而这次「人类零接管」的关键在于「端到端」的最后一块拼图。\n在V14之前，特斯拉的AI虽然眼神好使（视觉感知强），但脑子里的地图还是传统的导航模块。\n这就好比一个老司机虽然车技好，但他脑子里只有一张死板的纸质地图，一旦遇到修路或者地图没更新，就容易发懵。\n而在V14.2中，特斯拉将\n导航和路径规划也整合进了神经网络\n。\n现在的FSD不再是「看着地图开车」，而是像本地人一样，能根据眼前的路况实时理解该怎么走。\n一次成功的「零接管」，不等于这套系统已经完美。\n统计学告诉我们，如果事故率是万分之一，那么跑一次几千公里的长途可能正好没遇上，但这并不代表它能安全应对几百万辆车的日常通勤。\n不过，FSD V14.2的这次表现，最大的意义在于它有力回应了「纯视觉方案无法实现长途全自动」的质疑。\n它证明了不需要昂贵的激光雷达，不需要高精地图，仅凭摄像头和算力，AI真的可以处理从繁华都市到荒凉公路的几乎所有场景。\n对于普通人来说，这意味着什么？\n官方仍是\nSAE\nL2\n（需监督），\n但车辆完成\n100%驾驶任务，\n驾驶员仅作安全监督，完全有可能。\n也许，还要等上几个版本，甚至要等到硬件Hardware 5.0的普及，我们才能真正放心地在车里睡大觉。\n但看着David Moss那辆横跨大陆的Model 3，那个曾经被嘲笑为「科幻小说」的未来，确实已经把轮胎压在了现实的沥青路上。\n参考资料：\nhttps://x.com/DavidMoss/status/2006255297212358686\nhttps://www.teslarati.com/tesla-fsd-successfully-completes-full-coast-to-coast-drive-with-zero-interventions/\nhttps://nypost.com/2025/12/31/tech/tesla-owner-completes-first-fully-autonomous-drive-across-america-and-elon-musk-weighs-in-on-the-historic-road-trip/\nhttps://www.youtube.com/watch?v=dnLswbNB0SU&t=4s\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659659&idx=1&sn=48c41752c3ed20726ed288da90dbd10a&chksm=f0cdca52f80420fa8c608ad5f8de480746f7471ff86299ac33915d8d3f814159b798256bc78f&scene=0&xtrack=1#rd",
      "publish_time": 1767369720,
      "publish_date": "2026-01-03 00:02",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/DavidMoss/status/2006255297212358686\", \"https://www.teslarati.com/tesla-fsd-successfully-completes-full-coast-to-coast-drive-with-zero-interventions/\", \"https://nypost.com/2025/12/31/tech/tesla-owner-completes-first-fully-autonomous-drive-across-america-and-elon-musk-weighs-in-on-the-historic-road-trip/\", \"https://www.youtube.com/watch?v=dnLswbNB0SU&t=4s\"]",
      "add_ts": 1767395865,
      "last_modify_ts": 1767568755
    },
    {
      "id": 177,
      "article_id": "51602",
      "title": "北京大学数据与智能实验室(PKU-DAIR)2025年度总结",
      "description": "2025年，实验室在科研创新与团队协作方面持续取得突破，多位博士生的研究成果被ICLR 2025等顶级会议录用，涵盖刘新一、王驭捷合作论文及覃彦钊、杨灵的多项研究，共计7项成果于1月被录用。团队在探索中实现共同成长，项目进展显著。感谢各方支持，期待未来继续携手推进科研发展。",
      "content": "2025年，实验室在科研创新与团队协作方面持续深耕，取得一系列扎实成果。师生在探索与实践中共同成长，多个项目获得重要进展。感谢各位朋友一直以来的支持，期待新一年继续携手前行！\n2025年1月回顾\n2025年1月，我组成员7项成果被录用。\n论文录用\n我组博士生刘新一、王驭捷等合作的一篇论文被ICLR 2025录用；\n我组博士生覃彦钊的一篇论文被ICLR 2025录用；\n我组博士生杨灵的两篇论文被ICLR 2025录用；\n我组科研实习生王子豪的一篇论文被ICLR 2025录用；\n我组博士生王驭捷和硕士生竺沈涵等合作的两篇论文被ASPLOS 2025录用。\n论文汇总\nXinyi Liu, Yujie Wang, Fangcheng Fu, Xupeng Miao, Shenhan Zhu, Xiaonan Nie, Bin Cui: \"\nNetMoE: Accelerating MoE Training through Dynamic Sample Placement\n\",\nICLR 2025\n(\nSpotlight\n)\nYanzhao Qin, Tao Zhang, Tao Zhang, Yanjun Shen, Wenjing Luo, Haoze Sun, Yan Zhang, Yujing Qiao, Weipeng Chen, Zenan Zhou, Wentao Zhang, Bin Cui:\"\nSysBench: Can Large Language Models Follow System Messages?\n\",\nICLR 2025\nXinchen Zhang, Ling Yang, Guohao Li, Yaqi Cai, Jiake Xie, Yong Tang, Yujiu Yang, Mengdi Wang, Bin Cui: \"\nIterComp: Iterative Composition-Aware Feedback Learning from Model Gallery for Text-to-Image Generation\n\",\nICLR 2025\nLing Yang, Zhaochen Yu, Tianjun Zhang, Minkai Xu, Joseph E. Gonzalez, Bin Cui, Shuicheng Yan, \"\nSuperCorrect: Supervising and Correcting Language Models with Error-Driven Insights\n\", ICLR 2025\nZihao Wang, Bin Cui, Shaoduo Gan，\"\nSqueezeAttention: 2D Management of KV-Cache in LLM Inference via Layer-wise Optimal Budget\n\",\nICLR 2025\nYujie Wang, Shenhan Zhu, Fangcheng Fu, Xupeng Miao, Jie Zhang, Juan Zhu, Fan Hong, Yong Li, Bin Cui: Spindle: \"\nEfficient Distributed Training of Multi-Task Large Models via Wavefront Scheduling\n\",\nASPLOS 2025\nYujie Wang, Shiju Wang, Shenhan Zhu, Fangcheng Fu, Xinyi Liu, Xuefeng Xiao, Huixia Li, Jiashi Li, Faming Wu, Bin Cui: \"\nFlexSP: Accelerating Large Language Model Training via Flexible Sequence Parallelism\n\",\nASPLOS 2025\n2025年2月回顾\n2025年2月，我组成员2项成果被录用。\n论文录用\n我组博士生李昊洋，硕士生葛浩等合作的一篇论文被SIGMOD 2025录用；\n我组博士生张海林，硕士生季晓东等合作的一篇论文被SIGMOD 2025录用。\n论文汇总\nHaoyang Li, Fangcheng Fu, Hao Ge, Sheng Lin, Xuanyu Wang, Jiawen Niu, Yujie Wang, Hailin Zhang, Xiaonan Nie, Bin Cui: Malleus: \"\nStraggler-Resilient Hybrid Parallel Training of Large-scale Models via Malleable Data and Model Parallelization\n\",\nSIGMOD 2025\nHailin Zhang, Xiaodong Ji, Yilin Chen, Fangcheng Fu, Xupeng Miao, Xiaonan Nie, Weipeng Chen, Bin Cui: \"\nPQCache: Product Quantization-based KVCache for Long Context LLM Inference\n\",\nSIGMOD 2025\n2025年3月回顾\n2025年3月，我组成员2项成果被录用。\n论文录用\n我组博士生黄世悦，硕士生王子威等的论文被TKDE录用；\n我组2024届博士沈彧，硕士生徐贝澄、博士生陆宇鹏等合作的一篇论文被ICDE 2025录用。\n论文汇总\nShiyue Huang, Ziwei Wang, Yinjun Wu, Yaofeng Tu, Jiankai Wang, Bin Cui: \"\nOpDiag: Unveiling Database Performance Anomalies through Query Operator Attribution\n\",\nTKDE 2025\nYu Shen, Beicheng Xu, Yupeng Lu, Donghui Chen, Huaijun Jiang, Zhipeng Xie, Senbo Fu, Nan Zhang, Yuxin Ren, Ning Jia, Xinwei Hu, Bin Cui: \"\nA-Tune-Online: Efficient and QoS-aware Online Configuration Tuning for Dynamic Workloads\n\",\nICDE 2025\n荣 誉 奖 项\n祝贺我组博士生张海林、陈伯轩等发表于SIGMOD 2024的论文荣获\nSIGMOD 2024 Honorable Mention for Best Artifact\n奖。\nSIGMOD会议是数据库领域最具影响力的顶级国际学术会议之一，与VLDB和ICDE并称为数据库领域的三大顶级会议。PKU-DAIR实验室发表于SIGMOD 2024的研究成果《\nCAFE: Towards Compact, Adaptive, and Fast Embedding for Large-scale Recommendation Models\n》荣获\nSIGMOD 2024 Honorable Mention for Best Artifact\n奖，该奖项每年仅授予至多三篇文章，旨在表彰那些在可复现性、灵活性和可移植性方面表现卓越的研究工作。\n学 术 活 动\n2025年3月30日至4月3日，我组博士生王驭捷、硕士生竺沈涵前往荷兰鹿特丹参加国际学术会议ASPLOS 2025，并在会议期间就其研究成果进行学术报告。\n图1. ASPLOS 2025 会议合影\n2025年4月回顾\n2025年4月，我组成员2项成果被录用。\n论文录用\n我组硕士生林晟、博士生李昊洋等合作的一篇论文被VLDB 2025论文录用；\n我组硕士生葛浩的一篇论文被SIGCOMM 2025论文录用。\n论文汇总\nSheng Lin, Fangcheng Fu, Haoyang Li, Hao Ge, Xuanyu Wang, Jiawen Niu,  Yaofeng Tu, Bin Cui：\"\nLobRA: Multi-tenant Fine-tuning over Heterogeneous Data\n\",\nVLDB 2025\nHao Ge, Junda Feng, Qi Huang, Fangcheng Fu, Xiaonan Nie, Lei Zuo, Haibin Lin, Bin Cui, Xin Liu: \"\nByteScale: Communication-Efficient Scaling of LLM Training with a 2048K Context Length on 16384 GPUs\n\",\nSIGCOMM 2025\n学 术 活 动\n2025年4月24日至28日，我组博士生王驭捷、覃彦钊与刘新一前往新加坡参加国际学术会议ICLR 2025，并在会议期间就其研究成果进行学术报告。\n图2. ICLR 2025 会议合影\n2025年5月回顾\n2025年5月，我组成员2项成果被录用。\n论文录用\n我组博士生盛则昂的一篇论文被KDD 2025 录用；\n我组博士后赖沛超的一篇论文被ACL 2025录用。\n论文汇总\nZeang Sheng, Weiyang Guo, Yingxia Shao, Wentao Zhang, Bin Cui:  \"\nLLMs are Noisy Oracles! LLM-based Noise-aware Graph Active Learning for Node Classification\n\",\nKDD 2025\nPeichao Lai, Zhengfeng Zhang, Wentao Zhang, Fangcheng Fu, Bin Cui: \"\nEnhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning\n\",\nACL 2025\n学 术 活 动\n2025年5月19日至5月23日，我组硕士生沈思绮、徐贝澄前往中国香港参加国际学术会议ICDE 2025，并在会议期间就其研究成果进行学术报告。\n图3. 沈思绮在 ICDE 2025 作学术报告\n图4. 徐贝澄在 ICDE 2025 作学术报告\n2025年6月回顾\n2025年6月，我组成员1项成果被录用。\n论文录用\n我组博士生夏义扉、本科生凌宿寒等合作的一篇论文被ICCV 2025录用。\n论文汇总\nYifei Xia, Suhan Ling, Fangcheng Fu, Yujie Wang, Huixia Li, Xuefeng Xiao, Bin Cui: \"\nTraining-free and Adaptive Sparse Attention for Efficient Long Video Generation\n\",\nICCV 2025\n学 术 活 动\n2025年6月22日至6月27日，我组博士生李昊洋、硕士生季晓东前往德国柏林参加国际学术会议SIGMOD 2025，会议期间就其研究成果进行学术报告。\n图5. SIGMOD 2025 会议合影\n2025年7月回顾\n2025年7月，我组成员获得多个荣誉奖项。\n荣 誉 奖 项\n我组博士生张海林获评北京大学2025年优秀博士学位论文，指导教师为崔斌教授。\n图6. 张海林（左）与导师崔斌教授（右）\n我组本科生凌宿寒获评信息科学技术学院2021级本科生“十佳”优秀毕业论文，指导教师为崔斌教授。\n图7. 凌宿寒（左）与崔斌教授（右）\n学 术 活 动\n2025 年7月27日值8月1日，我组博士后赖沛超前往奥地利维也纳参加国际学术会议ACL 2025， 会议期间就其研究成果进行学术报告。\n图8. 赖沛超参加 ACL 2025 会议\n2025年8月回顾\n2025年8月，我组成员2项成果被录用。\n论文录用\n我组博士生李昊洋，硕士生林晟等合作的一篇论文被SIGMOD 2026录用；\n我组博士后赖沛超的一篇论文被EMNLP 2025录用。\n论文汇总\nHaoyang Li, Fangcheng Fu, Sheng Lin, Hao Ge, Xuanyu Wang, Jiawen Niu, Jinbao Xue, Yangyu Tao, Di Wang, Jie Jiang, Bin Cui: \"\nHydraulis: Balancing Large Transformer Model Training via Co-designing Parallel Strategies and Data Assignment\n\",\nSIGMOD 2026\nPeichao Lai, Jiaxin Gan, Feiyang Ye, Wentao Zhang, Fangcheng Fu, Yilei Wang, Bin Cui：\"\nImproving Low-Resource Sequence Labeling with Knowledge Fusion and Contextual Label Explanations\n\"，\nEMNLP 2025\n学 术 活 动\n2025年8月3日至8月7日，我组博士生盛则昂前往加拿大多伦多参加国际学术会议KDD 2025，会议期间就其研究成果进行学术报告。\n图9. KDD 2025 会议留影\n2025年9月回顾\n2025年9月，我组成员1项成果被录用。\n论文录用\n我组博士生杨灵的一篇论文被NeurIPS 2025录用。\n论文汇总\nLing Yang, Xinchen Zhang, Ye Tian, Shiyi Zhang, Chenming Shang, Minghao Xu, Wentao Zhang, Bin Cui: \"\nHermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation\n\",\nNeurIPS 2025\n学 术 活 动\n2025年9月1日至9月5日，我组硕士生林晟前往英国伦敦参加国际学术会议 VLDB 2025，会议期间就其研究成果进行学术报告。\n图10. VLDB 2025 会议合影\n2025年10月回顾\n学 术 活 动\n2025年10月19日-10月23日，我组博士生夏义扉前往美国夏威夷参加国际学术会议ICCV 2025，会议期间就其研究成果进行学术报告。\n图11. 夏义扉参加 ICCV 2025 会议\n2025年11月回顾\n2025年11月，我组成员2项成果被录用，参与多项学术活动。\n论文录用\n我组硕士生徐贝澄、硕士生刘玮、丁克尧等合作的一篇论文被 AAAI 2026论文录用；\n我组硕士生王煊宇、博士生李昊洋等合作的一篇论文被PPoPP 2026录用。\n论文汇总\nBeicheng Xu, Wei Liu, Keyao Ding, Yupeng Lu, Bin Cui: \"\nPSEO: Optimizing Post-hoc Stacking Ensemble Through Hyperparameter Tuning\n\",\nAAAI 2026\n(\nOral\n)\nXuanyu Wang, Fangcheng Fu, Haoyang Li, Hao Ge, Sheng Lin , Jiawen Niu, Bin Cui: \"\nElastor: Elastic and Efficient Model Partitioning and Checkpointing for Fault-tolerant Distributed Training\n\",\nPPoPP 2026\n学 术 活 动\n2025 年11月5日至11月9日，我组博士后赖沛超前往中国苏州参加国际学术会议EMNLP 2025，会议期间就其研究成果进行学术报告\n图12. 赖沛超参加 EMNLP 2025 会议\n2025年11月14日至11月15日，我组博士生刘新一等同学前往中国香港参加国际学术研讨会FAISys 2025，会议期间就其研究成果进行学术报告。\n图13. FAISys 2025 会议合影\n2025年12月回顾\n研究评测\n我组博士生张海林、硕士生季晓东等合作的研究成果“\nPQCache: Product Quantization-based KVCache for Long Context LLM Inference\n”，被美国伯克利大学SkyLab实验室所主导的\nSkyLight\n榜单\n（\nhttps://sky-light.eecs.berkeley.edu/#/home\n）评估多项指标名列第一，验证了我组研究工作的有效性。\n结 · 语\n辞别2025的忙碌与收获，迎接2026的希望与好运。马踏新春福气到，家家户户纳福安。祝福新老朋友们，马年行大运，马到成功事事顺，骏马奔腾步步高，事业蒸蒸日益兴！新春快乐！\nEND\n欢迎关注本公众号，帮助您更好地了解北京大学数据与智能实验室（PKU-DAIR），第一时间了解\nPKU-DAIR\n实验室的最新成果！\n实验室简介\n北京大学数据与智能实验室（Data And Intelligence Research Lab at Peking Univeristy，PKU-DAIR实验室）由北京大学计算机学院崔斌教授领导，长期从事数据库系统、大数据管理与分析、人工智能等领域的前沿研究，在理论和技术创新以及系统研发上取得多项成果，已在国际顶级学术会议和期刊发表学术论文200余篇，发布多个开源项目。课题组同学曾数十次获得包括CCF优博、ACM中国优博、北大优博、微软学者、苹果奖学金、谷歌奖学金等荣誉。PKU-DAIR实验室持续与工业界展开卓有成效的合作，与腾讯、阿里巴巴、苹果、微软、百度、快手、中兴通讯等多家知名企业开展项目合作和前沿探索，解决实际问题，进行科研成果的转化落地。",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzkzODMxNTkzNg==&mid=2247485086&idx=1&sn=464385366e75be6b4e0534a24e299d37&chksm=c34e306202f2831c46ca9d24e0c7bf20c17107420c6bbed3a4476789a588ae127f8e79c9ca69&scene=0&xtrack=1#rd",
      "publish_time": 1767355800,
      "publish_date": "2026-01-02 20:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://sky-light.eecs.berkeley.edu/\"]",
      "add_ts": 1767395872,
      "last_modify_ts": 1767482267
    },
    {
      "id": 178,
      "article_id": "51601",
      "title": "最新英伟达经济学：每美元性能是AMD的15倍，“买越多省越多”是真的",
      "description": "Signal65最新报告显示，英伟达AI算力性价比远超AMD，在生成相同数量token时，其成本仅为AMD的十五分之一。尽管单价较高，但英伟达平台每投入一美元获得的性能是AMD的15倍，整体更省钱，凸显其在AI算力领域的领先地位。",
      "content": "梦晨 发自 凹非寺\n量子位 | 公众号 QbitAI\n为什么AI算力霸主永远是英伟达？\n不算不知道，一算吓一跳：\n在英伟达平台每花一美元，获得的性能是AMD的15倍\n。\n尽管英伟达卖的更贵，但只要买齐一套，就更省钱。\n来自\nSignal65\n的一份最新详尽报告揭示了这个现实，一定条件下生成同样数量的token，英伟达的成本只有AMD的十五分之一。\n这份报告基于SemiAnalysis Inference MAX的公开基准测试数据，时间跨度从2025年10月到12月，覆盖了从密集模型到前沿MoE推理模型的全场景测试。\n黄仁勋的“买的越多，省的越多”原来是真的。\nMoE时代：8卡系统撞上Scaling天花板\nAI模型正在经历一场架构革命，打开Artificial Analysis排行榜就会发现，智能度排名前十的开源模型清一色都是MoE\n（Mixture of Experts，专家混合）\n推理模型。\n另一项来自OpenRouter的数据显示，超过50%的token流量正在被路由到推理模型上。\nMoE架构的核心思路是把模型参数拆分成多个专门化的“专家”子网络，每个token只激活其中一小部分。\n以经典的DeepSeek-R1为例，它拥有6710亿总参数，但每个token只激活370亿——这让它能以更低的计算成本提供前沿级别的智能。\n问题随之而来。当专家分布在多块GPU上时，GPU之间的通信延迟会导致计算单元空闲等待数据，这些空闲时间直接转化为服务商的成本。\n报告指出，无论是英伟达B200还是AMD MI355X，所有8卡系统在超出单节点规模后都会撞上“扩展天花板”（scaling ceiling）。\n英伟达GB200 NVL72的解法是把72块GPU通过NVLink连接成一个单一域，提供130 TB/s的互联带宽。\n在软件层面，整个系统就像一块巨型GPU一样运作。配合英伟达Dynamo推理框架的分离式预填充-解码调度和动态KV缓存路由，这套架构能够有效突破8卡系统的通信瓶颈。\n模型越复杂，英伟达的优势越明显\n报告测试了三类典型模型：模型越复杂，英伟达的优势越明显。\n在密集模型Llama 3.3 70B上，英伟达B200对比AMD MI355X的领先幅度相对温和。\n在基线交互性\n（30 tokens/sec/user）\n下，B200的性能约为MI355X的1.8倍；当交互性要求提升到110 tokens/sec/user时，这一差距扩大到6倍以上。\n中等规模的MoE模型GPT-OSS-120B开始让差距变得更加显著。\n这款OpenAI开源模型拥有1170亿总参数，但每个token只激活约51亿参数。在2025年12月的测试数据中，100 tokens/sec/user交互性下B200的性能接近MI355X的3倍。\n在更符合推理模型需求的250 tokens/sec/user条件下，差距扩大到6.6倍。\n两个平台的绝对性能相比10月都有显著提升，英伟达的峰值吞吐从约7000 tokens/sec跃升至14000以上，AMD则从约6000提升到8500左右，但相对差距反而拉大了。\n真正的分水岭出现在前沿推理模型DeepSeek-R1上。\n这款模型集MoE路由、大参数规模和高强度推理生成于一身，对基础设施的要求极为苛刻。\n测试结果显示：在25 tokens/sec/user交互性下，GB200 NVL72的每GPU性能是H200的10倍、MI325X的16倍；在60 tokens/sec/user下，相比H200的优势扩大到24倍，相比MI355X达到11.5倍；在75 tokens/sec/user下，GB200 NVL72的性能是B200单节点配置的6.5倍，是MI355X的28倍。\n更关键的是，GB200 NVL72能够达到竞争平台根本无法企及的水平，在28卡配置下可以输出超过275 tokens/sec/user，而MI355X在相当吞吐水平下的峰值只有75 tokens/sec/user。\nToken经济学：贵了1.86倍，便宜了15倍\n直觉上，性能更强的平台应该更贵。事实也确实如此：根据Oracle Cloud的公开定价，GB200 NVL72的每GPU每小时价格为16美元，MI355X为8.60美元，前者是后者的1.86倍。\n如果参照CoreWeave的定价，GB200 NVL72相比上一代H200的价格也贵了约1.67倍。\n但报告的计算揭示了一个反直觉的结论：\n在25 tokens/sec/user交互性下，GB200 NVL72的性能优势为5.85倍，除以1.86倍的价格溢价，每美元性能仍是MI355X的3.1倍。\n在75 tokens/sec/user交互性下，28倍的性能优势除以1.86倍的价格，每美元性能达到MI355X的15倍，这意味着生成同等数量的token，英伟达平台的成本只有AMD的十五分之一。\n与上一代产品的对比同样惊人。\n报告估算在DeepSeek-R1的典型工作负载下，GB200 NVL72相比H200的性能提升约20倍。\n而GB200 NVL72价格仅上涨1.67倍，换算下来每美元性能提升约12倍，单token成本降至H200的十二分之一。\nMoE推理让网络成为推理成本的瓶颈，而机柜级的GB200 NVL72恰好解决了这个问题。价值的衡量标准正在从单纯的算力转向“每美元能产出多少智能”。\n报告在结论中指出，AMD的竞争力并未被完全否定——在密集模型和容量驱动的场景下，MI325X和MI355X仍有用武之地。\nAMD的机柜级解决方案Helios也在开发中，可能在未来12个月内缩小差距。\n但就当前的前沿推理模型而言，从芯片到互联到软件的端到端平台设计，已经成为成本效益的决定性因素。\n参考链接：\n[1]https://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859650&idx=1&sn=583c1487a82314f3a8df0002721da2e8&chksm=e9506028eac20d23f5a6891aed378a7971dc25e0c261664a5e4798f1af34dc4f6bb385c4d96c&scene=0&xtrack=1#rd",
      "publish_time": 1767355800,
      "publish_date": "2026-01-02 20:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/\"]",
      "add_ts": 1767395876,
      "last_modify_ts": 1767482270
    },
    {
      "id": 179,
      "article_id": "51600",
      "title": "F1暴涨20分，推理速度恒定！新架构VGent：多目标定位又快又准",
      "description": "UIC与Adobe研究团队提出VGent模型，针对多目标和视觉参照带来的视觉定位挑战，采用模块化设计解耦推理与预测过程，兼顾推理速度与性能。通过多种模块化增强方案，显著提升模型效率与准确性，实现快速响应与高精度定位，为复杂场景下的视觉理解提供新思路。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n多目标（Multi-target） 以及 视觉参照（Visual Reference） 为视觉定位（Visual Grounding）任务的推理速度和性能同时带来了全新的挑战。 为了解决这一难题，来自UIC和Adobe的研究团队提出了VGent模型。这是一种兼顾速度与性能的模块化设计，旨在将模型的推理与预测能力解耦，并辅以多种模块化增强方案 。最终，VGent凭借不到16B的参数量，在多目标及带视觉参照的视觉定位基准（Omnimodal Referring Expression Segmentation, ORES）上，大幅超越了Qwen3-VL-30B，实现了平均+18.24 F1的巨大提升！\n在多模态大模型（MLLM）时代，视觉定位是MLLM细粒度推理能力的重要一环，同时也是实现人机交互和具身智能的核心能力。\n现有的解决方案主要分为两类：\n原生Token派（Native-token）：\n像 Qwen2.5-VL 或 Ferret-v2 这样的模型，通过自回归（auto-regressive）的方式利用原有的词表逐个生成边界框坐标 。这种方式不仅速度慢（推理时间随目标数量线性增加），而且在多目标场景下容易产生幻觉（Hallucinations），即模型可能会在列举完所有目标对象之前就过早停止，或者在目标密集的场景中陷入无限生成的死循环。如图一所示，随着目标数量的增加，这类方法在多目标场景下的低效和不稳定性变得尤为明显。\n新增Token派（New-token）：\n另一类方法尝试通过引入特殊的token（如[SEG]或 object token）来指代目标物。他们需要收集大规模的数据集、从LLM起重新构建一个能理解这些新增token的MLLM。因此，这种方法不可避免地会破坏LLM在预训练阶段获得的通用推理能力。更严重的是，其导致无法直接利用现有的、先进的、进行了更大规模预训练的开源MLLM（如 QwenVL系列）。\n来自UIC（伊利诺伊大学芝加哥分校） 和Adobe的研究团队提出一种模块化的编码器-解码器（Encoder-Decoder）架构\nVGent，\n其核心思想是：将高层的语义推理交给MLLM，将底层的像素预测交给目标检测器（detector），最终通过hidden state将这种解耦后的关系进行连接。\n论文地址：\nhttps://arxiv.org/abs/2512.11099\n研究人员认为，语义推理和精准定位是两种截然不同的能力，强迫训练一个单一的整体模型去同时精通抽象的语义推理和像素级别的底层预测，会导致性能和效率上的权衡。\n更符合直觉的方式，应该是由不同的组件做各自擅长的事。\n基于这一洞察，VGent提出了一种模块化的编码器-解码器设计，利用现成的MLLM和detector将高层多模态推理与底层预测解耦。\n其核心理念在于MLLM和detector的优势是互补的：\nMLLM擅长多模态语义对齐和推理，而detector则擅长高效地提供精准的多目标检测框\n。\n图一：VGent（蓝色）与现有先进的MLLM（Qwen2.5-VL，灰色）在多目标视觉定位任务上的对比。左图显示VGent的推理时间恒定且迅速，而 MLLM 随目标数量增加呈线性增长；右图显示VGent在F1分数上实现了显著提升，特别是在多目标场景下。\n方法\n基础架构\nVGent主要由图二所示的encoder和decoder两部分组成，并引入了三种模块化增强机制（图三、四和五）。\n图二：VGent框架概览\n如图二所示，左侧encoder是一个 MLLM，使用QuadThinker来提升其多目标推理能力。冻结的encoder输出hidden states并存储下来给到decoder。右侧decoder初始化自encoder的LLM 层，其将detector生成的object proposal作为query，通过cross-attention与encoder的hidden states交互。\n研究人员在decoder内部新增了self-attention层（参数初始化自同一层的cross-attention），用于促进query之间的信息交流。 最终的输出进行yes / no的二元判断来选择每个proposal是否属于目标。相应的segmentation mask则通过 prompt SAM 得到。\nQuadThinker：强化多目标推理能力\n针对MLLM在多目标场景下推理能力下降的问题，研究人员提出了一种基于 GRPO 的强化学习训练范式QuadThinker，通过设计特定的prompt和reward functions，引导模型执行区域到全局、分步推理的过程：先分别统计图像四个象限内的目标数量，再汇总总数，最后预测具体坐标。\n图三：QuadThinker所使用的prompt。\nMask-aware Label：解决检测与分割的歧义\n在多目标场景中，检测（Box）与分割（Mask）任务的定义存在一定的差别。检测通常优化「一对一」的匹配，而分割则旨在召回所有前景像素。\n图四：Mask-aware Label示意图。基于IoA的标签分配策略能召回被传统IoU忽略的细粒度部件。\n这种差异导致了标注歧义：例如图四（左）中，检测器可能将「鹿头装饰」与其「挂绳」视为两个独立的框。\n在检测任务的 IoU 标准下，由于挂绳的框比较小、相对于整体真值框的重叠率过低，往往会被当作负样本在标注阶段被过滤掉（被标上负标签）。但是对于分割任务来说，这个挂绳属于前景，其应该被标上正标签。\n为此，VGent引入了Mask-aware Label，使用IoA (Intersection-over-Area) 指标进行额外的标签分配。如图四（右），IoA通过计算候选mask （通过proposal prompt SAM得到）与多目标真值的union mask的交集，并除以候选mask自身的面积得到。\n因为IoA的分母是候选mask自身面积，该机制能精准召回那些虽然只覆盖了部分目标群（如细小的挂绳）但依然有效的 proposal。模型使用另一个独立的MLP head专门预测这种分割导向的标签，用于解决视觉定位中分割类型的输出。\nGlobal Target Recognition：增强全局感知\n为了提升候选框选择的准确性，VGent 引入了Global Target Recognition模块。\n图五：Global Target Recognition示意图。利用Learnable Queries注入全局目标数量信息，并聚合多个detector的结果以提升\n召回率\n。\n为了提高召回率，研究人员聚合了来自多个detector的proposal形成一个统一的query set，之后引入了额外的 learnable queries与这些proposal queries拼接作为decoder的输入。\n这组query被专门训练用于预测目标的总数以及正样本proposal的数量。通过decoder层内的self-attention机制，这些包含全局统计信息的learnable query能够与proposal query进行交互，将「全局线索」传播给每一个候选框，从而增强其对目标群体的整体理解，实现更精准的选择。\n实验结果\n研究人员在最新的多目标视觉定位基准 ORES (MaskGroups-HQ) 以及传统的单目标数据集上进行了广泛评估。\n多目标视觉定位（Multi-target Visual Grounding）\n图六：在 Omnimodal Referring Expression Segmentation (ORES) 上的性能对比。ORES是多目标以及存在视觉参照（w/ < mask-ref >）的视觉定位基准。\n如图六所示，在极具挑战的ORES基准上，VGent 取得了全新的SOTA成绩。相比之前的最佳方法RAS13B，VGent在F1分数上实现了+20.58%的巨大提升。VGent在gIoU和cIoU上都带来了明显的提升。\n值得注意的是，即使对比参数量更大的Qwen3-VL-30B，VGent 依然保持显著优势。同时，得益于模块化设计，VGent 在目标数量增加时保持恒定且快速的推理速度，避免了自回归模型随目标增加而线性增长的推理延迟（如图一所示）。\n单目标视觉定位（Single-target Visual Grounding）\n图七：在referring expression comprehension (REC) 上的性能对比。\nVGent在传统单目标基准（RefCOCO, RefCOCO+, RefCOCOg）上也表现卓越。\nVGent实现了90.1%的平均准确率，超越了InternVL3.5-20B和38B等更大规模的模型 。相比其backbone (Qwen2.5-VL-7B)，VGent带来了+3.5%的平均性能提升。\n可视化\n图八：VGent在不同挑战下的预测结果可视化。\nVGent在复杂场景中展现了极强的鲁棒性。\n如图八（上）所示，VGent精准定位所有方形钟表，即使存在大量相似的钟表作为干扰项，展现了VGent在密集多目标场景下的优越表现。\n图八（下）中，VGent 成功定位了视觉参照（蓝色 mask），并继续推断出左侧穿裙子的女士，排除了右侧的干扰项。\n参考资料：\nhttps://arxiv.org/abs/2512.11099\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659659&idx=3&sn=9c0411e0e0c30b3dfe6402420ce17078&chksm=f0e9e45cce53df8e57b5a523eabf101e0dff070323669b28593dcab76584240ae3030bc22076&scene=0&xtrack=1#rd",
      "publish_time": 1767331200,
      "publish_date": "2026-01-02 13:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.11099\"]",
      "add_ts": 1767395880,
      "last_modify_ts": 1767482277
    },
    {
      "id": 184,
      "article_id": "51594",
      "title": "董事长稚晖君发布上纬新材首款机器人！能塞书包还能骑机器狗",
      "description": "2025年12月31日，上纬新材董事长彭志辉（稚晖君）发布全球最小人形机器人上纬启元Q1，身高仅0.8米，为首款实现全身力控的微型具身智能机器人。作为智元机器人联合创始人，稚晖君将前沿技术融入该产品，不仅具备大型机器人全部功能，更在灵活性与场景适应性上实现突破，可轻松装入书包，甚至可骑行，展现出强大的创新潜力与应用前景。",
      "content": "henry 发自 凹非寺\n量子位 | 公众号 QbitAI\n2025年的最后一天，上市公司上纬新材董事长\n彭志辉\n（稚晖君）发布了一款能装进书包的机器人产品——\n上纬启元Q1\n。\n这是全球首款最小尺寸（0.8m）、实现全身力控的人形机器人，也是智元机器人联合创始人\n稚晖君\n担任上纬新材董事长以来，发布的首款具身智能机器人产品。\n虽然体型迷你，但大机器人能做的，启元Q1也能做。\n大机器人做不了的，启元Q1还能做。\n（我骑过狗你骑过吗？）\n而前段时间让网友猜疯了的 “大有可为” 神秘海报，也终于在这次的发布视频中正式揭晓答案。\n其中醒目的1.88，既不是身高，也不是售价，而是启元Q1的体积（立方米）——一个被压缩到背包级的人形机器人尺寸。\n启元Q1是一款怎样的机器人？\n从产品定位上看，稚晖君这次的新作\n启元Q1\n，是一款面向个人用户、开发者，科研、陪伴、创作场景的小尺寸人形机器人。\n相较于市面上的全尺寸人形机器人，启元Q1最直观的突破的就是把体型和重量狠狠压缩——\n甚至能主动来个双折叠，被你揣进书包。\n值得一提的是，这种小型化设计，并不只是为了方便携带。更轻的重量，让机器人本身更耐造，也把使用和试错成本一起打了下来，更适合个人和小团队反复折腾。\n在产品能力上，启元Q1反复强调了一个关键词——\n全身力控\n。\n简单来说，全身力控并不意味着机器人“力气更大”，而是全身关节都能感知和调节受力。\n传统机器人更多是“按角度走动作”，一旦遇到外力干扰，往往要么硬顶、要么停机。\n而具备全身力控的机器人，在被推、被拉、与环境接触时，会根据外力变化实时调整动作，避免僵硬对抗。\n这一能力让机器人在被推、被拉或与环境接触时，表现出更自然的物理交互特性，也是具身智能落地过程中较为关键的一项基础能力。\n在使用场景上，启元Q1可以充分满足各类用户的需求。\n在科研与教育场景中，它支持开放的SDK与HDK接口，可用于具身智能算法验证、教学实验和动作规划研究。\n小尺寸带来的直接好处是——不需要复杂防护结构，随拿随用，适合高频实验。\n在个人交互场景中，启元Q1接入启元灵心平台，支持自然语言对话、知识问答、英语教学和动作示范，并通过柔性阻抗控制，让人机交互更接近“可长期共处”的状态。\n而在创作者和极客用户方向，启元Q1采用模块化结构设计，支持3D打印外壳和外观定制，并可通过灵创平台编排动作、语音和行为逻辑，为二次创作留出了足够空间。\n这些能力背后，真正的技术难点集中在一个地方——\n关节系统\n。\n高性能人形机器人通常依赖QDD（Quasi-Direct Drive）准直驱关节，来实现力控和高动态动作，但这一方案长期面临的问题是：性能好，但难以做小、做轻。\n在启元Q1上，上纬启元对QDD关节进行了系统性重构——从材料选择、结构布局，到控制算法的协同设计，将核心关节模块压缩至\n不到鸡蛋大小\n，同时保留了力控性能和动态响应能力。\n也正因如此，启元Q1成为目前首个在小尺寸形态下实现全身力控的小尺寸人形机器人。\n机器人即产品\n这次启元Q1的发布，可以被视为稚晖君此前探索的“机器人即服务（RaaS）”路径，在个人机器人市场上的一次延伸。\n而这，也恰恰对应了当前具身智能厂商的普遍趋势——在持续服务科研、生产力和开发需求的同时，开始主动探索面向个人用户的产品形态。\n长期以来，无论是在工厂中的劳动力替代，还是科研中的实验载体，机器人始终被定义为一种工具。\n而今年开始，松延动力推出的Bumi人形机器人（售价 9998 元），以及维他动力推出的大头BoBo机器狗（售价 9988 元），都在指向一个相似方向——\n体型更小、价格更低、可被个人用户实际拥有和使用的具身智能产品。\n这些产品在保持科研与开发属性的同时，更加关注体积、价格、耐用性和可玩性，而这，也意味着具身智能正从“实验工具”，逐步走向“可使用的产品”。\n在2025年即将收官之际，启元Q1正是这一趋势下的一个具体落点——\n在科研与产业应用之外，机器人开始被真正放入个人与开发者的日常使用场景之中。\n而回看上纬新材的节奏，这一变化并非突然发生：\n11月6日完成控股权交割，智元系实现绝对控股，彭志辉入选董事候选人。\n11月25日董事会换届，稚晖君出任董事长。\n12月31日，发布首款具身智能机器人产品。\n短短两个月，这家以材料业务起家的上市公司，就已经是不折不扣的A股具身智能第一股了。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n专属AI产品从业者的\n实名社群\n，只聊AI产品\n最落地的真问题\n扫码添加小助手，发送\n「姓名+公司+职位」\n申请入群～\n进群后，你将直接获得：\n👉 最新最专业的AI产品信息及分析 🔍\n👉\n不定期发放的热门产品内测码 🔥\n👉\n内部专属内容与专业讨论 👂\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859620&idx=1&sn=8c1f3169aedb59161d6fd74dc4888e81&chksm=e924276799d0c252886315241822a49c44c2385338cc3f4cf8ef6ddbe396e1320ef7cb6e9954&scene=0&xtrack=1#rd",
      "publish_time": 1767319200,
      "publish_date": "2026-01-02 10:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767395900,
      "last_modify_ts": 1767482291
    },
    {
      "id": 185,
      "article_id": "51593",
      "title": "元生十倍升级：工业级智能体驱动规模化原创生物学假说发现",
      "description": "“创世纪计划”引发全球关注，推动人工智能与科研深度融合。2024年末，临港实验室启动“元生计划”，并于2025年6月联合上海人工智能实验室、上海交大、复旦大学等发布元生虚拟疾病生物学家v1.0。该AI系统通过干湿结合的系统性研究，显著提升药物靶标发现效率，打破多项纪录，标志我国在AI驱动生命科学领域取得重要突破，加速疾病机制解析与新药研发进程。",
      "content": "近期，“创世纪计划”在全球引发高度关注，表明人工智能与科学研究深度融合已进入提速阶段。\n2024年末，临港实验室启动元生计划，并在2025年6月联合上海人工智能实验室、上海交通大学、复旦大学等机构公开发布了元生虚拟疾病生物学家\nv\n1.0版本\n（\n超越OpenAI！临港实验室首发AI虚拟疾病生物学家“元生”，刷新多项纪录，破解药物靶标发现难题\n）\n。元生虚拟疾病生物学家通过系统性的干湿结合研究，验证了其在规模化生成原创科学假说方面的能力，并在我国人群重大疾病相关靶标的发现与验证中发挥了重要作用。\n今天，\n元生虚拟疾病生物学家v1.3版本\n（https://origene.lglab.ac.cn/\n）\n正式上线，并推出升级版科学假说发现模式。基于智能体实战经验和用户反馈，v1.3版本全面升级了认知能力与知识体系，以进一步适配创新药研发场景中所呈现的超长上下文、复杂知识空间、多层证据链、多模态以及多决策节点等特性。\n新模式总体文献阅读总量提升\n10倍\n、文献幻觉率相较行业标杆方法减少约\n40%\n、平行调研能力提高逾\n10倍\n。深度模式下单次任务可完成对超过\n1000篇文献\n和多模态数据的阅读与关联分析，将假说生成的广度、深度与可信度放大到工业级规模。随着规模化研究能力落地，元生正在推动\n重构生物医药创新体系的科研范式\n。\n接下来，我们将详细介绍本次版本的核心架构升级与实测表现。\n01\n多智能体虚拟协作空间\n元生v1.3模式创新性地构建了一个能够有序地组织和监督大规模智能体的虚拟协作空间。\n图1 智能体虚拟协作空间\n在纵向信息处理工序上，v1.3在调研开端新增了假说生成模块，面对用户对新科学假说的需求进行“合理候选生成”和“快速迭代筛选”，为深度调研步骤提供理想起始点。\n在横向调研广度上，v1.3能够自动对复杂科学问题进行合理的独立研究方向划分，对每个研究维度进行独立深入探讨，直至在该角度上足够形成证据充足、逻辑完整的研究报告。各个角度基于证据的报告支撑起v1.3最终形成围绕单主题的多角度研究成果，避免了现有智能体体系易落入局部单一视角问题。\n元生v1.3的设计理念是用户应该实时掌握智能体调研团队在科学研究过程中的关键决策和重要信息流动。如图1所示：元生v1.3创新构建智能体调研团队可视化界面，在多环节、多角度的调研过程中，实时展示当前主智能体数目、科学任务，以及思考和决策过程。未来版本将开放更多智能体人类协同和互动功能。\n02\n特性：工业级知识管理和调研能力\n元生v1.3的强大调研能力由海量的科学文献和网页作为科学证据支撑，相较于v1.0文献阅读量提升10倍以上。\n图2 元生\nv\n1.3版本主要升级的能力维度\n文献来源和广度提升10倍\n基于坚实的文献基建，元生v1.3大大提升了文献来源广度和阅读能力，针对每个细分问题在30s时间量级内给出约10篇科学文献回应。在v1.3深度研究模式中，智能体系统平均阅读超过1000篇科学文献或网页来生成满足严肃科研场景、证据充分的调研结果。\n文献引用幻觉率较行业标杆减少40%\n幻觉问题——尤其是文献引用幻觉——是科学研究智能体系统面对的最大挑战之一。在整体文献引用数量和文献阅读数量均超过同类产品10倍的前提下，v1.3版本的引用证据正确率仍保持>90%，显著超过Gemini，GPT，DeepSeek，和其他深度调研类及智能体类产品。文献正确率的提升源自于元生v1.3的知识框架迭代，使其能够进行“科学陈述-支持证据-原始文献”的溯源，从而使智能体在最终结果中更多使用可查询的证据。\n平行调研能力提高10倍\n元生v1.3通过大规模智能体协同架构，显著提升对复杂科学问题的平行调研能力。新版本将复杂问题自动拆解为5–10个独立但互补的调查维度，并为每个维度部署专用子智能体。这些子智能体可自主调度下级智能体，并行开展文献阅读、证据整合、假设推演与反思优化，实现深度与广度的同步扩展。相较于上一版本，v1.3的整体调研吞吐量提升约10倍，关键维度的分析深度平均提升一倍以上。这一架构使元生初步具备虚拟科研团队的协作能力，为生成更可靠、更系统的科学假说奠定基础。\n高质量科学假说产出\n元生v1.3在多角度评估中都表现优越。在生物医学研究问题集上，元生v1.3的标准模式和通用智能体Gemini-3-pro, DeepSeek v3.2，深度调研系统GPT Deep research和生物医药领域专用智能体系统进行了对比。如图3-4所示，在文献引用方面，元生v1.3标准模式的引用正确率显著超越现有方法，在调研过程中的总阅读量上，元生相比提供数据的其他候选系统高出一个数量级。在报告质量方面，基于三款领先的大模型评审员的独立打分，元生v1.3标准模式在五个报告质量维度均优于候选方法。\n图3 各模型产生报告的有效参考文献数目对比\n图4 科学假说报告效果评测。引用正确率使用CiteTrue（https://citetrue.com/）评价；其他科学假说相关指标参考相关工作[1, 2]，其中，充分性衡量对既定科学问题的解决程度；事实依据衡量证据和逻辑的正确性；影响力衡量假说对领域的贡献程度；预期有效性衡量假说和方案达到预期效果的可能性。\n多模态理解和可视化升级\n元生不仅生成科学假说与分析报告的文字内容，还能自主调用计算工具和可视化工具，动态生成高质量多模态结果图（如图5所示）。自主产生和搜集的可视化图片及其对应的科学证据共同支撑v1.3更丰富的调研报告，帮助元生从以文献和数据为中心走向更广泛的多模态智能体框架。\n图5 元生产生的多模态分析结果展示\n03\n案例展示\n以下是生物医学领域的专业内测用户提供的典型应用案例和用户反馈，\n点击\n“阅读原文”\n查看完整案例报告。\n1.非天然氨基酸在外泌体领域交叉应用：\n用户A：\n该报告提出非天然氨基酸为外泌体工程化提供了可编程的化学接口\n，通过代谢掺入与遗传密码扩展技术，实现了生物正交标记、表面功能化、互作捕获和货物强化的四位一体方法学框架。元生整合了生物化学和生物医学两个领域的研究成果，从实验室研究拓展到工业应用层面，有前瞻性，\n充分体现了跨学科信息整合能力\n。\n2.衰老新假说：\n用户B：\n针对人类衰老的生物学机制，\n元生提出新概念“Glycan Code Entropy (GCE)”以及相应的调控方式\n，非常新颖的概念，且支持证据扎实，融合了多个领域的研究成果提出的假说，相信相关领域的科研者看到会眼前一亮。提问中没有引导和倾向性的词语，该假说由元生自主提出，体现了元生产出具有科学性的\n原创概念假说\n的能力。\n3.疾病相关GPCR分析：\n用户C：\n针对用户提出的靶点调研问题，\n元生论证\n了\n10+个孤儿GPCR和疾病的关联性\n，证据来源可靠且多源，由元生提出了一套科学合理的靶标打分规则，分析流程也很规范，得出的结果可信，展示了元生基础坚实的\n系统分析能力\n。\n此外，在实际使用过程中，元生的用户群体发现该平台能够适配从基础生物机制研究到疾病转化策略生成的多类任务，其能力覆盖生物医学研究的各个领域。我们诚挚邀请各位用户共同体验、使用并探索元生的更多可能性。\n04\n邀请使用\n元生系统目前已经全面开放注册体验，欢迎试用：\nhttps://origene.lglab.ac.cn/\n相\n关链接\n·论文链接：\nhttps://www.biorxiv.org/content/10.1101/2025.06.03.657658v1.full.pdf\n·项目主页：\nhttps://gentel-lab.github.io/OriGene-Homepage/\n·代码仓库：\nhttps://github.com/GENTEL-lab/OriGene\n参考文献\n[1] Gottweis, Juraj, et al. arXiv preprint arXiv:2502.18864 (2025).\n[2]\nVasu, Rosni, et al. arXiv preprint arXiv:2510.00620 (2025).",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512423&idx=1&sn=cd4e2fdf8ede4acf805e9fcdcc8e3ff4&chksm=fd305c4b973f4b9fb63d2f11889c2aa0d4d373cdf90147d22310cfe8688ca9ee1bee8c48723b&scene=0&xtrack=1#rd",
      "publish_time": 1767318000,
      "publish_date": "2026-01-02 09:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://origene.lglab.ac.cn/\", \"https://citetrue.com/\", \"https://www.biorxiv.org/content/10.1101/2025.06.03.657658v1.full.pdf\", \"https://gentel-lab.github.io/OriGene-Homepage/\", \"https://github.com/GENTEL-lab/OriGene\"]",
      "add_ts": 1767395903,
      "last_modify_ts": 1767482298
    },
    {
      "id": 186,
      "article_id": "51606",
      "title": "Nat. Mach. Intell. | 利用 scPEFT 实现参数高效微调，赋能单细胞大语言模型",
      "description": "DRUGONE单细胞大语言模型（scLLMs）在“上下文外”场景中零样本预测不稳定。为此，研究提出参数高效微调框架scPEFT，通过冻结主干模型并引入低维可学习适配器，实现对特定任务与生物情境的高效适配。该方法显著减少可训练参数与GPU内存开销，缓解灾难性遗忘，在多种疾病状态与跨物种迁移任务中表现优异，提升模型泛化能力与应用潜力。",
      "content": "DRUG\nONE\n单细胞大语言模型（scLLMs）能够从大规模单细胞图谱中学习丰富的生物学知识，但在“上下文外”应用场景中，其零样本预测往往不稳定。研究人员提出了一个参数高效微调框架 scPEFT，通过在冻结主干模型参数的前提下，引入低维、可学习的适配器，实现对特定任务和生物情境的高效适配。scPEFT 在显著减少可训练参数和 GPU 内存开销的同时，有效缓解了灾难性遗忘问题。在多种疾病条件、跨物种迁移以及未充分表征的细胞群体任务中，scPEFT 均显著优于零样本模型和传统全参数微调方法。此外，通过注意力机制分析，scPEFT 能够识别疾病条件下的关键基因与细胞状态，为情境感知的单细胞解析提供了一种高效而可解释的解决方案。\n单细胞测序技术极大推动了对细胞异质性与功能状态的理解，但其数据分析仍面临批次效应、数据偏倚及生物情境复杂多变等挑战。近年来，受自然语言处理领域基础模型成功的启发，研究人员提出了将基因表达视作“生物语言”的单细胞大语言模型。这类模型在大规模图谱上预训练后，具备强大的表示能力。\n然而，scLLMs 在面对未见疾病状态、跨物种应用或罕见细胞群体时，往往表现不稳。传统的全参数微调虽然可以提升性能，但计算成本高昂，并易导致预训练知识被覆盖。如何在资源受限条件下高效、稳健地适配 scLLMs，成为制约其广泛应用的关键问题。\n方法\nscPEFT 通过在 scLLMs 的关键模块中引入参数高效的适配器，实现对模型的情境化调整。研究人员在冻结原有模型参数的基础上，仅更新低维适配器参数，从而在独立子空间中学习“模型增量”。scPEFT 支持多种适配器形式，包括基因标记适配器、前缀适配器、低秩适配（LoRA）以及编码器适配器，可灵活组合以适应不同任务需求。这种设计显著降低了可训练参数规模，减少了计算与内存开销，同时保留了 scLLMs 的原始生物学知识。\n图 1｜scPEFT 框架。\n结果\n疾病条件下的细胞类型识别性能\n在非小细胞肺癌、多发性硬化和 COVID-19 等疾病数据集中，scPEFT 在多种 scLLM 主干模型上均显著提升了细胞类型识别准确率。与全参数微调相比，scPEFT 在避免灾难性遗忘的同时，对罕见细胞类型具有更强的识别能力。\n图 2｜疾病条件下的细胞类型识别结果。\n参数效率与计算开销分析\nscPEFT 仅需原模型 0.05%–4% 的可训练参数，并将 GPU 内存占用降低至全参数微调的一半以下。在不同适配器配置和超参数设置下，scPEFT 均表现出较强的稳定性，对训练数据规模的依赖显著低于传统微调方法。\n图 3｜参数效率与资源消耗对比。\n疾病相关细胞状态基因的注意力解析\n通过分析模型注意力分布，scPEFT 能够在疾病条件下识别与特定细胞状态相关的关键基因。与原始模型和全参数微调模型相比，scPEFT 在保持细胞状态特异性的同时，更好地平衡了条件敏感性与生物学合理性。\n图 4｜基于注意力机制的细胞状态相关基因分析。\n跨物种迁移能力评估\n研究人员将 scPEFT 应用于小鼠、猕猴及秀丽隐杆线虫数据集。结果表明，scPEFT 能够利用同源基因信息有效迁移人类预训练模型，在跨物种细胞类型识别任务中显著优于全参数微调方法，并在零样本设置下保持较强鲁棒性。\n图 5｜跨物种迁移学习结果。\n无监督细胞群体发现与下游任务\n在无监督条件下，scPEFT 能够解析复杂的骨髓与 CD34⁺ 细胞群体结构，识别潜在的发育中或过渡态细胞亚群。此外，在转录因子识别、批次校正和基因扰动预测等任务中，scPEFT 在性能与计算效率之间实现了良好平衡。\n图 6｜无监督细胞群体解析与下游任务表现。\n讨论\nscPEFT 为单细胞大语言模型的高效适配提供了一种实用而通用的解决方案。通过将任务相关调整限制在低维子空间中，scPEFT 在显著降低计算成本的同时，有效缓解了灾难性遗忘问题，并提升了模型在复杂生物情境下的泛化能力。其模块化设计使其能够适配不同 scLLM 主干，并支持监督与无监督分析。\n未来，scPEFT 有望通过更精细的同源基因映射策略、跨模态适配以及任务特异化优化，进一步扩展其在单细胞生物学和系统医学中的应用潜力。\n整理 | DrugOne团队\n参考资料\nHe, F., Fei, R., Krull, J.E. et al. Harnessing the power of single-cell large language models with parameter-efficient fine-tuning using scPEFT. Nat Mach Intell (2025).\nhttps://doi.org/10.1038/s42256-025-01170-z\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512469&idx=2&sn=e28eff2aa6c36ca2893b6dc6b064c254&chksm=fd15bdefb1e4364376b5ef0d7e8bd377a881809439c8eb7e01d640ea179a13673c463a551ec1&scene=0&xtrack=1#rd",
      "publish_time": 1767407400,
      "publish_date": "2026-01-03 10:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s42256-025-01170-z\"]",
      "add_ts": 1767482255,
      "last_modify_ts": 1767568751
    },
    {
      "id": 194,
      "article_id": "51590",
      "title": "DeepMind内部视角揭秘！Scaling Law没死，算力即一切",
      "description": "2025年即将结束，DeepMind华人研究员撰文揭示谷歌内部对AI的核心观点：算力是推动人工智能发展的关键，其余皆为干扰。经历2024年的好奇探索后，2025年AI已深度融入社会，广泛影响各领域。模型迭代、资本涌入与算力竞争成为主线，通用人工智能虽未实现，但进展显著。文章指出，未来突破仍依赖于算力的持续提升，技术演进正加速重塑人类生活与工作方式。",
      "content": "新智元报道\n编辑：定慧\n【新智元导读】\n2025年就要结束，\nDeepMind华人研究员万字长文为我们揭秘了谷歌内部对于AI的预言：除了算力，其他一切都是杂音。\n今天是2025年的最后一天了，很多人都在这一天进行AI回顾总结。\n在经历一年的模型、算力、资本的新闻轰炸后，AI距离通用人工智能还有多远？\n如果说2024年是人们对于\nAI\n的好奇之年，那么2025年就是AI深刻影响人类社会之年。\n在这充满变数的一年里，我们听到了截然不同的声音：\nSam Altman\n在2025年中的博文《温和的奇点》中大胆预言：\n「我们已经知道如何构建AGI，2026年我们将看到能够产生原创见解的系统。」他坚持认为，Scaling Law远未触及天花板，智能的成本将随着电力的自动化生产而趋近于零。\n拓展阅读：奥特曼：温和奇点已降临！AI最终掌控物理世界，2030年人类命运大转折\nNVIDIA的\n黄仁勋\n则将目光从「算力崇拜」转向了「AI工厂」。\n他在2025年底的一次演讲中提到：\n「AI的瓶颈不再是想象力，而是电力。未来的Scaling Law不仅是模型的堆叠，更是推理效率10万倍的飞跃。」\n拓展阅读：英伟达AI工厂：人类历史酝酿12000年的绝对必然\n相比之下，Meta的前首席科学家Yann LeCun依然嘴炮，他甚至在离职创办新公司前公开表示：\n「LLM是通往 AGI 的死胡同，它没有世界模型，就像一个没有躯体的空中楼阁。」\n拓展阅读：LeCun赌上后半生，押注大模型必死！Hassabis誓将Scaling进行到底\n2026年，Scaling Law是否还能继续玩下去？\n对于这个问题，一篇来自DeepMind华人研究员的万字长文在社交网络火了：\nScaling Law没死！算力依然就是正义，AGI才刚刚上路。\n文章地址：https://zhengdongwang.com/2025/12/30/2025-letter.html\n本文是Google DeepMind研究员Zhengdong Wang撰写的2025年度长信。\n作者以独特的个人视角，回顾了从2015年至今AI领域的剧变，并深刻剖析了驱动这一切的核心动力——\n算力\n。\n尽管外界对Scaling Laws存疑，但历史反复证明，随着算力的指数级增长，AI模型不断涌现出超越人类预期的能力。\n作者结合自己在DeepMind的工作经历，验证了强化学习教父Richard S. Sutton「苦涩的教训」：\n通用算力方法终将战胜人类的特定技巧。\n这也是我们今年最大的感受！\n除了算力，其他都是杂音\n2025年12月30日，当回望这波澜壮阔的一年时，脑海中浮现的是十五年前那场由AlexNet开启的视觉革命。\n那场辛顿、李飞飞、Ilya都参与的大会，或许就是如今AI时代的真正萌芽。\n那时，大多数人认为人工智能仅仅是关于「特征工程」和「人类聪明才智」的博弈，而今天，我们已经进入了一个完全不同的维度：\n一个由算力主导、由Scaling Law驱动、且AGI（通用人工智能）才刚刚踏上征途的纪元。\n最近大家关注的焦点无外乎：Scaling Law是否已经撞墙？\n算力的信仰：为什么Scaling Law从未失效\n在2024年底，业内曾出现过一阵强烈的悲鸣，认为预训练数据的枯竭和边际收益的递减标志着Scaling Law的终结。\n然而，站在2025年的终点，我们可以负责任地说：\nScaling Law不仅没死，它正在经历一场从「暴力堆参数」到「智能密度」的深刻演化。\n十五年一遇的连续性\n我们要理解Scaling Law，首先要看到它的历史韧性。\n研究显示，过去十五年里，用于训练AI模型的算力每年以四到五倍的速度增长。\n这种指数级的复合增长，在人类技术史上是罕见的。\n在DeepMind内部观察到，模型在训练过程中所消耗的数学运算量，已经超过了可观测宇宙中的恒星数量。\n这种增长并非盲目，而是建立在极其稳定的经验公式之上。\n根据Kaplan和Hoffmann等人的实证研究，性能与算力之间存在着明确的幂律关系：性能提升与算力的0.35次方成正比。\n文章地址：https://fourweekmba.com/ai-compute-scaling-the-50000x-explosion-2020-2025/\n这意味着，每投入10倍的算力，大约能带来3倍的性能增益；而当我们跨越1000倍的算力鸿沟时，性能的提升将达到惊人的10倍量级。\n定性跃迁与涌现能力\nScaling Law最迷人的一点在于，它不仅带来了定量的误差减少，更诱发了不可预测的定性跃迁。\n在DeepMind的实验中，随着算力的增加，模型会突然展现出逻辑推理、复杂指令遵循以及事实性修正等「涌现能力」。\n这种现象意味着，算力不仅仅是燃料，它本身就是一种能够催生智能的物理量。\n2025年的真相是：我们已经从单纯的「预训练Scaling」转向了「全四个维度Scaling」：\n预训练Scaling\n通过海量多模态数据构建基础认知。\n后训练Scaling\n利用强化学习（RL）进行对齐和偏好优化。\n推理时Scaling\n即让模型在回答前「想得更久」。\n上下文Scaling\n通过超长记忆提升端到端任务能力。\n在DeepMind亲历的「1000倍算力」瞬间\n如果说Scaling Law是宏观的哲学，那么2021年Zhengdong Wang在DeepMind经历的那次实验，就是微观的启示录。\n那次经历彻底重塑了Zhengdong Wang的「智能观」，也让Zhengdong Wang理解了为什么说「算力即正义」。\n算法聪明才智的贬值\n当时，DeepMind团队正在尝试解决具身智能（Embodied AI）在3D虚拟环境中的导航与交互问题。\n那是典型的「硬核AI」挑战，涉及到复杂的强化学习算法优化。\n当时的共识是：这个问题的瓶颈在于算法的精妙程度，在于我们如何设计更优的采样策略和奖励函数。\n然而，一位同事提出了一个近乎「鲁莽」的方案：不要改算法，直接把算力投入增加一千倍。\n在那次算力狂飙之后，奇迹发生了！\n那些原本被认为需要突破性人类巧思才能解决的逻辑死角，在海量的矩阵乘法面前直接「融化」了。\n算法并没有变聪明，但规模赋予了它一种类似于生物本能的鲁棒性。\n算力之波的冲击\n那一刻，Zhengdong Wang深刻体会到了理查德·萨顿（Richard Sutton）在《苦涩的教训》中所表达的真理：\n人类在AI领域的所谓「巧思」，在算力的指数增长面前往往不值一提。\n这种realization就像是一股巨大的「算力之波」从你身上碾过，让你意识到，与其苦思冥想如何优化那1%的算法效率，不如直接去拥抱那1000倍的算力扩张。\n这种视角在2025年的今天已经成为了DeepMind内部的通用语：\n我们不再问「这个问题能不能解」，而是问「这个问题需要多少算力才能解」。\n正是这种心态，让我们敢于在数据中心投资上砸下远超阿波罗计划的重金。\n基础设施的极限与挑战：1GW时代的到来\nZhengdong Wang还提供了额外的视角。\n当DeepMind在内部讨论算力时，话题已经从「PFLOPS」转向了「GW」。\n2025年，AI不再仅仅是代码，它是重工业，是土地、能源和定制硅基芯片的终极整合。\n硬件的代际跨越：Blackwell与Ultra\n这种终极整合，用一个词概括就是「AI工厂」，正是黄仁勋在GTC大会所提出的概念。\nWang认为，NVIDIA在2025年交付的Blackwell平台，是DeepMind能够维持Scaling Law信仰的物理基础。\nGB200 NVL72系统将72颗GPU互联为一个单一的超级计算引擎，其万亿参数模型的推理速度比H100提升了30倍。\nBlackwellUltra的推出更是将单芯片显存推向了288GB的极限，这意味着即使是300B以上的模型，也可以在不需要显存卸载的情况下完整驻留，这对于长上下文和高并发推理至关重要。\n电力与散热的硬墙\n然而，物理定律依然严苛。\n单芯片功耗逼近1000W，让DeepMind不得不全面转向液冷方案。\n2025年，开始谈论「AI工厂」而非「数据中心」。\n谷歌的基础设施首席执行官Amin Vahdat在内部会议中明确指出，为了满足爆发式的算力需求，我们必须每六个月将算力能力翻倍，并在未来4-5年内实现1000倍的增长。\n这种压力不仅体现在金钱上。\n2025年上半年，AI数据中心投资占据了美国GDP增长的90%以上。\n尽管外界担心泡沫，但DeepMind内部的视角是：\n如果你能看到1000倍算力带来的智能红利，那么任何低于这个数字的投入都是一种风险。\n具身智能的突破：SIMA 2与通用Agent的诞生\n在DeepMind，始终认为AGI的终极形态不在对话框里，而在物理世界中。\n2025年，SIMA 2项目展示了从「理解」到「行动」的跨越。\n像素级交互与开放式学习\nSIMA 2是一个通用的具身智能体，它不依赖于游戏内部的数据接口，而是像人类一样，通过观察像素和操作键盘鼠标在复杂的3D虚拟世界中行动。\n这种设计确保了它所习得的技能——从基础的导航到复杂的工具使用——具有极强的泛化性，可以无缝迁移到完全不同的数字环境，甚至为未来的物理机器人提供大脑。\n更重要的是，SIMA 2展示了「自我进化」的能力。\n通过与Gemini基础模型的结合，它可以自主生成任务、自我设定奖励，并在没有任何人类标注的情况下，通过不断的尝试和错误习得新技能。\n扩展阅读：我的王者荣耀有救了！谷歌发布游戏SIMA 2，不开外挂「像人一样」练级\nMETR时间跨度图：智能的量化加速\n在评估进展时，作者最推崇的是METR的时间跨度图。\n两年前，AI只能稳定完成人类耗时9分钟的任务；而到了2025年底，这个数字已经跃升到了4小时以上。\n按照目前的Scaling趋势，到2028年，AI有望独立完成人类专家需要数周才能完成的科研或工程任务。\nAGI才刚刚上路，正处于爆发的前夜\n在结尾，Zhengdong Wang写道：「这就是我上车的地方——我们现在还极其早。」。\n尽管2025年我们已经看到了能过IMO的金牌模型，看到了能自主在3D世界中生存的Agent，但在DeepMind的「Post-AGI」团队看来，这仅仅是序幕。\n我们依然受困于1GW的电力瓶颈，受困于数据采集的效率，受困于推理成本的最后几美分。\nAGI不是终点，而是起点！\nDeepMind之所以成立Post-AGI团队，是因为预见到：\n当AGI的门槛被跨过那一刻，人类社会真正需要面对的挑战才刚刚开始：\n如何管理那些能够自主进化、且由于算力规模而产生「不可解释性」的智能体？\n在一个智能成本趋近于零的世界里，人类的独特价值如何重构？\n当AI开始主导科学研发的循环，人类文明的知识边界将以何种速度扩张？\n2025年的真相是，Scaling Law不仅是通往AGI的路径，它本身就是一种重塑物理世界的哲学。\n那些还在争论泡沫的人，或许还没意识到，这股由1000倍算力卷起的风暴，已经将人类送往了一个再也回不去的纪元。\n对于AI的拥趸，所有人正满怀敬畏地看着那列名为「智能」的火车加速驶向远方。\n我们并非在等待奇迹，我们正在亲手塑造它。\nAGI，才刚刚上路。\n参考资料：\nhttps://zhengdongwang.com/2025/12/30/2025-letter.html\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659613&idx=1&sn=e83ed377d42d496c71d70a082d26ea75&chksm=f01cc8fe6baa46da62bd51740b53a14eee1e7bdafe1bc9b2d2ce76bd7478d2f0f2aa8e690486&scene=0&xtrack=1#rd",
      "publish_time": 1767285600,
      "publish_date": "2026-01-02",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://zhengdongwang.com/2025/12/30/2025-letter.html\", \"https://fourweekmba.com/ai-compute-scaling-the-50000x-explosion-2020-2025/\"]",
      "add_ts": 1767482307,
      "last_modify_ts": 1767482307
    },
    {
      "id": 195,
      "article_id": "51629",
      "title": "Nat. Methods | Pertpy: 一个用于扰动分析的端到端框架",
      "description": "Pertpy 是一个基于 Python 的端到端单细胞扰动分析框架，旨在系统化组织、分析和解释大规模、多条件、多模态的单细胞扰动数据。随着单细胞技术的发展，传统分析方法因分散且任务单一难以应对复杂数据需求。Pertpy 提供标准化数据结构、丰富的扰动数据集与元数据资源，集成多种分析工具，支持从数据预处理到功能解读的全流程，提升研究效率与可重复性，推动精准解析细胞状态变化。",
      "content": "DRUG\nONE\n随着单细胞技术的发展，研究人员能够在多种遗传、化学、环境或疾病扰动条件下解析细胞状态变化。然而，现有扰动分析方法往往针对单一任务，分析流程分散，难以适应大规模、多条件和多模态的数据需求。研究人员提出 Pertpy，一个基于 Python 的端到端扰动分析框架，用于系统性组织、分析和解释大规模单细胞扰动实验数据。Pertpy 集成了标准化的数据结构、丰富的扰动数据集与元数据资源，并实现了多种成熟与新提出的分析方法，覆盖从数据预处理到生物学解释的完整流程。作为 scverse 生态系统的一部分，Pertpy 具备良好的可扩展性和互操作性，为复杂扰动实验提供统一、可复用的分析范式。\n理解细胞对扰动的响应是解析生物调控机制和疾病过程的核心问题。近年来，单细胞实验逐步从描述性研究转向系统性的扰动实验，包括基因编辑、药物处理、病理状态和环境刺激等多种形式。\n尽管已经开发出多种统计和机器学习方法用于分析此类数据，但现有工具普遍存在以下局限：\n仅支持特定扰动类型（如 CRISPR）;\n难以扩展至大规模或多条件实验;\n缺乏统一的数据结构与生物学上下文整合;\n分析流程碎片化，生态系统割裂。\n因此，研究人员迫切需要一个可扩展、模块化、具备生物知识整合能力的统一扰动分析框架。\n方法概述\nPertpy 是一个面向单细胞扰动数据的模块化分析框架，围绕统一的数据结构构建完整分析流程。其核心设计理念包括：\n统一数据表示：支持单模态和多模态单细胞扰动数据；\n标准化预处理：包括 gRNA 赋值、质量控制和批次效应校正；\n扰动空间建模：为每种扰动学习一个汇总细胞响应的低维表示；\n下游分析模块化：支持差异表达、细胞组成变化、扰动距离、响应预测和多细胞程序识别；\n生物知识增强：自动整合公共数据库中的细胞系、药物和机制信息。\n所有模块可自由组合，形成针对不同实验设计的定制化分析管线。\n结果\nPertpy 的整体框架与分析流程\nPertpy 提供了从扰动数据输入到生物学解释的完整分析管线，涵盖数据整理、元数据注释、扰动空间构建和多类型下游分析。该框架适用于遗传扰动、药物筛选及疾病状态等多种实验场景。\n图1｜Pertpy 框架与核心模块。\n学习可解释的扰动空间\n通过构建“扰动空间”，Pertpy 将大量细胞级响应压缩为每个扰动对应的整体表征，从而揭示具有相似转录效应的扰动之间的关系。\n在组合基因扰动实验中，该表示能够有效区分不同基因程序，并进一步细化或修正已有的生物学注释。\n图2｜组合 CRISPR 扰动数据中的扰动空间。\n解析药物扰动中的细胞响应机制\n在大规模药物扰动数据集中，Pertpy 通过整合药物敏感性信息，将基因表达响应分解为与细胞存活相关和与存活无关的两类效应。该分析揭示了传统机制注释难以捕捉的调控路径，为药物作用机制提供了新的解释维度。\n图3｜药物扰动中存活依赖与非依赖响应的分解分析。\n组织水平的扰动效应解析\n在肿瘤治疗相关的单细胞数据中，Pertpy 能够同时分析扰动引起的细胞类型比例变化和多细胞协同程序。研究人员借此识别了与治疗响应相关的关键免疫细胞亚群及其协同调控特征。\n图4｜多细胞组织中扰动效应的系统解析。\n讨论\nPertpy 提供了一个覆盖数据组织、分析与解释的端到端扰动分析框架，有效弥合了现有工具在规模、通用性和生态整合方面的不足。其模块化设计不仅降低了复杂分析流程的门槛，也为新方法的快速集成提供了基础设施支持。\n研究人员展示了 Pertpy 在基因扰动、药物筛选和肿瘤治疗响应分析中的通用性，表明统一的扰动表示和生物知识增强分析对于复杂单细胞实验至关重要。随着空间转录组等新型扰动数据的出现，Pertpy 有望成为构建大规模扰动图谱和评估基础模型的重要工具。\n整理 | DrugOne团队\n参考资料\nHeumos, L., Ji, Y., May, L. et al. Pertpy: an end-to-end framework for perturbation analysis. Nat Methods (2025).\nhttps://doi.org/10.1038/s41592-025-02909-7\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512504&idx=2&sn=2e8ae6dd83f8afb04d3589eb81957680&chksm=fdc68ea67ead0d3d93d8b95439b1530dad52f265975c1c4a4c2c7e62bd361375606cf7981331&scene=0&xtrack=1#rd",
      "publish_time": 1767544200,
      "publish_date": "2026-01-05 00:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s41592-025-02909-7\"]",
      "add_ts": 1767568673,
      "last_modify_ts": 1767741742
    },
    {
      "id": 197,
      "article_id": "51627",
      "title": "Commun. Chem. | 机器学习预测儿童药物副作用: 填补儿科用药安全的证据空白",
      "description": "中南大学湘雅药学院曹东升、蒋德军、邓友超团队针对儿童用药安全风险，开发出专用于预测儿童药物不良反应的计算框架。该研究弥补了当前儿科药物安全领域因临床数据缺乏和依赖成人数据导致的证据缺口，为儿童精准用药提供科学支持，成果发表于国际权威期刊《Communications Chemistry》。",
      "content": "儿童并非成人的缩小版，其独特的生理发育特点决定了他们在用药时面临着与成人截然不同的安全风险。药物不良反应（ADRs）是导致儿童患病和死亡的重要原因，但当前儿科药物安全研究却因临床数据匮乏和过度依赖成人研究而存在巨大证据缺口。中南大学湘雅药学院曹东升教授、蒋德军副教授、邓友超副教授团队开发了一套专门针对儿童群体的药物不良反应预测计算框架，研究成果已发表在国际权威期刊《Communications Chemistry》（中科院1区Top）上。该研究整合了共识驱动的信号检测、多层次生物学特征和可解释的机器学习方法，为儿科药物安全评估提供了创新性的解决方案。\n研究摘要图\nunset\nunset\n儿童用药安全：一个被忽视的临床难题\nunset\nunset\n药物不良反应是全球范围内导致患病和死亡的主要原因之一，给医疗系统带来了巨大的临床和经济负担。在所有患者群体中，儿童因其独特的生理特征和持续发育特点，成为药物治疗中尤为脆弱的人群。儿童器官系统尚未成熟，且药物代谢酶的表达呈现明显的年龄依赖性，这些因素显著影响了药物的药代动力学（PK）和药效学（PD）。与成人相比，药物在儿童体内的吸收、分布、代谢和排泄均发生明显改变。\n药物不良事件（ADEs）占儿科住院患者的10%，其中近一半属于危及生命的严重不良事件。儿童ADR的发生率从0.6%到16.8%不等，其中约3.9%为严重或致命性反应。更令人担忧的是，高达90%的住院儿童接受超说明书处方用药，这使他们暴露在未经评估的用药风险中。然而，伦理挑战和招募障碍限制了儿科临床试验的开展，导致高质量安全数据的匮乏。因此，儿科药物安全监测仍然不足，迫切需要专门的研究、强有力的药物警戒体系和个体化治疗指南，以降低儿童面临的高ADR风险。\nunset\nunset\n研究亮点：填补儿科药物安全数据空白\nunset\nunset\n本研究的核心创新主要体现在三个方面：高质量儿科数据集的构建、多层次生物学特征的引入，以及儿童与成人模型不可相互迁移的实证证明。\n首先，构建了迄今为止规模最大、质量控制最严格的儿科药物–不良反应数据集。研究团队系统整理了FDA不良事件报告系统（FAERS）2004–2024年间的全部报告，共筛选出约140万份明确涉及0-14岁儿童的不良反应记录，覆盖从新生儿到青春前期等多个关键发育阶段。图1展示了数据集的构建流程以及真实世界中儿童 ADR 报告的整体分布特征：不同年龄段儿童的不良反应报告呈现明显的年龄依赖性，在新生儿期和青春前期出现高峰，不同发育阶段对应的药物暴露类型和不良反应谱也存在显著差异。\n图1.基于FAERS（2004-2024）的儿科药物警戒数据集构建与特征分析\n在数据标注方面，研究针对儿童ADR中“严重但罕见”和“常见却复杂”并存的特点，综合使用了PRR、ROR、BCPNN和EBGM四种在药物警戒领域具有互补优势的信号检测方法，通过投票机制筛选在多种方法中均表现稳定的药物–ADR关联。图2 对比了这四种方法在识别FDA黑框警告 ADR 和常规 ADR 中的表现差异，验证了共识策略在平衡灵敏度与特异性方面的有效性。最终，研究构建的数据集涵盖2,363种药物和230个具有明确临床意义的不良反应终点。\n图2.四种信号检测方法的比较分析，展示ROR、PRR、EBGM和BCPNN在识别不良反应中的表现\n其次，创新性地引入了多层次生物学指纹特征（BioFeat）。传统的药物不良反应预测模型多依赖化学结构指纹（如Morgan指纹、RDKit描述符）。这类方法虽然能够捕捉分子结构信息，但难以解释药物在生物体内引发不良反应的具体机制。本研究采用的BioFeat框架涵盖分子、靶点、生物网络、细胞和临床五个层次共25个细分层级的生物学描述符，提供了多层次的生物学背景信息。\n结合XGBoost机器学习算法，BioFeat显著提高了模型的稳定性和整体预测能力（ROC AUC：0.7177，PRC AUC：0.5456，准确度：0.7259;详见论文原文表1）。图3的对比分析表明，在样本量较少的情况下，BioFeat 依然能够保持稳定的预测性能，而传统的化学指纹方法则表现出明显的性能波动。这一特性对于儿科药物安全研究尤为重要，因为儿童ADR数据本身就相对稀缺，模型需要在小样本条件下依然保持可靠的预测能力。\n图3.不同分子表示方法的性能比较，BioFeat在样本量较少的情况下仍保持优异性能\n第三，系统性地证实了儿童与成人ADR预测模型存在本质性差异，无法相互迁移。 尽管在实际临床实践中，儿科用药安全评估长期依赖成人研究数据进行外推，但本研究通过大规模跨领域验证实验明确表明，这种做法在计算模型层面并不可行。 研究分别构建了儿童–儿童模型和成人–成人模型，两者在各自领域内均表现稳健（ROC AUC 中位数分别为 0.7005 和 0.6913）。 然而，当尝试将成人模型应用于儿童数据，或将儿童模型应用于成人数据时，模型性能急剧下降（儿童到成人：0.4463，成人到儿童：0.4315），几乎接近随机猜测水平。\n图4直观展示了这一跨年龄领域的模型迁移性能评估结果，所有跨领域应用的性能下降均达到高度显著水平（p < 0.001）。这一发现从计算建模角度再次印证：儿童独特的生理发育特点使其药物不良反应模式与成人存在本质差异，必须采用专门针对儿童的建模方法，而不能简单依赖成人数据推断。\n图4.ADR预测模型在不同年龄段的可转移性评估\nunset\nunset\n新生儿用药风险：从“灰婴综合征”到母体药物暴露\nunset\nunset\n新生儿是特别脆弱的人群，由于生理系统尚未成熟，他们对药物干预极为敏感。研究模型成功识别了大量新生儿不良药物反应，所有预测结果均有文献证据支持，证明了模型具有稳健的预测性能。（详见论文原文表2）\n研究成功识别了氯霉素——一个具有历史意义的新生儿药物毒性案例。这种抗生素因在新生儿中引起致命的“灰婴综合征”而广为人知，主要表现为进行性发绀、血管塌陷，最终常导致死亡。其发病机制是新生儿肝脏葡萄糖醛酸化途径尚未成熟，导致药物在体内大量蓄积。此外，模型还预测了苯甲醇（一种常见的药用防腐剂）相关的新生儿不良反应。这种物质与早产儿的“喘息综合征”密切相关，由于早产儿代谢途径尚未发育完善，导致有毒的苯甲酸在体内蓄积，引发代谢性酸中毒和神经系统并发症。\n为了进一步理解模型预测的关键驱动因素，研究利用SHAP可解释性分析方法对特征重要性进行了评估（图5）。结果显示，临床层面特征（28.0%）和生物网络层面特征（21.4%）对新生儿黄疸预测贡献最大，而传统的分子结构特征仅占13.6%，再次印证了多层次生物学特征在儿科ADR预测中的独特价值。\n图5.模型消融分析与新生儿黄疸预测的SHAP特征重要性分析\n在母体精神健康领域，抑郁症发病率在孕期显著升高，精神药物使用日益普遍。美国阿片类药物滥用问题的蔓延，进一步加剧了母体用药暴露的风险，给新生儿健康带来了严峻挑战。丁丙诺啡和美沙酮等阿片类药物与新生儿呼吸系统疾病和戒断综合征显著相关。同时，某些抗抑郁药显示出与新生儿呼吸、神经和发育并发症的复杂关联。这些发现充分说明，新生儿神经生物学系统对母体药物暴露极为脆弱，迫切需要建立全面的风险评估体系和针对性的干预策略。\nunset\nunset\n儿童与成人ADR差异揭示发育药理学鸿沟\nunset\nunset\n研究构建了一个全面的药物-ADR网络，通过可视化方式展现预测结果，并系统比较了儿科与成人的ADR特征，网络中识别的所有儿科ADR都有文献证据支持。该网络展示了儿童和成人共有的ADR，以及在儿科患者中独特观察到的ADR。\n图6.儿童-成人药物-ADR网络图，展示不同年龄组的ADR差异\n分析确定了区分儿科药物安全与成人药理学的三个关键因素：代谢不成熟、发育神经可塑性和器官特异性脆弱性。儿童的肝酶系统和肾脏清除机制与成人存在根本差异，导致药物代谢和排泄模式显著不同。例如，茶碱和氟西汀等药物可引起新生儿黄疸、脑水肿和呼吸抑制等ADR，这正是由于代谢途径尚未成熟，使儿童更容易受到药物毒性的影响。神经系统的发育可塑性使儿科药理学变得更加复杂。阿立哌唑和氟西汀等神经系统药物在儿童中的不良反应谱与成人显著不同，表现为对肌肉僵硬、认知障碍和神经功能紊乱更为敏感。需要强调的是，这些差异并非简单的剂量问题，而是源于儿童期特有的神经网络发育过程。此期间进行的药物干预可能显著影响神经发育轨迹，形成一个动态而敏感的生理状态。\n器官的特异性脆弱性进一步凸显了儿科与成人药理学之间的巨大差异。儿童心血管和呼吸系统正处于快速发育成熟阶段，与成人相比面临着独特的用药安全风险。洛沙坦和普伐他汀等药物充分体现了这些差异：在成人中主要表现为心血管系统变化，而在新生儿中则以代谢紊乱为主。\nunset\nunset\n研究意义与未来展望\nunset\nunset\n本研究提出了首个综合性的儿科药物警戒框架，创新性地将共识驱动的信号检测方法与基于层次化生物学指纹特征的机器学习建模相结合。通过在FAERS数据库中应用稳健的投票机制构建大规模儿科特异性ADR数据集，并系统整合多层次生物学特征，本研究为特殊人群的药物安全研究提供了可借鉴的方法学框架。\n研究结果揭示了儿童与成人在药物不良反应谱上的实质性差异，表明儿童药物安全必须进行独立评估，不能简单依赖成人数据进行推断。通过这一计算框架，研究团队成功识别了多个具有历史意义的儿科ADR案例，包括氯霉素诱导的灰婴综合征等有充分文献记载的典型病例。这些发现充分说明，建立独立的儿科药物警戒系统至关重要。\n需要指出的是，尽管研究采用了严格的数据预处理和多方法共识策略来控制数据质量，但基于自发报告系统的数据仍存在漏报、报告偏倚和临床异质性等固有局限。此外，本研究将儿科人群定义为0-14岁，这一范围不可避免地涵盖了多个生理特征迥异的发育阶段。未来研究若能整合更精细的年龄分层数据和纵向临床随访信息，将有望进一步提高模型的准确性和临床适用性。\n本研究为儿科药物不良反应预测提供了一套系统化的方法框架，填补了特殊人群药物警戒研究的重要空白。研究不仅揭示了儿童与成人在药物安全性上的本质差异，更构建了可实际应用的计算预测流程，为提升儿科用药安全和完善药品监管风险评估提供了有力的技术支撑。\n参考资料：\nTian, Y., Yi, J., Li, K.\net al.\nMachine learning prediction of pediatric adverse drug reactions using consensus-derived scarce data.\nCommun Chem\n(2025). https://doi.org/10.1038/s42004-025-01865-9\n投稿人\n| 田  垚\n责   编\n|\n许燕红\n审   核\n|\n蒋德军",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512504&idx=1&sn=ea724c1fa4ff8da9eabb2bf145192c8c&chksm=fdc622c37a2c31197b8e047ea066ff32608d5f4906fe9af423764342541a625fef51bd610081&scene=0&xtrack=1#rd",
      "publish_time": 1767544200,
      "publish_date": "2026-01-05 00:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s42004-025-01865-9\"]",
      "add_ts": 1767568679,
      "last_modify_ts": 1767741752
    },
    {
      "id": 198,
      "article_id": "51626",
      "title": "仅需5秒一步实现克隆！Chatterbox-Turbo 实现高采样率无损音质的语音生成",
      "description": "Resemble AI推出开源高性能对话式TTS模型Chatterbox-Turbo，采用350M参数非自回归架构，结合知识蒸馏技术，将语音生成步数从十步降至一步，显著提升速度与效率。支持高保真语音克隆、原生副语言标签及隐式水印合规追踪，适用于智能客服、数字人、游戏NPC、有声书与多语言教育等实时交互场景，已在HyperAI官网开放体验。",
      "content": "近期，Resemble AI 发布高性能对话式文本转语音（\nTTS\n）模型 Chatterbox-Turbo，这是首个开源的情绪程度控制模型。\n该模型基于一个经过精简的 350M 参数架构构建，采用先进的非自回归生成架构，能够在生成高质量语音的同时，显著降低对计算资源与显存的需求，相比之前的模型实现了性能提升。\n此外，开发团队通过知识蒸馏技术，优化了原模型中构成生成瓶颈的语音表征解码器，\n成功将语音生成步骤从十步减少到一步，\n在极大提升生成速度的同时，确保了音频输出仍保持高保真度。\nChatterbox-Turbo 结合了 T3（Text-to-Token Transformer）语义处理模块与专为实时对话优化的 S3Gen 流量匹配解码器。其主要技术优势包括：\n* 优化推理效率：\n专为实时互动设计的 Turbo 版本显著提升输出效率，同时不牺牲高采样率输出。\n* 高保真克隆少数语音片段：\n只需 5 至 10 秒的参考音频，即可精确复制目标声音的音色、语调和韵律。\n* 原生副语言标签支持：\n集成的基于标签的控制，能够无缝生成如笑声、咳嗽声或叹息声等非语言信号，显著提升了人机对话的自然感。\n* 嵌入式合规性：\n系统采用 Perth 隐式音频水印技术，提供强大的来源追踪和版权保护，同时不影响音质。\nChatterbox-Turbo 的强大实时能力驱动了多领域创新：在智能客服与数字人领域，它能实现毫秒级响应；在游戏领域，为游戏开发提供动态 NPC 语音与情感化互动；在播客及有声书领域，提供高性价比方案生成高质量朗读；并能在多语言教育中，模拟带口音的自然情境对话。\n目前，HyperAI超神经官网已上线了\n「Chatterbox-Turbo 高性能对话式语音合成」，快来试试吧~\n在线使用：\nhttps://go.hyper.ai/GTYF4\n12 月 22 日-12 月 26 日，hyper.ai 官网更新速览：\n* 优质教程精选：4 个\n* 热门百科词条：5 条\n* 1 月截稿顶会：11 个\n访问官网：\nhyper.ai\n公共教程精选\n1. Chatterbox-Turbo 高性能对话式语音合成\nChatterbox-Turbo 由 Resemble AI 发布的一款高性能对话式文本转语音（TTS）框架，旨在为下一代 AI 代理提供超高速、富有表现力且情感细腻的语音交互。通过采用先进的非自回归生成架构，该模型在保持最小推理延迟的同时，实现了卓越的音频保真和音色准确性。其核心技术创新在于将流量匹配与高效的变换器骨干网集成，有效解决了传统 TTS 模型在长序列生成中常见的速度瓶颈。\n在线运行：https://go.hyper.ai/GTYF4\n2. Qwen Image Layered Interface 自动拆分多个图层\nQwen Image Layered 是由阿里 Qwen 团队发布的开源图像理解与分解模型。它专注于自动将复杂的自然图像分解为多个语义上连贯且空间对齐的图像层，基于单一输入图像，利用多阶段扩散和结构建模机制生成一组具有清晰语义层级的可视化层。它适用于图像结构分析、分层编辑、内容理解和多模态应用。\n在线运行：https://go.hyper.ai/RRZ0a\n3. LightOnOCR-1B-Interface：面向复杂文档的高速 OCR 引擎\nLightOnOCR-1B-1025 由 LightOn 发布的一款拥有 10 亿参数的端到端视觉语言 OCR 模型，专为从扫描文档、复杂布局页面和高分辨率 PDF 中提取文本而设计。该模型结合了基于 Pixtral 的 Vision Transformer 编码器和轻量级 Qwen3 文本解码器，两者均深度优化用于文档解析。它能够从高分辨率页面中执行布局感知、高精度的文本提取，并且在表格、收据、表格、数学符号和多列布局方面表现出色。\n在线运行：https://go.hyper.ai/JKERT\n4. LongCat-Image-Edit-Interface：双语文本驱动图像编辑系统\nLongCat-Image-Edit 是由美团 LongCat 团队发布的一款开源基于指令的图像编辑模型。基于 LongCat-Image 基础模型框架，它适用于中英双语场景，专注于通过自然语言指令对现有图像进行精准且可控的视觉修改。\n在线运行：https://go.hyper.ai/2OKU3\n💡\n我们还建立了\nStable Diffusion\n教程交流群，欢迎小伙伴们扫码备注【SD教程】，入群探讨各类技术问题、分享应用效果~\n热门百科词条精选\n1.\n核范数 Nuclear Norm\n2. 双向长短期记忆 Bi-LSTM\n3. 地面真实值\nGround Truth\n4. 具身导航 Embodied Navigation\n5. 每秒帧数 Frames Per Second (FPS)\n这里汇编了数百条 AI 相关词条，让你在这里读懂「人工智能」：\nhttps://go.hyper.ai/wiki\n1 月截稿顶会\n1.2\n8:00:00\nVLDB 2026\n1.6\n19:59:59\nACL 2026\n1.15\n19:59:59\nCCS 2026\n1.18\n19:59:59\nSIGMOD 2027\n1.20\n19:59:59\nIJCAI 2026\n1.23\n6:00:00\nSIGGRAPH 2026\n1.23\n19:59:59\nSIGIR 2026\n1.23\n19:59:59\nLICS 2026\n1.29\n19:59:59\nICML 2026\n1.29\n19:59:59\nCAV 2026\n1.30\n19:59:59\nISSTA 2026\n一站式追踪人工智能学术顶会：\nhttps://go.hyper.ai/event\n以上就是本周编辑精选的全部内容，如果你有想要收录 hyper.ai 官方网站的资源，也欢迎留言或投稿告诉我们哦！\n下周再见！\n关于 HyperAI超神经 (hyper.ai)\nHyperAI超神经 (hyper.ai) 是国内领先的人工智能及高性能计算社区，\n致力于成为国内数据科学领域的基础设施，为国内开发者提供丰富、优质的公共资源，截至目前已经：\n* 为 1800+ 公开数据集提供国内加速下载节点\n* 收录 600+ 经典及流行在线教程\n* 解读 200+ AI4Science 论文案例\n* 支持 600+ 相关词条查询\n* 托管国内首个完整的 Apache TVM 中文文档\n访问官网开启学习之旅：\nhttps://hyper.ai/\n内容中包含的图片若涉及版权问题，请及时与我们联系删除",
      "article_url": "https://hub.baai.ac.cn/view/51626",
      "publish_time": 1767524460,
      "publish_date": "2026-01-04 19:01",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://go.hyper.ai/GTYF4\", \"https://go.hyper.ai/RRZ0a\", \"https://go.hyper.ai/JKERT\", \"https://go.hyper.ai/2OKU3\", \"https://go.hyper.ai/wiki\", \"https://go.hyper.ai/event\", \"https://hyper.ai/\"]",
      "add_ts": 1767568682,
      "last_modify_ts": 1767655308
    },
    {
      "id": 199,
      "article_id": "51624",
      "title": "Nat. Comput. Sci. | 迈向机器人辅助化学实验室自动化的数字孪生",
      "description": "MATTERIX是一种多尺度、GPU加速的机器人仿真框架，旨在构建高保真化学实验室数字孪生，以加速材料与化学发现。该平台可同步模拟机器人操作、液体与粉体动力学、实验设备功能、热传递及基础化学反应动力学，突破传统实验对真实环境的依赖。通过融合物理仿真、语义建模与分层工作流设计，MATTERIX显著提升实验流程的规模化与迭代效率，为应对全球性挑战提供高效、可扩展的虚拟研发解决方案。",
      "content": "DRUG\nONE\n加速材料与化学发现对于应对全球性挑战至关重要，但当前实验流程的开发高度依赖真实实验环境，严重限制了规模化与迭代效率。研究人员提出 MATTERIX，一个多尺度、GPU 加速的机器人仿真框架，用于构建高保真化学实验室数字孪生。该平台能够同时模拟机器人操作、液体与粉体动力学、实验设备功能、热传递以及基础化学反应动力学。通过将物理仿真、语义建模与分层工作流设计相结合，MATTERIX 支持从虚拟环境到真实实验室的无缝迁移，显著降低对高成本真实实验试错的依赖，并为自动化化学工作流的设计、验证与优化提供统一平台。\n尽管实验室自动化和“自驱动实验室”近年来取得重要进展，但复杂化学实验流程的设计和部署仍主要在真实实验室中完成。这种方式不仅耗时、昂贵，还难以支持大规模参数探索和学习型方法的训练。相比之下，数字孪生技术已在制造业和自动驾驶等领域展示出巨大潜力，但在化学实验室自动化中的系统性应用仍然不足。\n化学实验室的复杂性体现在多方面：多类型机器人协作、液体与粉体处理、设备功能逻辑、热与反应动力学耦合，以及高安全性要求。现有仿真工具往往只能覆盖其中的部分要素，缺乏一个统一的、多尺度的解决方案。MATTERIX 正是为填补这一空白而提出。\n方法\nMATTERIX 构建在高性能物理仿真引擎之上，并引入一个 GPU 加速的语义引擎，用于模拟传统机器人仿真难以覆盖的行为，如设备逻辑、热传递和简化化学反应过程。研究人员通过资产库快速构建数字实验室环境，并使用分层状态机将底层操作技能组合成高层化学工作流。系统支持刚体、液体、粉体和多机器人协作，并通过感知模块将真实实验室中的物体位姿同步到数字孪生环境，实现从仿真到现实的部署。\n图 1｜MATTERIX 总体架构与数字孪生流程。\n图 2| 数字孪生要求及与 MATTERIX 的比较。\n结果\n数字实验室环境的构建能力\nMATTERIX 提供了丰富的三维实验室资产库，包括玻璃器皿、机器人机械臂、液体处理平台及完整实验室场景。研究人员展示了从简单工作站到完整化学实验室的数字孪生构建过程，并支持基于三维感知技术从真实实验室快速生成对应虚拟环境。\n图 2｜数字实验室环境与资产库。\n操作、感知与技能库评估\nMATTERIX 内置可复用的操作与感知技能库，包括抓取、倒液、称量、粉体处理及多机器人协作。通过分层状态机，研究人员能够将底层操作组合为抽象技能，并进一步构建长时序实验流程。系统在 GPU 并行仿真下保持了较高的运行效率。\n图 4｜操作与感知技能库及其层级组合。\n物理–语义联合仿真性能\n通过引入语义引擎，MATTERIX 能够模拟热传递、设备状态变化和简化反应动力学。性能测试表明，在引入语义建模后，系统在大规模并行仿真场景下仅带来极小的 GPU 计算开销，保持了高吞吐率。\n多尺度化学工作流模拟\n研究人员展示了有机反应与多步氧化还原反应的完整数字孪生模拟，涵盖样品转移、加热、反应执行和结果验证等环节。模拟结果在反应趋势和过程逻辑上与真实实验保持一致，为实验设计与验证提供了可靠虚拟环境。\n图 5｜多尺度化学实验流程的数字孪生模拟。\n仿真到真实实验室的部署验证\nMATTERIX 支持将仿真中设计的工作流直接部署到真实实验室。研究人员在真实环境中验证了抓取放置、倒液操作以及机器人与自动化液体处理平台的协同工作，展示了较高的成功率和可重复性。\n图 6｜仿真到真实实验室的工作流迁移。\n讨论\nMATTERIX 为机器人辅助化学实验室自动化提供了一个统一、多尺度的数字孪生框架，在工作流设计、验证与部署方面显著降低了实验成本和开发周期。其物理与语义联合建模、分层技能与工作流表示，以及仿真到现实的无缝迁移能力，使其区别于以往面向单一任务的仿真工具。\n同时，MATTERIX 仍存在局限，例如化学反应动力学的近似建模、对复杂多相体系的支持不足，以及真实环境与仿真环境之间的差异。未来，通过引入更精细的物理与化学模型、结合大语言模型进行自动化工作流规划，以及利用实时传感数据进行在线校正，MATTERIX 有望进一步提升其作为“自驱动实验室”核心基础设施的价值。\n整理 | DrugOne团队\n参考资料\nDarvish, K., Sohal, A., Mandal, A. et al. MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation. Nat Comput Sci (2025).\nhttps://doi.org/10.1038/s43588-025-00924-4\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512499&idx=2&sn=b914a18ee49855a66229f79d87acd6e4&chksm=fd1a648d6c8d833337a3e363a853ced7be84855688788b0218efeaecd13fcd9114f59343600b&scene=0&xtrack=1#rd",
      "publish_time": 1767497040,
      "publish_date": "2026-01-04 11:24",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s43588-025-00924-4\"]",
      "add_ts": 1767568686,
      "last_modify_ts": 1767655313
    },
    {
      "id": 200,
      "article_id": "51623",
      "title": "继Ilya之后，KAN一作再发檄文：Scaling终将撞铁壁！",
      "description": "刘子鸣，KAN网络一作，于2025年圣诞发表新作，直指当前AI发展核心痛点——Scaling Law依赖海量资源“穷举”实现性能提升，实为伪智能。他认为，真正的AGI应追求“大道至简”，而非靠算力堆砌。继Ilya之后，他以柯尔莫哥洛夫-阿诺德网络为基，挑战主流范式，呼吁转向更简洁、可解释、高效的学习路径，推动AI向本质智能演进。",
      "content": "新智元报道\n编辑：KingHZ\n【新智元导读】\nKAN网络作者刘子鸣新作直击痛点：Scaling Law虽然能通过「穷举」达成目标，但其本质是用无限资源换取伪智能。而真正的AGI应大道至简。\n继Ilya之后，\n柯尔莫哥洛夫-阿诺德网络KAN一作\n向Scaling Law发出最新檄文！\n2025年圣诞节，斯坦福大学博士后、清华大学赴任助理教授刘子鸣把矛头对准了Scaling Law。\n在他看来，如今的大模型，更像是在用\n无限算力和数据做穷举\n，换来的却只是\n看起来聪明的假智能\n。\n而真正的AGI应当像物理学定律一样，用最简洁的「结构」驾驭无限的世界。\n刘子鸣话说很直白：\n要想聪明地造出AGI，我们缺的不是规模，而是结构\n。\n在他看来，结构主义AI并不是为了「否定」 Scaling Law。\n问题在于，Scaling\n终究会撞上两堵墙：\n能源和数据\n。\n当这两样东西耗尽时，Scaling的路，也就到头了。\nScaling Law\n用战术上的勤奋掩盖战略上的懒惰\n在过去数年中，\nScaling Law几乎成为\nAI\n的「黄金法则」。\n它的地位，就像AI界的「元素周期表」——\n一旦被发现，整个方向都被统一了。\n这一经验规律揭示了模型性能与模型规模、数据量、计算量之间的幂律关系：\n当模型参数、\n训练数据\n和算力不断增加时，模型性能会持续提升\n。\n然而，Scaling Law背后的逻辑却出奇简单：由于在分布外任务上，AI表现不佳，最直接的解决方案就是收集更多数据、训练更大模型，直到一切任务都变得「分布内」。\n换句话说，这就是AI版的「大力出奇迹」。\n因此，Scaling Law提供了一个\n可靠但低效\n的未来。\n其实，刘子鸣的立场非常明确：\n如果大家完全忽略能源与数据的限制，我毫不怀疑仅靠Scaling Law最终能够实现通用人工智能。\n我从未怀疑过这一点。\n如果算力无限、数据无穷，大模型原则上可以覆盖一切。\n问题恰恰在于——现实世界并不是这样。\n算力有限。能源有限。高质量数据，同样有限。\n于是，真正的问题浮出水面：\n有没有一条更明智的路，在资源有限的前提下，走向AGI？\n资源有限\nAGI需要「智能」而非「蛮力」\n刘子鸣认为有：\n答案不是更大的规模，而是更多的结构。\n注意：这里是结构而非符号。他有意区分了这一点。\n为什么我们需要的是结构？\n因为结构能带来压缩。而压缩正是智能的核心。正如Ilya曾经说过的那样：\n压缩就是智能（Compression is intelligence）\n。\n举个简单例子。\n如果允许分形结构，那么雪花的内在复杂度极低——它是高度可压缩的。如果不允许结构、必须逐点描述它，那么雪花的表观复杂度几乎是无限的。\n今天的Scaling Law更像后者：用越来越多的参数和计算去拟合巨大的表观复杂度。\n一个更深的例子来自天体力学。\n对行星运动建模最直接的方法，是把行星在每一个时刻的位置都存下来——一个成本极其高昂的查找表。\n随后，发生了两次关键的「结构化压缩」：\n开普勒意识到行星轨道是椭圆，从而第一次实现了真正的压缩：他找到了一个贯穿时间的全局结构，复杂度立刻大幅下降。\n牛顿则发现了局部的动力学定律，实现了第二次压缩：用更少的参数解释了更多现象。\n那么，现代AI大致站在什么位置？\nKeyon Vafa和合作者的研究表明，Transformer并不会自然地学出牛顿式的世界模型。\n这意味着：\n正确的物理结构并不会因为你把模型做得更大，就可靠地自动涌现。\n如果我们把「结构终将涌现」当作默认信条，很多时候就像原始人的祈祷。\n区别只是：我们的祭品（数据与算力）确实在一定程度上有效。也正因为它有效，我们反而缺少动力去追问更科学、更明智的路径。\n自然科学之所以成立，是因为结构是显式的，而且无处不在。没有结构，就不会有自然科学。\n沿着「第谷–开普勒–牛顿」的轨迹做类比：\n在很大程度上，\n今天的AI仍像「第谷时代」：实验驱动、数据驱动；\n只是刚刚进入「开普勒式阶段」：出现了像Scaling Law这样的经验规律。\n但问题在于：我们把经验规律变成了信条。\n大家选择了激进Scaling、围绕经验规律做工程化系统，而不是把它们当作通往更深理论的线索——一种属于AI的「牛顿力学」。\n从思想层面看，这并不是\n进步\n，反而可能是一种\n退步\n。\n到这里你可能会反问：这不就是「批评Scaling、批评基础模型」的老生常谈吗？刘子鸣不就是年轻版Yann LeCun吗？\n不。并非如此。\n刘子鸣选择了另一条路。\n另一条路，\n在联结主义x符号主义之外\n刘子鸣的立场更中性：按照「无免费午餐」（No Free Lunch）的视角，每一种模型都有适用范围和局限。\n直白一点：\n所有模型都是错的，但有些是有用的。\n关键问题不在「用不用基础模型」，而在我们是否真正理解：\n不同任务，具有本质不同的结构与可压缩性。\n从「压缩」的角度，并借鉴自然科学的类比，任务大致可分为三类：\n类物理任务\n：高度可压缩，符号公式可能从连续数据中涌现出来。\n类化学任务\n：可压缩性强、结构清晰，但符号往往不完整或只能近似。\n类生物任务\n：只能弱压缩，更多依赖经验规律与统计归纳。\n纯噪声当然存在，但任何模型都处理不了，可先忽略。\n一个理想的智能系统，应该能判断自己面对的是哪一类任务，并施加\n恰到好处\n的压缩。\n符号模型擅长类物理任务，却在类化学与类生物任务上失败。\n联结主义模型因其通用性，原则上可处理所有类型——但恰恰因其缺乏结构，在类物理与类化学问题上极其低效。\n这便是他主张结构主义的原因。\n结构主义既不是Thinking Machines青睐的联结主义，也不看好一度洛阳纸贵的符号主义，也不是两者简单杂交出的「双头怪兽」。\n符号主义从类物理任务出发，联结主义从类生物任务出发。\n一个自然而然的问题是：我们能否从类化学任务出发构建AI？\n结构主义的设计初衷，正是要捕捉这一中间状态。\n符号是一种更严格、更离散的结构，而经验规律是一种更松散的结构。\n我们期望符号能从结构中涌现；也期望经验规律能通过从数据中松弛结构而习得。\n在监督学习里，这种区分已经相当具体。\n线性回归是符号主义的。\n多层感知机（MLP）是联结主义的。\n方程学习器(EQL，equation learner)则是神经–符号混合。\n相比之下，Kolmogorov–Arnold Networks（KANs）是结构主义的。\nKAN背后的表示理论可以紧凑地捕捉多变量函数的组合结构。因此，KAN既不像MLP那样无结构，也不像线性模型那样过度约束，也不会因为神经–符号不匹配而充满不稳定性。\n结构主义不是一种妥协。它是一种统一。\n但真实世界远不止监督学习。\n我们不只是从数据里学习结构，我们还会比较结构、复用结构，并构建「结构的结构」。\n这就是抽象。\n范畴论研究「结构的结构」\n刘子鸣把话说得更明确：\n抽象可能是AGI最核心的瓶颈之一。\n这一点也与Rich Sutton在OaK架构里对抽象的强调相呼应：\n持续学习，本质是在跨任务保留抽象不变性；\n适应性与流动性（例如ARC-AGI语境）体现为在上下文中即时做抽象；\n许多ARC-AGI任务，本质上是「直观物理」的简化形式，而直观物理恰恰是世界模型的关键组成。\n未来之路\n如何让抽象发生？\n刘子鸣坦言：\n还没有完整解法。\n刘子鸣有一个洞见是：\n抽象来自对结构的比较与复用\n。\n注意力（Attention）当然也是一种比较机制，但它隐含了两个强假设：\n结构可以嵌入向量空间；\n相似性可以用点积来度量。\n现实中，很多结构并不与向量空间同构。\n这种表示方式之所以被广泛采用，很大程度上不是因为它在认知上或科学上更正确，而是因为它更适配GPU计算范式。\n他认为，当下AI的发展其实「暗地里」已经很结构主义，但更多是\n外在意义上的结构主义\n：\n推理过程是结构化的；\nAI智能体框架是结构化的；\n但底层模型依然是联结主义的。\n这带来一个直接后果：系统高度依赖Chain-of-Thought（思维链，CoT）数据，通过显式监督把结构「贴」在模型外面。\n他更愿意押注：下一波关键进展会来自\n内在结构主义\n——\n把通用结构注入模型，或让结构在模型内部自行涌现，而不是持续依赖显式CoT监督来「外置结构」。\n从应用角度看，我们真正需要的通用人工智能，必须同时满足：\n高效\n可适应\n可泛化\n具备物理基础\n结构对这四点都至关重要。\n因为物理世界本身就是高度结构化、也高度可压缩的：可组合性、稀疏性和时间局部性。\n如果这些结构无法在模型里出现，「世界模型」就仍遥不可及。\n总结一下：结构主义AI代表了一条与Scaling根本不同的道路。\n它可能更难，但也更有趣、机会更多，而且长远看来看更有前途。\n到了2026年，是时候把筹码押在不一样的方向上并身体力行：\n结构，而不是规模\n。\n参考资料：\nhttps://kindxiaoming.github.io/blog/2025/structuralism-ai/\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659818&idx=2&sn=eacd1126408ed49374fe1cd4656c45d1&chksm=f02edb4625981ee6014c9181ea8b1925566b2e3708fc12ecfb4d5216e2754e4a91cf995466fc&scene=0&xtrack=1#rd",
      "publish_time": 1767496920,
      "publish_date": "2026-01-04 11:22",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://kindxiaoming.github.io/blog/2025/structuralism-ai/\"]",
      "add_ts": 1767568689,
      "last_modify_ts": 1767655318
    },
    {
      "id": 204,
      "article_id": "51619",
      "title": "刚刚，DeepSeek扔出大杀器，梁文锋署名！暴力优化AI架构",
      "description": "新智元报道  编辑：编辑部【新智元导读】2026新年第一天，DeepSeek发表了梁文锋署名的重磅新论文，提出了一种名为「mHC（流形约束超连接）」的新架构，在27B参数模型上，仅增加约6.7%的训练时间开销，即可实现显著性能提升。重磅！刚刚，DeepSeek送上2026年新年第一个王炸。这次的创新是，mHC（流形约束超连接）新架构。标题：mHC：Manifold-Constrained Hy",
      "content": "新智元报道\n编辑：编辑部\n【新智元导读】\n2026新年第一天，DeepSeek发表了梁文锋署名的重磅新论文，提出了一种名为「mHC（流形约束超连接）」的新架构，在27B参数模型上，仅增加约6.7%的训练时间开销，即可实现显著性能提升。\n重磅！\n刚刚，\nDeepSeek送上2026年新年第一个王炸\n。\n这次的创新是，\nmHC\n（流形约束超连接）新架构。\n标题：mHC：Manifold-Constrained Hyper-Connections\n链接：https://arxiv.org/abs/2512.24880\n在这篇论文中，DeepSeek提出了流形约束超连接（mHC），将矩阵投影到约束流形上优化残差连接空间，从而确保稳定性，彻底颠覆了传统AI架构认知——\n可以扩大残差流通道宽度（residual stream width）\n，而在算力和内存上的代价却微乎其微。\n图1： 残差连接范式示意图\n继Hyper-Connections（HC）开辟「残差连接宽度可扩展」路线之后，mHC直接把这一思路推上实用化的快车道。\nDeepSeek这次直击AI痛点，给同行上了一课！\n值得一提的是，这次梁文锋署名，但解振达、韦毅轩、Huanqi Cao为核心贡献者，解振达为通讯作者。\nDeepSeek，或敲响ResNet丧钟\n这简直是为「模型优化玩家」量身打造的王牌秘方。\n过去，超连接（hyper-connections）更多只是学术圈的小众尝试。\n而现在，DeepSeek直接把它升级为基础架构的核心设计要素。\n这也正是拥趸一直以来对DeepSeek的期待：数学上的洞察力+硬件层面的极致优化。\n顶级大语言模型（LLM）中，ResNet结构或许即将被淘汰。\n毕竟，残差流通道宽度一直是扩展模型的「烦人瓶颈」。\n这波操作，也再次展现了DeepSeek典型的风格：对同行的温和降维打击——\n你们两年时间都在打磨微结构，调整DS-MoE？挺可爱哈。\n来看看我们怎么玩：把一个理论上看起来还不够成熟的高级原语，直接做实，顺手解锁游戏下一关。\n他们在论文中写道：「我们的内部大规模训练实验进一步验证了mHC在大规模应用中的有效性。」\n这句话在DeepSeek的原生稀疏注意力（Natively trainable Sparse Attention，NAS）那篇论文里可没有。\n在27B模型的系统级基准测试结果中，\n新架构mHC在绝大多数基准测试中持续超越基线模型并优于HC，这证明其在大规模预训练中的有效性\n。\n换句话说，DeepSeek信心十足，不怕同行知道自己的「杀招」。\n这给了DeepSeek的铁粉Teortaxes很大信心，他有九成把握：mHC会进入DeepSeek V4。\n核心方法\nManifold-Constrained Hyper-Connections (mHC)\n这个方法的关键目标，就是在Hyper-Connections的拓扑设计下恢复身份映射属性。这样，就可以在大规模训练与现实基础模型任务中体现实际价值。\nmHC与传统残差连接和HC的根本差异在于：\n传统残差连接\n只保留简单的输入 + 输出形式（稳定但表达受限）；\nHyper-Connections (HC)\n强化连接能力，但牺牲了稳定性与效率。\n而mHC的思路是：\n将Hyper-Connections的参数空间约束到特定的流形（manifold）上，以恢复恒等映射结构。\n技术细节\n受\n恒等映射原则\n的启发，mHC的核心思想是在一个\n特定流形\n上对残差映\n进行约束。尽管原始的恒等映射通过强制\n来保证训练稳定性，但这种做法从根本上\n阻断了残差流内部的信息交互\n，而这种交互对于充分发挥多流（multi-stream）架构的潜力至关重要。\n因此，作者提出将残差映射投影到一个既能维持跨层信号传播稳定性、又能促进残差流之间相互作用的流形上，从而在保证稳定性的同时保留模型的表达能力。\n为此，他们将\n约束为\n双随机矩阵\n，即矩阵元素非负，且每一行与每一列的元素之和均为 1。\n形式化地，记\n为双随机矩阵所构成的流形（亦称\nBirkhoff多面体\n），将\n约束在其投影\n上，其定义为：\n需要注意的是，当n=1时，双随机条件会退化为标量1，从而恢复为原始的恒等映射。选择双随机性能够带来若干对大规模模型训练具有重要意义的严格理论性质：\n1.\n保\n范性：\n双随机矩阵的谱范数有上界 1，即\n。\n这意味着该可学习映射是非扩张的，从而能够有效缓解梯度爆炸问题。\n2.组合闭包性\n：\n双随机矩阵集合在矩阵乘法下是封闭的。这保证了跨越多层的复合残差映射\n仍然是双随机的，从而在整个模型深度范围内保持稳定性。\n3.通过Birkhoff多面体的几何解释\n：\n集合\n构成Birkhoff多面体，即置换矩阵集合的凸包。\n这提供了清晰的几何直观：残差映射可以被看作是若干置换的凸组合。\n从数学上看，此类矩阵的反复作用会单调地增强不同信息流之间的混合程度，从而有效地充当一种鲁棒的特征融合机制。\n参数化与流形投影\n在本节中，作者详细介绍了mHC中\n、\n以及\n的计算过程。\n给定第l层的输入隐藏矩阵\n，首先将其展平成向量\n，以保留完整的上下文信息。随后，遵循原始HC的建模方式，得到动态映射和静态映射，具体如下：\n随后，通过如下方式得到最终满足约束的映射：\n其中，\n表示Sigmoid函数。\nSinkhorn–Knopp(⋅) 算子首先通过指数运算保证所有元素为正，然后执行交替的迭代归一化过程，使矩阵的行和列分别归一到1。\n具体而言，以正矩阵\n作为初始值，归一化迭代过程为：\n随着迭代次数增加，当\n时，该过程收敛到一个双随机矩阵\n。\n在实验中，取\n作为一个实用的近似值。\n高效的基础设施设计\n通过一系列严格的工程优化，作者成功将mHC（取n=4）部署到大规模模型中，训练开销仅增加约 6.7%。\n内核融合\n作者观察到，在mHC中，当对高维隐藏状态\n进行操作时，RMSNorm会带来显著的延迟。\n为此，他们将「除以范数」的操作重新排序，使其发生在矩阵乘法之后。该优化在数学上是等价的，但在工程实现上显著提升了效率。\n此外，我们采用混合精度策略，在不牺牲计算速度的前提下最大化数值精度，并将多个具有共享内存访问模式的算子融合为统一的计算内核，以降低内存带宽瓶颈。\n基于公式（10）至（13）中给出的输入与参数设置，作者实现了三个专用的 mHC计算内核。\n利用上述内核计算得到的系数，他们又引入了两个额外的计算内核来应用这些映射。\n该框架能够简化复杂计算流程内核的实现，并在较小工程代价下充分发挥内存带宽的潜力。\n重计算\nn路残差结构在训练过程中会引入显著的内存开销。\n为缓解这一问题，作者在前向传播结束后丢弃mHC内核产生的中间激活，并在反向传播阶段通过重新执行mHC内核（不包含计算量较大的层函数F）来即时重计算这些激活。\n因此，对于连续的L_r个层组成的一个模块，只需存储第一层的输入\n。\n在忽略轻量级系数、同时考虑到F中的pre-norm开销后，表3总结了在反向传播中需要保留的中间激活以及在L_r个连续层中被重计算的瞬时激活。\n随后，他们通过最小化与L_r对应的总内存占用来确定最优的块大小\n。\nDualPipe中的通信重叠\n在大规模训练中，\n流水线并行（pipeline parallelism）\n是缓解参数与梯度内存占用的标准实践。\n具体而言，他们采用了\nDualPipe调度策略\n，该策略能够有效地重叠跨节点（scale-out）的互连通信流量，例如专家并行与流水线并行中的通信开销。\n然而，与单流（single-stream）设计相比，mHC中提出的\nn-流残差结构\n会在流水线阶段之间引入显著的通信延迟。\n此外，在阶段边界处，对所有Lr层重新计算mHC内核也会带来不可忽略的计算开销。为了解决这些瓶颈，作者对DualPipe调度进行了扩展（见下图），以在流水线阶段边界实现更高效的\n通信与计算重叠\n。\n原文图4：mHC的通信–计算重叠机制。\n具体而言，为避免阻塞通信流，他们把\nMLP（即FFN）层的\n内核\n放置在一个\n独立的高优先级计算流\n上执行。\n同时，在注意力层中，他们刻意避免使用长时间运行的持久化内核（persistent kernels），以防止产生长时间的停顿。\n该设计允许对已重叠的注意力计算进行抢占，从而在保持计算设备处理单元高利用率的同时，实现更加灵活的调度。\n此外，\n重计算过程被与流水线通信依赖解耦\n，这是因为每个阶段的初始激活x0l已经被缓存在本地。\n实验结果\nDeepSeek团队首先检验了27B模型的训练稳定性和收敛性。\n如下图（a）所示，mHC有效缓解了在HC中观察到的训练不稳定性，相比基线最终降低了0.021的损失。\n下图(b)中的梯度范数分析，进一步证实了这种改善的稳定性，表明mHC展现出显著优于HC的稳定性，与基线相当。\n原文图5： 流形约束超连接（mHC）的训练稳定性，展示了 (a) mHC与HC相对于基线的绝对训练\n损失\n差距，以及 (b) 三种方法的梯度范数。所有实验均采用27B模型。\n在多样化基准测试集上，mHC全面提升了下游性能，在所有任务上持续超越基线，并在大多数任务上优于HC。\n值得注意的是，与HC相比，mHC进一步增强了模型的推理能力，在BBH上实现了2.1%的性能提升，在DROP上实现了2.3%的提升。\n这证明其在大规模预训练中的有效性。\n原文表4：27B模型的系统级基准测试结果。 本表比较了基线、HC和mHC在8个不同下游基准测试中的零样本和少样本性能。\n为了评估方法的扩展性，DeepSeek报告了mHC在不同规模下相比基线的相对损失改进。\n结果表明，即使在更高的计算预算下，mHC依然稳健保持性能优势，仅轻微衰减。\n此外，研究团队考察了训练过程中的动态变化，展示了3B模型的token扩展曲线。\n综合来看，这些发现验证了mHC在大规模场景下的有效性。这一结论得到了我们内部大规模训练实验的进一步证实。\n原文图6：mHC相比基线的扩展特性。 (a) 计算扩展曲线：实线展示了不同计算预算下的性能差距。每个点代表模型大小和数据集大小的特定计算最优配置，从3B和9B扩展到27B参数。(b) Token扩展曲线：3B模型在训练期间的轨迹。每个点代表模型在不同训练token数下的性能。\n理想情况下，单层映射应满足双随机约束，即前向信号增益与后向梯度增益均等于1。\n然而，为提升计算效率，实际实现中使用的Sinkhorn-Knopp算法必须限制迭代次数，这次实验中为20次。\n因此，如下图(a)所示，后向梯度增益会略微偏离1。在下图(b)所示的复合映射情况下，偏离有所增加但仍保持有界，最大值约为1.6。\n原文图7：流形约束超连接（mHC）的传播稳定性。 本图展示了27B模型中 (a) 单层映射与 (b) 复合映射  的传播动态\n值得注意的是，与HC中近3000的最大增益幅度相比，\nmHC将其降低了三个数量级\n。\n这些结果表明，mHC相比HC显著增强了传播稳定性，确保了前向信号与后向梯度的稳定流动。\n此外，团队观察到，对于HC，当最大增益较大时，其他值也往往显著，这表明所有传播路径普遍存在不稳定性。相比之下，mHC始终产生稳定的结果。\n原文图8：可学习映射的可视化，展示了\nHC\n（第一行）与mHC（第二行）的代表性单层及复合映射。每个矩阵通过对选定序列内所有token取平均计算得出。y轴和x轴上的标签分别表示前向信号增益（行和）与后向梯度增益（列和）。\n更多详情请参阅原论文。\n参考资料：\nhttps://arxiv.org/abs/2512.24880\nhttps://x.com/teortaxesTex/status/2006628917428334631\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659737&idx=1&sn=67e75df37091ded752976f4f74e61c05&chksm=f02215448c91d98b86149d8ffe30c60403111d2d9a68122e94d4aec116b74f4dbce32c2e084c&scene=0&xtrack=1#rd",
      "publish_time": 1767496800,
      "publish_date": "2026-01-04 11:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.24880\", \"https://x.com/teortaxesTex/status/2006628917428334631\"]",
      "add_ts": 1767568706,
      "last_modify_ts": 1767655343
    },
    {
      "id": 205,
      "article_id": "51618",
      "title": "",
      "description": "SeedProteo是字节跳动Seed团队推出的蛋白从头设计框架，标志着蛋白质研究从“理解结构”迈向“创造结构”的重要突破。该模型基于AlphaFold系列的先进折叠架构，转化为高效生成系统，在结构预测基础上实现高精度、多样化的蛋白质设计，显著提升了生成蛋白的可折叠性与功能潜力，为合成生物学与药物开发提供了强大工具，树立了蛋白质设计新标杆。",
      "content": ":\n，\n.\nVideo\nMini Program\nLike\n，轻点两下取消赞\nWow\n，轻点两下取消在看",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512499&idx=1&sn=effeab297b94c9a2591e29435a3b6e20&chksm=fdda4947bbd6493b24278ce10f4a5a57ca180c76becd5402a01f473b48d493710c08f58e026a&scene=0&xtrack=1#rd",
      "publish_time": 1767496800,
      "publish_date": "2026-01-04 11:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767568709,
      "last_modify_ts": 1767655344
    },
    {
      "id": 207,
      "article_id": "51614",
      "title": "DeepSeek改造何恺明残差连接！梁文峰亲自署名，十年首次重大升级",
      "description": "2026年新年伊始，DeepSeek发布新论文，对何恺明2016年提出的ResNet核心组件“残差连接”进行升级。该研究由梁文峰署名，Zhenda Xie、Yixuan Wei、Huanqi Cao为共同一作。十年来残差连接未有本质改进，但其扩展应用已带来潜在问题。此次工作重新审视其设计，提出更高效稳定的新型残差结构，显著提升深度网络性能与训练稳定性，为深度学习基础架构带来重要突破。",
      "content": "梦晨 发自 凹非寺\n量子位 | 公众号 QbitAI\n2026年新年第一天，\nDeepSeek\n上传新论文。\n给何恺明2016成名作ResNet中提出的深度学习基础组件\n“残差连接”\n来了一场新时代的升级。\nDeepSeek\n梁文峰\n亲自署名论文，共同一作为Zhenda Xie , Yixuan Wei, Huanqi Cao。\n残差连接十年未变，扩展之后却带来隐患\n残差连接自2016年ResNet问世以来，一直是深度学习架构的基石。\n其核心机制简洁明了，x𝑙+1 = x𝑙 + F (x𝑙 ,W𝑙)，即下一层的输出等于当前层输入加上残差函数的输出。\n这个设计之所以成功，关键在于“恒等映射”属性，信号可以从浅层直接传递到深层，不经任何修改。\n随着Transformer架构的崛起，这一范式已成为GPT、LLaMA等大语言模型的标准配置。\n这个设计之所以成功，关键在于\n“恒等映射”\n属性，信号可以从浅层直接传递到深层，不经任何修改。\n近期出现的\nHyper-Connections（HC）\n试图打破这一格局。HC由字节跳动Seed团队在2024年首次提出，它将残差流的宽度从C维扩展到n×C维，并引入三个可学习的映射矩阵来管理信息流动。\nDeepSeek团队的实验表明，在这三个映射中，负责残差流内部信息交换的Hres矩阵贡献了最显著的性能提升。\n但问题随之而来，当HC扩展到多层时，复合映射不再保持恒等性质。\n论文中展示的27B模型训练曲线显示，HC在约12000步时出现了突发的损失激增，梯度范数也表现出剧烈波动。\n研究团队计算了复合映射对信号的放大倍数：在HC中，这个值的峰值达到了3000，\n意味着信号在层间传播时可能被放大数千倍，或者相应地被衰减至近乎消失\n。\n双随机矩阵的三重保障\nDeepSeek论文的核心思路是将残差映射矩阵约束到一个特定的流形上，一个\n由双随机矩阵构成的Birkhoff多面体\n。\n双随机矩阵的每一行和每一列之和都等于1，所有元素非负。这种约束带来了三个关键的理论性质。\n第一是范数保持：\n双随机矩阵的谱范数不超过1，这意味着信号在经过映射后不会被放大，有效防止了梯度爆炸。\n第二是组合封闭：\n多个双随机矩阵相乘的结果仍然是双随机矩阵，因此无论网络多深，跨层的复合映射都能保持稳定性。\n第三是几何解释：\nBirkhoff多面体是所有排列矩阵的凸包，残差映射实际上是在对特征做凸组合，相当于一种稳健的特征融合机制。\n为了将任意矩阵投影到这个流形上，论文采用了\nSinkhorn-Knopp\n算法。该算法先对矩阵取指数使所有元素为正，然后交替对行和列进行归一化，迭代收敛到双随机矩阵。\n实验数据显示，这个近似解已经足够有效：在27B模型中，mHC的复合映射信号增益最大值约为1.6，与HC的3000形成了三个数量级的差距。\n工程优化：从内核融合到流水线重叠\n接下来进入DeepSeek的拿手好戏，工程优化环节。\n扩展残差流宽度必然带来额外的内存访问开销，论文详细分析了每个token的内存读写成本：\n标准残差连接需要读取2C个元素、写入C个元素，而HC需要读取(5n+1)C + n² + 2n个元素、写入(3n+1)C + n² + 2n个元素。\n当扩展率n=4时，这是一个相当可观的增量。\n团队为此开发了一系列基础设施优化，他们使用\nTileLang框架\n实现了多个融合内核，将原本分散的操作合并执行以减少内存访问次数。\n针对Sinkhorn-Knopp算法，他们设计了专门的前向和反向内核，在芯片上重新计算中间结果以避免存储开销。\n在流水线并行方面，他们扩展了\nDualPipe调度策略\n，通过将MLP层的特定内核放在高优先级计算流上执行，实现了计算与通信的重叠。\n论文还给出了重计算策略的优化公式。对于L层的网络，最优的重计算块大小约为：\n这个值通常与流水线阶段的层数相当，因此研究者选择将重计算边界与流水线阶段边界对齐。\n实验验证：稳定性与性能兼得\n论文在3B、9B和27B三个规模的MoE模型上进行了验证，扩展率n设为4。\n在27B参数的MoE模型上，mHC展现出稳定的训练曲线，最终损失相比基线降低了0.021，同时保持了与baseline相当的梯度范数稳定性。\n在下游任务评测中，mHC在BBH推理任务上比HC提升2.1%，在DROP阅读理解任务上提升2.3%。mHC在大多数任务上不仅超过基线，还超过了HC。\n计算缩放曲线显示，mHC的性能优势在更高计算预算下仍然保持，仅出现轻微衰减。对3B模型的token缩放曲线分析表明，mHC的优势贯穿整个训练过程。\n论文提到，内部的大规模训练实验进一步证实了这些结论，且当扩展率n=4时，mHC仅引入6.7%的额外时间开销。\n论文地址： https://arxiv.org/abs/2512.24880\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859682&idx=1&sn=2847fa67445fc84e1d745e3f4680e56a&chksm=e9a38cc469a70345af22c97a05300084d764b12aa9cc3cbefcd60968867ba3a965c0c1631c8e&scene=0&xtrack=1#rd",
      "publish_time": 1767495600,
      "publish_date": "2026-01-04 11:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.24880\"]",
      "add_ts": 1767568719,
      "last_modify_ts": 1767655355
    },
    {
      "id": 208,
      "article_id": "51613",
      "title": "谷歌DeepMind爆出震撼预言！2026年，持续学习将让AI「永生」",
      "description": "谷歌DeepMind研究员预测，2026年将实现AI“持续学习”突破，解决当前大模型无法持续吸收新知识的痛点。这一进展或已在谷歌内部取得关键进展。Jeff Dean此前指出，缺乏持续学习是LLM的主要瓶颈。若突破成功，AI将在2030年实现全自动编程，长远或于2050年主导诺奖级科研，逐步接管科学发现主导权，标志着人类向AI让渡科学创新能力的开端。",
      "content": "新智元报道\n编辑：编辑部\n【新智元导读】\n2026年点亮持续学习，2030年实现全自动编程，2050年垄断诺奖级研究……人类向AI让渡科学主导权的倒计时，似乎已经开始。\n一早，谷歌DeepMind研究员重磅预测刷屏全网！\n2026年，将会成为「持续学习」之年。\n或许它已经在谷歌内部实现了。\n此前，Jeff Dean曾在NeurIPS 2025炉边谈话上，指出了目前LLM痛点在于「缺乏持续学习」。\n去年底，谷歌团队提出的「嵌套化方法」增强了LLM上下文处理能力，实现了持续学习。\n拓展阅读：\n终结Transformer统治！清华姚班校友出手，剑指AI「灾难性遗忘」\n持续学习，对于任何一个模型和智能体来说，至关重要。它是AI能否自我改进，不断涌现的一个核心要素。\nAnthropic CEO Dario Amodei也表示，持续学习将在2026年就搞定了，并能实用起来。\n实际上，AI这种持续学习的苗头，早已显现。\nAnthropic工程师自曝，过去一个月，自己对Claude Code的贡献，全部由AI 100%直出代码。\n另一位非技术型程序员Ben Tossell四个月，烧掉30亿Token，用Claude Code连造50个项目。\nTossell全程所做的，只是看着AI完成编码。\n这一刻，模型不再通过训练获得改进，而是在自编码过程中不断进化。\n人类不用插手，几乎0干预，全自动化编程和研究的时代更近了。\nOpenAI研究员Hieu Pham预测，2026将见证AI破解一个千禧年难题\n2030告别手搓代码？\n前OpenAI研究员揭秘ASI倒计时\n全自动化编程（Automated Coder, AC），会不会成为AGI乃至ASI加速到来的关键拐点？\n前OpenAI研究员Daniel Kokotajlo和他的团队给出了肯定答案。\n他们利用自主开发的AI Futures Model做出了惊人预测：\n2030年不仅可能实现完全自动化编程，更有约25%的概率在一年内实现向ASI的飞跃！\n团队认为，AC就像是AGI研发进入自动化加速阶段的「开关」。\n一旦这个开关被按下，ASI就极有可能快速起飞（25%概率在1年内实现）。\n扩展阅读（前作）：\n末日时间表来了！前OpenAI研究员76页硬核推演：2027年ASI接管世界，人类成NPC\nhttps://blog.ai-futures.org/p/ai-futures-model-dec-2025-update\n核心锚点：用METR-HRS外推「编码时间跨度」\n针对 AGI 时间线预测这一争议话题，团队认为METR-HRS是目前最适合用于线性外推至超强AI的基准。\n具体来说，就是以「能力基准趋势外推」作为核心方法，利用METR的编码时间跨度套件（METR-HRS）来设定达到AGI所需的有效算力，并沿着这条趋势线进行推演。\nAI Futures Model 将 AI 软件研发的自动化与加速轨迹，直观地划分为三个阶段：\n自动化编程\n自动化研究品味\n智能爆炸\n阶段1： 自动化编程\n首先预测「写代码」何时会被完全自动化。\n模型对自动化编程器（Automated Coder，AC）的定义非常硬核：\nAC可以将某个AGI项目的代码编写工作完全自动化，直接替代该项目的整个程序员团队。\n模型的推演起点的依据是METR图表的趋势外推，并预估「智能体式编码时间跨度」达到何种水平才算作AC。\n同时，模型不仅仅盯着曲线，还综合考量了多重变量：\n供给约束是否会导致增长放缓；\nAI研发自动化是否会带来加速效应；\n时间跨度趋势是否呈现超指数级增长；\n……\n阶段2：自动化研究品味\n除了代码之外，模型还追踪了另一项关键能力——研究品味（Research Taste）。\n它指的是确定研究方向、挑选实验、解读结果以及从实验中提取知识的能力。\n这更像是一种「团队协作」：写代码是执行力，研究品味是方向感。执行力再强，如果方向感跟不上，也只是在跑无效里程。\n阶段2的目标是预测从AC进化到超人类AI研究员（Superhuman AI Researcher，SAR）需要多长时间。\nSAR的定义同样强悍：\nSAR可以将AI研发完全自动化，完全替代所有人类研究员。\n这一阶段的速度取决于三个因素：\n写代码自动化能为AI研发带来多大的加速；\n当AC出现时，AI的研究品味已经达到了什么水平；\nAI研究品味的提升速度（即在同样的进展输入下，每做一次实验能带来多少额外价值）。\n阶段3：智能爆炸\n当AI研发实现完全自动化，模型便进入了最让人心跳加速的阶段：\nAI会以多快的速度自我提升，逼近智能上限。\n这一阶段追踪的里程碑包括：\n超智能AI研究员（Superintelligent AI Researcher，SIAR）：\n在顶尖AGI项目中，AI研究员与人类研究员的差距，达到了顶尖人类研究员与中位研究员差距的2倍。\n顶尖专家级AI（Top-human-Expert-Dominating AI，TED-AI）：\n在几乎所有认知任务上，至少达到顶尖人类专家的水平。\n超级人工智能（Artificial Superintelligence，ASI）：\n在几乎所有认知任务上，ASI与最强人类的差距，是最强人类与中位专业人士差距的2倍。\n在模拟推演中，研究人员发现，存在一些轨迹显示AI可以在数月内从SIAR跃升至ASI；但也存在在智能爆炸阶段「哑火」的可能，即需要继续通过堆算力才能达到ASI。\n要想实现最快的起飞，通常需要一个反馈循环：让AI能力每一次翻倍所需的时间，都比上一次更短。\n在此，模型提出了一个关键概念——「仅靠研究品味的奇点（taste-only singularity）」：\n速度的翻倍完全来自于研究品味的提升，而非算力增加或代码能力的提升。\n这一奇点是否会出现，将取决于「创新想法变得越来越难挖掘的速度」与「AI研究品味提升速度」之间的博弈。\nNature\n2050年，AI扛下诺奖级研究\n如果说AI Futures Model描绘的是AI自身进化的「速度」，那么Nature最新的展望则向我们展示了这种进化将如何重塑科学探索的「广度」。\n尽管时间线难以精确锁定，但科学界对终局的共识逐渐清晰：\n到2050年，AI系统或将成为「诺奖级」科学研究的主力军。\n常驻牛津、《超级智能：路径、危险与策略》的作者Nick Bostrom预计，AGI将2050年前后出现，并具备回答「我们当前关心、且原则上可以由科学回答的大多数问题」的能力。\n即便没有所谓的超级智能全面主导，到了2050年，AI也可能让科学研究的方式发生根本变化。\n对此，伦敦研究与前瞻公司Outsmart Insight联创Alex Ayad描述了一种名为「黑灯实验室」（lights out labs）的场景：\n由AI算法驱动的自主系统，结合机器人实验员，能够24小时不间断地攻克生物技术难题。\n在此期间，完全不需要人类在场，故名「黑灯」。\n而这，也将催生一个完美的「共生循环」：\n新技术催生新的科研方式，新知识反过来推动更新、更强的技术，从而不断解锁新的科学领域。\n在此基础上，墨西哥国立自治大学物理学家Juan Carlos Hidalgo给出了一个乐观的预测：\n在AI的辅助攻坚下，到2050年，核聚变能源成熟的前景「相当可期」。\n参考资料：HYB\nhttps://www.nature.com/articles/d41586-025-04100-6\nhttps://x.com/slow_developer/status/2006800088627048584?s=20\nhttps://www.aifuturesmodel.com/%20\nhttps://blog.ai-futures.org/p/ai-futures-model-dec-2025-update\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659818&idx=1&sn=a4d07f563f7c94e7c06de7d4bc1a10a4&chksm=f0cddae2bcdfa956539af62f93a0b2353871728cd788bf8c3114c0ee5b21dfb66fef115ef90e&scene=0&xtrack=1#rd",
      "publish_time": 1767495600,
      "publish_date": "2026-01-04 11:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://blog.ai-futures.org/p/ai-futures-model-dec-2025-update\", \"https://www.nature.com/articles/d41586-025-04100-6\", \"https://x.com/slow_developer/status/2006800088627048584?s=20\", \"https://www.aifuturesmodel.com/%20\"]",
      "add_ts": 1767568723,
      "last_modify_ts": 1767655365
    },
    {
      "id": 212,
      "article_id": "51609",
      "title": "字节Seed团队: Scaling线性注意力首个超越AlphaFold3",
      "description": "字节跳动Seed团队提出的SeedFold系统探讨了生物分子结构预测模型的可扩展性问题，填补了该领域在scaling law研究上的空白。从AlphaFold2到AlphaFold3，尽管预测精度不断提升，但模型随数据和参数增长的性能演化规律尚不明确。SeedFold通过大规模实验揭示了结构预测模型在不同规模下的表现趋势，为构建更高效、可扩展的生命科学基础模型提供了理论依据和实践方向，推动分子建模迈向系统化发展新阶段。",
      "content": "近年来，生物分子结构预测已经成为构建生命科学基础模型的重要基石。从 AlphaFold2 到 AlphaFold3，深度学习模型不断刷新结构预测的精度上限。然而，一个长期被忽视但同样关键的问题是：这些折叠模型是否具备真正的“可扩展性”？\n字节跳动 Seed 团队最新提出的 SeedFold，正是一次系统性回答这一问题的尝试。\n结构预测模型也需要“Scaling Law”\n在大语言模型领域，研究人员早已发现：模型能力的提升很大程度上依赖于合理的规模扩展策略。相比之下，当前主流的生物分子折叠模型在架构设计上仍高度继承自 AlphaFold 系列，其扩展方式主要集中在：\n增加网络深度；\n依赖 recycling 机制反复迭代。\n但这些方式是否真正释放了模型潜力，仍缺乏系统性验证。\nSeed 团队提出了一个关键问题：当前折叠模型的性能瓶颈，究竟来自深度不足，还是表示维度受限？\nSeedFold 的三大核心设计\nSeedFold 并非简单“堆参数”，而是从 模型、架构和数据 三个层面系统性推进规模化。\n宽度优先：重新审视 Pairformer 的扩展方式\n研究人员系统比较了三种扩展路径：\n加深 Pairformer 层数\n加深结构模块\n增加 Pairformer 的隐藏维度（128 → 256 → 384 → 512）\n结果显示：宽度扩展显著优于深度扩展，模型容量的核心瓶颈在于 pair 表示维度，而非网络层数。\n图1：SeedFold 的整体设计与三种规模化路径。\n线性三角注意力：破解计算复杂度瓶颈\n传统 AlphaFold 架构中的 三角注意力操作 具有立方级复杂度，是规模扩展的主要障碍。SeedFold 引入了一种 线性三角注意力机制，将计算复杂度从立方级降低至二次级，在保持预测精度的同时显著提升计算效率。\n研究人员提出两种模型配置：\nSeedFold：512 维 Pairformer + 标准三角注意力；\nSeedFold-Linear：384 维 Pairformer + 线性三角注意力。\n图2：不同扩展策略下结构精度与训练效率对比。\n大规模蒸馏数据：弥补实验结构数据不足\n由于实验解析结构数量有限，SeedFold 构建了一个 基于 AlphaFold2 的大规模蒸馏数据集，将训练样本规模扩展至 2650 万级别。\n这一策略有效提升了模型在多模态结构任务上的泛化能力，为“折叠基础模型”提供了更坚实的数据支撑。\n在 FoldBench 上全面领先\nSeedFold 在标准化基准 FoldBench 上进行了系统评估，覆盖多种结构预测任务。\n蛋白单体结构预测\nSeedFold 在 局部结构质量（lDDT）和整体 RMSD 指标上整体优于 AlphaFold3。\n蛋白–蛋白与抗体–抗原复合物\n在界面预测成功率（DockQ）上，SeedFold 在多数阈值区间内表现领先，尤其在抗体–抗原任务中优势明显。\n蛋白–小分子复合物\n值得注意的是，SeedFold-Linear 在蛋白–配体任务中表现尤为突出，显示线性注意力机制在该类任务中的独特优势。\nSeedFold 的意义在哪里？\nSeedFold 的价值并不只是“又一个更强的折叠模型”，而在于它揭示了更深层的设计原则：\n折叠模型同样遵循规模定律，但扩展维度比堆深度更关键；\n异构注意力机制 在不同任务中各有优势；\n大规模蒸馏数据 是构建生物分子基础模型的现实可行路径。\n这项工作为未来的 蛋白结构基础模型、复合物建模乃至生成式设计模型 提供了重要参考。\n小结\nSeedFold 展示了一条清晰的路线图：想让生物分子结构预测真正“规模化”，不仅要更大，还要更合理。\n对于正在探索 蛋白基础模型、结构生成、复合物建模 的研究人员而言，这项工作提供了难得的系统性经验。\n整理 | 王建民\n参考资料\nhttps://seedfold.github.io/\nhttps://doi.org/10.48550/arXiv.2512.24354",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512469&idx=1&sn=f8843a776e233dc2d1057dc7c6c72814&chksm=fd71c64eac14c1438fc2cca92d822d788669c814206bf0d1ccbeca6560056b035b50aace464d&scene=0&xtrack=1#rd",
      "publish_time": 1767494640,
      "publish_date": "2026-01-04 10:44",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://seedfold.github.io/\", \"https://doi.org/10.48550/arXiv.2512.24354\"]",
      "add_ts": 1767568736,
      "last_modify_ts": 1767655387
    },
    {
      "id": 213,
      "article_id": "51608",
      "title": "「北京版幻方」冷不丁开源SOTA代码大模型！一张3090就能跑，40B参数掀翻Opus-4.5和GPT-5.2",
      "description": "中国新模型IQuest-Coder-V1引发关注，在SWE-Bench Verified榜单中，其40B版本取得81.4%的优异成绩，超越传闻中的Claude Opus-4.5与GPT-5.2，展现强大性能，迅速刷屏国内外科技圈，彰显中国在大模型领域的突破进展。",
      "content": "衡宇 发自 凹非寺\n量子位 | 公众号 QbitAI\n又一个中国新模型被推到聚光灯下，刷屏国内外科技圈。\nIQuest-Coder-V1模型系列\n，看起来真的很牛。\n在最新版SWE-Bench Verified榜单中，40B参数版本的IQuest-Coder取得了81.4%的成绩，这个成绩甚至\n超过了Claude Opus-4.5和GPT-5.2\n（这俩模型没有官方资料，但外界普遍猜测参数规模在千亿-万亿级）\n。\nOh～Tiny Core, Titan Power。\n好，看到这里我盲猜很多人肯定已经开始边摇头边笑了。\n毕竟这年头，benchmark的权威犹在，但说服力似乎已经大不如前了。\n那咱们就\n看看这个模型跑出来的case\n——\nPrompt：编写一个网页来展示一个逼真的太阳系模拟。\n然后你将得到：\n可以自由切换各种视角，让画面暂停、放大，调整公转速度也ok。\n选中具体的行星，还会跳出相应的名字和简单介绍。\n目前，这套代码大模型系列已经在GitHub和抱抱脸上开源\n。\n有一个重点一定要划！！！\n这个模型团队IQuest，和DeepSeek团队一个路数，都出自中国的量化私募。\n背后公司就是北京版幻方量化——\n九坤投资\n。\n（两家公司都是业内公认的量化私募头部）\n𝕏、Reddit等平台上，关于IQuest-Coder的消息和对中国量化公司杀入AI模型战场的讨论已经满天飞了。\n有网友一脸unbelievable地问出了令他诧异的问题：\n中国量化公司到底吸纳了些什么人才，才能把模型训练成这样啊？？？\nOk，一起来看看这套模型的详细情况吧～\nIQuest-Coder-V1系列\n从定位上看，IQuest-Coder-V1是一套覆盖多个参数规模与使用场景的家族版本，\n专注于代码生成、代码理解与软件工程任务的模型系列\n。\n参数有7B、14B和40B的，每个规模均提供Instruct和Thinking两种版本。\n其中，\nInstruct\n偏向指令跟随与工程使用，更高效；\nThinking\n强化复杂推理和多步问题拆解，响应时间更长。\n特别提醒大家注意一下，\n40B参数规模的IQuest-Coder-V1额外提供了Loop版本\n，用于探索更高的参数利用效率。\n与计算成本相似的模型相比，IQuest-Coder-V1-40B-Loop的HBM和KV Cache开销显著降低，而吞吐量大幅提升。\n仅增加约5%的训练成本，Loop架构下，40B模型达到数百亿参数MoE模型的水平。\n在架构设计上，IQuest-Coder-V1系列强调了“工程友好”和“长上下文可用性”。\n官方在GitHub上给出的四点架构特性分别是：\n分组查询注意力\n（Grouped Query Attention，GQA）\n以实现高效推理\n原生支持128K上下文长度\n词表大小：76800个token\n循环变体采用了具有共享参数的循环Transformer设计，该设计在两个迭代过程中保持一致。\n首先说说GQA的引入。\n通过减少KV头数量来降低推理阶段的显存占用和计算压力，对长上下文场景超级友好。\n其次，模型原生支持128K上下文长度。这就让模型有能力直接处理完整代码仓库、跨文件依赖以及大规模工程上下文。\n第三，76800个token的词表大小，更贴近真实代码环境中频繁出现的标识符、路径名和符号组合。\n最后，在Loop变体中，模型采用了具有跨两次迭代共享参数的循环Transformer设计，用重复计算换取更高的参数利用率，在不线性扩大模型规模的前提下提升性能。\n作者刻意指出，这和早期Parallel Loop Transformer不同，去掉了token shifting和inference trick，更强调推理阶段的稳定性。\n这些特性组合在一起，\n有利于模型在真实软件工程场景中跑得更好\n。\n来看官方展示的更多case。\nPrompt 1：构建一个粒子-文本动画，满足以下要求。\n文本采样\n：将给定文本（例如，IQuest）在 Canvas 上转换为由数百个小粒子组成的点阵。\n状态\n：每个粒子都有一个当前位置和一个目标位置（形成文本）。\n交互式物理效果\n：当鼠标靠近时相互排斥和散开；当鼠标移开时平滑地弹回。\n视觉效果与缓动\n：随机/渐变颜色，用于整体运动的缓动效果。\nPrompt 2：构建一个实时像素沙盒游戏。\n通过按钮切换沙子、水、石头和酸液；在画布上涂画可生成具有不同颜色的元素；大规模更新依然流畅；元素会自然下落并流动。\nPrompt 3：构建一个完整的单文件HTML5 Canvas太空射击游戏，具有复古霓虹美学和明显的战斗反馈。\n视觉风格\n：黑色背景，高饱和度霓虹几何形状，街机感。\n控制\n：WASD移动；两种瞄准/炮塔模式（鼠标跟随，或按R键旋转炮塔）。\n射击\n：带完整视觉效果的自动射击太空飞船。\n反馈\n：击杀时，出现粒子爆炸效果；受到伤害时，屏幕会震动。\n敌人\n：普通士兵/奇袭者/重型坦克，以及Boss战。\n进阶\n：按P键能升级火力。\nPrompt 4：基于鸟群算法的仿生鸟/鱼群体模拟，拥有150个以上的自主Agent，有实时调节功能。\n核心规则\n：分离（避免碰撞）、对齐（速度匹配）和内聚（群体中心）。\n实时面板\n：调整分离/对齐/凝聚权重（0-3）、视觉半径（20-150 像素）和最大速度。\n交互\n：鼠标充当捕食者，使附近的智能体散开。\n渲染\n：在深色背景下，以运动方向旋转的霓虹三角形和发光轨迹。\n工具\n：FPS 计数器和暂停/继续（空格键）。\n与众不同的“代码流多阶段训练”训练策略\nIQuest-Coder的训练流程如下——\n预训练阶段\n先用通用数据和大规模代码数据打底，然后通过高质量代码annealing强化基础代码表征。\n中期训练阶段\n第一次明确引入reasoning、agent trajectory和长上下文代码，并且分32K和128K两个尺度逐步推进。\n最终post-training阶段\n，模型被明确分流成instruct路线和thinking路线，分别用不同目标函数和RL方式收敛。\n官方强调，IQuest-Coder-V1系列采用了与传统单一静态源代码训练不同的训练策略。\n称之为\ncode-flow multi-stage training\n。\n与大量代码模型侧重从静态代码片段中学习不同，这套方法强调从代码的演化过程中学习。\n团队专门设计了基于项目生命周期的triplet数据构造方式，用 (R_old, Patch, R_new) 这样的结构，让模型看到稳定期代码、变更内容以及变更后的结果。\n而且刻意避开项目早期和后期，只取40%–80%生命周期区间。\n这一步\n实际上把“软件工程经验”显式编码进了训练数据里\n。\n所以模型看到的并不只是某一时刻的完成态代码，还包括修改前后的差异、提交历史中的逻辑变化，以及真实工程中反复试错和修正的痕迹。\n也就是说模型被训练得能够捕捉软件逻辑的动态演变。\n不少网友猜测，这就是IQuest-Coder-V1在多个软件工程类评测中表现突出的重要原因之一。\n这套模型成绩确实亮眼。\nSWE-Bench Verified\n：81.4%\nBigCodeBench\n：49.9%\nLiveCodeBench v6\n：81.1%\n下面这张图体现得更直观一点，IQuest-Coder\n在八个代码、Agentic相关榜单上都独占鳌头。\n不过，GitHub上白纸黑字写着，模型可以生成代码，但不能执行，始终在沙盒环境中验证输出结果。\n部署方面，官方信息显示，不管是基础版本还是Loop版本，都支持单卡H20推理。\n其Int4版本可在单张消费级3090/4090 GPU上部署。\n有网友表示，\n非Loop版本的模型似乎采用的是阿里Qwen2的架构。\n随着关注度上升，质疑也同步出现。\n九坤投资公司是谁？\n好，最后我们来认识一下IQuest-Coder背后的公司，\n九坤投资\n（Ubiquant Holding Limited）\n。\n公司成立于2012年，是中国较早一批专注量化投资和高频交易的私募机构之一，目前管理规模在数百亿元人民币，和幻方同属于公认的国内量化私募头部公司。\n九坤\n主要办公地在北京\n，3周前开设了新加坡办公室。\n联合创始人王琛\n，2000年考入清华大学，获得数学物理学士学位和理论计算机博士学位，博士期间师从图灵奖得主姚期智院士。\n博士毕业后，王琛就职于美国顶级对冲基金Millennium，后创业担任九坤投资联合创始人、CEO。\n联合创始人姚齐聪\n，2002年考入北京大学数学系，获得数学学士和金融数学硕士学位。\n硕士毕业后进入Millennium，后与王琛共同创业，主要负责九坤投研体系搭建、量化策略开发和风险管理，被视为公司策略和风控体系的核心设计者之一。\n九坤的投研与技术团队人数超过百人，90%以上毕业于清华、北大、复旦、斯坦福等国内外知名高校，博士占比超过60%。\n公开信息显示，这家公司目前也倾向于从全球顶尖高校招募具有计算机、数学、物理、统计学等背景的应届毕业生。\n在AI领域，幻方更早凭DeepSeek站到台前。\n不过查询有关资料发现，\n此前九坤也很注重AI技术这一块\n。\n目前，九坤的IT和算力建设位居国内量化机构前三，并建立了数据实验室\n（DATA LAB）\n、人工智能实验室\n（AI LAB）\n等多个前沿实验室。\n本次发布的IQuest-Coder就出自其发起设立的独立研究平台至知创新研究院。\n倒也不全是为了把AI用在金融市场预测和交易决策啦——前段时间\n（2025年12月16日）\n，九坤已经推出过通用推理模型URM。\n该模型在ARC-AGI正确率为53.8%，当允许多次尝试时，URM的成功率能达到85%以上；在更困难的ARC-AGI 2上也拿到了16.0%。\nPaper最后附上了IQuest-Coder团队的成员名单。\n挺长的，就不一一介绍了。\n不过我们发现这篇paper的\n核心作者层\n，和《Scaling Laws for Code》《CodeSimpleQA》《From Code Foundation Models to Agents and Applications》作者阵容重合度非常高。\n所以这里稍微展开介绍一下Core Contributor的几位成员。\n（注：IQuestLab团队成员很多没有公开个人档案，我们这里放出可寻找到的公开资料）\nJian Yang\n，谷歌学术被引量超过1.6万。\n此前应该在Qwen 2.5和Qwen 3团队待过很长一段时间，2025年起开始在九坤投资发表论文。\nZhengmao Ye\n，本科毕业于西南交通大学，在四川大学获得计算机科学硕士学位。\n此前，他曾在华为和商汤科技担任过技术工作人员。\n你没看错，8位Core Contributor就找到了2位的公开资料，真的尽力了.gif\n另外，\npaper的通讯作者，是九坤人工智能实验室首席研究员和负责人Bryan Dai\n。\nPaper地址：\nhttps://github.com/IQuestLab/IQuest-Coder-V1/tree/main/papers\n参考资料：\n[1]https://x.com/zephyr_z9/status/2006579658972868988?s=20\n[2]https://github.com/IQuestLab/IQuest-Coder-V1?tab=readme-ov-file\n[3]https://iquestlab.github.io/#/\n[4]https://www.reddit.com/r/LocalLLaMA/comments/1q0x19t/anyone_tried_iquestcoderv1_yet_the_40b_numbers/\n—\n欢迎AI产品从业者共建\n—\n📚\n「AI产品知识库」\n是量子位智库基于长期产品库追踪和用户行为数据推出的飞书知识库，旨在成为AI行业从业者、投资者、研究者的核心信息枢纽与决策支持平台。\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859736&idx=1&sn=6731d555d78d4ec9e15330ee7a3afbc7&chksm=e9309ff2f54f416e4f6ef320faf2d2022e08daeb0d54b0d3758dd77889afad218bcbf7ff00da&scene=0&xtrack=1#rd",
      "publish_time": 1767494640,
      "publish_date": "2026-01-04 10:44",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/IQuestLab/IQuest-Coder-V1/tree/main/papers\", \"https://x.com/zephyr_z9/status/2006579658972868988?s=20\", \"https://github.com/IQuestLab/IQuest-Coder-V1?tab=readme-ov-file\", \"https://iquestlab.github.io/\", \"https://www.reddit.com/r/LocalLLaMA/comments/1q0x19t/anyone_tried_iquestcoderv1_yet_the_40b_numbers/\"]",
      "add_ts": 1767568744,
      "last_modify_ts": 1767655393
    },
    {
      "id": 214,
      "article_id": "51607",
      "title": "特斯拉首跨全美，Grok灵魂注入！马斯克「三位一体」帝国浮现",
      "description": "新智元报道  编辑：定慧【新智元导读】马斯克正在亲手终结百年汽车工业的时代。特斯拉这次不光让车自己横穿美国，还给它塞了个会看世界的Grok灵魂。路上跑的可能已经不是汽车，而是四个轮子的机器人。特斯拉FSD，人类0接管完成横穿美国壮举！2026年开年第一天，马斯克的FSD就引爆社交网络。车主戴维·莫斯（David Moss）驾驶着搭载FSD v14.2.1.25及AI4硬件的Model 3，完成",
      "content": "新智元报道\n编辑：定慧\n【新智元导读】\n马斯克正在亲手终结百年汽车工业的时代。特斯拉这次不光让车自己横穿美国，还给它塞了个会看世界的Grok灵魂。路上跑的可能已经不是汽车，而是四个轮子的机器人。\n特斯拉FSD，人类0接管完成横穿美国壮举！\n2026年开年第一天，马斯克的FSD就引爆社交网络。\n车主戴维·莫斯（David Moss）驾驶着搭载FSD v14.2.1.25及AI4硬件的Model 3，完成了全球首次、经由第三方验证的「0接管」横贯美国之旅。\n整整2,732.4英里，跨越两个时区！\n从洛杉矶的特斯拉餐厅，到南卡罗来纳的海滩。\n历时2天20小时，人类没有一次接管，没有一次干预。\n这不仅是AI的胜利，更是FSD正式通过「物理图灵测试」的铁证。\n马斯克等待了十年的梦，在这一刻终于化为现实。\n除了横穿这种字眼带来的感官刺激外，最核心的依然是FSD的稳定性。\n要知道，特斯拉这些汽车已经无人直接从工厂直接开到你的家门口。\n很多人都逐渐意识到，FSD已经非常厉害了；\n但很多人没有意识到，在FSD背后更可怕的是：\n在Tesla汽车的钢铁躯壳下，正跳动着一颗名为Grok的AI灵魂。\n如果说FSDv14赋予了机器「肌肉」与「反应」，那么Grok将赋予了机器「大脑」与「性格」。\n车主@spampeg分享了自己Tesla中的Grok是如何通过借助车身摄像头来实现真实物理交互的。\nGrok也在评论区现身，实锤了特斯拉现在是「双大脑引擎」，FSD+Grok。\n特斯拉在2025年7月12日交付的新车中，都预装了Grok人工智能系统。\n当所有人的目光都聚焦在FSD时，Grok已经在车端开始了进化。\n百年汽车工业即将巨变！\n如果说FSD让方向盘成为历史，那么Grok或许将彻底重构汽车。\n为冰冷的钢铁注入灵魂\n在2025.26版本后的更新中，Grok不再仅仅是屏幕里的聊天机器人，它已经进化为特斯拉车辆的全能「解释层」与「行动派」。\nGrok在特斯拉内部的应用已不再局限于语音控制，而是深植于车辆的逻辑循环中。\n通过下面的真实车主故事，看Grok是如何改写驾驶体验的。\n动态路径规划与生活决策\n车主不再需要输入地址。\n你只需要告诉它：「Grok，带我走一条不收过路费、风景好、且沿途有高分素食咖啡店的路线。」\nGrok能瞬间整合FSD的导航系统、实时交通流及网络点评，完成全行程排布。\n即时的故障自检自愈\n当某位Cybertruck车主的FSD出现报错时，Grok不仅解释了原因，还指导车主通过简单的屏幕操作重启系统。\n这种「AI机械师」的能力，极大降低了用户焦虑。\n驾驶意图的「拟人化说明」\n在FSD驾驶过程中，Grok会主动开口：「由于前方路面有大水坑，我正在切换到防御性驾驶模式并减速。」\n这种透明度让乘客感到自己面对的不是冷冰冰的代码，而是一位经验丰富的「老司机」。\n跨平台个性同步\n通过关联X账号，Grok能根据车主的日常社交偏好，在长途行驶中自动播放80年代合成器电子乐，或为车主总结其关注博主最新的技术讨论。\n错失OpenAI？\n不，马斯克手握真正的「大杀器」\n2025年，外界曾嘲笑马斯克在AI竞赛中落后，并且错失了OpenAI了。\n但随着2026年FSD与Optimus（擎天柱）的成熟，这种观点或许需要重新考量。\nOpenAI的GPT系列依然被困在数字世界的「盒子」里，而马斯克通过\nGrok+Tesla+Optimus\n构建了一个前所未有的物理AI帝国。\nFSD v14赋予了机器「肌肉」与「反应」，Grok赋予了机器「大脑」与「性格」，而Optimus则赋予了智能「行动的躯体」。\n在这套「三位一体」的霸权下，特斯拉已经从一家车企彻底蜕变为定义人工智能如何在这个星球上移动、交流与工作的先驱。\n而这就是马斯克的终极野心。\n2025年11月07日，特斯拉股东大会刚刚批准了一项史无前例的高管薪酬方案：\n未来十年，马斯克将有机会获得近\n1万亿美元\n的股票奖励。\n现场，马斯克激动地和机器人擎天柱「Optimus」共舞：\n超过75%的股东投票通过了价值最高达1万亿美元的薪酬方案。\n全场沸腾。\n欢呼声响彻全场。\n而这些人和驾驶特斯拉横穿美国的车主戴维·莫斯（David Moss）一样，都是马斯克的绝对拥趸。\n车+机器人+AI，这就是马斯克三位一体帝国，而这个帝国已经开始出现了雏形和信徒。\n<<  滑动查看下一张图片  >>\n从对话框到物理载体\nOpenAI缺乏「身体」。\n虽然它能写出完美的诗歌，但它无法感知重力，无法理解三维空间的复杂性。\n而马斯克拥有的，是真正的\n具身智能\n：\n超过700万辆特斯拉汽车正实时采集真实世界的视觉数据。\n这些真实的物理反馈是任何文本语料都无法模拟的「真理」。\n而由于马斯克第一性原理，Grok从车辆里学到的知识和经验，可以无缝衔接Optimus。\n当Grok的大脑被装进Optimus的躯体，原本用于自动驾驶的避障、感知逻辑被无缝平移到机器人身上。\n2026年，OptimusGen3已开始在德州工厂执行精细组装任务，其50执行器手部组件甚至被认为在未来能执行外科手术。\n自动驾驶的阿波罗登月时刻\n这场FSD个人秀背后，可以看到马斯克更大野心。\n先来看一看FSD和其他自动驾驶，比如Waymo的成本对比。\n特斯拉的纯视觉方案与Waymo为代表的激光雷达方案，在跨区域扩张中存在着本质的效率与成本差异：\n硬件端的「轻量化」：\n特斯拉的硬件套件（AI4硬件）成本估计仅约1,000美元，而一套典型的L4级多传感器方案（含多个激光雷达与高冗余计算单元）成本往往高达数万美元，甚至10万至20万美元。这意味着特斯拉可以迅速将FSD部署到百万量级的存量车队中，而竞争对手每扩张一台车都需要支付巨额溢价。\n地理扩张的「无界化」：\nWaymo等方案高度依赖\n高精地图（HDMaps）\n和地理围栏。这意味着每进入一个新城市，都需要先进行昂贵的激光雷达地图采集。相比之下，FSD14能够「像人类一样」通过摄像头观察并实时决策，这次\n0接管横穿美国（2,732.4英里）\n证明了它不依赖预设地图、不分区域的通用性，具备了在任何有路的地方瞬间落地的能力。\n自动驾驶商业闭环临界点\n这次2,700多英里的长征不仅是技术秀，更是Cybercab商业模式的终极预演：\n从「监督」到「无人驾驶」的跨越\n马斯克已确认Cybercab生产已在2025年末开始准备，并计划于\n2026年4月正式量产\n。\nFSD14在真实长途环境下的零接管表现，为监管机构批准「无监督驾驶」提供了核心安全数据。\n极致的运营效率\nCybercab预计采用革命性的\nUnboxed（拆解式）制造工艺\n，单车成本有望压低至\n2万美元以下\n。\n配合FSD14的算法进化，特斯拉正试图建立一个全球性的\nRobotaxi网络\n。\n物理\n图灵测试\n的终结\nFSD14处理了包含超级充电站自动停车、复杂城市街道及夜间极端环境在内的所有场景。\n这种全链路（End-to-End）的自动化，意味着2026年的Cybercab将不再需要安全员，直接实现从「卖车给用户」到「让车为用户赚钱」的商业逻辑闭环。\n马斯克的底气：算力\n在自动驾驶的下半场，硬件装车只是门槛，\n后台算力集群的规模与训练效率\n才是决定胜负的「核武器」。\n特斯拉通过xAI的\nColossus（巨像）集群\n与自研的\nDojo超算\n，构建了一个传统车企几乎无法追赶的算力护城河。\n全球最强「炼丹炉」的溢出效应\nColossus是目前全球最强大的AI训练系统之一！\n其规模在2025年底已达到20万块NVIDIA H100/H200 GPU，并正向100万块GPU的目标迈进。\n算力共享与知识蒸馏\n尽管xAI与特斯拉是独立公司，但马斯克明确表示FSD的训练受益于xAI工程师的算法突破。\nColossus训练出的Grok等超大规模模型，可以通过「知识蒸馏」技术，将复杂的语义理解能力压缩并注入到FSD的端到端神经网络中。\n攻克「长尾场景」\n自动驾驶最难的是处理1%的极端罕见场景。\n传统车企由于算力不足，训练一次模型可能需要数周；而拥有Colossus的特斯拉可以将训练周期缩短至数天甚至数小时，实现算法的「日更」迭代。\n传统车企难以跨越的「鸿沟」\n传统车企（如大众、丰田）在算力上正面临「降维打击」：\n特斯拉拥有百万量级的「移动传感器」车队，每天产生PB级视频数据。\n如果没有像Colossus这样2GW级别的计算力去消化这些数据，数据就只是负债而非资产。\nColossus集群消耗的电力高达250MW以上，甚至需要Tesla Megapack专门为其提供电力缓冲。\n传统车企缺乏这种跨行业的能源与基建整合能力。\n最重要的，人才与\n算法\n的一体化\n马斯克将xAI、TeslaAI和Optimus的人才打通，形成了一个「通用人工智能驱动物理世界」的闭环。传统车企的软件部门大多仍处于「外包或追赶」状态。\n让我们畅想一下。\n到2026年，当特斯拉拥有100万块GPU级别的算力时，FSD的进化速度将呈指数级增长。\n或许那时候，不仅仅是横穿美国，而是可以环绕地球了。\n马斯克正在亲手终结那个百年汽车工业的时代。\n当Grok的灵魂注入Tesla的骨架，一个横跨算力、能源与机器人的三位一体帝国已然合龙。\n2018年，马斯克用SpaceX的猎鹰重型火箭将Roadster跑车发射进了太空\n这不再是关于科技的胜负，而是关于一个疯子如何把科幻活成现实。\n2026年，或许可以坐在特斯拉里，见证那个「环绕地球」的梦想照进现实。\n参考资料：\n马斯克10年梦成真！特斯拉全球首次自动驾驶横穿美国，人类0接管\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659964&idx=1&sn=fb026a6a5af3a446d819b6541c19ff94&chksm=f0db62f195989f438892d7fcfff9ee191959452c4060d1457bab9a3c71b09c27359e3a50b617&scene=0&xtrack=1#rd",
      "publish_time": 1767494640,
      "publish_date": "2026-01-04 10:44",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767568748,
      "last_modify_ts": 1767655403
    },
    {
      "id": 215,
      "article_id": "51660",
      "title": "Nat. Biotechnol. | 无需RNA三级结构的小分子–RNA相互作用预测方法",
      "description": "SMRTnet是一种无需RNA三级结构、仅依赖二级结构的小分子–RNA相互作用预测深度学习模型。该方法结合RNA与化学语言模型、卷积神经网络及图注意力网络，实现多模态数据融合，显著提升预测精度，拓展了小分子靶向RNA在疾病治疗中的应用前景。",
      "content": "DRUG\nONE\n小分子通过结合 RNA 调控其命运与功能，为疾病治疗提供了重要机遇。然而，现有小分子–RNA 相互作用预测方法通常依赖 RNA 的三维结构信息，严重限制了适用范围。研究人员提出 SMRTnet，一种无需 RNA 三级结构、仅基于 RNA 二级结构的小分子–RNA 相互作用预测深度学习框架。该方法融合 RNA 与化学语言模型、卷积神经网络和图注意力网络，通过多模态数据融合实现高精度预测。SMRTnet 在多个实验基准上显著优于现有方法，并在十个疾病相关 RNA 靶点的筛选中验证了 40 个结合分子，亲和力覆盖纳摩尔到微摩尔范围。以 MYC IRES 为例，预测得分与实验验证率高度相关，且其中一个分子在多种癌细胞系中下调 MYC 表达、抑制增殖并促进凋亡。该工作在不依赖 RNA 三级结构的前提下，显著拓展了 RNA 靶点药物发现的可行性。\nRNA 作为功能分子，在多种生命过程中发挥核心调控作用，其异常与癌症、遗传病和病毒感染密切相关。相较于蛋白质，RNA 靶点在药物开发中仍处于早期阶段，其中一个关键瓶颈在于 RNA 三级结构难以通过实验手段大规模解析。\n虽然近年来已发展出基于分子对接和深度学习的方法预测小分子–RNA 相互作用，但这些方法大多依赖高质量的 RNA 三维结构，限制了其在真实生物医学场景中的适用性。因此，亟需一种摆脱 RNA 三级结构依赖、可扩展至大规模 RNA 靶点的预测方法。\n方法概述\nSMRTnet 以 RNA 序列与二级结构 以及 小分子 SMILES 表示 作为输入，通过多模态深度学习架构完成相互作用预测。模型主要包括四个模块：\nRNA 编码器\n：结合 RNA 语言模型与卷积神经网络，提取序列与碱基配对信息；\n小分子编码器\n：融合化学语言模型与图注意力网络，捕获化学组成与拓扑结构特征；\n多模态数据融合模块\n：利用注意力机制整合 RNA 与小分子特征，学习其相互作用表示；\n预测模块\n：输出小分子与 RNA 的结合评分，并可进一步解析潜在结合位点。\n模型训练基于从结构数据库与文献中整理的大规模 RNA–小分子相互作用数据，并通过严格的数据划分与集成策略提升泛化能力。\n图1｜SMRTnet 的整体框架。\n结果\nSMRTnet 的整体性能\n在来源于结构数据库和多个独立实验数据集的基准测试中，SMRTnet 在区分真实结合对与非结合对方面表现稳定，整体预测性能显著优于传统分子对接方法和已有深度学习模型。\n图 2｜SMRTnet 的预测性能评估。\nRNA 二级结构与模型组件的重要性\n消融实验表明，RNA 序列与二级结构信息对预测性能至关重要；移除二级结构会显著降低模型表现。多模态融合模块也对整体性能提升具有重要贡献。\nRNA 结合位点的可解释性预测\n通过注意力与梯度分析，SMRTnet 可在 RNA 上定位潜在小分子结合位点。预测得到的高关注区域与多种已知实验结合位点高度一致，证明模型不仅能预测是否结合，还能提供空间层面的解释。\n疾病相关 RNA 靶点的小分子筛选\n研究人员利用 SMRTnet 对十个疾病相关 RNA 靶点进行虚拟筛选，并通过实验验证确认 40 个真实结合分子。不同 RNA 靶点呈现出差异化的结合分子谱，显示模型对 RNA 结构差异具有良好分辨能力。\n图 3｜疾病相关 RNA 靶点的小分子实验验证结果。\nMYC IRES 的系统验证\n在 MYC IRES 案例中，预测结合评分与实验验证率呈明显正相关，表明 SMRTnet 的评分可用于有效排序真实结合分子。进一步分析显示，预测结合位点与突变实验结果高度一致。\n图 4｜不同预测区间内 MYC IRES 靶向小分子的实验验证结果。\n图 5｜MYC IRES 上预测结合位点的实验验证。\nMYC IRES 靶向小分子的功能验证\n在 MYC 内部核糖体进入位点（IRES）研究中，SMRTnet 预测的小分子与实验验证结果高度一致。其中一个候选化合物能够显著下调 MYC 表达、抑制癌细胞增殖并促进细胞凋亡，显示出潜在的治疗价值。\n图 6｜MYC IRES 靶向化合物 IHT 抑制 MYC 表达与细胞增殖。\n讨论\nSMRTnet 提供了一种不依赖 RNA 三级结构的小分子–RNA 相互作用预测新范式，显著扩展了可计算研究的 RNA 靶点空间。研究结果表明，RNA 二级结构结合序列信息已足以支持高质量的小分子识别，这为 RNA 靶向药物的早期发现提供了切实可行的计算工具。\n该研究不仅展示了人工智能方法在 RNA 药物发现中的潜力，也为未来整合更多 RNA 动态结构信息和细胞环境因素奠定了基础。总体而言，SMRTnet 有望加速 RNA 靶向小分子药物的发现进程。\n整理 | DrugOne团队\n参考资料\nFei, Y., Wang, P., Zhang, J. et al. Predicting small molecule–RNA interactions without RNA tertiary structures. Nat Biotechnol (2026).\nhttps://doi.org/10.1038/s41587-025-02942-z\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512561&idx=2&sn=968bb72097c7a12117760e68375c345f&chksm=fd174c76931283bfc332c15de56f88bcd6aef929a79a4a367a02318dd3791a09054b225d1ce4&scene=0&xtrack=1#rd",
      "publish_time": 1767631800,
      "publish_date": "2026-01-06 00:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s41587-025-02942-z\"]",
      "add_ts": 1767655130,
      "last_modify_ts": 1767828098
    },
    {
      "id": 217,
      "article_id": "51658",
      "title": "Nano Banana不会应试！指标拉垮，视觉效果惊艳，实测14个任务",
      "description": "报告探讨生成式模型Nano Banana Pro在去雾、超分等低层视觉任务中的表现，发现其视觉效果优于传统模型，但PSNR/SSIM等像素级指标偏低，因生成式模型更注重语义合理性而非像素对齐。研究指出当前评测体系的局限性，呼吁建立更符合生成式特性的新评估范式，并认为尽管该类模型潜力巨大，但在特定任务上仍与专用模型存在差距。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n最新报告探讨了生成式模型Nano Banana Pro在低层视觉任务中的表现，如去雾、超分等，传统上依赖PSNR/SSIM等像素级指标。研究发现，Nano Banana Pro在视觉效果上更佳，但传统指标表现欠佳，因生成式模型更追求语义合理而非像素对齐。报告还提出改进方向和新评测范式的思考，强调生成式模型虽有潜力，但与专用模型仍有差距。\n过去几年，文本生成图像（T2I）与多模态生成式模型的能力突飞猛进，已经能稳定地产生高质量、具备细节与语义一致性的图像内容。\n报告关注的核心矛盾在于：\n这些「擅长生成」的模型，是否也能在传统低层视觉任务中充当通用求解器（generalist）？\n低层视觉（low-level vision）通常强调对图像退化的「精确逆过程」：例如去雾、超分、去噪、去雨、去模糊、去反射、去光晕等。\n这类任务的经典评价方式往往依赖 PSNR/SSIM 等参考指标，强调像素级一致性。但生成式模型天生带有「补全/重建」的倾向：它们可能会依据先验去「合理地编造」高频细节，从人眼观感看更清晰、更「像真的」，却在像素对齐意义上偏离GT。\n华中科技大学的研究人员最近发布了一篇报告，把这种冲突概括为「人类感知偏好 vs. 传统指标导向」的张力。\n项目主页：https://lowlevelbanana.github.io\n论文链接：https://arxiv.org/abs/2512.15110\n开源仓库：https://huggingface.co/datasets/jlongzuo/LowLevelEval\n报告中提出一个非常直接的问题：\nNano Banana Pro能否成为低层视觉全能选手？\n报告采用了一个刻意「极简」的使用范式：不训练、不微调，只用「输入图 + 简单文本 prompt」直接让Nano Banana Pro输出结果，对其进行zero-shot基准评测。\n零样本+文本提示\n14个低层任务的系统基准\n研究人员把评测扩展到14个低层视觉任务、40个数据集，覆盖三大类能力：图像恢复（restoration）、图像增强（enhancement）、图像融合（fusion）。\n任务清单包括：Dehazing、Super-Resolution、Deraining、Deshadowing、Motion Deblur、Defocus Deblur、Denoising、Reflection Removal、Flare Removal、Low-Light Enhancement、Underwater Enhancement、HDR Imaging、Multi-focus Fusion、Infrared-Visible Fusion；\n图中用颜色区分了restoration / enhancement / fusion三类任务。\n保守估测性能\n报告特别强调：当前结论是对模型能力的保守估计，即研究人员没有做精细 prompt tuning，也没有用多轮推理去「挑选最好看的输出」，而是用固定、简单的提示词来模拟一种更接近「普通用户上手」的用法。\n闭源模型的评测约束\n在一些任务章节里，研究人员也说明了评测工程细节：由于模型以API方式调用且闭源，无法做任务定制训练；并且生成输出分辨率可能固定在约1024尺度，因此需要将输出resize回与GT一致的分辨率再计算指标，以保证定量比较尽量公平。\n视觉「更好看」\n但指标「更差」\n报告最重要的结论可以概括为一句话：\nNano Banana Pro在主观视觉质量上往往更讨好，但在PSNR/SSIM等传统参考指标上整体落后于专用模型。\n研究人员将其归因于生成式模型的内在属性：生成式模型更倾向于追求「语义可信/感知合理」，而非严格的像素级对齐；同时模型输出带有随机性（stochasticity），使得稳定性与可复现性也成为部署障碍。\n系统性现象：\n感知质量与指标不一致\n以Flare Removal为例，研究人员观察到一种非常典型的现象：有些样本视觉上已经「挺干净、挺舒服」，但因为亮度/颜色等与GT存在偏差，量化分数依然不高，这反映了像素级指标对生成式增强的惩罚机制。\n同时，研究人员也指出生成模型存在「高上限、低下限」的特征：在合适输入上，它可能在细节恢复上超过 SOTA，但这种优势会被扩散/生成模型的随机性与语义漂移所抵消，出现明显方差与语义幻觉，prompt 工程也只能部分缓解，难以保证工业级确定性。\n稳健但不极致：生成式模型有时会选择更保守的输出\n在低光增强（Low-Light Enhancement）的分析中，研究人员给出另一个视角：\nNano Banana Pro可能不太会引入显著的光晕、结构破坏、严重色偏等「灾难性伪影」，这使得它在某些实际应用中具备吸引力；\n但它也会出现亮度控制不一致、对prompt敏感、以及与benchmark的GT定义不完全匹配等问题，因此整体仍难以与专用方法竞争。\n更进一步，报告还给出可能的改进方向：更具体的prompt设计、few-shot示例对齐、轻量适配/微调、以及把统一多模态模型与任务模块结合的混合范式。\n报告贡献与意义：它不只是在「打分」，而是在推动重新定义评测与目标\n这份报告的价值不止在于给Nano Banana Pro下结论，更在于它把一个长期存在但常被忽略的问题摆到台面上：\n当生成式模型进入低层视觉后，「像素一致性」是否仍是唯一目标？\n传统指标是否在系统性地误导我们对生成式恢复/增强的判断？\n是否需要能同时刻画「感知质量 + 结构/语义稳定性 + 像素保真」的新评测范式？\n报告明确指出：Nano Banana Pro作为零样本低层视觉求解器，已经是一个很强的 baseline，并展示出跨任务的「泛化潜力」；但要达到专用模型那种高保真、可控、稳定的水准仍有明显鸿沟。\n参考资料：\nhttps://arxiv.org/abs/2512.15110\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660443&idx=2&sn=89d658b8ae2d8317319a90e6b0c92030&chksm=f0b914d6a83fab1bd25a224e0e76fa38f900fc9954ed84855b2f6ef118fe0b396039ff0728fb&scene=0&xtrack=1#rd",
      "publish_time": 1767631800,
      "publish_date": "2026-01-06 00:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://lowlevelbanana.github.io\", \"https://arxiv.org/abs/2512.15110\", \"https://huggingface.co/datasets/jlongzuo/LowLevelEval\"]",
      "add_ts": 1767655140,
      "last_modify_ts": 1767828104
    },
    {
      "id": 218,
      "article_id": "51657",
      "title": "npj Drug Discov. 综述｜深度学习助力抗癌药物协同研究",
      "description": "安徽大学郑春厚与苏延森团队于2025年12月16日在《npj Drug Discovery》发表综述，系统评述深度学习在抗癌药物协同作用预测中的应用。文章从单任务与多任务学习角度，梳理现有模型架构、数据资源及评估指标，分析方法优势与局限，展望未来研究方向，为基于人工智能的精准癌症治疗提供重要参考。",
      "content": "随着人工智能技术的发展\n及大规模数据集的积累，深度学习已成为抗癌药物协同作用预测的核心方法。\n针对该领域，\n安徽大学郑春厚与苏延森团队\n于2025年12月16日在《npj Drug Discovery》期刊上发表题为“A review of deep learning approaches for drug synergy prediction in cancer”的综述文章。\n文\n章从单任务学习和多任务学习的视角，对经典与新兴的深度学习模型进行系统梳理，讨论了当前面临的数据与技术挑战，并展望了推动计算药物协同预测发展的未来研究方向。\n背景\n近年来，药物治疗受到越来越多的关\n注，已成为攻克癌症的重要手段之一。然而，\n传统的癌症单药治疗存在诸多局限性，例如耐药性增强、患者不良反应增加、治疗效果有限以及治疗失败风险上升。\n从药理学角度看，药物联合使用可能产生协同、相加或拮抗效应，具体取决于其联合效应是否分别高于、等于或低于各单药的独立效应。其中，\n协同效应在药物治疗中尤为理想，因为其能够降低耐药发生率、增强治疗效果、减少患者副作用并提高治疗成功率。\n如图1所示，药物协同治\n疗能够有效弥补单药治疗的不足。\n图1 单药治疗与药物协同治疗的比较。\n目前，已经开\n发了多种知名的\n体外计算方法\n用于检测药物组合的协同效应。代表性方法包括 Loewe、Bliss、HSA以及ZIP。此类方法通常基于药物剂量数据和表型效应，采用统计学方法计算药物组合的协同评分。然而，这些方法无法提供药物在分子层面相互作用的详细信息，从而\n限制了对药物协同机制的深入理解。\n此外，由于依赖实验筛选，这些方法通常只能在有限范围内识别协同药物效应，因而\n被认为耗时且效率较低。\n为弥补体外方法的不足，研究者提出了\n基于传统机器学习的药物协同预测模型。\n代表性方法包括ComboFM、ComboLTR等。与体外计算方法相比，基于传统机器学习的预测模型具有高时效性和高成本效益的优势。然而，这类模型仍然面临\n可解释性不足和预测精度有限\n的问题。\n基于深度学习的预测模型\n在推断协同药物组合方面展现出良好前景。一方面，随着深度学习可解释性技术的发展，深度学习预测模型的\n决策过程变得更加透明。\n另一方面，深度学习预测模型\n通过整合多种生物医学数据，显著提升了预测精度。\n深度学习模型能够基于已有的异构数据推断潜在的相互作用，从而\n减少对多来源信息的大规模采集需求。\n这种表示学习能力使研究人员能够高效筛选并优先验证最具潜力的药物组合，在保证较高预测准确性的同时节省时间和资源。\n在该综述中，作者系统介绍了经典及最新的基于深度学习的药物协同预测模型，重点关注多任务学习模型，并讨论了该领域面临的局限性与挑战。图2清晰展示了利用深度学习模型进行药物协同预测的整体流程。\n图2 深度学习模型在药物协同预测流程中的应用。\n药物协同资源\n深度学习预测模型依赖于多种资源捕获\n药物之间复杂的关系与模式。近年来，许多专注于药物协同研究的科研机构相继开发了协同效应\n评价指标、数据库、交互式软件工具以及网络平台，\n用于促进协同药物组合的发现与分析。\n协同效应评价指标\n从不同角度刻画了药物-药物之间的关系。具体来说，Loewe和Bliss侧重于理论参考模型，HSA强调基于经验的比较，而ZIP则融合了概念模型与实验数据两方面的视角。在药物协同预测研究中，审慎选择并一致性地应用这些评价指标，对于构建具有可重复性和可比性的基准体系至关重要。\n多种常用的\n药物协同数据集\n涵盖了在多种癌症细胞系中测试的数千种药物组合，并经过专门整理，用于训练基于深度学习的预测模型。关于这些数据集的详细信息见表1。这些全面且高度整合的药物协同数据集为构建\n高可靠性的深度学习预测模型提供了宝贵资源，并加速了用于癌症治疗的新型协同药物组合的发现。\n表1 基准药物协同数据集汇总。\n目前已开发出\n多种\n交互式软件工具和网络平台，\n用于促进药物协同数据的可视化、分析与解读，其汇总见表2。总体而言，这些交互式分析\n平台为药物组合研究提供了强有力的计算支持。通过实现数据可视化、协同效应定量评估以及预测建模，它们显著提升了药物协同研究的可访问性与可重复性，并有助于推动更有效联合治疗方案的开发。\n表2 公开交互式软件工具和网络平台汇总。\n药物与细胞系的特征表示\n基于深度学习的药物协同预测模型的输入通常\n由\n癌症细胞系特征\n和\n药物特征\n共同构成。这些特征的质量对于预测模型的性能至关重要。如图3所示，研究者从不同角度发展多种特征表示方法，用以刻画药物和细胞系的性质。\n图3 常见药物与细胞系特征。\n对于药物而言，\n其化学结构是其理化性质的基础。具有相似化学结构的药物往往表现出相似的生物活性和药代动力学特性。药物的化学信息通常可表示为\n字符串形式，\n最常见的是采用SMILES表示法。SMILES可被视为一种将分子结构编码为字符串的方式，以紧凑的文本形式描述原子及其连接关系。在计算研究中，SMILES字符串常被转换为\n分子图，\n其中原子作为节点，化学键作为边。分子图能够有效捕获分子内部的拓扑关系。基于分子图，可以计算\n拓扑指纹，\n用于刻画原子对或原子路径之间的连接模式。此外，分子图主要描述单一化合物内部的拓扑结构，而\n异构图\n则将这一概念扩展至分子间及跨实体的关系，将药物与蛋白质、细胞系和通路等生物实体连接起来。通过异构图建模整合药物–生物实体相互作用信息，已成为构建全面药物表示的重要策略。\n对于细胞系而言，\n基于深度学习的模型通常采用\n基因组学和功能组学数据\n作为输入特征，包括基因表达谱、突变状态、拷贝数变异、DNA甲基化、基因效应评分以及依赖概率等。这些特征能够全面刻画每个细胞系的分子状态和调控程序，为理解其潜在的药物响应提供关键信息。除内在的基因组特征外，\n细胞系与药物、蛋白质及组织等生物实体之间的相互作用\n反映了疾病表型背后的多层次调控机制。通过在\n图结构框架\n下整合细胞系的分子特征及其基于相互作用的关系，模型不仅能够捕获分子层面\n的属性，还能学习系统层面的依赖关系，从而提升深度学习模型在药物协同预测中的可解释性和预测性能。\n基于深度学习的药物协同预测模型\n表3总结了代表性深度学习模型所使用的数据集，以及对应的药物和细胞系特征信息。\n表3 深度学习预测模型所使用的数据集与特征信息汇总。\n现有的深度学习预测模型可大致分为单任务学习框架和多任务学习框架。\n单任务学习模型\n仅关注药物协同预测任务，其模型结构可采用\n分支结构(图4a)\n或\n图结构(图4b)。\n具体来说，分支结构使模型能够并行处理多种特征或信息来源，从而有效捕获与药物和疾病相关的多种输入之间的关系；相比之下，图结构通常用于处理异构网络中的复杂关系，以揭示药物与疾病之间的相互作用。而\n多任务学习模型\n则在预测药物协同作用的同时，引入\n药物敏感性预测(图4c)\n或\n药物–药物相互作用预测(图4d)\n等辅助任务。\n此外，药物协同\n预测既可建模为分类任务，也可建模为回归任务。\n在分类设定下，\n模型根据实验协同评价指标的预定义阈值，将药物组合划分为协同或非协同两类，并使用二分类标签进行区分；\n在回归设定下，\n模型学习预测连续的协同评分，以表征不同细胞系中药物相互作用的强度。表4对代表性的深度学习模型进行了汇总，包括模型属于单任务或多任务、模型结构设计以及任务建模方式等信息。与大多数单任务学习模型相比，多任务学习模型的整体架构相对简洁，\n模块数量也更少。通过引入辅助任务，多任务学习模型的预测性能得到了显著提升。\n单任务学习：基于协同效应预测的模型方法\n单任务学习方法以药物组合协同效应预测为唯一建模目标，是该领域最早、也是研究最为广泛的一类方法。现有单任务模型主要可分为基于网络结构的模型和基于图结构的模型两大类。\n（1）基于分支结构的单任务学习模型\n该类方法通常为两种药物及细胞系的多模态特征（如分子指纹、基因表达谱等）设计独立的分支网络进行编码，每条分支能够专门提取对应实体的特征表示。随后，各分支的输出在高层融合，通过多层感知机、注意力机制或特征交互模块建模药物-药物-细胞系三者之间的非线性关系。通过端到端训练，该类模型在药物协同预测任务中取得了良好性能，显示了深度神经网络的应用潜力。\n（2）基于图结构的单任务学习模型\n图神经网络被广泛应用于构建包含药物、细胞系、蛋白质及疾病等多维信息的异质图模型，通过整合转录组学、蛋白质组学及药理学等多源异质数据，构建起跨尺度的生物关联网络。通过在图结构上执行多轮消息传递与聚合，该类模型能有效捕获不同生物实体间潜在的高阶复杂交互，挖掘深层生物路径关联，从而为预测药物协同效应提供关键的结构特征与语义表征。\n图4. 用于药物协同预测的单任务学习模型与多任务学习模型结构概况。\n多任务学习：协同效应预测模型的重要拓展方向\n为缓解单任务学习在监督信号不足方面的局限，近年来多任务学习逐渐成为药物协同预测领域的重要研究方向。该类方法通过在共享表示空间中联合建模多个相关任务，引入额外的生物学约束与辅助监督信息，从而提升模型的鲁棒性和泛化能力。根据辅助任务的类型，多任务模型主要可分为以下两类。\n（1）基于药物敏感性预测的多任务模型\n该类方法将单药敏感性预测作为辅助任务，与药物组合协同效应预测进行联合学习。通过共享药物和细胞系的底层表示，该类模型能够同时捕获单药作用机制与联合用药效应之间的内在联系，从而在一定程度上缓解协同数据稀缺带来的训练不稳定问题。\n（2）基于药物-药物相互作用预测的多任务模型\n另一类多任务方法引入药物-药物相互作用预测任务，显式刻画药物之间的相互作用关系。该类模型通常通过共享药物表示或引入任务特异的交互模块，使模型在关注协同效应的同时，对药物对之间潜在的相互作用保持敏感，有助于从更全面的角度理解药物组合的生物学效应。\n表4 不同深度学习预测模型及其对应任务设置。\n为比较不同类型模型的预测性能，作者选取了若干具有代表性的模型以DrugComb数据集作为数据来源开展对比实验。\n为\n直观展示模型比较过程，图5给出了所有模型所遵循的完整流程，包括数据准备、样本划分和模型构建。\n图5 用于药物协同预测模型比较的完整工作流程。\n预测模型性能比较结果如表5所示。总的来说，\nSynergyX和MDNNSyn的优异表现源于其构建高质量特征的能力，而对于多任务学习模型而言，特征质量，尤其是共享特征的质量，同样至关重要。\n因此，未来的多任务学习模型应进一步提升构建信息更丰富的共享药物或细胞系特征的能力。\n表5 预测模型在DrugComb数据集上的性能比较。\n讨论及展望\n基于深度学习的预测模型在预测药物组合协同效应方面显示出巨大潜力，但在\n数据、技术和优化方面\n仍有改进空间，如图6所示。\n图6 基于深度学习的药物协同预测模型的发展展望。\n数据方面：药物浓度测量。\n在实际应用中，药物浓度是影响治疗效果的重要因素。在实验验证阶段，研究人员需要通过生物实验测量并调整药物浓度，以确保药物组合在适宜浓度下发挥最佳效果。该过程不仅耗时，而且需要大量实验资源和专业技术。为了提升模型的实用性和准确性，未来的发展方向可包括\n将药物浓度纳入关键参数，\n使模型不仅预测哪些药物组合具有协同效应，还能评估不同浓度下的药物作用效果，并指导浓度调整以实现最佳治疗效果。这需要\n构建包含药物浓度信息的药物协同数据集，\n使预测模型能够处理并学习药物浓度与疗效之间的关系。\n技术方面：优化药物和细胞系特征。\n大多数深度学习方法通常独立分析药物和细胞系特征。然而，不同药物之间的相互作用在不同细胞系中可能产生不同效果，从而影响整体治疗结果。未来研究方向可包括\n开发新算法，更好地理解和建模药物组合与细胞系之间的复杂相互作用，从而为构建更合理的药物和细胞系特征提供指导。\n在多任务学习框架下，共享特征可以帮助模型同时执行药物协同预测任务与辅助任务。不同任务可以共享表示学习过程中获得的通用特征，同时学习任务特异性特征，这种互补性有助于增强模型对药物协同效应的理解。因此，\n设计新技术以提升多任务学习预测模型中共享特征的质量，也是一个值得探索的发展方向。\n优化方面：提升多任务预测能力。\n在构建多任务预测模型时，\n寻找每个损失函数的最优权重参数，以及确定如何组合多个损失函数以实现最佳整体性能，是值得研究的问题。\n此外，在某些多任务学习模型中，单药敏感性预测任务的性能尚未与以往研究进行直接比较。这主要是由于不同研究中所用的数据集、敏感性评分指标和评价方法存在差异。因此，未来研究有望解决这些差异问题，从而\n实现辅助任务的更有意义比较。\n此外，\n设计新的辅助任务也是必要的。\n通过引入新型辅助任务，如疾病–靶点关联预测、药物–靶点亲和力预测等，模型可以从多个角度和层次理解药物组合的协同效应，从而学习更丰富、更具多样性的特征。\n参考资料\nLi, L., Zhang, H., Zheng, C. et al. A review of deep learning approaches for drug synergy prediction in cancer. npj Drug Discov. 2, 30 (2025).\nhttps://doi.org/10.1038/s44386-025-00034-1",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512561&idx=1&sn=25a1172e3da46955dfaff3f7bdcb50bd&chksm=fde9ace1646e91bf9cbf94d3db930f0072c4d4df5747267dfd7b9f9fefaad61c133868a60954&scene=0&xtrack=1#rd",
      "publish_time": 1767631800,
      "publish_date": "2026-01-06 00:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s44386-025-00034-1\"]",
      "add_ts": 1767655146,
      "last_modify_ts": 1767828108
    },
    {
      "id": 219,
      "article_id": "51656",
      "title": "【TVM教程】TVM 运行时系统",
      "description": "TVM 更新至 0.21.0，中文文档同步上线。作为深度学习编译框架，TVM 支持多种硬件后端与编程语言，广泛用于模型优化与部署。其核心运行时需满足多语言调用、调试、链接、原型开发等需求。PackedFunc 是关键解决方案，实现跨语言函数调用，支持灵活的接口交互与轻量级部署，尤其适合嵌入式设备，兼顾实验与生产需求。",
      "content": "TVM 现已更新到 0.21.0 版本，\nTVM 中文文档\n已经和新版本对齐。\nApache TVM 是一个深度的深度学习编译框架，适用于 CPU、GPU 和各种机器学习加速芯片。更多 TVM 中文文档可访问 →\nApache TVM\nTVM 支持多种编程语言用于编译器栈的开发和部署。在本说明中，我们将解释 TVM 运行时的关键组成部分。\nVM 的运行时系统需要满足多种看似相互矛盾但又非常关键的需求：\n部署（Deployment）：能够在 Python / JavaScript / C++ 等语言中调用已编译的函数。\n调试（Debug）：允许用户在 Python 中定义函数，并从已编译的代码中反向调用。\n链接（Linking）：需要编写驱动端代码来调用设备端实现（如 CUDA kernel），并且运行时需要能从主机端代码中调用它们。\n原型开发（Prototyping）：支持在 Python 中创建 IR Pass，并能从 C++ 后端调用。\n接口暴露（Frontend Exposure）：编译器的核心逻辑由 C++ 实现，但必须便捷地暴露给 Python 等前端语言。\n实验与部署（Experiment & Deployment）：能够将编译好的函数直接传输并运行在嵌入式设备上。\n我们希望能够在任何语言中定义函数并在另一种语言中调用。我们还希望运行时核心尽可能小，以便部署到嵌入式设备上。\nPackedFunc\n​\nPackedFunc\n是我们找到的一个简单但优雅的解决方案来解决列出的挑战。 一个\nPackedFunc\n对象就表示一次函数调用，而调用方和被调用方可以处于不同的语言环境中。\n下面的代码块提供了一个 C++ 示例\n#include <tvm/ffi/function.h>\n\nvoid MyAdd(ffi::PackedArgs args, ffi::Any* rv) {\n  // automatically convert arguments to desired type.\n  int a = args[0].cast<int>();\n  int b = args[1].cast<int>();\n  // automatically assign value return to rv\n  *rv = a + b;\n}\n\nvoid CallPacked() {\n  PackedFunc myadd = PackedFunc(MyAdd);\n  // get back 3\n  int c = myadd(1, 2);\n}\n在上面的代码块中，我们定义了一个 PackedFunc MyAdd。它接受两个参数：\nargs\n表示输入参数，\nrv\n表示返回值。该函数是类型擦除的，这意味着函数签名不会限制传入或返回值的类型。在底层，当我们调用一个 PackedFunc 时，它会将输入参数打包成 ffi::PackedArgs 放在栈上，并通过 ffi::Any 获取返回结果。\n得益于 C++ 中的模板机制，我们可以像调用普通函数一样调用 PackedFunc。由于其类型擦除的特性，我们可以在诸如 Python 这样的动态语言中调用 PackedFunc，而不需要为每一种新函数类型额外编写 glue 代码。下面的例子展示了如何在 C++ 中注册一个 PackedFunc，并在 Python 中调用它。\n// register a global packed function in c++\nTVM_FFI_STATIC_INIT_BLOCK() {\n  namespace refl = tvm::ffi::reflection;\n  refl::GlobalDef().def_packed(\"myadd\", MyAdd);\n}\nimport tvm\n\nmyadd = tvm.get_global_func(\"myadd\")\n# prints 3\nprint(myadd(1, 2))\nPackedFunc 的大部分「魔力」来自\nffi::PackedArgs\n和\nffi::Any\n这两个结构。我们对可传递的类型做了限制，常见的类型包括：\nint、float 和 string\nPackedFunc 本身\nModule，用于表示已编译模块\nDLTensor*，用于张量对象交换\nTVM Object，用于表示 IR 中的任意对象\n这种限制使得实现变得简单，无需序列化。即使实现精简，PackedFunc 在深度学习部署的场景中依然绰绰有余，因为大多数函数只需要处理 DLTensor 或数字。\n由于一个 PackedFunc 可以将另一个 PackedFunc 作为参数传递，因此我们可以将 Python 中的函数（转换为 PackedFunc）传递给 C++。\nTVM_FFI_STATIC_INIT_BLOCK() {\n  namespace refl = tvm::ffi::reflection;\n  refl::GlobalDef().def_packed(\"callhello\", [](ffi::PackedArgs args, ffi::Any* rv) {\n    ffi::Function f = args[0].cast<ffi::Function>();\n    f(\"hello world\");\n  });\n}\nimport tvm\n\ndef callback(msg):\n  print(msg)\n\n# convert to PackedFunc\nf = tvm.convert(callback)\ncallhello = tvm.get_global_func(\"callhello\")\n# prints hello world\ncallhello(f)\nTVM 提供了一个最小化的 C API\nminimum C API\n，它允许我们将 PackedFunc 嵌入到任意语言中。除了 Python 以外，目前还支持\njava\n和\njavascript\n。这种嵌入式 API 的设计理念与 Lua 很相似，只不过我们并没有创造一门新的语言，而是直接使用了 C++。\n关于 PackedFunc 有一个有趣的事实：我们在编译器栈和部署栈中都使用它。\nTVM 中所有编译器 Pass 函数都以 PackedFunc 的形式暴露给前端\n已编译模块同样以 PackedFunc 的形式返回已生成的函数\n为了保持运行时尽可能精简，我们将 IR Object 支持从部署运行时中分离开来。最终生成的运行时大小大约为 200K - 600K，具体取决于包含的运行时驱动模块数量（例如 CUDA）。\n调用 PackedFunc 相比普通函数的开销很小，只多做了一些栈上值保存。因此，只要不频繁包装非常小的函数，这样的开销是可以接受的。总的来说，PackedFunc 是 TVM 的通用“胶水层”，我们在编译和部署模块中都大量依赖它。\n组件\n​\n由于 TVM 支持多种不同类型的硬件设备，我们也需要支持对应的不同驱动程序。我们必须使用这些驱动 API 来加载内核、以打包形式设置参数并启动内核执行。同时，我们还需要对驱动 API 进行封装，以确保暴露给用户的接口是线程安全的。因此，我们通常会在 C++ 中编写这些驱动层 Glue 代码，并通过 PackedFunc 将其暴露给用户。显然，我们不可能为每类函数都单独编写接口，因此 PackedFunc 再次成为解决方案。\nTVM 将编译结果抽象为一个\nModule\n。\n用户可以从 Module 中以 PackedFunc 的形式获取已编译函数。生成的代码在运行时可以动态地从 Module 中获取目标函数，并在第一次调用时缓存句柄，后续复用。这使得我们可以在生成代码中链接设备端函数，并调用任意 PackedFunc（例如 Python 回调）。\nModuleNode 是一个抽象类，不同设备类型可以各自实现。例如，我们已支持 CUDA、Metal、OpenCL 以及动态库（Shared Library）。这种抽象设计使得引入新设备变得简单，而无需重新生成每种设备的主机端代码。\n远程部署\n​\nPackedFunc 和 Module 系统也使得我们可以将函数直接部署到远程设备上。在底层，我们提供了一个 RPCModule，它负责序列化参数、进行数据传输，并在远程设备上启动计算。\nRPC 服务器本身非常精简，可以直接与运行时一起打包。我们可以在 iPhone、Android、树莓派甚至浏览器中启动一个最小化的 TVM RPC 服务器。交叉编译、模块打包与测试都可以在同一个脚本中完成。更多细节可参考\ntutorial-cross-compilation-and-rpc\n。\n这种即时反馈带来了显著优势。例如，当我们希望验证生成的代码在 iPhone 上的正确性时，不再需要手动用 Swift/Objective-C 重写测试样例——我们可以直接使用 RPC 在 iPhone 上执行代码，将结果复制回主机，并使用 numpy 进行验证。同样，我们也可以使用同一个脚本进行性能分析。\nTVM 对象与编译器栈\n​\n如前所述，我们在 PackedFunc 运行时系统之上构建了编译器栈的 API。由于研究需求，编译器 API 经常需要不断变化。当我们想要测试新的语言原语时，就需要引入新的语言对象或 IR 节点。但是我们又不希望频繁修改 API。此外，我们还希望：\n能够序列化任意语言对象和 IR；\n能够在前端语言中探索、打印和操作 IR 对象，以便进行快速原型开发。\n为了解决这些问题，我们引入了一个基类\nObject\n。 编译器栈中的所有语言对象都是\nObject\n的子类。每个对象都包含一个字符串 type_key，用于唯一标识对象类型。我们选择字符串而不是整数作为类型键的原因是：这样可以以去中心化方式添加新的\nObject\n类，而无需往中心仓库中添加代码。为了加速调度，我们会在运行时为每个 type_key 分配一个整数 type_index。\n由于一个\nObject\n通常会在语言中被多个地方引用，我们使用 shared_ptr 来管理对象引用。\nObjectRef\n类用于表示对\nObject\n的引用，可以将其视为指向\nObject\n容器的 shared_ptr。我们也可以定义\nObjectRef\n的子类来对应不同的\nObject\n子类型。每个\nObject\n子类都需要实现 RegisterReflection 函数。\n每个\nObject\n子类会重写该函数来注册其成员。下面是 IntImmNode 的示例实现：\nclass IntImmNode : public PrimExprNode {\npublic:\n  /*! \\brief the Internal value. */\n  int64_t value;\n\n  static void RegisterReflection() {\n    namespace refl = tvm::ffi::reflection;\n    refl::ObjectDef<IntImmNode>().def_ro(\"value\", &IntImmNode::value);\n  }\n  TVM_FFI_DECLARE_OBJECT_INFO_FINAL(\"ir.IntImm\", IntImmNode, PrimExprNode);\n};\n// in cc file\nTVM_FFI_STATIC_INIT_BLOCK() { IntImmNode::RegisterReflection(); }\nRegisterReflection\n为我们提供了一个反射接口，用于注册对象的成员。我们可以利用这个函数递归地访问并序列化任何语言对象。同时，它也使我们可以在前端语言中轻松访问对象的字段。例如：\nimport tvm\n\nx = tvm.tir.IntImm(\"int32\", 1)\n# access the value field of IntImmNode\nprint(x.value)\n新的\nObject\n可以仅在 C++ 中添加而无需修改前端运行时，从而方便扩展编译器栈。需要注意的是，这种机制不是访问成员的最高性能方式，但它是最简单的方法之一。我们发现这种方式非常适合我们的目的：用 Python 进行测试和原型开发，而真正的计算和重工作交由 C++ 完成。\n实现细节\n​\nPackedFunc 中的每个参数由一个联合体\nTVMValue\n和一个类型码组成。这样的设计使得动态类型语言可以直接转换到对应类型，而静态类型语言则可以在转换过程中执行运行时类型检查。\n相关文件包括：\npacked_func.h\n—— C++ API\nc_runtime_api.cc\n—— C API 以及如何提供回调支持\n为了支持扩展类型，我们使用了一个注册表系统来注册类型相关信息，例如允许 C++ 中对\nany\n的支持。更多详情可参考：\nExtension types\n。\n与运行时相关的信息\nVulkan Runtime\n内容中包含的图片若涉及版权问题，请及时与我们联系删除",
      "article_url": "https://hub.baai.ac.cn/view/51656",
      "publish_time": 1767622500,
      "publish_date": "2026-01-05 22:15",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://zhida.zhihu.com/search/3705836406608869133\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/runtime/%23packedfunc\", \"https://link.zhihu.com/?target=https%3A//github.com/apache/tvm/blob/main/include/tvm/runtime/packed_func.h\", \"https://github.com/apache/tvm/blob/main/include/tvm/runtime/base.h\", \"https://github.com/apache/tvm/tree/main/jvm\", \"https://github.com/apache/tvm/tree/main/web\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/runtime/#%E7%BB%84%E4%BB%B6\", \"https://github.com/apache/tvm/blob/main/include/tvm/runtime/module.h\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/runtime/#%E8%BF%9C%E7%A8%8B%E9%83%A8%E7%BD%B2\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/runtime/#tvm-%E5%AF%B9%E8%B1%A1%E4%B8%8E%E7%BC%96%E8%AF%91%E5%99%A8%E6%A0%88\", \"https://github.com/apache/tvm/blob/main/include/tvm/runtime/object.h\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/runtime/#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82\", \"https://github.com/apache/tvm/blob/main/include/tvm/runtime/base.h#L135\", \"https://github.com/apache/tvm/blob/main/include/tvm/runtime/packed_func.h\", \"https://github.com/apache/tvm/blob/main/src/runtime/c_runtime_api.cc#L262\", \"https://github.com/apache/tvm/tree/main/apps/extension\"]",
      "add_ts": 1767655148,
      "last_modify_ts": 1767741647
    },
    {
      "id": 222,
      "article_id": "51653",
      "title": "MIT新论文：2026推理模型过时了，“套娃模型”当立",
      "description": "MIT博士生论文提出“套娃模型”新范式，即递归模型，通过将文本存入代码环境，让模型编写程序拆解并递归调用自身，显著提升长文本处理能力。该方法使上下文窗口扩大两个数量级，缓解“上下文腐烂”问题，且成本更低。相比GPT-5等传统推理模型，性能更优，有望成为2024年主流。",
      "content": "克雷西 发自 凹非寺\n量子位 | 公众号 QbitAI\n推理模型这就过时了？\n当中的扛把子GPT-5被一篇博士生论文打了个措手不及，上下文窗口被甩出两个数量级。\n而且新方法面对长文本时的“上下文腐烂”现象也大幅减少，关键是成本还更便宜。\n这就是MIT最新论文当中提出的“套娃模型”新范式，被预言将成为今年的主流。\n“套娃模型”正式名称叫做\n递归模型\n，核心流程是\n将文本存入代码环境\n，让模型编写程序拆解并递归调用自身处理。\n有网友评价说，递归模型不仅是在节省Token，更是在改变交互方式。\n从它的各种指标来看，推理模型，看上去真的是不香了。\n代码驱动的递归推理\n递归语言模型（RLM）一改将长文本直接作为Prompt输入神经网络的传统做法，转而采用一种\n“环境化”\n的处理范式。\n其核心逻辑在于将自然语言处理任务重构为交互式编程任务，引入一个外部的Python REPL（读取-求值-输出循环）环境，\n将超长文本作为一个静态字符串变量存储在内存中\n。\n在这种架构下，大模型不再一次性编码所有信息，而是作为一个拥有读写权限的Agent，通过生成和执行Python代码来对这个外部变量进行操作。\n这种设计从根本上解耦了输入数据的长度与模型自身的上下文窗口大小，允许处理的文本长度仅受限于物理内存而非Transformer的注意力机制跨度。\n在具体的执行流程中，RLM建立了一套基于代码的认知循环。\n当系统接收到一个长文本任务时，它首先启动Python环境并将文本载入变量P，随后，模型进入一个迭代循环，首先观察当前的环境状态，编写一段Python代码来探测文本。\n这些代码在REPL环境中被执行后，其运行结果会作为新的观测数据反馈给模型。\n通过这种\n“编写代码-观察执行结果”\n的循环，模型能够以极低的计算成本在庞大的文本数据中进行索引和定位，仅在必要时读取关键段落，从而实现了对上下文的高效管理。\n递归调用是该机制能够处理无限长上下文的关键所在。\nRLM允许模型在编写的代码中调用一个特殊的接口函数，该函数的作用是启动模型自身的一个新实例（或更小的子模型）来处理特定的子任务。\n当模型通过代码将长文本切割为多个部分后，它可以针对每一个部分生成一个新的Prompt，并调用子模型分别进行处理。\n这些子模型的输出并不是直接返回给用户，而是被赋值给新的变量，存储在当前的Python环境中。\n主模型随后可以编写代码读取这些变量，对其进行逻辑判断、拼接或进一步的语义整合。\n这种递归结构不仅实现了任务的并行化分解，更重要的是它支持多层级的深度推理，每一层递归都只需要处理当前层级的局部信息，从而确保整个处理过程始终维持在模型原本的上下文窗口限制之内。\n这种基于代码环境的交互方式为模型诱发了多种高效的涌现策略，模型在并未经过专门训练的情况下，自发学会了利用正则表达式等编程工具来过滤信息。\n例如，在寻找特定信息时，模型会先构造查询语句在变量中进行关键词匹配，仅提取包含关键词的上下文片段进行阅读，这种先检索后阅读的策略极大地减少了Token的消耗。\n此外，针对输出长度受限的问题，RLM显现出了通过变量拼接结果的能力。\n在处理需要生成超长答案的任务时，模型会将子任务的生成结果分别存储在列表变量中，最后通过代码将这些字符串连接起来。\n这种机制实际上是在外部环境中构建了一个动态的、可编程的工作记忆空间，使得模型能够像操作数据库一样操作自然语言文本，在不改变底层神经网络权重的前提下，具备了处理极高复杂度长文本的逻辑推理能力。\n突破千万级Token的性能极限\n实验数据显示，RLM的有效处理规模已达到1000万Token级别，超出GPT-5等前沿模型原生上下文窗口两个数量级。\n在包含GPT-5和Qwen3-Coder-480B等模型的评测中，RLM突破了物理显存对上下文长度的限制，并在任务完成质量上超越了基础模型及现有的长文本处理方案。\n并且针对长文本处理中常见的“上下文腐烂”问题，RLM也表现出了较强的稳定性。\n传统基础模型在S-NIAH单针大海捞针等简单检索任务中尚能维持表现，但在信息密度更高的复杂任务中，其推理性能随输入长度增加而下降。相比之下，RLM在输入长度超过特定阈值区间后，依然保持得分稳定性。\nRLM在对高密度、高复杂度信息的整合能力上也表现出了显著差异。\n对于要求模型线性扫描并处理文中几乎所有信息的OOLONG任务，基础GPT-5的性能随长度增加而衰减，而RLM则实现了双位数的性能提升。\n在难度更高的OOLONG-Pairs测试（该任务要求模型聚合文中成对的信息片段）中，处理复杂度随长度呈二次方增长。\n面对这种高难度的推理任务，基础GPT-5和Qwen3-Coder模型F1分数不足0.1%。然而，搭载RLM架构的GPT-5和Qwen3-Coder在同一任务上分别取得了58.00%和23.11%的F1分数。\n由于RLM将Prompt视为外部环境，有选择性地读取与任务相关的片段，而非被迫全量摄入，因此在成本效益方面，RLM改变了“上下文越长成本越高”的线性规律。\n例如在BrowseComp-Plus基准测试中，GPT-5-mini处理600万至1100万Token输入的理论成本约为1.50至2.75美元，而RLM的平均实际花费仅为0.99美元。\n这一成本低于全量阅读的基础模型，也比试图压缩上下文的Summary Agent方案更低。\n这表明RLM能够在保持性能的同时，通过按需读取策略控制推理成本，为长文本应用的大规模落地提供了经济可行的路径。\n作者简介\n本文第一作者为MIT CASIL实验室博士生Alex Zhang。\nAlex本科就读于普林斯顿，以该校计算机科学系第一名的成绩毕业。\n其研究方向主要包括评估语言模型能力、机器学习系统和GPU编程，以及用于代码生成的AI。\n另外两位署名者Omar Khattab和Tim Kraska都是Alex的导师。\nTim和Omar两人均为MIT助理教授。\n论文地址：\nhttps://arxiv.org/abs/2512.24601\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859921&idx=1&sn=66c97b10dc003570aa0efcac4daf9611&chksm=e905d64a05da01e23b87f6b0e47a7ec490c81c42631e33354d1d090f1e32321819786b1bdb8f&scene=0&xtrack=1#rd",
      "publish_time": 1767615600,
      "publish_date": "2026-01-05 20:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.24601\"]",
      "add_ts": 1767655167,
      "last_modify_ts": 1767741661
    },
    {
      "id": 223,
      "article_id": "51652",
      "title": "比SOTA提速10倍！北大DragMesh重塑3D交互，物理零失真",
      "description": "北京大学团队提出DragMesh，通过“语义-几何解耦”与双四元数VAE，显著提升静态3D模型动化效率。该方法将算力消耗降至现有最佳模型的1/10，运动轴预测误差降低10倍，无需标注数据即可实现符合物理规律的实时动态模拟，突破生成速度与物理合理性的双重瓶颈，推动图形学领域新进展。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n让静态3D模型「动起来」一直是图形学界的难题：物理模拟太慢，生成模型又不讲「物理基本法」。近日，北京大学团队提出DragMesh，通过「语义-几何解耦」范式与双四元数VAE，成功将核心生成模块的算力消耗降低至SOTA模型的1/10，同时将运动轴预测误差降低了10倍。得益于底层数学的完备性，该模型无需任何标注，即可让任意静态Mesh实现符合物理规律的实时交互。\n在生成式AI的浪潮下，业界已经可以通过LRM、TripoSR等模型生成高质量的静态3D资产。\n然而，一个完整的3D世界模型（World Model）不仅需要知道物体「长什么样」，更需要理解它们「怎么动」以及如何响应用户的交互。\n当前的3D交互生成领域面临着一道难以逾越的「交互-保真度鸿沟」：\n1. 物理模拟派（如基于优化的方法）：\n虽然物理一致性高，但计算过于沉重，无法满足实时交互需求。\n2. 纯生成派（如基于扩散模型的方法）：\n虽然生成速度较快，但经常违反运动学约束，产生「关节脱臼」、「穿模」或轨迹漂移等幻觉。\n为了打破这一僵局，北京大学团队推出了DragMesh，这是一个专为实时交互设计的轻量级框架，它没有盲目堆砌算力，而是从数学表征和架构设计底层入手，实现了物理真实性与计算效率的双重飞跃。\n论文链接：https://arxiv.org/abs/2512.06424\n代码链接：https://github.com/AlGeeksGroup/DragMesh\n项目主页：https://aigeeksgroup.github.io/DragMesh\n核心技术\n两大创新重塑3D交互\nDragMesh 并没有采用端到端的暴力生成，而是提出了解耦的设计哲学。团队认为，现有模型之所以庞大且低效，是因为试图用一个网络同时解决「语义理解」（这是微波炉还是柜子？）和「动作生成」（它该怎么转？）这两个性质完全不同的问题。\n语义-几何解耦范式\nDragMesh将交互过程拆解为两个轻量级流水线：\ninference pipeline（推理流程）\n意图推理：\n利用 VLM（如 GPT-4o）的通识能力，快速判断用户的交互意图，解决语义歧义（例如：判断关节类型是旋转的合页还是滑动的抽屉）。\n几何回归：\n团队设计了专用的 KPP-Net (Kinematics Prediction Network) 。不同于通用的点云编码器，KPP-Net采用了双流注意力机制，专门用于从 Mesh 和拖拽信号中回归精准的关节轴和原点。\n这种解耦设计使得核心生成网络不再需要「猜测」物体结构，而是直接基于预测出的运动学参数进行生成，大幅减轻了模型负担。\n双四元数VAE\n为了解决传统欧拉角（万向节死锁）或变换矩阵（参数冗余、不连续）的问题，团队引入了双四元数 (Dual Quaternions, DQ) 作为核心运动表征。\n一个单位双四元数仅需8个参数，即可同时完美描述三维空间中的旋转和平移，且天然满足螺旋运动理论。\n基于此，团队构建了DQ-VAE。\nDQ-VAE training pipeline\n非自回归Transformer解码器：\n摒弃了容易产生误差累积的自回归方式，采用并行解码，保证了长序列动作的连贯性 。\nFiLM条件注入：\n将KPP-Net预测的关节先验通过FiLM (Feature-wise Linear Modulation) 层注入到Transformer的每一层中，确保生成的每一帧都严格「听从」物理约束。\n物理修正模块：\n在解码器末端引入残差修正，进一步微调轨迹以消除微小的物理漂移，确保最终输出严格遵循物理法则 。\n性能评测\n算力暴降，精度暴涨\n团队在GAPartNet和Objaverse数据集上进行了广泛的对比实验，结果显示DragMesh在各项指标上均实现了高效提升 。\n效率：比SOTA提速10倍\n性能对比，横轴为计算量 (GFLOPs)，气泡大小代表参数量。紫色气泡代表现有的通用模型（如DragAPart, PartRM），它们往往参数量巨大且计算昂贵 。DragMesh（左下角）的核心生成模块参数量仅为27.5M，GFLOPs 仅为5.2 。\n相比MeshArt (304M Params, 1540 GFLOPs) 和DragAPart (1100M Params, 350 GFLOPs)，DragMesh的计算开销降低了5到10倍，且无需针对每个物体单独训练。\n精度：几何误差降低一个数量级\n在运动学预测的消融实验中，架构的优势尤为明显 ：\nBaseline (PointNet)，\n轴预测误差高达450.0mrad\nOurs (KPP-Net)，\n通过解耦设计与双流注意力机制，轴预测误差降至45.0mrad，原点预测误差仅为1.8mm\n这意味着用户在拖拽柜门时，DragMesh预测的旋转轴偏差极小，几乎不会出现门板「飞出」或「歪斜」的现象。\n物理一致性可视化\n对比分析\n在定性对比中，面对微波炉、折叠椅等物体时，\nArtGS / PartRM：\n因为流程复杂需要的前验内容较多，经常出现结构崩坏或无法识别的情况（图中标空缺部分）。\nDragMesh：\n无论是平移（抽屉）还是旋转（门、翻盖），都能生成平滑、结构完整的运动轨迹，且严格保持了物体的刚性结构 。\n总结与展望\n开启通用物理交互新纪元\nDragMesh的发布不仅仅是提出了一个新的模型，更重要的是验证了一条通往3D世界模型的极简路径 。\n传统方法往往需要针对「旋转」和「平移」分别设计约束，而DragMesh采用的双四元数从数学底层上实现了刚体运动的「大一统」 。\n根据沙勒定理，空间中任意刚体运动都可以描述为螺旋运动。这意味着 DragMesh 的核心架构天然具备描述世间万物复杂运动的能力。\n无论是机械臂的复合扭转，还是更精密的螺旋传动，DragMesh 无需修改底层架构，即可将其纳入「语义-几何」的统一流形中。\n得益于解耦设计与DQ-VAE的紧凑表征，DragMesh成功将物理交互带入实时时代，证明了我们不需要等待分钟级的物理模拟，也不需要忍受离线渲染的延迟。\n在未来的元宇宙构建、机器人仿真以及数字孪生场景中，DragMesh这种「即拖即动、即动即真」的轻量化范式，将成为赋予静态资产「物理常识」的基础设施 。\n未来，DragMesh将继续利用其在螺旋理论上的数学优势，向多关节级联及更复杂的动力学场景从容扩展，让AI真正理解物理世界的运行规律。\n参考资料：\nhttps://arxiv.org/abs/2512.06424\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660714&idx=2&sn=46ba07fe4dfcbab53e1c1ca05db556d9&chksm=f09435f97fca7becd0ba6f1741a587e2ae3cc1e7e60de98149f8473db2b895033394a899993d&scene=0&xtrack=1#rd",
      "publish_time": 1767615600,
      "publish_date": "2026-01-05 20:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.06424\", \"https://github.com/AlGeeksGroup/DragMesh\", \"https://aigeeksgroup.github.io/DragMesh\"]",
      "add_ts": 1767655172,
      "last_modify_ts": 1767741664
    },
    {
      "id": 224,
      "article_id": "51651",
      "title": "生成1.8万年气候数据，英伟达等提出长距离蒸馏，仅需单步计算实现长期天气预报",
      "description": "AI天气预报在中期表现优异，但长期预测受限于误差累积与数据稀缺。英伟达与华盛顿大学提出“长距离蒸馏”方法，利用自回归模型生成万年量级合成气候数据作为“教师”，训练单步输出的“学生”模型，突破观测数据限制。该方法避免迭代误差，提升S2S预测可靠性，性能媲美ECMWF系统，且随数据量增加持续优化，为气候尺度预报提供高效新路径。",
      "content": "天气预报的精准度和预见期，直接影响灾害防御、农业生产和全球资源调度。从短时预警到季节乃至更长期的气候预测，每延长一步，技术挑战都成倍增加。传统数值预报发展多年后，AI 为这一领域带来了新动力。近年来，AI 天气预报模型已在中期预报上取得突破，其性能媲美甚至超越了先进的传统动力模式。\n目前主流 AI 气象模型多采用自回归架构，其原理是逐步推演，通过学习历史数据中的短期大气变化规律，预测未来几小时的状态。这种模型在中期预报中表现出色，\n但在向次季节至季节（S2S）等长期尺度拓展时，遇到了根本性瓶颈。\n长期预报需依赖概率方法，而自回归模型只能通过反复迭代进行多步预测，导致误差不断累积，且难以校准。其核心矛盾在于：\n训练目标是学习短期规律，而长期预报需要构建能够刻画气候慢变率的概率模型。\n为突破此局限，研究者开始探索单步长预测新路径。但新问题随之而来：基于现有再分析数据训练长期单步模型时，会因数据样本稀少而严重过拟合，模型可靠性无法保证。\n在此背景下，\n英伟达研究院联合华盛顿大学的研究团队推出了一种\n长距离蒸馏\n（Long-Range Distillation）新方法，\n其核心思路是利用擅长生成真实大气变率的自回归模型作为「教师」，通过其低成本、快速模拟产生海量合成气象数据；再用这些数据训练一个概率化的「学生」模型。学生模型仅需单步计算即可生成长期预报，既避免了迭代误差累积，也绕过了复杂的数据校准难题。\n这一方法脱离自回归建模框架，转而将大规模气候数据压缩为条件生成模型，突破了以往训练数据有限的制约。研究中采用能稳定模拟百年气候的自回归耦合模型作为教师，生成了规模远超真实记录的训练样本。初步实验表明，基于此训练出的学生模型，在 S2S 预报上与 ECMWF 集成预报系统相当，且其性能随合成数据量增加而持续提升，有望在未来实现更可靠、更经济的气候尺度预测。\n相关研究成果以「Long-Range Distillation: Distilling 10,000 Years of Simulated Climate into Long Timestep AI Weather Models」为题，已发表于 arXiv。\n研究亮点：\n* 突破真实观测数据时长限制，利用 AI 气象模型生成超万年合成气候数据，使模型能够学习实际观测中未曾充分呈现的慢变气候模态；\n* 提出长距离蒸馏方法，仅需单步计算即可输出长期概率预报的模型，克服了传统自回归框架中数百步迭代导致的误差累积与不稳定问题；\n* 经真实世界数据适配后，模型在次季节至季节预报上的技巧，已达到欧洲中期天气预报中心业务系统的相当水平。\n数据集：合成气候数据的生成、划分与评估框架\n在评估长距离蒸馏模型的跨时效集成预报能力时，该研究首先在受控的理想模型实验中进行验证。\n所有评估数据均取自自回归教师模型\nDLESyM\n（Deep Learning Earth System Model）预留的模拟数据，\n且在蒸馏模型的训练过程中从未被使用。这一设置的核心目的，是检验在初始条件未完全确定的情况下，蒸馏长步长模型与 DLESyM 教师模型对未见模拟天气的预报表现，确保评估的客观性。\n评估不仅采用了集成均方根误差（RMSE）等确定性指标，还引入了连续排序概率评分（\nCRPS\n）这一概率预报评估工具，以更全面地衡量预报性能。研究人员选取了 3 个具有不同可预测性机制的预报时效进行测试：\n* 中期时效：\n针对 7 天的日平均预报（参数 N=28, M=4），使用 2017 年 1 月 1 日至 2019 年 3 月 10 日（模拟年）的预留数据，每 2 天选取一个初始日期，共 400 余个样本。\n* S2S 时效：\n针对 4 周的周平均预报（参数 N=112, M=28），使用 2017 年 1 月 1 日至 2021 年 5 月 16 日（模拟年）的数据，每 4 天一个初始日期，样本量同样超过 400 个。\n* 季节时效：\n针对 12 周的月平均预报（参数 N=336, M=112），使用 2017 年 1 月 1 日至 2025 年 9 月 28 日（模拟年）的数据，每 8 天选取初始日期，样本数约 400 个。\n为确保独立性，研究人员将由 DLESyM 生成的总计约 15,000 年合成气候模拟数据，按集合成员维度划分为训练集（75%，约 11,000 年）和验证集（25%），并为每个预报时效训练了独立的蒸馏模型。这些合成数据的生成采用了并行化策略：在 2008 年 1 月 1 日至 2016 年 12 月 31 日期间均匀选取 200 个初始日期，每个日期对应进行 90 年模拟，\n从而获得总时长 18,000 年的气候数据。\n该研究的最终目标是将训练好的模型应用于真实世界长期预报。需要注意的是，DLESyM 长期运行形成的「模型气候」与真实气候存在差异。因此，将模型迁移至真实应用时，需重点解决这一「\n域转移\n」问题。\n长距离蒸馏：「数据蒸馏」与「概率校准」的双重创新\n长距离蒸馏方法的创新思路在于，\n它利用一个能够稳定长期运行的短步长自回归模型作为「教师」，来训练一个仅需单步计算即可输出长期预报的「学生」模型。\n这从根本上避免了传统自回归框架中数百步迭代所带来的误差累积问题。\n具体而言，研究人员从教师模型的长期滚动序列中定义长期预报目标，即未来某一时间窗口内状态的平均值。学生模型则直接学习从初始状态到该长期目标的条件概率分布。教师模型的核心价值在于其高效生成海量合成数据的能力，这些数据的规模远超原始再分析数据，从而解决了长期预报训练样本稀缺的难题。\n长距离蒸馏示意图\n为实现这一目标，\n该研究采用 DLESyM 模型作为「教师」。\n该模型基于 ERA5 再分析数据初始化，预报关键变量如海温、气温和位势高度等。研究人员设计了高效的数据生成策略：从 2008 至 2016 年间均匀选取 200 个初始日期，并行开展为期 90 年的模拟，总计得到 18,000 年的合成气候数据。在强大算力支持下，数据生成过程仅耗时数小时，充分体现了 AI 气候模拟的效率优势。经过质量筛选，约 15,000 年的有效数据被用于后续模型的训练与验证。\n「学生」模型采用\n条件扩散模型\n架构，专门为概率预报而设计。\n其目标是建模未来长期天气状态与输入条件（如前 4 天的日平均状态）之间的复杂关系。模型架构基于一个适配于 HEALPix 网格的 UNet 网络改进而成，通过引入可学习的空间嵌入和周期性的时间嵌入，以有效捕捉全球天气场的时空依赖特性。在训练中，研究人员采用特定的噪声调度策略，以确保模型能学习到数据中所有尺度的特征。\n为精确校准概率预报的不确定性，本研究创新性地引入了「无分类器引导（Classifier-Free Guidance）」，\n允许在模型推理阶段通过调节一个简单的权重参数，灵活控制预报集合的离散度，\n使其与预报误差达到最佳平衡，从而便捷地生成校准良好的概率预报。\n为使模型能够胜任真实世界的预报任务，该研究针对「域转移（domain shift）」问题实施了双重策略。一是进行气候偏差订正，修正模拟数据与真实观测在平均态上的系统性差异；二是利用有限的 ERA5 再分析数据对模型进行微调，仅更新网络中的部分关键参数，使模型在保留从海量合成数据中学到规律的同时，更好地适应真实大气的特征。最终，通过与欧洲中期天气预报中心（ECMWF）等顶尖业务系统的对比，评估了模型在真实场景中的竞争力。\n多维度突破，数据可扩展、预报可校准、技能可比肩顶尖业务系统\n通过系列实验，该研究围绕训练数据规模的影响、预报不确定性的校准、多时效预报技能，以及与业务系统的对标四个方向，系统地验证了长距离蒸馏模型的性能与潜力。\n首先，该研究验证了核心假设——增加合成训练数据量能显著提升模型预报能力。如下图所示，该研究使用仅 40 年模拟数据训练的模型很快出现过拟合，而基于约 1.1 万年合成数据训练的模型（简称 DLESyM10K）则表现出稳定的学习曲线。更重要的是，\n数据量的增长直接转化为预报技能的提升：\n在 4 周气温预报中，CRPS 评分降低了 14%。这首次证明，利用自回归模型生成大规模合成数据，可有效构建更强大的长期预报模型。\n基于训练数据集的学生模型 S2S 预测技能缩放\n研究采用「无分类器引导」技术来校准概率预报的离散度。通过调节引导强度，可以控制预报集合的分散程度，使其与预报误差达到最佳平衡。实验表明，\n引导强度设为 1 时，模型即可自动实现良好的校准；\n若需调整，也只需在推理阶段简单调节该参数。这为概率预报提供了一种高效、灵活的校准手段。\n使用无分类器指导的中期蒸馏学生模型的预测校准\n模型在中期、次季节至季节（S2S）和季节预报中均表现出稳健性能。\n在中期预报中，模型对初始误差表现出较强的鲁棒性，其概率建模特性有助于对冲初始条件的不确定性。在更具挑战的 S2S 和季节预报中，DLESyM10K 的技能显著优于气候学基准，尤其在热带和海洋等可预测性较高的区域表现突出。值得注意的是，\n它通过单步计算就达到了与自回归教师模型数百步迭代相当的技能，\n体现了该框架的高效性。\n真实场景下的中期预报技能\n将模型迁移至真实世界预报时，通过微调和偏差校正解决了「模型气候」与真实气候的差异问题。与欧洲中期天气预报中心（ECMWF）业务系统的对比显示：\n经过微调的 DLESyM10K，其 4 周气温预报技能与 ECMWF 系统非常接近，且两者均显著优于气候学基准。\n区域分析表明，两者在不同地理区域各有优势，例如 DLESyM10K 在美洲和非洲中部部分区域表现更好。这证明了该 AI 模型具备与先进业务系统竞争的潜力，同时凸显了其差异化价值。\n在完美模型实验中提炼学生模型远期预测技巧\n综上所述，长距离蒸馏方法通过「数据缩放」与「单步概率建模」的结合，训练出能单步输出长期概率预报的条件扩散模型，并结合无分类器引导技术实现了灵活的不确定性校准。实验表明，\n该方法在次季节至季节预报中已达到与欧洲中期天气预报中心业务系统相当的性能。\n这一范式不仅为长期天气预报提供了新方案，也为构建服务于气候科学探索的通用生成模型奠定了基础。\n全球产学研协同加速气象技术变革\n以 AI 生成合成数据解决长期预报中的数据瓶颈，正成为学术界与工业界共同推动气象预报革新的重要方向。一系列前沿研究与工程实践接连涌现，持续推动长期天气预报从理论探索走向业务应用。\n在学术界，跨学科协作正成为攻克核心技术难题的关键。例如，\n芝加哥大学发起的「AI 气候计划（AICE）」，\n联合了气候科学、计算机与统计学等多领域专家，致力于大幅降低气候预报的计算成本。其研发的技术已实现使用普通笔记本电脑生成高水平预报，有望帮助缩小不同地区在气象预报能力上的差距。\n剑桥大学联合图灵研究所、欧洲中期天气预报中心等机构，共同开发了端到端数据驱动预报系统 Aardvark Weather。\n该系统能够融合多种观测数据，同步输出全球网格预报与局部站点预报，在 10 天预报时效上已展现出可与优化后的业务数值模式相媲美的性能。其端到端的建模理念，与长距离蒸馏简化预报流程的初衷高度一致，为长期预报的精准化提供了技术范本。\n* 点击查看\nAardvark Weather\n深度解读：\n登Nature，剑桥大学等发布首个端到端的数据驱动天气预报系统，预测速度提升数十倍\n* 论文名称：End-to-end data-driven weather prediction\n* 论文地址：\nhttps://www.nature.com/articles/s41586-025-08897-0\n在工业界，创新实践更侧重于技术的工程化落地与场景化应用。科技企业通过深度参与产学研合作与自主研发，不断拓展 AI 气象的技术边界。例如，\n微软、谷歌 DeepMind 等机构深入参与了 Aardvark Weather 系统的研发，\n将其在大规模数据处理与深度学习架构方面的优势，转化为气象模型在效率与精度上的提升。其中，谷歌 DeepMind 在生成模型与概率预报校准方面的技术积累，也为解决类似长距离蒸馏中集合离散度控制等问题提供了重要参考。\n与此同时，企业界也积极推动 AI 气象技术在具体场景中的落地。例如，通过与园区管理、应急部门合作，将精准化的长期预报技术整合进智慧防灾系统中，通过全流程模拟灾害演变，为园区安全、水利调度与农业生产等场景提供定制化的预报服务，使长期气象预报的价值真正惠及终端用户。\n这些来自学术界与工业界的探索，不仅验证了以数据蒸馏和单步建模为代表的技术路径的可行性，也逐步形成了「学术突破引领方向、工程创新驱动落地」的良性循环，共同推动全球 AI 气象预报向着更精准、更高效、更普惠的方向持续发展。\n参考链接：\n1.https://climate.uchicago.edu/entities/aice-ai-for-climate/\n内容中包含的图片若涉及版权问题，请及时与我们联系删除",
      "article_url": "https://hub.baai.ac.cn/view/51651",
      "publish_time": 1767613740,
      "publish_date": "2026-01-05 19:49",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://mp.weixin.qq.com/s?__biz=MzU3NTQ2NDIyOQ==&mid=2247519745&idx=1&sn=dcb8b12450f0cbdc32ae5264d442c544&scene=21#wechat_redirect\", \"https://www.nature.com/articles/s41586-025-08897-0\", \"https://climate.uchicago.edu/entities/aice-ai-for-climate/\"]",
      "add_ts": 1767655175,
      "last_modify_ts": 1767741666
    },
    {
      "id": 229,
      "article_id": "51644",
      "title": "DeepSeek后又一神作！清华校友出手，终结ResNet十年统治？",
      "description": "2026年AI架构革命拉开序幕，ResNet的“加法捷径”虽推动训练优化十年，但局限性显现。新年伊始，DeepSeek推出mHC技术，革新残差连接，引发广泛关注。紧随其后，普林斯顿与UCLA联合发布DDL方法，赋予神经网络“遗忘、重写与反转”能力，突破传统模型“只加不减”的瓶颈。与此同时，斯坦福Christophe教授团队亦贡献重要研究，推动深度网络向更高效、动态方向演进，预示着深度学习进入新纪元。",
      "content": "新智元报道\n编辑：桃子 好困\n【新智元导读】\n2026年架构革命的枪声已经打响！ResNet用十年证明了「加法捷径」能救训练，但也暴露了「只加不减」的天花板。DeepSeek新年王炸之后，普林斯顿和UCLA新作DDL让网络学会忘记、重写和反转。\n新年第一天，DeepSeek祭出大杀器——mHC，对「残差连接」做出了重大改进，引爆全网。\n紧接着，另一篇重磅研究诞生了！\n斯坦福著名教授Christopher Manning读完后直言，「2026年，将成为改进残差连接之年」。\n拓展阅读：\n刚刚，DeepSeek扔出大杀器，梁文锋署名！暴力优化AI架构\n这篇来自普林斯顿和UCLA新研究，提出了一个全新架构：Deep Delta Learning（DDL）。\n它不再把「捷径」（shortcut）当作固定的恒等映射，而让它本身也能学习并随数据变化。\n论文地址：https://github.com/yifanzhang-pro/deep-delta-learning/blob/master/Deep_Delta_Learning.pdf\n一个是mHC流形约束超连接，一个是DDL深度增量学习，几乎在同一时间，传递出一个强烈的信号：\n残差连接，正在进入一个必须被重新设计的时代。\n那么，这篇论文主要解决了什么问题？\nResNet用了十年「加法」\n终于被改写了\n2015年，ResNet（残差网络）横空出世后，「加法捷径（shortcut）」几乎成为了深度网络的默认配置。\n它解决了梯度消失的难题，撑起了现代深度学习的高楼。\nResNet通过残差学习，解决了深度神经网络训练中的核心难题——层数加深，AI性能不升反降。\nResNet为什么能训得这么深？\n因为它只做了一件极其「保守」的事，当深度网络什么都学不会的时候，至少别把输入弄坏。\n如今，无论是CNN、ViT，还是各种混合架构，那条「直接把输入加回去」的残差连接，成为了标配。\n这套架构设计稳定的同时，也带来了一个后果——\n神经网络几乎只会累加信息，却很难修改状态。\n经典ResNet核心更新公式非常简单：\n从动力系统角度看，它等价于对微分方程做一步前向欧拉离散。\n这意味着，对应的线性算子所有特征方向的特征值都是+1，网络只能「平移」状态，而不能反转、选择性遗忘。\n换句话说，旧特征很难被彻底清除，中间表示几乎不会被「反转」，深度网络在表达复杂动态时，显得有些笨重。\n如果「捷径」永远只是恒等映射，深度神经网络不够灵活，本质上只能「加法叠加」。\n来自普林斯顿和UCLA的最新论文，第一次系统性提出——\n这条「捷径」，其实限制了深度神经网络的想象力。\n此外，近期一些研究还指出，缺乏负特征值，是深度网络建模能力的隐形天花板。\n让深度网络学会「忘记」\n如果允许「捷径」本身可以被学习，可以选择性遗忘，甚至可以反转某些特征，会发生什么？\nDDL给出的答案是：用一个rank-1的线性算子，替代固定的identity shortcut。\n简单来说，DDL把ResNet的「固定加法捷径」，升级成了一个可控的状态更新机制。\n其核心变化只有一个——\n每一层不再只是加新东西，而会先决定：要不要保留旧状态。\n在这个全新架构中，引入了一个非常关键的标量β，这个数值决定了当前层如何对待已有特征。\n增量残差块\nDDL不再把隐藏状态，看成一个向量，而是一个矩阵\n这个设计，让网络状态具备了「记忆矩阵」的含义，也为后续的Delta Rule的对齐埋下了伏笔。\n其核心更新公式如下所示：\n而DDL真正的关键所在，是Delta Operator，让「捷径」不再是I，而是\n这是一个rank-1 的对称线性算子，其谱结构异常简单。即d−1个特征值恒为1，只有一个特征值是1−β。\n换句话说，一个标量β，就能精确控制某个特征方向的命运。\nDDL将三种几何行为，统一在一个模块中，以下当β ∈ [0, 2]时，不同情况——\n当β接近0时，DDL什么都不做\n这一层几乎被跳过，DDL的行为和ResNet完全一致，非常适合深层网络的稳定训练。\n当β接近1时，DDL会先忘掉，再写入\n这时，网络会主动「清空」某个特征方向，再写入新的内容，类似一次精准的状态重置。\n这也恰恰是，传统ResNet很难做到的事。\n当β接近2时，DDL就会实现特征反转\n某些特征会被直接「翻转符号」，深度网络第一次具备了「反向表达」的能力，这对建模振荡、对立关系非常关键。\n值得注意的是，它还出现了负特征值，这是普通残差网络几乎不可能产生的行为。\n目前，论文主要提出了DDL核心方法，作者透露实验部分即将更新。\n残差网络，2.0时代\n为什么这一方法的提出，非常重要？\n过去十年，传统残差网络的一个隐患是：信息只加不减，噪声会一路累积。\nDDL明确引入了忘记、重写、反转，让网络可以主动清理无用特征，重构中间表示，让建模成为非单调动态过程。\n神经网络可以自己决定，如何处理输入的信息。\nDDL不会推翻ResNet，当门控（gate）关闭时，它就是普通残差网络，当它完全打开时，便进入了全新的表达空间。\nResNet让深度学习进入了「可规模化时代」，而DDL提出的是下一步——\n让深度神经网络不仅稳定，而且具备真正的状态操控能力。\n也许多年后回头看，残差网络真正的进化，不仅仅是更深，还会改自己。\n最后的最后，我们让ChatGPT分别总结下DDL和mHC的核心贡献：\n一位网友对这两种革命性架构的亮点总结：\n这一切，只说明了一件事：残差连接，真正被当成「可设计对象」来认真对待。\n这就像是一个「时代切换」的信号，过去模型变强=更大+更深+更多参数，现在「模型变强=更合理的结构约束」。\n作者介绍\nYifan Zhang\nYifan Zhang\n是普林斯顿大学的博士生，也是普林斯顿AI实验室的Fellow，师从Mengdi Wang教授、姚期智教授和Quanquan Gu教授。\n此前，他获得了清华大学交叉信息研究院计算机科学硕士学位并成为博士候选人；本科毕业于北京大学元培学院，获数学与计算机科学理学学士学位。\n个人研究重点是：构建兼具高扩展性和高性能的LLM及多模态基础模型。\nYifeng Liu\nYifeng Liu是加州大学洛杉矶分校的计算机博士，本科毕业于清华信息科学与技术学院，姚班出身。\nMengdi Wang\nMengdi Wang是普林斯顿大学电气与计算机工程系以及统计与机器学习中心的副教授。\n她曾获得了MIT电气工程与计算机科学博士学位，在此之前，她获得了清华大学自动化系学士学位。\n个人研究方向包括机器学习、强化学习、生成式AI、AI for science以及智能系统应用。\nQuanquan Gu\nQuanquan Gu是UCLA计算机科学系的副教授，同时领导UCLA通用人工智能实验室。\n他曾获得伊利诺伊大学厄巴纳-香槟分校计算机科学博士学位，分别于2007年和2010年获得了清华大学学士和硕士学位。\n个人研究方向是人工智能与机器学习，重点包括非凸优化、深度学习、强化学习、LLM以及深度生成模型。\n参考资料：\nhttps://x.com/chrmanning/status/2006786935059263906\nhttps://x.com/yifan_zhang_/status/2006674032549310782?s=20\nhttps://github.com/yifanzhang-pro/deep-delta-learning/blob/master/Deep_Delta_Learning.pdf\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659938&idx=1&sn=e5c83df23866eebc14f74fce60b0ecf2&chksm=f0af0ef9289cb073571d355520b5172f5d0a233a88533bc0cd5b512f49c3c84b63a5a5ecf383&scene=0&xtrack=1#rd",
      "publish_time": 1767596040,
      "publish_date": "2026-01-05 14:54",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/yifanzhang-pro/deep-delta-learning/blob/master/Deep_Delta_Learning.pdf\", \"https://x.com/chrmanning/status/2006786935059263906\", \"https://x.com/yifan_zhang_/status/2006674032549310782?s=20\"]",
      "add_ts": 1767655205,
      "last_modify_ts": 1767741687
    },
    {
      "id": 231,
      "article_id": "51642",
      "title": "机器人也怕疼！港城突破性电子皮肤：主动痛觉 + 损伤自检双buff拉满",
      "description": "香港城市大学团队研发出新型神经形态电子皮肤（NRE-skin），可让机器人感知“疼痛”。该皮肤模仿人类神经系统，采用分层架构，在皮肤内部完成触觉信号的初步处理与脉冲编码，无需依赖中央处理器。这一突破提升了机器人对触觉刺激的响应速度与智能化水平，为未来人机交互、服务机器人等领域带来重要应用前景。",
      "content": "henry 发自 凹非寺\n量子位 | 公众号 QbitAI\n这下，你打人形机器人，它真的会「疼」了。\n来自香港城市大学的研究团队提出了一种全新的\n神经形态机器人电子皮肤（neuromorphic RE-skin，NRE-skin）\n。\nNRE-skin通过模仿人类神经系统，利用分层（Hierarchical）的神经形态架构，让触觉信号不再需要传到中央处理器，而是在皮肤内部就完成了初步处理与脉冲编码。\n基于这一仿生设计，NRE-skin同时实现了三项关键能力：\n高分辨率触觉感知\n：高效采集并编码精确的压力和位置信息。\n主动保护机制\n：具备局部反射机制，能够进行主动疼痛感知与损伤检测。\n维护高效性\n：支持快速更换的模块化快拆结构。\n网友表示这种复杂而精细的触觉感知，将会为机器人领域带来一次巨大的跃迁。\n而这一研究也无疑会为后续的触觉反馈算法和硬件设计提供新的思路。\n接下来我们具体来看。\n把触觉转成“神经脉冲”\n相比于以往的电子皮肤，NRE-skin没有继续沿用传统电子皮肤的“模拟信号采集”思路，而是模拟人类，直接把触觉转译成神经元式的脉冲信号。\n在生物系统中，感觉信号经历的是一个分级处理过程：刺激由末梢神经的\n局部“感受野”\n捕获并编码，再通过神经纤维层层递进、逐渐聚焦，最终形成完整的感觉信息传导至大脑。\nNRE-skin遵循这一思路，在硬件层面实现了“传感器即神经元”的设计：它将每个压力传感器直接与一个微型振荡电路相集成。\n当皮肤感知压力时，传感器的电阻变化会即时调控振荡电路，导致其输出的脉冲信号频率发生改变。\n具体而言，压力越大，脉冲发射得越密集，以此完成压力强度到脉冲频率编码的直接转译。\n更巧妙的是，为了精确定位，每个传感器被赋予了一组独特的无源元件（电阻R和电容C）作为其“位置指纹”。\n这些元件的配置使得每个位置发出的脉冲，在形状、宽度或幅度上都具有独一无二的特征。\n由此，NRE-skin通过这种“频率-强度，特征-位置”的编码方式，将所有复杂的触觉信息高效地汇聚到单一传输通道中。\n分层（Hierarchical）处理\n在将触觉信息编码为脉冲信号后，NRE-skin借鉴人类皮肤的分层处理，设计了四层结构（封装层、传感层、电路层、基底层） 。\n而且还在电路层面建立了分层的、神经状的感受野结构，以实现信号的渐进降维和数据流简化。\n在生物系统中，人类皮肤的功能由精密的四层结构支撑：角质层、表皮层、真皮层和皮下组织。\n这些层级中蕴含着高度复杂的感觉系统，分布于真皮和表皮的多种机械感受器与分层的神经感受野共同构成了信息采集与处理的一体化网络。\n该网络将触觉刺激分为两类：\n基础感知（如剧烈疼痛）通过脊髓反射弧快速处理，触发无需大脑参与的局部自动反应（如缩回）。\n复杂感知（如刺激强度的精确定位和损伤识别）则会被逐级传递至大脑皮层，进行更深层次的分析和决策。\n与之类似，NRE-skin也采用了类似的四层结构，将感觉信号从外周逐级传递至更高层级的处理中心，实现了从粗到细的定位与筛选：\n封装层：模拟角质层，提供表面的机械保护和整体防护。\n基底层：模拟皮下组织，提供缓冲，吸收外力冲击，并作为机械支撑。\n传感层：对应人类的机械感受器,负责感知外部刺激（如压力），并将其转换为电信号。\n电路层：对应人类的信号传导神经，NRE-skin的核心。负责脉冲编码、信号处理、局部反射决策。\n在四层结构中，电路层是NRE-skin 的核心处理模块。\n它位于传感层之下，负责将压力刺激转换为脉冲序列，并通过一套\n模拟生物感觉处理机制的人工感受野网络对信号进行初步处理，实现渐进降维和数据流简化\n。\n电路层被进一步细分为五个关键功能区域：\n疼痛中心：用于疼痛信号评估、\n特征中心：用于识别信号来源的皮肤模块\n信号整合器：用于合并各路输出\n脉冲发生器：用于生成脉冲序列\n和连接器（用于与外部皮肤模块连接\n在此基础上，研究人员进一步集成了两大高级功能：\n主动疼痛感知与局部反射\nNRE-skin具备基于疼痛阈值触发的局部反射机制。电路层面的“疼痛中心”实时监测脉冲频率所反映的压力强度。\n一旦压力超过阈值，系统会绕过中央处理器，直接触发类似脊髓反射弧的机制，实现毫秒级的即时保护动作（如缩回），大幅提升机器人的安全响应能力。\n损伤自检与模块化维护\nNRE-skin 通过检测传感器周期性产生的\n“活脉冲”状态，实现了皮肤损伤的精确自检和定位\n。\n一旦脉冲停止，即意味着皮肤受损。结合其模块化快拆设计，这极大地简化了受损皮肤单元的快速更换与维护流程。\n总体看来，NRE-skin 不仅是一种更高效的电子皮肤，更是一种具备自主感知、实时判断和自我保护机制的仿生智能系统，为未来制造更安全、更具人性化的仿人机器人奠定了坚实的工程基础。\n这篇论文的第一作者是来自香港城市大学的高育育。\n他目前是港城大学的博士后，研究方向包括触觉感知（Tactile Sensing）和柔性电子（Flexible Electronics）。\n他本科和硕士都毕业于西南交通大学，博士毕业于香港城市大学。\n参考链接\n[1]https://arstechnica.com/science/2025/12/researchers-make-neuromorphic-artificial-skin-for-robots/?comments-page=1\n#comments\n[2]https://www.pnas.org/doi/10.1073/pnas.2520922122\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n专属AI产品从业者的\n实名社群\n，只聊AI产品\n最落地的真问题\n扫码添加小助手，发送\n「姓名+公司+职位」\n申请入群～\n进群后，你将直接获得：\n👉 最新最专业的AI产品信息及分析 🔍\n👉\n不定期发放的热门产品内测码 🔥\n👉\n内部专属内容与专业讨论 👂\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859838&idx=2&sn=63479ba548ae3f19af80cbb5dd084c98&chksm=e935c92a13f1d1a68534262c5dbbe804c2d02652d63149c2436bcf6be6f558b176d4fe064174&scene=0&xtrack=1#rd",
      "publish_time": 1767590160,
      "publish_date": "2026-01-05 13:16",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arstechnica.com/science/2025/12/researchers-make-neuromorphic-artificial-skin-for-robots/?comments-page=1\", \"https://www.pnas.org/doi/10.1073/pnas.2520922122\"]",
      "add_ts": 1767655215,
      "last_modify_ts": 1767741693
    },
    {
      "id": 235,
      "article_id": "51638",
      "title": "英伟达仍是王者！GB200贵一倍却暴省15倍，AMD输得彻底",
      "description": "AI推理竞争正转向成本效益，而非单纯算力比拼。最新报告显示，英伟达GB200 NVL72吞吐量达AMD MI350X的28倍，且在高交互场景下，DeepSeek R1每Token成本可低至15倍。性能优势结合高效能设计，使GB200在“每美元智能输出”指标上领先，标志着AI推理进入以单位成本效能为核心的新阶段。",
      "content": "新智元报道\n编辑：桃子\n【新智元导读】\nAI推理游戏规则，正悄然改变。一份最新报告揭示了关键转折：如今决定胜负的，不再是单纯的芯片性能或GPU数量，而是 「每一美元能输出多少智能」。\nAI推理，现已不只看算力硬指标了！\nSignal65一份最新报告中，英伟达GB200 NVL72是AMD MI350X吞吐量28倍。\n而且，在高交互场景在，DeepSeek R1每Token成本还能低到15倍。\nGB200每小时单价大概是贵一倍左右，但这根本不重要。因为机柜级NVLink互联+软件调度能力，彻底改变了成本结构。\n顶级投资人Ben Pouladian称，「目前的关键不再是算力或GPU数量，而是\n每一美元能买到多少智能输出\n」。\n如今，英伟达仍是王者。其他竞争对手根本做不到这种交互水平，这就是护城河。\n最关键的是，这还没有集成200亿刀买入Groq的推理能力。\n这里，再mark下老黄\n至理名言——\nThe more you buy, the more you save！\nAI推理重心：一美元输出多少智能？\n这篇万字报告，探索了从稠密模型（Dense）到混合专家模型（MoE）推理背后的一些本质现象。\n传统的「稠密模型」架构要求：在生成每个Token时都激活模型里的全部参数。\n这就意味着：模型越大，运行越慢、成本越高，同时还会带来相应的内存需求增长等问题。\nMoE架构，正是为了释放更高水平的智能而生——在每个Token上只激活最相关的「专家」。\n搂一眼Artificial Analysis排行榜即可发现，全球TOP 10开源LLM，全部都是MoE推理模型。\n它们会在推理阶段额外「加算力」来提高准确性：\nLLM不会立刻吐出答案，而是先生成中间的推理Token，再输出，相当于先把请求和解法「想一遍」。\n前16名里有12个是MoE模型\n这些推理Token往往远多于最终回复，而且可能完全不会展示出来。能否既快又便宜地生成Token，对推理部署来说就变得至关重要。\n那么，MoE方法的主要约束在哪里？\n一个核心限制在于「通信瓶颈」。\n当不同专家分布在多块GPU上时，任何GPU之间通信的延迟，都会让GPU空闲等待数据。\nOpenRouter一份近期报告，超50%的Token会被路由到推理模型上\n这些「空转时间」（idle time）代表着被浪费的、低效的算力，并且会直接体现在服务提供商的成本底线上。\n当评估AI基础设施的「经济性」时，一般会聚焦在三个方面：\n性能（吞吐量与交互性）\n能效（在既定功耗预算下，可生成的Token数）\n总体拥有成本（通常以Token/每百万的成本衡量）\n基于公开可用的基准测试数据，Signal65对不同LLM架构下AI基础设施方案进行了对比分析。\n分析中，团队采用第三方基准测试所提供的性能数据，来估算相对的Token经济性。\n具体来说，他们选取了B200、GB200 NVL72，以及AMD MI355X部分结果，用以对比它们在不同模型场景下的真实性能表现及相应的TCO估算。\n结果显示，在稠密架构以及较小规模的MoE中，B200性能优于AMD MI355X。\n当模型扩展到像DeepSeek-R1这样需跨越单节点的前沿级规模时，GB200 NVL72性能最高可达到MI355X的28倍。\n在高交互性的推理工作负载中，NVL72的单位Token成本最低，可降至其他方案的约1/15。\n尽管GB200 NVL72的单GPU小时价格几乎是这些竞争平台的2倍，但其机架级能力——从NVLink高速互连，到覆盖72块GPU的软件编排——共同推动了这种显著更优的单位经济性。\n价值评估的重心，正在从单纯的原始FLOPs，转向「每一美元所获得的总体智能」。\n这一结论非常明确：\n随着MoE模型和推理工作负载带来的复杂性与规模持续上升，行业已无法仅依赖芯片层面的性能提升。\n能够在系统层面实现峰值性能的端到端平台设计，已经成为实现低成本、高响应AI服务的关键杠杆。\n「稠密模型」推理，英伟达领先\nSignal65选择了Llama 3.3 70B作为稠密模型的性能基准，结果如下所示：\n帕累托曲线清晰显示出，HGX B200-TRT方案在整个吞吐量与交互性区间内，都具备持续的性能优势。\n具体到基线交互性水平，B200的性能大约是MI355X的1.8倍，这为交互式应用部署，以及更高的单GPU并发密度提供了显著余量。\n再来看，当交互性提升至110 tokens/sec/user时，这一优势进一步被放大：B200吞吐量超过MI355X的6倍。\n整体上，在Llama 3.3 70B测试中，AMD MI355X在单位成本性能方面确实具备一定吸引力。\n但这种优势并不能代表更现代的推理技术栈，尤其是以MoE架构和高强度推理工作负载构建的系统。\nMoE推理，英伟达领先\n那么，在MoE架构上，英伟达和AMD表现又如何？\n中等规模推理：gpt-oss-120B\nSignal65认为，OpenAI gpt-oss-120B是理解MoE部署特性的一个理想「桥梁案例」。\n它足够大，可以把MoE的复杂性暴露出来；\n但规模又没有大到离谱，仍然是很多团队能现实部署并调优的范围。\n它处在一个很有用的中间地带：介于稠密的70B级模型，与市场正在快速转向的、更前沿的推理型MoE架构之间。\n在10月下旬数据里，当目标是100 tokens/sec/user时，B200大约比MI355X快1.4倍；\n但当目标提高到250 tokens/sec/user时，差距会扩大到约3.5倍，说明越追求「更快的交互」，平台差异越容易被放大。\n不过，12月上旬的数据则呈现出不同局面。\n得益于软件优化，两边平台的绝对性能都明显提升：英伟达单GPU峰值吞吐从大约7,000 tokens/sec提升到超过14,000；AMD也从约6,000提升到大约8,500。\n前沿推理：DeepSeek-R1\n在DeepSeek-R1推理上，测试结果正如开篇所介绍那样，英伟达GB200 NVL72大幅领先。\n更多数据如下图所示：\n基准测试数据展示了一个被重塑的格局：\nGB200 NVL72让「超过8块GPU的张量并行配置」也能进入帕累托前沿，达到单节点平台根本无法匹敌的性能。\n在25 tokens/sec/user交互性目标下，GB200 NVL72单GPU性能大约是H200的10倍，并且超过MI325X单GPU性能的16倍。\n这类性能差距，正是能为AI服务提供商带来「断崖式」TCO改善的那种差距。\n当交互性目标提高到60 tokens/sec/user时，GB200 NVL72相比H200带来了超24倍的代际提升，同时也接近MI355X的11.5倍性能。\n在同样25 tokens/sec/user下，GB200 NVL72单GPU性能大约是B200的2倍、是MI355X的5.9倍；\n而到60 tokens/sec/user时，这些优势进一步扩大：相对单节点B200达到5.3倍、相对MI355X达到11.5倍。\nGPU越贵，token成本越低\n英伟达从Hopper过渡到Blackwell，并推出GB200 NVL72时，不仅提升了每GPU算力、内存带宽以及NVLink互连带宽，还对底层系统架构做了重新设计。\n从8-GPU风冷HGX服务器转向全液冷的机架级系统，并把72块GPU连接在同一个域内，系统成本和复杂度显然都上升了。\n据CoreWeave公布的目录价，按单GPU口径，GB200 NVL72价格大约比H200贵1.7倍。\n不过，每一代新技术的目标之一，就是压低「每Token成本」。\n对推理而言，具体就是：实际交付的Token吞吐提升幅度，要超过底层基础设施成本的提升幅度。\n而从公开的性能数据来看，这正是GB200 NVL72相比Hopper所呈现出的结果。\nSignal65把本次的tokenomics（Token经济学）分析，锚定在前文建立的DeepSeek-R1性能差距上：\n在25 tokens/sec/user时，GB200 NVL72单GPU性能大约是H200的10倍；\n在更高的交互点位上，这个差距会更大（24倍）。\n下表总结了成本归一化，以及由此得到的「每美元性能」计算：\n这些结果一开始可能有点反直觉：更「贵」的GPU反而更省钱——因为它带来的性能提升远大于价格差异，使得它能以更低成本生成Token。\n与AMD相比，英伟达系统在推理token成本上的一些数据对比：\n按单GPU口径，MI355X价格大约只有GB200 NVL72配置的一半；\n但由于GB200 NVL72单GPU性能优势从低端接近6倍，到高交互性时高达28倍不等，英伟达仍然能提供最高15倍的每美元性能优势。\n换句话说，英伟达能实现相对每Token成本仅为竞争对手的1/15。\n结论\n前沿AI模型的未来，会是更大、更复杂的MoE。\n随着模型更深地走向MoE与推理架构，最终效果将不再只取决于原始GPU性能或内存容量。\n平台级设计会成为决定性因素——包括互连与通信效率、多节点扩展特性、软件栈成熟度、生态支持与编排能力，以及在并发与混合负载下维持高利用率的能力。\n从当前趋势看，来自OpenAI、Meta、Anthropic等前沿公司的旗舰模型，很可能会继续沿着MoE与推理方向演进。\n如果这一轨迹成立，英伟达将维持关键的性能与经济性优势。\n谷歌TPU这类架构也提供机架级方案，但它们对非自家模型的适用性与性能表现仍不明确。\n本文记录的性能差异，能够直接转化为可量化的商业结果：\n在既定交互性阈值下，每部署一块GPU能服务更多用户，就能降低每个「有用Token」的生成成本，提高每机架的收入潜力（通过规模化交付更高价值的体验），最终AI企业和部署AI的企业获得更好的TCO。\n一个具体例子足以说明量级：当一个平台在某个交互性目标下，能提供28倍的单GPU吞吐提升时，它可以在不需要线性扩大硬件规模的情况下，解锁新的产品档位以及更复杂的功能。\n这就是AI推理「经济学」，而它会更偏向那些从底层就为MoE与推理时代而设计的平台。\n参考资料：\nhttps://x.com/kimmonismus/status/2005753458188771768\nhttps://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660003&idx=3&sn=9327273acd3c48156b3155cfb0c63d79&chksm=f08a1890a76437c458a913c45b73dcd433851a17ab3e68faa6d72836b61ba643d06056fe28b2&scene=0&xtrack=1#rd",
      "publish_time": 1767586920,
      "publish_date": "2026-01-05 12:22",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/kimmonismus/status/2005753458188771768\", \"https://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/\"]",
      "add_ts": 1767655240,
      "last_modify_ts": 1767741709
    },
    {
      "id": 238,
      "article_id": "51635",
      "title": "",
      "description": "本期报告由香港大学范天宇分享，探讨AI-Trader在实时金融市场中的应用。尽管强化学习使Agent在静态环境中表现出近似人类专家的推理与工具使用能力，但在动态金融环境中，其面临信息实时整合、快速适应市场变化等挑战。报告聚焦Agent如何应对不确定性、延迟反馈及多变市场结构，评估其决策效率与稳定性，为构建更智能、适应性强的交易系统提供理论支持与实践方向。",
      "content": ":\n，\n.\nVideo\nMini Program\nLike\n，轻点两下取消赞\nWow\n，轻点两下取消在看",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU4MjkzNDMwNg==&mid=2247491577&idx=2&sn=2dc5b6b867016f8d6d88b491e63072c7&chksm=fc57a7f7c4bfdd89d6a1d794d4a6b1c53f7c463165631905acd0b1716e6d1b58fdede691b95c&scene=0&xtrack=1#rd",
      "publish_time": 1767583800,
      "publish_date": "2026-01-05 11:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767655256,
      "last_modify_ts": 1767741718
    },
    {
      "id": 240,
      "article_id": "51633",
      "title": "腾讯AI Lab &马里兰大学，首个用于复杂现实世界推理任务的并行思维强化学习框架",
      "description": "报告介绍了“并行思维”方法，通过同时探索多条推理路径提升大语言模型的推理能力。目前该方法主要依赖合成数据上的监督微调，存在过度模仿教师模型、缺乏自主探索与泛化的问题。马里兰大学郑童分享了基于强化学习的Parallel-R1框架，旨在通过奖励机制引导模型自主发现高效推理路径，减少对教师行为的依赖，增强泛化能力，推动大模型实现真正意义上的并行思考与自我优化。",
      "content": "报告主题：\nParallel-R1：基于强化学习实现大语言模型并行思考\n报告日期：\n01\n月09日（周五）10:30-11:30\n报告要点：\n本期报告将由马里兰大学郑童进行分享。\n并行思维作为一种新方法，通过同时探索多个推理路径来增强大语言模型（LLMs）的推理能力。然而，目前主要依赖于在合成数据上的监督微调（SFT）来激活这种能力，这种方式鼓励的是强制模仿教师模型的行为，而非探索和泛化能力的培养，因此通过训练实现并行思维仍具有挑战性。与现有方法不同，我们提出了\\textbf{Parallel-R1}，这是\n首个用于复杂现实世界推理任务的并行思维强化学习（RL）框架\n。我们的框架采用了一种渐进式的课程学习策略，明确解决了使用强化学习训练并行思维时面临的冷启动问题。我们首先在较简单任务生成的提示轨迹上进行监督微调，以初步掌握并行思维能力，随后过渡到强化学习阶段，在更具挑战性的问题上进一步探索和拓展这一能力。\n在包括MATH、AMC23和AIME在内的多个数学基准测试中进行的实验表明，Parallel-R1成功地培养了并行思维能力，相比直接在复杂任务上使用强化学习训练的顺序思维模型，准确率提升了8.4%。进一步分析显示，模型的思维行为发生了明显转变：在训练初期，并行思维主要作为探索策略被使用；而在后期，则更多地用于从多个角度进行验证。最重要的是，我们将并行思维验证为一种\\textbf{中期训练的探索支架}，这种临时性的探索阶段在强化学习后期释放出了更高的性能上限，在AIME25上相比基线模型提升了42.9%。我们的模型、数据和代码将开源，地址为 https://github.com/zhengkid/Parallel-R1。\n相关论文：\nParallel-R1: Towards Parallel Thinking via Reinforcement Learning\n报告嘉宾：\n郑童，美国马里兰大学博士生，导师为 Heng Huang。曾在腾讯Ai lab 西雅图实习，他的研究方向聚焦大语言模型效率，重点关注高效模型架构、解码算法与新一代推理范式。\n扫码报名\n更多热门报告",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU4MjkzNDMwNg==&mid=2247491577&idx=3&sn=469c3df86cec06a69645c510acb9f7f4&chksm=fcb4f4e9de251f0ea33e24b2ed23009e6f0e6b5adf39e1f5d80c0fa9b5376b4e6f3b3e65bc48&scene=0&xtrack=1#rd",
      "publish_time": 1767583320,
      "publish_date": "2026-01-05 11:22",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://hub.baai.ac.cn/paper/9829cd45-8911-475c-bc7c-44dc46f37592\", \"https://event.baai.ac.cn/activities/963\", \"https://event.baai.ac.cn/activities/965\", \"https://github.com/zhengkid/Parallel-R1\"]",
      "add_ts": 1767655271,
      "last_modify_ts": 1767741729
    },
    {
      "id": 241,
      "article_id": "51632",
      "title": "30天没写一行代码，他却赚了10亿美金！",
      "description": "工程师以“副业”开发的Claude Code，仅用6个月实现10亿美元收入，实现AI 100%编写代码。该工具不仅颠覆传统编程模式，更引发对工作方式的变革，推动“四天工作制”成为可能，展现了个体创造力在AI时代的巨大潜力与行业冲击。",
      "content": "新智元报道\n编辑：Aeneas\n【新智元导读】\n6个月，10亿美元收入，这就是Claude Code创下的奇迹。就在刚刚，自曝靠Claude Code让AI 100%写代码的工程师，大方揭秘了自己的配置！众多大佬预言：四天工作制真来了。\n如果有一个\nAI\n，可以帮你写100%的代码，你还会通宵加班吗？\n更夸张的是，这个工具不是大厂项目立项，不是融资砸钱堆出来的，而是\n一个工程师的「副业」\n。\n6个月，从个人项目起步，做到了\n10亿美元\nARR\n（\n年度经常性收入\n）\n，直接成为程序员圈的爆款现象级神器。\n你肯定已经猜到了，它就是Claude Code。\n而Claude Code之父已经承认，过去30天里，自己100%的代码，都是靠这个AI写的！\n作为Claude Code项目的开发负责人，Boris Cherny可以说是Claude Code技术的灵魂人物。他曾被Cursor开发商 Anysphere重金挖走，然后又被Anthropic闪电速度挖回。\n上线半年，收入破10亿\n就在25年12月初，AI编程圈炸锅了。\nAnthropic\n宣布，旗下AI编码神器\nClaude Code\n上线仅\n6个月，\n就创造了近\n10亿美元年化营收\n，堪称AI编程类工具史上最亮眼纪录，直接一条腿跑赢很多大厂半年成绩！\n同时，它还完成了令人咋舌的\n首笔战略收购——吞下开发者神器Bun。这就意味着，\nAI\n编码工具已经进入了中后台的基础设施时代，企业的付费市场已经打开！\nClaude Code的神奇增长速度，背后有一个关键秘密： 它不是简单的「代码补全器」，而是一个\nAI\n数字「码农同事」。\n一般的AI工具最多也就是补代码片段、解释bug，但Claude Code的目标是：能理解整个项目上下文，自动设计、生成、测试代码，并且与真实工作流程深度融合！\n这就意味着：无论是写功能、调试、打包，AI都能自动完成，可以直接在终端/IDE 里一条命令「召唤」，而且几乎不需要手工写冗余代码。\n可以说，它已经是一个能和你一起独立写项目的\nAI\n工程师\n。\n这也就是为什么，上线后仅\n6个月\n，Claude Code单靠企业付费订阅和API商业版，就让其年化营收跑到了\n快10亿美元\n。\n这个数字，比很多\n传统软件老牌公司的全年营收还要高！\nClaude Code之父，手把手亲授\n自从Claude Code之父Boris Cherny承认自己的代码100%由Claude Code写成，AI社区大为震惊：这是怎么做到的？\n就在刚刚，Boris大方揭秘了自己的配置！\n出乎意料的是，这个配置竟然如此简单。\n可以说，Claude Code开箱即用，效果很好，所以Boris Cherny很少对它进行自定义设置。\n具体步骤如下。\n1.在终端中并行运行5个Claude。\n2.在Claude.ai/code上，也同时运行5-10个Claude。\n通过终端编码时，他会经常会将本地会话交给网络，或者手动在Chrome中启动会话，有时还会来回传送。\n每天早上和白天，他都会从自己手机上（通过Claude iOS应用）启动几个会话，然后会检查它们。\n然后，他会用Claude Opus 4.5来思考。可以说，这是他用过最好的编程模型，虽然它比Sonnet更大、更慢，但是因为它需要的引导更少，在工具使用上也更好，所以在小模型中，它几乎总是最快的。\nBoris的团队会共享一个CLAUDE.md用于 Claude Code仓库。他们会将其提交到git，整个团队每周贡献多次。\n每次他们看到Claude做错事时，就会将其添加到CLAUDE.md ，这样Claude就知道，下次不能这样。\n代码审查期间，他常常在同事的PR上标记@.claude，从而将某些内容添加到CLAUDE.md，作为PR的一部分。他们会使用Claude Code Github action (/install-github-action) ，来实现这一点。\n大多数会话以Plan模式启动。如果目标是写一个Pull Request，他就会使用Plan模式，并与Claude来回沟通，直到满意为止。\n然后，他会切换到自动接受编辑模式，Claude通常可以一次性完成。\n一个好的计划，真的非常重要。\nBoris说，自己会使用斜杠命令来处理每天多次执行的「内循环」工作流。这样一来，就不用一次次重复写提示词，而且\nClaude也可以直接使用这些工作流\n。\n例如，Claude和他每天都会使用/commit-push-pr这个斜杠命令数十次。\n这个命令里会直接内嵌bash脚本，提前计算好\ngit status\n以及一些其他信息，这样命令执行得更快，也避免了和模型之间来回确认、反复沟通。\nBoris会经常用到几个\n子代理（subagents）。\n比如\ncode-simplifier\n，在Claude完成代码后负责对代码进行简化；\nverify-app\n则有一套非常详细的说明，用来对Claude Code进行端到端测试，等等。\n和斜杠命令类似，Boris把子代理看作是对\n大多数\nPR\n中最常见工作流的自动化封装\n，会把那些重复、固定的流程交给它们。\n他们团队会经常使用\nPostToolUse hook，\n来对Claude生成的代码进行格式化。\nClaude通常一开始就能生成格式很规范的代码，而这个hook主要负责补上\n最后那10% 的细节\n，从而避免后续在CI中因为格式问题而报错。\n他不会使用\n--dangerously-skip-permissions\n。相反，他会通过\n/permissions\n预先放行那些能确认在当前环境中是安全的常用bash命令，从而避免频繁弹出不必要的权限提示。\nBoris表示，Claude Code已经替他使用所有他的工具。\n它经常会搜索信息、通过MCP服务器在Slack上发消息，还会用\nbq\nCLI 运行BigQuery 查询来回答分析类问题，或者从Sentry拉取错误日志等等。\n对于运行时间特别长的任务，他通常会采用以下几种方式之一：\n（a）在任务完成后，提示Claude使用一个后台agent来校验自己的工作； （b）使用agent的\nStop hook\n，用更确定、可控的方式来完成校验；\n（c）或者使用\nralph-wiggum插件。\n最后，一个很重要的建议就是：\n想要把Claude Code的效果发挥到极致，最重要的一点就是——给Claude一个验证自己工作的方式。\n一旦Claude拥有这样的反馈闭环，最终产出的质量通常能提升\n2～3倍\n。\nBoris的X发布后，大量专业人士在帖子下方表示赞叹，而且提出了不少细节问题。\n2026，人类离「只工作四天」竟如此之近？\n说到这里，就不得不提最近大佬们对于人类未来工作的预测了。\n2026年伊始，一场关于\n「未来工作模式革命」\n的大讨论正在兴起。\n曾被视为理想主义者的「四天工作制」，如今正被世界上最有影响力的商业领袖们认真讨论，而且越来越多人认为：\n这不再是乌托邦，而是很有可能成为现实！\n比尔盖茨认为，未来人类可能每周只需要工作2到3天。\n摩根大通的\nJamie Dimon\n预测，下一代人将活到100岁且没有癌症，每周仅需工作\n3.5天\n。\n黄仁勋认为，4天工作制是最有可能的。\n马斯克的预测则最为激进：他认为未来10到20年内，工作将变成可选项，未来将是\n「全民高收入」\n且没有贫困的世界。\n而且，这场变革并非空想。已经有多国开始试点四天工作制，结果显示，工作效率不降反升，人类员工压力降低，满意度上涨。\n然而，这场变革也不是毫无代价的。人们可能会被AI迅速替代，低技能的岗位转型压力巨大，而且失业风险和社会支持体系也需要改革。\n然而，技术进步从不会因为恐惧而停下脚步。\n可以肯定的是，我们正处在一个劳动方式被彻底改写的时代。\n参考资料：\nhttps://x.com/bcherny/status/2007179832300581177\nhttps://fortune.com/2026/01/02/four-day-workweek-possible-2026-business-leaders-jensen-huang-elon-musk-bill-gates-jamie-dimon/\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660003&idx=1&sn=da6f633164b1904b1a3a63da728af133&chksm=f041f389608d1680a5ea1b02225eec027790a8eb03f199f3fd71e6525db1221c3e76a0ebbe12&scene=0&xtrack=1#rd",
      "publish_time": 1767583320,
      "publish_date": "2026-01-05 11:22",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/bcherny/status/2007179832300581177\", \"https://fortune.com/2026/01/02/four-day-workweek-possible-2026-business-leaders-jensen-huang-elon-musk-bill-gates-jamie-dimon/\"]",
      "add_ts": 1767655276,
      "last_modify_ts": 1767741732
    },
    {
      "id": 244,
      "article_id": "51628",
      "title": "陶哲轩泼冷水：我不相信AGI！但又一数学难题被GPT-5.2 Pro攻克",
      "description": "陶哲轩指出当前AI虽具“通用狡猾”但难实现真正AGI，GPT-5.2 Pro虽攻克数学难题，仍属特定能力突破。LeCun再次强调现有路径无法通向AGI，质疑当前主流方法的根本局限。与此同时，Shane Legg预测未来或需更小、更高效的模型推动AGI发展。多方观点表明，尽管AI在特定任务上表现优异，但在通用智能层面仍存在本质瓶颈，需全新理论与架构突破。",
      "content": "新智元报道\n编辑：Aeneas\n【新智元导读】\n就在刚刚，陶哲轩po文揭秘：当前的AI无法实现真正的AGI，不过，他们倒是拥有一些有用的小聪明，或者可以说「通用狡猾」。\n而就在同时，又一多年数学难题被GPT-5.2 Pro攻克了。\n就在今天，即将离职Meta的LeCun再次给当前AI判死刑——这条路行不通，而且永远不会成功。\n前不久，谷歌DeepMind首席科学家Shane Legg给出预测：最小AGI有50%的可能性在2028年实现。\n业界都在讨论的AGI之争，陶哲轩是如何看待的？\n就在刚刚，陶哲轩po文明确了自己的态度——还不行。\n他认为，目前还无法实现AGI。\n我怀疑目前工具还无法实现真正意义上的「人工通用智能」。然而，我认为一种较弱但仍然非常有价值的「人工通用才智」，正在以各种方式成为现实。\n而他的观点，立马在网上引起了广泛讨论。\n网友们表示，陶哲轩这样聪明的人，都认为AGI并未实现，这样太令人绝望了——希望他是错的吧。\n陶哲轩：不是AGI，只是魔术师\n什么叫通用才智？\n陶哲轩是这样解释的。\n「通用才智」是指通过某种临时手段解决广泛复杂问题的能力。\n这些手段可能是随机的，也可能是暴力计算的成果；它们可能缺乏根基或容易出错；它们可能难以解释，也可能能追溯到AI训练数据中类似的技巧。\n因此，它们不能被视为任何真正「智能」的结果。\n然而，它们在实现日益广泛的任务时，可以拥有非同寻常的成功率，尤其是在结合严格的验证程序以过滤掉错误或不具前景的方法时，其规模已超出了单个人类所能达到的范围。\n可以理解为，这是一种「通用狡猾」AI。\n而这种「通用狡猾」AI，就会让人感觉非常匪夷所思。\n比如在有时候，这些技术非常实用，令人印象深刻，然而从根本上说，它却令人不满和失望。\nAI是「最强大脑」魔术师？\n想象这样一个场景：一位魔术师上台，凭空变出鸽子、猜中你选的牌、把水杯变成金鱼。全场掌声雷动，观众目瞪口呆。\n结果他平静自曝：「其实我袖子藏了十八个机关，桌下有暗格，牌是特制的，金鱼是提前藏好的。」掌声戛然而止。\n如今的AI，就像这位魔术师一样。\n它能写诗、编程、解数学题——但如果你问它：「你是怎么想到这个答案的？」\n它可能会诚实坦白：「我在训练数据里见过类似题目，概率上这个回答匹配度最高。」\n所以，这其实不是智能，而是基于海量数据的「聪明把戏」。\n「通用狡猾AI」，反而起了大作用\n对于这种「通用狡猾AI」，陶哲轩是怎么解释的。\n虽然聪明才智和智力在人类身上是某种程度上相关的特质，但对于AI工具（这些工具通常被优化以追求聪明才智）来说，它们却更加解耦，将当前一代这样的工具主要视为一个随机生成有时聪明，且往往有用的思想和输出的生成器，在尝试使用它们解决难题时，可能是一种更具生产性的视角。\n也就是说，智能≠聪明。\n对人来说，二者是同时存在的；但对于AI而言，所谓的「聪明」，也就是快速解决复杂问题，可以独立存在。\n当前AI的「聪明」，是随机的，暴力的，可错的，难解释的。\n最终，它并不是靠智慧取胜，而是靠「大规模试错与匹配」，就像用超级望远镜，在答案星海里捞最亮的几颗。\n当今的AI，并不是全知全能，然而这个「不够智能但足够聪明」的工具，却已经悄悄改变知识工作的每一个环节。\n对于陶哲轩的说法，网友们表示的确如此。\n对于目前的AI来说，看似便利但难以预测的思想，似乎是一种主要应用场景。\n可以说，陶哲轩所说的，就是目前AI能力「参差不齐的边界」。\n甚至评论区还出现了中文留言，认为目前的AI底层架构就决定了，即使投入无限多的算力，产出的东西也依然有边际。\n而在Reddit的帖子中，网友们也对此展开热议。\n有人对表示，自己非常尊重陶哲轩，但对他的部分观点表示反驳。\n有人说，他用「狡猾」或「巧妙」一词，来针对现代LLM缺乏系统性思维的缺点。\n目前，他或许是对的。不过，ChatGPT还只有3岁，如果要宣布所有LLM都有此局限，至少还应该再等待十年。\n又一数学难题被AI破解\n巧的是，就在陶哲轩发出这个论点不久，又有一道数学难题被AI破解了！\n滑铁卢大学计算机系的助理教授Kimon Fountoulakis激动发帖称，GPT-5.2刚刚解决了COLT 2022开放问题——\n使用标准加速梯度算法和互补性边界假设，证明加速L1正则化PageRank的运行时间复杂度。\n其中，所有证明都由GPT-5.2 Pro生成。算法总工作量的关键界限，则是使用 GPT-5.2 Pro、Aristotle和Antigravity上的Gemini 3 Pro (High) 组合完成了自动的形式化。\n多伦多大学的教授Daniel Litt也出来表示，GPT-5.2 Pro的确很强，它对于自己的代数几何和数论研究，都产生了巨大飞跃。\n悬赏8年难题，GPT-5.2用数学证明封神\n这道难题，已经困扰了教授8年。\n自2024年以来，每次OpenAI或谷歌发布一个新模型，他都会拿过来尝试一下。\n令人没想到的是，这一次，GPT-5.2竟然成功了！\n教授这样回忆道：这个开放性问题，我们尝试了三年，失败了；找博士生做，也失败了；问了多位顶尖学者，都说太难了。\n2022年，这道关于「加速L1正则化PageRank算法时间复杂度」的难题，被正式列为COLT国际顶级会议的开放问题之一，悬赏求解。\n谁也没想到，两年后，这道难倒无数学者的题目，竟被GPT-5.2悄然攻克。\n悬赏\n故事要从2016年说起。当时，教授在优化PageRank算法时发现，经典迭代软阈值算法在求解带L1正则的PageRank问题时，其运行时间竟然只与最终解的非零节点数有关，出奇地高\n一个很自然的追问随之而来：如果用上加速算法，比如在优化领域声名显赫的FISTA，会不会更快？\n理论上应该如此。但现实却泼了一盆冷水：FISTA在迭代过程中会「激活」大量本应为零的节点，虽然最终能收敛到正确的稀疏解，但中间过程却很铺张浪费。\n开始，教授尝试了三个月，想从理论上界定FISTA的总计算量，失败了。后来断断续续又试了几次，直到2021年，无论是教授最杰出的学生，还是几位大牛研究者，都对这个问题束手无策。\n团队决定，将这个难题公之于众。\n2022年，它被正式列为COLT的开放问题，向全球机器学习社区发起挑战。\n破局\n第一个成功的解法，出现在2023年。David Martínez-Rubio等人提出了一种新颖的加速算法，从完全不同的角度给出解答。\n然而，这个算法为了达到加速效果，需要在每一步求解一个昂贵的子问题，在实际应用中效率很低。\n直到GPT-5.2发布后，真正的转折点来了。\n这一次，GPT-5.2给出了完整的证明。\n而且令人震惊的是，它给出的恰恰是针对经典FISTA算法的证明。\n它揭示了在一种被称为「互补性边界」的合理假设下，FISTA的总计算量可以被优雅地界定，并且在特定的图结构上，能展现出明确优于经典算法的加速效果。\n更关键的是，这个证明解释了长期困扰学界的现象：尽管FISTA在迭代中会激活更多节点，但这些「多余激活」是可控的、暂时的。一旦迭代进入最优解的一个邻域，算法就会迅速收敛。\n怎么证明？三重验证\nGPT-5.2的证明能令人信服吗？为此，团队搭建了一个三重验证体系。\n首先，GPT-5.2 Pro生成了完整的证明初稿。\n接着，团队借助@HarmonicMath的Aristotle系统，结合Gemini 3 Pro模型，将证明中的关键不等式和复杂度上界，逐行转化成了形式化的Lean代码。\n而且除了形式化验证之外，教授自己也把证明从头到尾证明了两遍。目前看来，证明是没问题的。\n陶哲轩会被说服吗\n又一数学难题被GPT-5.2 Pro攻克，这不由得引起网友讨论——\n它会成为AGI吗？陶哲轩会看到希望吗？\n至少，目前GPT-5.2再一次证明了LLM在深度数学推理上的惊人潜力。\n而且，它也弥合了理论分析与实际算法之间的鸿沟。它的证明，为最经典的加速算法提供了缺失的理论基石。\n当然，这并不意味着AI能取代理论科学家。\n可以说，它更像是一个拥有惊人直觉和不知疲倦的协作者。\n人类提出关键问题、界定框架、判断价值，AI则能在庞大的数学空间里，帮我们找到那条通往答案的隐秘小径。\n参考资料：\nhttps://mathstodon.xyz/@tao/115722360006034040\nhttps://x.com/kfountou/status/2000957773584974298\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660003&idx=2&sn=4a0dc7cc63d47bcf1537acf9bd257d6d&chksm=f09b6fe8ebfa4e69318ca971ba01bb4176084758024c4b9dc8c37d577fce56b5b6a09032f38b&scene=0&xtrack=1#rd",
      "publish_time": 1767544200,
      "publish_date": "2026-01-05 00:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://mathstodon.xyz/@tao/115722360006034040\", \"https://x.com/kfountou/status/2000957773584974298\"]",
      "add_ts": 1767655300,
      "last_modify_ts": 1767741745
    },
    {
      "id": 246,
      "article_id": "51621",
      "title": "当机器学习遇见拓扑：拓扑数据分析与拓扑深度学习",
      "description": "拓扑学作为数学分支，近年来在机器学习中广泛应用，尤其在数据表示与特征提取方面发挥重要作用。拓扑数据分析（TDA）基于代数与计算拓扑，擅长处理结构性数据，已成为“数学与AI”交叉领域的重要工具，在集智俱乐部相关读书会中备受关注。",
      "content": "导语\n作为数学的一个分支，拓扑学以独特的方式描述空间的性质和结构。近年来，几何和拓扑在机器学习中得到了广泛应用，尤其是拓扑模型，在数据表示和特征提取方面有着重要作用。拓扑数据分析（Topological Data Analysis, TDA）植根于代数拓扑和计算拓扑，在处理具有结构性的数据上得到了极大的发展，并逐渐成为 Math for AI 的一个重要方面。\n在集智俱乐部「\n数学与人工智能读书会\n」中，夏克林老师讨论了拓扑数据分析（Topological Data Analysis, TDA）的主要思想和模型，首先介绍了基本的拓扑数据表示模型，尤其是基于数据的单纯复形构造，以及和传统图模型的差异，之后介绍了基于单纯复形的拓扑深度学习。拓扑数据分析在刻画复杂的高阶相互作用方面展示出极大的优越性，尤其是它可以刻画体系最本质的拓扑信息。拓扑数据分析将进一步促进我们对数据的本质信息的挖掘和刻画，为提高机器学习模型的精度、可解释性、迁移性等打下坚实的数学基础。\n研究领域：\n复杂系统，Math for AI，拓扑数据分析，单纯复形，拓扑深度学习，图神经网络，过滤流过程\n夏克林\n| 讲者\n王至宏\n| 整理\n梁金\n| 编辑\n目录\n1. 数据的拓扑表示\n2. 拓扑数据处理的特征\n3. 拓扑深度学习\n4. 基于单纯复形的图神经网络\n1. 数据的拓扑表示\n本文以分子数据处理为切入点，探讨拓扑数据分析\n（Topological Data Analysis, TDA）\n的应用和特点。AI 在数据处理上的两个关键环节——\n数据表征\n和\n建模分析特性\n，与拓扑数据分析有着紧密的联系。接下来，我们将展开介绍这两个环节。\n图1. 基于 AI 的分子数据分析\nTauzin, Guillaume, et al. \"giotto-tda: A topological data analysis toolkit for machine learning and data exploration.\" The Journal of Machine Learning Research 22.1 (2021): 1834-1839.\n文章总结了拓扑数据和机器学习的结合的相关理论。\nChazal, Frédéric, and Bertrand Michel. \"An introduction to topological data analysis: fundamental and practical aspects for data scientists.\" Frontiers in artificial intelligence 4 (2021): 108.\n1.1 数据表征\n在处理图像数据时，我们可以借助神经网络模型生成相应的数据表示。例如通过提取特定的特征点构建网格模型进行人脸识别。除了网格模型，还有其他如特征图和热度图等不同的数据表示方式。虽然源自同一图像数据，但从数学角度可以建立起不同的模型：最简单的矩阵模型，或者点阵模型、网格模型，甚至更复杂的函数模型。一旦数学模型建立，就可以基于模型提取特征，并与后续关注的信息产生联系，如通过多层感知器\n（MLP）\n进行预测等。\n图2. 人脸识别模型\n类似地，在处理分子数据\n（如小分子数据和蛋白质数据）\n时，也有多种不同的数据表示方式。一种常见方法是基于共价键的\n图表征\n，其中每个节点代表一个原子，边代表共价键，形成一种图的表示形式。\n图3. 不同的分子模型\n除此之外，还有\n几何方法\n，例如将原子看作半径固定的球体，观察者可以从球体集合的外部，即分子的表面进行研究，查看其表面积或凸凹区域。这些凸凹区域与原子间的相互作用信息有关，这种描述更偏向几何。\n更进一步，还可以通过密度泛函理论来计算\n电子密度或电子函数分布\n，将分子数据转化为一种空间形态的数据表现形式。因此，\n尽管源自同样的分子数据，我们可以从多个角度对其进行表征\n。一旦完成表征，就可以在此基础上提取各种特性，包括各种指纹\n（fingerprint）\n和描述符\n（descriptor）\n等等。这些性质可能和最终想要理解的功能产生联系，例如水溶性、脂溶性、毒性等。\n1.2 分子结构的建模\n在构建关于分子功能模型的过程中，大量使用了结构数据。这是因为分子的结构和其功能之间存在强烈的关系，被称为“\n结构-功能关系\n”\n（Structure-Function Relationship\n）\n。\n例如，离子通道蛋白质的显著特点是它们中心有一个洞\n（图4左上）\n，这个洞对离子通道的功能至关重要，因为它方便了细胞膜外部的离子进入膜内，或者膜内的离子离开细胞。另一个例子是蛋白质笼\n（图4右下）\n，这种蛋白质的表面有一定结构，但其内部是空的，就像用来装东西的盒子，这种空心的结构有利于某些物质的存储和运输。最后一个例子是具有两个固定区域，并通过一个灵活连接区域相连的分子。这种结构可以形成一种开关状态，使得分子能够处于激发态或非激发态，从而影响其功能。\n图4. 蛋白质分子结构\n无论是通过共价键连接还是通过非共价键的相互作用，都会影响最终的稳定态结构，这种稳定态结构与分子功能紧密相关。因此，\n描述分子的结构对于理解分子功能\n具有\n重要作用\n。为更好地描绘分子的结构，大量的描述符\n（无论是组合量，代数量还是几何量）\n被提取了出来。在这些描述符中，有一些关注拓扑特性，比如图上向量、几何量等等，还有一些关注组合或邻近信息的指纹。\n图5. 化学描述符\n在大量关于结构的描述量中，\n可能存在某些更本质、更全局的量，它们能够更好地抓住结构的整体信息，从而在理解和描绘分子的功能方面起到更重要的作用\n。这就引出了拓扑数据处理的核心：\n通过拓扑不变量来描述数据\n。\n2. 拓扑数据处理的特征\n拓扑数据分析与传统的工具相比有三个主要特征：\n1）单纯复形\n：采用单纯复形\n（simplicial complex）\n的描述方式，相比图描述能捕获数据中更丰富的拓扑和几何信息。\n2）拓扑不变量\n：拓扑数据分析使用拓扑不变量，而非仅仅依赖于统计量或描述性量。这些拓扑不变量可以提供对数据的深度理解，包括数据的连接性、洞等复杂结构。\n3）过滤流过程\n：\n拓扑数据分析包含一个过滤流过程，这个过滤流过程可以与系统内的多尺度描述很好地结合。通过从不同的尺度去观察和分析数据，我们能够得到更全面的信息。\n2.1 单纯复形\n在非数学领域，如计算机科学、工程和生物学中，人们通常使用图来表达实体之间的连接关系。然而，在基础数学领域中，更经常使用的是称为单纯复形\n（Simplicial Complex）\n的描述方式。作为高级的拓扑工具，单纯复形能更好地描绘复杂系统中的结构信息。\n与图相比，单纯复形有几个重要的不同点：\n1）高维度描绘：\n除表示节点和边\n（即0维和1维的对象）\n，单纯复形可以表示更高维度的对象。例如，填充的三角形代表一个2维的对象，填充的四面体代表3维对象。\n图6. 图与单纯复形\n2）高阶相互作用\n：图主要描述两两之间的相互作用，而通过引入“\n更高维度的单元\n”，单纯复形能够表达出超过两个实体之间的相互作用。例如，填充的三角形表示三个实体之间的相互作用，填充的四面体表示四个实体之间的相互作用。注意二者的区别，用一个形象的比喻来解释：图可以表示父亲与孩子的关系，以及母亲与孩子的关系；而复形则能表示父亲、母亲、孩子三者组成的家庭单位的关系，用一个填充的二维三角形。\n3）距离和体积的描述\n：图通常只能描述路径或距离，单纯复形则可以描述面积，两边夹角\n（2维单元）\n或者体积\n（3维单元）\n。这为我们提供了更高阶的信息，使我们能够捕获到实体间更复杂的相互作用。\n举个简单的例子，从一组点和固定距离构造一个复形\n（Vietoris-Rips复形）\n：\n图7. Vietoris-Rips复形\n或者复杂些，在微分拓扑中，根据函数导数取值0的信息及其正定性将流形分片\n（Morse复形）\n：\n图8. Morse 复形\nMagillo, Paola, et al. \"A discrete approach to compute terrain morphology.\" Computer Vision and Computer Graphics. Theory and Applications: International Conference VISIGRAPP 2007, Barcelona, Spain, March 8-11, 2007. Revised Selected Papers. Springer Berlin Heidelberg, 2008.\n提取 Morse 复形的离散方法\n2.2 拓扑不变量\n拓扑不变量是对拓扑空间性质的一种刻画，在数据分析中提供了全局和本质的视角。相较于如 PCA 这样的统计方法，它更关注整体的性质。举两个经典的拓扑不变量例子：\n1）欧拉示性数：\n欧拉示性数取值为“\n顶点数\n减去\n边数\n加上\n面数\n”\n（V-E+F）\n。对于拓扑等价于球体的多面体\n（例如立方体或八面体等）\n，欧拉示性数均为2。这是因为在拓扑意义上，这些形状都可以被连续地变形为球形。\n图9. 四面体与六面体的欧拉示性数\n2）贝蒂数：\n贝蒂数是在拓扑数据分析\n（TDA）\n中常用的拓扑不变量，用来描述\n拓扑空间的复杂度\n。零维的贝蒂数表示连通分支的数量，一维贝蒂数表示独立环路的数量，二维贝蒂数表示“空心”球面的数量，等等。\n图10. Betti 数描述分子结构\n2.3 过滤流过程\n过滤流过程\n（filtration）\n是拓扑数据分析的核心概念。这个过程可以理解为\n不断改变尺度以观察复杂系统如何随着尺度的变化而变化\n。过滤流过程在不同的尺度上描述单纯复形，并且生成相应的条形码来记录每个尺度下的拓扑信息。\n图11. 过滤流过程\n上图最左边的十四个点代表原始数据，每点周围有一个球体，随时间推移，这些球体的半径增大。当两个球体接触时，表示两个数据点之间存在连接，这就形成了一条边，同时独立分支的数量减一。在过滤流过程中，随着球体半径的增大，独立元素逐渐减少，同时出现新的拓扑结构\n（比如环和更高维的洞）\n。\n从图中的条形码可以看出，初始有14个独立节点，所以 Betti\n0\n为 14 个。随着时间的推移，球体之间的连接增多，独立的节点数目减少。同时，当出现闭合的路径时，就形成了环，可以在 Betti\n1\n的条形码中看到这种变化。\n图12. Vietoris-Rips 复形与单纯复形\n通过\n过滤流过程\n和\n单纯复形\n，我们可以从全局和多尺度的角度理解复杂系统的结构，并通过 Betti 数这类\n拓扑不变量\n来量化这些性质。这种方法在机器学习、迁移学习等领域有着重要的应用，相比传统的统计工具，它提供了对数据深层本质结构的理解。\n图13. 多尺度的单纯复形\n3. 拓扑深度学习\n3.1 拓扑深度学习的基本流程\n前边更多是从数学角度出发的讨论，在处理真实世界的问题时，我们该如何\n将拓扑理论应用到化学分子等具体科学问题上？\n以碳60分子为例，C\n60\n是由 60 个碳原子组成的分子，其形状类似于足球，包含了 12 个五元环和 20 个六元环。\n如下图所示，我们用拓扑数据分析进行分析，X 轴表示直径。\n图14. C\n60\n分子模型随直径变化的 Betti 数\n• 在 Betti-0 中，有 60个条形码，其中 30 个较短，30 个较长。较短的代表碳碳双键，因为双键较强，原子拉得近；而较长的则代表碳碳单键，比双键要弱，因此距离稍长。这样，\nBetti-0 描述的是共价键的信息。\n• 在 Betti-1 中，有 32 个条形码，其中 12 个较短，20 个较长。较短的对应五元环，而较长的则对应六元环。所以，\nBetti-1 描述的是环的信息\n。\n• 在 Betti-2 中，可以看到一个长条形码，这个对应\nC\n60\n分子整体的空心结构\n。\n通过这些特征信息，我们将拓扑数据分析与机器学习相结合。例如在数据上构建不同类型的单纯复形，进行过滤流过程，得到条形码，然后提取各种特征\n（如最长的条形码、最短的条形码、总的数量等）\n，并将这些特征输入到机器学习模型，如 Random Forest 或 Gradient Boosting Tree 等，进行功能预测等任务。这样就实现了拓扑深度学习的基本流程。\n图15. 拓扑深度学习的基本流程\n3.2 领域相关工作\n在拓扑数据分析\n（TDA）\n与机器学习相结合的研究领域中，魏国卫教授和他的团队做了大量的创新性工作。他们通过 TDA 提取数据集的特征，并将这些特征用于各种预测任务。在过去的几年里，在图网络并未广泛应用、且可处理数据量相对较小\n（通常在三千到四千之间）\n的时代，他们的研究成果表明 TDA 能提取出比传统统计方法或某些特定组合更有效的特征。\n图16. 基于拓扑学习的预测\n从多个benchmark数据集的结果来看，他们的基于 TDA 的模型表现非常好。尤其值得注意的是，他们在 D3R 药物设计比赛中，通过结合TDA和机器学习的方法，在2017和2018两届比赛中都取得了显著的优势，并超越了许多传统的方法。他们在TDA和机器学习结合的研究方向上的早期工作，为该领域奠定了坚实的基础。\n图17. D3R 药物设计比赛\nCang, Zixuan, Lin Mu, and Guo-Wei Wei. \"Representability of algebraic topology for biomolecules in machine learning based scoring and virtual screening.\" PLoS computational biology 14.1 (2018): e1005929.\n拓扑机器学习模型预测配体蛋白质结合能。\nNguyen, Duc Duy, et al. \"MathDL: mathematical deep learning for D3R Grand Challenge 4.\" Journal of computer-aided molecular design 34 (2020): 131-147.\n拓扑机器学习模型应用于药物设计。\n3.3 Persistent Spectral：谱图法结合过滤流过程\n在观察和分析数据时，主要有两种方式：一是考虑数据的表征\n（representation）\n，二是利用数据的特性\n（features）\n。前面讨论我们主要关注拓扑的特性，包括各种拓扑不变量，它们描述了结构的复杂性。另一方面，当我们想保留数据的更精细的特征，就需要考虑数据的其他数学不变量。例如，针对图或单纯复形，我们可以考虑谱图方法以及它的扩展，这种方法基于图、单纯复形或超图上的离散拉普拉斯算子\n（Hodge Laplacian）\n，并用其谱的信息进行数据表示。\n图18. 谱图法结合过滤流过程\n为将这两种思路相结合，我们提出一种新的模型\nPersistent Spectral\n。这个模型综合利用了过滤流过程和谱图方法，在保留数据原始形态的同时，还能揭示其内在的拓扑特性。\nEdelsbrunner, Herbert, and John Harer. \"Persistent Homology-a Survey.\" Contemporary mathematics 453.26 (2008): 257-82.\n持续同调（Persistent Homology）是拓扑数据处理（Topological data analysis, TDA）核心模型。\nWang, Rui, Duc Duy Nguyen, and Guo‐Wei Wei. \"Persistent Spectral Graph.\" International journal for numerical methods in biomedical engineering 36.9 (2020): e3376.\n提出了持续谱图法。\n拉普拉斯矩阵\n拉普拉斯矩阵的概念我们只做大致介绍，k 维拉普拉斯矩阵 L\nk\n有如下计算公式\n图19. 拉普拉斯矩阵计算公式\n举个例子，0维拉普拉斯矩阵 L\n0\n以点为单位对象\n，对角线为点的度数，当点 i 和 j 连接时 L\n0\n的 (i, j) 位置取 -1 否则取0。类似地，在复形上，将\n边作成单位对象\n，由边的关系得到 1 维拉普拉斯矩阵 L\n1\n。\n图20. 图的拉普拉斯矩阵 L\n0\n, L\n1\n, L\n2\n将得到拉普拉斯矩阵进行特征值分解，其中零特征值的数目对应了 Betti\n0\n，其反映图的连通分量的数量。拉普拉斯矩阵的非零特征值也包含有丰富的信息。比如最小的非零特征值，也被称为 Fiedler 值，常用来刻画图的连通性，展示单纯复形各部分之间的连接关系。\n图21. 零特征值数目与 Betti 数\n3.4 Ricci 曲率\n另外一个重要的不变量是几何不变量，例如 Ricci 曲率。\nRicci 曲率能够捕获图或网络中的社区结构或簇（cluster）结构\n。举个例子，当图中有一个紧密连接的社区或聚类时，这个区域的 Ricci 曲率通常是一个较大的正值。而连接两个不同社区或聚类的桥梁部分，Ricci 曲率则可能为负值。因此，许多研究者利用 Ricci 曲率的赋值方法来描述网络中各区域之间的相互连接性。\n图22. Ricci 曲率\nRicci 曲率及其它各种曲率都是用来描述整体结构、簇结构、社区结构以及链接结构间关系的重要工具，能用于揭示网络或数据集内部丰富复杂的拓扑和几何属性。\n实际上，上边提到的信息可以相互关联起来。比如，拓扑学中的 Betti 数\n（homology信息）\n和Hodge Laplacian中的零特征值是一一对应的。离散形式的 Ricci 曲率\n（例如Forman Ricci curvature）\n也可以通过与Hodge Laplacian的某种组合\n（比如Bochner-Weitzenböck公式）\n来产生联系。\n图23. 几何不变量的关联\n使用这些工具从不同角度描述数据的结构：\n• Ricci\n曲率帮助我们理解数据的几何性质；\n• Betti\n数或者更一般的\nhomology\n信息揭示数据的拓扑性质；\n• 谱方法则能捕获网络或数据集的全局特性。\n3.5 单纯复形的构造\n上边主要介绍几种基于数学不变量的数据的特征\n（featurization）\n，包括 Betti数、曲率和谱信息等方式。另一个更本质的问题是数据的表征\n（representation）\n。比如用图、单纯复形，以及超图来表征数据。\n图24. 单纯复形与超图\n考虑图或单纯复形的子结构，比如社区、簇或模块等。这些子结构往往能够展示数据内部更加精细的组织形式，从而帮助我们更准确地理解和预测系统的行为。此外，也可以考虑动态的视角，比如时间演化网络，这种视角可以帮助我们理解系统的变化和发展规律。\n构造单纯复形的方法很多，除了常用的方法如 Clique complex，VR complex，Alpha complex，等等，下边会介绍三种方法。他们在拓扑学中有着广泛应用。另外拓扑信息还可以通过其他代数模型来表征，这里我们将介绍一种特殊的代数模型，Tor-algebra。\nBodnar, Cristian. \"Topological deep learning: graphs, complexes, sheaves.\" PhD diss., University of Cambridge, 2022.\n拓扑深度学习。\n3.5.1 Neighborhood Complex\n最简单的构造方式是邻域复形\n（Neighborhood Complex）\n，基于给定图中的邻接关系来构建。如下图所示，假设有一个点，其邻接点有三个。我们将这四个点构成一个四边形\n（称为2-simplex）\n。如果邻接点中有两点也相互邻接，则连起这两个点构成一条边\n（1-simplex）\n。如果有三点相互邻接，那么将这三点组成一个填充的三角形\n（2-simplex）\n。通过这种方式将图转化为邻域复形。\n图25. 邻域复形\n这种邻域复形所描述的拓扑信息与由其他方式\n（例如Clique Complex）\n所得到的结果会有显著的不同。\n另外一个有趣的单纯复形构造方式是\nDowker Complex\n。\n3.5.2 Dowker Complex\n当研究两个实体间的相互作用，例如两个分子之间的连接时，我们可能更关心分子之间的全局交互关系，而不是各自内部的连接方式。此时二部图\n（bipartite graph）\n是一个很好的工具，我们将小分子\n（例如蓝点和绿点）\n视为图节点，再根据它们之间的相互作用关系添加边。\n图26. Dowker 复形\n在此基础上构建邻域复形。由于蓝点的所有邻接点位于绿点集合中，反之亦然，因此最终得到了两个单纯复形，分别由蓝点和绿点组成，借助 Dowker 复形探讨实体之间的相互作用关系。\n3.5.3 Hom 复形\nC. H. Dowker, “Homology groups of relations,” Annals of mathematics, pp. 84– 95, 1952. L. Lovász, “Kneser’s conjecture, chromatic number, and homotopy,” Journal of Combinatorial Theory, Series A, vol. 25, no. 3, pp. 319–324, 1978.\n更复杂的场景可以用“Hom Complex”构造方式，这种方法适用于研究两个图的相互作用。其核心是构建一个称为Polyhedral Complex 的结构，其中元素为多重同态\n（Multihomomorphisms）\n。\n举个例子，假设有两个图\nK\n2\n和\nK\n3\n，选择某种映射策略将\nK\n2\n映射到  K\n3\n。这个映射只需保证：原图存在的边，映射到新图中也存在对应边。比如将\nK\n2\n的点\nK\n1\n映射到\nK\n2\n中的点 a，点\nx\n2\n映射到点 b。但如果尝试将点\nK\n1\n和\nx\n2\n都映射到点a，那就会出现问题，因为在原图中点 x\n1\n和 x\n2\n之间存在边，但在新图中，点 a 无法形成自环。\n图27. Hom 复形\n如上图所示，将\nx\n2\n,\nx\n2\n分别映到单点集的映射构成零单形 0-cell，将其中一点映到二点集的映射构成了一单形 1-cell，所有这些映射\nη\n构成了复形 Hom(K\n2\n, K\n3\n)。当考虑更复杂的连接关系时，比如使用高阶或卷积核样式的关系进行映射，这种方法能够帮助生成新的单纯复形，进一步反映图在这种特定内核下的深层联系。\n图28. Hom 复形示例\n3.5.4 Tor-algebra\n我们还能将单纯复形的结构提升到更复杂的代数结构进行考虑。比如，给定一个单纯复形，定义一组多项式，并在这些多项式之间建立特定的关系\n（例如Stanley-Reisner理论）\n，进而得到一个理想\n（ideal）\n的结构，然后研究这个理想的性质，例如它的Tor函子等。这样，图的拓扑信息就被转换为了代数量，单纯复形上升到代数层面，在这个层面上进行研究。\n图29. Tor 代数\nXiang, L. I. U., and Kelin Xia. \"Persistent Tor-algebra based stacking ensemble learning (PTA-SEL) for protein-protein binding affinity prediction.\" ICLR 2022 Workshop on Geometrical and Topological Representation Learning. 2022.\nPersistent Tor-algebra（PTA）为生物学研究提供了一种强大且有效的新工具\n4. 基于单纯复形的图神经网络\n最后一部分，夏克林老师介绍了基于单纯复形的图神经网络，可以理解为图神经网络的一种扩展。在图神经网络中，核心的想法是通过消息传递\n（message passing）\n机制，将一个节点周围邻居的信息进行聚集，并传递到目标节点，然后通过迭代这个过程，实现对整个图结构的学习。\n图30. 图神经网络\n在拓扑数据处理中，我们不再只是基于图来操作，而是在更高维度的单纯复形或者其它复杂结构\n（例如Stellar complex）\n上进行操作。例如，除了在点的层面上进行信息传递，我们也可以在边、面或更高维度的单纯形上进行类似的操作。\n图31. 单纯复形上的信息传递\n在进行这种复杂的拓扑数据分析时，有两个非常核心的概念：边界运算\n（Boundary Operation）\n和余边界运算\n（Coboundary Operation）\n。简单来说，边界运算是指\n从给定的单纯形中找到其所有低一维的面\n。例如，从一个边\n（1-simplex）\n出发，我们可以找到它的两个端点\n（0-simplex）\n。而余边界运算则是反向操作，即\n从低维单纯形出发找高一维的单纯形\n。\n图32. 边界运算和邻接关系\n除此之外，还有两个重要关系：Lower Adjacency 和 Upper Adjacency。这两个关系都是描述图中的邻接关系，但方式各异。Lower Adjacency指的是当两条边有一个公共顶点时，我们称这两条边是邻接的。而Upper Adjacency则更为严格，只有当两条边共享一个高维单纯形\n（比如三角形）\n时，我们才认为它们是邻接的。\n通过考虑不同的连接方式，可以进一步描绘出数据中信息传递的不同路径，并通过将不同维度的信息耦合在一起，构建一个复杂的“\n拓扑神经网络\n”。\n图33. 拓扑神经网络\n这种结合了拓扑和深度学习的研究领域还相对较新，但已经被广大学者所关注，并有越来越多的研究工作开始尝试利用拓扑数据分析来提升深度学习模型的性能。\nHajij, Mustafa, Kyle Istvan, and Ghada Zamzmi. \"Cell complex neural networks.\" arXiv preprint arXiv:2010.00743 (2020).\n拓扑神经网络\n思考延伸\n在拓扑数据分析\n（TDA）\n中，我们用单纯复形来表述和理解复杂的数据结构。然而，其他专业领域的研究者可能对这样的描述方式感到困惑。在他们眼中，原子\n（点）\n和共价键\n（边）\n具有明确的物理含义，而单纯复形中的三角形看起来似乎没有直观的物理意义？实际上，在 TDA 中，三角形捕获了三个元素之间的相互关系。在化学领域，这可以用来表示由三个原子组成的二个共价键之间的角度信息\n（bond angle）\n。而且这个角度信息在分子动力学的模拟中有极其重要的作用。然而，如何更好地定义单纯复形，并用它来描述体系中的高阶相互作用仍然是TDA建模中的一个主要问题。\n另外一个 TDA 面临的挑战是如何\n将抽象的数学不变量与实际问题紧密联系起来\n。为了解决这个问题，我们需要理解这些拓扑特征所代表的实际意义。例如数据中的环状结构是否反映出它的物理、化学、\n生物，或其他实际信息。尽管 TDA 与传统图的方法在概念上有所不同，但其在刻画复杂的高阶相互作用的问题中展示出了极大的优越性，尤其是它可以刻画体系的最本质的拓扑信息。\n在实际应用中，我们需要\n构造合适的单纯复形来描述高阶信息，并且找出拓扑不变量的合适的实际意义，\n这样才能发挥 TDA 模型真正作用\n，\n并使模型的解释性和性能得到提升。这就需要我们深入理解问题背景，将数学工具与实际问题紧密结合，并寻找到一个合适的应用场景来展示这种方法的优点。只有这样，TDA 才能表现其价值，并吸引更多人尝试使用这种新方法。\n更进一步，除了拓扑数据分析，对于其他数学不变量，包括几何不变量、代数不变量、组合不变量等，也可以用于数据的表征和特征提取，这些模型将进一步促进我们对数据的本质信息的挖掘和刻画。为提高机器学习模型的精度、可解释性、迁移性等打下坚实的数学基础。\n图34. 分子数据，数学表征，数据特性与深度学习\n扫描二维码观看读书会回放视频\n读书会地址：https://pattern.swarma.org/study_group_issue/540\n学者简介\n夏克林\n，南洋理工大学副教授。2013年1月获得中国科学院博士学位，于2009年12月至2012年12月在美国密歇根州立大学数学系作为访问学者。从2013年1月至2016年5月，在密歇根州立大学担任访问助理教授。2016年6月，加入南洋理工大学，并于2023年3月晋升为副教授。夏克林的研究专注于分子科学的数学人工智能，在《SIAM Review》、《Science Advances》、《npj Computational Materials》、《ACS nano》等期刊上发表了70多篇论文。\n拓扑学课程：从空间直觉到系统科学\n你是否曾思考过：为什么咖啡杯在数学上可以变成甜甜圈？为什么混沌系统中会出现周期轨、可约化结构和“奇怪吸引子”模式？为什么神经网络、量子物理甚至心理结构，都可以从“拓扑”角度理解？\n拓扑学不仅是数学的抽象分支，更提供了系统的思维方式，让我们理解连续性、结构不变性乃至复杂系统的整体规律。从欧拉七桥问题到DNA的缠结，从量子场论到思维科学与脑科学，拓扑学思想正在各学科中普遍而深刻地重塑着我们的认知方式。\n集智学园联合北京大学博士金威老师开设\n「拓扑学的思维革命：从空间直觉到系统科学」\n，课程于11月23日开启，欢迎感兴趣的读者加入。\n详情请见：\n拓扑学的思维革命：从空间直觉到系统科学\n推荐阅读\n1.\n脑网络中的高阶拓扑结构\n2.\n拓扑深度学习捕捉数据的高阶关系：信息传递拓扑神经网络概述\n3.\nNat. Phys.速递：拓扑如何改写复杂系统动力学？\n4.\n系统科学前沿十讲：探究复杂世界演变背后的规则（二）\n5.\n集智学园精品课程免费开放，解锁系统科学与 AI 新世界\n6.\n高考分数只是张入场券，你的科研冒险在这里启航！\n7.\n加入集智字幕组：成为复杂科学知识社区的“织网人”\n点击“阅读原文”，报名课程",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247724677&idx=2&sn=0f387a79f87a9623b48ce6484f01ed03&chksm=e98aa1a081ed3dafb99b9d59676d38c003efa276be3f30580e706102d5decde4afcaf880893c&scene=0&xtrack=1#rd",
      "publish_time": 1767496800,
      "publish_date": "2026-01-04",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://pattern.swarma.org/study_group_issue/540\"]",
      "add_ts": 1767655332,
      "last_modify_ts": 1767655332
    },
    {
      "id": 247,
      "article_id": "51620",
      "title": "马斯克宣布：量产脑机接口，手术全自动化",
      "description": "马斯克宣布Neuralink将于2026年启动脑机接口设备的大规模生产，并转向自动化手术流程，推动技术从实验室迈向临床应用。此举引发网友热议，畅想通过脑机接口实现意念编程、植入AI模型如Grok 4等未来场景，展现了人机融合的广阔前景与公众对技术落地的高度期待。",
      "content": "Jay 发自 凹非寺\n量子位 | 公众号 QbitAI\n马斯克的脑机接口，今年就要开始量产了。\n新年第一天，老马就在X上高调立下flag，宣布要\n把Neu\nralink从\n实验室推向临床\n：\nNeuralink将于2026年开始大规模生产脑机接口设备，并转向一种精简、几乎完全自动化的手术流程。\n消息才刚出来，网友们便已脑洞大开，畅想各种玩法：\n能给我脑子里装个Grok 4吗？\n想象一下，直接通过脑机接口vibe coding……\n我需要一键入睡，还有永久愉悦模式。\n谁能想到，仅仅经过十年的发展，Neuralink居然真的准备要从实验室走向临床。\n脑机接口的重要转折点\n老马不是第一次想要大规模生产Neuralink了。\n早在2024年7月，马斯克便曾透露，预计到2026年，Neuralink有望服务超过1000人。\n消息公布四个月后，Neuralink即开始扩充团队，集中招聘制造技术人员与微纳加工专家，为量产提前铺路。\n但截至2025年9月，Neuralink累计服务的患者\n只有12人\n。\n考虑到存量巨大的市场需求，这一现象无疑有些反常。对于神经系统疾病而言，脑机接口几乎是当前最具潜力、甚至唯一有效的解决方案。\n为何迟迟未能落地？\n技术成熟度始终是一个绕不开的因素。但对应用而言，更现实的挑战，或许不是芯片，而在手术本身。\n按照既有方案，植入手术需要由外科医生先切除部分颅骨，切除部分硬脑膜，再由机械臂将超细电极线植入大脑。\n这一流程相当复杂，并且个体差异相当大，极度依赖医生经验。因此很难规模化。\n马斯克表示，到2026年，Neuralink的植入手术将升级为一种「高度简化、几乎完全自动化的流程」。\n而这一「简化」的核心，在于脑芯片电极线的进入方式。\n而此次再度官宣量产，马斯克称，脑芯片电极线将\n直接穿过硬脑膜\n，而无需将其切除。\n硬脑膜\n覆盖于大脑表面，是位于颅骨和脑组织中间的\n天然屏障\n，可以隔离异物入侵、防止感染。\n但这层保护层也阻碍了医疗器械的植入。要想往脑里插东西，通常要把这层膜切开。这加大了手术难度，若操作不当很容易感染、出血。\n而新技术的这种更「微创」方式，能让电极线直接从「门缝」里穿进去，而不用「开门进屋」。这意味着更低的成本、更小的风险、更短的恢复周期，\n标准化的门槛因此更低\n。\n正如马斯克所说：\n这是一件大事。\nNeuralink成立于2016年，致力于通过硬币大小的脑芯片，让人们通过神经信号直接控制计算机。\n鉴于其离大脑的位置，这项全新的技术，诞生第一天便在医疗领域展现出巨大潜力。借助脑机接口这座桥梁，大脑第一次不再是「黑箱」，而是能被拆解的工程系统。\n目前，Neuralink的产品重点仍集中在\n治疗神经系统疾病\n，包括瘫痪、肌萎缩、帕金森、老年痴呆和视力障碍。\n2024年1月，因潜水事故导致瘫痪的前国际象棋棋手\nNoland Arbaugh\n，成为Neuralink的首位志愿者。\n手术后，这位肩部以下完全失去知觉的患者，仅凭植入大脑的芯片，便能在X上发帖，甚至还能玩《马里奥赛车》。\nNoland表示，\nNeuralink让他获得新生\n。\n倘若Neuralink真能通过规模化生产降低这一手术的门槛与价格，对于成千上万个「Noland」而言，这无疑是一项改变命运的事件。\n但对马斯克而言，Neuralink的版图中还有一片和医疗一样，广袤、神秘，且至今无人探索过的新大陆——赛博格。\n在马斯克看来，Neuralink并不只是医疗设备，而是人类应对潜在「邪恶AI」的重要防身武器。\n他认为，在ASI必然出现的那一天，人类只有拥有与硅基智能相当的高带宽接口，才不至于沦为「被圈养的宠物」。\n简而言之：\n打不过，就加入\n。\n而一旦所有人都能通过脑机接口直连网络，人类的进步速度将不再受基因和时间限制。而是\n能像软件一样，随时通过OTA更新自己的技能储备\n。\n届时，人类文明将迎来一次大爆发。\n也许在未来，你的孙辈们会难以理解：曾经有一段时间，人类的大脑竟然无法下载技能。\n但回到现实，从现有的技术进展和公开的行业研究来看，\n自动化脑机接口植入手术仍然停留在实验阶段\n。\n毕竟，手术对象是大脑。一旦出现失误，其风险与后果，远非普通外科手术能比拟的。\n至少目前，在受控实验环境之外，涉及Neuralink等脑植入设备的自主神经外科手术，仍未得到充分验证。\n狂奔的Neuralink\n立下「规模化生产」flag的Neuralink，成立于2016年。\n朝临床狂奔的十年里，Neuralink也是一路过关斩将——\n2019 年，首次展示动物实验。\n2020 年，展示配有脑机接口设备的小猪 。\n2021年，成功让猴子凭借意念玩乒乓球游戏。\n2022年，实验引发争议，进展慢于预期，FDA审批受阻。\n2023年，迎来拐点，获FDA批准，开展人体临床实验。\n2024年，首位患者Noland Arbaugh接受植入，通过脑信号发帖、玩游戏。\n2025年，普及速度开始加速。\n9月，宣布已为12名受试者完成植入；12月，这一数字已经变成了20。\n2026年开年，宣布要在一年内实现大规模量产。\n两年时间，从第一例人体试验，到20名参与者，再到量产预告。这一路走过来，Neuralink其实一直在推动手术流程的标准化，为应用阶段做准备。\n上世纪80年代，史蒂夫·乔布斯曾将个人电脑比作「思维的自行车」。\n十年后，人们又铺设了互联网这条「高速公路」。\n但即便如此，大多数白领的工作仍高度依赖人力。我们需要亲自「蹬车」数百公里，才能抵达目的地。\n现在，马斯克打算\n用脑机接口，把这条高速公路直接修进人类的大脑\n。\n参考链接：\n[1]https://x.com/elonmusk/status/2006513491105165411?s=20\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859753&idx=1&sn=64c1e4d9604d3c752d46c6efef339926&chksm=e970a4e1dd7e7cfcc4bcfe07cb63dc62a1642435903c04667573df7e0e706e3daed547694096&scene=0&xtrack=1#rd",
      "publish_time": 1767496800,
      "publish_date": "2026-01-04",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/elonmusk/status/2006513491105165411?s=20\"]",
      "add_ts": 1767655337,
      "last_modify_ts": 1767655337
    },
    {
      "id": 251,
      "article_id": "51610",
      "title": "系统观下的复杂科学：拓扑学、线性代数与统计物理的互补角色",
      "description": "复杂系统由大量相互作用的组分构成，整体行为无法还原为个体简单叠加，而是依赖于关系结构、作用尺度与动力学过程。大脑、生态、社会、气候与金融市场等均属此类。其研究需跨越多个层次，运用多种抽象语言与数学工具，揭示系统在时间演化中涌现的非线性特征与自组织规律，理解整体与部分之间的动态关联。",
      "content": "导语\n在复杂科学中，我们面对的研究对象往往并不是某个孤立的实体，而是由大量组分构成、通过多层次相互作用不断演化的系统。无论是大脑、生态系统、社会组织，还是气候与金融市场，这些系统的共同特征在于：整体行为无法简单还原为个体行为的线性叠加，而是深刻依赖于关系的组织方式、作用尺度以及随时间展开的动力学过程。\n正因如此，复杂系统研究往往不仅依赖单一的数学工具，而会使用多种抽象语言从不同层次刻画系统的结构与行为。拓扑学、线性代数与统计物理，正是其中最为基础、也彼此互补的三种理论框架。它们并非彼此替代的技术路线，而是从不同分辨率、不同系统层级出发，回答关于复杂系统的不同核心问题。\n赵思怡\n丨作者\n金威、诸葛昌靖\n丨审校\n系统观的出发点：复杂系统不是“对象”，而是“关系与过程”\n系统科学的一个基本立场是：复杂系统的本质不仅在于组成元素本身，而在于子系统和元\n素之间、系统与环境的关系、关系的组织方式，以及这些关系随时间不断演化的过程。\n因此，研究复杂系统并不是简单地描述“对象长什么样”，而是要在不同抽象层次上刻画结构约束与动力学机制。\n从这一立场出发，复杂系统研究通常需要回答三类根本性问题。第一，在忽略大部分定量细节之后，系统主要能提取出哪些不可消除的整体结构，\n这是\n系统的结构\n方面；\n第二，在既定结构下，系统状态如何演化，其中哪些模式占主导地位，\n这与\n系统及其状态的表示和运算\n有关；\n第三，当系统包含大量相互作用单元时，为何仍会涌现出稳定模式、临界行为或突变现象，\n这则涉及涌现，以及\n系统各层次\n之间的关系\n。\n正是在这三类问题上，拓扑学、线性代数与统计物理分别发挥了不可替代的作用。\n拓扑学：系统最粗粒度的“结构骨架”\n在系统科学与复杂科学中，拓扑学主要用于刻画系统整体结构的稳定性与全局组织方式，尤其关注在噪声、扰动、尺度变化或参数连续变化下，哪些性质能够保持不变。与依赖精确数值或度量的分析方法不同，拓扑学更加关注连接关系、邻近性、连通性以及回路、空腔乃至空间所对应的更深刻的代数对象等结构性特征。在系统“如何运行”之外，这些特征还从更根本的层面限定了系统“可以运行成什么样”。\n在具体研究中，网络模型常被用作表达这类结构关系的工具，但拓扑学的关注点并不局限于网络本身，而在于其背后的结构及其约束。通过拓扑视角，研究者可以判断系统是否整体连通，是否能够分解为若干相互弱耦合的子结构，以及信息、物质或影响能否在系统中长期传播等等。这些全局结构性质直接影响系统的健壮性、同步能力以及集体行为的形成方式。\n拓扑数据分析方法（如持久同调）在\n神经科学中，\n被用于从高噪声的神经活动数据中提取稳定的功能结构，从而区分不同生理、认知或行为状态下大脑活动的拓扑特征；在材料科学和凝聚态物理中，拓扑学则用于理解拓扑相变、拓扑材料与拓扑物态，解释为何某些宏观性质对局部缺陷和微扰具有高度稳定性，并从更加理论化的高度刻画各种物质状态及其相互关系。\n近年来，人们又用拓扑思想来研究复杂系统中的高阶相互作用与多体结构。传统模型（如经典的复杂网络）通常只描述成对关系，而高阶拓扑框架通过引入三角形、四面体等单纯形结构，刻画真实系统中普遍存在的多体协同行为。在这一视角下，系统的动态变量不再仅定义在节点上，\n也可以附着于边、三角形等高阶结构之上，形成所谓的“拓扑信号”。\n研究表明，这类高阶拓扑结构会显著重塑系统的动力学特性，催生出拓扑同步、复杂模式形成等新的集体\n现象，揭示了结构与动力学之间更为紧密的耦合关系。\n图 1 拓扑神经网路（详情请见\n集智俱乐部\n公众号文章\n《拓扑深度学习捕捉数据的高阶关系：信息传递拓扑神经网络概述》\n）\n更进一步的研究表明，拓扑结构与动力学过程之间还往往存在双向作用：一方面，拓扑结构限定了系统可实现的动力学模式与同步形式；另一方面，系统的演化过程也可能反过来改变其拓扑组织，使结构在时间中发生重构。这种“拓扑—动力学共演化”的视角，为理解大脑功能重组、气候系统振荡以及自适应人工系统等诸多复杂系统提供了重要线索。\n图 2. 拓扑Kuramoto模型与全局同步。（详情请见集智俱乐部公众号文章\n《Nat. Phys.速递：拓扑如何改写复杂系统动力学？》\n）\n系统科学视角下，拓扑学关注的是在纷繁复杂的具体数值细节背后，系统“内蕴空间”中决定作用的关于连通性与整体组织的定性信息。在复杂系统中，我们往往无法精确掌握每一个相互作用的强度或每一个单元的具体状态，但总会关心一些更根本的问题：系统是否连通？是否存在彼此隔离的子系统？信息或影响是否能够跨尺度传播？系统能否被分解为若干相对独立的功能模块？拓扑学正是以高度抽象而自然的方式回应这些问题。\n从系统观来看，拓扑学关注的是当我们忽略具体数值与微观机制之后，一个系统仍然保留下来的结构约束。它并不直接给出系统的演化方式，而是为后续分析划定了一个可能性空间——只有在这个空间之内，动力学模式才有意义，统计行为也才有讨论的基础。\n详情链接：\n拓扑学的思维革命：从空间直觉到系统科学|新课上线\n线性代数：系统状态的表示与可操作性\n在线性代数的视角下，复杂系统被理解为状态空间中的线性结构及其演化规律。尽管大量真实系统在微观层面本质上是高度非线性的，但线性代数仍然构成了人类目前最为成熟、最易理解、也最具操作性的分析语言之一。通过恰当的表示、投影与变换，复杂的非线性动力学常常可以在中尺度上被有效嵌入到线性框架之中，从而转化为可分析、可分解、\n可近似的线性过程。这种“以线性把握非线性”的策略在复杂系统研究中反复出现，并在理论建模、数据分析与数值计算之间起到了关键的枢纽作用，使我们即便无法完全掌控系统的全部细节，仍能抓住其主导结构与动力学特征。\n这种“以线性把握非线性”的策略在复杂系统研究中反复出现。以\nKoopman 算子理论\n为代表，线性代数被系统性地用于“线性化”非线性动力学系统。Koopman 算子本质上是作用在观测函数空间上的无限维线性算子，其谱结构编码了系统的全局动力学信息。通过对该算子进行谱分解，研究者能够识别系统中的慢模态、亚稳态结构以及主导时间尺度，从而在不依赖精确动力学方程的前提\n下，直接从数据中提取系统的内在组织方式。这一方法已广泛应用于分子动力学、流体力学、气候系统以及复杂网络等领域，并在非线性强、维度高、模型不完全已知的情形下展现出独特优势。\n图3：\n转移算子在不同领域的应用（详情请见\n集智俱乐部\n公众号文章\n《前沿进展：Koopman算子视角看动力系统和复杂网络》\n）\n随着数据驱动方法的发展，线性代数的这一思想进一步扩展为\n神经算子\n框架。与传统神经网络不同，\n神经算子\n直接学习函数空间之间的映射，本质上是在无限维空间中逼近系统的演化算子。以傅里叶神经算子为例，其通过谱展开与积分算子，将偏微分方程的全局结构编码进模型之中，从而在保持物理一致性的同时，实现高效的数值近似。这使得线性代数不仅是分析工具，也逐渐成为连接物理结构与机器学习的重要桥梁。\n图4：神经算子的输入和输出（详情请见集智俱乐部公众号文章\n《傅立叶神经算子：傅立叶变换应用于深度学习，顽强求解偏微分方程》\n）\n在复杂网络与系统动力学研究中，线性代数同样发挥着核心作用。图拉普拉斯算子、谱聚类方法以及振子网络的线性稳定性分析，使研究者能够理解网络结构如何约束集体动力学行为，例如同步、鲁棒性与相变等现象。通过谱结构，系统整体的稳定性以及对局部失效的敏感性得以被定量刻画，从而为神经网络、电力系统乃至生物节律系统的设计提供理论依据。\n从系统观来看，线性代数关注的核心问题在于：当复杂系统处于平衡态或参考态附近时，如何将决定其主要行为的关键信息有效刻画出来。借助线性化、谱分解和模态展开等手段，高维动力学得以投影到一个低维但信息高度集中的子空间中，使主导模式、慢变量和稳定方向清晰浮现。与关注全局结构约束的抽象视角、以及着眼于多体极限与统计规律的宏观视角相比，线性代数恰好工作在二者之间，为复杂系统提供了一种既可计算、又可理解、同时保留结构线索的中尺度描述——而这些线索，往往正是通向更深层结构与更大尺度规律的入口。\n详情链接：\n线性代数：一名合格科研人的筑基课丨新课上线\n统计物理：多体系统中的涌现与普适规律\n在系统科学与复杂科学中，统计物理提供了一种研究大量相互作用单元如何涌现出稳定宏观结构与功能的核心理论框架。其基本思想并非追踪单个自由度的精确演化，而是通过概率分布、能量景观与尺度变换，揭示系统整体行为的统计规律与普适性。这一视角已从传统物理系统扩展到生物系统、信息系统与智能计算等多个领域。\n在生命科学中，统计物理与人工智能的结合正在重塑结构生物信息学的研究范式。以 AlphaFold 为代表的深度学习模型推动蛋白质结构预测进入原子精度时代，并催生了覆盖数亿蛋白质结构的大规模数据库。在此基础上，统计物理方法得以从单个分子的动力学模拟，扩展到对海量结构数据的整体统计分析，从而揭示蛋白质结构、动力学、功能与进化之间的普适联系。大量研究发现，天然态蛋白质普遍呈现出长程关联和接近临界态的特征，其结构在稳定性与构象柔性之间维持着精细平衡。这种“临界附近”的物理性质，被认为是蛋白质高效执行复杂生物功能的重要基础。由此，统计物理为理解生命系统的鲁棒性、可塑性与可进化性提供了一套统一而深刻的理论语言，也为人工蛋白质设计和合成生物学提供了原则性指导。\n图5：基于AlphaFold数据库研究不同复杂度物种体内蛋白质结构与动力学的统计规律（详情请见集智俱乐部公众号文章\n《<合成生物学>期刊 | 唐乾元等：统计物理与人工智能驱动的蛋白质结构生物信息学》\n）\n在计算与工程系统中，统计物理同样成为处理复杂优化问题的重要思想源泉。许多组合优化问题可以被自然地映射为具有复杂能量景观的多体系统，其求解过程等价于在高维状态空间中寻找低能态或基态。近年来，自由能最小化、平均场理论以及退火机制被系统性地引入机器学习与计算框架，发展出如“自由能机器”等新型方法。这类方法通过变分自由能的梯度优化，在 GPU 等并行计算平台上高效求解大规模、含多体耦合的优化问题，不仅显著提升了计算效率，也在算法层面体现了统计物理思想对现代计算范式的深刻塑造。\n图6：FEM解决组合优化问题（COPs）的原理与框架（\n详情请见集智俱乐部公众号文章\n《Nature计算科学最新：统计物理x机器学习用于求解组合优化问题》\n）\n从系统视角来看，统计物理的核心贡献在于揭示：复杂系统的关键行为往往并不依赖于微观细节本身，而是由能量—熵平衡、相互作用结构以及尺度组织方式共同决定。无论是在蛋白质这样的生物分子系统中，还是在网络优化与人工智能等信息系统里，统计物理都为我们提供了一种理解“秩序如何从噪声中产生”“功能如何从多体耦合中涌现”的通用框架，使不同领域的复杂系统得以在同一理论视野下被比较、解释与统一。\n详情链接：\n李永乐的统计物理基础课\n系统观下的统一理解：多重视角描述同一复杂现实\n从系统科学的整体视角来看，拓扑学、线性代数与统计物理并非彼此孤立的理论工具，而是针对同一复杂系统在不同抽象层级上的互补描述方式。它们共同构成了一条由结构约束出发，经由动力学过程，最终通向宏观涌现的分析路径。这种跨层次、跨尺度的整合分析，正是复杂科学区别于传统还原论方法的核心特征之一。\n拓扑学限定了系统可能行为的结构边界；线性代数在这些约束之内提取出可操作的主导模式；统计物理则解释了这些模式为何能够在大量相互作用中稳定出现并长期存在。正是在这种多层次、跨尺度的系统观整合之下，复杂系统才不再只是“复杂”，而逐渐变得可理解、可预测、也可被设计。\n拓扑学课程：从空间直觉到系统科学\n你是否曾思考过：为什么咖啡杯在数学上可以变成甜甜圈？为什么混沌系统中会出现周期轨、可约化结构和“奇怪吸引子”模式？为什么神经网络、量子物理甚至心理结构，都可以从“拓扑”角度理解？\n拓扑学不仅是数学的抽象分支，更提供了系统的思维方式，让我们理解连续性、结构不变性乃至复杂系统的整体规律。从欧拉七桥问题到DNA的缠结，从量子场论到思维科学与脑科学，拓扑学思想正在各学科中普遍而深刻地重塑着我们的认知方式。\n集智学园联合北京大学博士金威老师开设\n「拓扑学的思维革命：从空间直觉到系统科学」\n，课程于11月23日开启，欢迎感兴趣的读者加入。\n详情请见：\n拓扑学的思维革命：从空间直觉到系统科学\n推荐阅读\n1.\n脑网络中的高阶拓扑结构\n2.\n拓扑深度学习捕捉数据的高阶关系：信息传递拓扑神经网络概述\n3.\nNat. Phys.速递：拓扑如何改写复杂系统动力学？\n4.\n系统科学前沿十讲：探究复杂世界演变背后的规则（二）\n5.\n集智学园精品课程免费开放，解锁系统科学与 AI 新世界\n6.\n高考分数只是张入场券，你的科研冒险在这里启航！\n7.\n加入集智字幕组：成为复杂科学知识社区的“织网人”\n点击“阅读原文”，报名读书会",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247724677&idx=1&sn=301b9448a93267fe9cf23ab7d8bc438b&chksm=e9e58cf36fceda74ca53e07bd7f3ceb1f54863033b666ff207fef004d80ac68a6b1cef4b40df&scene=0&xtrack=1#rd",
      "publish_time": 1767494640,
      "publish_date": "2026-01-04",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767655382,
      "last_modify_ts": 1767655382
    },
    {
      "id": 252,
      "article_id": "51686",
      "title": "PPoPP 2026 | Elastor：面向故障恢复的弹性模型切分与高效检查点",
      "description": "PPoPP是并行与高性能计算领域的CCF-A类国际会议，聚焦并行程序设计、系统与运行时等方向。第31届ACM SIGPLAN并行编程原理与实践研讨会（PPoPP）汇聚全球学者，探讨并行编程理论与实践的最新进展，涵盖编程模型、编译优化、并发控制及性能分析等关键议题，推动并行计算技术的发展与应用。",
      "content": "PPoPP（Principles and Practice of Parallel Programming）是并行与高性能计算领域的CCF-A类国际会议，关注并行程序设计、系统与运行时等研究方向。第31届“ACM SIGPLAN并行编程原理与实践研讨会”（ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPoPP '26）将于2026年1月31日至2月4日在澳大利亚悉尼召开，本次会议从280篇投稿论文中接收51篇，接收率为18.2%。\nPKU-DAIR实验室论文《Elastic and Efficient Model Partitioning and Checkpointing for Fault-Tolerant Distributed Training》被PPoPP 2026接收。\nElastor: Elastic and Efficient Model Partitioning and Checkpointing for Fault-Tolerant Distributed Training\n作者\n：Xuanyu Wang，Fangcheng Fu，Haoyang Li，Hao Ge，Sheng Lin，Jiawen Niu，Bin Cui\nGithub链接\n：\nhttps://github.com/PKU-DAIR/Hetu\n01\n背  景\n大模型训练离不开分布式：数据并行（DP）负责扩吞吐，张量并行（TP）/流水并行（PP）负责把超大模型拆到多张GPU上。但现实世界的集群并不“理想”：GPU宕机、节点掉线、网络故障会让可用GPU数量在训练中波动。如果系统只能按“整节点失败”去设计，一旦出现“部分GPU不可用”，要么浪费仍然健康的GPU，要么被迫长时间停机等待。更麻烦的是，训练策略一变（例如从32卡变成28卡、PP stage数和TP组大小都发生变化），检查点也随之变得难处理。很多框架按“当前并行策略切分参数”来存储权重，恢复时如果切分方式不同，就会出现冗余读取与重分片开销，在共享文件系统（如NAS）上尤其致命——I/O调用次数多、单次I/O延迟高，恢复速度很容易被拖垮。\n《Elastor: Elastic and Efficient Model Partitioning and Checkpointing for Fault-Tolerant Distributed Training》聚焦于以上两个问题：”当GPU/节点在训练过程中失效、可用GPU数量发生变化时，如何既能快速恢复训练，又不把时间浪费在反复的检查点保存/加载与重分片上”，并提供了创新的协同设计解决方案：一方面让模型切分足够弹性，能在任意数量GPU上恢复；另一方面让检查点足够“策略无关”，尽量避免因为切分变化而产生重复I/O，并把周期性检查点的额外开销隐藏到训练流水线里\n02\n方  法\nElastor的核心可以概括为四件事：弹性切分（HMP）、策略搜索、细粒度检查点、以及训练-保存的重叠优化。\n异构模型并行\n（\nHMP, Heterogeneous Model Parallelism\n）：当某些GPU失效时，系统仍能用剩余GPU继续训练。HMP允许不同DP rank内的TP组大小不一致，并在此基础上组织PP阶段与通信组，从而适配“非整除”的GPU数量。\n图1：异构模型并行切分方案\n恢复时的策略搜索\n（\nStrategy Searching\n）：当GPU数量变化后，Elastor会在候选的{DP, TP_max}组合中搜索合适的并行策略。其流程包含：①把可用GPU划分成若干TP组并分配给各DP rank；②在每个DP rank内部进一步决定层/数据如何分配，并通过微批（micro-batch）分配平衡不同rank的计算。在论文的模拟中，策略搜索在1024张GPU规模下也能在数秒内完成。\n图2：自适应策略搜索示意图\n细粒度、分片驱动的检查点\n（\nFine-grained Checkpointing via Splits\n）：将参数张量统一切成全局的global_split份（split），并保证任意HMP策略下每张GPU都持有整数个split。这样恢复时每张GPU只需要加载“自己负责的split”，避免了因切分变化导致的冗余读取。同时，Elastor用JSON元数据记录split与文件位置的映射，做到策略变化下仍能精确定位所需数据。\n图3: 细粒度、自适应模型切分\n高效保存/加载与重叠\n（\nOverlapping Training & Checkpointing\n）：保存过程被拆成GPU→CPU内存与CPU内存→文件系统两段，通过共享内存与多进程/多线程把参数搬运、序列化（Safetensors）和写盘解耦，并与训练计算流并行执行，尽量把检查点成本“藏起来”。加载阶段则通过重排与合并I/O，把大量小I/O尽可能合并为更少的顺序读取，降低共享文件系统上的开销。\n图4: 高效的异步存储方案和流水线\n03\n实  验\n论文在32张A100-40G的集群上评估Elastor：4台服务器每台8卡，机内NVLink带宽约600GB/s，机间InfiniBand带宽约200GB/s。文件系统使用NAS，单文件写入带宽约800MB/s、读取约1800MB/s，总带宽超过5TB/s。\n工作负载选择了3个LLM：LLaMA2-7B、LLaMA2-13B与Qwen2.5-32B；默认上下文长度4096，全局batch size为256。为了贴近真实环境，作者根据集群故障统计构造了5种GPU可用性轨迹（Case A-E），包括单GPU故障、多个节点内GPU故障、整节点掉线/断网、以及混合故障等。\n对比基线主要包括：FSDP2+PyTorch Distributed Checkpoint（DCP），以及Megatron配合不同检查点方案（如MCP与BCP）。实验从三个维度评估：训练效率、模型加载效率、以及模型保存效率。\n训练效率\n：在无故障（Case A）下，Elastor与强基线训练效率接近；当GPU数量动态变化（Case B-E）时，Elastor能更稳定地维持MFU，并在端到端训练时间上取得约1.12×–1.40×的加速。\n图5: 训练效率\n加载效率\n：由于检查点对并行策略更“无关”，且I/O合并更充分，Elastor在不同故障场景下的加载耗时显著降低，整体可达约1.95×–4.98×的加速。\n保存效率\n：通过训练-保存流水线化与线程解耦，模型保存阶段也获得约1.62×–3.94×的提升，降低了周期性检查点对长期训练的侵蚀。\n04\n总  结\nElastor把“弹性训练”往前推进了一步：不再只假设整节点失败，而是正面面对更常见的部分GPU不可用。它通过HMP让模型切分能适配任意GPU数量，又通过细粒度split把检查点做成策略无关，避免了恢复时的冗余I/O与重分片；最后再用重叠与I/O合并把检查点成本压到更低。\n对工程实践而言，这篇工作有两个启示：一是故障恢复能力要与并行策略的动态变化绑定考虑；二是检查点格式与加载路径的设计，往往比“写不写检查点”本身更决定系统能否在真实集群里跑得稳、跑得快。\nEND\n欢迎关注本公众号，帮助您更好地了解北京大学数据与智能实验室（PKU-DAIR），第一时间了解\nPKU-DAIR\n实验室的最新成果！\n实验室简介\n北京大学数据与智能实验室（Data And Intelligence Research Lab at Peking Univeristy，PKU-DAIR实验室）由北京大学计算机学院崔斌教授领导，长期从事数据库系统、大数据管理与分析、人工智能等领域的前沿研究，在理论和技术创新以及系统研发上取得多项成果，已在国际顶级学术会议和期刊发表学术论文200余篇，发布多个开源项目。课题组同学曾数十次获得包括CCF优博、ACM中国优博、北大优博、微软学者、苹果奖学金、谷歌奖学金等荣誉。PKU-DAIR实验室持续与工业界展开卓有成效的合作，与腾讯、阿里巴巴、苹果、微软、百度、快手、中兴通讯等多家知名企业开展项目合作和前沿探索，解决实际问题，进行科研成果的转化落地。",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzkzODMxNTkzNg==&mid=2247485111&idx=1&sn=48503a6ee8ddcb86c2183555c24dea96&chksm=c3d7f5a63b08c85c4192015d2569f041ce52c25f41cbfa4c008008f9f25c11e20fa3e40fb09b&scene=0&xtrack=1#rd",
      "publish_time": 1767715800,
      "publish_date": "2026-01-07 00:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/PKU-DAIR/Hetu\"]",
      "add_ts": 1767741546,
      "last_modify_ts": 1767914530
    },
    {
      "id": 254,
      "article_id": "51684",
      "title": "众智FlagOS 1.6发布，以统一架构推动AI硬件、软件技术生态创新发展",
      "description": "2026年1月5日，北京智源人工智能研究院在“2026北京人工智能创新高地建设推进会”上发布众智FlagOS 1.6系统软件栈，支持多种AI芯片。该软件栈聚焦解决硬件生态割裂、开发效率低和应用落地难等问题，通过技术创新提升自主算力生态的成熟度与产业化水平，并启动系列生态建设行动，推动AI研发加速与硬件架构深度协同，助力北京建成国际人工智能创新高地。",
      "content": "2026年1月5日，“2026北京人工智能创新高地建设推进会”在中关村国际创新中心举行。会上，北京智源人工智能研究院正式发布面向多种AI芯片的系统软件栈 —— 众智 FlagOS 1.6，并同步启动生态建设系列行动。直面硬件生态割裂、开发效率不足和应用落地难等行业痛点，众智FlagOS通过进一步技术创新，加快生态使能、深化硬件架构感知、加速AI赋能研发，为自主算力生态的规模化成熟与产业化落地夯实基础。\n智源研究院副院长兼总工程师林咏华表示，FlagOS 1.6 推动 AI 系统软件迈入“一次开发、跨芯片运行、多框架支持”的新阶段，使开发者能够更专注于模型与应用创新。通过统一框架插件、算子自动生成、编译器新语言扩展、和FlagOS具身智能框架（FlagOS-Robo）等关键突破，FlagOS 正在整合算力与开源生态，加速 AI 从实验室走向规模化应用。\n1\n核心发布：\nFlagOS1.6能力全方位跃升\n当下，人工智能从芯片到应用快速创新，AI芯片架构持续升级，3D堆叠、存算一体等新设计不断涌现，系统架构也进入以多样互联与混合算力为特征的超节点阶段。强化学习、世界模型、具身智能等方向推动模型持续迭代，随之而来的新型算子需求日益增长，开发工具与语言也需相应演进。AI智能体与具身智能等正成为应用创新的焦点。这些从芯片硬件到应用场景的快速演进，无一不对处于关键“中间位”，起到“承上启下”作用的AI系统软件提出了更多的技术需求和更大的创新挑战。\n为了应对这样的技术新趋势，众智FlagOS专注于加快生态使能、深化架构感知、加速AI赋能的创新，推出FlagOS 1.6 为开发者提供更易适配、更高性能、更快迭代的一体化工具链，同时支持具身智能模型研发，推动AI开发模式从“适配硬件”转向“模型创新”。\n框架FlagScale v1.0版本：一次开发，多芯运行\n破解生态割裂的“NxM”难题，FlagOS从解决“N种芯片生态”的统一，进入解决“M种框架/算法包的接入”的下半程。FlagScale v1.0通过多芯片统一插件方式，对框架/算法包实现非侵入式修改，极大降低适配成本，助力大模型Day0支持，保持用户使用习惯，无缝获得跨芯一致性结果。该框架为各种AI软硬件厂商提供了统一、标准化的接入机制，有效解决以往生态分散、版本不一的困境。\nKernelGen 1.0：全球首个支持多芯片的算子自动生成平台上线，开发进入“分钟级”\n全球首个支持多种AI芯片的 Triton 算子自动生成平台 KernelGen 1.0 正式发布\n，突破传统 copilot 仅生成代码、不保证效果的局限，实现从需求理解、算子生成、正确性验证及加速比评测的全生命周期自动化。开发者一次描述即可完成生成与评测，全流程仅需 2 分钟，50% 生成算子在同等算力下性能达到或超过 CUDA 原生算子。基于 FlagOS 技术栈，KernelGen 1.0 已支持英伟达、摩尔线程、华为、海光、天数等多种芯片，实现跨芯片生成与多端验证，显著降低算子适配与优化成本，加速算子生态的规模化共建。\n在 KernelGen 1.0 的辅助下，\nFlagGems总规模扩容至363个高质量算子\n，涵盖正式发布的230个算子，及首批机器自动生成的133个算子。FlagGems作为全球最大的 Triton 算子库，其中82%以上的Triton算子与CUDA原生算子性能平齐或超过，并已支持10多种AI芯片。\n编译器FlagTree v0.4：探索Triton的新语言，让算子优化更简单\nFlagTree升级推出\nTriton语言扩展（TLE）的预览版\n，通过分层设计在易用性与极致手写优化之间取得平衡，覆盖从初级到高级不同程度开发者的多样化需求。以中级开发者使用的基础原语扩展为例，关键算子性能提升超过 10%；在多芯片高效运行时，已支持 Nvidia、华为昇腾、摩尔线程和天数等平台，关键算子性能可进一步提升 20% 以上，大幅降低了多芯片适配与算子优化的技术门槛。\n从数据到模型的落地路径，具身智能一体化工具链\n本次推进会上，智源研究院以RoboBrain2.5为案例，展现了FlagOS作为国产软件栈，如何整合国产芯片、推进国产\n具身大脑基础模型RoboBrain2.5的研发。RoboBrain2.5 在全面继承2.0版本通用感知、空间推理和时序建模三大核心能力的基础上，通过融合更大规模、更高质量的训练数据集，于\n3D空间理解和时序价值预测\n两大维度实现了能力跃升。\n为系统性地降低具身智能研发门槛高、技术链路长的挑战，FlagOS1.6专门推出\nFlagOS-Robo版本\n，覆盖数据加载、模型训练、推理到具身评测的全流程工具链，显著降低开发复杂度。基于此，智源同步上线\nRoboXStudio具身智能一站式平台\n，实现从具身数据采集、标注到模型训练的全链路贯通，大幅提升“数据-模型”的闭环迭代效率。通过标准化、自动化的体系化支持，该架构为具身智能的快速验证与规模化落地奠定基础，加速其从实验室走向产业应用。\n2\n生态共建：产学研用全面落地\n实现技术突破的同时，众智FlagOS 生态建设也在持续推进。本次大会上，智源研究院理事长黄铁军代表研究院与多家重点企业机构达成生态合作，共同推动人工智能基础设施的规模化部署与产业化落地。\n智源与焕新社区联合共建 “众智 FlagOS 创新试验场” ，支持基于FlagOS的模型研发部署、课程教学和应用大赛等各类研发实验与社区活动，促进FlagOS生态成熟；与浪潮信息联合面向万亿参数大模型推理场景展开联合优化，推出基于众智FlagOS的大模型推理优化方案，显著提升推理效率与性价比；与清微智能基于众智FlagOS打造可重构超节点标杆产品，实现FlagOS与4K可重构超节点的全面适配与深度部署；\n与软通动力基于众智FlagOS发布集成部署全栈创新方案，打造“软件服务包”。\n众智FlagOS产业合作签约仪式，从左至右：浪潮集团副总裁、浪潮北京市公司总经理蒋永昌，中国移动集团首席科学家冯俊兰，北京智源人工智能研究院理事长黄铁军，清微智能CEO王博，软通集团首席AI官金亚东\n会上还启动了FlagOS开放计算全球大赛，智源与合作方一起为全球算法英雄和工程技术高手搭建施展才华的舞台，携手推进开放计算生态发展。\n由众智FlagOS社区、智源研究院、中国计算机学会（CCF）联合发起的“FlagOS开放计算全球大赛”正式启动，在Kaggle和魔搭双平台上线\n面向未来，众智FlagOS 将坚持做面向多种AI芯片的系统软件栈，持续以开源开放为核心，汇聚全球产学研力量，构建统一、高效、可持续的 AI 软件与算力基础设施。我们诚挚地邀请全球的开发者、研究人员以及产业伙伴，关注并加入到FlagOS的开源建设中来，为智能时代构建一个更加坚实、开放的智算底座。\n阅 读 更 多",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI2MDcxMzQzOA==&mid=2247548615&idx=1&sn=f765c437e806de72f82c8d54cf020ef2&chksm=eba5ecacf191812424148bf997bbe5c49db0d55dcb0a74f85b267e4e411f6151f137fb14cb70&scene=0&xtrack=1#rd",
      "publish_time": 1767708600,
      "publish_date": "2026-01-06 22:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767741553,
      "last_modify_ts": 1767828022
    },
    {
      "id": 255,
      "article_id": "51683",
      "title": "黄仁勋最新演讲：5项创新加持，Rubin性能数据首曝；多样化开源，覆盖Agent\\u002F机器人\\u002F自动驾驶\\u002FAI4S",
      "description": "CES 2026在拉斯维加斯开幕，英特尔、AMD、高通、英伟达等科技巨头纷纷亮相。英特尔发布酷睿Ultra第3代Panther Lake处理器，AMD推出基于Zen5架构的Ryzen新芯片，高通展示骁龙X2 Elite系列进展。黄仁勋虽未列入官方演讲名单，但在NVIDIA LIVE中重磅发布Rubin平台，涵盖Nemotron、Cosmos、Alpamayo、Isaac GR00T和Clara五大...",
      "content": "新年伊始，素有「科技春晚」之称的 CES 2026（Consumer Electronics Show，国际消费电子展）在美国拉斯维加斯拉开序幕。除了具身智能、人形机器人、自动驾驶等仍然占据核心展示位置之外，作为新芯片亮剑的重要秀场，英特尔、AMD、高通、英伟达等厂商之间的激烈角逐也是 CES 上的重头戏。\n根据各方爆料，英特尔计划在 CES 上正式发布 Panther Lake 处理器，即酷睿 Ultra 第 3 代。高通将展示骁龙 X2 Elite 和骁龙 X2 Elite Extreme 平台在 PC 上的最新进展。AMD CEO 苏姿丰则是计划在 1 月 5 日晚的主题演讲中发布新版 Ryzen 芯片，例如近期曝光的 Ryzen 7 9850X3D、基于 Zen 5 架构的 Ryzen 9000G 系列。\n黄仁勋虽然并未出现在 CES 官方 Keynotes 演讲名单中，但仍在到处赶场站台，尤为值得关注的便是其在 NVIDIA LIVE 中的个人演讲，安排在了北京时间 1 月 5 日凌晨 5 点。外界猜测，老黄将披露 Rubin 平台的最新进度，以及围绕 Physical AI、智能驾驶的相关进展。\n黄仁勋也并未令业界失望，在刚刚结束的演讲中，\n身着标志性黑色皮衣的老黄进一步介绍了这个引入了 5 项创新的 Rubin 平台，并发布了多项开源成果。\n具体而言：\n* 面向 Agentic AI 的\nNVIDIA Nemotron\n系列\n* 面向 Physical AI 的 NVIDIA Cosmos 平台\n* 用于自动驾驶研发的 NVIDIA\nAlpamayo\n系列\n* 面向机器人领域的 NVIDIA Isaac GR00T\n* 服务于生物医药领域的 NVIDIA Clara\n5 项创新加持，Rubin 恰逢其时\n「当前训练和推理的 AI 计算需求正急剧攀升，Rubin 的问世恰逢其时」，\n黄仁勋对 Rubin 平台寄予厚望，并表示 Rubin 已全面投产，预计于 2026 年下半年正式送达首批用户手中。\n聚焦到平台性能方面，Rubin 平台在 6 款芯片之间实现了「极致协同设计（extreme codesign）」，包括 NVIDIA\nVera CPU\n、NVIDIA Rubin GPU、NVIDIA NVLink 6 交换芯片、NVIDIA ConnectX-9 SuperNIC、NVIDIA BlueField-4 DPU 以及 NVIDIA Spectrum-6 以太网交换机。基于此，相比 NVIDIA Blackwell 平台，\n其可实现推理阶段每 token 成本最高降低 10 倍，以及训练 MoE（混合专家）模型所需 GPU 数量减少 4 倍。\n其中，NVIDIA Spectrum-6 Ethernet 是面向 AI 网络的下一代以太网，采用 200G SerDes、共封装光学和 AI 优化网络架构，为 Rubin AI 工厂提供更高效率和更强韧性。基于 Spectrum-6 架构的 Spectrum-X 以太网光子交换系统，在实现 5 倍能效提升的同时，提供 10 倍可靠性和 5 倍更长运行时间。\n根据官方介绍，Rubin 平台引入了 5 项创新：\n* 第六代 NVIDIA NVLink\n为大规模 MoE 模型提供高速、无缝的 GPU-GPU 通信。单 GPU 带宽达 3.6TB/s，Vera Rubin NVL72 机架总带宽达 260TB/s，超过整个互联网的总带宽。NVLink 6 交换芯片内置网络计算能力，加速集合通信，并在可维护性与韧性方面引入新特性，使大规模 AI 训练和推理更快、更高效。\n* NVIDIA Vera CPU\n专为智能体推理设计，是大规模 AI 工厂中能效最高的 CPU，采用 88 个 NVIDIA 自研 Olympus 核心，全面兼容 Armv9.2，并支持超高速 NVLink-C2C 互连，为现代数据中心工作负载提供卓越性能、带宽和行业领先的能效。\n* NVIDIA Rubin GPU\n搭载第三代 Transformer Engine，并支持硬件加速的自适应压缩，在 AI 推理中可提供 50 PFLOPS 的 NVFP4 计算性能。\n* 第三代 NVIDIA 机密计算\nVera Rubin NVL72 成为首个在机架级实现 NVIDIA 机密计算的平台，在 CPU、GPU 与 NVLink 全域内保障数据安全，保护全球规模最大的专有模型及其训练和推理任务。\n* 第二代 RAS Engine\n覆盖 GPU、CPU 和 NVLink 的实时健康监测、容错和预测性维护机制，最大化系统生产力；模块化、无缆托盘设计使组装和维护速度相比 Blackwell 提升最高可达 18 倍。\n同时，Rubin 平台引入了 NVIDIA 推理上下文内存存储平台，这是一种全新的 AI 原生存储基础设施，旨在实现千兆级规模的推理上下文扩展。该平台由 NVIDIA BlueField-4 驱动，可在 AI 基础设施中高效共享和复用 KV Cache 数据，在提升响应速度和吞吐量的同时，实现可预测、低功耗的智能体 AI 扩展。\nRubin 平台虽仍未真正走出工厂，但已经得到一众大佬的站台支持，在 NVIDIA 官方发布的 blog 中，OpenAI CEO Sam Altman、Anthropic CEO Dario Amodei、Meta CEO Mark Zuckerberg、以 xAI CEO 身份亮相的 Elon Musk 以及微软、谷歌、AWS、戴尔等科技大厂的掌舵人均带来了极高评价——马斯克直言，\n「Rubin 会再次向世界证明，NVIDIA 是行业的黄金标准。」\n多样化开源：Agent、AI4S、自动驾驶、机器人\n除了备受关注的 Rubin 平台外，「开源」是黄仁勋本次演讲的另一重要关键词。\n首先是面向 AI Agent 的 NVIDIA Nemotron。在此前发布的 NVIDIA Nemotron 3 开放模型与数据基础上，NVIDIA 进一步推出了面向语音、多模态检索增强生成（RAG）和安全性的 Nemotron 模型。\n* Nemotron Speech\n由多款在榜单中排名领先的开放模型组成，包括全新的 ASR（自动语音识别）模型，可为实时字幕和语音 AI 应用提供低延迟、实时语音识别能力。Daily 和 Modal 基准测试显示，其性能比同类模型快 10 倍。\n* Nemotron RAG\n包含全新的嵌入模型和重排序视觉语言模型（VLM），可提供高精度的多语言、多模态数据洞察，显著提升文档搜索和信息检索能力。\n* Nemotron Safety\n用于增强 AI 应用安全性和可信度的模型体系，现已包括 Llama Nemotron 内容安全模型（支持更多语言）以及 Nemotron PII，后者可高精度识别敏感数据。\n其次，面向 Physical AI 和机器人领域，NVIDIA 更新了 Cosmos 系列模型：\n* Cosmos Reason 2\n全新的、在榜单中排名领先的推理型 VLM，帮助机器人和 AI 智能体在物理世界中实现更高精度的感知、理解与交互。\n* Cosmos Transfer 2.5 与 Cosmos Predict 2.5\n可在多样化环境和条件下生成大规模合成视频。\n基于 Cosmos，NVIDIA 还针对不同物理 AI 形态发布了开源模型：\n* Isaac GR00T N1.6\n一款面向人形机器人的开放推理型视觉-语言-动作（VLA）模型，实现全身控制，并借助 Cosmos Reason 提升推理与上下文理解能力。\n* 视频搜索与摘要 NVIDIA Blueprint\n隶属于 NVIDIA Metropolis 平台，为构建视觉 AI 智能体提供参考工作流，可分析大量录制与实时视频，以提升运营效率和公共安全。\n第三，针对自动驾驶行业，其全新开源了 NVIDIA Alpamayo ——包含开源模型、仿真工具和大规模数据集:\n* Alpamayo 1\n首个面向自动驾驶车辆（AV）的大规模推理型 VLA 开源模型，使车辆不仅能够理解环境，还能解释自身行为。\n* AlpaSim\n一个开源仿真框架，支持在多样环境和复杂边缘场景中，对推理型自动驾驶模型进行闭环训练与评估。\n此外，NVIDIA 还发布了 Physical AI 开放数据集，包含 1,700 多小时来自全球最广泛地理区域和环境条件的真实驾驶数据，覆盖大量罕见且复杂的现实世界边缘场景，对推进推理架构至关重要。\n最后，面向 AI4S 领域，NVIDIA 推出了 Clara AI 模型，包括了：\n*\nLa-Proteina\n支持设计大规模、原子级精度的蛋白质，用于科研和药物候选开发，为研究以往被认为「不可治疗」的疾病提供新工具。\n*\nReaSyn v2\n在药物发现过程中引入制造蓝图，确保 AI 设计的药物具备可合成性。\n* KERMT\n通过预测药物与人体的相互作用，在早期阶段提供高精度的计算安全性测试。\n* RNAPro\n通过预测 RNA 分子的复杂三维结构，释放个性化医疗的潜力。\n此外，NVIDIA 还发布了包含 45.5 万个合成蛋白质结构的数据集，帮助研究人员构建更精准的 AI 模型。\n结语\n当拉斯维加斯的聚光灯再度投向 AI、指向底层硬件支撑，无论是黄仁勋侃侃而谈的 Rubin 平台，亦或是苏姿丰将于今晚揭晓的重磅新品，都不仅仅是在发布一代芯片或一次性能跃迁，更像是在为下一阶段的 AI 发展划定边界：算力如何被组织、成本如何被压缩、模型如何真正走向推理、Agent 与现实世界如何深度耦合。\nCES 2026 所呈现的，已不只是厂商之间的规格对决，而是一场围绕 AI 基础设施形态的集体选择。可以确定的是，竞争的重心，正在从模型本身，转向谁能更高效、更稳定地承载智能的规模化落地。\n参考资料\n1.https://nvidianews.nvidia.com/news/rubin-platform-ai-supercomputer\n2.https://blogs.nvidia.com/blog/open-models-data-tools-accelerate-ai/\n内容中包含的图片若涉及版权问题，请及时与我们联系删除",
      "article_url": "https://hub.baai.ac.cn/view/51683",
      "publish_time": 1767707280,
      "publish_date": "2026-01-06 21:48",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://nvidianews.nvidia.com/news/rubin-platform-ai-supercomputer\", \"https://blogs.nvidia.com/blog/open-models-data-tools-accelerate-ai/\"]",
      "add_ts": 1767741556,
      "last_modify_ts": 1767828028
    },
    {
      "id": 258,
      "article_id": "51679",
      "title": "蚂蚁·安诊儿医疗大模型：正式开源并登顶权威医疗榜单",
      "description": "蚂蚁集团联合浙江省卫健委开源自研的蚂蚁·安诊儿医疗大模型，登顶全球权威医疗AI榜单。该模型具备复杂病例解读与健康科普能力，可提供类医生级专业建议，助力大众健康管理与临床决策提效。作为当前最大规模开源医疗大模型，其在专业性、实用性与可及性方面实现突破，推动AI赋能基层医疗与公众健康服务，展现人工智能在医疗领域的深度应用前景。",
      "content": "新智元报道\n编辑：艾伦\n【新智元导读】\n医疗健康领域的AI应用迎来「最强大脑」！蚂蚁·安诊儿医疗大模型正式开源，专业能力登顶全球权威榜单。从复杂病例解读到日常健康科普，它能为大众提供专业医生般的解答，也能助力医生更高效精准做临床判断。AI 技术如何让健康守护更简单？快来看看这个最大规模开源医疗模型背后的故事！\n近日，蚂蚁集团联合浙江省卫生健康委正式开源其自研的蚂蚁·安诊儿医疗大模型（AntAngelMed）。\n该模型基于蚂蚁百灵大模型的高效混合专家（MoE）架构，结合真实、全面的医疗数据深度训练而成，是迄今为止\n参数规模最大的开源医疗模型（100B 总参数）\n。\n用户价值：领先的医学能力\nAntAngelMed 已在 OpenAI 发起的\nHealthBench\n和国家人工智能应用中试基地（医疗）的\nMedAIBench\n等评测基准中表现出色，树立了开源 AI 医疗模型「高效、专业、安全」的新标杆。\n在由 OpenAI 主导、全球 262 名医生参与构建的 HealthBench 评测中，\nAntAngelMed 在 HealthBench 上的评分达到开源模型第一，\n超过 DeepSeek-R1、Qwen3、OpenAI GPT-OSS 等模型，并且在极具挑战性的 HealthBench-Hard 子集上展现出尤为显著的优势，充分证明了其在真实、复杂医疗环境中的可靠性与专业性。\nHealthBench\n在由国家人工智能应用中试基地（医疗）·浙江联合中国医学科学院北京协和医学院、中国信息通信研究院三方共建的权威测评体系 MedAIBench 中，AntAngelMed 同样展现出强大的综合专业性与安全性，在医疗知识问答、医疗伦理安全等多个核心维度表现突出。\nMedAIBench\n这种「通用智能+医疗专长」的全栈能力闭环，标志着开源 AI 医疗模型进入了「高效、专业、安全」三者兼顾的新阶段，为 AI 技术在医疗领域的应用树立了新的标杆。\n对于面向中文医疗场景医疗大模型评测体系 MedBench（36 个自主评测集，覆盖约 70 万条样本），AntAngelMed 位列评测榜单第一，在医学知识问答、医学语言理解、医学语言生成、复杂医学推理、医疗安全与伦理五大核心维度也都表现出领先水平，体现出 AntAngelMed 医疗大模型的专业性、安全性与临床适用性。\nAntAngelMed 在 MedBench 上排名评测榜单第一\n技术解析：三阶段专业训练\nAntAngelMed 卓越的医疗能力源于其专业、精细的\n三阶段训练流程\n。\n首先，通过\n持续预训练\n对通用基座模型 Ling-flash-base-2.0 注入大规模、高质量的医学语料，构建了深厚的医疗知识底蕴；\n随后，在\n监督微调\n阶段，通过多源异构的高质量指令数据，一方面强化了模型的通用核心思维链，另一方面针对医患问答、诊断推理等真实医疗场景进行深度适配；\n最后，AntAngelMed 采用先进的\nGRPO\n强化学习\n算法\n，并通过\n双阶段强化学习路径\n对模型能力进一步优化提升：首先以「推理强化学习」锻造其逻辑推理的核心能力，再以「通用强化学习」打磨其同理心与安全边界意识，最终实现了医疗专业性与人文关怀的高度统一。\n专业三阶段训练流程\n高效架构、高速推理\n作为蚂蚁在医疗AI领域的关键突破，AntAngelMed 大模型在模型架构设计、训练效率与推理性能上实现了技术引领。\nAntAngelMed 继承了百灵大模型 Ling-flash-2.0 的高效混合专家（MoE）架构，并在一系列核心设计上进行了全面优化，包括 1/32 激活比例、无辅助损失 + Sigmoid 路由策略、MTP 层及 Partial-RoPE 等。\n这些精细的改进使得模型相比同等规模的 Dense 架构实现了\n7 倍的效率提升\n。\n换言之，AntAngelMed仅需\n6.1B 激活参数\n，即可媲美约\n40B 稠密模型的性能\n，并在 H20 硬件上实现超过\n200 tokens/s\n的推理速度，展现了极致的性能与效率。\nLing-flash-2.0 模型架构\n技术团队还专为 AntAngelMed 进行推理加速\n，\n采用 FP8 量化 + EAGLE3 优化，在 32 并发场景下，\n推理\n吞吐量\n较 FP8 显著提升\n：\n在 HumanEval 提升 71%，GSM8K 提升 45%，Math-500 提升高达 94%，实现了推理性能与模型稳定性的深度平衡。\n使用体验：推理效果展示\n蚂蚁·安诊儿医疗大模型不管是在您身体抱恙需要诊断的场景，还是在平时生活中的健康管理场景，都可以使用，为您的健康保驾护航，相关能力可通过模型调用在下游应用中快速上线。\n症状/疾病诊治类\n提问：为什么肝硬化切除部分肝脏的手术要做肝癌的检查，肝硬化肝腹水等于肝癌吗？做肝癌检查的目的是什么？\n思考过程：\n嗯，用户问为什么肝硬化做部分肝切除时要检查肝癌，肝硬化和肝腹水是不是等于肝癌，还有检查的目的。\n首先得理清楚这几个概念的关系。\n肝硬化本身是肝脏结构改变，纤维化导致结节形成，常见原因有病毒、酒精或者脂肪肝这些。\n肝腹水是肝硬化晚期的并发症，因为门静脉高压和低蛋白血症引起的液体积累在腹腔。\n这两个都不等于肝癌，但肝硬化确实会增加肝癌风险，因为慢性炎症让肝细胞反复损伤修复，容易基因突变。\n接下来要解释为什么手术前必须查肝癌。\n肝硬化患者做部分肝切除的话，肝脏本来已经受损，再切掉一部分负担更重，万一藏着隐匿的肝癌，术后可能出现复发或者剩下的肝脏负担太大。\n所以术前检查像 AFP、超声、CT 这些，就是排除有没有肝癌，因为如果同时有癌而不知道，手术可能白做，甚至加速病情。\n还要说明肝癌和肝硬化的关系，不是直接等同，但肝硬化患者定期筛查很重要，因为早期发现肝癌治疗效果更好。\n用户可能担心检查会不会多余，或者以为做了肝硬化手术就不用防癌了，得强调即使不是所有肝硬化都会癌变，但风险高出很多，所以必须检查。\n另外得注意用户可能的误区，比如把肝腹水和肝癌混为一谈，其实腹水只是肝硬化的表现之一，不是癌症本身。\n但长期腹水可能和肝癌有关联，比如门脉血栓或肿瘤转移，但需要检查确认。\n最后总结检查的目的：确保安全手术，避免漏诊癌，准确分期，制定方案。\n可能还要提一下术后也要随访，因为肝硬化是持续恶化的风险因素。\n总之得用简单的话把逻辑理清楚，让用户明白为什么这些步骤必不可少。\n上下滑动查看更多\n回答：\n这是一个非常好的问题，涉及到肝硬化、肝癌、肝腹水等多个重要概念的关系，以及术前检查的必要性。\n我来一步步解释清楚：\n核心概念澄清\n1. 肝硬化 (Cirrhosis)：\n是什么？\n肝脏长期受到损伤（如病毒性肝炎：乙肝、丙肝；酒精性肝病；非酒精性脂肪性肝病；自身免疫性肝病等）后，正常的肝细胞被大量的\n纤维组织（疤痕）和增生的肝细胞结节\n所替代，导致肝脏\n结构破坏、质地变硬、功能严重下降。\n关键点：\n肝硬化本身不是癌症，它是一种\n终末期肝脏病的病理状态\n，是多种慢性肝病的共同结局。肝硬化患者的肝脏组织已经「变形」了，但还不等于已经发生了肝癌。\n2. 肝腹水 (Ascites)：\n是什么？\n是\n肝硬化发展到门静脉高压和低白蛋白血症\n后，\n腹腔腔内积聚了过量液体\n的一种\n并发症。\n关键点：\n肝腹水是\n肝硬化失代偿期的常见表现之一，\n是\n门静脉高压和低蛋白血症\n的结果。\n肝腹水本身不等于肝癌！\n它只是说明肝硬化已经很严重，肝脏功能严重受损，失去了维持体液平衡的能力。\n3. 肝癌 (Hepatocellular Carcinoma, HCC)：\n是什么？\n是起源于肝脏\n肝细胞\n的\n恶性肿瘤\n。在肝硬化患者中，肝细胞在长期慢性炎症、再生和修复的过程中，\n基因容易发生突变，癌变风险显著增高。\n关键点：肝硬化和肝癌密切相关，但不等同：\n大多数肝癌（尤其是最常见的类型——肝细胞癌）发生在\n肝硬化的基础上\n。\n可以说，肝硬化是肝癌最重要的危险因素和背景。\n但是，不是所有肝硬化都会发展成肝癌！\n肝硬化患者需要\n定期筛查\n是为了在\n癌变发生之前或早期\n发现它，以便及时治疗。\n也有一部分肝癌患者\n没有明显的肝硬化背景\n（例如某些病毒性肝炎直接导致肝癌，或少数非酒精性脂肪性肝病进展较快的情况），不过这种情况相对少见。\n为什么肝硬化患者要做部分肝切除术时，必须先做肝癌检查？\n当肝硬化患者（特别是需要做肝移植或复杂的部分肝切除手术时）必须排查肝癌，原因如下：\n1. 肝硬化患者是肝癌的高危人群：\n如前所述，肝硬化背景下，肝脏长期处于修复-损伤的循环中，癌变的概率远高于普通人群。术前不检查，\n很可能遗漏已经存在的早期肝癌。\n2. 保证手术安全和效果：\n如果同时存在未发现的肝癌：\n可能不适合做部分肝切除：\n医生需要评估剩余的肝脏（切除部分后剩下的肝）是否能负担起身体的代谢需求（功能足够），以及剩下的肝脏里\n是否还存在其他未被发现的微小癌灶。如果切除大块肝组织后，剩下的「安全」肝脏负担过重，或者体内已有隐匿癌灶，术后肝癌复发的\n风险\n会极高，\n导致手术白做甚至加速病情。\n可能导致错误的手术范围：\n例如，如果只发现一个明显的肿瘤块做切除，但没发现多发小癌灶，术后很快复发。\n术后管理困难：\n肝癌术后需要密切随访和可能的进一步治疗。如果术前不知道有癌，医生对术后方案就缺乏依据。\n肝功能储备评估：\n肝癌的存在本身可能影响对剩余肝脏功能的判断。肝癌有时会消耗大量营养，或肿瘤本身造成肝内血流改变。\n3. 决定手术方案：\n肝癌的\n数量、大小、位置\n是决定能否手术切除以及采用何种术式（单发、小病灶可能可以局切或多发、晚期可能不适合切除或需肝移植）的\n最关键因素之一\n。如果术前不知道有癌，就无法制定最合适的治疗方案。\n4. 排除转移：\n虽然原发肝癌在肝内常见，但术前检查（如胸部 CT、骨扫描等）有时也能发现远处转移，这对判断肿瘤分期和手术可行性至关重要。\n5. 为后续治疗提供依据：\n即使决定不立即手术切除（因为肿瘤小、数量多或位置不好），\n早期发现\n对后续选择\n局部消融、介入、TACE（栓塞化疗）、靶向、免疫\n等方案都\n必不可少\n。\n6. 肝移植的绝对指征（米兰标准等）：\n在某些符合严格标准的早期肝癌（通常要求单发<5cm或多发<3cm且总数≤3个，无血管侵犯和肝外转移）中，肝移植是根治性手段之一，但\n术前必须全面检查确认符合标准\n。如果术前没发现，术后会很快复发。\n「肝硬化肝腹水＝肝癌吗？」 答案非常明确：不是！\n肝硬化：\n是肝脏的结构性改变（纤维化+结节再生）。\n肝腹水：\n是肝硬化严重到一定程度后出现的一种\n并发症\n（门脉高压+低白蛋白血症导致液体漏入腹腔）。\n肝癌：\n是肝脏细胞发生了\n恶性转化\n，长出了\n肿瘤\n（可以是单个结节，也可以是多个）。\n它们是三种不同的\n疾病\n状态，但存在密切的关联：\n严重的\n肝硬化 + 肝腹水\n提示\n肝功能已经严重失代偿，\n此时\n肝脏合成功能显著下降、解毒能力减弱，\n为\n肝癌的发生创造了非常好的土壤\n（慢性炎症、再生活跃）。\n但是，\n肝硬化（无论有无腹水）本身不等于有肝癌。必须通过专门的肝癌筛查手段\n（如每 6 个月做一次肝脏超声 + 血清甲胎蛋白 AFP）才能判断。\n肝癌可以发生在没有明显肝硬化的肝脏上\n（相对少见），也可以\n在已经存在的肝硬化肝脏上发生\n（最常见）。\n肝腹水本身也不是肝癌的直接标志，\n但它预示着肝脏疾病非常严重，进展到一定程度后需要高度警惕肝癌的可能。\n做肝癌检查的目的（针对肝硬化/肝腹水患者）\n1. 早期发现肝癌：\n这是\n最主要、最核心的目的\n。在肝癌\n还很小、没有症状\n的时候（早期），通过肝脏超声和 AFP 等检查发现它，此时肿瘤通常\n可切除、可消融，治愈率非常高\n。晚期发现则预后很差。所以\n定期筛查是肝硬化患者延长\n生存期\n、提高生活质量的最关键措施之一。\n2. 评估当前肝脏状况和肝癌风险：\n帮助医生判断患者目前肝硬化的严重程度、是否有肝功能严重减退或门脉高压并发症（如腹水、脾大），从而更全面地评估患者整体状况和手术/其他治疗的可行性。\n3. 术前\n风险\n评估和规划（对于考虑手术的患者）：\n确认是否有需要处理的肝癌（以及数量、大小、位置）。\n评估剩余肝脏是否能耐受手术（如果切除包含肿瘤的部分）。\n判断是否符合肝移植的指征（如果同时有符合标准的肝癌）。\n排除可能影响手术或增加术后风险的合并症（包括隐匿的转移灶）。\n4. 排除其他可能混淆的\n疾病\n：\n有时肝脏上的占位不一定是肝癌，也可能是肝腺瘤、局灶性结节增生、血管瘤等，但\n在肝硬化背景下，首要排查的就是肝癌\n（因为危害最大、最常见）。\n5. 基线建立和随访：\n即使这次检查没发现癌，也建立了「正常」的参考值，以后每次随访就可以对比，及时发现微小变化（因为早期癌变可能信号微弱）。\n总结\n肝硬化 ≠ 肝癌，肝腹水 ≠ 肝癌。\n肝硬化是肝癌的\n高危背景\n，但不是所有肝硬化都会得癌；肝腹水是肝硬化\n失代偿的表现\n，同样不等于癌。\n肝硬化患者（无论有无腹水）都是肝癌的高危人群，必须定期进行肝癌筛查！\n(通常每6个月：肝脏超声 + 血清AFP)\n当肝硬化患者需要做包括部分肝切除在内的任何可能影响肝脏的重大手术时，术前必须全面评估是否存在肝癌（以及其他重要问题）\n：\n目的：\n确保手术是安全且有意义的（能去除问题且剩余肝功能足够）；避免在不知情的情况下进行可能无效甚至有害的手术；准确制定手术方案；排除禁忌症；作为后续治疗决策的重要依据。\n肝癌检查（特别是针对高危人群的筛查）是挽救生命的关键一步！\n早期发现早期治疗，肝癌是可以被有效控制甚至治愈的；而等到出现症状（如腹痛、消瘦、黄疸、腹水突然加重等）再检查，往往已经是中晚期，预后很差。\n因此，如果你或你认识的人有肝硬化或肝腹水，务必遵医嘱定期进行规范的肝癌筛查（超声+AFP），这是保护自己\n健康\n最重要的措施之一。\n不要因为觉得「没有症状」就忽视检查，早期肝癌常常是「无声的杀手」。\n手术前的彻底检查是为了确保每一步治疗都建立在准确信息的基础之上，最大限度保障安全和治疗效果。\n强烈建议：\n所有明确诊断为肝硬化的患者，都应在肝病专科医生的指导下，建立并严格遵守个体化的肝癌筛查和随访计划。\n上下滑动查看更多\n泛健康与生活方式类\n提问：早起就喝水能缓解便秘吗？\n思考过程：\n嗯，用户问早起喝水能不能缓解便秘。\n这个问题看起来挺常见的，但可能得仔细分析一下。\n首先得回忆一下便秘的基本知识。\n便秘有很多原因，比如饮食不均衡、喝水少、缺乏运动或者压力大等等。\n那早上喝水这个习惯，民间说法里确实经常提到，但科学上到底有没有依据呢？\n首先想到的是生理机制。\n人在睡了一觉之后，身体会脱水，因为呼吸和皮肤都在蒸发水分。\n这时候补充水分，可能有助于软化大便，让肠道更容易蠕动。\n不过，得考虑个体差异。\n比如，有些人可能效果明显，有些人可能没感觉。\n这时候需要解释清楚原理，但也要说明不是对所有人都有效。\n然后要区分「缓解」和「治疗」。\n如果只是偶尔的便秘，比如因为前一天喝水少或者饮食变化导致的，早起喝水可能有点用。\n但如果是长期慢性便秘，可能需要更全面的方法，比如增加膳食纤维、运动等等。\n这时候得提醒用户别只依赖喝水，避免耽误更严重的情况。\n还要注意水温和量的影响。\n太凉的水可能刺激肠胃，特别是对敏感的人。\n建议温水比较好，量的话一般说300-500毫升，但得看个人情况。\n一下子喝太多可能引起不适，所以得慢慢喝。\n另外，早起喝水还有其他好处，比如补充夜间流失的水分，促进新陈代谢，还能帮助排毒。\n但「排毒」这个概念比较模糊，可能需要委婉说明，实际是帮助身体正常运作而已。\n然后得考虑用户可能的误区。\n比如有人以为光喝水就能解决所有便秘问题，结果忽略了其他因素。\n这时候需要强调综合措施的重要性，比如饮食结构、运动习惯，甚至排便时间的固定也很重要。\n还要提醒特殊情况。\n如果长期便秘或者伴随其他症状，比如腹痛、便血，必须建议及时就医，排除器质性疾病。\n不能因为早起喝水没效果就忽视潜在问题。\n最后总结的时候，要肯定早起喝水的辅助作用，但说明它只是整体方案的一部分。\n避免绝对化的说法，用「可能有一定帮助」这样的表述更科学。\n可能还需要检查有没有遗漏的点，比如水的种类？\n白开水最好，咖啡或茶可能有利尿作用反而加重脱水？\n这些细节也要提到，让建议更全面。\n总之，结构应该是先讲原理，再讲怎么做有效，接着说明注意事项和局限，最后给综合建议。\n这样用户看起来比较清晰，也不会有误导。\n上下滑动查看更多\n回答：\n早起喝一杯水（通常建议喝温水）\n对缓解某些类型的轻度、暂时性便秘可能有一定辅助作用，但它并不是解决便秘问题的万能方法，效果因人而异，且不能替代综合的便秘管理措施。\n我们来详细分析一下：\n为什么早起喝水可能有助于缓解便秘（原理）\n1. 补充夜间水分流失：\n睡眠过程中，身体通过呼吸、皮肤蒸发等方式会持续流失水分，血液浓缩。清晨起床时身体处于轻度脱水状态，这可能会使大便在肠道内停留时间过长，水分被过度吸收而变干变硬，导致排便困难。喝一杯水可以迅速补充这部分流失的水分，稀释肠道内容物，使其更湿润、更易排出。\n2. 刺激胃肠反射：\n大量水分进入胃部可以刺激胃结肠反射（一种自然的生理反应，食物或液体进入胃后，会引起结肠收缩，促进排便）。对于习惯性在早晨有便意的人来说，起床后空腹喝水可能有助于「唤醒」这种反射，产生自然排便的冲动。\n3. 促进肠道蠕动：\n充足的水分是肠道正常蠕动所必需的。缺水时，肠道会吸收更多粪便中的水分来维持身体水分平衡，导致大便干结。补充水分有助于维持肠道内适当的湿度，使粪便更容易成形和通过。\n重要注意事项和局限性\n1. 效果因人而异：\n对于\n轻度、暂时性\n的便秘（比如因为前一天喝水少、吃得太精细、运动量突然减少、出差环境改变等引起的），早起喝水可能会感觉有帮助，让大便更通畅些。\n对于\n中重度、长期慢性便秘\n，或者由\n器质性\n疾病\n（如肠梗阻、肠道肿瘤、甲状腺功能减退、糖尿病神经病变、盆底肌功能障碍等）、\n药物副作用\n（如某些止痛药、抗抑郁药、钙片、铁剂等）或\n严重饮食结构不良\n引起的便秘，\n仅仅依靠早起喝水效果非常有限，甚至无效。\n这时候需要查明病因并进行综合治疗。\n2. 不是「特效药」：\n喝水只是解决便秘拼图中的一小块。\n单靠喝水，尤其是只靠早上喝一杯水，很难解决根本问题。\n3. 需要「足量+持续」：\n量要够：\n通常建议每日总饮水量在\n1500-2000 毫升\n左右（根据活动量、气候调整）。早上起床那杯水（100-300ml）只是全天总饮水量的开始，不能指望靠这一杯水就解决便秘。\n要规律：\n光是早上喝，晚上不喝，或者平时喝得少，临时抱佛脚，效果很差。需要养成全\n天均匀适量饮水\n的习惯。\n4. 水温与速度：\n建议喝\n温水\n（接近体温），避免喝\n凉水\n（可能刺激肠胃，引起不适）。不要\n一次性猛灌\n大量水（可能引起水中毒或加重心脏负担，尤其对老年人），小口慢饮即可。\n5. 需要结合其他措施：\n缓解和预防便秘，\n最有效的方法是综合性的：\n增加膳食纤维：\n多吃全谷物（燕麦、糙米）、蔬菜（绿叶菜、西兰花）、水果（带皮苹果、梨、火龙果、香蕉——注意未熟香蕉可能加重便秘）、豆类、薯类。目标是每天 25-30 克纤维。\n⚠️增加纤维的同时必须同时多喝水！否则纤维会吸收肠道水分，加重便秘！\n规律运动：\n特别是像快走、慢跑、瑜伽、促进腹部活动的运动，能刺激肠道蠕动。\n建立规律的排便习惯：\n每天固定时间（如早餐后）尝试排便几分钟，利用人体天然的「胃结肠反射」，即使没有便意也坐一会儿，帮助形成条件反射。\n切忌憋便！\n避免久坐：\n长时间坐着不动会减缓肠道蠕动。\n管理压力：\n长期紧张焦虑会影响肠道功能（肠易激综合征常见诱因）。\n必要时在医生指导下用药：\n对于顽固性便秘，可能需要短期使用温和的通便剂（如聚乙二醇、乳果糖）或医生处方的药物。\n总结与建议\n1. 可以尝试，但别抱过高期望：\n把「早起喝一杯温水」当作一个健\n康\n习惯的开始\n，而不是治疗便秘的特效方。对轻度、因夜间缺水引起的暂时性「憋住」的感觉，可能有点帮助。\n2. 关键在「持续喝」和「总量够」：\n不要只关注早上这一杯，要保证\n全天充足且规律\n的饮水（白开水是最好的）。观察自己大便是否变得柔软、不费力，是判断喝水是否有效的简单指标。\n3. 必须配合其他措施：\n单独靠喝水无法解决大部分便秘问题。\n务必同时重视增加膳食纤维摄入、规律运动和建立排便习惯。\n4. 注意特殊情况：\n如果便秘是\n突然出现\n的，程度\n非常严重\n（如超过 7-10 天完全不排便、腹痛、腹胀、呕吐、便血、黑便、体重不明原因下降等），\n请立即就医\n，排除急症或严重疾病。\n如果长期（超过 3 个月）、反复便秘，通过调整生活方式（饮食、运动、饮水、排便习惯）\n仍然没有改善，务必去看医生\n（消化内科或普通内科），找出根本原因，进行针对性治疗。\n结论\n早起喝一杯温水作为\n日常\n健康\n饮水习惯的起始步骤，是值得推荐的好习惯，\n可能对维持肠道基础水分状态和轻微促进晨间排便反射有\n辅助益处\n。\n但它\n不能作为治疗便秘的主要或唯一手段。\n解决便秘的黄金法则在于：均衡饮食（高纤维+适量\n健康\n脂肪+足够蛋白质）、足量饮水（全天的总量达标）、规律运动、定时排便、放松心情。\n如果便秘问题持续存在或严重，寻求专业医疗意见是最安全有效的选择。\n简单来说：可以喝（温水，适量），但别指望单靠它就解决所有便秘问题，更重要的是把「喝水」变成「全天的喝水习惯」，并同时做好其他几件事。\n如果调整后没改善，快去看医生！\n上下滑动查看更多\n开源开放：助力行业发展\nAntAngelMed 模型系列已在模型平台开源，可以访问开源仓库下载使用：\nHuggingFace：\nhttps://huggingface.co/MedAIBase/AntAngelMed\nModelScope：\nhttps://modelscope.cn/models/MedAIBase/AntAngelMed\nGitHub:\nhttps://github.com/MedAIBase/AntAngelMed\n蚂蚁集团始终致力于构建「可解释、可信赖、可落地」的医疗 AI 技术。\n此次蚂蚁·安诊儿医疗大模型的开源，是该理念的重要实践，旨在降低前沿医疗AI技术的应用门槛。\n未来，蚂蚁集团将依托国家人工智能应用中试基地（医疗），持续推进「AI + 医疗」的开源生态与技术创新，让顶尖技术普惠更多开发者与用户，共同助力国民健康事业。\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660905&idx=1&sn=e96dbc51d0c718fd5e8361818e2fee92&chksm=f0faa7ae508101f2fd26c55696d81ac5e33bbbca8e871c9271a5e168f193b45420e0a5936791&scene=0&xtrack=1#rd",
      "publish_time": 1767688800,
      "publish_date": "2026-01-06 16:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://huggingface.co/MedAIBase/AntAngelMed\", \"https://modelscope.cn/models/MedAIBase/AntAngelMed\", \"https://github.com/MedAIBase/AntAngelMed\"]",
      "add_ts": 1767741569,
      "last_modify_ts": 1767828038
    },
    {
      "id": 259,
      "article_id": "51678",
      "title": "华为开源7B多模态模型，视觉定位和OCR能力出色，你的昇腾端侧“新甜点”来了",
      "description": "华为推出开源多模态模型openPangu-VL-7B，专为端侧部署与个人开发者优化。该模型具备7B量级轻量化结构，适配图像信息抽取、文档理解、视频解析等高频场景，依托昇腾原生架构，在单卡Ascend设备上实现高效推理，显著提升性能与能效比，推动终端AI应用落地。",
      "content": "允中 发自 凹非寺\n量子位 | 公众号 QbitAI\n7B量级模型，向来是端侧部署与个人开发者的心头好。\n轻量化特性让它能灵活适配各类终端场景，而强劲性能又能覆盖图像信息抽取、文档理解、视频解析、物体定位等高频需求。\n刚刚，华为重磅推出\n开源新玩家openPangu-VL-7B\n，直接瞄准这一核心场景精准发力。\n昇腾原生的模型结构，让openPangu-VL-7B的推理性能极具性价比：\n720P图像在单张Ascend Atlas 800T A2卡上\n首字模型推理时延\n（ViT与LLM模型时延和）\n仅160毫秒\n，能够进行5FPS的实时推理；\n训练阶段的MFU更是达到42.5%\n。\n更值得关注的是，模型\n在预训练阶段完成了3T+tokens的无突刺集群长稳训练\n，为开发者使用昇腾集群提供了极具价值的实践参考。\nopenPangu-VL-7B\n在通用视觉问答、文档图表理解&OCR、视觉定位、短视频理解等核心任务上表现突出\n，在开源榜单中力压同量级模型，展现出强悍的综合实力。\n官方提供的cookbook也展现了模型在这些领域的优异能力。\n比如我们给模型一张菜品图，让模型找到一共有多少个樱桃番茄，模型能够点出所有的位置并正确计数。\n给模型一张年报截图，模型也能将其转变为markdown格式，省去了人工摘录的痛苦。\n除了亮眼的榜单成绩和针对昇腾的训推优化，\n技术报告中\n还披露了若干核心技术细节\n，揭秘模型高性能背后的设计巧思：\n1）适配昇腾的高性能视觉编码器\n业界传统视觉编码器多针对GPU架构设计，没有充分发挥昇腾硬件优势。\n团队通过大量先导实验与性能分析，\n找到模型结构的最优平衡点\n——相同参数量下，该视觉编码器在昇腾芯片上的吞吐较使用窗注意力的ViT-H系列编码器提升15%。\n同时，采用多标签对比学习框架，让模型具备更优的细粒度理解能力，为后续VLM训练中的视觉定位数据学习筑牢基础。\n2）样本均衡的损失设计\n为解决不同长度训练样本的学习均衡问题，openPangu-VL-7B\n创新采用 “加权逐样本损失+逐令牌损失” 的混合训练方案\n，加权系数由令牌位置和样本重要性动态决定。\n这一设计让模型在训练中既能吃透长回复数据，也不忽视短回复信息，避免 “顾此失彼”，消融实验已充分验证其有效性。\n3）带填充的定位数据格式\n区别于业界主流的0-999定位方案，openPangu-VL-7B\n采用000-999千分位带填充相对坐标完成视觉定位\n。\n整齐的三个token进行位置回归，不仅降低了模型学习难度，更显著提升了格式遵从性，让定位任务的精度和效率同步提升。\n此外，技术报告还深入探索了预训练数据配比、位置编码、模型融合等关键策略，\n为开发者提供了全面的技术细节参考\n。\n对于昇腾使用者而言，openPangu-VL-7B 的开源无疑是一大利好。\n这款兼具轻量化、高性能与强通用性的多模态模型，既为端侧开发和个人使用提供了新选择，也将进一步丰富昇腾生态的应用场景，为创新注入新动力。\n模型链接：\nhttps://ai.gitcode.com/ascend-tribe/openPangu-VL-7B\n技术报告：\nhttps://ai.gitcode.com/ascend-tribe/openPangu-VL-7B/blob/main/doc/technical_report.pdf\n*本文系量子位获授权刊载，观点仅为原作者所有。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860058&idx=2&sn=ec5212e280b96401abf9f60adff6142a&chksm=e9dd0ff71e99e3515989dafb7cfb0e8a2ccfcc99a622752c2ff51e9a23a11e17ecd36e71f22b&scene=0&xtrack=1#rd",
      "publish_time": 1767688440,
      "publish_date": "2026-01-06 16:34",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://ai.gitcode.com/ascend-tribe/openPangu-VL-7B\", \"https://ai.gitcode.com/ascend-tribe/openPangu-VL-7B/blob/main/doc/technical_report.pdf\"]",
      "add_ts": 1767741572,
      "last_modify_ts": 1767828041
    },
    {
      "id": 260,
      "article_id": "51677",
      "title": "DeepSeek-OCR是「长文本理解」未来方向吗？中科院新基准给出答案",
      "description": "新智元报道  编辑：LRST【新智元导读】DeepSeek-OCR的视觉文本压缩（VTC）技术通过将文本编码为视觉Token，实现高达10倍的压缩率，大幅降低大模型处理长文本的成本。但是，视觉语言模型能否理解压缩后的高密度信息？中科院自动化所等推出VTCBench基准测试，评估模型在视觉空间中的认知极限，包括信息检索、关联推理和长期记忆三大任务。近期，DeepSeek-OCR凭借其创新的「视觉",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\nDeepSeek-OCR的视觉文本压缩（VTC）技术通过将文本编码为视觉Token，实现高达10倍的压缩率，大幅降低大模型处理长文本的成本。但是，视觉语言模型能否理解压缩后的高密度信息？中科院自动化所等推出VTCBench基准测试，评估模型在视觉空间中的认知极限，包括信息检索、关联推理和长期记忆三大任务。\n近期，\nDeepSeek-OCR\n凭借其创新的「视觉文本压缩」（Vision-Text Compression, VTC）范式引发了技术圈的高度关注，\n以极少的视觉Token实现高效的文本信息编码，为长文本处理开辟了新路径。\n这一突破性进展让大模型处理超长文档的成本大幅降低，但也抛出了一个核心\n问题\n：\n当长文本被高度压缩为2D图像后，视觉语言模型（VLM）真的能理解其中的内容吗？\n为了解答这一疑问，来自中科院自动化所、中国科学院香港创新研究院等机构的研究团队推出了首个专门针对视觉-文本压缩范式的基准测试——\nVTCBench。\n论文链接：https://arxiv.org/abs/2512.15649\nVTCBench链接: https://github.com/Moenupa/VTCBench\nVLMEvalKit链接：https://github.com/bjzhb666/VLMEvalKit\nHuggingface链接: https://huggingface.co/datasets/MLLM-CL/VTCBench\n图 1：视觉-文本压缩 (VTC) 流程演示及VTCBench\n与传统大模型直接读取成千上万的纯文本Token不同，VTC范式（如\nDeepSeek-OCR\n）先将长文档\n渲染 （Rendering）\n为高密度的2D图像，再由视觉编码器转化为少量的\n视觉Token\n。\n该技术可实现\n2倍至10倍\n的Token压缩率，显著降低了长文本处理时的计算与显存开销。\nVTCBench现已在GitHub和Huggingface全面开源，其衍生版本VTCBench-Wild是一个统一的、全方位评估模型在复杂现实场景下视觉文本压缩的鲁棒性，现已集成到VLMevalkit。\n核心使命\n衡量「看得见」之后的「看得懂」\n目前的VLM也许能出色地完成OCR识别，但在处理 VTC 压缩后的高密度信息时，其长文本理解能力仍存疑。\nVTCBench\n通过三大任务，系统性地评估模型在视觉空间中的认知极限：\n1.\nVTC-Retrieval (\n信息检索\n)\n：\n在视觉「大海」中寻找特定事实的「针」（Needle-in-a-Haystack），测试模型对空间分布信息的捕捉能力。\n2.\nVTC-Reasoning (关联推理)\n：\n挑战模型在几乎没有文本重叠的情况下，通过关联推理寻找事实，超越单纯的词汇检索。\n3.\nVTC-Memory (长期记忆)\n：\n模拟超长对话，评估模型在视觉压缩框架下，抵御时间与结构性信息衰减的能力。\n此外，团队同步推出了\nVTCBench-Wild\n，引入 99 种不同的渲染配置（涵盖多种字体、字号、行高及背景），全方位检测模型在复杂现实场景下的鲁棒性。\n揭秘视觉压缩背后的认知瓶颈\n图 2：VTCBench针对模型在长图像中检索信息的热力图。横轴代表上下文长度，纵轴代表关键事实（Needle）在文档中的深度。展现了模型表现的「迷失」与突破。\n测试结果呈现出显著的\n「U 型曲线」\n：与文本模型类似，视觉语言模型（VLM）能够精准捕捉开头和结尾的信息，但对于\n中间部分\n的事实，理解能力会随着文档变长而剧烈衰退。这证明了即使在视觉空间，模型依然存在严重的「空间注意力偏见」，是未来 VTC 架构优化的关键方向。\n行业洞察\n视觉压缩是长文本的终局吗？\n通过对\nGPT、Gemini、Claude、QwenVL、InternVL、Gemma、KimiVL、Seed1.5\n等10余种尖端模型的深度评测，可以发现：\n虽然VTC极大提升了效率，但现有VLM在复杂推理和记忆任务上的表现仍普遍弱于纯文本LLM；\n消融实验证明，信息密度是决定模型性能的关键因素，直接影响视觉编码器的识别精度；\nGemini-3-Pro\n在VTCBench-Wild上表现惊艳，\n其视觉理解能力已几乎追平其纯文本基准\n，证明了VTC是实现大规模长文本处理的极其可行的路径！\n总结\n如果说传统的长文本处理是「逐字阅读」，那么DeepSeek-OCR所引领的VTC范式就是「过目成诵」的摄影式记忆。\nVTCBench\n的出现，正是为了确保模型在拥有这种「超能力」的同时，依然能够读懂字里行间的微言大义。\n参考资料：\nhttps://arxiv.org/abs/2512.15649\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660897&idx=2&sn=13772cf1ca4a5b7cbbaa855f60c04457&chksm=f0530b8a185563842a3021c3482be7156581377f04c0bba7daa6a474cca746bfda3db70fd7d5&scene=0&xtrack=1#rd",
      "publish_time": 1767688440,
      "publish_date": "2026-01-06 16:34",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.15649\", \"https://github.com/Moenupa/VTCBench\", \"https://github.com/bjzhb666/VLMEvalKit\", \"https://huggingface.co/datasets/MLLM-CL/VTCBench\"]",
      "add_ts": 1767741575,
      "last_modify_ts": 1767828044
    },
    {
      "id": 261,
      "article_id": "51676",
      "title": "AI破解500年《纽伦堡编年史》天书！仅用1小时，隐藏惊天真相被揭开",
      "description": "2026年初，Gemini 3.0 Pro仅用1小时、花费0.02美元算力成本，成功破解533年未解的《纽伦堡编年史》手写注释难题。该注释字迹残损且含大量中世纪缩写，困扰人类学者逾五个世纪。AI通过高精度识别与上下文推理，精准复原内容，揭示16世纪历法对账单细节，展现其在古籍破译中的强大能力，标志着AI以“全知视角”推动考古学进入智能新纪元。",
      "content": "新智元报道\n编辑：Aeneas 倾倾\n【新智元导读】\n2026开年王炸！Gemini 3.0 Pro仅用1小时，暴力破解533年未解的《纽伦堡编年史》天书。从0.02美元的算力成本到精准复原16世纪学霸的历法对账单，AI正以全知视角降维打击传统考古！\n就在刚刚，500年前的《纽伦堡编年史》天书，被AI破解了！\n其中的一段手写注释，难倒了人类历史学家整整500年。\n这些注释字迹残损严重，夹杂着大量中世纪拉丁文缩写，几个世纪以来，学者们始终无法解释它的含义。\n然而，Gemini 3.0 Pro仅在一个小时内，就清晰地给出了解读！\n它成功识别出：这段注释并非随意的标记，或者装饰性的涂画，而是与不同圣经年代学体系之间的比较和计算有关。\n也就是说，几百年前作者的逻辑，被AI精准地捕捉到，完成了整套推理！\n研究者们激动地在博客中写道——\n令人难以置信的是，LMM的视觉理解能力已经发展到Gemini 3 Pro能阅读 500 年前的手写缩写速记旁注，回过头去阅读整页印刷内容，并利用页面内容来推演和澄清速记的含义，然后将所有这些信息整合起来，得出一个能契合所有拼图碎片的最终理解，而这一切都不需要任何形式的人类协助！\n老祖宗的古籍，被AI破译了！\n《纽伦堡编年史》是一部出版于\n1493 年\n的世界史巨作。\n它不仅内容宏大，而且配有大量精美木刻插图，是一部试图囊括人类历史的早期百科全书，被视为早期印刷史上的重要经典。\n然而，在某一页的边缘，忽然出现了\n四个手绘的圆圈\n，里面写着一些密集的拉丁缩写和罗马数字。\n这些文字看起来既不像装饰，也不像批注，却又意味深长——一度让历史学家、古文字专家都难以确切解释其含义。\n几个世纪以来，学者们反复尝试解读这些标记，却总是卡在两个地方：潦草到近乎破碎的笔迹，以及高度压缩的拉丁文缩写。\n其中一个圆环，虽然能辨认出与基督相关的日期词首（Anno），但核心内容始终隐没在斑驳的墨迹中\n熟悉拉丁语的学者能读出一星半点，但要是放到1493年的神学体系里，即使是经验丰富的历史学者，也很难在没有大量比对的情况下给出确定结论。\n为了破解这个谜题，研究人员将这一页的高分辨率图像输入到\nGemini 3.0 Pro\n。\n奇迹般的一刻来了，Gemini 3.0 Pro给出结论——\n这些圆圈并不是随意涂写，而是某位古代读者试图调和《七十士译本》（希腊旧约）与《希伯来圣经》两种不同年代计算体系所做的笔记。\n具体来说，圆圈中记录的是两种计算方法下「亚伯拉罕出生年份」的不同结果，并将其换算为我们熟悉的公元前年代。这样一来，这位古代读者就把手写注释变成了一个跨体系的年代转换表。\n注意，在这个过程中，它不仅识别出了图像，还能理解了文字、推断了历史背景，分析出了背后的逻辑。\n也就是说，它结合了古文字学、年代学和神学史的多层背景，进行了严谨的推理。\n从几百年前的拉丁缩写开始，它就做到了连接当时的历史语境、年代体系，甚至涉及古代不同版本《圣经》的时间表。\n可以说，\nAI\n给出的解释链条严谨清晰，是目前为止首次令人信服的完整解释！\n可以说，这次Gemini 3.0 Pro 解读《纽伦堡编年史》圆形注释，是AI技术在历史人文解读上的重大成功。\n《伏尼契手稿》被称为「世界第一天书」，全书240页，文字系统未知，插图中包含着未知的植物，和奇怪的天文图。顶级语言学家、二战秘密学家都试图破解，但至今无人能成功破译。\n埃特鲁里亚文明是罗马文明前身，但《埃特鲁里亚文文献》只有字母可读，词义与语法却完全让人读不懂。\n其中，《利布尔·林特乌斯》干脆被称为「裹尸布书」。\n玛雅抄本（比如《德累斯顿抄本》）也是一大难题。虽然玛雅文字已经部分破译，但因为天文周期与神话高度交织，「神—时间—数字」的一体化难倒了众多历史学家。\n死海古卷中，包含大量未被纳入《圣经》的文本，这部「末世文献」挑战了我们熟悉的宗教叙事剧结果，因而极其难解。\n而现在，这些难解的古籍，或许在未来某一天，就能被AI破解！\nGemini破解三大难题\n在整个破解过程中，Gemini 3.0 Pro攻克了三大难题，淋漓尽致地展现出了AI模型的惊人能力。\n第一步：视觉识别，重现字迹\n首先，就是要知道这些「鬼画符」究竟写的是什么。\n然而，在扫描图像里，这些笔迹早已被时间侵蚀得支离破碎，墨水氧化、纸张老化，不少字符在人眼中几乎糊成一片。\nGemini重新拆解了每一笔的方向、粗细与残留痕迹。\n沿着种种细节，推断出这是一种带有人文主义时期特征的「运行草书」。\n更棘手的是，这些数字和缩写并不遵循严格的标准写法。\n中世纪的书写者往往会根据个人习惯压缩表达，省略结构，只留下自己能看懂的符号。\nGemini仍然捕捉到了这些不规范的速记习惯——比如将900写作「ix c」，而不是标准的「cm」。\n在这种微米级的识别精度下，AI得以从暗斑中打捞出「iii^m c lxxx iiii」（3184）这类肉眼难以辨认的符号。\n第二步：联系上下文，解读缩写\n不得不提的是，这位500年前的笔者思维也非常跳跃——他会将复杂的短语简化为An xpi这种代号。\n这可就苦了人类学者。他们需要翻阅大量文献，耗时数周进行人工比对之后，才敢推测其含义。\n但Gemini来解读时，它的思路就要高出人类好几个level了。\n在Gemini眼中，这些缩写不是孤立的。它会同时回看页面正文中出现的相关段落，把这些零散字符重新放回语境里判断含义。\n就这样，它不仅将缩写还原为Anno ante Christi incarnationem（基督降生前），还瞬间阅读了数千字正文。\n在完整上下文的支撑下，这些手写字符与亚伯拉罕生平的关系，逐渐变得清晰。\n当所有字符被逐一展开之后，一个更大的结构逐渐显现出来：这些圆圈是在计算、对照、核验。\n第三步：还原500年前的「赛博对账」\n在所有文字都破解后，Gemini发现，这四个圆圈实际上是一张「历法转换表」：\n左侧：提取正文中按《七十士译本》计算的亚伯拉罕出生年份AM 3184，并自动换算为2015 BC。\n右侧：提取按《希伯来圣经》计算的AM 2040，换算为1915 BC。\n在中世纪神学语境中，这类年代差异直接关系到圣经叙事的时间一致性，也影响着不同传统对历史真实性的理解。\n写下这些圆圈的人，显然是在为这种差异找到一个自洽的解释。\nGemini沿着笔者的思路，发现他通过这四个圆圈精准锁定了一个争议——两个版本的圣经在关键纪年上，正好存在100年的系统性偏差。\n就这样，这个500年难题破解了，而且Gemini的耗时不超过1个小时！\n这个过程所需的算力成本，也低到惊人。\n整个发现过程中最令人震惊的是：AI证明了自己不仅破解古籍中的文字，甚至能与几百年前的人逻辑共鸣！\n当然，这并不意味着谜题已经被「彻底解决」。\nGemini的这个答案，是一种高度一致的解释方案，但并非经学界验证过的结论。\n然而这次成功破解，意义却是颠覆性的。\n解释历史的角色，正在悄悄转变\nGemini 3.0 Pro 对《纽伦堡编年史》的破解，与其说是一次学术上的查漏补缺，不如看成是一场关于「解释权」的更迭。\n在传统认知里，解读孤本笔记是极少数精英学者的特权。\n他们需要花费数十年时间去习得拉丁语、古文字学、中世纪历法和神学逻辑，高昂的「时间成本」构成了历史研究的尊严与壁垒。\n然而，这种壁垒在Gemini面前，一击即碎。\n它提醒我们，在需要大规模检索与长链条推理的任务上，人类经验并不是最大优势。\nGemini 3.0 Pro，破解了人类对「未知」的恐惧与依赖。\n智能的本质是消除信息熵，而这一次，它将手伸向了时间深处。\n旧世界的静默文明，终于在数字时代开始清晰展现。\n那些淹没在时间长河中的细节，正在被重新点亮。\n接下来该如何解读它们，反而更考验人类自己。\n参考资料：\nhttps://siliconangle.com/2026/01/01/googles-gemini-3-0-pro-helps-solve-long-standing-mystery-nuremberg-chronicle/\nhttps://blog.gdeltproject.org/gemini-as-indiana-jones-how-gemini-3-0-deciphered-the-mystery-of-a-nuremberg-chronicle-leafs-500-year-old-roundels/\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660897&idx=1&sn=23976484871be7f5a196c4ec0db53a10&chksm=f0d0d8994618c3d17b80200ee2da587a7c2f116be96200a5c8060923a71bceadddaf886781c4&scene=0&xtrack=1#rd",
      "publish_time": 1767688320,
      "publish_date": "2026-01-06 16:32",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://siliconangle.com/2026/01/01/googles-gemini-3-0-pro-helps-solve-long-standing-mystery-nuremberg-chronicle/\", \"https://blog.gdeltproject.org/gemini-as-indiana-jones-how-gemini-3-0-deciphered-the-mystery-of-a-nuremberg-chronicle-leafs-500-year-old-roundels/\"]",
      "add_ts": 1767741577,
      "last_modify_ts": 1767828051
    },
    {
      "id": 263,
      "article_id": "51674",
      "title": "融资35亿后，Kimi神秘模型现身竞技场",
      "description": "融资35亿后，月之暗面Kimi被曝推出新模型Kiwi-do，引发关注。该模型自认来自Kimi团队，训练数据截至2025年1月，在推特上被网友发现并测试，展现出较强竞技场表现，身份疑为Kimi新一代大模型。目前官方尚未正式发布，但其出色能力已引发热议，或将成为大模型赛道新竞争者。",
      "content": "克雷西 发自 凹非寺\n量子位 | 公众号 QbitAI\n融资35亿后，Kimi的新模型紧跟着就要来了？！\n大模型竞技场上，一个名叫\nKiwi-do\n的神秘模型悄然出现。\n发现这个新模型的推特网友询问了模型的身份，结果模型自报家门，表示自己来自月之暗面Kimi，训练数据截止到2025年1月。\n另有网友表示，Kiwi-do表现出了一些有趣的结果，尤其是在竞技场当中。\n那么，Kiwi-do的真实身份究竟是什么呢？\n神秘模型就是K2-VL？\n最早发现Kiwi-do的博主先是对比了Kiwi-do和已上线的K2-Thinking在SVG绘图上的表现。\n绘画的内容分别是一只骑自行车的鹈鹕和一个游戏手柄，下面这组图就是Kiwi-do的作品。\n而K2-Thinking的绘制结果长下面这样，两个结果有明显差别。\n但除了SVG绘图与K2-Thinking相比有区别之外，没有更多信息可以用来推测模型身份。\n还有网友猜测可能是一个小参数模型。\n不过博主很快联想到了Kimi\n在此前的AMA活动当中曾提及要发布VL模型\n。\n随后这位博主使用了VPCT基准测试中的一些视觉任务对Kiwi-do进行了测试。\nVPCT基准全称Visual Physics Comprehension Test，即视觉物理理解测试，模型需要在理解图像内容的基础上结合物理规律进行推理，比如看图推断小球会落入哪个容器。\n结果博主表示，Kiwi-do正确解决了所有问题。\n这样一来，博主和帖子下面留言的网友们纷纷推测，Kiwi-do很有可能就是AMA中提到的K2-VL。\n有网友评论称，Kimi的新模型通过VPCT测试，将会改变多模态Agent的格局。\n另外国内这边也有爆料，根据《科创板日报》稍早前的消息，\nKimi计划在今年一季度上线多模态新模型，型号可能是K2.1或K2.5\n。\n而之前AMA中提到的K2-VL也是一个多模态版本，因此不排除两者指向的是同一个模型只是代号不同的可能。\n月之暗面年末融资35亿\n就在Kiwi-do出现之前的2025年末，Kimi卡着年关官宣了一波5亿美元（约35亿人民币）的C轮融资。\n这轮融资由IDG领投，阿里、腾讯、王慧文等老股东也都进行了认购，投后估值43亿美元。\n另外，杨植麟在内部信当中透露，融资后Kimi的现金储备达到了100亿人民币。\n杨植麟表示，融到的资金将被用于“激进地扩增显卡”，从而加速K3模型的训练和研发。\n远期目标则是成为世界领先的AGI公司，对此杨植麟也公布了今年的战略：\nK3模型在预训练水平上追平世界前沿模型，借助技术改进、进一步的Scaling，让其等效FLOPs提升至少一个数量级；\n让K3成为更 “不同” 的模型，垂直整合训练技术和产品taste，让用户体验到全新的、其他模型不具备的能力。\n营收规模实现数量级增长，产品和商业化上聚焦Agent，不以绝对用户数量为目标，而是追求智能上限，创造更大的生产力价值。\n纵观整个大模型行业，无论是租还是买，算力成本都是巨额数字，需要不断进行融资来维持运转。\n同为六小虎的MiniMax和智谱选择了IPO，在招股书中无一例外都提及了算力扩张。\n但Kimi在融资方式上却依然看好一级市场，并不急于迈出IPO的步伐。\n杨植麟表示，Kimi的B/C轮融资额超过了许多IPO募资和上市公司定向增发，因此上市并非当务之急。\n不过，未来Kimi也会将上市作为加速AGI的手段，择时而动。\n参考链接：\n[1]https://x.com/AiBattle_/status/2007543920201269416\n[2]https://x.com/AiBattle_/status/2007679208042934509\n[3]\nhttps://mp.weixin.qq.com/s/9GbOpiB1WWJX30hkoU3D0w\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860058&idx=1&sn=148ce3ee32319a79ba0df4e85d243a1b&chksm=e955ac1badccdfcaf73f784bc1e0614d2bd3dd26ccc168b6a8f883e5745bde3f95415652c9ae&scene=0&xtrack=1#rd",
      "publish_time": 1767688200,
      "publish_date": "2026-01-06 16:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/AiBattle_/status/2007543920201269416\", \"https://x.com/AiBattle_/status/2007679208042934509\"]",
      "add_ts": 1767741583,
      "last_modify_ts": 1767828056
    },
    {
      "id": 265,
      "article_id": "51672",
      "title": "结构化预处理让DeepSeek准确率提升51%，现已开源丨清华&深言",
      "description": "LingoEDU团队提出新方法LingoEDU（EDU），通过基本信息单元技术降低大模型幻觉。该方法在生成前引入预处理环节，精准切分文本为最小信息单元并赋予唯一索引，提升信息组织与检索精度。实验显示，DeepSeek准确率提升51%，显著增强模型可靠性，且实现零成本部署，为大模型输出稳定性提供高效解决方案。",
      "content": "LingoEDU团队 投稿\n量子位 | 公众号 QbitAI\n零成本降低大模型幻觉新方法，让DeepSeek准确率提升51%！\n方法名为\nLingoEDU\n（简称EDU）\n，即基本信息单元\n（Elementary Discourse Unit，EDU）\n技术。\nLingoEDU在大模型正式生成之前装上的一个专门执行「预处理环节」的模型，这一环节主打精准切分，并且为每一个最小信息单元分配唯一的索引标记，给每一个生成内容打上标号——当需要引用某个信息时，可以精确地指向它的位置。\n如此一来，让信息进入主模型进行思考生成前，先完成结构化预处理。\nLingoEDU示意：将原文拆分成基本语义单元树后，能方便地在多文档问答、文档总结、DeepSearch等应用场景进行高效地上下文处理\n这种「坐标系」让后续的所有操作都可以溯源，模型输出的任何内容都能精确对应到原文的具体位置，将「生成」关进「可追溯」的笼子里。\n试想，\n如果生成的每句话、每个信息点都能精准地追溯到原文，都能check其正确与否，那么幻觉问题就可以在最大程度上被解决\n。\n总结来说，其核心是对上下文进行结构化的精准切分，形成富含结构信息和语义信息的篇章结构树——每个节点都是一个完整的基本话语单元，节点之间通过清晰的层级关系连接。\nLingoEDU具备如下优点：\n1.\n所形成的最小信息单元完整保留了原文的「语义信息」，同时保留了节点信息的完整性和节点之间信息的连贯性。\n2.\n使得上下文包含精准的「结构信息」，便于高效压缩，提升生成准确性。\n实验结果显示，LingoEDU在切分准确性指标上\n显著超过所有基线模型\n，在成本和效率上也显著优于所有通用大模型的方法。\nLingoEDU能够零成本适配所有大模型。在有着“AGI终极试炼”之称的HLE榜单上，\nDeepSeek-R1\n的准确率是9.0%，使用EDU之后准确率提升到13.6%，\n准确率相对提升51%\n。\n这项研究由深言科技联合清华大学NLP实验室提出，以下是更多细节。\n现有方案的两难困境\n大模型产生幻觉的核心原因，从输出一侧来看，可以归结为其任务是基于概率的“合理的下一个词”的生成器；从输入一侧来看，则是由于输入的上下文过长，模型容易在海量信息中「迷路」，无法准确理解其中全部内容，从而产生不忠实于原文的输出。\n前者是这种技术范式的固有特征，后者则可以在一定程度上被规范。\n基于这一洞察，对后者问题的一个自然解决思路是：\n在把文档喂给模型之前，先做一些预处理，压缩去除冗余信息、保留必要信息，这样降低模型幻觉风险，同时降低模型处理成本和效率。\n在过去的大模型训练过程中，任一基础模型都能实现对文档进行基本的结构化切分，但是其精准性却无法得到保证，这也是幻觉率居高不下的原因。\n目前业界主要有两类上下文压缩方法，但都存在明显的缺陷：\n显式压缩：看得见，但读不懂\n这类方法直接对文本「动刀」，比如删除不重要的词或句子。\n问题在于，这种操作往往基于单个词\n（Token）\n或粗糙的句子级别进行，容易把句子切得支离破碎。\n比如，原文是「因为天气恶劣，航班被迫延误」，压缩后可能变成「天气恶劣，航班延误」——虽然保留了关键词，但因果关系变得模糊。\n对模型来说，这就像阅读一篇被打了马赛克的文章，很难准确理解原意。\n隐式压缩：效率高，但成了黑盒\n另一类方法是把文本压缩成向量表示\n（即“Gist Tokens”）\n，相当于把整段话「浓缩」成一个黑盒表示。\n这种方法效率很高，但问题在于：模型完全看不到原文是什么，只能依赖这个抽象的向量。\n这就像让你只看一张照片的缩略图来描述细节——很容易产生误解和臆测。\n我们需要的是什么？\n归根结底，我们需要一种「两全其美」的方法：既保留文本的可读形式、避免黑盒带来的幻觉，又能维持语义的完整性、避免碎片化导致的连贯性丧失。\n这就需要找到一种合适的切分方式，能把文档拆解成满足以上两个需求的信息块，作为文档处理、大模型正式生成的基础。\n核心方法\n团队提出全新框架LingoEDU，核心是提升文档处理的\n可溯源性\n和\n生成质量\n。该方法包含两个核心部分：以忠实度为导向的输入/输出设计，以及一套严格的自我修正数据合成流程。\n△\nLingoEDU方法示意图\n训练方法侧：基于EDU的忠实度\n忠实度意味着可溯源性\n。团队通过将生成过程完全锚定在预定义的每一个EDU上，来实现这一目标。\n1.EDU表示策略：前置唯一索引标记，为模型创建参考坐标系\n选择句子作为EDU：\n不同于大多方案选用token或段落，该项目选择\n句子\n作为操作单元。\n与token相比，句子包含完整的语义命题，减少了碎片化；\n与段落相比，句子在不同文体中长度分布更稳定，便于模型建模。\n最关键的是，团队在输入Embedding中为每个EDU前置了\n唯一的索引标记\n，为模型创建了一个明确的参考坐标系。通过明确的位置表示，方便大模型进行可溯源生成，提升生成内容的忠实度。\n2. 增强型结构生成：让模型「引用」而非「创作」\n指针机制：\n为了保证结构忠实于原文，项目采用了\nAugmented Markdown\n模式。\n模型被训练为输出指向EDU的“指针”，而不是重新生成文本内容\n。生成的节点格式如下：\n消除幻觉：\n通过解码这个范围标记，\n可以将生成的结构无损地映射回原文的物理位置，从而有效消除了“位置幻觉”，从根本上消除了”凭空捏造”的可能。\n3. 受限解码：从物理上阻止幻觉\n为了进一步确保忠实度，项目在推理阶段施加了严格的词法约束。当模型生成范围标记中的数字时，可选的词表被严格限制为当前输入中实际存在的索引。\n这就像给模型戴上了一副”有色眼镜”——它只能”看到”真实存在的选项，从物理上阻止了编造不存在引用的可能性。\n训练数据侧：基于分解的可扩展数据合成\n这一部分工作的核心作用是生产高质量的拆分数据用于模型训练。为了解决高质量、对齐的结构化数据稀缺的问题，项目引入了一个自动化流水线，其核心思想是在“角色”和“任务颗粒度”两个维度上进行分解。\n1. 利用生成对抗的思想提升数据质量\n项目实施了一种\n迭代优化机制\n，引入两个不同的代理：\na. 求解器（The Solver）\n： 提出初步的EDU层级分解方案。\nb. 批评家（The Critic）\n： 审计提案的语义连贯性和边界精确度，只提供口头反馈，不直接修改结构。\n这种对抗式协作迫使求解器重新思考模糊的边界，显著减少了在长文本场景下的性能退化。\n2.双层任务分解（Bi-Level Task Decomposition）\n核心作用：区分「结构信息」和「语义信息」，提升模型切分的准确性\n团队认识到，文档结构化其实涉及两类本质不同的子任务：\na. 显性布局提取（Explicit Layout Extraction）：\n这类任务确定性高，比如识别标题、列表、代码块等格式元素。模型主要依赖视觉和格式线索来构建骨架。\nb. 深度语义分割（Deep Semantic Segmentation）：\n这类任务歧义性高，模型专注于大段文本内的语义转换，划分更细粒度的EDU。\n这种分离避免了端到端方法中常见的“指令冲突”\n（Instruction Conflict）\n，即避免模型混淆视觉布局与语义逻辑，从而提升了训练数据的整体质量。\nLingo EDU让DeepSeek准确率相对提升51%\n语义切分效果实验\n为了验证LingoEDU的切分效果，团队构建了248篇文章\n（包含web和pdf文件）\n组成的语义切分评测数据集，在这个数据集上，对比了本项目所采用的切分方法和各种基线方法的效果，主要指标是树编辑距离\n（TED，Tree Edit Distance）\n和文章级别准确率\n（DLA，Document Level Accuracy）\n，同时针对成本和效率进行了对比。\n实验结果显示，本项目的方法在切分准确性指标TED和DLA上显著超过所有基线模型，在成本和效率上也显著优于所有通用大模型的方法。\n下游应用效果实验\n相对线形的文本，精细化切分后的语义单元树能提供更加丰富的结构化信息和更加细粒度的信息管理和压缩，提升模型生成的准确性；同时由于信息表达的方式相对原始文本没有发生变化，可以方便地应用在各种下游任务上。\n在有着中文网页检索天花板难度之称的测试集\nBrowseComp-ZH上，将各大模型的LLM API+RAG Research叠加EDU技术后，准确率全部提升，其中DeepSeek V3.1提升的幅度近一倍，达到18.7%\n。\n在有着“AGI终极试炼”之称的HLE\n（Humanity’s Last Exam，人类最后的考试）\n测评集上，官方数据对行业头部大模型准确率的测评结果如下：\n适配EDU技术之后，各模型的准确率表现有明显提升，DeepSeek R1的提升幅度较大，从9.0%提升到13.6%，准确率相对提升51%。\n同时，团队也在LongBench\n（包括Multi-Doc QA、Summarization和Few-shot任务）\n上进行了对比实验，以Gemini-2.5-Pro和GPT-4.1为代表模型，验证LingoEDU的效果，实验结果显示\nLingoEDU能够提升模型在LongBench所有摘要总结、多文档问答等子任务的效果\n。\n核心价值\n价值点一：解决行业核心痛点——根治“幻觉”，让AI生成更可信\n核心：直接回应当前大模型应用中最受诟病、也最影响商用的“幻觉”问题。LingoLingoEDU不是“缓解”，而是通过结构性变革\n“根治”幻觉\n。\nLingoEDU\n（基本语义单元）\n技术，将文本拆解为一棵「语义树」。AI的每一次生成，都像在树上「按图索骥」，精准锚定到原文句子，从源头上杜绝了编造与偏离。\n可溯源的生成：每个结论都能\n追溯到原文的精确位置\n，让AI「引用」而非「重写」，保证\n100%的文本忠实度\n。\n价值点二：实现革命性效率——高效降本，实现智能“管理”\n核心：将超长文本从粗放的压缩升级为“智能信息管理”，提供\n更优的投入产出比\n。\n传统的上下文处理是「粗放式压缩」，而LingoEDU进行的是「精细化信息管理」。LingoEDU提供的不是更短的文本，而是\n结构更清晰、语义更完整的「文本地图」\n。\n实验证明，该项目所采用的方法在取得最高切分精度的同时，成本与效率显著优于调用通用大模型。这意味着客户能以更低的计算开销，获得更准确、更可靠的AI处理结果。\n这棵\n「语义树」\n是通用的能力增强器。无论是长文档问答、摘要总结还是复杂推理，它都能\n让现有模型的性能获得普适性提升\n。\n价值点三：彰显技术领导力——定义新标准，从“黑盒”走向“白盒”\n核心：将LingoEDU定位为一次重要的技术范式演进，引领行业走向\n可解释、可控制\n的AI。\nAI应用正从「效果惊艳」走向「流程可信」。忠实度意味着可溯源性，LingoEDU正是这一理念的工程化实践，推动AI从「黑盒魔术」走向「白盒工程」。\n开创了「基于分解的可扩展数据合成」流程，通过「求解器-批评家」循环与双层任务分解，自动化生产高质量训练数据，解决了该领域数据稀缺的核心瓶颈，构建了坚实的技术壁垒。\nLingoEDU不仅是一项技术，更是为下一代可信AI基础设施提供的一个关键模块。它定义了如何让大模型更可靠地理解与处理人类复杂知识的新标准。\n论文链接：\nhttps://arxiv.org/pdf/2512.14244\nGithub开源链接：\nhttps://github.com/DeepLangAI/LingoEDU\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n我们正在招聘一名眼疾手快、关注AI的\n学术编辑实习生\n🎓\n感兴趣的小伙伴欢迎关注 👉\n了解详情\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860058&idx=3&sn=a88cc7f65a5d8ac660c3a34cbcc2cb6a&chksm=e911cc9570c41ec3fe233a3a5e305bc6d11a3ec5d290a03d0db4c7d939f0af7099664a15b5e6&scene=0&xtrack=1#rd",
      "publish_time": 1767682800,
      "publish_date": "2026-01-06 15:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/pdf/2512.14244\", \"https://github.com/DeepLangAI/LingoEDU\"]",
      "add_ts": 1767741595,
      "last_modify_ts": 1767828062
    },
    {
      "id": 266,
      "article_id": "51671",
      "title": "",
      "description": "字节Seed团队提出DLCM（动态大概念模型），将大模型推理单位从固定Token提升至动态的Concept（概念）层级。DLCM通过端到端学习语义边界，自适应分割Token序列并压缩为概念单元，在概念空间中实现更高效的深度推理，突破传统以词为单位的局限，显著提升语义理解与推理效率，为LLM架构演化提供新方向。（150字）",
      "content": ":\n，\n.\nVideo\nMini Program\nLike\n，轻点两下取消赞\nWow\n，轻点两下取消在看",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859923&idx=1&sn=f241aba04987c23166cde804d3652d2d&chksm=e971de6c12fafa53bfc5d1f89caeaa4573d149fd1f80fea3f6168d41064c493b2f96ca6c01c8&scene=0&xtrack=1#rd",
      "publish_time": 1767682200,
      "publish_date": "2026-01-06 14:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767741598,
      "last_modify_ts": 1767828064
    },
    {
      "id": 267,
      "article_id": "51670",
      "title": "李飞飞踢馆游戏圈：Unity们，该退场了！",
      "description": "游戏行业正面临转型，传统高投入、长周期的开发模式遭遇瓶颈。《原神》式重金堆砌难以为继，李飞飞团队携「世界模型」入局，借助AI技术推动游戏创作变革。Genie 3等工具实现秒级生成内容，开发效率提升数倍，预示着AI将颠覆传统“搬砖式”游戏制作。这场由AI驱动的造物革命，正在重新定义创作边界，玩家或将成为“上帝”般的创造者。",
      "content": "新智元报道\n编辑：倾倾\n【新智元导读】\n1900亿美金的游戏帝国正迎来寒冬！《原神》式的重金堆砌已近极限，李飞飞携「世界模型」暴力拆解行业规则。从4倍速开发到Genie 3瞬间造梦，AI正在终结搬砖时代。这场关于造物权的豪赌，你准备好成为上帝了吗？\n在游戏界，我们似乎已经习惯了用「生命」去等待。\n米哈游的《原神》研发了4年，每年的运营成本超过2亿美元；全球玩家翘首以盼的《GTA6》，距离前作发布已经过去了整整十二年。\n然而，在那个高耸的技术围墙内，顶级游戏却也在成为开发者的重担。\n据Newzoo数据显示，这个产值1900亿美元的版图，正陷入一种僵局：3A大作的研发成本动辄几十亿美金，开发者在无尽的加班中灵感枯竭。\n就在这个节点，AI领军人物李飞飞撕开了旧时代的裂缝。她直言不讳地指出：\n这一切都将被颠覆，模拟引擎早该改进了。\n李飞飞的World Labs展示的世界模型，正试图赋予AI理解并重构3D物理空间的能力。\nGame Gears首席执行官在实测中证实：AI已经让开发速度实打实地翻了4倍。\n我们正站在奇点之上。原本属于巨头们的战场，正向每个人敞开。\n效率的「核裂变」\n从千人团队到4倍速革命\n当大多数人还在讨论「AI能不能画出一张好看的海报」时，游戏行业已经拿到了让传统工作室汗颜的成绩单。\nGame Gears首席执行官Alexander Vaschenko透露了：\n在开发《Aliens vs Zombies: Invasion》等作品时，AI将开发速度提升了整整4倍。\n这意味着，需要几个月才能完成的建模和关卡设计，被压缩到了以「周」甚至「天」为单位的生命周期。\nAI自动生成的复杂3D场景。这种实时的生产力释放，是过去任何引擎都无法比拟的。\n那么，它究竟是怎么做到的？\n以Google DeepMind发布的Genie 3为例。在传统的游戏逻辑中，如果你想让角色在森林里奔跑，你得先建出树木的模型，写好碰撞体积的代码，再设置复杂的光影渲染。\n但在世界模型面前，这一切都消失了。你只需给它一张森林的照片，它就能「明白」什么是树，什么是路。\n正如Shlomi Fruchter所说：\n这种模型正在赋予开发者一种从未有过的超能力。它不再是帮你修剪枝叶的剪刀，而是直接生成整片森林的土壤。\n更让人惊艳的是出自李飞飞之手World Labs，及其推出的Marble模型。\n它生成的3D环境不仅具有视觉上的深度，更拥有内在的逻辑——知道重力如何作用，也懂光线如何折射。\n这种基于「物理直觉」的生成方式，让原本需要算力维持的模拟，变得像呼吸一样自然。\n当一个团队能够通过AI达到千人工作室的产出水平时，游戏行业的「重工业时代」也将落下帷幕。\n引擎已老\n逻辑的「降维打击」\n传统的游戏引擎（如 Unreal/Unity），本质上是一套依赖「预设规则」的执行器。\n它并不真正理解物理，它只是在执行人类写的代码。\n如果你想在游戏里推倒一堵墙，需要程序员写下复杂的碰撞检测代码，需要美术师精修碎裂的纹理。\n传统引擎依赖极其复杂的逻辑节点来模拟现实，每一个动作背后都是海量的参数堆砌。\n而李飞飞所倡导的「世界模型」，推行的是一套「自上而下」的视觉智能。\n它不需要人类去定义什么是重力，什么是摩擦力。\n通过学习数以亿计的视频数据，AI自己通过观察就能学会「物理直觉」。\n它「知道」玻璃碎裂的轨迹，也「懂得」水流如何绕过岩石。\n原本需要成千上万行代码才能模拟的物理世界，现在已经成了AI的基础设置。\n正如李飞飞所言，现有的模拟引擎早已到了改进的关口。\n当世界模型成熟后，游戏引擎不再是一个需要开发者去苦苦钻研、考取证书的复杂软件，而是一个能够听懂人类意图的「数字容器」。\n这正是DeepMind的专家们所期待的「解脱」。\n当繁琐的、重复性的模拟工作被AI取代，开发者们终于能从中抽身，重新把精力投入到那份久违的、关于「寻找乐趣」的冒险中去。\n人人都是造物主\n从「看电影」到「造梦境」\n当技术的围墙被世界模型被推倒，最兴奋的是每一个普通人。\n如果说去年的Genie 2还是一个「视频生成器」，那么今年的 Genie 3则彻底打破了屏幕的第四面墙，是真正的「构建者」。\nGenie 3，它生成的不再是平面的画面，而是一个拥有实时物理交互能力的3D环境。\nGenie 3相比Genie 2提升了一致性和真实性。\n长期以来，游戏是开发商写给我们玩的作品；但在未来，游戏将成为我们灵魂的延伸。\n通过 AI 驱动的世界模型，个性化游戏的生产正变得异常简单。\n你甚至不需要学习枯燥的C++或复杂的3D建模，你唯一的「开发工具」就是你的想象力。\n在《堡垒之夜》中，开发团队利用AI让Darth Vader跨越荧幕。\n这种「造物权」的下放，不仅是效率的提升，更是情感的弥补。\n未来，我们或许能利用世界模型，在3D空间里复刻童年的模糊记忆，或者与记忆中的故人，在AI编织的世界中重逢。\n技术的尽头\n是茧房，还是灵感？\n正如任何一场伟大的革命都会伴随怀疑，「造物权」移交也不例外。\n在本月，六个欧洲视频游戏工会发出了集体谴责。他们担心这些工具正在「强加于人」，不仅威胁到艺术家的生计，更可能让游戏世界被平庸的、低质量的「AI废料」淹没。\n这种担忧并非空穴来风。当生成一个世界的成本趋近于零，我们是否会像被困在信息茧房里一样，被困在由算法编织的、失去灵魂的数字化垃圾场里？\n这正是李飞飞所预言的颠覆中，最隐秘也最沉重的代价。\n然而，Alexandre Moufarek提供了一个视角。\n这位曾任职于Ubisoft的资深制片人深知，传统游戏开发的末期往往是一场灵感的屠杀——为了追赶圣诞节的发行窗口，开发者们不得不放弃打磨、放弃冒险，陷入无尽的调试与查错中。\nAI的意义，是给开发者空间去「寻找乐趣」。\n我们正站在旧时代的黄昏与新纪元的黎明之间。未来的游戏，可能不再是标准化的商品，而是一个随心生长、具备物理灵魂的生命体。\n当$1900亿美金的重工业围墙轰然倒塌，我们最终会发现，技术的尽头不是机器取代了人，而是让每个人都能像儿时一样，在想象力的旷野里，重新找回那份最纯粹、最毫无顾忌的快乐。\n参考资料：\nhttps://www.ft.com/content/9b1b1bc3-6573-451d-892b-e6abb819a112?utm_social_post_id=633473265&utm_social_handle_id=18949452\nhttps://deepmind.google/blog/genie-3-a-new-frontier-for-world-models/\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660307&idx=2&sn=d6b0d3ad67436310a5bd59dd445db2e5&chksm=f0f28af38ae1de3cb7f65f86c9b29db938490ee671f3f940d3b1a808a25c3d8746f26e2e989c&scene=0&xtrack=1#rd",
      "publish_time": 1767682200,
      "publish_date": "2026-01-06 14:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.ft.com/content/9b1b1bc3-6573-451d-892b-e6abb819a112?utm_social_post_id=633473265&utm_social_handle_id=18949452\", \"https://deepmind.google/blog/genie-3-a-new-frontier-for-world-models/\"]",
      "add_ts": 1767741601,
      "last_modify_ts": 1767828070
    },
    {
      "id": 269,
      "article_id": "51668",
      "title": "语义分割别无脑用Argmax！港中文新算法：三行代码，推理速度提升10倍",
      "description": "香港中文大学提出新算法框架RankSEG，旨在提升语义分割性能。传统方法依赖threshold或argmax生成掩码，存在局限性。RankSEG无需重新训练模型，仅在推理阶段添加三行代码，即可优化预测结果，显著提高Dice、IoU等关键指标，有效增强分割精度与模型泛化能力，为现有分割模型提供简单高效的改进方案。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n香港中文大学提出了一个全新的算法框架RankSEG，用于提升语义分割任务的性能。传统方法在预测阶段使用threshold或argmax生成掩码，但这种方法并非最优。RankSEG无需重新训练模型，仅需在推理阶段增加三行代码，即可显著提高Dice或IoU等分割指标。\n在语义分割任务中，通常采用「在预测阶段，通过对概率图应用threshold 或argmax来生成mask」的传统范式。\n然而，你是否思考过：这种做法真的能够最大化Dice或IoU等主流分割评估指标吗？\n香港中文大学的最新研究证明了这一传统方法的次优性，并提出了一种创新性\n算法\n框架RankSEG，无需重新训练模型，仅需三行代码即可显著提升分割性能。\n系列工作包括刚被NeurIPS 2025接收的高效分割算法，以及发表于JMLR的核心理论，还开源了配套的Python工具包，无需重训模型，仅通过增加三行代码，即可有效提升分割指标表现。\nNeurIPS论文链接：https://openreview.net/forum?id=4tRMm1JJhw\nJMLR论文链接:https://www.jmlr.org/papers/v24/22-0712.html\n代码链接：https://github.com/rankseg/rankseg\n如果业界从业者希望最大限度地「榨干」分割模型的性能，只需阅读第一节，即可解锁如何将RankSEG无缝集成到现有流程中。\n开源软件包\n研究人员提供了一个易用的\nRankSEG\n类，初始化时可指定需要优化的分割指标（如 Dice、IoU 等）。随后，只需调用\npredict\n方法并输入概率图，即可获得优化后的预测结果。\n实际使用时，只需将原有的\nprobs.argmax(dim=1)\n替换为\nrankseg.predict(probs)\n，即可轻松集成，无需过多改动，简单高效。\nfrom rankseg import RankSEG\n# 1. Initialize RankSEG (optimizing for Dice)\nrankseg = RankSEG(metric='dice')\n# 2. Get your model's probability outputs (batch_size, num_classes, *image_shape)\nprobs = model(images).softmax(dim=1)\n# 3. Get optimized predictions; replace `preds = probs.argmax(dim=1)`\npreds = rankseg.predict(probs)\nRankSEG与传统argmax方法的效果对比，使用同一个训练好的模型，唯一的区别仅在推理阶段的处理方式。图中用红框进行了重点标注：在第一个例子中，RankSEG 成功识别出桌子上的小瓶子；在第二个例子中，RankSEG成功分割出了被遮挡的人脸；第三个例子捕捉到更完整的肿瘤块。可以明显看出，RankSEG在小物体识别和处理被遮挡等复杂场景时，分割效果相较于传统 argmax 有显著提升。\nDemo链接：https://huggingface.co/spaces/statmlben/rankseg\nQuickStart：https://colab.research.google.com/drive/1c2znXP7_yt_9MrE75p-Ag82LHz-WfKq-?usp=sharing\n文档链接：https://rankseg.readthedocs.io/en/latest/index.html\n传统threshold/argmax的局限性\n目前主流的分割流程，通常通过训练模型来估计每个像素的类别概率，随后采用threshold或argmax方法生成最终的预测掩码（Mask）。\n这种逐像素分类（pixel-wise classification）的方法，优化目标是像素级的准确率；但分割任务真正关心的，是整体的重合度指标（如Dice或IoU），二者并不完全一致。\n理论上，传统的threshold / argmax预测方式是次优的（suboptimal）。例如，在下面这个由两个像素组成的简化场景中，即便其中一个像素的预测概率低于0.5，为了获得最优的Dice分数，依然应该将其判定为前景。简单来说，逐像素最优解不一定能带来全局最优的分割效果。\n左侧红框给出了最终分割结果，右侧展示了简要的计算过程。其中，\n表示通过threshold/argmax得到的预测结果。\n可以看到，这种预测方式对应的Dice分数并未达到最优；而为了获得最优的Dice，实际上应当将第二个概率低于0.5的像素也判为前景，这个例子直观地揭示了传统threshold/argmax方法在整体分割性能上的局限性。\n核心理论：RankSEG\n那么，如何才能获得最优的分割预测呢？下面的定理给出了理论上的解答，并指出了实现该最优性的具体方法（这里以Dice指标为例，类似的思路同样适用于IoU优化）。\n这个定理可以分为以下几个关键部分理解：\nDice期望的计算\n已知每个像素的概率值，输入预测的mask\n，该 mask 的Dice系数的期望可以表示为：\n只要遍历所有可能的二值 mask，计算对应的Dice期望，并取最大的那一个就能获得最优解。\n然而，所有mask的组合数为\n2的d次方\n，计算量呈指数增长，直接穷举在实际应用中不可行。\n排序性质\n定理进一步指出，只需关注这样一类特殊的mask：\n即概率值排序后，取前\n大的像素预测为前景。那么只需要搜索「体积」\n从0到d，大大减少了计算复杂度。\n这里隐含了一种排序（Ranking）性质：如果像素j\n的概率\n大于像素\nj'\n的概率\n，那么把j\n判作前景对Dice期望的提升更大。该工作针对这一直观结论给出了严格的理论证明，也由此取名RankSEG。\n自适应阈值的最优预测规则\n这里，\n是遍历不同体积\n，找到Dice期望最大的对应阈值。与传统的\n固定阈值不同，这种阈值是自适应（adaptive）的，会根据每张图片的概率分布动态调整，不再局限于 0.5。\n符号记号及期望公式的化简\n：为简化后续推导，我们将上述Dice期望重写如下：\n其中\n是去掉第\nj\n个元素后的向量，\n（替换\n）为剩余像素的前景体积。\n由于每个像素是独立伯努利分布，\n实质上服从泊松二项分布（概率完全相同则退化为经典二项分布）。\nRankSEG定理直接以寻找Dice最优预测为目标，巧妙地利用排序性质，带来了简洁且高效的分割预测方法。不过，在定理的实际应用过程中，仍存在两个主要挑战：\n期望值计算的复杂性：\n对每个候选分割\n，Dice期望\n的精确计算开销大；\n多类别分割的最优刻画困难：\n在多类别（multi-class）语义分割场景下，由于每个像素只能归属于一个类别（即「无重叠」约束），最优预测的刻画以及直接优化全局指标都变得更加复杂和棘手。\n针对以上难点，研究人员引入近似化的技巧，旨在进一步简化计算，同时提出更为实用（practical）的算法方案，以促进RankSEG在各类实际分割任务中的高效应用。\n高效近似算法：RankSEG-RMA\nRankSEG的计算复杂度较高，限制了其在高维图片中的实际应用，最新的算法（NeurIPS 2025）引入倒数矩近似和多类别分割。\n倒数矩近似\nRankSEG计算的主要瓶颈在于每个候选掩码\n都需要精确计算Dice期望\n。\n具体而言，难点在于求解如下关于\n的倒数期望项：\n。该期望需要针对每对\n重新展开\nd\n项求和；如果能够找到一个近似表达式，使得该期望对不同的\n和j\n无需重复独立计算，就可以一次性高效推断，并在不同的\n评估中复用结果，从而大大降低整体计算复杂度。\n首先，注意到在当前的图像分割任务中，像素数量d\n通常非常大。\n在这种情况下，去除单个像素j\n前后的和（即\n与\n）之间差异极小。因此，可以用\n直接近似\n，从而消除了对像素\nj\n的依赖。\n其次，针对泊松伯努利分布，进一步观察到：当\nd\n足够大时，倒数的期望\n和期望的倒数\n非常接近。\n因此，后者可以作为前者的近似值，这样一来，期望的计算同样摆脱了对\n的依赖。研究人员将这种近似称为倒数矩近似（Reciprocal Moment Approximation, RMA）。\n借助该方法，用定理2中的\n替换原来的\n，在显著提升计算效率的同时，依然能够保持较低的近似误差。\n这里\n和前缀和\n都可以提前一次性算好，并在后续所有的\n评估中反复使用，整体计算复杂度仅为\n。\n多类别分割\nRankSEG的框架可以自然地扩展到multi-label场景（即单个像素允许属于多个类别）。然而，在多类别单标签（multi-class）分割任务中，每个像素只能分配一个类别的「非重叠」约束，使得直接扩展RankSEG会涉及到复杂的匹配（assignment）问题，计算复杂度显著提升。\n为此，研究人员提出如下近似算法，兼顾了效率与精度：\n1. 独立二值分割：\n对每个类别独立应用RankSEG-RMA算法，分别获得各自的binary mask。\n2. 去除重叠：\n对于预测结果中重叠的区域，仅保留masks之间无重叠部分，舍弃多类别同时预测的像素。这一步可能导致部分像素没有被分配给任何类别。\n3. 计算提升值：\n对于这些未分配的像素\nj\n，计算其加入不同类别的提升值\n，其中c\n是类别，\n是已分配给类别\nc\n的像素集合。\n4. 贪心分配：\n在重叠或未分配像素\n中，根据最大增益为每个像素\nj\n选择类别：\n这种方法虽然在最后一步引入了 argmax 机制，但与传统方法相比，具备以下两个显著优势：\n选择性使用argmax\n：\n只有在重叠区域才采用argmax，而大部分像素预测仍然由RankSEG原始算法直接决定，充分发挥了RankSEG的优势。\nPrincipled scores\n：\n反映的是某像素j被分给类别\nc\n后Dice期望的提升，因而比单纯的概率最大化更符合分割性能的优化目标。\n需要说明的是，此方法实质上是一种\n贪心的近似策略\n，因为\n仅考虑每次加入单个像素时的「瞬时」效益，未全局协同优化。\n但实验结果显示，在兼顾计算效率的同时，该方法能够带来不错的分割性能提升，体现出了合理的实用价值。\n实验结果\n研究人员在多个主流分割数据集（如PASCAL VOC, Cityscapes, LiTS, KiTS等）和多种深度学习模型上进行了广泛实验，验证了RankSEG系列方法的优越性。\n从表中结果可以观察到：\n性能提升显著：\nRankSEG系列方法相较传统的argmax预测机制，在分割精度上均有显著提升。\n高效近似性：\nRankSEG-RMA与原始的RankSEG-BA在分割性能上几乎无损失，但推理速度提升数十倍，极大地提升了实际应用的效率。\n整体开销较低：\n尽管RankSEG-RMA在推理阶段相较于argmax在绝对时间上有增加，考虑模型前向（model forward）时间后，其整体计算开销增加有限。而原始的 RankSEG-BA，其耗时则接近于模型前向传播时间本身，限制了实际部署。\n公平性对比：\n所有结果均基于同一个训练模型，RankSEG 作为模型输出的「后处理」操作，避免了因神经网络训练过程中的随机性导致的性能波动，保证了对比结果的客观性。\n参考资料：\nhttps://openreview.net/forum?id=4tRMm1JJhw\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660795&idx=2&sn=9de6af93cb1ab505d6ccda87cca651be&chksm=f09bfe2ed41b6facb0e91e8be9f5fb3f0855aec1c82edff09b5fc4e093385575efd91c45131b&scene=0&xtrack=1#rd",
      "publish_time": 1767671040,
      "publish_date": "2026-01-06 11:44",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://openreview.net/forum?id=4tRMm1JJhw\", \"https://www.jmlr.org/papers/v24/22-0712.html\", \"https://github.com/rankseg/rankseg\", \"https://huggingface.co/spaces/statmlben/rankseg\", \"https://colab.research.google.com/drive/1c2znXP7_yt_9MrE75p-Ag82LHz-WfKq-?usp=sharing\", \"https://rankseg.readthedocs.io/en/latest/index.html\"]",
      "add_ts": 1767741608,
      "last_modify_ts": 1767828076
    },
    {
      "id": 280,
      "article_id": "51648",
      "title": "Anthropic打响「去CUDA」第一枪！210亿美元豪购谷歌100万块TPU",
      "description": "Anthropic凭借Claude Opus 4.5在AI竞争中抢占先机，仅用一小时完成谷歌工程师耗时一年的代码复现，引发业界震撼。公司更豪掷100万块谷歌TPU自建超算，展现强大技术实力。谷歌工程师公开称赞其性能，标志着AI军备竞赛迎来关键拐点，2026年或成技术格局重塑之年。",
      "content": "新智元报道\n编辑：桃子\nKingHZ\n【新智元导读】\n未发先赢，也只有Anthropic了！\nClaude一小时写完谷歌一整年代码震撼全网，甚至，他们豪购100万块谷歌TPU自建超算。AI军备赛拐点，或许就在这一年。\n2026年开局，Anthropic未发一弹已占先机！\n谷歌首席工程师Jaana Dogan连发多帖，高度赞扬Claude Opus 4.5——\n仅用一小时，便复现了一个曾让谷歌工程师钻研整年的AI系统。\n另一个前谷歌和Meta科学家Rohan Anil观点更具冲击力：\n若借助Opus的智能编码能力，自己早期长达六年的探索工作，可被高度浓缩至几个月内完成。\n自发布过去一个多月，Claude Opus 4.5真正的实力爆发了。\n没有图像/音频模型、巨大的上下文，仅有一款专注编码的Claude，Anthropic依旧是OpenAI谷歌最有力竞争者。\n这究竟是什么神仙打法？\n联创Daniela Amodei给出了一个直白有力的回答，「少即是多」。\n一直以来，Anthropic都在押注用最少的资源，做更多的事，才不会掉队，始终跑在AI最前沿。\n豪购100万块TPU，自建超算\n相较于模型发布，更重大的一件事是，Anthropic也要自建超算了。\n权威机构SemiAnalysis爆出，Anthropic准备买下近100万块TPU v7芯片。\n这批芯片将从博通直接下单，并将其部署在自控基础设施中。\n整个部署架构是这样的：\nAnthropic持有TPU的所有权，基础设施部分交给了TeraWulf、Hut8和Cipher Mining合作伙伴来提供。\n至于现场的实际落地运维，比如布线、开机测试、上线验收和日常远程管理这些活，都外包给了Fluidstack来全权负责。\n目前，谷歌虽暂未公布TPU v7单价，但依据行业推测，大概在15,000–25,000美元之间。\nAnthropic一出手就是100万张，\n此前爆料称，这笔交易金额或达210亿美元。\n对于英伟达来说，将丢失300亿美元\n（B200）\n潜在大订单。\n然而，这笔交易最危险的地方不在金额，而在于结构：\n这意味着，Anthropic自有超算将不再依赖CUDA生态，不再被云厂商「算力税」抽成，将算力主权握在手中。\n有网友表示，这显然是一件大事。\n谷歌现在大力推行商用芯片战略，这将在未来催生一个基于TPU构建的生态系统。\n毕竟，谷歌已经用Gemini 3实证了，不用GPU，TPU也可以训出强大模型。\n2026年AI生死局，\n反向押注\n如今进入2026年，AI行业已演变为「暴力规模与效率」的较量。\n作为规模派的代表，OpenAI投入1.4万亿美元用于算力和基础设施建设。\n相较之下，Anthropic却选择了一条不同的道路——「花小钱办大事」（Do more with less），把筹码押在了三件事上：\n更高质量、结构更好的训练数据\n明显加强模型推理能力的后训练技术\n以及极度现实的目标：\n让模型跑得更便宜、更容易被大规模采用\n在CNBC采访中，Daniela Amodei强调，公司一直以来都以审慎的态度利用资源。\n下一阶段的胜利，不会仅靠最大规模的预训练任务来赢得，而是取决于每一美元算力能交付多少能力。\nAmodei称，我们在Anthropic一直以来的目标是——在这个单纯依赖大量算力的领域运作时，尽可能审慎地利用我们拥有的资源。\n就算力和资本而言，Anthropic拥有的资源一直只是竞争对手的一小部分。\n然而，在过去几年的大部分时间里,\n我们\n都拥有最强大、性能最好的模型，一以贯之。\n当然，这并不意味着Anthropic「没钱」。\n恰恰相反，这家公司目前已经锁定了\n约1000亿美元规模的算力承诺\n，而且他们自己也承认，如果要继续站在前沿，这个数字只会继续飙升。\n他们并不是否认Scaling。\n他们赌的是：\n规模并不是唯一的杠杆。\nAnthropic并没有把自己定位成一个面向大众的「消费级AI明星产品」。\n它更像是一个\n企业优先的模型供应商\n。\nClaude的主要收入来源，是被嵌入到别人的产品、工作流和内部系统中。\n这类场景虽无噱头，但黏性更强、更接近真实生产力。\nAnthropic表示，他们的收入已经\n连续三年实现\n同比\n十倍增长\n。\n更罕见的是，他们还构建了一张非常不寻常的销售策略：「Claude几乎\n出现在所有主流云平台上\n，包括那些\n同时也在卖自家竞争模型的云厂商\n。」\nDaniela Amodei对此的解释很直白：不是缓和关系，而是被\n客户需求倒逼\n。\n大型企业希望在云厂商之间保有选择权，而云厂商也不愿意因为模型问题失去最大客户。\n下一阶段真正的赢家，可能不是那个烧钱最多的实验室，而是那个\n能在实体经济承受范围内持续改进的公司\n。\n「指数级增长会持续，直到它停止。」\n2026年真正的问题是：如果那条被整个行业奉为信仰的曲线，真的开始失灵——\n这场由算力堆起来的AI军备竞赛，是否还能体面收场？\nClaude Opus 4.5，刷屏了\n如今，全网都被Claude Opus 4.5震撼到了。\nHelius首席执行官表示，「Opus 4.5简直疯狂到离谱」。\n本人已编程十年，它却可以根据提供系统设计指导，以及明确的自我验证路径，完成任何要求的任务。\n有开发者在短短半小时内，不写一行代码，构建出一款iOS应用。\n同样地，还有人在20分钟内打造了类似ESPN风格的应用。\n有人用Claude编程一个程序，用摄像头记录下了花开的时刻。\n就连Karpathy几天前发文，自己也上手Claude Code，让其接入智能家居系统。\n不仅如此，Claude Code不仅适用于编程，Pietro Schirano还将原始DNA数据输入，并利用它找出了一些与健康相关的基因。\nOne More Thing\n去年3月12日，《纽约时报》报道，谷歌持有Anthropic公司14%的股份。\n2024年，Anthropic将亚马逊云服务（AWS）确定为其主要训练合作伙伴；亚马逊将向Anthropic追加投资40亿美元。\n此外，Zoom也有Anthropic部分股权。\n最近，谷歌被传出正在洽谈追加投资Anthropic。新一轮融资或将使Anthropic的估值突破3500亿美元。\n不得不让人怀疑，谷歌是不是要在2026年收购Anthropic？Claude Code要并入谷歌了？\n不过，Anthropic如此成功，有必要卖给谷歌吗？\n而且，Anthropic一贯标榜「安全AI」，一旦被收购，「谷歌+Anthropic」毫无疑问地将终结AI竞赛，OpenAI、微软、英伟达等另一方会甘心吗？\n参考资料：\nhttps://x.com/SemiAnalysis_/status/2007225399080550506\nhttps://x.com/8teAPi/status/2007252568427376954\nhttps://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660284&idx=1&sn=0e6fdac002d8db2e6df9a6235babb5f4&chksm=f0a95027c2970c50e0b57ea04cabcdb19c708785aee9b6b88a756928eca933ae6d365d8e655e&scene=0&xtrack=1#rd",
      "publish_time": 1767612600,
      "publish_date": "2026-01-05",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/SemiAnalysis_/status/2007225399080550506\", \"https://x.com/8teAPi/status/2007252568427376954\", \"https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html\"]",
      "add_ts": 1767741676,
      "last_modify_ts": 1767741676
    },
    {
      "id": 284,
      "article_id": "51640",
      "title": "MIT发现让AI变聪明的秘密，竟然和人类一模一样",
      "description": "新智元报道  编辑：定慧【新智元导读】你有没有发现，你让AI读一篇长文章，结果它读着读着就忘了前面的内容？ 你让它处理一份超长的文档，结果它给出来的答案，牛头不对马嘴？ 这个现象，学术界有个专门的名词，叫做上下文腐化。 这也是目前AI的通病：大模型的记忆力太差了，文章越长，模型越傻！2025年最后一天，麻省理工学院（MIT）丢了一篇重磅论文，就是要解决这个问题的。这篇论文叫《Recursive",
      "content": "新智元报道\n编辑：定慧\n【新智元导读】\n你有没有发现，你让AI读一篇长文章，结果它读着读着就忘了前面的内容？ 你让它处理一份超长的文档，结果它给出来的答案，牛头不对马嘴？ 这个现象，学术界有个专门的名词，叫做上下文腐化。 这也是目前AI的通病：大模型的记忆力太差了，文章越长，模型越傻！\n2025年最后一天，麻省理工学院（MIT）丢了一篇重磅论文，就是要解决这个问题的。\n这篇论文叫《Recursive Language Models》，也就是递归语言模型。\n看起来很学术，但说人话就一句：\n让\nAI\n再做一遍，效果直接起飞。\n论文地址：https://arxiv.org/pdf/2512.24601\n先剧透两个核心数据：\n在复杂推理任务上，仅仅让模型多过2-4遍，正确率就能提升10%-25%\n在超长文档处理上，RLM（递归语言模型）在1000万+token的规模下，依然保持稳定表现，而传统模型直接崩盘！\n这啥概念？\n以前我们觉得，AI不够聪明，那就给它堆参数、加显卡、买更多GPU。\nMIT这篇论文直接掀桌子：\n别堆参数了，让它返工重写一遍，效果可能更好。（真就是人类监工了）\n原来解决问题的方法就是这么简单！\n并且X上很多大佬纷纷点赞～\n从一个让人崩溃的问题说起\n你有没有这种经历：\n让ChatGPT帮你写一篇文章，它洋洋洒洒写了三千字，你一看——卧槽，离题万里。\n或者让它帮你写代码，它写完了，一运行——全是bug。\n但神奇的是，你让它再检查一遍、重新想想，有时候它就突然能改对了。\nMIT的研究人员发现，这不是玄学，这是有规律的。\n大多数\nAI\n犯的错，不是因为它不懂，而是因为它初稿写太快了。\n就像你写论文，第一稿总是稀烂，但改个三四遍，就像换了个人写的。\nAI也是一样。\n问题是：现在的大模型基本都是一遍过的模式，你输入问题，它输出答案，完事。\n它自己不会主动返工、不会自我检查、不会反复推敲。\n或者换一个思路来理解大模型原先的思路：\n假设你是一个刚进公司的实习生，领导给你发了一份500页的资料，让你整理出一份报告。\n你会怎么做？\n正常人的做法是：先翻一翻，找到重点章节，然后一章一章地读，读完一章做个总结，最后把所有总结串起来。\n对吧？\n但大模型不是这么干的。\n大模型的做法是：直接把500页资料从头到尾一口气读完，然后尝试凭记忆回答问题。\n这能记住才有鬼了。\n这就是大模型面临的困境。\n它不是不聪明，它是记不住。\nMIT这篇论文干的事儿，就是给AI装上了一个返工的能力。\nAI的真正瓶颈：不是脑子不够大，是记性太差\n在聊MIT的解决方案之前，我得先跟你说清楚，为什么这件事这么重要。\n你可能听说过一个词，叫上下文窗口。\n啥意思呢？\n你可以把AI大模型想象成一个天才，但是这个天才有个致命缺陷——他的工作台太小了。\n你给他一份超长的资料，让他帮你分析，但他只能把资料的一小部分放到工作台上看。\n超过工作台大小的部分？看不到，直接忽略。\n现在最牛逼的GPT-5，工作台能放27万个token（大约相当于20万字中文）。\n听着挺厉害的对吧？\n但问题来了。\n就是说，哪怕是在这27万token的限制之内，模型的表现也会随着输入变长而急剧下降。\n当你给它8000个token的时候，它表现贼棒。\n给它8万个token的时候，它开始有点迷糊。\n给它27万个token的时候，它直接开始胡说八道。\n为什么？\n因为信息太多了，它处理不过来了，脑子乱了。\n就像让一个人同时记住一整本百科全书然后回答问题——记是记住了，但找不到了。\n这就是大模型现在的困境：\n不是上下文窗口不够长，而是长了也用不好。\nMIT的天才想法：把资料放到抽屉里\n好了，问题讲清楚了，现在来看MIT的解决方案。\n传统做法是：你把资料直接塞进AI的脑子里。\nMIT的做法是：\n别塞进去了，放抽屉里吧。\n他们发明了一个叫RLM的东西。\nRLM的核心思路是：\n不要让\nAI\n直接读那份巨长的资料，而是让AI用代码去翻那份资料。\n打个比方。\n以前的AI，就像一个学生，你把一整本教科书拍在他面前说：看完，然后回答我的问题。\n学生：？？？我看不完啊，我能不能看一部分？\n然后他就硬着头皮看前面的一部分，后面的直接放弃。\nRLM的做法不一样。\n它更像是给这个学生配了一个目录系统和搜索引擎。\n资料还是那份资料，但学生不用从头到尾读了。他可以先翻目录，看看大概结构，然后针对问题去搜索相关段落，把有用的信息摘出来。\n更牛的是，这个学生可以把一个复杂问题拆成好几个小问题，然后——注意重点来了——\n他可以召唤自己的分身，让分身去同时处理各个小问题，最后汇总答案。\n这就是递归的意思：AI可以调用自己的分身，让自己帮自己干活。\n或者再降维一下理解就是：\n它把这份超长的文档，当成一个\n放在外面的资料库\n，而不是直接塞进脑子里。\n然后，模型可以写代码，自己去查这个资料库。\n需要第一章的内容？写个代码去查。\n需要第十章的内容？再写个代码去查。\n需要把第一章和第十章的内容对比？\n那就先查第一章，做个总结，再查第十章，做个总结，最后把两个总结合起来。\n这就像是一个有无限容量的外置硬盘。\n模型的脑子里装不下那么多东西，没关系。\n可以随时去硬盘里查，用到什么查什么。\n这样一来，理论上，模型可以处理\n无限长\n的文档。\n具体怎么做的？\nMIT的实现方式其实挺优雅的。\n他们给AI配了一个Python编程环境（REPL），把那份超长的资料存成一个变量。\n然后AI不再直接去读这份资料，而是用代码去操作它。\n比如：\n想看资料有多长？写一行代码len(input_text)就知道了\n想看资料的前1000个字符？写input_text[:1000]\n想在资料里搜索关键词？写个正则表达式\n更厉害的是，AI可以把这份资料分段，把每一段交给一个子AI去处理，然后自己汇总结果。\n这个子AI，用的其实是同一个模型，只不过是递归调用自己。\n这个设计有两个巨大的好处：\n第一，\nAI\n不用在脑子里记住那份超长资料了。\n资料就放在外面的抽屉里，需要的时候用代码去取。\n这就意味着，理论上，资料可以无限长——只要抽屉够大。\n第二，\nAI\n可以自己判断需要看什么、不需要看什么。\n它不会傻乎乎地从头读到尾，而是会聪明地挑重点看。\n这大大节省了计算成本，也提高了准确率。\n效果到底有多猛？\nMIT在论文里做了一堆实验，结果还是挺震撼的。\n实验一：超长文档理解\n他们用了很多测试机，其中一个叫OOLONG的测试集，这个测试需要AI理解超长文档，并回答需要综合全文信息才能回答的问题。\n结果：GPT-5基座模型的准确率44%，而RLM达到了56.5%。\n而在CodeQA中，GPT-5基座模型的准确率24%，而RLM达到了62%，直接提升了2.7倍！\n实验二：超超超长文档（1000万+token）\n他们还把文档长度一路拉到1000万token以上（相当于几十本书的长度）。\nGPT-5？压根处理不了，直接爆炸。\nRLM(GPT-5)？稳稳当当，表现基本不掉。\n这是一个质的飞跃。\n实验三：成本对比\n你可能会想：这么牛逼的东西，是不是巨贵？\n神奇的是，并没有。\n在BrowseComp-Plus基准测试中，让GPT-5-mini直接处理600万-1100万token的输入，成本大约是1.5-2.75美元。\n而RLM(GPT-5)的平均成本只有0.99美元。\n更便宜，效果还更好。\n为什么？\n因为RLM不会傻傻地把所有内容都读一遍，它只读需要的部分。\n这个发现为什么重要？\nMIT这篇论文的意义，远不止于让AI处理更长的文档。\n它揭示了一个更根本的道理：\nAI\n的能力边界，不只取决于模型本身有多大、参数有多多，还取决于你怎么使用它。\n以前我们的思路是：模型不够强——那就加参数。\nMIT告诉我们：\n等等，也许不用加参数，让它多想几遍就够了。\n回到开头提到的那个发现：\n在多步推理任务中，仅增加2-4次递归处理，正确率就能提升10%-25%。大约4次迭代后，收益逐渐趋于平缓。\n这说明什么？\n大多数\nAI\n犯的错，都是初稿错误：不是它不懂，是它第一遍太草率了。\n让它返工几次，就能改对。（\n所以有时候，你在使用AI时，还真的当个监工，让AI多输出几次\n）\n这跟人类其实一模一样。\n任何牛逼的程序员都知道，第一版代码永远是最烂的，代码质量是改出来的，不是写出来的。\n任何牛逼的作家都知道，第一稿永远是废稿，好文章是改出来的，不是写出来的。\n现在，AI也一样了。\n未来展望\nMIT在论文最后提到，这只是一个开始。\n目前的RLM还有很多可以优化的地方：\n1.\n异步调用\n：目前子任务是一个接一个执行的，如果能并行执行，速度会更快。\n2.\n更深的递归\n：目前只允许一层递归（AI调用自己的分身），如果允许分身再调用分身，理论上能处理更复杂的任务。\n3.\n专门训练\n：目前RLM用的是现成的大模型，如果专门为递归思考训练一个模型，效果可能更猛。\nMIT的研究者们相信，这可能代表了大模型能力扩展的一个新方向：\n不是一味地堆参数、堆算力，而是让模型学会更聪明地思考。\n彩蛋\nMIT这篇论文，让我想起了一个老笑话：\n客户问程序员：这个bug你修了多久？\n程序员说：5分钟。\n客户说：那为什么收我500块？\n程序员说：找出问题在哪，花了我3天。\nAI也是一样。\n它的思考时间远比我们想象的更重要。\n给它一点返工的机会，它可能就能从还行变成牛逼。\n这也许就是下一代AI进化的方向：不是更大的脑子，而是更深度的思考。\n参考资料：\nhttps://x.com/a1zhang/status/2007198916073136152?s=20\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652660307&idx=1&sn=0dd61959a25f4ad1896852268be0359c&chksm=f068f8bada5987cb19f280adfd7f3c5084bc69cd2e70b635452eb5646f8cf69104b54b0e0d50&scene=0&xtrack=1#rd",
      "publish_time": 1767589920,
      "publish_date": "2026-01-05",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/pdf/2512.24601\", \"https://x.com/a1zhang/status/2007198916073136152?s=20\"]",
      "add_ts": 1767741700,
      "last_modify_ts": 1767741700
    },
    {
      "id": 286,
      "article_id": "51709",
      "title": "Nat. Biotechnol. | 实验×AI：加速RNA结构测定",
      "description": "DRUGONERNA的生物学功能依赖其动态三维结构，但因高度柔性与环境敏感性，结构解析长期受限。近年来，冷冻电镜等实验技术突破与受蛋白质预测启发的AI方法推动了RNA结构研究快速发展。文章综述了实验与人工智能技术在RNA结构解析中的最新进展，强调二者深度融合可显著提升解析的分辨率、效率与可行性，为RNA功能研究和药物开发提供关键支撑。",
      "content": "DRUG\nONE\nRNA 是细胞内关键的功能分子，其生物学作用高度依赖复杂而动态的三维结构。然而，RNA 的高度柔性、电荷特性以及对环境的敏感性，使其结构解析长期面临挑战。近年来，随着冷冻电镜等实验技术的突破，以及受蛋白结构预测成功启发的人工智能方法兴起，RNA 结构解析进入快速发展阶段。研究人员综述了实验技术与 AI 方法在 RNA 结构解析中的最新进展，重点强调二者的深度融合如何在分辨率、效率与可扩展性方面带来质的提升，并讨论了当前挑战与未来发展方向。\nRNA 结构解析的挑战与背景\nRNA 不仅通过经典的碱基配对形成二级结构，还依赖多种非经典相互作用和三级基序构建功能性构象。这些相互作用对离子环境和溶剂条件极为敏感，使得实验解析和计算建模均面临困难。尽管数据库中 RNA 结构数量持续增长，但与蛋白相比仍明显不足，且类型分布高度不均，严重制约了方法评估与模型泛化。传统实验手段在小 RNA、动态构象和无蛋白 RNA 体系中尤为受限，促使研究人员不断探索新的实验策略与计算工具。\n实验技术的新进展\n近年来，冷冻电镜在 RNA 结构解析中的适用范围显著扩大。通过引入 RNA 支架策略、改进样品制备流程以及新一代探测器，研究人员成功解析了多种小分子 RNA 和 RNA 多聚体的高分辨结构。同时，高分辨率冷冻电镜使得水分子和小配体的直接观测成为可能，为理解 RNA 的溶剂化和稳定机制提供了新视角。除冷冻电镜外，抗体辅助晶体学、原子力显微镜和核磁共振等技术也在捕捉 RNA 构象多样性和动态行为方面发挥着互补作用。\n图1 | RNA 结构数据增长趋势及冷冻电镜解析代表性实例。\nAI 驱动的 RNA 结构预测\n受蛋白结构预测革命性进展的推动，研究人员将深度学习引入 RNA 三维结构预测。现有方法通常利用序列进化信息、语言模型嵌入或预测的二级结构作为输入，通过两步式或端到端网络生成三维模型。这些 AI 方法在准确性和速度上显著优于传统自动化方法，并逐步扩展至 RNA–蛋白及 RNA–配体复合物预测。然而，由于 RNA 结构数据稀缺、进化信号弱以及动力学信息缺失，自动化预测仍难以全面超越人工专家。\n图2 | AI 驱动的 RNA 结构预测流程及典型预测示例。\n实验与计算的深度融合\n实验数据与计算方法的协同正在成为推动 RNA 结构生物学的核心动力。AI 不仅加速了冷冻电镜密度图到原子模型的解析，还通过生成式模型直接从原始粒子图像中探索构象异质性。与此同时，实验数据也反向为 AI 模型提供关键约束和训练信号，使预测结果更加符合物理和生物学现实。将不同分辨率、不同模态的实验信息系统性地融入生成模型，被认为是未来实现高效 RNA 结构解析的关键路径。\n图3 | 实验数据与 AI 方法协同解析 RNA 结构与动力学的代表性框架。\n讨论与展望\n实验技术与人工智能的持续融合正在重塑 RNA 结构解析的研究范式。未来的重要方向包括：识别并优先解析更多结构多样的新型 RNA、通过 AI 降低高分辨实验的门槛以加速结构测定流程，以及发展更具结构感知能力的 RNA 语言模型与生成模型。随着实验与计算之间的协同不断加深，研究人员有望更系统地揭示 RNA 结构与功能的内在联系，为生物技术和医学应用奠定坚实基础。\n整理 | DrugOne团队\n参考资料\nWang, W., Su, B., Peng, Z. et al. Integrated experimental and AI innovations for RNA structure determination. Nat Biotechnol (2026).\nhttps://doi.org/10.1038/s41587-025-02974-5\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512585&idx=2&sn=e0b34abe28e039539c8895175c8db25d&chksm=fda62522ad364707dfd45838c0e1d7c7611880796dc088fe00d57c1601ffc0e3be0ecc049bc2&scene=0&xtrack=1#rd",
      "publish_time": 1767803400,
      "publish_date": "2026-01-08 00:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s41587-025-02974-5\"]",
      "add_ts": 1767827947,
      "last_modify_ts": 1768001027
    },
    {
      "id": 291,
      "article_id": "51701",
      "title": "贝佐斯\\u002F比尔盖茨\\u002F英伟达\\u002F英特尔等押注，NASA工程师带队打造通用机器人大脑，公司估值达20亿美元",
      "description": "FieldAI致力于打造通用机器人智能大脑Field Foundation Models（FFMs），突破真实世界数据稀缺瓶颈。不同于传统“感知优先”路线，FFMs以物理约束为核心，从底层构建具备泛化与自主能力的具身智能系统，使机器人能在无地图、无预设环境中自主决策。通过任务执行中的数据闭环持续优化模型，实现智能进化。公司聚焦建筑、物流、能源等场景，推动机器人无需训练即可部署的通用化落地。",
      "content": "在大模型可以从互联网、图像库和海量文本中「无限生长」的今天，机器人却被困在另一个世界——真实世界的数据极度稀缺、昂贵且不可复用。Business Insider 曾发布过一则看似轻巧却又极具洞察力的报道，「AI 机器人面临数据荒，一家初创公司找到了出人意料的解决方案」。\n报道指出，相比语言和视觉模型几乎取之不尽的训练语料，机器人与现实世界交互所需的数据在规模、结构化程度和可迁移性上都远远不足，这成为机器人规模化智能的关键瓶颈，对此一家名为\nFieldAI\n的初创机器人公司给出了自己的答案。\n针对机器人在物理世界中数据规模不足、结构化程度有限的现实约束，FieldAI 选择了一条不同于主流感知优先路线的解决方式，从底层构建以物理约束为核心的通用机器人智能体系，以提升机器人在真实环境中的泛化与自主能力。\n公司官网： https://www.fieldai.com\nFieldAI 的宣言：不是只造机器人，而是造通用机器人大脑\n在绝大多数机器人公司致力于打造硬件和展示高难度动作的时代，FieldAI 选择了一条看起来更加长期主义的路线，它不以制造具体的单一机器人为最终目标，而是致力于打造能够跨不同类型机器人和适配各种环境的「通用机器人智能大脑」。\n这个通用大脑被称为 Field Foundation Models（FFMs），它不是某一种硬件或者单一功能的软件，而是专为\n具身智能\n构建的新型「以物理为先」的基础模型。\n通俗来讲，以物理为先与「先感知、后控制」的传统 AI 路线有本质区别，FFMs 从设计之初就把真实世界的物理约束、不确定性和风险作为模型的首要任务，而不是在模型输出后再用规则或控制器去兜底，这使得机器人在面对陌生环境时比如：没有地图、GPS 或者预定路线时，能够在现场做出决策具备更安全可靠的智能行为。\nFieldAI 自身也强调，机器人智能不仅是执行行为本身，更重要的是形成现实世界数据的闭环，在执行任务时产生的感知数据会不断反馈到模型，用于训练、优化和迭代，从而让智能持续进化。\n创始人 Agha 在阐述公司愿景时说道，「我们的客户无需精确的地图、甚至无需进行任何训练，只需按下一个按钮，机器人就能探索环境的每一个角落」。\n图源 FieldAI 官网\n在 FieldAI 的产品落地中，机器人正在承担现实世界中的刚需任务，他们将目光聚焦于建筑、物流、能源、采矿、电力、农业等传统工作场景，实现规模化的工业级自主运作。\n2025 年 11 月，FieldAI 与 DPR Construction 的合作案例就展示了在真实建筑工地创造的价值。装备 FieldAI 大脑的机器人可以自主巡视工地，自动采集数万张照片、扫描建筑内部、绘制大范围地图，并将这些数据转化为可用于进度跟踪、风险检测和质量分析的实时信息，这不仅节省了大量人工巡检时间，也提高了现场安全与效率。\n图源 FieldAI 官网\nNASA 工程师的「现实主义」革命\nFieldAI 独特的技术路线，在某种程度上可以说是深深植根于其创始人的工程背景之中。\n公司创始人兼 CEO\nAli Agha\n的职业履历中清晰的记录着，在 NASA 喷气推进实验室（JPL）的 7 年工作时光。他曾参 NASA 自主火星洞穴探索以及原型火星直升机-漫游车协同自主项目、\nDARPA RACER\n（越野自动驾驶汽车）等相关研究，细数这些项目便不难发现一个共通点：环境不可预测以及出错代价极高，几乎不存在人为干预的可能性。\n图源 NASA JPL Robotics 官网\n从学术背景来看，Ali Agha 也并不只是「做过 NASA 项目」的超级研究员，他还是长期亲自参与机器人核心智能问题与自主算法研究的学者。根据公开的学术成果可以总结出，他在多个机器人顶级会议和期刊中都围绕了一个主题进行过深入探讨——机器人如何在缺乏完整信息的情况下，自主理解环境并持续做出可靠决策。\n图源 Google Scholar 个人主页\n例如，Agha 与团队成员在 Journal of Field Robotics 上发表了题为「NeBula: Team CoSTAR’s robotic autonomy solution that won phase II of DARPA Subterranean Challenge」的论文，系统介绍了用于复杂、未知环境下机器人的自主决策框架\nNeBula\n，该框架能够在面对不完整感知和任务不确定性时，结合多模态信息进行风险感知、环境映射与路径规划。\n此外，他还参与了多篇发表在 IEEE Robotics and Automation Letters 等会议和期刊的研究工作。例如，在论文「Nonlinear MPC for Collision Avoidance and Control of UAVs With Dynamic Obstacles」中，探讨了无人系统在动态环境中进行安全控制与避障的问题；另一篇名为「LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging Large-Scale Underground Environments」的论文也展示了在大尺度、感知退化环境中，进行稳定地图构建的具体技术细节。\n或许正是在这样的工作与学术背景下，塑造了 Agha 对机器人智能更偏向「底层」的理解。以此为基石，FieldAI 汇聚了来自 DeepMind、特斯拉、SpaceX、NASA 以及亚马逊等顶级公司的技术精英，共同实现是让机器人能在现实世界中长时间稳定工作，并在不断变化的环境中能做出安全、合理决策的美好愿景。\n图源 IEEE Spectrum 的报道\n通用机器人 OS 的争夺战\nFieldAI 在 2023 年正式成立，但其在资本市场上的进展速度，远远快于一家初创公司的常规节奏。截止 2025 年 8 月，公司在不到两年时间内完成了超过 4.05 亿美元融资，投后估值约 20 亿美元，并且投资阵容十分豪华包括：贝佐斯的私人投资办公室、英特尔资本、英伟达风投部门、比尔盖茨的投资基金、三星等。这反映的不仅是数字规模问题，更是其背后所代表的资本判断。\n对这些投资方而言，押注 FieldAI 并不只是在选择某一款具体机器人产品，而是在押注一个更底层、更具通用性的智能发展方向。\n图源 FieldAI 官方 X 账号\n路透社曾在报道中援引 F-Prime Capital 的报告指出「2024 年全球机器人领域的投资额将飙升至 186 亿美元，比上一年增长 116%」，根据 F-Prime 在 2025 年下半年发布的最新动态数据进一步显示，这一增长势头并未放缓，全球机器人投资额预计在 2025 年有望突破 209 亿美元大关，刷新历史最高纪录。\n除此之外通用与垂直迎来了双重爆发，通用机器人（General Purpose） 的投资额预计从 19 亿美元飙升至 49 亿美元；针对特定场景的垂直机器人（Vertical Robotics） 则占据了半壁江山，规模从 81 亿美元跃升至 132 亿美元。\n图源 F-Prime Capital 报告\n在这样的背景下，FieldAI 所处的位置并没有在「通用」与「垂直」之间做单选题。一方面，它正全力投入的 通用机器人智能大脑，对应了迅速最快的通用机器人板块。正如 2025 年的投资者不再满足于买「一台会干活的机器」，而是在抢夺一张能让所有机器都学会干活的「入场券」。另一方面，FieldAI 着力产品在垂直场景的应用，通过解决建筑工地、检查、城市配送、能源等实实在在产生商业现金流的问题。也许正因如此，它才能同时获得芯片巨头、科技创始人及长期资本的共同押注。\n图源 FieldAI 官网\n具身智能行业的这些年\n如果说过去十年机器人行业的主旋律是看创新，那么接下来十年真正决定行业格局的将是规模化部署。\nFieldAI 的路径恰好切中这个结构性转折点，它不押注某一种机器人外形或单一场景，而是押注一套可扩张、可复用、可持续升级的「通用机器人大脑 + 数据基础设施」。\n在具身智能领域蓬勃发展的今天，共同期待着未来的机器人生态像当下的智能手机那个一样百花齐放，真正服务于人类便利于生活。\n参考链接：\n1.https://www.businessinsider.com/ai-robotics-data-problem-fieldai-surprising-fix-ali-agha-2025-9\n2.https://robobdtw2025.mapyourshow.com/8_0/sessions/session-details.cfm?scheduleid=100&\n3.https://spectrum.ieee.org/autonomy-unstructured-field-ai\n4.https://www.reuters.com/business/robotics-startup-fieldai-raises-314-million-new-funding-sources-say-2025-08-20/\n5.https://fprimecapital.com/blog/robotics-on-the-rise-the-state-of-robotics-investment-in-2025/\n内容中包含的图片若涉及版权问题，请及时与我们联系删除",
      "article_url": "https://hub.baai.ac.cn/view/51701",
      "publish_time": 1767787020,
      "publish_date": "2026-01-07 19:57",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.fieldai.com\", \"https://www.businessinsider.com/ai-robotics-data-problem-fieldai-surprising-fix-ali-agha-2025-9\", \"https://robobdtw2025.mapyourshow.com/8_0/sessions/session-details.cfm?scheduleid=100&\", \"https://spectrum.ieee.org/autonomy-unstructured-field-ai\", \"https://www.reuters.com/business/robotics-startup-fieldai-raises-314-million-new-funding-sources-say-2025-08-20/\", \"https://fprimecapital.com/blog/robotics-on-the-rise-the-state-of-robotics-investment-in-2025/\"]",
      "add_ts": 1767827965,
      "last_modify_ts": 1767914448
    },
    {
      "id": 292,
      "article_id": "51700",
      "title": "Nat. Mach. Intell. |  自监督图 Transformer 解码空间单细胞互作: 从细胞状态到生态位关联",
      "description": "GITIII是一种轻量、可解释的自监督图Transformer模型，用于解析单细胞分辨率下细胞—细胞相互作用。该模型将细胞视为“词”，其空间邻域作为“上下文”，充分利用空间转录组数据中的位置信息，增强配体–受体互作覆盖，提升对细胞状态与其生态位关系的理解，克服了现有方法在覆盖性、空间利用和可解释性方面的局限，为组织发育与器官功能研究提供了新工具。",
      "content": "DRUG\nONE\n细胞—细胞相互作用（CCI）是组织发育与器官功能维持的核心机制。尽管成像型空间转录组技术使单细胞分辨率的 CCI 研究成为可能，但现有分析方法仍受限于配体–受体覆盖不足、空间信息利用不充分以及模型可解释性弱等问题。研究人员提出 GITIII，一种轻量、可解释的自监督图 Transformer模型，将细胞视为“词”，其空间邻域视为“上下文”，通过解析细胞状态与其生态位（niche）之间的相关性来推断空间单细胞层面的相互作用。GITIII 能量化邻近细胞对受体细胞基因表达的影响，实现空间 CCI 可视化、基于 CCI 的细胞亚群划分以及 CCI 网络构建。该方法在多物种、多组织、多平台的四个空间转录组数据集中成功揭示了大脑与肿瘤微环境中的关键相互作用模式。\nCCI 既可通过直接接触介导，也可经由旁分泌/自分泌信号影响基因表达与细胞行为，其强度受空间距离、局部微环境、信号分子表达等多因素共同调控。当前多数计算方法依赖已知配体–受体对，往往忽略同一细胞类型内部的状态异质性，并且难以刻画距离对相互作用强度的连续影响。图神经网络虽引入了空间结构，但多层架构常导致可解释性不足。鉴于此，研究人员提出从**“邻域如何塑造细胞状态”**这一角度出发，直接建模邻近细胞对受体细胞转录状态的影响，以获得更具生物学可解释性的 CCI 推断。\n方法\nGITIII 以成像型空间转录组数据为输入，包括基因表达、空间坐标和细胞类型注释。模型首先将每个细胞的表达分解为细胞类型表达与细胞状态表达；随后基于空间邻近关系为每个细胞构建局部子图，并通过单层图 Transformer学习中心细胞与邻居细胞之间的相互作用。模型在自监督框架下预测中心细胞的状态表达，同时生成影响张量，用于量化不同邻居细胞对各基因表达的贡献。基于该影响张量，研究人员开展单细胞层面的空间可视化、同类型细胞内的 CCI 驱动聚类、细胞类型层面的 CCI 网络构建以及不同条件间的相互作用强度比较。\n图1 | GITIII 的整体架构。\n结果\nGITIII 总体框架与空间相互作用建模\nGITIII 能够在单细胞层面捕捉相互作用强度随距离衰减的总体趋势，同时识别出在一定距离范围内由信号表达差异驱动的强相互作用，说明空间接近性并非唯一决定因素。\n小鼠大脑皮层中的空间 CCI 模式\n在小鼠初级运动皮层数据中，GITIII 区分了不同细胞类型对之间的相互作用模式，并在星形胶质细胞和 L2/3 IT 神经元中识别出具有明确层特异分布的亚群。这些亚群的转录差异与其所处空间邻域高度一致，反映了微环境驱动的状态异质性。\n图2 | 小鼠大脑皮层中 CCI 模式及 CCI 驱动的细胞亚群划分。\n与基因表达直接关联的 CCI 网络\n通过构建基因层面的 CCI 网络，研究人员揭示了特定细胞类型对之间的相互作用如何上调或下调关键基因的表达。例如，神经元—神经元或胶质细胞—胶质细胞之间的相互作用与层特异基因表达变化高度一致。\n阿尔茨海默病脑组织中的 CCI 重塑\n在阿尔茨海默病患者脑组织中，GITIII 识别出小胶质细胞与神经元之间的异常相互作用模式，并发现与疾病风险基因相关的 CCI 网络在痴呆与非痴呆样本间存在系统性差异，提示免疫相关细胞在疾病进程中的重要作用。\n图3 | 阿尔茨海默病数据集中 CCI 网络差异及其与认知状态的关联。\n肿瘤微环境中的空间互作解析\n在非小细胞肺癌和乳腺癌数据中，GITIII 揭示了肿瘤细胞、免疫细胞和结构细胞之间复杂的双向调控关系。部分巨噬细胞和内皮细胞亚群显示出明显受肿瘤细胞影响的转录特征，反映了肿瘤驱动的微环境重塑。\n图4 | 肿瘤微环境中不同细胞亚群的 CCI 模式。\n图5 | 乳腺癌数据集中的细胞类型内异质性。\n跨数据集一致性与方法比较\n跨物种、跨平台分析表明，GITIII 在不同数据集中能够一致地识别相似的 CCI 规律。与多种现有方法相比，GITIII 在单细胞层面和细胞类型层面均表现出更强的空间一致性与解释能力。\n图6 | 跨数据集一致性分析与方法性能比较。\n讨论\nGITIII 提供了一种从“细胞状态—生态位相关性”角度理解空间 CCI 的新范式，避免了对配体–受体数据库的强依赖，并显著提升了模型的可解释性。该方法能够系统性揭示微环境如何塑造细胞状态，为理解脑功能、神经退行性疾病以及肿瘤微环境中的细胞互作提供了新的计算工具。未来，将该框架与多模态数据或时间维度结合，有望进一步拓展其在发育生物学和疾病研究中的应用。\n整理 | DrugOne团队\n参考资料\nXiao, X., Zhang, L., Zhao, H. et al. Inferring spatial single-cell-level interactions through interpreting cell state and niche correlations learned by self-supervised graph transformer. Nat Mach Intell (2025).\nhttps://doi.org/10.1038/s42256-025-01161-0\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512570&idx=2&sn=1a4c4ef2df0cde4295710c4c837fa0c7&chksm=fdc0ec590389aa225b1955e4a48dcf7cb0eb815586dbf260d9252374ee854b64c0963bfb4741&scene=0&xtrack=1#rd",
      "publish_time": 1767773400,
      "publish_date": "2026-01-07 16:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s42256-025-01161-0\"]",
      "add_ts": 1767827968,
      "last_modify_ts": 1767914454
    },
    {
      "id": 294,
      "article_id": "51698",
      "title": "陈天桥代季峰打响2026大模型第一枪：30B参数跑出1T性能",
      "description": "陈天桥与代季峰联合推出自研开源大模型MiroThinker 1.5，定位为搜索智能体领域的“最强小钢炮”。该模型在四项基准测试中表现优异，对标GPT-5-High、Gemini-3-Pro、DeepSeek-V3.2等顶尖模型，展现出强大竞争力，成为新年首个重磅开源成果，推动智能体模型发展。",
      "content": "鹭羽 发自 凹非寺\n量子位 | 公众号 QbitAI\n新年刚至，陈天桥携手代季峰率先打响开源大模型\n的第一枪。\n正式发布其自研的旗舰版搜索智能体模型——\nMiroThinker 1.5\n，堪称智能体模型领域的最强小钢炮。\n最直观的还是基准测试上的性能评测：\n在面对GPT-5-High、Gemini-3-Pro、DeepSeek-V3.2等一系列国内外顶尖模型，MiroThinker 1.5在四项基准测试中的表现都毫不逊色：\nHLE-Text\n（人类终极测试）\n：39.2%\nBrowseComp\n（网页检索类大模型基准测试）\n：69.8%\nBrowseComp-ZH\n（BrowseComp的中文适配版本）\n：71.5%\nGAIA-Val-165\n（GAIA基准测试验证集）\n：80.8%\n尤其是在BrowseComp上，直接刷新了ChatGPT-Agent保持的榜单纪录，强势跻身全球第一梯队。\n但要知道MiroThinker 1.5的参数规模只有它们的\n1/30\n，仅30B和235B大小。\n换句话说，在全行业大模型都在卷参数规模和上下文长度时，MiroThinker 1.5直接用高智效比跑出了相近甚至更好的效果，原因就在于它抓住了这股“巧劲”：\n给答案不靠死记硬背，而是通过大量深入的外部世界交互来逐步提升推理能力。\n比如将MiroThinker-v1.5-30B和1T参数的Kimi-K2-Thinking对比，不仅在BrowseComp-ZH测试中实现了4.5%的性能超越，在推理成本上，MiroThinker 1.5的单条调用成本更是低至$0.07，只有Kimi的1/20。\n不止如此，MiroThinker 1.5的推理速度也显著优于Kimi-K2-Thinking，足以见得\n“大”不等于“强”\n，叠参数也并非大模型的唯一通解。\n值得关注的是，它对开发者也相当友好，上线即开源。\n而负责操刀这款模型的正是\nMiroMind\n团队，此前曾凭借成功预测Polymarket\n（全球最大的去中心化预测市场）\n筛选题目，连续登顶Future X全球榜首，力压诸多国际顶尖机构和闭源商业模型。\nMiroThinker 1.5的推出，则是在团队已有的技术积累上更进一步，整体预测能力达到next level。\n那么具体效果如何？眼见为实，下面实测见真章。\n小参数也能跑进第一梯队\n实测之前，先简要介绍一下交互界面。\n（体验入口：\nhttps://dr.miromind.ai/\n）\n和常规的大模型对话窗口一致，点击左下角按钮即可升级为\n专业模式\n：内置更大尺寸的模型，同时支持文件上传。\nP.S.界面下方还有一些系统自动推荐的预测问题可供参考。\n下面我们先以一个基础的体育赛事预测为例，测试模型对实时信息的捕获和分析能力：\n在2026年即将举办的世界杯中，考虑到分组名单和球队阵容，请给出胜率预测及可能的原因。\n首先给我的第一感受是：\n快+完整\n。\n从输入问题到输出，总耗时两分钟，而且思维过程全部清晰可见。\n比如它会先梳理自己所需的全部信息，给出一条合理的预测路径：分组情况→阵容信息→胜率预测。\n接着在每一项具体步骤中，反思验证当前内容，并给出修正意见。\n根据上一步的反馈，模型会逐渐逼近最合理的答案。\n在这一点上，近似于数学的迭代，都是从一个初始猜测值出发，通过反复的过程计算，将结果一步步收敛到真实解。\n或者简单来说，就是和面时，水多了加面，面多了加水，最后总能成型。\n那么再看输出的结果，和模型一般最后放结论不同，MiroThinker 1.5直接开门见山，先给整体结论，以及详细的概率统计。\n（用户体验感UP！）\n然后它会对每一支热门球队都进行一一阐述，包括所在小组情况、各阶段的出线概率和多角度原因，乃至可能遇到的隐患。\n即使是一些概率较低的可能性，它也能面面俱到。\n不过显然，MiroThinker 1.5在青春风暴VS老将最后一舞里，更支持前者。\n（doge）\n接着我们再预测一个经典问题：GTA 6什么时候发？\n也算是回归陈天桥的老本行了。\nGTA 6明年能按时发布吗？请收集相关线索，给出确定性的回答。\n很合理！预测逻辑严谨且层层递进，核心围绕着R星官方发布的权威信息，进行了多维度交叉验证，强化结果的可信度。\n这次我们再将同样的问题，交给ChatGPT、Gemini和DeepSeek，看看它们又会给出怎样的结果。\nChatGPT：和MiroThinker 1.5的逻辑闭环相似，既遵循了行业规律，也为普通用户提供了建议。\nGemini：虽然把核心时间说清楚了，但证据支撑不足、缺乏风险提示。\nDeepSeek：和Gemini类似，缺少关键背景补充，分析维度也相对单一。\n有意思的是，仔细回看Gemini和ChatGPT的分析过程，它们都不约而同地在解释为什么2025年不能发……\n一顿操作猛如虎，结果忘了已经2026。\n更深入一步，最后我们尝试将MiroThinker 1.5放进专业场景中测试，比如\n股市预测\n。\n请根据今天A股的指数面，情绪面，板块以及前几天的情况，帮我选择一只连板梯队里最有可能晋级的股票。\n（注：以下仅为技术展示，不构成投资建议）\n同样，MiroThinker 1.5非常之快，不只是推理速度快，收集新信息的速度也相当快。\n在股市这类不确定性强的复杂环境中，MiroThinker 1.5能够做到有理有据，既不是凭感觉走的玄学赌徒，也不是事后找补的诸葛亮，而是在极度噪声化环境中做到证据集合和可验证的因果推断。\n总之实测下来，MiroThinker 1.5确实是一款区别于市面上同类产品的模型，调用轻松、思考过程可视、逻辑也更严明，不靠单一猜测下定论，而是在不断复盘交互中逐步逼近真相。\nu1s1，光冲着这理性全面的证据链，就值得一个点赞。\n将交互内化进模型推理，用确定性对抗不确定性\n问题是为什么MiroMind团队能率先做到这一点？\n关键依然在“大力出奇迹”。\n在过去一年里，行业普遍存在的问题是过度依赖堆参数叠资源，本质来说就是让模型吃进更多知识，然后思维链沿着已记住的知识空间一步步往前推。\n一旦其中一步发生偏离，后面所有步骤都会随着这个错误累计放大，最终导致整条逻辑链崩坏。\n换言之，当模型参数规模到达一定程度后，继续堆资源对模型预测的边际收益只会迅速下降，行业不得不寻找新的智能增长路径。\nMiroThinker 1.5的解法恰恰在于将推理过程和外部环境深度绑定，为每一轮推理都引入一个反馈校验环节，构建起一整条\n“推理-验证-修正”\n的循环路径。\n首先是将\nInteractive Scaling\n从原先的推理阶段前移，并内化为训练阶段的核心机制，把模型训练成一个更注重求证、校验和自我修正的探索型Agent。\n范式的转变决定了模型不再局限于内部知识和单次长链推理，而是通过和物理世界建立更深入的交互，以强化自身的行为模式：\nEvidence-Seeking\n（主动求证）\n：模型会将每个关键判断拆解为可验证子假设，并主动发起对外查询、检索与比对。如果输出缺乏信源支撑，则会受到惩罚。\nIterative Verification\n（多轮校验与自我修正）\n：\n推理过程不再是一次性路径，而是允许反复回溯修正。当发现证据矛盾时，会立即进行调整，而非像传统思维链那样将错误延续下去。\nAnti-Hallucination\n（对捷径的系统性过滤）\n：\n对过去一些看似合理但缺乏证据的推理结果给予否定，并标记为低质量推理。相比之下，更关注“怎样得出答案”，而非只是简单的对错。\n由此，MiroThinker 1.5形成了行之有效的本能反应：\n对于不确定性问题，先交互再判断；对于高风险结论，先查证再收敛。\n模型不再依赖全部的世界知识，也无需那么多的参数支持，就能够按需地向外部世界精准取证，最终促成更小的参数规模，却拥有更高的智能密度。\n而这正是MiroThinker 1.5推理成本显著降低，但性能始终保持一线水准的根本原因。\n其次是让模型杜绝复述结果，实现未来预测的关键因子——\n时序敏感训练沙盒\n。\n传统大模型表面上看似是预测，实则只是在知识库里搜索结果并复述出来，或者是使用未来时间范畴的数据超前“剧透”，时序敏感训练沙盒则为模型戴上一个“紧箍咒”，严格约束只能使用当前可见的信息，并做出真实预测。\n它可以分为两步，其一是可控数据合成引擎，负责构建覆盖多任务类型的、难度与时间戳可控的数据合成体系。\n每一道题目的答案都会随着时间戳动态演化，判断过程会严格限制信息可见性，校验阶段同样也会显式引入时间戳约束，以确保推理逻辑和评分标准都符合真实世界的时间因果关系。\n其二是时序敏感训练机制，在每一步训练中都只能访问当前时间戳之前的信息，从机制上彻底杜绝Future Leakage\n（未来信息泄露）\n，模型无法超前看到结果。\n这样下来，模型就会被迫学会在信息不完备、噪声存在、信号延迟的真实条件下完成推演，并随着新证据的出现不断修正判断。\n时间也从原来被忽视的背景变量，升级为塑造模型行为与推理方式的核心约束，使模型更接近真实世界时序的认知与决策过程。\n模型的预测能力不再是不可知的黑箱过程，而是可训练强化的关键要素。\n当预测被拆解为一系列可约束、可反馈、可修正的行为模式之后，模型能力的上限也随之发生改变：\n性能提升不再简单取决于参数规模的线性扩张，而开始受益于模型与外部世界交互的方式与效率。\n做题家模式 VS 科学家模式\n而这套以小搏大的逻辑背后，正是MiroMind团队长期以来对Scaling Law的再解读。\n早在模型1.0版本中，MiroMind就首次系统性提出了除模型规模、上下文长度之外的第三大核心可扩展维度Interactive Scaling，把智能的增长空间瞄准到外部世界。\nV1.5则是在此基础上，进一步落地融入贯穿训练与推理的全流程。\n传统的Scaling Law，走的是靠大脑更大解决问题的路线，本质上是\n“做题家模式”\n，靠记忆和统计，而非真正理解和验证。\n反之当模型内化Interactive Scaling，它就不再是靠概率瞎猜，而是像\n科学家\n一样建立起慢思考的研究闭环：提出假设→向外部世界查数据/取证→发现对不上→修正假设→再查证，直到证据收敛到合理范围之内。\n这样能有效降低Scaling Law导致的幻觉，提升可靠性。\n所以与其说这是算力的博弈，不如说是底层逻辑的转变在影响算力的着力点：算力没有集中用于模型的知识储备，毕竟知识无限，但算力始终有限。\n有限的算力无法覆盖掉全部的知识，所以不妨转换思路，将算力效益最大化，也就是引向该去的地方——\n对外的信息获取与交互\n，把智能的扩展维度从“更大脑袋”变成“更勤快的手”。\n这一点也与MiroMind始终强调的\n发现式智能\n不谋而合，即在未知条件下重建对世界的理解，抽丝剥茧发现真相而非简单地记住答案。\n它不靠全知，而靠会研究、会查证、会修正。它能像顶级情报官一样对外极速取证、对内严苛去伪存真；像严谨研究员一样在不确定性里逼近真相，把“预测未来”从特权变成能力。\n显然，陈天桥带领下的MiroMind已经率先转换赛道，找到了智能“奇点”的关键所在，是\n交互\n。\nP.S. 如果感兴趣的话，可以加入官方社群：\nDiscord ：https://discord.gg/F7EQFnYscV\n微信社群：添加小助手 miromind001\n体验网站：https://dr.miromind.ai/\nGithub代码地址：https://github.com/MiroMindAI/MiroThinker\nMiroFlow开源框架：https://github.com/MiroMindAI/MiroFlow\nHugging Face模型下载：https://huggingface.co/miromind-ai/MiroThinker-v1.5-235B\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860263&idx=1&sn=fb6ac9c674c6cc4909c66662e49a413f&chksm=e94d2b16cfea59e5a8710ac3bae3559b932da55948153c59e9c37eb618e656f855a0f27c1d66&scene=0&xtrack=1#rd",
      "publish_time": 1767770400,
      "publish_date": "2026-01-07 15:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://dr.miromind.ai/\", \"https://discord.gg/F7EQFnYscV\", \"https://github.com/MiroMindAI/MiroThinker\", \"https://github.com/MiroMindAI/MiroFlow\", \"https://huggingface.co/miromind-ai/MiroThinker-v1.5-235B\"]",
      "add_ts": 1767827974,
      "last_modify_ts": 1767914465
    },
    {
      "id": 297,
      "article_id": "51695",
      "title": "真实音频场景，大模型集体挂科！首个原生语音基准MultiChallenge",
      "description": "Scale AI发布首个原生音频多轮对话基准Audio MultiChallenge，揭示大模型在真实语音场景中的表现远不如文本领域。实验显示，即便如Gemini 3 Pro等先进模型，在真实人声对话中通过率仅过半，GPT-4o Audio表现更差，暴露出当前模型在处理自然语音交互时的严重缺陷，打破依赖合成语音评测的“优等生”假象，凸显语音理解能力亟待突破。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n文本领域的大模型满分选手，换成语音就集体挂科？大模型引以为傲的多轮对话逻辑，在真实人声面前竟然如此脆弱。Scale AI正式发布首个原生音频多轮对话基准Audio MultiChallenge，直接撕开了大模型靠合成语音评测维持的优等生假象。实验显示，强如Gemini 3 Pro在真实场景下的通过率也仅过半数，而GPT-4o Audio的表现更是令人大跌眼镜。\n随着实时语音大模型的普及，人们一度以为AI实时伴侣已经跨越了自然交互的最后一道门槛。\n然而，大模型在语音对话中表现出的聪明，很大程度上源于评测手段的滞后。\n此前，Scale AI推出的MultiChallenge基准凭借对指令保留、推理记忆和自我一致性的严苛考察，被公认为评估大模型逻辑长性的黄金标准。\n但长久以来，该基准一直缺少一个真正的音频原声版本。\n最近，Scale AI正式补齐了这块拼图，发布Audio MultiChallenge，不仅刷新了语音交互的新高度，更揭开了行业内一个公开的秘密：\n由于缺乏原生音频测试集，模型厂商在发布报告时，往往不得不利用T2S（Text-to-Speech）将文本基准转换为语音进行评测\n。\n论文链接：https://arxiv.org/pdf/2512.14865\n这种做法虽然让数据看起来很漂亮，却在无形中给模型加了一层过度美化的滤镜。\n撕掉语音外壳\n为什么TTS测不出真本事？\n利用TTS转换来进行评测，实际上是为模型营造了一个完美的无菌环境。\nTTS 生成的语音平滑、规律且高度标准化，彻底过滤掉了人类语言中最重要的特质：日常说话时的各种吞吐、重复、琐碎停顿以及临时改口。\n当你对AI说：\n我想定周一，哦不，是周三的票，等下……还是周二吧。\n这种充满了逻辑回溯和口语碎片的自然场景，是目前TTS技术极力避免但在现实生活中无处不在的。\n过去，模型穿上了一层由合成语音搭建的语音外壳，本质上是在用文本思维处理洁净信号。\n而一旦脱离这个外壳，面对Audio MultiChallenge中47名真实说话者录制的原始音频，模型的逻辑链条便会迅速崩塌。\n论文直言不讳地指出：模型在合成语音上的得分显著高于真实人声，这证实了干净的合成音频掩盖了模型在现实世界中的失败模式（Masking real-world failure modes）。\nGemini 3 Pro勉强登顶\nGPT-4o意外折戟\n标题\nAudio MultiChallenge延续了原版的严苛逻辑，并针对音频特性新增了致命的一击，从指令保留、推理记忆、自我一致性以及核心的Voice Editing（语音编辑） 四个轴向对模型进行综合考核。\n根据论文公布的排行榜，目前全球顶尖模型的音频原生能力普遍处于及格线以下：\n实验数据揭露了一个惊人的落差：Gemini 3 Pro Preview凭借其推理架构在逻辑深度上维持了领先；而GPT-4o Audio Preview在面对真实人类语音时，表现出的鲁棒性远低于预期，通过率甚至只有Gemini的一半左右。\n揭秘三大失败模式\n语音逻辑的深层鸿沟\n论文通过详细的错误分析，精准捕捉到了模型在音频模态下的三个软肋，这些结论直接指出了大模型在语音交互中的底层Gap：\n语音编辑是逻辑黑洞：\n这是本次基准新增的维度。当用户在说话过程中中途改口或逻辑回溯时，大多数模型会死板地执行听到的第一个指令。该维度的平均通过率仅为17.99%，这意味着模型在听觉上无法有效处理信息的撤回与覆盖。\n时长驱动的崩溃：\n模型表现随着音频总时长增加而稳步恶化。数据显示，当对话累计音频超过8分钟时，模型的自我一致性得分会骤降至 13% 左右。这意味着目前的语音模型在处理长程语音上下文时，状态追踪能力极其薄弱。\n音频线索的感知缺失：\n当任务要求模型识别非语义信号（如背景的环境声、说话人的语气情绪）来辅助推理时，模型表现比纯语义任务下降了 36.5%。这说明模型依然把语音当成脱水的文字在读，而没能真正听懂声音背后的物理世界。\n结语\nAudio MultiChallenge的发布证明了语音绝不仅是文本的简单投射，包含着实时状态跟踪、情绪理解以及复杂的口语特质处理。\nScale AI的这一记重锤敲醒了业界：如果我们不能撕掉那层精美的语音外壳，解决模型对自然语音中不完美特征的感知断层，那么AGI驱动的自由交互，将永远停留在听懂单词却不懂逻辑的初级阶段。\n参考资料：\nhttps://arxiv.org/pdf/2512.14865\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652661349&idx=2&sn=5e7613c1d84794522e5d04019da62b44&chksm=f031b937fd02871fb443140a72f4421e257741ccee6d482ab13130ff0f45ec4b86a430cb83d4&scene=0&xtrack=1#rd",
      "publish_time": 1767770040,
      "publish_date": "2026-01-07 15:14",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/pdf/2512.14865\"]",
      "add_ts": 1767827986,
      "last_modify_ts": 1767914485
    },
    {
      "id": 299,
      "article_id": "51693",
      "title": "2025人工智能大事件回顾丨科技巨头篇",
      "description": "2025年1月，中国AI初创企业DeepSeek发布开源推理模型DeepSeek-R1，性能媲美OpenAI的o1模型，训练成本仅约600万美元，远低于行业水平，引发全球AI市场震动。该成果标志着中国在大模型领域的重要突破，推动全球科技巨头重新审视研发策略与成本效益，成为年度人工智能发展的重要里程碑之一。",
      "content": "2025\n人工智能\n科技巨头大事件\nKNOW\n年度大事件\n清华大学人工智能国际治理研究院\nAI\n2025人工智能大事件回顾\n科技巨头篇\n-2025 Annual Major Events-\n1月\n中国DeepSeek发布R1推理模型，震动全球AI市场\n1月20日，中国AI初创公司DeepSeek发布了开源推理模型DeepSeek-R1，宣称其性能与OpenAI的o1模型相当，但训练成本仅为约600万美元——远低于OpenAI GPT-4约1亿美元的训练成本。该模型采用MIT许可证开源发布，引发全球科技界震动。1月27日，DeepSeek的消息导致英伟达市值单日蒸发约6000亿美元，创下美国公司史上最大单日市值损失纪录。DeepSeek证明了即使在美国芯片出口限制下，中国仍能开发出具有竞争力的AI模型，这一事件也推动了开源AI模型的发展浪潮。\n2月\n特朗普宣布Stargate项目，5000亿美元投资AI基础设施\n1月21日，美国总统特朗普在白宫宣布了名为\"Stargate\"的AI基础设施投资计划。该项目由OpenAI、软银和甲骨文联合发起，计划在四年内投资高达5000亿美元，用于在美国建设AI数据中心。软银CEO孙正义担任项目主席，OpenAI负责运营。项目首批1000亿美元将立即投入使用，首个数据中心已在德克萨斯州阿比林开工建设。特朗普称这是\"史上最大的AI基础设施项目\"，将创造超过10万个美国就业机会。马斯克对此表示质疑，声称\"他们实际上没有这笔钱\"，但OpenAI CEO阿尔特曼进行了反驳。\n3月\nAnthropic完成35亿美元融资，估值达615亿美元\n3月3日，Anthropic宣布完成35亿美元融资，投后估值达到615亿美元。本轮融资由Lightspeed Venture Partners领投，Salesforce Ventures、思科投资、富达等机构参与。Anthropic由前OpenAI高管创立，其Claude AI助手已成为ChatGPT和Google Gemini的主要竞争对手。截至年初，公司年化收入已达10亿美元。融资将用于推进下一代AI研发，特别是在机制可解释性和对齐研究领域。\n3月\n谷歌发布Gemini 2.5，引入\"思考\"能力\n3月25日，谷歌发布了其最智能的AI模型Gemini 2.5，首个版本为Gemini 2.5 Pro实验版。这是谷歌首款具备\"思考\"能力的模型，能够在回答前进行推理过程，在数学、科学、编程等领域的基准测试中达到最先进水平，并在LMArena排行榜上以显著优势位居第一。\n4月\nMeta发布Llama 4系列模型，首次采用MoE架构\n4月5日（周六），Meta发布了全新的Llama 4模型系列，包括Llama 4 Scout和Llama 4 Maverick，以及仍在训练中的Llama 4 Behemoth。这是Llama系列首次采用混合专家（MoE）架构和原生多模态设计。Scout拥有17B活跃参数、109B总参数和10M token上下文窗口；Maverick同样拥有17B活跃参数，但总参数达400B，拥有128个专家。Meta声称其教师模型Behemoth（约2万亿参数）在STEM基准测试中超越了GPT-4.5、Claude Sonnet 3.7和Gemini 2.0 Pro。当被问及为何选择周六发布时，CEO扎克伯格简单回应：\"准备好了就发了。\"\n5月\nAnthropic正式发布Claude Code，编程助手市场爆发\n5月，Anthropic正式发布了Claude Code开发工具，专为软件工程师设计。该工具通过命令行和编辑器插件（VS Code、JetBrains等）集成，提供AI驱动的结对编程、调试和多文件代码编辑功能。凭借在SWE-bench上72.5%的成绩，Claude Code被认为是市场上最强大的编程助手之一。该产品迅速获得市场认可，到8月已产生超过5亿美元的年化收入，三个月内使用量增长超过10倍。\n7月\n英伟达成为全球首家市值突破4万亿美元的公司\n7月10日，英伟达收盘市值首次突破4万亿美元大关，成为史上第一家达到这一里程碑的上市公司。在AI芯片需求持续火爆的推动下，英伟达的市值此时已超过英国所有上市公司的总和。从2023年6月的1万亿美元，到2024年2月的2万亿美元、6月的3万亿美元，英伟达仅用了约一年时间就实现了市值的四倍增长。\n8月\nOpenAI发布GPT-5，整合推理与通用能力\n8月7日，OpenAI通过直播活动正式发布了GPT-5。这是继GPT-4之后的第五代生成式预训练变换器模型，首次将推理能力与非推理功能整合到统一接口中。发布时，GPT-5在数学（AIME 2025达94.6%）、编程（SWE-bench Verified达74.9%）、多模态理解等多项基准测试中达到最先进水平。据OpenAI表示，GPT-5的响应速度更快、编程和写作能力更强、健康问题回答更准确、幻觉率也大幅降低。然而，部分用户反映GPT-5的语气较GPT-4o显得\"平淡\"和\"缺乏创意\"，OpenAI CEO阿尔特曼随后表示将优化模型的个性化表现。\n8月\nOpenAI发布首个开源模型GPT-OSS，应对中国开源浪潮\n8月5日，在GPT-5发布前两天，OpenAI发布了GPT-OSS，这是自2019年GPT-2以来该公司首次发布开放权重模型。阿尔特曼在后来的采访中承认，来自中国开源模型（尤其是DeepSeek）的竞争影响了这一决定，他表示：\"很明显，如果我们不这样做，世界将主要建立在中国的开源模型之上。\"这标志着OpenAI战略方向的重大转变。\n9月\nAnthropic完成130亿美元融资，估值跃升至1830亿美元\n9月2日，Anthropic宣布完成130亿美元F轮融资，投后估值达1830亿美元，较3月估值增长近三倍。本轮融资由ICONIQ领投，富达和Lightspeed联合领投，Altimeter、General Catalyst、Coatue等参与。公司表示，年化收入已从年初的约10亿美元飙升至8月的超过50亿美元，成为史上增长最快的科技公司之一。Anthropic服务超过30万企业客户，包括Netflix、Spotify、Salesforce等知名企业。\n10月\n英伟达成为全球首家市值突破5万亿美元的公司\n10月29日，英伟达股价上涨超过3%，收盘市值突破5万亿美元，成为人类历史上首家达到这一里程碑的公司。从4万亿到5万亿，英伟达仅用了约三个月时间。当天，特朗普总统表示将与黄仁勋讨论Blackwell芯片对华出口事宜，为股价注入额外动力。英伟达CEO黄仁勋在此前一天披露，公司已获得5000亿美元的芯片订单，并宣布与诺基亚合作开发6G技术、与Uber合作开发自动驾驶汽车。此时，英伟达的市值已超过除美国和中国以外所有国家的GDP。\n11月\n谷歌发布Gemini 3，开启智能新时代\n11月，谷歌发布了Gemini 3，这是其有史以来最强大的AI模型。据报道，Gemini 3 Pro的发布让OpenAI进入\"红色警戒\"状态，该模型迅速占据AI排行榜榜首位置。在LMArena排行榜前10名中，谷歌独占4席，是表现最好的公司；OpenAI唯一进入前10的模型排名第8。Gemini 3被引入Google搜索的AI模式，标志着首次在发布当天就将最新模型应用于搜索产品。谷歌还宣布在德克萨斯州投资400亿美元用于AI和云基础设施建设。\n11月\n谷歌宣布400亿美元德克萨斯州AI基础设施投资\n11月，谷歌和Alphabet CEO桑达尔·皮查伊与德克萨斯州州长格雷格·阿博特共同宣布了400亿美元的AI和云基础设施投资计划。这是谷歌2025年AI投资推进计划的收官之作，该计划旨在释放经济机遇、推进科学突破，投资范围覆盖美洲、欧洲、非洲和亚太地区。计划还包括培训10万名电气工人和创造3万个新学徒岗位的美国劳动力发展计划。\n12月\n特朗普政府允许英伟达H200芯片出口中国\n12月，特朗普总统宣布允许英伟达向中国出口H200芯片，但需向美国财政部缴纳15%的销售收入作为费用。这是继禁止最先进Blackwell芯片出口后的政策调整。H200是英伟达上一代Hopper架构中最强大的AI芯片，其性能约为中国国产最先进加速器的2-3倍。消息传出后，阿里巴巴、字节跳动等中国科技巨头立即联系英伟达下单，据报道订单量已达200万片，远超英伟达当前70万片的库存。英伟达已开始与台积电协商增加H200产能。\n12月\n谷歌发布Gemini 3 Flash，以速度和效率取胜\n12月17日，谷歌发布了Gemini 3 Flash，这是其旗舰模型的更高效、更经济版本，旨在帮助用户更快速地处理复杂查询。Gemini 3 Flash将取代Gemini应用中的2.5 Flash，并成为Google搜索AI模式的默认模型。该模型结合了前沿模型的速度与改进的推理能力，为博士级推理能力提供了堪比大型模型的表现，同时在多模态理解方面实现了重大飞跃。",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU4MzYxOTIwOQ==&mid=2247522448&idx=1&sn=0d4c3e43b74c75cad9cc487f21581c64&chksm=fc946796350c91ae22b6cfb60f9399e767017b19c5074a8e501efbbfa604b57d04d5f0e901c9&scene=0&xtrack=1#rd",
      "publish_time": 1767760800,
      "publish_date": "2026-01-07 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767827992,
      "last_modify_ts": 1767914497
    },
    {
      "id": 300,
      "article_id": "51692",
      "title": "英特尔CES奇袭老黄大本营！英伟达显卡刚涨价，最强酷睿量产出货",
      "description": "英特尔推出史上最强AI PC处理器——第三代酷睿Ultra，基于关键的Intel 18A制程节点打造，标志其重返制程领先地位。该处理器由客户端计算事业部高级副总裁Jim Johnson发布，性能与AI能力大幅提升，旨在推动PC在本地运行复杂AI任务的能力，强化英特尔在AI computing领域的竞争力。",
      "content": "金磊 发自 拉斯维加斯\n量子位 | 公众号 QbitAI\n千呼万唤始出来，\n英特尔\n迄今\n最强\nAI PC处理器，正式开卖了——\n第三代\n英特尔\n®\n酷睿\n™\nUltra\n处理器，首款基于Intel 18A制程节点打造。\n没错，就是那个被英特尔中国区董事长王稚聪比作\n重庆\n、被视为英特尔重回制程霸主地位的关键一役的18A。\n在现场，英特尔客户端计算事业部高级副总裁兼总经理\nJim Johnson\n介绍说：\n第三代英特尔\n®\n酷睿\n™\nUltra**处理器，有望成为英特尔有史以来覆盖范围最广的AI PC平台。\n这次的发布，意味着英特尔不仅兑现了制程节点的计划，更是直接把半导体制造带入了一个全新的维度。\n这款处理器除了提升了能效、增强CPU的性能之外，另一大看点就是集成了自家的\nArc GPU\n。\n为什么这么说？\n因为除了自身性能比较彪悍之外，还有一个非常有意思的看点，那就是重新定义了SOTA这个概念：\nState of the Arc。\n一个字母之差\n（SOTA：State of the Art，最先进的）\n，也是彰显了英特尔对自家GPU实力的自信。\n有点意思，着实有点意思。\n那么这款英特尔客户端最强的处理器，性能到底几何，我们具体往下看。\n英特尔最强AI PC处理器\n在聊性能之前，必须先看懂这次的底层杀手锏——Intel 18A。\n正如我们刚才提到的，这是英特尔重回制程霸主地位的关键一役，相比传统的芯片设计，18A工艺在方寸之间实现了两大核心黑科技的突破，这也是第三代酷睿Ultra的物理基础：\n第一，RibbonFET（全环绕栅极晶体管）。\n简单说，以前的晶体管电流控制像是在水管一面装阀门，现在是把水管四面都包起来控制。这样一来，开关更精准，漏电更少。这让芯片在微观层面的控制力达到了前所未有的高度。\n第二，PowerVia（背面供电技术）。\n以前的芯片，供电和信号传输都在晶圆的正面，容易造成信号干扰和拥堵。PowerVia技术创造性地将供电电路移至晶体管背面。\n这样一来，信号在上面跑，电力在下面供。互不干扰，还能大幅降低电压损耗。\n根据官方数据，靠着这两手绝活，Intel 18A制程让芯片在相同功耗下性能提升超过15%，或者在相同性能下功耗降低25%以上，晶体管密度更是直接提升了30%。\n而刚刚发布的第三代酷睿Ultra\n（代号Panther Lake）\n，就是这一集大成者的首秀。\n看电影能持续27小时\n基于Intel 18A打造的SoC，到底给AI PC带来了什么体验上的质变？\n英特尔这次在移动端直接亮出了两款大杀器：\n酷睿Ultra X9\n和\n酷睿Ultra X7\n。\n旗舰型号最高配备了16个CPU核心。其中包括了全新的性能核\n（P-Core）\n和能效核\n（E-Core）\n，甚至还有12个X\ne\n核心。\n至于名字的命名，初衷是因为这是一个非线性的产品切换，需要一个让最终用户找到的产品，加之此前英特尔已有产品名字，因此取名为X7和X9。\n但最让游戏党兴奋的，绝对是显卡。\n这次集成的英特尔Arc\n™\n显卡，配合18A工艺的红利，图形处理能力直接起飞。\n官方实测数据显示，相比于上一代口碑极佳的Lunar Lake平台\n（酷睿Ultra 9 288V）\n，新的酷睿Ultra X9在1080p高画质设定下，45款游戏的平均帧率提升了77%！\n注意，这可是核显啊朋友们。这意味着轻薄本也能随时随地从容应对复杂的游戏负载。\n以及，英伟达在前几个小时的发布会上没有发新游戏卡，而且价格还涨了，这一波是属实利好英特尔~\n而且不仅仅是游戏。\n在生产力方面，多线程性能提升了60%\n（基于Cinebench 2024测试）\n。\n这意味着无论是剪视频、跑代码，还是同时开几十个网页摸鱼，这颗芯都能处理得游刃有余。\n最后就是\n续航\n。\n通常性能暴涨意味着功耗崩盘，但得益于18A的超高能效比，这一代处理器的持久续航达到了惊人的27小时。\n基本上，出差两天甚至都不用带充电器了。\n除此之外，这次英特尔在性能上也拿酷睿Ultra X9和英伟达 Jetson Orin做了对比，也是完胜的结果：\n边缘处理器和PC做到了同步\nAI PC时代，怎么能不谈算力？但这次英特尔的野心不止于PC。\n第三代酷睿Ultra在AI方面进行了全面重构，旗舰型号的NPU算力达到了50 TOPS。\n配合强大的GPU和CPU，整个平台在大语言模型、端到端视频分析以及视觉语言动作模型中表现出了显著的竞争优势。\n在体验中心，量子位也感受了一把在英特尔AI Playground中，断网情况下运行大模型和处理图像、视频等多模态任务的速度：\n更关键的是，这次有一个重磅动作：\n边缘处理器与PC版本同步发布。\n这是3系列处理器首次针对嵌入式和工业边缘场景获得测试与认证。\n这意味着，第三代酷睿Ultra不仅会装进你的笔记本，还会被装进具身智能机器人、智慧城市的摄像头、自动化生产线和医疗设备里。\n它支持宽温范围，拥有确定性以及7x24小时全天候的可靠性。相较于传统的多芯片CPU和GPU架构，这种单芯片系统（SoC）方案能提供卓越的总体拥有成本（TCO）。\n敲黑板，划重点了：什么时候能买到？\n不用等到明年，就在本月！\n1月6日：首批搭载第三代酷睿Ultra的消费级笔记本开启预售。\n1月27日：全球正式发售/面市。\n目前已有超过200+款PC产品设计正在路上，覆盖了从消费级PC到边缘计算的广泛领域。\nOne More Thing：\n这次英特尔在CES上的发布会中，\n中国企业\n身影的占比也是越发的重了起来。\n首先在\n大厂\n方面，\n字节跳动\n直接独占了主论坛PPT的一页；更重要的是，字节跳动的云计算（火山引擎）与英特尔已经有了深度的合作：\n在\n新秀\n方面，此次英特尔邀请的比较有意思的ISV是\n新智慧游戏\n，主攻AI\n游戏陪练\n。\n目前已经覆盖CS2、英雄联盟等四款主流游戏，并且断网和实时都是可以的哦~\n至于搭载18A的英特尔\n®\n酷睿\n™\nUltra**处理器实际效果如何，就要等用户们的真实反馈了。\n若是有友友们体验过了，欢迎回来留言哦~\n—\n欢迎AI产品从业者共建\n—\n📚\n「AI产品知识库」\n是量子位智库基于长期产品库追踪和用户行为数据推出的飞书知识库，旨在成为AI行业从业者、投资者、研究者的核心信息枢纽与决策支持平台。\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860181&idx=2&sn=975320d672bcebf8b8c3b25dcb94f72a&chksm=e9fa003fcae796ba4cc5d6646b38ef5d59050a68c630151b9c9e23633531ca49d432b0e49a9b&scene=0&xtrack=1#rd",
      "publish_time": 1767760800,
      "publish_date": "2026-01-07 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767827995,
      "last_modify_ts": 1767914503
    },
    {
      "id": 301,
      "article_id": "51691",
      "title": "任意图像+视频=无限创意！港科大BiCo：AI视频进入组合时代，随意换角",
      "description": "BiCo是一种创新的AI视觉内容生成方法，通过分层绑定器、多样化与吸收机制及时间解耦策略，实现图像与视频中视觉概念的灵活组合与可控编辑。该技术提升了概念一致性与提示忠实度，解决了传统方法在概念提取与融合上的局限，显著增强AI对视觉元素的理解与组合能力，适用于视频制作、艺术创作等场景，为内容创作者提供高效、精准的工具支持。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\nBiCo是一种创新的AI视觉内容生成方法，能灵活组合图像和视频中的视觉概念，实现可控编辑。它通过分层绑定器、多样化与吸收机制、时间解耦策略等技术创新，解决了现有方法在概念提取和组合上的问题，让AI真正理解并融合视觉元素。BiCo在概念一致性、提示忠实度等方面表现优异，可应用于视频制作、艺术创作等领域，为创作者带来强大助力。\n在AI视觉内容生成领域，如何将多种视觉概念无缝融合，一直是研究的热点。\n现有的主流方法主要存在两大问题：\n概念提取不准确：\n现有方法使用LoRA适配器或可学习嵌入来提取概念，但面对\n遮挡、时间变化\n等复杂场景时，难以准确分解概念，对于\n非物体概念\n（如风格、光照变化）的提取能力有限。\n组合方式太局限：\n现有方法主要局限于「用视频中的动作来驱动图片中的主体」，无法灵活组合图像和视频中的\n各种属性\n（如视觉风格、光照变化等），虽然图像域已有灵活组合的探索，但\n任意图像+视频的通用组合\n和\n可控的概念组合编辑\n仍是未解难题。\n近日，来自香港科技大学、香港中文大学等机构的研究人员提出了一种名为\nBiCo（Bind & Compose）\n的创新方法，能够灵活组合任意数量的图像和视频，实现可控的对应元素概念组合编辑，创造出全新的创意内容，在\n概念一致性、提示忠实度和运动质量\n等方面均优于现有方法。\n项目主页\n：\nhttps://refkxh.github.io/BiCo_Webpage/\n论文链接：https://arxiv.org/abs/2512.09824\n还记得《无间道》中那个经典的屋顶对峙场景吗？\n梁朝伟和刘德华站在屋顶，背后是香港的城市天际线\n——这个场景已经成为影史经典。\n现在，想象一下：\n如果把这个经典场景中的角色换成\n哈士奇和杜宾犬\n，会是什么效果？\n使用BiCo方法可以轻松实现：\n输入：\n两张狗狗的照片（\n哈士奇\n、\n杜宾犬\n）+ 《无间道》屋顶场景视频\n输出：\n生成一段视频——\n哈士奇站在屋顶，杜宾犬出现在身后，背景是熟悉的城市天际线\n这不是简单的「换脸」，而是AI真正理解了场景中的\n空间关系、人物位置、背景环境\n等复杂概念，并将来自不同来源的视觉元素完美融合。\n这还只是BiCo能力的冰山一角，实际上，它可以做的远不止这些。\n想象一下这样的场景，你有一张\n秋田犬\n的照片，还有一段\n人类在客厅玩游戏\n的视频。现在，你想让AI帮你生成一段视频：「\n一只穿着红色格子衬衫、戴着黑色耳机的秋田犬，兴奋地举起爪子，手持游戏手柄，沉浸在游戏中。」\n或者，你有两张图片（\n我的世界风格的风景\n、\n火山爆发\n）和一段\n蝴蝶在花上扇动翅膀\n的视频，想让AI将它们组合成一个创意视频。\n这些看似「不可能」的创意组合，现在都可以通过\nBiCo\n轻松实现。\nBiCo的三大创新\n让AI真正「理解」视觉概念\nBiCo方法的核心思想是：\n将视觉概念与文本提示词绑定，然后灵活组合来自不同来源的绑定token\n。\n具体来说，BiCo包含三大技术创新：\n分层绑定器结构（Hierarchical Binder Structure）\n问题\n：\n如何准确分解复杂的视觉概念？\n在Diffusion Transformer（DiT）的交叉注意力机制中，设计\n分层绑定器结构；\n将视觉概念编码到对应的文本token中；\n实现\n隐式分解\n，无需显式的掩码输入。\n效果\n：\n当组合来自多个来源的概念时，目标提示中的概念token会通过对应的绑定器传递，从而整合视觉特征，实现基于文本条件的概念组合。\n多样化与吸收机制（Diversify-and-Absorb Mechanism, DAM）\n问题\n：\n如何提高concept-token绑定的准确性？\n多样化\n：在训练时对单样本提示进行多样化处理，同时保留关键概念\n吸收\n：引入额外的\n吸收令牌\n，在训练过程中消除与概念无关的细节影响\n效果\n：\n通过这一机制，BiCo能够更精确地绑定概念，避免无关信息的干扰。\n时间解耦策略（Temporal Disentanglement Strategy, TDS）\n问题\n：如何增强图像和视频概念之间的兼容性？\n将视频概念的训练过程\n解耦为两个阶段\n：\n第一阶段\n：在单个帧上训练绑定器，不涉及时间概念（与图像概念训练设置一致）\n第二阶段\n：在视频上训练绑定器，采用\n双分支绑定器结构\n进行时间建模，同时继承第一阶段的知识\n效果\n：\n通过分阶段训练，BiCo能够更好地处理图像和视频概念的组合，提升兼容性。\nBiCo模型整体架构\nBiCo分层绑定器结构结构；BiCo多样化与吸收机制\n实验结果\n全面超越现有方法\n在实验评估中，BiCo在多个维度上均优于现有方法：\n定量结果\n概念一致性\n显著提升，\n提示忠实度\n明显改善，\n运动质量\n更加自然流畅。\n定性结果\n案例1：动作迁移（图像+视频）\n输入：\n一张\n小猴子\n的图片 + 一段\n松鼠在阳光下吃东西\n的视频\n输出：\n生成一只小猴子在阳光下吃东西的视频，完美结合了猴子的外观和松鼠的动作\n可控编辑\n：\n精确指定使用猴子的外观概念和松鼠的动作概念进行组合\n案例2：创意风格迁移（图像+视频）\n输入：\n一张\n线条艺术风格的大象\n图片 + 一段\n大象行走\n的视频\n输出：\n生成线条艺术风格的大象行走视频，成功融合了艺术风格和运动\n可控编辑\n：\n精确控制风格概念和运动概念的组合方式\n生成线稿风格大象视频，BiCo与之前方法的对比结果\n案例3：多概念组合（多图像+视频）\n输入：\n三张图片（\n快乐的秋田犬\n、\n时尚服装套装\n、\n蓝白条纹帽子\n）+ 一段\n女子坐在木制长椅上读书\n的视频\n输出：\n生成秋田犬穿着服装套装和帽子，坐在木制长椅上读书的视频，完美融合了来自三个图像源的不同概念元素（主体、服装、配饰）和视频场景（动作和场景）\n可控编辑\n：\n灵活组合来自多个图像源的不同概念元素（主体外观、服装、配饰）和视频概念（动作、场景），实现复杂的多概念编辑\n案例4：多视频组合\n输入：\n两段视频（\n弹吉他的男子\n、\n穿绿色西装举小号的男子\n）\n输出：\n生成弹吉他的男子与举小号的男子同时出现的视频，将两个视频中的不同人物和动作进行组合\n可控编辑\n：\n用户可以精确指定要从每个视频中提取和组合的概念元素（人物外观、动作、场景等）\n与可灵O1对比：BiCo在概念组合上的显著优势\n为了更直观地展示BiCo的优势，我们将其与业界领先的视频生成模型\n可灵O1\n进行了比较。\n将《我的世界》风格、火山爆发与蝴蝶振翅三个概念，融合成一段创意视频\n。\n输入的视频与图片概念\nBiCo的生成结果\n可灵O1的生成结果\n概念一致性：BiCo更精准\nBiCo\n：能够保持生成结果中\n蝴蝶栖息在花朵上的姿势状态一致\n，花朵始终存在，蝴蝶与花朵的关系保持稳定\n可灵O1\n：\n花朵直接消失了\n，蝴蝶变成了在空中飞行的状态，完全偏离了输入视频中的概念\n概念泄漏控制：BiCo更严格\nBiCo\n：\n火山喷发状态与输入图片完全相同\n，精确保持了输入图像中的喷发特征，没有引入额外的无关元素\n可灵O1\n：存在\n概念泄漏\n，火山喷发状态与输入图片不一致，出现了输入中不存在的元素\n风格一致性：BiCo更忠实\nBiCo\n：\n像素艺术风格的流体效果（流动的岩浆）表现完美\n，成功将像素艺术风格应用到动态的岩浆流动中，保持了整体风格的统一\n可灵O1\n：\n岩浆没有变成像素艺术风格\n，风格迁移失败，导致生成的视频中风格不一致\n通过这个对比案例，我们可以清晰地看到BiCo在以下三个关键维度上的显著优势：\n1.\n可控性更强\n：\nBiCo能够精确控制要组合的概念元素，实现保持概念高度一致性的组合，用户可以精确指定要保留和组合的视觉特征\n2.\n概念一致性更高\n：\nBiCo能够准确保持输入概念的状态和关系，避免概念丢失或改变（如蝴蝶与花朵的关系、火山喷发状态）\n3.\n提示词忠实度更好\n：\nBiCo能够忠实执行用户的组合意图，在复杂多概念组合场景中，仍然能够准确地将不同来源的概念按照提示词要求进行组合（如像素艺术风格的完整应用）\n应用场景\n为创作者打开新世界\nBiCo支持任意数量的图像和视频输入，实现可控的概念组合编辑，应用场景非常广泛：\n视频内容创作\n电影制作\n：将任意多个场景的元素进行可控组合，创造新的视觉效果\n广告创意\n：快速组合多个创意素材，生成个性化广告视频\n短视频\n：为内容创作者提供强大的多素材组合工具，实现精确的概念编辑\n艺术创作\n风格迁移\n：将多个艺术风格与真实场景进行可控组合\n概念设计\n：快速组合多个概念元素，可视化创意想法\n动画制作\n：灵活组合多个动画元素，简化动画制作流程\n技术优势\n为什么BiCo更强大？\n灵活性\n支持\n任意数量的图像和视频\n进行组合（图像+图像、图像+视频、视频+视频、多图像+多视频等）\n可以组合\n物体、风格、动作、光照\n等各种视觉概念\n实现\n可控的对应元素概念组合编辑\n，用户可以精确指定要组合的概念元素\n准确性\n通过分层绑定器和DAM机制，实现更精确的概念提取\n避免概念泄漏和无关信息干扰\n兼容性\n通过TDS策略，增强图像和视频概念之间的兼容性\n更自然的组合效果\n易用性\n单样本学习\n：只需一张图片或一段视频即可进行概念绑定\n无需掩码\n：不需要手动标注，降低使用门槛\n灵活组合\n：支持任意数量的输入源，实现多概念的可控组合\n结语\nAI视觉创意的未来已来\nBiCo方法的提出，标志着AI视觉内容生成领域的一个重要突破。它不仅解决了现有方法在概念提取和组合方面的局限，更为视觉内容创作提供了新的工具和思路。\n随着技术的不断发展和完善，我们有理由相信，AI将在视觉创意领域发挥越来越重要的作用，为创作者打开无限可能。\n参考资料：\nhttps://refkxh.github.io/BiCo_Webpage/\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652661319&idx=2&sn=16a07c40ab7cb36f7dabcba42baeb672&chksm=f0131c2788e9d2dea83b2a4a33f234adbccad283dd4e2a5141495b2db57abe8c25589da43d9c&scene=0&xtrack=1#rd",
      "publish_time": 1767760800,
      "publish_date": "2026-01-07 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://refkxh.github.io/BiCo_Webpage/\", \"https://arxiv.org/abs/2512.09824\"]",
      "add_ts": 1767827998,
      "last_modify_ts": 1767914509
    },
    {
      "id": 305,
      "article_id": "51687",
      "title": "老黄All in物理AI！最新GPU性能5倍提升，还砸掉了智驾门槛",
      "description": "西风 闻乐 发自 凹非寺量子位 | 公众号 QbitAI刚刚，英伟达CEO黄仁勋穿着鳄鱼皮夹克，在全球最大消费电子展CES 2026上发布AI新品。这是五年来，英伟达首次来到CES却没有发游戏显卡，态度很明确：全力搞AI。全力搞出来的结果也让围观群众直呼：竞争对手如何追上英伟达？下一代Rubin架构GPU推理、训练性能分别是Blackwell GB200的5倍和3.5倍（NVFP4数据格式）。除此",
      "content": "西风 闻乐 发自 凹非寺\n量子位 | 公众号 QbitAI\n刚刚，英伟达CEO黄仁勋穿着鳄鱼皮夹克，在全球最大消费电子展\nCES 2026\n上发布AI新品。\n这是五年来，英伟达首次来到CES却没有发游戏显卡，态度很明确：\n全力\n搞AI。\n全力搞出来的结果也让围观群众直呼：竞争对手如何追上英伟达？\n下一代Rubin架构GPU\n推\n理、训练性能分\n别是\nBlackwell GB\n200的5倍和3.5倍\n（NVFP4数据格式）。\n除此之外，老黄还带来了五大领域的全新发布，包括：\n面向Agentic AI的\nNVIDIA Nemotron\n模型家族\n面向物理AI的\nNVIDIA Cosmos\n平台\n面向自动驾驶开发的全新\nNVIDIA Alpamayo\n模型家族\n面向机器人领域的\nNVIDIA Isaac GR00T\n面向生物医学的\nNVIDIA Clara\n同时，英伟达宣布持续向社区\n开\n源训\n练框架\n以\n及\n多模\n态数据\n集\n。其中数据集包括10万亿语言训练token、50万条机器人轨迹数据、45.5万个蛋白质结构、100TB车辆传感器数据。\n这次的核心主题，直指\n物理AI\n。\n用网友的话来说：\n这是英伟达将护城河从芯片层进一步拓展到全栈平台层（模型+数据+工具）的体现，通过这种方式可以持续拉动更多GPU与基础设施投入，并显著增强用户与生态的锁定。\n值得一提的是，咱国产开源模型又双叒被cue到了。\n老黄在演讲开篇便提及了DeepSeek，Kimi K2、Qwen也出现在PPT展示页上。\n正式推出Vera Rubin NVL72\n老黄正式推出英伟达下一代AI数据中心的机柜架构\nVera Rubin\n，披露架构细节。\n六大\n核心组\n件共同构成Vera\nRubin NVL72机\n架：\nVera CPU、Rubin GPU、NVLink 6 switch、ConnectX-9 SuperNIC、BlueField-4数据处理单元（DPU）、Spectrum-6 Ethernet switch。\n在NVFP4数据类型下，Rubin GPU\n推理性能可达50 PFLOPS，是Blackwell GB200的5倍\n；NVFP4\n训练性能为35 PFLOPS，是Blackwell的3.5 倍\n。\n为支撑这些计算能力，\n每颗Rubin GPU封装了8组HBM4内存\n，提供288GB容量和22 TB/s的带宽。\n随着主流大模型转向MoE架构，模型得以相对高效地进行规模扩展。然而，这些专家模块之间的通信，对节点间带宽提出了极高要求。\nVera Rubin引入了用于规模内扩展网络的\nNVLink 6\n。\n它将单GPU的互连带宽提升至3.6 TB/s（双向）。每颗NVLink 6交换芯片提供28 TB/s的带宽，而每个Vera Rubin NVL72机架配备9颗这样的交换芯片，总规模内带宽达到260 TB/s。\nNVIDIA\nVera CPU集成了88个定制的Olympus Arm核心\n，采用英伟达称为“spatial multi-threading”设计，最多可同时运行176个线程。\n用于将Vera CPU与Rubin GPU进行一致性连接的NVLink C2C互连，其带宽提升了一倍，达到1.8 TB/s。每颗Vera CPU可寻址最多1.5 TB的SOCAMM LPDDR5X内存，内存带宽最高可达1.2 TB/s。\n为将Vera Rubin NVL72机架扩展为每组8个机架的DGX SuperPod，英伟达推出了一对采用共封装光学（CPO）的\nSpectrum-X以太网交换机\n，\n均基于Spectrum-6芯片构建\n。\n每颗Spectrum-6芯片提供102.4 Tb/s的带宽，英伟达基于该芯片推出了两款交换机。\nSN688提供409.6 Tb/s的总带宽，支持512个800G以太网端口或2048个200G端口。\nSN6810则提供102.4 Tb/s的带宽，可配置为128 个800G或512个200G以太网端口。\n这两款交换机均采用液冷设计，英伟达表示，与不具备硅光子技术的硬件相比，它们在能效、可靠性和运行时间方面表现更优。\n随着上下文窗口扩展到数百万token，英伟达还指出，存储AI模型交互历史的键值缓存（KV cache）相关操作，已成为推理性能的瓶颈。\n此前黄仁勋曾表态：\n没有HBM，就没有AI超算\n。\n为突破这一限制，英伟达推出新硬件\nBlueField-4 DPU\n，构建了一个新的内存层级，称为推理上下文内存存储平台（Inference Context Memory Storage Platform）。\n英伟达表示，这一存储层旨在实现键值缓存数据在AI基础设施中的高效共享与复用，从而提升系统响应速度和吞吐能力，并实现Agentic AI架构可预测、能效友好的规模扩展。\n这是Vera Rubin首次将英伟达的可信执行环境扩展至整个机架级别。\n整体来看，每个Vera Rubin NVL72机架可提供：\n3\n.\n6\nexaFLOPS的NVFP4推理性能\n2.5\nexaFLOPS的NVFP4\n训练\n性能\n54 TB的LP\nDDR5X内存\n（连接至Vera\nCPU）\n2\n0\n.7 TB的HBM4内存，带宽达\n1.6 PB/s\n为保障机架系统的持续高效运行，英伟达在机架层面引入了多项改进，包括无缆化模块托盘设计，使组件更换速度显著快于此前的NVL72机架；增强的NVLink弹性能力，实现零停机维护；以及第二代RAS引擎，可在不中断服务的情况下完成健康检测。\n另外，英伟达表示，与Blackwell相比，\nVera Rubin在训练MoE模型时所需的GPU数量仅为四分之一；在MoE推理场景下，其每token成本最高可降低10倍\n。\n反过来看，这也意味着Rubin能在相同机架空间内，大幅提升训练吞吐量，并生成远多于以往的token数量。\n据介绍，目前用于构建Vera Rubin NVL72所需的六类芯片已全部从晶圆厂交付，英伟达预计将在2026年下半年启动Vera Rubin NVL72的规模化量产。\n自动驾驶全新开源模型系列发布\n再来看英伟达重磅推出的全新开源模型系列——\nAlpamayo\n，面向安全推理的自动驾驶。\n全球首款开源、大规模的\n自动驾驶视觉-语言-行动（VLA）推理模型\nAlpamayo 1\n，参数100亿。\n它能够让自动驾驶车辆理解周围环境，并对自身的决策行为做出解释。\n模型接收车辆自身的运动历史数据、多摄像头采集的实时视频画面、用户指令三类输入信息，然后进行推理，之后生成具体的驾驶决策、因果推理结果、规划出的行驶轨迹。\n配套推出的还有一款\n开源仿真框架\n——\nAlpacaSim\n。\n它支持在各种不同的环境与边缘场景中，对基于推理的自动驾驶模型进行闭环训练与评估。\n此外，英伟达还发布了一个包含\n1700小时驾驶数据的开源数据集\n。这些数据采集于全球最广泛的地理区域与环境条件下，涵盖了推进推理架构发展所必需的罕见及复杂真实边缘场景。\n落地方面，据介绍，Alpamayo将率先搭载于2025年第二季度欧洲上市的梅赛德斯-奔驰CLA车型，后续将通过OTA升级逐步推送高速公路脱手驾驶、城市全场景自动驾驶、端到端自动泊车等功能，并计划登陆美国市场。\n英伟达基于自身技术构建的全球L4级自动驾驶与Robotaxi生态系统全景也亮相了，通过连接软件开发商、整车厂/出行平台、硬件供应商，覆盖全产业链。\nNemotron再推专项模型\nNVIDIA Nemotron在AI智能体领域的新拓展，核心是在已发布的Nemotron 3开放模型与数据基础上，进一步推出针对\n语音\n、\nRAG\n以及\n安全\n三大场景的专项模型。\n其中，\nNemotron Speech\n包含新的自动语音识别（ASR）模型，不仅语音识别性能强，而且能支持实时字幕生成这样的\n实时低延迟场景\n，速度比同类模型快10倍。\n英伟达表示，目前博世已采用该模型实现司机与车辆之间的交互。\nNemotron RAG\n则搭载新的视觉语言模型，能精准处理多语言、多模态数据，有效提升文档搜索效率。\nNemotron Safety\n系列模型专注于增强AI应用的安全性与可信度，具体包括支持更多语言的Llama Nemotron内容安全模型，以及高精度检测敏感数据的Nemotron PII模型。\n机器人推理大脑Cosmos升级\n活动现场，老黄宣布英伟达为机器人推出的懂推理的“大脑”Cosmos再度升级。\nCosmos主要被用来生成符合现实世界物理规律的合成数据，自发布以来，已被Figure、Agility Robotics、通用汽车等一众知名机器人和自动驾驶公司采用。\n这次全新发布了：\nCosmos Reason 2\n：一款全新的、排名领先的视觉-语言推理模型（VLM）。它能够帮助机器人与AI智能体更精准地感知、理解并与物理世界进行交互。\nCosmos Transfer 2.5与Cosmos Predic\nt\n2.5\n：两款领先的模型，可在各种不同的环境与条件下，生成大规模的合成视频。\n英伟达还基于Cosmos模型，为各类物理AI应用推出了专用的开源模型与参考蓝图：\nIsaac GR00T\nN1.\n6\n：一款专为类人机器人打造的开源视觉-语言-行动（VLA）推理模型。它支持机器人的全身控制，并集成了英伟达Cosmos Reason模型，以实现更强大的推理能力与上下文理解能力。\nNVIDIA AI Blueprint for Video Search and Summarization\n：作为英伟达Metropolis平台的一部分，该蓝图提供了一套参考工作流，可用于构建视觉AI智能体。这些智能体能够分析大量的录播及直播视频，从而提升运营效率并保障公共安全。\n据了解，Salesforce、Milestone、Hitachi、Uber、VAST Data、Encord等企业正采用Cosmos Reason模型，开发面向交通与职场生产力提升的AI智能体。Franka Robotics、Humanoid和NEURA Robotics则利用Isaac GR00T模型，在机器人大规模量产前，对其全新行为进行仿真、训练与验证。\n针对医疗健康与生命科学的AI\nNVIDIA Clara是专门针对医疗健康与生命科学领域的AI技术工具。\n核心目标是降低行业成本、加速治疗方案落地，打通数字科研与实际医疗应用之间的壁垒。\n该系列中的多款专项模型各有侧重：\nLa-Proteina\n能设计原子级精度的大型蛋白质；\nReaSyn v2\n在药物发现阶段就开始考虑“如何生产”的问题；\nKERMT\n可以预测潜在药物进入人体后的反应，提前排查安全问题；\nRNAPro\n用来预测RNA分子复杂的3D结构，推进个性化医疗方案。\n模型之外，老黄表示英伟达还将为研究者提供含45.5万个合成蛋白质结构的数据集。\n总之，老黄的2026开年第一讲，真是让人眼花缭乱了……\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860123&idx=1&sn=5da5c9583d4fdcdd019954d37e787224&chksm=e989915497f7fa627124367f441b5b58990923e9ed13f0f882f118038e53830331733b5550db&scene=0&xtrack=1#rd",
      "publish_time": 1767747240,
      "publish_date": "2026-01-07 08:54",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767828013,
      "last_modify_ts": 1767914527
    },
    {
      "id": 308,
      "article_id": "51736",
      "title": "谷歌看了都沉默：自家「黑科技」火了，但为啥研发团队一无所知？",
      "description": "Gemini 3 Flash以3倍于前代的速度和超越Pro级的推理能力，被误认为实现“直觉”模拟，实则其所谓“并行验证循环”仅为AI生成的社交网络幻象，揭穿了科技圈对谷歌新技术的过度神化，揭示AI进步背后仍存夸大与误解。",
      "content": "新智元报道\n编辑：KingHZ\n【新智元导读】\n当整个科技圈都在为「谷歌黑魔法」集体高潮时，真相恐给了所有人一记耳光。那套被捧上神坛的「并行验证循环」，不过是社交网络上AI生成的「赛博跳大神」。\n如果说之前的AI模型是在模拟人类的思考，那么\nGemini 3 Flash就是在模拟人类的「直觉」。\n3倍于Gemini 2.5 Pro的速度\n，却拥有超越Pro级的推理能力。\n更离谱的是，\n它的智力竟然在某些基准测试超越了自家的Pro大哥。\n但目前为止，依然没人能说明白：Flash凭为什么比Pro还要「聪明」。\n谷歌DeepMind到底有啥黑魔法？\n「林子大了，什么鸟都有」，以至于X上网友Jainam Parmar爆料：\nAlphaGo团队根本不使用思维链。\n他们采用并行验证循环机制。\n这套方法正在碾压你听说过的所有「高级推理」技术。\n成千上万的网友浏览过这个帖子。\n这靠谱吗？这有没有可能是「以讹传讹」、用AI生成的「假新闻」？\n如果是假新闻，难道只是因为「DeepMind碾压同行的推理」这样的噱头吗？\n我们先看一下推文到底讲了啥。\n谷歌DeepMind的黑科技?\n首先，这位「万能的网友」直击CoT命门，解释了\n为什么Chain-of-Thought很糟糕。\n当前的AI推理是线性的：\n思考步骤1→步骤2→步骤3。\n但这并不是专家级问题解决者的思维方式。\n然后，他写道：「DeepMind分析了他们的AlphaGo团队是如何应对复杂问题的，结果发现了一件非常惊人的事情。」\n并行验证循环（Parallel Verification Loops）：\n专家型思考者并不会沿着一条冗长的推理链一路走到底，而是同时运行多个验证循环。\n他们会提出一个解决方案，用约束条件去检验它；必要时回退；同时探索其他可能的路径——这些过程是并行发生的。\n而Chain-of-Thought做不到这一点。\n架构上的差异（The Architecture\nDifference\n）：\n传统的思维链：A→B→C→D（线性）\nDeepMind的框架：A→[B1,B2,B3]→分别验证→精炼→迭代\n这就好比是在一条路上一直往前走，而另一种方式则是同时探索整棵决策树。\n结果非常夸张：\n在复杂推理基准测试中：\n相比标准的Chain-of-Thought，性能提升\n37%\n捕捉逻辑错误的能力提升\n52%\n收敛到正确解的速度快了\n3倍\n这不是小幅优化，而是\n架构层面的飞跃\n。\n它实际是如何运作的\n：\n步骤1：同时生成多个候选解决方案\n步骤2：每个方案各自运行一套验证循环\n步骤3：不同方案之间进行交叉验证\n步骤4：剪除较弱的分支，强化更有潜力的路径\n步骤5：持续迭代，直到收敛\n自我纠错优势：\n这才是杀手级特性：系统在\n给出最终答案之前\n，就能发现并纠正自己的错误。\n传统的CoT（思维链）是按步骤顺序「提交」的，只要其中一步出错，后面就全盘皆输。\n而\n并行验证\n允许在不中断整体流程的情况下回溯和修正，而不必从头再来。\n对训练方式的影响：\n他们不只是测试了这种方法，而是\n直接用这一框架来训练模型\n。\n模型学会了：\n提出多个假设\n让这些假设相互检验\n通过验证逐步建立置信度\n尽早剪除错误或低质量的推理路径\n现实世界中的应用：\n这一框架在以下场景中表现尤为强大：\n数学证明\n（一步出错，整体就会崩塌）\n代码调试\n（可能同时存在多个潜在Bug）\n战略规划\n（需要探索复杂的决策树）\n科学推理\n（假设提出与验证）\n凡是\n正确性优先于速度\n的地方，它都具备压倒性优势。\n如果你正在构建\nAI\n智能体或推理系统，Chain-of-Thought已经过时了。\n未来属于\n并行验证（Parallel Verification）\n。\n生成多条路径。\n对它们进行测试。\n让最优解自然浮现。\n这正是AlphaGo击败世界冠军的方式。\n这也是推理真正运作的方式。\n疑点重重，被AI袭击的一天？\n在这些描述中，「并行验证」简直就是为数学证明和代码调试量身定制的终极武器。\n凡是追求正确性的场景，它似乎都能实现降维打击。\n这套理论听起来是不是太完美了？简直就像是DeepMind真的把人类直觉代码化了一样。\n但恰恰是这种「过度的完美」和「极具煽动性」的文风，引起了业内人士的警觉。\n当成千上万的网友还在为这套「黑魔法」转发点赞时，冷静下来的人们开始追问一个最基本的问题：\n这套东西，到底是谁说的？\n发帖的Jainam Parmar，也不是什么AI研究领域的大牛，也不是谷歌DeepMind的员工。\n他也没有明确给出DeepMind的可信的源链接。\n他说的靠谱吗？\n即使DeepMind放缓发布世界知名的研究成果，以便在AI竞赛中赢得先机。\n但DeepMind仍在发布他们的研究成果。\n去年11月初，谷歌DeepMind团队还发布了号称解决「可持续学习」难题的新的机器学习范式──嵌套学习（nested learning）。\n原推文那种藏头露尾、吊人胃口的写作风格，令人不喜，甚至部分网友怀疑，帖子压根就是大模型生成的！\n熟悉DeepMind研究工作的网友，则认为帖子在故弄玄虚，甚至歪曲原意！\n更有网友毫不客气地指出，发帖人就是蹭热度，半年前他还在鼓吹「CoT就是下一代推理技术」。\n还有更关键的证据，之后，另一网友Chris Laub发布了一模一样的内容：\n帖子底下，也有网友怀疑，这就是诱导人点击的AI垃圾！\n事实上，CoT早不是什么先进技术。\n长思维链和短思维链截然不同。\n长思维链，有三大关键特征: 深度推理、广泛探索和可行的反思。\n这些特征使得模型能够处理更复杂的任务，并且与较浅的短思维链相比，产生更高效、更连贯的结果。\n回到问题本身：Gemini 3\nFlash 到底凭什么更聪明？\n至少目前，没有任何可靠证据表明DeepMind已将「并行验证循环」作为核心推理框架，全面取代Chain-of-Thought。\n相反，这场风波更像一次典型的 AI 舆论实验—— 当模型表现出现异常跃迁，人们总是更愿意相信「黑魔法」，而不是渐进式优化。\n真正值得警惕的，也许不是CoT是否过时，而是我们是否\n过度迷信单一解释\n。\n推理的未来，未必只有一条路，但谣言，往往只需要一条推文。\n参考资料：\nhttps://github.com/LightChen233/Awesome-Long-Chain-of-Thought-Reasoning\nhttps://x.com/iruletheworldmo/status/2007550905177256071\nhttps://x.com/aiwithjainam/status/2005629090943193552\nhttps://x.com/ChrisLaubAI/status/2006668516280197287\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652662456&idx=2&sn=85de0aeab3607f802190df2c81c599d7&chksm=f03288f70475b5f6c6bcb649da7faa9866fdc818223ed87dde5c1cc567d5dda4a52e4735a60c&scene=0&xtrack=1#rd",
      "publish_time": 1767890400,
      "publish_date": "2026-01-09 00:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/LightChen233/Awesome-Long-Chain-of-Thought-Reasoning\", \"https://x.com/iruletheworldmo/status/2007550905177256071\", \"https://x.com/aiwithjainam/status/2005629090943193552\", \"https://x.com/ChrisLaubAI/status/2006668516280197287\"]",
      "add_ts": 1767914254,
      "last_modify_ts": 1768087225
    },
    {
      "id": 309,
      "article_id": "51735",
      "title": "大模型最难的AI Infra，用Vibe Coding搞定",
      "description": "Andrej Karpathy 推荐的 Vibe Coding 通过自然对话提升简单任务开发效率，但在复杂系统如 AI Infra 中面临挑战。主要问题包括：上下文丢失导致关键设计决策在多轮对话中被压缩遗忘；系统级知识难以通过聊天完整表达；抽象层次不匹配使 AI 难以理解架构意图。这限制了其在复杂工程中的应用，需更完善的上下文管理和建模支持。",
      "content": "Andrej Karpathy 大神力荐的 Vibe Coding，正在成为开发者的新宠。这种「只需聊一聊，AI 可以把功能写出来」的体验，极大提升了简单任务的开放效率。\n然而，当我们目光转向实际的系统，特别是 AI Infra 这种复杂系统时，Vibe Coding 就会常常会陷入「水土不服」的困境。\n总结下来，主要有这三个方面的问题。\n首先是\n上下文丢失\n问题：对话历史被压缩，关键设计决策在多轮交互中逐渐遗忘，导致后续生成的代码与前期讨论脱节。其次是\n决策偏离\n困境：AI 在面对复杂系统时需要做出大量技术决策（如架构选择、接口设计、错误处理策略等），自主决策容易偏离开发者意图，生成的代码难以符合预期。最后是\n质量不稳定\n挑战：即使提供了完整的需求描述，生成代码的质量仍然波动很大，同样的需求在不同时间可能得到截然不同的实现方案。\n而这些问题背后的根源在于：AI Infra 到底还是个复杂系统，动辄数万行代码、成百上千个相互关联的决策点，而当前的对话式编程缺乏持久化、结构化的决策管理机制。\n换句话说，Vibe 本身是模糊且不稳定的，无法支撑严肃复杂的 Infra。\n不过 Vibe Coding 的发展不可逆，其广泛应用的潜力不应就此止步。要让 Vibe Coding 真正适用于 AI Infra 开发，我们实践了\n文本驱动的 Vibe Coding\n方法：通过设计文档将所有关键决策体系化、持久化。\n将复杂系统的关键决策前置到设计阶段，通过结构化文档让开发变得有章可循，大幅降低复杂度门槛。\n程序员只需要专注于高层设计决策，AI 负责代码实现细节，真正实现「几乎不写一行代码，就可以完成复杂功能」。\n整个过程通过详细的设计规范和代码逻辑来约束 AI 生成，确保实现复合预期，同时提升系统健壮性。\n而要验证这一新范式的有效性，我们需要一个兼具高复杂度、强工程约束和真实业务价值的典型场景。\nAI Infra 中的资源调度系统，尤其是面向 Agentic RL，正是这样一个理想试验场。该系统是数万行代码的分布式训练系统，面临 GPU 利用率优化的复杂挑战，涉及核心调度逻辑改动。\n新开发范式是如何在这一场景实操的？\n阿里巴巴未来生活实验室与智能引擎团队带你\n进一步来看。\n第一部分：Agentic RL 中的 GPU 利用率挑战\n在 Agentic RL 的采样过程中，系统需要支持越来越高的交互轮数，让智能体有足够的环境交互来处理复杂任务。然而，这一趋势带来了显著的资源调度挑战。\n在实际采样中，智能体执行任务的时间分布呈现典型的长尾特征：绝大多数样本能够在较少轮数内快速完成采样并得出结果，而只有少数复杂样本需要执行到最大轮数限制才能终止。这种极不均匀的执行分布成为 GPU 资源利用的核心瓶颈。\n问题的本质\n在于分布式计算中经典的 \"落后者效应\"（Straggler Effect）：无论有多少样本已经完成，系统都必须等待最慢的那个样本执行完毕，才能进入下一阶段。等待过程成为整个训练流程的性能瓶颈，更造成 GPU 资源浪费。\n1.2 方案对比与技术优势\n业界针对 Agentic RL 训练存在两种主流解决方案，但都存在根本性缺陷：\n共置方案\n采用严格的串行执行策略：所有 GPU 首先统一投入 rollout 阶段，等待全部样本采样完成后再切换至 training 模式。这种方案存在双重效率问题。首先是阶段内的资源闲置：在 rollout 阶段，由于落后者效应的存在，大量 GPU 在短样本完成后进入闲置等待状态，无法有效利用。其次是阶段间的严格串行限制：rollout 和 training 完全无法并行执行，training 阶段必须等待 rollout 完全结束才能开始，导致整体迭代时间被显著拉长。\n异步分离方案\n通过静态分配专用的 rollout GPU 和 training GPU 实现流水线并行。虽然理论上能够缩短单轮迭代时间，但引入了严重的 \"双边空泡\" 问题。在 rollout 侧，短样本快速完成后，rollout GPU 进入闲置状态等待长尾样本执行完毕；在 training 侧，训练任务完成后需要等待新一轮 rollout 数据，training GPU 同样处于闲置状态。使得理论上的并行优势在实际运行中大打折扣。\n我们提出的\n时分复用方案\n通过 GPU 池动态分配机制解决上述问题。其核心创新基于一个关键洞察：\n异步训练过程中，rollout 对 GPU 资源的需求呈现动态波动特征。\n在 training 触发前，大量样本已进入完成阶段，系统处于样本数目的低谷期，此时对 GPU 资源的需求自然下降。相反，在训练结束后，新一轮大量样本涌入系统，对 GPU 资源的需求急剧激增，形成明显的高峰期。基于这一波动规律，我们设计了智能资源调度机制，在采样需求低谷期分配部分 GPU 资源用于执行训练任务，从而实现需求波动与资源调度的有效匹配。\n系统采用\n两阶段执行流程\n来实现这一设计理念。在全力采样阶段，所有 GPU 协同处理大多数样本，快速推进系统至需求低谷状态。当采样完成度达到训练要求时，系统执行缩容操作，释放固定的 rollout GPU 资源转入训练模式。随后进入并行执行阶段，被释放的 GPU 专门执行训练任务（充分利用低谷期的闲置资源），而长尾样本被迁移至剩余 GPU 继续处理。训练任务完成后，系统立即执行扩容操作，回收所有 GPU 资源恢复全力采样状态，为应对下轮需求高峰做好准备。\n这种基于工作负载特征的智能时分复用策略，不是简单的资源分割，而是将训练的快速执行特性与 rollout 需求波动在时间维度巧妙匹配提升了整体的 GPU 资源利用效率。\n以 4GPU 系统为例，我们比较各个方案的任务执行时间线。\n时分复用方案的核心挑战在于\n系统复杂度的显著提升\n。为了追求高性能，需要精细复杂的控制机制，在分布式高并发的系统中实现尤其困难。相比串行执行和静态资源分配，动态调度引入了诸多技术难点：分布式环境下的精确同步控制，以及扩缩容操作的原子性保证，并发场景下样本状态的无缝迁移。\n各个方案的优缺点\n在一个包含数万行代码的分布式 RL 系统中，手工编码不仅周期长，更易引入隐蔽的状态不一致 bug。传统的开发方式已难以应对这种「高价值、高复杂度」的功能迭代需求。\n正是在这一背景下，我们创新性地采用了文档驱动的 Vibe Coding 方法论，通过系统化的设计文档驱动开发流程，显著提升了复杂系统的实现效率和代码质量。\n第二部分：文档驱动的 Vibe Coding 方法论\n前文提到的氛围编程三大痛点，上下文丢失、决策偏离、质量不稳定，其根源都指向同一个问题：\n缺乏持久化、结构化的决策管理机制\n。\n要理解设计文档如何解决这一问题，我们需要先认识到代码实现的本质：它是由成百上千个相互关联的决策点构成的。从顶层的架构选择、接口设计，到底层的变量命名、错误处理，每个决策都影响着最终的代码质量。在理想情况下，如果 AI 已经掌握了完整的代码改动（如代码迁移任务），它可以直接复制执行这些修改。但现实中，我们要解决的往往是全新的问题，比如本文的 \"训练 - 推理时分复用优化\" 功能此前从未实现过。\n既然没有现成的代码可以参考，那么退而求其次，如果我们能够\n系统化地枚举出所有决策点\n，AI 就可以按照这些明确的决策逐步生成代码。\n设计文档正是实现这一目标的关键工具\n：它通过结构化的方式，将高层的设计思路逐步细化为具体的代码改动，完整记录每一个决策点。\n经过程序员审阅的设计文档，意味着人与 AI 在关键决策上达成一致。这直接解决了氛围编程的三大痛点：\n持久化文档\n消除上下文丢失，\n明确决策\n避免 AI 偏离意图，\n规范和代码逻辑\n确保代码质量稳定。这带来工作方式的根本转变：程序员从编码、调试、测试等执行层面，转向与 AI 讨论设计，通过文档明确决策点直到完全对齐，然后 AI 负责实现。设计文档同时记录实施进度，确保可追溯性。更重要的是，设计文档本身由 AI 管理，大大降低了编写门槛。\n设计文档驱动的氛围编程和传统的 vibe coding 的工作流对比\n这三种开发方式的优缺点\n2.1 核心方法论：设计文档驱动开发\n在明确了设计文档的必要性后，我们需要建立一套系统化的方法论来指导实际操作。设计文档驱动开发不仅仅是编写文档，更是一种全新的开发范式：通过结构化的文档组织决策过程，通过迭代审阅确保决策质量，通过分步实施降低实现风险。\n这一方法论的核心在于将复杂的系统开发问题分解为三个可管理的环节：\n内容组织\n（如何构建决策体系）、\n审阅修改\n（如何确保决策质量）、\n分步实施\n（如何将决策转化为代码）。每个环节都有明确的操作流程和质量标准，确保整个开发过程的可控性和可预测性。\n2.1.1 流程概览\n设计文档的审阅是一个迭代优化的过程，需要人和 AI 协作来确保文档质量。我们建立了系统化的审阅流程，通过多轮迭代逐步完善设计文档，直到达到实施标准。\n总体审阅流程\n2.1.2 如何组织内容：开发者与 AI 共同完成\n代码实现的结果是由一系列自顶向下的决策决定的，顶层的关键决策包括新功能如何融入已有架构，底层的决策如是否需要增加成员变量。组织设计文档的核心目的是系统性的跟进这些决策点，并逐步完善解决。由于底层的决策，往往依赖于顶层或者上层的决策，设计文档需要层次化的拆解决策，形成决策体系。开发者需要按照章节的先后顺序和目录层次结构审阅文档中的自顶向下的决策过程，当我们指出前面顶层设计的错误时，AI 会自动修改后面章节的中层和下层决策以保持内部逻辑的一致性。因此，我们可以按章节层次和顺序和 AI 逐个对齐自顶向下的决策。同时，在开发者和 AI 共同修正这些决策的过程中文档不断演进，文档需要自包含这个迭代的过程，记录迭代的版本。最后，文档也需要记录代码实施的进度和一些衍生的待办。\n具体而言我们的设计文档模板包含如下内容：\n2.1.3 如何审阅修改：复用 iFlow CLI 的 prompt 模板\n上文描述的逐章节审阅对齐的过程理论上已经完备，但实践中会遇到一系列挑战。为应对这些挑战，我们建立了多层次的文档质量保证机制。\n由于这些场景在文档审阅中反复出现，我们利用 iFlow CLI 的 Sub Command 功能，将不同场景的指令逻辑固化成了自定义的 prompt 模板。\n审阅挑战与解决方案对照表\n2.2 设计文档的实施\n2.2.1 如何分步计划和实施\n当 Section 5 完成所有 API 和 Implementation 的设计后，我们需要将这些设计转化为可执行的代码。这个转化过程分为两个阶段：首先规划 Section 6 制定实施步骤，然后进入 AI 辅助的增量开发循环。\n规划实施步骤： 规划的核心目标是将 Section 5 中的方法拆解为依赖有序的小步骤。我们首先分析每个方法的 deps: 字段，识别底层 helper 方法和高层 orchestration 方法之间的依赖关系，绘制出完整的依赖图。在拆解步骤时，我们遵循 \"每步越小越好\" 的原则，通常一个 Step 包含 3-5 个相互关联的方法，避免单个 Step 包含超过 10 个方法。步骤的排序遵循依赖关系：Step 1 通常是基础设施（配置、常量、基础类），Step 2 到 Step N 按照从底层到高层的顺序排列，最后一个 Step 负责集成和端到端测试。每个 Step 都定义清晰的验证点和测试用例覆盖，确保可以独立验证和方便回退。\n规划完成后，我们得到一个清晰的依赖图，指导后续的增量开发：\n增量开发循环： Section 6 规划完成后，我们进入实施阶段。对于每个 Step，AI首先读取 Section 6 中的 purpose 和 dependencies，以及 Section 5 中相关方法的 Signature 和 Implementation，然后按照 docstring 和代码实现具体代码，同时展开 validation placeholders 为实际的验证逻辑。AI 完成编码后，会自动更新 Section 6 中该 Step 的状态，将方法从 NOT_STARTED 改为 DONE。\n接下来是人工代码审查环节。我们使用 IDE 的 Local History 功能查看当前 step 的代码改动，重点检查代码是否符合 Section 5 的设计、是否正确实现了 validation 和 assertion、是否存在明显 bug。如果发现问题，小范围修正或进入错误处理流程（见 2.2.3）。审查通过后，我们创建一个 git commit，commit message 遵循 \"Step N: [描述]\" 的格式，然后继续下一个 Step，重复这个循环直到所有 Steps 完成。\n2.2.2 防御性编程：让复杂系统更可靠\n在分布式 AI 训练环境中，微小的错误可能触发级联故障，而异步操作和资源调度的复杂性使得问题追溯本就困难。更糟糕的是，AI 编程倾向于主动做错误处理，这种 \"善意\" 的处理机制往往弄巧成拙，掩盖了真实的错误信息，使得问题定位变得更加复杂。我们真正需要的是防御性编程，让错误主动暴露而不是被掩盖。然而，传统的防御性编程因其开发繁琐性和进度压力常被开发人员选择性忽略，导致系统健壮性完全依赖个人自觉。为此，我们将防御性思维前置到设计阶段：在关键节点设置验证点，构建标准化的错误处理模式库，利用 AI 技术自动生成健壮的防御代码，从而在保证开发效率的同时实现快速问题定位，显著降低维护成本。\n统一的验证模式库： 我们维护了一个包含常用验证模式的库，每个模式都有唯一的 ID 和标准化的实现。这些模式遵循单一定义，多处复用原则。当需要在代码内增加某个验证逻辑时，只需在注释中加入模式库中的一处定义，AI 实施时会按 ID 查表展开，确保整个代码库中相同验证逻辑的一致性。\n设计阶段的验证标注： 在 Section 5 的设计文档中，我们不直接编写完整的验证代码，而是用标准化的注释标注验证需求。以 shrinksampler () 函数为例，通过 VALINTRANGE 标注 GPU 列表的合法性验证，通过 ASTPOSTCONDITION 标注返回结果的有效性检查。这种标注方式清晰表达了验证意图，同时保持了设计文档的简洁性。\ndef\nshrink_sampler\n(\nself\n,\ntarget_gpus\n: List [\nint\n]):\n# VAL: VAL_INT_RANGE (min=0, max=7)\n# 将在实施时展开为实际 validation 代码\noffload_ranks =\nself\n.\n_calculate_offload_ranks\n(target_gpus)\n# AST: AST_POSTCONDITION (len (offload_ranks) > 0)\n# 将在实施时展开为 assert 语句\nreturn\noffload_ranks\nAI 自动展开验证逻辑： 当 AI 根据设计文档生成代码时，会自动将标注中的模式 ID 展开为具体的验证逻辑。参数范围验证会展开为完整的条件检查语句，后置条件会生成带有详细错误信息的 assert 语句。这种自动展开机制避免了人工编码时的遗漏和不一致。\n# 设计文档中的标注：\n# AST: AST_POSTCONDITION (len (offload_ranks) > 0)\n# AI 实施时展开为带详细信息的断言：\nassert\nlen\n(offload_ranks) >\n0\n, \\\nf\"Post-condition: offload_ranks not empty, got\n{offload_ranks}\n\"\n复杂验证的独立处理： 当验证逻辑超过 10 行时，内联展开会让代码变得臃肿难读。对于这类复杂验证，我们在设计文档中定义专门的验证函数，详细描述验证项和错误处理策略。例如 validategpuallocation () 函数负责验证 GPU 分配逻辑的完整性，包括检查 targetgpus 非空、确保 GPU ID 在有效范围内等。在实施计划中，我们会安排专门的步骤来实现这些复杂验证函数，为后续的核心逻辑步骤提供坚实的基础。\n#### 5.2.8 _validate_gpu_allocation () - Full Specification\ndef\n_validate_gpu_allocation\n(\nself\n, target_gpus, current_allocation):\n\"\"\" 验证 GPU 分配的复杂逻辑。\n检查项：\n- target_gpus 非空且元素唯一\n- GPU ID 在有效范围内\nRaises:\nValueError: 违反任何检查条件\n\"\"\"\n# 10-20 行的详细 validation 逻辑\n第三部分：在生产级别的大规模集群上验证\n3.1 实验配置\n我们在生产级别的大规模集群上验证了时分复用方案的实际效果。实验环境采用 160 卡 GPU 集群，选择了具有代表性的 SWE Agentic 工作负载作为测试场景。模型使用 Qwen3-235B-A22B，这是一个具有 235B 参数规模、22B 激活参数的大规模语言模型，能够充分体现真实生产环境的计算压力。\n为了模拟真实的智能体长时交互场景，我们将最大交互轮数设置为 100 轮，最大 token 长度为 64K，batch size 为 512。我们设置异步训练的 async ratio 为 1，这样的配置确保了实验的真实性和挑战性。在对比方案设置上，我们将时分复用方案与传统的异步分离方案进行对比：baseline 采用 128 卡用于 training、32 卡用于 rollout 的静态分配策略，而时分复用方案则采用 128 卡 training、160 卡 rollout 的动态调度策略。\n3.2 性能对比分析\n实验结果显示时分复用的 rollout 吞吐率提升了 3.5 倍。时分复用方案的 rollout 阶段几乎始终比完全分离的 baseline 要快，甚至在某些情况下训练任务无需等待 rollout 即可开始，性能提升明显。\n更值得关注的是任务完成率的提升。在 baseline 的完全分离方案中，由于 rollout 资源受限（仅 32 卡），导致采样速度较慢，大量任务触发了环境默认的超时限制，采样轨迹的 timeout 比例居高不下。而时分复用方案通过动态释放更多 GPU 资源用于 rollout，显著加快了采样速度，完全避免了 timeout，提升了整体训练的稳定性和样本利用效率。\n3.3 系统开销分析\n在评估时分复用方案时，我们也仔细分析了引入的系统开销。参数同步开销方面，由于时分复用方案需要在更多的 GPU 之间进行参数同步（160 卡 vs 32 卡），相比分离方案会产生额外的通信开销，但这一开销在整体训练整体时间中占比极小。\n缩容操作的开销主要来自于 rollout 模型参数的 offload 过程。当系统需要将部分 GPU 从 rollout 模式切换到 training 模式时，需要从显存中将 rollout 参数释放，实测耗时在秒级。尽管这一操作引入了额外的同步点，但由于缩容操作开销极低，因此并未成为性能瓶颈。\n综合来看，时分复用方案通过智能的资源调度策略，在引入极小系统开销的前提下，显著提升了 GPU 利用率和训练效率，特别是在降低 timeout 率方面表现突出，充分证明了该方案在大规模 Agentic RL 训练中的实用价值。\n第四部分：团队介绍\n本文是 ROCK & ROLL 团队使用 iFlow CLI 在开源框架实践中的探索成果，后续相关功能将持续迭代并陆续发布。\nROCK & ROLL 由阿里巴巴未来生活实验室与智能引擎团队联合打造，致力于开拓强化学习（RL）的未来，探索面向未来的创新生活方式。ROLL 是灵活高效的 Agentic RL 训练框架，支持从十亿到千亿参数大模型的优化训练；ROCK 是易用、可扩展的沙箱环境管理器，可在分钟级拉起海量环境。我们坚持工程系统与算法协同创新，持续关注 RL 社区发展并分享开源实践，为 RL 在不同场景中的规模化落地提供坚实的基础设施支持。\niFlow CLI 是阿里巴巴未来生活实验室推出的一款终端 AI 智能体，支持通过自然语言进行交互。它能够高效分析代码仓库、完成各类编程任务，并准确理解特定的上下文需求；同时可将从基础文件操作到复杂工作流的流程自动化，显著提升开发者的工作效率。\n欢迎关注、Star、试用并贡献代码，一起推动 RL for LLM 走向更广阔的实用化未来。\nROCK： https://github.com/alibaba/ROCK\nROLL：http://github.com/alibaba/ROLL\niFlow CLI： https://cli.iflow.cn/\n关注\n「阿里妈妈技术」\n，\n了解更多\n~\n喜欢要“\n分享\n”，好看要“\n点赞\n”哦ღ~",
      "article_url": "https://mp.weixin.qq.com/s?__biz=Mzg5NTk4MDMwMA==&mid=2247496899&idx=2&sn=9fc332da8c7cc197da728590e1f52a54&chksm=c1412a9046a1fb8ae205574e57a6ac674710706875fab5b0bdc73ba2aae4a7fc9ae88cb0cd74&scene=0&xtrack=1#rd",
      "publish_time": 1767890400,
      "publish_date": "2026-01-09 00:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/alibaba/ROCK\", \"http://github.com/alibaba/ROLL\", \"https://cli.iflow.cn/\"]",
      "add_ts": 1767914260,
      "last_modify_ts": 1768087228
    },
    {
      "id": 314,
      "article_id": "51730",
      "title": "阿里团队重磅推出智能体模型：IFLOW-ROME",
      "description": "阿里巴巴发布智能体模型ROME-V0.1，依托未来生活实验室与智能引擎、数据技术团队研发，在多项主流Agent基准测试中表现领先。IFLow-CLI + ROME-V0.1在同规模开源模型中成绩突出，部分指标接近百亿参数以上模型，如Terminal-Bench 2.0成功率高达24.72%，展现强大智能任务执行能力，推动轻量高效AI智能体发展。",
      "content": "阿里巴巴未来生活实验室与智能引擎、数据技术团队正式发布智能体模型ROME-V0.1（\nR\nOME is\nO\nbviously an Agentic\nM\nod\nE\nl）。\n在多项主流 Agent 基准测试中，\nIFLow-CLI + ROME-V0.1\n在同规模开源模型中取得了领先结果，并在部分榜单上接近\n100B+ 参数规模模型\n——例如，在\nTerminal-Bench 2.0\n上达到\n24.72%\n的成功率，在\nSWE-bench Verified\n上取得\n57.40%\n的任务完成率。\nROME-V0.1 是面向真实执行场景训练的智能体模型，其并非针对某些单一评测的优化，而是建立在大规模真实环境交互、端到端执行闭环训练以及面向长链任务的强化学习范式之上。得益于完善的训练系统基建--ALE（Agentic Learning Ecosystem），ROME-V0.1 在 超过百万数量级别的可验证交互轨迹上完成训练。\n需要强调的是，ROME-V0.1 并不是一次“拼性能”的大规模模型尝试，而是一项围绕 Agent 模型应该如何被训练出来的系统性探索。\n下文将详细介绍，这一套 Agent 训练体系是如何一步步构建，并最终支撑起 ROME 的诞生。\n从一个能干活的 Agent  CLI框架开始\n2025年 8 月，\niFlow CLI\n正式发布。这是一个面向真实工程场景的 Agent 产品， 基于开源模型，我们不断改进框架，使其更贴合开发中的实际需求,  迅速获得一批真实用户， 同时也在用户的反馈中发现:\n无论模型本身的推理能力多强、或在测评中分数多高，一旦进入真实复杂的工程环境，也会频繁翻车。\n显然，这不是“模型还不够大”的问题，而是更多地暴露出一个现实问题：现有训练体系对智能体模型在真实任务环境中的执行与反馈的建模仍然不足。\n真正难的，从来不是“回答问题”\n对一个合格的Agent 来说，真正的难点是如何具备在真实的环境中自主收集信息、执行交互，最终完成任务的能力，而不只是“纸上谈兵”。而要解决这个难点，就要构建真实的训练场，让模型在真实环境中交互和学习，一步一步地去试错并修正，最终实现能力上的进化。可惜的是，这部分内容往往很少被人关注或提及，且相关工作在开源社区里几乎是一片空白。\n为了打破这个困局，阿里巴巴未来生活实验室（Future Living Lab）与智能引擎、数据技术团队将丰富的内部实践经验沉淀为开源基础设施，隆重推出了智能体学习生态系统ALE (Agentic Learning Ecosystem)。该系统旨在解决 Agent 训练里最现实的几个问题:\n1. 训练数据通常为脱离环境的静态文本，缺少规模化的高质量实战数据。\n“纸上得来终觉浅”，如果只是一味在静态的交互轨迹上进行学习，模型的泛化能力难以得到保障。只有让模型与环境动态进行交互，在不断的试错中学习，才能使之真正掌握遇到真实问题时实时分析和解决的能力。\n为此，团队用自主研发的沙盒管理器\nROCK\n（\nR\neinforcement\nO\npen\nC\nonstruction\nK\nit）构建了万级别并发的沙盒训练场，以 GitHub 真实项目为基础，通过实时交互为模型训练提供超过 100 万条具备环境反馈的交互轨迹。ROCK 的存在确保了模型在训练阶段接触到的每一个操作，都有真实环境的运行结果作为反馈，从而支撑其解决现实问题的能力。\n2. 复杂工程任务链路极长，长尾rollout导致训练效率低下。\n强化学习的Rollout效率优化是一个老生常谈的问题，而在Agent相关的复杂任务中，由于不同任务的难度、复杂度差异较大，环境交互与样本生成的长尾现象也更加严重。为了等待某些任务轨迹完成采集，往往会拖慢整个链路的节奏，极度影响训练效率。\n为此，团队用自主研发的大模型强化学习训练框架\nROLL\n(\nR\neinforcement Learning\nO\nptimization for\nL\narge-Scale\nL\nearning)实现了极致的分布式并行化与异步加速，大大提升了训练效率。ROLL 的异步训练pipeline极大地缩短了轨迹采样和策略优化的耗时，支持模型在海量任务中同步进行试错迭代，让模型能在单位时间内完成更高频次的闭环训练，从而在海量训练任务中练就稳健的执行能力。\n3. 缺乏标准化的上下文衔接与\n工具调用协议\n，难以实现端到端的闭环优化。\n想要让模型能够顺利地在训练中与环境完成高效交互，往往需要标准化的上下文衔接与\n工具调用协议\n来保障模型推理状态与环境执行反馈之间的顺畅链接。一旦这个环节出现问题，就会导致长链条任务中的交互逻辑极易断裂且难以实现端到端的闭环优化。\n为此，团队通过自主研发的智能体框架\niFlow CLI\n实现了标准化的上下文管理与灵活开放的配置设定，消除了训练与实战的隔阂。这样以来，Agent 模型能够在复杂任务的工作流中时刻保持与环境实时顺畅的交互，从而保障了整个系统链路的稳定性与持久训练迭代的可能性。\nROME，基于 ALE 体系的首个Agent 模型\nROME 并非针对某些评测基准特定优化的模型，而是基于 ALE 基础设施，自然而然的诞生。在千万数量级别的模拟环境里不断训练、收集反馈、持续优化。它的能力，是从一次次真实交互中进化而来。\n在技术报告中，团队系统性地披露了 ROME 背后的关键技术细节和创新，核心目标只有一个：\n让模型真正具备在真实环境中完成任务的 Agent 能力。\n以下是部分关键技术：\n从静态文本到可执行环境：以环境为中心的数据构建范式\n传统 LLM 的训练数据主要来源于静态文本语料，这类数据缺乏可执行的环境约束与明确的反馈信号，使模型难以感知自身行为在真实系统中的后果。\n同时主流的LLM数据合成范式更多是doc-centric(围绕文档或是代码片段)或是query-centric(围绕问题)来组织扩充语料，缺乏对真实执行环境、工具链差异以及运行状态的建模能力。模型容易学到“看起来合理”的文本模式，而“在真实条件下不能跑通”的行为策略\n因此ROME主要采用\nenvironment-centric\n的数据构建范式。团队首先大规模构建和扩充可复现的执行环境与可运行的任务实例（instances），再在这些实例之上系统性生成多轮交互轨迹， 每个instance包括：任务描述、Docker环境、初始化脚本、测试文件与golden solution等。\n在这一路径下，所有生成的轨迹都是经过运行与测试验证。同时不同环境与工具之间的差异也都会体现在不同的轨迹之中，使模型从一开始就被约束在“可执行、可验证”的学习目标上。\n依托 ROCK 提供的高并发沙盒调度与隔离能力，该数据构建机制以流水线化方式持续运行。最终形成了超过百万级、具备完整环境反馈的高质量交互轨迹，为后续的 Agent 训练提供了稳定而可验证的基础。\n三阶段训练训练：一套面向 Agent 的课程学习体系\n在训练链路上，ROME 并未简单沿用“预训练—微调—强化学习”的通用范式，而是围绕\nAgent 能力的逐级形成过程\n，设计了一套课程化的三阶段训练体系。\n该体系以能力解耦为前提， 逐步引导模型从学习基础agentic行为到能够具备解决高难任务的智能体\n1. 阶段一：CPT（持续预训练）—— 构建基础 Agentic 能力\n在 CPT 阶段，训练目标并非直接优化任务成功率，而是为模型系统性注入基础 Agent 能力，包括：\n代码理解与修改代码理解与修改\n任务分解与阶段性规划任务分解与阶段性规划\n工具使用与多步推理工具使用与多步推理\n对环境状态变化的感知能力对环境状态变化的感知能力\n同时数据筛选并不以结果正确性为唯一标准，而是主要关注行为模式的覆盖率， 通过该阶段引入多样化的交互轨迹为后续的策略优化提供充分的可激发空间。\n2.\n阶段二：SFT（监督微调）—— 面向交互稳定性的对齐训练\nSFT阶段的核心目标还将后续强化学习锚定在可靠、可执行的策略区域内，避免较高频率出现低质量或不可执行行为\n为此，ROME 采用了\n两阶段 SFT 训练策略\n：\n第一阶段：基于启发式规则进行数据过滤的轻量 SFT，确保模型具备正确的行为模式\n第二阶段：引入自适应样本筛选机制，对具有高学习价值的交互轨迹进行重点增强\n在此过程中，团队也对传统 SFT 目标函数进行了重新设计。在长链交互中，工具调用错误或执行失败极为常见，若对所有 token 一视同仁地反向传播梯度，反而会无意中强化错误行为。\n为此，ROME 引入了\n错误掩码训练机制\n：\n基于工具执行反馈，将不可执行或失败行为对应的梯度置零\n同时，在多子 Agent 场景中，系统会识别特定任务的\n决策边界\n，仅保留与当前子任务直接相关的上下文回合。\n通过基于模式的启发式识别，对冗余、高度相似或已被剪枝的历史回合屏蔽损失梯度，使学习信号集中于真正具有因果影响的交互过程，从而显著提升样本效率。\n3. 阶段三：IPA 强化学习—— 从对齐到策略进化\n在完成基础对齐后，ROME 进入基于\nIPA（Interaction-Perceptive Agentic Policy Optimization）\n的强化学习阶段。该阶段的核心目标，是在真实环境约束下进一步提升模型在长链任务中的决策质量与执行稳定性。\nIPA-交互感知的智能体策略优化\n针对在长时程的agent任务中，传统的奖励机制往往面临信用分配困难、奖励信号稀疏的问题，团队提出了 IPA (Interaction-Perceptive Agentic Policy Optimization) 算法。该研究的核心在于将优化目标从传统的“Token 粒度”提升到“语义交互块 (Interaction Chunk)”级别，极大提升了强化学习在复杂交互场景下的训练稳定性。\n🌟\nChunked Markov Decision Process（交互块级别的马尔可夫决策过程）\n为了能更好地引出后续在交互块级别的算法优化，首先在交互块层面重新建模了马尔可夫决策过程（Markov Decision Process，MDP）。然后在Token级别MDP的基础上，将一个完整的token序列划分为一个一个的交互块，每个交互块覆盖了连续两次环境交互之间的过程，构成一个完整的决策单元。以工具调用为例，一个交互块包含了“分析推理->工具调用->触发执行”的完整过程。这种建模方式可以把轨迹中共同影响某一次环境交互的token很好地聚合成一个整体，使得每个优化目标（交互块）都可以与同一次环境交互对应，有利于实现更准确的信度分配。\n1. Chunk-Level Discounted Return（交互块级别的折扣回报）\n在传统的强化学习算法中，折扣奖励扮演着相当重要的角色。如果没有时间折扣奖励，就将无法衡量行为和奖励之间在时间距离上的因素，进而导致长尾轨迹中早期行为的价值估计存在较高的方差，最终影响训练的稳定性。而在大模型的强化学习训练中，传统基于token的优化方法天然的难以引入有意义的折扣奖励。这是因为一次完整的轨迹中往往包含了成千上万个token。折扣因子（<1）会在这些token上以指数级速度衰减并无限接近0。这会导致轨迹中相当多的token被过度降低奖励权重，使之难以获得有效的梯度更新，进而导致训练相当低效。\n随着将优化目标从token层级聚合到交互块层级，奖励折扣的时间步可以与实际的每一次环境交互完美对齐，折扣因子的衰减次数被大大降低，从而避免了早期交互被过度降权。自然地，团队在交互块级别重新引入了折扣回报，来缓解长交互轨迹信度分配中的偏差-方差平衡问题。通过合理地对奖励施加交互块级别的时间步衰减惩罚，可以很好地避免早期尝试时的无效操作（例如无效的工具调用）被过度奖励，促使模型更高效地学习高影响力的交互步骤，进而提高样本的利用效率和训练的稳定性。\n2.\nChunk-Level Importance Sampling（交互块级别的重要性采样）\n更进一步地，团队提出了交互块级别的重要性采样。类似GSPO在序列级别的重要性采样计算方式，在每个交互块内部计算所有token上的训练分布的概率和采样分布的概率的比值，用这些概率比值的几何平均值来衡量交互块级别的采样概率差异，这样可以减弱异常token的影响并避免极端比值的出现。进一步结合交互块级别的奖励分配，我们可以用交互块级别的重要性采样来调整优化目标从而弥补采样分布和训练分布之间的偏差导致的训练不稳定。\n3.\nChunk-Level Initialized Resampling（交互块级别的初始化重采样）\n强化学习的有效性和稳定性除了算法本身的优化外，还取决于采样数据的质量和奖励信号的丰富性。在一些较为复杂的多轮交互任务中，如果模型无法在每一个关键点稳定地做出正确决策，任务成功率将以指数的速度快速降低，最终导致这些任务上的正信号极其稀疏。一方面，正向信号的缺失使得训练缺乏引导，降低了收敛速度和探索效率，使得模型难以逃离次优区域；另一方面，过多的负向奖励将会持续降低轨迹上的token概率并分配到其他token上，提高了崩溃的风险。\n为了解决这一问题，IPA使用了交互块级别的初始化重采样方法（Chunk-Level Initialized Resampling）。该方法利用成功的参考轨迹（来自模型本身或外部专家模型生成）中的交互块作为锚点，通过使用这些交互块“预填充”轨迹的前半部分并执行交互，使环境被初始化到这些成功轨迹的中间状态。接着，模型就可以从中间状态“重采样”后续的交互块并继续与环境交互，补完整条轨迹并获取最终的奖励。这种重采样方式可以让模型“站在巨人的肩膀上”：利用成功轨迹锚定部分交互，降低整体任务难度的同时，让模型先学习如何完成后面的步骤，再修改初始化点，最终逐步学会解决整个任务。\n为了更好地决定在参考轨迹上具体的初始化位置，IPA首先提出了一种序列回退（Sequential Rollback）的方式。该方式选择从参考轨迹的最后一个交互块的位置开始进行初始化，并记录该位置重采样轨迹的成功率，然后“回退”初始化点到上一个交互块执行前的状态。当模型的重采样成功率在某次回退后骤降，我们就定义这次回退越过的的参考交互块为一个“关键交互”--即可以显著提升重采样成功率但模型尚未熟练掌握的交互决策。此时模型停止回退，从该交互块执行前的状态开始多次重采样后续交互轨迹并学习，直到熟练掌握后再继续“Rollback”。此外，考虑到数据本身的特性和一些极端案例，IPA在序列回退的基础上又提出了并行初始化（Parallelized Initialization）方法，使模型可以同时从参考轨迹的多个初始化点开始重采样，并且引入了对参考交互块的模仿学习，大大加速了训练的效率。\nAgent-Native Training：以真实 Agent 执行链路作为训练对象\n在许多 Agent 训练链路中，训练时使用的上下文组织方式，与实际的agent框架存在显著差异，导致模型能力在生产环境中出现退化。在许多 Agent 训练链路中，训练时使用的上下文组织方式，与实际的agent框架存在显著差异，导致模型能力在生产环境中出现退化。\nROME通过Agent-Native Training从根本上解决了Agent训练与真实使用场景之间的差异问题\n训练阶段直接复用iflow CLI完整的执行逻辑\n在训练过程中，ROLL不使用人为重写的 prompt 拼接或简化的 Agent scaffold，而是直接调用 iFlow CLI 运行真实 Agent。\n这意味着模型输入包含了iFlow CLI动态生成的上下文：包括长上下文压缩，可调用工具的更新，各种系统提示与中间状态管理，使RL训练阶段看到的输入分布与线上使用时保持一致。\n通过ModelProxy Service实现“无侵入式”Agent 训练\n为避免在训练框架中重复实现 Agent 逻辑，ROCK 在沙盒内引入了ModelProxy Service。Agent 在沙盒内仍然按照原有方式调用模型接口，而这些请求会被 ModelProxyService 异步转发至 ROLL 拉起的推理服务，而后再将推理结果再回传给 Agent。\nROLL 无需感知 Agent 的 prompt 结构或上下文管理细节，即可对真实 Agent 行为进行训练。\n训练、蒸馏与评测复用同一执行链路\n由于训练阶段直接运行真实 Agent，数据合成、强化学习、蒸馏与评测均可复用同一套执行与环境交互逻辑。\n这一设计显著降低了 Agentic RL 的工程复杂度，同时确保不同阶段之间不存在行为偏移，也为后续消融实验与 Agent 框架切换（如 iFlow CLI、SweAgent、OpenHands）提供了统一接口。\nAgent-Native 设计保证了模型在 训练、评测与真实部署 三个阶段中的行为高度一致, 总结来说“ROME不是在一个模拟agent中训练，而是在真实环境直接训练agent本身”。\n这套端到端的完整解决方案，覆盖从环境构建、并行采样、策略优化到生产部署的全链路。\n在这一体系下，ROME-V0.1 并不是一次“追求极限性能”的规模尝试，而是以环境与执行为中心的 Agent 训练范式的一次完整落地验证。因此，选择首先发布\n30B MoE\n这一规模：在保证足够能力的同时，更强调可训练性、可部署性与可复现性，使完整的 Agent 训练闭环能够以极高的效率和性价比稳定运行。\n同时希望降低 Agentic LLM 的使用与迭代门槛，让更多让个人开发者和团队在本地或私有环境中构建属于自己的 Agent CLI。欢迎大家在 iFlow CLI 论坛中分享硬核 Case 和创新Agent 设计，共同推动 Agent 能力在真实环境中的演进。\n团队将沿着 ALE 已经跑通的训练链路，系统性地扩展环境规模与任务复杂度，并同步推进模型迭代。\nROME，只是开始。\n想了解 ROME 背后更多的细节？点击下方【阅读原文】，获取论文全文。\n关注\n「阿里妈妈技术」\n，\n了解更多\n~\n喜欢要“\n分享\n”，好看要“\n点赞\n”哦ღ~",
      "article_url": "https://mp.weixin.qq.com/s?__biz=Mzg5NTk4MDMwMA==&mid=2247496899&idx=3&sn=b280980070a09db1a688a58f8d925ac3&chksm=c13be3a74cb4d847a1f5c10788962b95f32dcf52d0ce748348ceb19a05366565c32e7237b20f&scene=0&xtrack=1#rd",
      "publish_time": 1767870600,
      "publish_date": "2026-01-08 19:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767914297,
      "last_modify_ts": 1768000919
    },
    {
      "id": 315,
      "article_id": "51729",
      "title": "李飞飞又被超越了？百万「普通视频」打造通用4D世界模型！",
      "description": "中科院与CreateAI推出NeoVerse，利用百万单目视频构建4D世界模型，突破性地实现AI对开放世界的动态理解。相较李飞飞团队局限于静态场景的3D模型Marble，NeoVerse在时间维度上延伸，具备更强的空间与动态感知能力，推动空间智能迈向新高度，为数字内容生成和真实世界建模提供关键技术支撑。",
      "content": "新智元报道\n编辑：桃子 好困\n【新智元导读】\n当全行业还在为昂贵的多视角数据焦头烂额时，\n中科院和CreateAI重磅推出\nNeoVerse，直接用百万单目视频砸开了4D世界模型的大门，让AI真正学会了理解开放世界。\n李飞飞团队提出的 Marble 极大地推动了空间智能的边界，但因其应用场景仍局限于静态环境，本质上归属于 3D 世界模型的范畴。相比之下，4D 世界模型作为空间智能的演进形态，在数字内容创作、游戏开发、自动驾驶仿真及具身智能等领域展现出巨大的应用潜力。然而，当前的 4D 世界模型训练方案正面临严峻的\n扩展性（Scalability）瓶颈\n。\n模型的训练通常需要成对的视频，即输入给模型的\n原视角视频\n，和作为监督的时间同步的\n新视角目标视频\n。这种特殊的数据需求使得训练难以扩展到海量的数据上。现有的研究往往受困于以下两点：\n多视角数据难扩展\n：\n现有的多视角数据通常是在静态场景多次采样，或者用多相机直接采集或者在仿真引擎渲染。前者无法扩展到动态场景，后者采集成本高，限制了训练数据的泛化性，难以触及真实的开放场景。\n预处理效\n率低\n：\n为了摆脱多视角依赖，一些研究尝试通过离线方式对单目视频构建训练数据对。但是这会引入额外的计算和存储负担，更让训练变得异常僵化，无法灵活扩展到互联网级的海量数据上。\n这些限制构成了重重壁垒，将互联网上最廉价、最丰富的资源——\n开放场景单目视频数据\n阻隔在外。\n为此，来自中科院自动化研究所和 CreateAI 的研究者提出了\nNeoVerse\n。NeoVerse 彻底抛弃了昂贵的多视角数据和沉重的离线预处理，直接拥抱互联网上的海量单目视频，首次利用100万段开放场景单目视频进行大规模训练。\n项目主页：https://neoverse-4d.github.io/\n论文链接：https://arxiv.org/abs/2601.00393\n前馈式4DGS：免位姿的高效重建底座\nNeoVerse 是一种重建-生成混合式的架构，其首先重建出 4D 表示，然后将其用于生成模型的作为新视角的几何引导。要实现训练管线的 scaling up，第一步必须解决「重建速度」问题。NeoVerse 提出了一种\n免姿态输入（Pose-free）的前馈式 4DGS 模型\n。\n与传统针对专一场景迭代优化的重建方法不同，NeoVerse 基于视觉几何基础变换器（VGGT）进行动态化和高斯化改进。这种前馈式重建无需复杂离线预处理，一次预测即可在几秒内完成动态场景 4D 建模。\n双向运动建模\nNeoVerse 引入双向运动编码分支，通过交叉注意力机制分别提取前向 （\n）和后向（\n）的运动特征，这种有利于精准预测高斯基元的双向线速度和角速度，实现相邻时间戳的中间时刻高斯插值渲染。\n具体来说，对于帧特征\n，NeoVerse 沿时间维度将其复制并切分成两部分：\n和\n。其中前者作为查询特征，后者作为键和值来获取前向运动特征，反之则得到后向运动特征。\n其中\n和\n分别是\n的前向运动特征和\n的后向运动特征，这些特征将用于预测高斯基元双向运动的线速度和角速度。\n4D高斯化\nNeoVerse 定义的 4D 高斯基元如下\n包括传统 3D 高斯属性：3D 位置\n、不透明度\n、朝向\n、大小\n和球谐系数\n。双向建模预测的前后向线速度\n和角速度\n。以及 4DGS 常用的生命周期\n。\n其中 3D 位置\n是通过预测深度和相机参数将像素深度反向投影到 3D 空间获得的，动态属性\n由双向运动特征预测，其他属性则由帧特征预测。\n秒级在线构建数据对：规模化训练4D世界模型\n稀疏帧重建 × 密集帧渲染\n为了进一步加快重建速度从而提升训练效率，NeoVerse 提出「稀疏帧重建，密集帧渲染」策略，在少量稀疏关键帧输入的条件下通过高斯场插值渲染出连续密集的视频画面。对于一个非关键帧时间戳\n，NeoVerse 将其最近的关键帧时间戳\n下的高斯基元\n转移到\n：\n其中为了处理非均匀的关键帧间隔，NeoVerse 归一化时间距离\n来对不透明度的衰减进行建模，\n是\n的左右两个关键帧时间戳。生命周期\n约束在\n范围内，当\n接近于1时，\n趋于1，表明\n，否则不透明度会快速衰减。\n单目退化模拟\n在单目视频训练中，最大的挑战是缺乏「新视角」的监督信号。NeoVerse 并没有尝试寻找完美的数据，而是反其道而行之，引入了\n单目退化模拟\n机制，在训练的每一次迭代中，NeoVerse 并不是简单地从输入视角渲染，而是刻意「模拟」了单目重建在不同视角下的退化规律，从而建立起一套自监督训练范式：\n高斯剔除（Gaussian Culling）\n：\n模拟相机移动时可能出现的遮挡与视场丢失（图(a)）。通过剔除部分 4D 高斯基元，模型被迫在「信息不全」的情况下学习维持物体的几何完整性。\n平均几何滤波（Average Geometry Filter）\n：\n除了遮挡之外，另一种典型的退化模式是深度不连续的飞行边缘像素。NeoVerse 通过在采样的新视角上渲染深度图并作平均滤波，再根据滤波后的深度值调整每个高斯基元的位置。当调整位置后的高斯重新渲染回原视角，则能模拟出现飞边现象（图(b)）。当增大平均滤波核半径时，则能模拟出更大范围的空间畸变（图(c)）。\n退化渲染引导\nNeoVerse 通过控制分支将模拟的渲染结果（包含渲染图像、深度、不透明度图以及相机位姿的 Plüker 嵌入）注入视频生成模型。在训练过程中，NeoVerse 仅训练控制分支，同时冻结视频生成主干模型，这不仅可以提升训练效率，更重要的是，使其能够支持步数蒸馏 LoRAs，以加速生成过程。\n实验结果与分析\nNeoVerse 通过 VBench 测评了共计400个测试样例，无论是从重建和生成的运行速度，还是从生成质量上均显著优于现有方法。\n即使在具有挑战性场景上进行大幅度视角运动控制。 NeoVerse 依然能在保持精确相机可控性的同时实现更好的生成质量。\n较大的相机运动下的渲染图像容易产生包括飞边像素和扭曲等现象。上图展示了 NeoVerse 单目退化模拟的必要性。如果没有在模拟出的退化样本上进行训练，生成模型往往会过于信任重建渲染中的几何伪影，导致出现「鬼影」效果或模糊输出。通过结合退化模拟，生成模型能够学会抑制这些伪影，并在遮挡或扭曲区域生成逼真的细节。\n下游应用\n在大规模视频训练的支持下，NeoVerse 不仅能实现高精度的 4D 重建与精准漫游，更能跨越影视制作、具身智能与自动驾驶等多个领域，支持多视角生成、视频编辑等丰富下游应用。\n子弹时间\n从图像到世界：重建 + 生成的迭代闭环\n多样化相机控制\n视频编辑\n具身场景应用\n驾驶场景应用\n驾驶场景前视相机到多视角相机扩展\n总结\nNeoVerse 的出现，标志着 4D 空间智能从「实验室精雕细琢」向「大规模数据驱动」的范式转移。它通过攻克核心的\n扩展性（Scalability）瓶颈\n，构建了一套能够无缝适配互联网单目视频的训练管线。这种对海量开放场景数据的深度挖掘，不仅让 NeoVerse 在泛化能力上实现了质的飞跃，更使其成为了支撑自动驾驶、具身智能及内容创作等多元领域的通用 4D 世界模型底座。\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652661234&idx=1&sn=c59d4711562b3da786564e52b039926d&chksm=f09c4b298c7ba8a16bca5ce1bae80152e6ac966ac23d9b6ee6e8b1922fded1d7b501e0e63e52&scene=0&xtrack=1#rd",
      "publish_time": 1767870600,
      "publish_date": "2026-01-08 19:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://neoverse-4d.github.io/\", \"https://arxiv.org/abs/2601.00393\"]",
      "add_ts": 1767914303,
      "last_modify_ts": 1768000925
    },
    {
      "id": 317,
      "article_id": "51727",
      "title": "Adv. Sci. | ALLSites: 基于序列的蛋白质全模态药物结合位点预测框架",
      "description": "蛋白质在细胞中通过与多种分子模态相互作用发挥关键功能，但目前对结合位点的识别仍不完整，导致人类蛋白质组的成药性未被充分挖掘。现有小分子药物仅能靶向不足15%的蛋白质，限制了治疗范围。为此，研究者正探索基于蛋白质、多肽、核酸和糖类等新型药物模态，以拓展可靶向蛋白谱。全面鉴定各类药物模态的蛋白质结合位点，有助于揭示潜在药物靶点，推动新药开发，提升疾病治疗潜力。",
      "content": "研究背景\n蛋白质通过与多种分子模态相互作用在细胞过程中发挥着关键作用。然而，由于结合位点鉴定的不完整，全蛋白质组的成药性在很大程度上仍未被充分探索。尽管小分子药物是最常见的药物形式，但它们只能调节不到15%的人类蛋白质组。研究人员开始探索其他新型药物模态，包括基于蛋白质、多肽、核酸和糖分子的治疗策略，以调控蛋白质功能。因此，全面鉴定各类药物模态的蛋白质结合位点具有重要意义，能够将某一种药物模态下的“难成药靶标”重新定义为另一种模态下的“可成药靶标”，从而显著拓展全蛋白组的可药靶性。然而，药物模态的多样性与复杂性给实验方法鉴定蛋白质结合位点带来了巨大挑战。为此，有大量研究致力于开发能够预测各种药物模态结合位点的计算方法。\n目前的计算方法面临着三大挑战：（1）大多数方法仅针对单一药物模态设计，缺乏通用性；（2）基于结构的方法严重依赖高质量的三维结构数据，而实验解析的蛋白质结构覆盖率不足；（3）基于序列的方法虽然适用性更广，但忽略了残基间相互作用信息，预测准确性往往不尽如人意。因此，开发一种能够准确识别全蛋白质组范围内所有药物模态结合位点的通用方法，对于扩展可成药蛋白质组、加速药物发现进程具有重要意义。\n研究亮点\n浙江大学团队在Advanced Science上发表了题为“Accurate Identification of Protein Binding Sites for All Drug Modalities Using ALLSites”的研究论文。该研究构建了一种统一的、基于蛋白质序列的深度学习框架ALLSites，实现了对蛋白质、多肽、小分子、糖分子、DNA和RNA等主要药物模态结合位点的准确预测。\nALLSites的核心创新在于：它是一种支持所有主要药物模态结合位点预测的统一框架，仅需蛋白质序列信息即可工作，无需依赖难以获取的高质量三维结构。更重要的是，ALLSites在所有基于序列的方法中达到了先进的性能水平，甚至可以与最佳的基于结构的方法相媲美。在实际应用中，ALLSites展现出极高的效率，可以在16小时内完成整个人类蛋白质组的扫描，为全蛋白质组可成药位点发现提供了强大工具。\n技术方法\nALLSites采用基于Transformer的深度学习架构，将蛋白质语言模型与门控卷积网络、交叉注意力机制相结合。整个框架包含三个关键模块协同工作。\n图1：ALLSites模型框架。\n模块一：蛋白质特征编码器模块。\n选用了预训练的ESM-2语言模型来生成残基级别的表示。这个拥有30亿参数的大模型能够捕获丰富的进化信息和复杂的序列模式。编码器进一步集成了门控卷积网络，通过多层卷积操作提取每个残基的局部上下文特征，并将这些局部特征整合形成全局序列表示。\n模块二：交叉注意力解码器模块。\n这是ALLSites能够从序列直接建模残基相互作用的关键。解码器采用改进的Transformer架构，通过多头交叉注意力机制，让每个残基都能关注到蛋白质中其他残基的信息。这种设计使得模型能够在没有三维结构的情况下，仅从序列就能学习到残基之间的空间相互作用模式，从而弥合了序列方法和结构方法之间的性能差距。\n模块三：由多层全连接网络组成的分类模块。\n该模块将解码器输出的特征映射为每个残基作为不同药物模态结合位点的概率。研究团队针对每种药物模态分别训练了专门的模型，确保了预测的准确性和特异性。\n性能比较\n蛋白质和多肽结合位点预测表现优异\n在蛋白质-蛋白质相互作用位点预测任务中，ALLSites展现出了显著优势。在PPI-Test70数据集上，ALLSites的AUROC达到0.755，比第二名的EnsemPPIS提升了5.0%；AUPRC达到0.438，提升幅度达到8.1%；关键的MCC指标也提升了0.042。在另一个更大规模的PPI-Test355数据集上，改进幅度更加明显，AUROC提升6.9%，AUPRC提升高达24.6%，MCC提升0.096。\n研究团队还进行了蛋白质水平的精细化分析。在PPI-Test315数据集的315个蛋白质中，ALLSites在73.7%的蛋白质上取得了比EnsemPPIS更高的MCC分数。以一个具体案例（PDB ID: 6G4JB）为例，ALLSites预测的MCC达到0.834，而EnsemPPIS仅为0.425，预测的结合位点也更接近实验结果，降低了预测结果的假阳性和假阴性。\n图2：ALLSites对于蛋白质和多肽结合位点上的预测性能。\n小分子和糖分子结合位点预测准确\n对于最常见的小分子药物，ALLSites与知名的基于结构的方法P2Rank进行了对比。结果显示，ALLSites在所有评估指标上都优于P2Rank。F1分数达到0.601，提升了0.151；MCC为0.560，提升了0.136；召回率为0.593，提升了0.232。在蛋白质水平的分析中，ALLSites在66.4%的案例中表现更优。值得关注的是，ALLSites在不使用任何结构信息的情况下，就超越了专门利用结构特征的P2Rank，这证明了ALLSites从序列中提取关键特征和建模残基相互作用的强大能力。\n糖分子是一类特殊的小分子，具有独特的化学性质，其结合位点与典型小分子存在本质差异。ALLSites在糖分子结合位点预测中展现出了对这种特殊性的良好适应能力。与三种结构方法FTMap、CAPSIF:V和CAPSIF:G相比，ALLSites在所有评估指标上都取得了最佳表现。相比通用小分子工具FTMap，平均DICE和MCC指标分别提升了0.258和0.381，这进一步证实了糖分子结合位点确实不同于常规小分子结合位点，需要专门的预测工具。\n图3：ALLSites对于小分子和糖分子结合位点的预测性能。\n核酸结合位点预测准确可靠\n在DNA结合位点预测任务中，ALLSites在两个独立测试集DPI-Test129和DPI-Test181上的性能超越了所有基于序列的方法。与当前最佳的结构方法GraphBind相比，ALLSites的AUROC表现相当，MCC略低但差距很小。考虑到ALLSites完全不依赖结构信息，这样的表现已经相当出色。\nRNA结合位点的预测结果也展现出类似的模式。在RPI-Test117数据集上，ALLSites的AUROC和MCC均排名第二，AUROC值与最佳结构方法GraphBind几乎持平。这些结果充分说明，ALLSites能够仅从序列信息就准确识别核酸结合位点。\n图4：ALLSites对于DNA和RNA结合位点的预测性能。\n结构预测的局限性凸显ALLSites优势\n研究团队还评估了当使用AlphaFold2预测的结构代替实验解析结构时，基于结构的方法GraphBind的性能变化。结果显示，在DPI-Test129数据集上，使用预测结构后，GraphBind的AUROC和AUPRC都降到了ALLSites之下；在DPI-Test181上，所有三个关键指标都低于ALLSites。\n这个发现揭示了一个重要事实：尽管AlphaFold2等结构预测工具取得了巨大进步，但预测结构与真实结构之间仍存在偏差，而结构方法对这些偏差高度敏感。相比之下，ALLSites直接从序列学习，不受结构误差影响，在处理缺乏实验结构的蛋白质时具有明显优势。考虑到只有不到35%的人类蛋白质有实验解析的晶体结构，ALLSites的这一特性使其能够实现全蛋白质组范围的应用。\n研究意义与展望\nALLSites的开发为蛋白质-配体相互作用预测领域带来了重要突破。这是能够跨所有主要药物模态进行准确预测的统一框架，克服了以往方法局限于单一模态的束缚。\n从方法学角度，ALLSites实现了仅从序列信息就能有效建模残基间的相互作用。通过编码器-解码器架构和交叉注意力机制，ALLSites成功弥合了序列方法和结构方法之间的性能差距，在不使用结构信息的情况下达到了与结构方法相媲美的预测准确度。\n在实际应用层面，ALLSites展现出了强大的全蛋白质组应用潜力。它能在16小时内完成整个人类蛋白质组的扫描，平均每个蛋白质仅需约3秒。这种高效率使得全蛋白质组范围的系统性可成药位点识别成为可能。更重要的是，ALLSites可以帮助研究人员重新评估那些在某一药物模态下被认为“不可成药”的蛋白质，通过预测其他模态的结合位点，将它们转变为“可成药”靶点，从而大幅扩展可用的药物靶点空间。\n这项工作不仅为药物发现提供了强大的计算工具，也为理解蛋白质功能多样性和成药性机制提供了新的视角，有望加速难成药靶标的药物发现。\n参考资料\nMinjie Mou, Mingkun Lu, Zhimeng Zhou, et al. Accurate Identification of Protein Binding Sites for All Drug Modalities Using ALLSites. Advanced Science (2025).\nhttps://doi.org/10.1002/advs.202516530",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512585&idx=1&sn=774b0896e8dc38d11154b864c9cb8c63&chksm=fd695db9d3d00a154f44c9726b19fe5a791c272aad3795850485b8acbe51a756e947b5978fbd&scene=0&xtrack=1#rd",
      "publish_time": 1767861000,
      "publish_date": "2026-01-08 16:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1002/advs.202516530\"]",
      "add_ts": 1767914316,
      "last_modify_ts": 1768000935
    },
    {
      "id": 319,
      "article_id": "51725",
      "title": "1人顶1个Infra团队！OpenAI前CTO新招，让大模型训练跌成白菜价",
      "description": "大模型竞争转向后训练，传统显卡租赁模式难以为继。Serverless按Token计费彻底颠覆算力暴利时代，降低门槛，赋能算法工程师。OpenAI前CTO Mira Murati创立的Thinking Machines Lab推出Tinker，推动大模型从“作坊炼丹”迈向“工业微调”，实现高效、标准化的模型迭代，开启AI开发新范式。",
      "content": "新智元报道\n编辑：好困\n【新智元导读】\n当大模型竞争转向后训练，继续为闲置显卡烧钱无异于「慢性自杀」。如今，按Token计费的Serverless模式，彻底终结了算力租赁的暴利时代，让算法工程师真正拥有了定义物理世界的权利。\n大模型训练，正从「作坊炼丹」进化为「工业微调」！\n当OpenAI前CTO Mira Murati创立的Thinking Machines Lab推出Tinker时，一切都变了。\n通过将训练拆解为forward、backward等⼀系列基本原语，算法设计终于不再受限于基础设施。\n现在，训练大模型就像「函数调用」一样简单。\n紧跟前沿，潞晨云微调\nSDK\n正式发布！\n这是国内首个兼容Tinker范式、且全面开放的Serverless微调平台。\n针对复杂且昂贵的强化学习，给出了更具成本优势的工业级解法：\n零门槛\n：开发者无需囤积显卡。\n全透明\n：Rollout → Reward → Update，全流程按Token计价。\n极高效\n：\n拒绝算力浪费，让每一分钱都花在产生梯度的「刀刃」上。\n拥抱后训练与RL\n算法层与底层算力架构的解耦\n随着OpenAI o1在推理能力上的突破，业界逐渐形成共识：\n大模型的能力突破已不再单纯依赖预训练（Pre-training）阶段的参数堆砌，\n后训练（Post-Training）特别是强化学习正成为决定模型实用价值的核心战场。\n以DeepSeek‑R1为例，仅靠强化学习训练，模型在AIME数学推理基准上的pass@1从15.6%提升至77.9%，充分展示了RL在低数据量条件下即可实现大幅能力跃升，迅速成为后训练赛道的新范式。\n然而，摆在算法工程师面前的问题依旧严峻。\n强化学习涉及到更为复杂的系统设计，训练过程中存在一系列的问题，如多个模型的优化，数据的传递，以及模型权重的传递；一系列工程化的工作，给算法的设计带来了更多的困难，同时也对基础设施提出了更高的要求。\nTinker的出现，就是为了解决这个问题：\n把繁杂训练变成标准易用的\nAPI\n。\n潞晨云把这一范式写进底层假设，\n算法\n设计与基础设施解耦\n——\n开发者只负责定义数据与Loss函数，底层的异构集群调度、并行策略优化、容错运维等应被封装为基础设施服务，对开发者实现\n全托管与无感支持。\n致敬创新，更致力于\n落地\n。\n潞晨云微调SDK，直接兼容Tinker接口。\n它在「零代码」与「裸机手写」之间，找到了最佳平衡点。从此，从算法灵感到模型落地，再无工程壁垒。\n如今，开发者可以把研究精力和算力成本从集群运维还原至算法本身，感受「本地写码，云端计算」的\n「训练即服务（Training as a Service）」\n流畅体验\n。\n颠覆性人效比\n1名算法工程师顶替庞大Infra团队\n潞晨云微调\nSDK\n的核心思路可以概括为：\n算法\n工程师定义算法逻辑，潞晨云搞定Infra。\n在传统的开发中，用户往往要花大量精力去租赁合适的算力集群、管理环境配置、调训练框架和集群运维。\n但潞晨云将大模型训练拆解成了一组标准的函数原语，打通了\n从SFT到RL的全链路\n：\nForward & Backward：\n处理前向传播与梯度计算\nOptimizer Step：\n执行权重更新策略\nSample (Rollout)：\n做推理生成和评估，使用户不仅可以完成SFT，更能轻松构建PPO、GRPO、DPO等复杂的强化学习（RLHF/RLAIF）训练流\nSave State：\n管理模型检查点与状态保存\n这意味着，用户可以在本地熟悉的Jupyter Notebook或IDE里，用最标准的Python语法像搭积木一样自由组合，掌控训练逻辑的细节。\n这种模式带来了颠覆性的「人力效能比」提升——\n它将原本需要运维工程师、Infra工程师、平台工程师和算法工程师紧密配合的庞大团队，简化为了「一个算法工程师」的独立闭环。\n用户不再被底层繁杂的基建拖累，不再背负多职能的枷锁，也不再是黑盒填参的被动执行者，而是能够独立驾驭大规模训练流的主动设计师。\n无论是监督微调（SFT）还是更复杂的强化学习（RL）Pipeline，都能通过组合这些原子函数来灵活构建。\n为什么这种体验如此丝滑？\n为了实现极致的流畅度，潞晨云基于现有的GPU云服务架构实现了一套完整的后端系统。\n在具体实现中，潞晨云采⽤控制⾯与计算⾯分离设计，通过统⼀API Server管理跨地域的多个GPU计算集群，实现多云部署能⼒。\n核⼼采⽤基于Future模式的异步API，所有训练操作⽀持⾮阻塞调⽤，⽤⼾⽆需等待GPU计算完成即可继续执⾏后续逻辑。\n潞晨云微调SDK还具备智能队列系统。\n即使在资源洪峰期，任务也会自动进入持久化队列（Persistence Queue），一旦底层资源可用，毫秒级启动：\n队列等待期间0计费\n仅对实际prefill + sample + train的Token量收费\n彻底告别资源闲置浪费，让用户的每一分钱都用在产生梯度的刀刃上。\n模型微调算力零售革命\n从包机租赁到按Token计费\n如果说「易用性」是后训练平台的入场券，那么「成本结构」则是决定谁能走得更远的护城河。\n在传统云主机的「包机/时租」模式中，用户一直在为「过程」买单——无论是在加载数据、调试代码，还是仅仅在思考Loss函数，只要占用了显卡，计费表就在跳动。\n这种模式下，\n开发过程中有一半以上的预算都浪费在了这些没有实际产出的「垃圾时间」里\n。\n潞晨云为微调大模型场景引入了Serverless架构，推行「按Token计费」的商业模式，将微调场景的算力服务切分到了最细的颗粒度：\n为价值付费\n就像使用推理API一样，用户只需为Prefill（输入）、Sample（推理输出）和Train（训练）产生的\n有效计算Tokens量\n付费。\n其他环节全免费\n本地代码调试、环境配置、数据预处理、模型Checkpoint保存……这些在传统租卡模式下分秒必争的环节，在潞晨云\n全部免费\n。\n极致性价比\n通常，RL需要同时维护高吞吐的推理集群（vLLM）和训练集群，算力成本极高。\n但在潞晨云上，实测基于官方Cookbook的\nmath_rl\nrecipe跑通包含Rollout采样、Reward评分和PPO更新的\n完整RL流程\n（~300 steps），总算力成本\n仅8.61元\n。\n这意味着，个体开发者也能低成本复现RLHF/RLAIF探索。\n技术落地的三个场景\nSFT与RL同时开箱即用\n这种新模式，也将彻底改变不同领域开发者的工作流：\n科研场景：告别资源焦虑\n学术界，时间与算力往往是最紧缺的资源。研究人员不仅要面对繁琐的集群运维（Slurm/Docker 配置），还要应对昂贵的实验复现成本。\n潞晨云微调SDK支持「白盒级」的科研探索，全面兼容Tinker API。\n研究人员可以自定义Evaluation逻辑、通过Forward/Backward，Sample等原语精确控制后训练和强化学习Pipeline，而无需关心底层的分布式实现，让实验复现成本大幅降低。\n创业与独立开发：极速验证\nMVP\n对于初创团队，「快」是生存根本。利用潞晨云微调SDK的Serverless特性，开发者无需等待资源排期。\n配合极低的Token成本，实测从\npip install\n到跑通一个包含1000条样本的SFT或RL微调实验，仅需数分钟。\n这种极致的边际成本，让创业者敢于在有限预算下快速迭代Reward模型，实现真正的「低成本试错」。\n工业级\n落地\n：复杂架构突围\n在金融、医疗等垂直领域的工业应用中，已有微调API往往难以应对复杂的异构架构与RLHF/RLAIF需求。\n潞晨云微调SDK允许工程师通过\ntrain_step\n自由定义Loss逻辑与强化学习奖励函数。\n开发者拥有对模型权重与训练细节的完整控制权\n，\n实现端到端定制。\n极简实战\n三步上手\n没有复杂的集群配置，没有冗长的Docker构建。\n使用潞晨云微调SDK，训练一个大模型就像写普通Python脚本一样简单：\n1. Install & Import:\npip\ninstall hpcai\n2. Initialize Client：\n目前已支持Qwen3系列（4B - 32B），更多模型即将上线。\nimport hpcai\n# 初始化 LoRA 训练客户端，无需配置复杂的分布式参数\ntraining_client = service_client.create_lora_training_client(\nbase_model=\n\"Qwen/Qwen3-4B\"\n,\nrank=32\n)\n3. Define Training Loop & Run：\n像在本地写PyTorch一样，拥有对训练循环的完整控制权。\n# 训练循环：完全可控\nfor\nstep\nin\nrange\n(\ntarget_steps\n):\n# 前向与反向传播\nfwd_bwd = training_client.forward_backward(batch,\n\"cross_entropy\"\n)\n# 优化器步进\noptim = training_client.optim_step(adam_params)\n# 实时获取 Loss 进行监控\nloss = fwd_bwd.result().metrics.\nget\n(\n\"loss:mean\"\n)\n⽬前，微调SDK已覆盖Qwen3系列模型（4B、8B、14B、32B），支持监督学习和强化学习训练方式，并将持续扩展更多模型能力与细分落地场景，大家也可以向官方提交需求push更新。\n平台还准备了开箱即用的HPC-AI Cookbook\n，提供包括\nDeepSeek-R1 GRPO\n算法\n、\n基于Verifier的数学推理\n、\n自定义Reward函数\n等复杂RL场景的完整代码实现。\n开发者无需从零构建复杂的PPO/GRPO流水线，只需复制Cookbook中的「配方」，\n运行轻量级本地\ntrain.py\n脚本，即可驱动云端复杂的分布式RL训练流，\n在潞晨云上复现具备复杂逻辑推理能力的SOTA模型。\n现在体验\n后训练正从学术支线升级为工程主线，AI基础设施的终极形态应该是「零认知负荷」——\n开发者只需描述数据与算法，其余（租卡、配环境、并行策略、运维调度、故障自愈，乃至RL涉及的一系列工程化的工作）全部下沉到用户无感。\n当GPU闲置成本趋近于0，环境配置时间趋近于0，长序列RLHF也能按Token即时计费，应用创新效率直接逼近算力上限。\n潞晨云微调SDK今日起全量开放：\n无需白名单，无需预约\n前150名专属链接注册即得30元使用额度\n（可点击\n【阅读原文】\n跳转）\n：\nhttps://cloud.luchentech.com/account/signup?invitation_code=\nXZ\nY\n把资源弹性交给平台，把算法自由度留给自己，每一分钱都用在产生梯度的刀刃上！\n立即体验：\nhttps://cloud.luchentech.com/fine-tuning\n使用文档：\nhttps://cloud.luchentech.com/doc/docs/finetune-sdk/\nTinker SDK：\nhttps://github.com/thinking-machines-lab/tinker\nDeepSeek-R1：\nhttps://arxiv.org/pdf/2501.12948\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652662432&idx=1&sn=435b9156c8f42fcbd7006e9ca54e76c7&chksm=f03e6a2983820f6cd40a2536d8b75023835dbf6ba6fb7a837326623c96da57d93a1c7a0607c4&scene=0&xtrack=1#rd",
      "publish_time": 1767861000,
      "publish_date": "2026-01-08 16:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://cloud.luchentech.com/account/signup?invitation_code=\", \"https://cloud.luchentech.com/fine-tuning\", \"https://cloud.luchentech.com/doc/docs/finetune-sdk/\", \"https://github.com/thinking-machines-lab/tinker\", \"https://arxiv.org/pdf/2501.12948\"]",
      "add_ts": 1767914333,
      "last_modify_ts": 1768000945
    },
    {
      "id": 323,
      "article_id": "51721",
      "title": "让欧美老外彻底“真香”，这家中国割草机器人品牌正在定义一个行业新标准",
      "description": "在CES展会上，中国厂商未岚大陆凭借割草机器人Navimow X4展现了中国在具身智能机器人领域的领先实力。继扫地机器人之后，中国企业在割草机器人赛道再次实现突破，技术成熟度与市场推进速度均走在前列。未岚大陆已将产品落地于超40万欧美家庭，标志着中国智造在家庭服务机器人垂直场景中的全球化拓展取得显著成果。",
      "content": "梦瑶 发自 凹非寺\n量子位 | 公众号 QbitAI\n要是没来CES，都不知道具身智能机器人的又一个垂直场景，也被中国玩家占领了高地。\n前几年，这个位置属于扫地机器人，而现在相似的剧本正在\n割草机器人\n身上重演——从技术成熟度到市场推进速度，中国厂商依旧走在前面。\n在这条赛道上，一家名叫\n未岚大陆\n的中国厂商已经率先跑出了结果，把割草机器人送进了「四十万」欧美家庭的真实使用环境中。\n△\nNavimow X4 CES 2026 现场互动体验\n就在今年的\nCES 2026\n现场，未岚大陆把最新产品、能力演进以及背后的核心技术，一次性完整摊开。\n重磅发布了面向大面积全地形庭院、主打极致性能的\nX4旗舰系列\n；搭载三重融合定位技术、专为复杂庭院设计的\nH2系列\n；针对中小面积、全驱不伤草的\ni2 AWD\n和兼顾精准导航与轻松上手的\ni2 LiDAR\n；以及面向商业场景的\nTerranox系列\n五大新品阵容。\n△\nNavimow CES 2026 新品阵容\n通过其行业领先的\n「Xero-Turn™ 零转全驱、越障不伤草」\n解决方案，与全系列支持的\n「免部署、自动建图」\n功能，共同呈现\n“Navimow标准”\n体系下的具体实践。\n台前看到的是一整套行业标准，台后其实全是\n技术硬活儿\n。\n那么问题来了，未岚大陆到底是用了哪些带派的招数，才能让这些风吹日晒的小小割草机器人不再频频卡bug的？\n定位部署这一步，终于不用人“下场”了\n大家应该都有过这种经历：每次我们要去一个陌生地方的时候，都会先打开导航App，确认自己目前的定位，接着设定目的地，然后跟着导航的方位指示出行。\nu1s1，这套逻辑放到机器人身上其实也适用，割草机器人导航核心解决的就三个问题：\n我在哪儿、我要去哪儿、我怎么去\n。\n其中“我在哪儿”说的就是\n「定位」\n问题，小小机器人得知道现在具体的位置才能开始工作，而在真实的庭院环境中，定位要想稳定成立，首先得把活动范围划清楚——明确哪些地方能去、哪些地方不能去，避免机器人跑偏或越界，也就是要做定位部署工作。\n最初，割草机器人的定位部署主要采用的是传统\n「物理埋线」\n方法。\n在草坪边缘埋一圈电缆，机器人通过无线电信号判断边界，来判断自己能不能往前走，但是这样的部署过程真的很苦命！不仅整个埋线过程要耗费几个小时，精度也不高，草坪边界一变就要把线挖出重来…\n于是这几年整个割草机器人行业也一直反复琢磨：怎么把定位部署这事儿，做得又简单又精准呢？\n方法总比困难多，聪明的厂商们很快换了新思路，在第二阶段开始引用\n「RTK」定位技术\n。\n不用人工埋线，只需要安装天线和基站，再拿着手机遥控机器，绕庭院溜达一圈，就能建立地图和作业边界，定位部署流程大大缩短，目前市面上主流割草机器人大多都是这么处理的～\n从有线到无线的部署，确实是一次不小的跨越，但在未岚大陆看来，这一步还远没到终点。\n团队成员又开始动起了小脑袋瓜儿：定位这件事，能不能再少一点部署，甚至…干脆做到“\n开箱即用\n”呢？\n在这次发布的新品中，未岚大陆给出的答案是：让全系产品实现\n「免部署、自动建图」\n。\n简单点说就是，彻底丢掉了之前定位部署过程中所需的埋线、插杆、遥控建图等麻烦步骤，真正做到开箱即用。\n借助\nGeoSketch™\n可视化编辑功能，用户可以直接在APP中将庭院实景投射为全彩实景的可交互地图。\n感觉整个过程更像是在玩《我的世界》，画面能拖能拽，地图清晰可见，还能直观地进行互动编辑～\n此外，用户还能针对不同区域定制专属的\n割草计划\n，将专业级庭院规划变得更easy，大幅增强了可操作性与控制感。\n对用户来说，这种体验上最直观的变化不光是省时间，更关键的是\n心智负担\n被拿掉了。\n不用再研究部署步骤，也不用反复对着说明书折腾，上手就能直接用起来，后面想改区域调细节，打开App点几下就行，省力更省心。\n当定位部署从一套需要经验和耐心的工程流程，变成普通用户也能轻松完成的日常操作时，割草机器人这类产品，也就进一步具备了大规模走进家庭和长期使用的条件了。\n再复杂的庭院环境，导航定位也能稳稳接住\n不知道大家跟我一不一样，对割草机器人的印象主要来自于美剧， 就像《绝望的主妇》中Gaby连夜除草的经典场景，总感觉它看起来已经像是一件成熟得不能再成熟的产品。\n但现实可没那么理想，因为老外家里的庭院状况真的太——复——杂——了：\n面积大不说，坡多、拐弯多、遮挡物还多，再加上天气变化带来的各种干扰，割草机器人的定位和导航就很容易出问题，一个不小心就晕头转向找不着北了…\n为了解决这个行业老大难问题，在这次CES展出的系列新品里，未岚大陆给产品补上了一项关键能力——\n「EFLS™ LiDAR\n⁺\n三重融合定位系统」\n。\n在固态激光雷达基础上，叠加视觉感知与Network RTK，并结合AI算法进行实时数据协同处理，实现了在极端复杂环境下的厘米级精准建图与稳定导航。\n不卖关子，具体咋实现的，咱往下看！\n懂定位的Network RTK\n刚才我们聊到了割草机器人的免部署、自动建图的功能，但是要实现这项能力可没那么简单，背后得有强大的技术能力支撑。\n其中，就包括未岚大陆在这次系列新品中引入的\n「Network RTK」\n定位技术，我们可以把它理解成一种接入网络的RTK。\n未岚大陆总裁兼CTO\n陈子冲\n提到，\n在传统RTK定位中，基站的位置直接影响了定位效果，一旦被房子、树木挡住，机器人能“看到”的卫星定位信号数量就会明显减少，定位精度自然跟着下滑。\n而Network RTK的技术逻辑很有意思，它不再需要用户在院子里自建基站，而是通过\n4G/网络\n，直接接入运营商侧已经长期部署、持续校准的RTK基准数据，把原本依赖现场条件的那部分能力，交给网络侧来执行！\n这样一来好处很直接，首先就是定位部署这一步被明显压轻，用户不再需要在庭院里架天线、建基站，而是通过网络接入定位基准，进而实现真正意义上的\n免部署\n。\n此外，由于基准数据来自视野更开阔、稳定性更高的网络侧，机器人的信号就不再那么容易被庭院不确定的环境变化牵着走，整体定位\n准确度\n和一致性也随之提升。\n从RTK到Network RTK，未岚大陆的想法其实很明确：在尽量帮用户省力的同时，把原本受外部环境制约很大的定位问题补齐，让机器人在不同环境条件下都能把定位稳住。\n放到割草机器人身上，这一步带来的意义也很明显。\n割草机器人的定位能力逐渐从一个需要反复调试、容易出问题的环节，转变为能够在复杂庭院环境中持续发挥作用的基础能力，也为整个割草机器人行业，在定位这件事上铺出了一条更稳定、更可复用的长期路径。\n能感知环境的固态激光雷达\n当我们真正把割草机器人丢进现复杂实庭院环境后，我们还会发现一个很容易被忽略的问题：单单知道「我在哪儿」，还远远不够。\n小机器人们还得具备一定的\n环境感知能力\n，清楚地知道周围环境的情况，比如哪儿能走，哪儿不能走。\n而这项能力很大一部分正是由\n激光雷达\n来承担的：它负责把真实、立体、充满细节的庭院，变成机器人真正“\n看得懂\n”的空间结构。\n给大家小小科普一下，激光雷达不算是个新技术，目前已经经历了几轮技术迭代，但…多少都有点小问题。\n最早的机械式激光雷达，靠转动结构扫描环境，体积大速度慢，用久了还容易磨损，主要应用在自动驾驶测试车场景。\n后来出现的混合固态、半固态激光雷达，虽然在体积和扫描速度上有所改善，但仍然保留了运动部件，长期使用场景下可靠性问题并没有被彻底解决。\n考虑到目前激光雷达的技术bug，在本次发布的新品中，未岚大陆采用了最新一代\n「固态激光雷达」\n技术，彻底解决了机械雷达在高振动、强户外、追求轻薄美观的消费级产品上的可靠性、耐用性与集成度难题。\n未岚大陆CEO\n任冠佼\n表示，\n在\n耐用性\n上\n，\n由于固态激光雷达没有转动部件，也就少了震动和磨损带来的偏差，小体积也更容易藏进机身里，长期在颠簸、冲击不断的庭院环境中，感知能力更容易保持稳定。\n其次在\n分辨率\n上，固态激光雷达传感器每秒可扫描约\n20万\n个点，其成像精度是行业内普通机械雷达的4倍之多，能够提供更多环境细节，配合\n70米\n的长测距和50ms的扫描间隔，机器人在复杂庭院里也能看得更远、反应更快～\n△\nNavimow i2 LiDAR 固态激光雷达\n对应到\n避障层面\n，变化同样明显，配合「视觉能力」，固态激光雷达能轻松识别出\n1厘米\n左右的障碍物，整体可识别的障碍类型超过\n200种\n。\n秋千、蹦床、滑梯这些固定设施不用多说，就连在院子里活动的小动物、走动中的人，也能被提前感知，并在接近前完成减速、绕行和安全距离判断，而不是等到快撞上了才急刹～\n环境感知足够可靠之后，割草机器人才能真正融入日常生活，用户不需要为了它改变庭院生活习惯，安全、避障这些事，开始由机器人自己承担。\n也正因为这种稳定、精确的环境感知能力，固态激光雷达才会被视为未来高级自动驾驶的重要方向——而在割草机器人这个场景里，它已经提前在未岚大陆的产品线中发挥出了技术的价值。\n会融合3D信息的AI视觉能力\n如果说LiDAR更像是在摸环境，负责量距离算高低，那在割草机器人身上，\nVision\n就是负责「看」的那一部分。\nVision干的事很直观：它可以告诉机器人，这是一整片草坪、那是围栏、那边是花坛，哪些地方能走，哪些地方最好避开。\n但问题在于，目前行业应用的Vision方案大多仍然采用单目视觉，也就是一颗摄像头，虽然能大概齐知道眼前物体是什么，但一到该算距离、抠细节的时候，就容易判断失准。\n这次未岚大陆给出的思路很直接，通过\n融合固态激光雷达的3D数据信息\n，让割草机器人在视觉上具备更精细的\nAI识别\n能力。\n逻辑也很简单，摄像头先把庭院环境拍下来，提供完整的画面，固态激光雷达同步给出对应的3D信息，包括高度和距离等等，由于\nAI模型\n已经在大量数据上训练过，就能轻松把画面中的像素特征和具体语义对应起来进行判断。\n机器人不但知道前方物体是什么，还能够结合空间信息判断它是高是矮、是扁是立，是边界杂草还是需要避开的障碍物。\n这样一来视觉上就能实现\n厘米级的精准度\n，眼前东西要不要割、哪里能走哪里要避开，对小机器人们来说都不在话下了～\n可优势互补的三重融合定位系统\n目前，行业在定位和导航上的主流方案，大多采用RTK+Vision的组合方式：一个负责定位，一个负责看环境，条件允许还会再叠加雷达技术做感知兜底。\n但叠起来也不是就高枕无忧，RTK能定位但吃亏在对信号要求高，Vision看得懂环境但怕光线和环境变化，雷达能感知环境和物体，但在啥都没有的空旷地，也会有点犯懵。\n简单说就是，组合能提升覆盖面，但盲区依然存在，因为每家每户的庭院结构都不一样，每种技术自身的bug都容易钻空子。\n好在，如今有了新解法～\n未岚大陆这次推出的\n「EFLS™ LiDAR\n⁺\n三重融合定位系统」\n，直接把最新一代固态激光雷达、Network RTK和Vision拉到一块儿干活，谁在当前环境说话好使就听谁的，这样一来割草定位问题对小机器人来说就是手拿把掐～\n△\nNavimow H2 狭窄地区导航示意图\n我们举个复杂庭院场景的的例子大家就明白了。\n我们来想象这样一个庭院场景：一侧是自家的草坪，另一侧可能紧挨着邻居的房子，中间有道路、篱笆、灌木，后面再接一块更大的草坪，看起来很规整，但细节其实非常多。\n在这种环境里，房子、树木、灌木都会形成遮挡，单靠Network RTK网络定位，容易信号出现不稳的情况，这时候\n固态激光雷达和视觉感知\n就成了关键补充。\n此外，当灌木附近有泥巴时，由于泥巴长得大差不差，机器人的视觉感知可能会出问题，这时候\n固态激光雷达\n就可以通过空间结构，把灌木的轮廓、高低关系感知清楚，帮助机器人稳住做出导航判断。\n再比如，当机器人进入一块儿大草坪空间时，周围几乎没有明显参照物，视觉和雷达反而缺少足够特征点，这时\nNetwork RTK网络定位\n反而会更加稳定，精准告诉机器人「我在哪儿」，保证整体位置不跑偏～\n也正因为如此，「EFLS™ LiDAR\n⁺\n三重融合定位系统」真正带来的价值，并不是让某一项能力变得极致，而是让定位和导航这件事不再被单一场景牵着走。庭院越复杂，越需要\n三种技术一起配合\n。\n用户不需要为了适配机器人去刻意调整院子，也不用担心环境一变化导航就失效，在此基础上，割草机器人的定位导航能力，才真正具备了在不同庭院环境下都能成立的稳定性。\n原地转向+控制算法，伤草问题有救了\n不知道大家留没留意过有一个蛮有意思的现象：\n在各大割草机器人厂商的宣传演示视频里，小机器人们看起来都割得很好，可一到真实庭院，原地一转，草坪上的\n磨痕\n基本谁都躲不过…\n目前市面上主流的割草机器人沿用的普遍是「硬转向」思路。\n四个轮子本身并不能转向，原地掉头完全依赖正反转来实现，转向过程中不可避免地产生侧向摩擦，实际使用中草坪上经常会留下明显磨痕，本质上既伤草，也会加速轮胎磨损。\n针对这个问题，未岚大陆这次提出了行业领先的\n「Xero-Turn™ 零转全驱、越障不伤草」\n的解决方案，专门解救被割草机器人无情伤害的草坪！\n在底盘上，未岚大陆这次引入了\n「零转模组」\n，在原有动力轮之外，引入可调角度的零转轮，让轮子真正具备主动转向能力。\n具体来说，在转弯时，提供驱动力的\n动力轮\n持续输出，由零转模组控制的\n转向轮\n不再简单地同步摆向同一角度，而是根据内外侧差异，形成不同转角，模拟真实车辆的转向轨迹。\n需要像汽车一样拐弯时，前面的轮子可直接实现转向；需要原地掉头时，轮子就也能被调整到特定角度，直接在原地完成转向，全程不蹭地、不伤草。\n△\nNavimow X4 复杂地形穿越\n在这种分工下，轮子的运动方向始终与自身滚动方向保持一致，转向过程中几乎不再产生横向拖拽。草地承受的受力，也从原本的侧向撕扯，转为\n更可控\n的纵向滚压，磨痕自然明显减少。\n为了防止复杂地形下的意外伤草，未岚大陆在软件层面还引入了稳定控制逻辑，通过\n电子稳定控制算法\n（ESC）\n，让机器人在坡地横向行走时实时感知姿态并进行修正，避免机器下滑。\n同时结合\n牵引力控制逻辑\n（TCS）\n，持续计算四个轮子的相对运动关系，防止在湿滑草皮上打滑空转，避免对草坪造成刨坑式损伤。\n通过\n硬件与软件的深度协同\n，该技术实现了高效作业与生态友好之间的统一， 重新定义了高端智能割草机器人的性能标准，目前此技术在X4系列和i2 AWD上已经实现了完美应用～\n大家发没发现，割草机器人虽然看起来是一个高度垂直、边界清晰的应用，但它所依赖的技术路径，并不封闭。\n未岚大陆围绕\nNavimow标准\n所建立的技术体系，真正产生影响的也不只是某一款特定产品的体验，还会在具身智能机器人整体技术体系中，沉淀出一套可复用、可扩展的工程范式。\n当定位、导航、执行等关键能力被统一纳入同一套框架中，行业中长期存在的不确定性，开始被系统性地收拢。\n这意味着，割草机器人能否稳定运行、是否覆盖更多真实场景、效果能否长期保持，不再主要依赖经验和运气，而是逐步进入可验证、可评估、可持续优化的状态。\n而对用户而言，这种变化来得更直接：许多原本需要自己兜底的事情，开始被一个方案标准接走。\n免部署、自动建图，让设备从开箱那一刻就进入可用状态；精准靠谱的三重融合定位系统，让用户不必为了机器人的导航问题而抓耳挠腮；零转全驱与越障不伤草的设计，则解决了机器人频繁伤草的老bug。\n你会发现，割草这件看起来简单、却总是小毛病不断的事，正在悄悄发生变化，从需要时刻盯着、反复介入，慢慢变成了一件可以放心交给机器去完成的日常。\n当技术标准不再停留在方法论和方案层面，而是真正进入长期运行，并持续作用于真实使用场景时，行业看到的第一个完整落地案例，已经出现——来自未岚大陆。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860431&idx=1&sn=ad84950d6d85a91a5125b0c2efae52ea&chksm=e9de304fdb3404ea0e7de1ddb77782021d8ee59372c1409567b9ea2b7c42362e9826ce0e03ce&scene=0&xtrack=1#rd",
      "publish_time": 1767860400,
      "publish_date": "2026-01-08 16:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767914358,
      "last_modify_ts": 1768000971
    },
    {
      "id": 325,
      "article_id": "51719",
      "title": "8块钱跑通一次强化学习全流程，潞晨云重塑微调赛道：1名算法工程师=1支Infra团队",
      "description": "大模型进入下半场，竞争焦点从预训练转向后训练，强化学习与精细微调成为突破关键。OpenAI o1与DeepSeek-R1的进展表明，模型性能不再仅依赖算力堆砌，而更看重迭代优化能力。然而，高昂的硬件成本、复杂的分布式架构与技术门槛，限制了多数工程师的实践空间，后训练落地仍面临巨大挑战。",
      "content": "允中 发自 凹非寺\n量子位 | 公众号 QbitAI\n大模型下半场的战火，已经从“暴力预训练”烧向了“后训练”战场。\n无论是OpenAI o1的推理突破，还是DeepSeek-R1靠强化学习\n（RL）\n实现的性能飞跃，都释放了一个明确信号：\n决定模型天花板的，不再只是算力堆砌，而是更精准的微调和RL迭代。\n但现实很骨感——复杂的分布式基建、高昂的显卡租金、繁琐的架构调优，像一道道高墙，把无数算法工程师挡在了“炼丹房”外。\n现在，这堵墙正在被推倒。\n潞晨云微调SDK\n正式开放上线——这是\n国内首个全面开放、且兼容Tinker范式的Serverless微调平台\n。\n其基于Thinking Machine Lab开源的Tinker SDK构建，核心目标只有一个：\n为复杂且昂贵的强化学习，提供一套更具成本优势的工业级解法。\n拥抱后训练与RL：算法层与底层算力架构的解耦\n随着OpenAI o1在推理能力上的突破，业界逐渐形成共识——\n即大模型的能力突破已不再单纯依赖预训练\n（Pre-training）\n阶段的参数堆砌，\n后训练（Post-Training） 特别是强化学习，正成为决定模型实用价值的核心战场\n。\n以DeepSeek‑R1为例，仅靠强化学习训练，模型在AIME数学推理基准上的pass@1从15.6%提升至\n77.9%\n，充分展示了RL在低数据量条件下即可实现大幅能力跃升，迅速成为后训练赛道的新范式。\n然而，摆在算法工程师面前的问题依旧严峻。\n强化学习涉及到更为复杂的系统设计，训练过程中存在一系列的问题，如多个模型的优化，数据的传递，以及模型权重的传递；\n另外，一系列工程化的工作，给算法的设计带来了更多的困难，同时也对基础设施提出了更高的要求。\nTinker的出现，就是为了解决这个问题：\n把繁杂训练变成标准易用的API\n。\n潞晨云把这一范式写进底层假设，\n算法设计与基础设施解耦\n——开发者只负责定义数据与Loss函数，底层的异构集群调度、并行策略优化、容错运维等应被封装为基础设施服务，对开发者实现\n全托管与无感支持\n。\n它试图回答的不是范式是否新，而是开发者能否用起来、能否稳定跑起来。\n具体来看，\n潞晨云微调SDK\n兼容\nTinker接口\n，消除了从“算法灵感”到“模型落地”之间的工程化壁垒，在\n零代码微调\n与\n裸机全手写\n之间落在最佳平衡点，将研究精力和算力成本从集群运维还原至算法本身，带给开发者“本地写码、云端计算”的\n“训练即服务（Training as a Service）”\n流畅体验 。\n颠覆性人力效能比：1名算法工程师顶替原庞大Infra团队\n潞晨云微调SDK的核心思路可以概括为：\n算法工程师定义算法逻辑，潞晨云搞定Infra\n。\n在传统的开发中，用户往往要花大量精力去租赁合适的算力集群、管理环境配置、调训练框架和集群运维。\n但潞晨云将大模型训练拆解成了一组标准的函数原语, 打通了\n从SFT到RL的全链路\n：\nForward & Backward\n：\n处\n理前向传播与梯度计算；\nOptimizer Step\n：执行权重更新策略；\nSample (Rollout)\n：做推理生成和评估，使用户不仅可以完成SFT，更能轻松构建PPO、GRPO、DPO等复杂的强化学习\n（RLHF/RLAIF）\n训练流；\nSave State\n：管理模型检查点与状态保存。\n这意味着，用户可以在本地熟悉的Jupyter Notebook或IDE里，用最标准的Python语法像搭积木一样自由组合，掌控训练逻辑的细节。\n这种模式带来了颠覆性的“人力效能比”提升：它将原本需要运维工程师、Infra工程师、平台工程师和算法工程师紧密配合的庞大团队，简化为了“一个算法工程师”的独立闭环。\n用户不再被底层繁杂的基建拖累，不再背负多职能的枷锁，也不再是黑盒填参的被动执行者，而是能够独立驾驭大规模训练流的主动设计师。\n这也意味着，无论是监督微调\n（SFT）\n还是更复杂的强化学习\n（RL）\nPipeline，都能通过组合这些原子函数来灵活构建。\n那么问题来了，为什么体验能做到如此丝滑？\n为了实现极致的流畅度，潞晨云基于现有的GPU云服务架构实现了一套完整的后端系统。\n在具体实现中，潞晨云采⽤控制⾯与计算⾯分离设计，通过统⼀API Server管理跨地域的多个GPU计算集群，实现多云部署能⼒。\n核⼼采⽤基于Future模式的异步API，所有训练操作⽀持⾮阻塞调⽤，⽤⼾⽆需等待GPU计算完成即可继续执⾏后续逻辑。\n潞晨云微调SDK还具备智能队列系统，即使在资源洪峰期，任务也会自动进入持久化队列\n（Persistence Queue）\n，一旦底层资源可用，毫秒级启动，队列等待期间0计费，仅对实际prefill+sample+train的Token量收费，无资源闲置，将用户每一分钱都用在产生梯度的刀刃上。\n模型微调的算力零售革命：从“包机租赁”到“按Token计费”\n如果说“易用性”是后训练平台的入场券，那么“成本结构”则是决定谁能走得更远的护城河。\n在传统云主机的“包机/时租”模式中，用户一直在为“过程”买单——\n也就是说，无论是在加载数据、调试代码，还是仅仅在思考Loss函数，只要占用了显卡，计费表就在跳动。\n这种模式下，开发过程中有一半以上的预算都浪费在了这些没有实际产出的“垃圾时间”里。\n潞晨云为微调大模型场景引入了\nServerless架构\n，推行\n“按Token计费”\n的商业模式，将微调场景的算力服务切分到了最细的颗粒度：\n为价值付费\n：就像使用推理API一样，用户只需为Prefill\n（输入）\n、Sample\n（推理输出）\n和 Train\n（训练）\n产生的\n有效计算Tokens量\n付费。\n其他环节全免费\n：本地代码调试、环境配置、数据预处理、模型Checkpoint保存……这些在传统租卡模式下分秒必争的环节，在潞晨云\n全部免费\n。\n极致性价比\n：通常，RL需要同时维护高吞吐的推理集群\n（vLLM）\n和训练集群，算力成本极高。但在潞晨云上，实测基于官方Cookbook的math_rl recipe跑通包含Rollout采样、Reward评分和PPO更新的\n完整RL流程\n（~300 steps），总算力成本\n仅8.61元\n。这意味着，个体开发者也能低成本复现RLHF/RLAIF探索。\n技术落地的三个场景：SFT与RL同时“开箱即用”\n这种新模式，也将彻底改变不同领域开发者的工作流：\n1、科研场景：告别资源焦虑\n学术界，时间与算力往往是最紧缺的资源。\n研究人员不仅要面对繁琐的集群运维\n（Slurm/Docker配置）\n，还要应对昂贵的实验复现成本。\n潞晨云微调SDK支持“白盒级”的科研探索，全面兼容Tinker API。\n研究人员可以自定义Evaluation逻辑、通过Forward/Backward，Sample等原语精确控制后训练和强化学习Pipeline，而无需关心底层的分布式实现，让实验复现成本大幅降低。\n2、创业与独立开发：极速验证MVP\n对于初创团队，“快”是生存根本。\n利用潞晨云微调SDK的Serverless特性，开发者无需等待资源排期。配合极低的Token成本，实测从pip install到跑通一个包含1000条样本的SFT或RL微调实验，\n仅需数分钟\n。\n这种极致的边际成本，让创业者敢于在有限预算下快速迭代Reward模型，实现真正的“低成本试错”。\n3、工业级落地：复杂架构突围\n而在金融、医疗等垂直领域的工业应用中，已有微调API往往难以应对复杂的异构架构与RLHF/RLAIF需求。\n潞晨云微调SDK允许工程师通过train_step自由定义Loss逻辑与强化学习奖励函数。开发者拥有对模型权重与训练细节的完整控制权，实现端到端定制。\n极简实战：三步上手\n没有复杂的集群配置，没有冗长的Docker构建。\n使用潞晨云微调SDK，训练一个大模型就像写普通Python脚本一样简单：\n1、\nInstall & Import\n:\nBash\npip install hpcai\n2、\nInitialize Client\n: 目前已支持Qwen3系列\n(4B - 32B)\n，更多模型即将上线\nPython\nimport hpcai\n# 初始化 LoRA 训练客户端，无需配置复杂的分布式参数\ntraining_client = service_client.create_lora_training_client(\nbase_model=”Qwen/Qwen3-4B”,\nrank=32\n)\n3、\nDefine Training Loop & Run\n：像在本地写PyTorch一样，拥有对训练循环的完整控制权：\nPython\n# 训练循环：完全可控\nfor\nstep\nin\nrange\n(\ntarget_steps\n):\n# 前向与反向传播\nfwd_bwd = training_client.forward_backward(batch, “cross_entropy”)\n# 优化器步进\noptim = training_client.optim_step(adam_params)\n# 实时获取 Loss 进行监控\nloss = fwd_bwd.result().metrics.\nget\n(\n\"loss:mean\"\n)\n⽬前，微调SDK已覆盖Qwen3系列模型\n（4B、8B、14B、32B）\n，支持监督学习和强化学习训练方式，并将持续扩展更多模型能⼒与细分落地场景，⼤家也可以向官⽅提交需求push更新。\n平台还准备了\n开箱即用的HPC-AI Cookbook\n，提供包括\nDeepSeek-R1 GRPO算法、基于Verifier的数学推理、自定义Reward函数\n等复杂RL场景的完整代码实现。\n开发者无需从零构建复杂的PPO/GRPO流水线，只需复制Cookbook中的“配方”，\n运行轻量级本地train.py脚本，即可驱动云端复杂的分布式RL训练流\n，在潞晨云上复现具备复杂逻辑推理能力的SOTA模型。\n从“能训”到“可持续训”\n后训练正从学术支线升级为工程主线，AI基础设施的终极形态应该是“零认知负荷”——\n开发者只需描述数据与算法，其余\n（租卡、配环境、并行策略、运维调度、故障自愈，乃至RL涉及的一系列工程化的工作）\n全部下沉到用户无感。\n当GPU闲置成本趋近于0，环境配置时间趋近于0，长序列RLHF也能按Token即时计费，应用创新效率直接逼近算力上限。\n潞晨云微调SDK今日起全量开放：\n无需白名单，无需预约\n前150名专属链接注册即得30元使用额度\n（见置顶评论）\n立即体验：\nhttps://cloud.luchentech.com/fine-tuning\n使用文档：\nhttps://cloud.luchentech.com/doc/docs/finetune-sdk/\nReference\n[1] Tinker SDK: https://github.com/thinking-machines-lab/tinker\n[2] DeepSeek-R1: https://arxiv.org/pdf/2501.12948\n*本文系量子位获授权刊载，观点仅为原作者所有。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860414&idx=1&sn=9c444f49ba7b5b442106a459169eddbb&chksm=e9aa8382cd2901ce51ed3d54ebe3dea0773c3ec54342585fa5d319ce7d3f8e6f0f4e3a073934&scene=0&xtrack=1#rd",
      "publish_time": 1767851400,
      "publish_date": "2026-01-08 13:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://cloud.luchentech.com/fine-tuning\", \"https://cloud.luchentech.com/doc/docs/finetune-sdk/\", \"https://github.com/thinking-machines-lab/tinker\", \"https://arxiv.org/pdf/2501.12948\"]",
      "add_ts": 1767914373,
      "last_modify_ts": 1768000981
    },
    {
      "id": 327,
      "article_id": "51716",
      "title": "今夜无显卡！老黄引爆Rubin时代，6颗芯狂飙5倍算力",
      "description": "在CES 2026上，黄仁勋发布英伟达新一代Vera Rubin超算架构，推理性能提升5倍，训练性能提升3.5倍，成本降低10倍，预计2026年下半年量产。此次发布会虽无新显卡亮相，但全面聚焦AI，展现英伟达“All in AI”战略，彰显其在AI计算领域的领先地位与未来布局。",
      "content": "新智元报道\n编辑：编辑部\n【新智元导读】\n刚刚的CES 2026上，老黄带着Vera Rubin超算架构向全世界走来！Rubin的推理性能比Blackwell提升了5倍，训练性能提升3.5倍，成本降低10倍，已经大规模投产，将于2026下半年面世。没有新显卡的昨夜，老黄表示all in AI！\n天空一声巨响，全新版本的「皮衣老黄」闪亮登场。\n在本次CES演讲中最为激动人心的瞬间，就是英伟达全新一代芯片架构——Vera Rubin正式登场！\n全球AI算力告急？老黄霸气回应：Vera Rubin已全面投产。\n这是新一代的算力怪兽，也是对上一代霸主Blackwell的降维打击——\n推理Token成本直接暴降10倍，算力性能狂飙5倍。\n就连训练MoE模型所需的GPU数量，也直接减少了4倍。\n曾经，Blackwell终结了Hopper；如今，Rubin亲手埋葬了Blackwell。\n全程近两小时演讲，老黄提及重点包括——\n下一代Rubin平台亮相：六颗芯片，推理狂飙十倍\n自动驾驶端到端模型：AlphaMayo会思考、自主推理，全程0接管上路\n物理AI全家桶开源：基础模型、框架\n玩家彻夜难眠：CES 2026，没有显卡\n至于游戏玩家？\n对不起，这次真的没有新显卡。\n英伟达在X上的一纸公告，彻底击碎了「攒机党」最后的幻想：\nCES 2026将没有任何新\nGPU\n发布。\n这意味着，英伟达自2021年以来连续五年在CES发布新硬件的传统，就此终结。\n传闻已久的RTX 50 Super系列，受困于GDDR7显存的「产能地狱」，大概率已经胎死腹中。\nRubin炸裂登场\n6颗芯片，10倍推理，AI超算变工厂\n去年10月，老黄曾预计：未来五年，将有3到4万亿美元砸向AI基础设施。\nVera Rubin的大规模投产，可谓生逢其时。\n如果说Blackwell打破了单卡性能的极限，那么Rubin解决的则是\n系统规模化\n的难题。\n从此，算力将像电力一样廉价，AI的大爆发已近在咫尺！\n2024年，Vera Rubin架构首次亮相。\n等了两年，现在它终于正式投产了！\nBlackwell架构，从此将退出历史舞台。\n演讲现场，老黄告诉大家：AI所需的计算量急剧飙升，怎么办？不用怕，Vera Rubin，将解决我们面临的根本性挑战！\n这套为万亿参数模型的海量推理而生的平台，会彻底让算力低成本、规模化、工业化生产。\nRubin架构，以天文学家Vera Florence Cooper Rubin而命名。\n可以说，Rubin是英伟达第一次把CPU、GPU、网络、存储、安全，当成一个整体来设计。\n核心思路就是：不再「堆卡」，而是把整个数据中心变成一台AI超算。\n整个Rubin平台，由这6个关键组件构成。\n其中，Rubin GPU是整个平台的核心。它搭载第三代Transformer引擎，为AI推理提供50 PFLOPS的NVFP4算力。\n之所以能达到Blackwell GPU性能的5倍，是因为它的NVFP4张量核心，后者能分析Transformer各层的计算特性，动态调整数据精度与计算路径。\n另外，该架构还引入一颗全新的Vera CPU，专为智能体推理而设计。\n它采用88个英伟达自研Olympus核心，完全兼容Armv9.2，并具备超快的NVLink-C2C 连接，能实现176个线程的全性能执行，I/O带宽和能效比直接翻倍。\n当我们在Agentic AI或长期任务中启用全新的工作流时，会对KV cache造成很大压力。\n为了解决存储和互联的瓶颈，Rubin架构特别改进了Bluefield和NVLink系统。它通过外部方式和计算设备相连，这样就能更高效地扩展整体存储池的规模。\nBlueField-4 DPU是一个数据处理单元，它能卸载网络、存储和安全任务，还能管理AI的上下文记忆系统。\nNVLink 6中，单芯片就能提供每秒400Gb的交换能力。每块GPU提供3.6TB/s 的带宽，而Rubin NVL72机架提供260TB/s，带宽超过整个互联网。\n通过3.6 TB/s的带宽和网络内计算能力，它能让Rubin中的72个GPU像一个超级GPU一样协同工作，直接把推理成本打至1/7。\n现场，老黄给我们展示了Vera Rubin的托盘。小小的托盘上集成了2颗Vera CPU、4颗Rubin GPU、1颗BlueField-4 DPU和8颗ConnectX-9网卡，整个计算单元算力达到100 PetaFLOPS。\nRubin的目标，是解决MoE和万亿参数模型的训练成本，它做到了吗？显然，成果是显著的。\n训练、推理效率暴增\n测试结果显示，Rubin架构训练模型时的运行速度，直接达到上一代Blackwell架构的3.5倍（35 petaflops），推理任务的速度则高达5倍，最高可达50 petaflops！\n同时，它的HBM4内存带宽提升至22 TB/s，达到2.8倍，单GPU的NVLink互连带宽则翻倍到3.6 TB/s。\n在超大规模MoE训练中，Rubin所需的GPU数量相比Blackwell可减少至1/4，同时整体能耗显著下降。\n这背后，就有三大功臣。\nNVLink 6，让GPU间互联带宽再次大幅提升，多卡训练不再被通信拖慢；Vera CPU与Rubin GPU的协同调度，可以减少「GPU等数据」的空转时间；而ConnectX-9与Spectrum-6的深度协同，也让大模型训练不会再被集群规模限制。\n从此，训练万亿模型，不再是「堆钱」，只会是工程问题。\n训练解决了，那推理呢？\n结果显示，在推理侧，Rubin平台单位token的推理效率提升最高可达10倍！同样的模型和响应延迟，算力成本可以直接下降到原来的1/10。\n所以，模型可以跑得起百万token的长下文，企业级AI应用也可以部署了。\n存储瓶颈解决\n如上文所言，让AI模型多跑一会的关键挑战，就在于上下文数据。\n大量KV Cache该如何处理？英伟达推出了由BlueField-4驱动的推理上下文内存存储平台。\n这个平台在GPU内存和传统存储之间创建了「第三层」，直接让每秒处理的 token数提升高达5倍。\nDGX Super POD\n本次CES上，英伟达还推出了新一代DGX SuperPOD。\n它把多个装有72个GPU的Rubin NVL72连接起来，形成了更大的AI计算集群。\n在这次的DGX SuperPOD中，共有8个Rubin NVL72机架，相当于有576个GPU。\nNVIDIA Vera Rubin NVL72 提供统一、安全的系统，集成了72 块Rubin GPU、36块Vera CPU、NVLink 6、ConnectX-9 SuperNICs和BlueField-4 DPUs\n这样，SuperPOD就可以处理数千个Agentic AI智能体，以及数百万token上下文。\n可以说，英伟达一次性解决了数百个GPU相连、管理存储的问题，直接给我们提供了开箱即用的AI基础设施。\n第三代机密计算平台\n更为重要的是，Rubin是首个支持第三代机密计算（Confidential Computing）的AI超算平台。\n模型参数、推理数据、用户请求都会被全链路加密，即使的云厂商，也无法直接访问明文数据。\n这就解决了「敢不敢把核心AI放到云上」的问题，对于金融、医疗、政府、企业私有模型都非常重要。\n这些大厂，第一批用上Rubin\n老黄介绍说，Rubin会由AWS、Microsoft Azure、Google Cloud、Meta、OpenAI这些头部厂商先部署。\n而到2026年下半年，Rubin平台就会进入大规模商用阶段。\n所以，下一代GPT、Gemini、Claude模型，大概率都会运行在Rubin架构上。\n全程0接管，自动驾驶AI「会思考」\n如何教会AI物理学的基础事实？\n英伟达给出的答案是，把算力变成高质量的数据（Compute is Data）。\n在这一体系中，「世界基础模型」Cosmos扮演着重要的角色。\n交通模拟器输出的信号，被送入Cosmos再生成合理、运动上连贯的环绕视频，让AI学习其中真实世界的行为模式。\n如今，Cosmos已被全球下载数百万次，成为物理AI时代的重要基础设施。在英伟达，内部也在用其做自动驾驶研究。\n在此基础上，今天，英伟达正式发布了「端到端」自动驾驶AI——AlphaMayo。\n它是一个会思考、会推理的自动驾驶AI。从摄像头输入到车辆执行动作，全流程由模型完成。\nAlphaMayo独特之处，在于它具备了显式推理能力。\n系统不仅执行转向、制动、加速动作，还会给出即将采取行动的理由，以及对应的形式轨迹。\n自动驾驶最大挑战，来自于「长尾场景」，几乎不可能覆盖所有国家、所有道路的数据。\nAlphaMayo的策略是将复杂场景，拆解为多个熟悉的物理与交通子问题，通过推理将罕见情况分解为常见组合，完成应对。\n在演示中，车辆可以在全程0接管状态下，完成路径规划与行驶，顺利抵达目的地。\n在自动驾驶领域，英伟达投入持续了八年，如今第一次把AI「五层架构」完整跑通。\n由下到上：实体本身、芯片体系、模型层、基础设施层、应用层，构成了一套完全贯通的AI系统栈。\nAlphaMayo构成模型层，梅赛德斯-奔驰汽车构成应用层。\n这一次，老黄还官宣了，NVIDIA DRIVE AV软件首次搭载全新梅赛德斯-奔驰 CLA，提供L2级端到端驾驶。\n更重磅的是，Alpamayo家族全部开源。这一整套方法论，并不只适用于汽车，同样适用于机器人、机械臂等各类系统。\n全家桶开源，机器人ChatGPT时刻\n下一阶段，机器人将以各种形态进入现实世界，前提是，它们首先在Omniverse中学会如何行动。\n现场，老黄又召唤来了机器人瓦力登台配合演出，这里他讲了一句意味深长的话：\n未来的系统，都诞生在计算机里。\n英伟达正把自身能力嵌入到，计算密度最高、最复杂的工业体系统，就像此前与Palantir、ServiceNow的集成一样。\n如今，这一模式正被复制到了工业仿真与设计领域。\n在具身智能领域，老黄直接扔下了一套针对物理AI（Physical AI）的「开源全家桶」——模型、框架及基础设施，应有尽有。\n机器人的ChatGPT时刻已经到来！\n目前，所有新模型均已上线Hugging Face，拿来即用：\nNVIDIA Cosmos Transfer/Predict 2.5，这是完全可定制的世界模型，专门在虚拟世界里生成符合物理规律的数据，训练机器人的大脑。\nNVIDIA Cosmos Reason 2，让机器像人一样「看懂」世界并进行逻辑推理。\nNVIDIA Isaac GR00T N1.6，专为人形机器人打造，解锁全身控制，让机器人不再四肢僵硬。\n为了解决机器人开发中「各自为战」的痛点，英伟达发布了两大神器：\nIsaac Lab-Arena：这是GitHub上的开源框架，连接了主流基准测试，确保机器人在进厂打工前，已经在虚拟世界里经过了千锤百炼。\nNVIDIA OSMO：无论是在工作站还是混合云，它都能统一调度数据生成、模型训练和测试，大幅缩短开发周期。\n机器人技术已是Hugging Face上增长最快的领域。英伟达这次不仅是提供模型，更是深度集成：\nLeRobot集成：Isaac和GR00T技术直接通过LeRobot框架即可调用。\n硬件互通：Hugging Face的开源机器人Reachy 2和Reachy Mini现已完美适配英伟达的Jetson平台，语音、视觉、大模型能力瞬间拉满。\n软件强还不够，硬件必须硬。如今，全新的Jetson T4000模组，直接将Blackwell架构带到了边缘端：\n算力高达1200 FP4 TFLOPS，是上一代的4倍。\n1000台起订单价仅1999美元。\n70瓦功耗，简直是为能源受限的自主设备量身定做。\n老黄震撼预言\n未来所有应用，建在AI之上\n每隔10-15年，计算产业就会重来一次。\n演讲伊始，老黄还回顾了计算产业过去数十年的演进路径——\n从大型机到CP，到互联网、云计算，再到移动计算，每一次平台级跃迁，都会催生一整套全新的应用生态，软件开发方式也随之重构。\n而这一次，变化来得更加猛烈。\n他提到，当前产业正同时经历两次平台级转变：一是从传统计算走向AI，另一个是整个软件、硬件栈的底层重塑。\nAI正成为全新的「底座」，应用开始建立在AI之上。同时，软件开发与运行方式、应用生成方式发生了根本性变化。\n这一切，共同推动了「加速计算+AI」对整个计算体系的重塑，五个层级正在同时被重新发明。\n2022年ChatGPT爆发后，AI才真正走进大众视野。一年之后，推理模型首次登场，引入了「测试时Scaling」这一概念。\n模型不仅在训练阶段学习，还在推理阶段实时计算和推演。预训练、RL、推理这些阶段，都需要机器庞大的计算资源，也同时推动模型能力持续提升。\n2024年，另一项突破开始显现，直到2025年，智能体系统（Agentic AI）才迅速扩散开来。\n老黄再次提及，在英伟达内部，像Cursor这样的Agentic工具已深刻改变了软件的开发方式。\n智能体AI之后，下一个前沿便是物理AI（Physical AI），理解自然规律和物理法则，为AI打开了全新疆域。\n除此之外，过去一年，另一个具有决定性意义的变化来自「开源模型」。\nDeepSeek R1的出现，作为首批开源推理模型之一，给行业带起来巨大震动。\n但不可否认的是，其仍比前沿模型落后六个月。每隔半年，就有新模型涌现，而且越来越智能。\n英伟达，正引领着开源模型的生态，遍布多个领域。而且，在多个榜单上取得了亮眼的成绩。\n最具代表性的包括多模态Nemotron 3、世界模型Cosmos、机器人模型GR00T、蛋白预测模型OpenFold 3......\n老黄现场表示，以上一切成果，都为构建AI智能体服务，这是真正突破性的发展领域。\n当前AI模型已变得极其强大，智能体的推理能力为各类应用开启了大门。\n令老黄深感震惊的是，首次在Perplexity见证了其同时调用多个模型——AI在推理任何环节，直接调用最顶尖的模型。\n这背后本质上是「多云协同」，同时还具备了混合云特性。\n老黄明确地表示，这就是未来AI应用的基本形态。或者说，因为未来应用都构建在AI之上，这就是未来应用的基础框架。\n一方面，AI可以被深度定制。另一方面，系统始终保持最前沿。「定制+前沿」能力在同一架构中同时存在。\n在软件世界之外，更大挑战来自于现实世界。为此，物理AI需要三台计算机——\n第一台计算机：用于训练模型\n第二台计算机：用于推理，运行咋i汽车、机器人、工厂等边缘环境\n第三台计算机：专门用于仿真、模拟\n老黄提到，仿真是整个体系的核心，只有在可控的数字环境中，AI才能反复尝试、评估行为后果，并逐步建立对世界的理解。\n彩蛋\n演讲最后还有一个幕后花絮，DGX Station台式AI超算将在2026年春季上线。\n届时，英伟达还将同步推出更多针对GB300系统的实战手册（Playbooks）。\n如果说DGX Spark是开发者的入门首选，那么DGX Station就是一台放在你办公桌上的微型数据中心：\n搭载\nGB300 Grace Blackwell Ultra\n超级芯片。\n配备高达\n775GB\n的FP4精度一致性内存（Coherent Memory）。\n拥有Petaflop级AI算力，支持在本地运行高达\n1万亿（1T）参数\n的超大规模模型。\n得益于强大的硬件基础，DGX Station实测威力惊人：\nLLM预训练速度高达\n250,000 Token/秒\n。\n支持对数百万数据点进行聚类和大型可视化。\n从DeepSeek R1的开源震动，到Agentic AI的全面爆发，计算产业正在经历一场前所未有的重塑。\n在这个只有玩家落泪的早上，一个由物理AI驱动的全新世界，正在Vera Rubin的轰鸣声中，加速向我们走来。\n参考资料：HYZ\nhttps://nvidianews.nvidia.com/news/rubin-platform-ai-supercomputer\nhttps://www.nvidia.com/en-gb/data-center/vera-rubin-nvl72/\nhttps://blogs.nvidia.com/blog/dgx-superpod-rubin/\nhttps://www.nvidia.com/en-us/events/ces/\nhttps://youtu.be/0NBILspM4c4\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652661287&idx=1&sn=cd23c82dab944f74d2f3e48fa9a3d702&chksm=f04bc60ca7020467fc525cf47a0f9979b0c2a8f401b0405ecdaf904ea1aebf6f086b573c5cdb&scene=0&xtrack=1#rd",
      "publish_time": 1767847860,
      "publish_date": "2026-01-08 12:51",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://nvidianews.nvidia.com/news/rubin-platform-ai-supercomputer\", \"https://www.nvidia.com/en-gb/data-center/vera-rubin-nvl72/\", \"https://blogs.nvidia.com/blog/dgx-superpod-rubin/\", \"https://www.nvidia.com/en-us/events/ces/\", \"https://youtu.be/0NBILspM4c4\"]",
      "add_ts": 1767914384,
      "last_modify_ts": 1768000993
    },
    {
      "id": 329,
      "article_id": "51714",
      "title": "HPCA 2026 | DC-MBQC：首个面向基于测量的量子计算的分布式编译框架",
      "description": "本文提出DC-MBQC，一种面向基于测量的量子计算（MBQC）的分布式编译框架，旨在提升大规模量子计算的执行效率。该框架支持将复杂的量子计算任务自动分解并分配到多个量子处理单元中，优化资源利用并降低通信开销。通过创新的分布式编译策略，DC-MBQC有效解决了MBQC在可扩展性和实际硬件部署中的关键挑战，为未来高性能分布式量子计算系统提供了可行路径。",
      "content": "关键词\n：\n基于测量的量子计算，分布式量子计算\n导  读\n本文为 HPCA 2026\n（IEEE International Symposium on High-Performance Computer Architecture）\n会议接收论文\nDC-MBQC: A Distributed Compilation Framework for Measurement-Based Quantum Computing\n的解读。该工作由北京大学计算机学院李彤阳课题组完成。论文第一作者薛烨诚是北京大学计算机学院博士生，合作者包括北京大学计算机学院博士生杨睿以及香港中文大学助理教授梁之鼎博士。\n论文提出了\n首个面向基于测量的量子计算\n（measurement based quantum computing, MBQC）\n的\n分布式编译框架 DC-MBQC\n。该框架通过自适应图划分与层次调度算法，在多量子处理单元\n（QPU）\n系统中实现了计算任务的高效映射，显著降低了对光子寿命的硬件需求，为光量子计算的分布式扩展提供了重要的系统级解决方案。\n↑扫码跳转论文\n论文地址：\nhttp://arxiv.org/abs/2601.00214\n01\n问题介绍\n当前，量子计算硬件在超导、离子阱、中性原子等多个技术路线上均取得了显著进展。光量子计算凭借其高达 99.7% 以上的保真度和 MHz 级别的时钟频率\n[1][2]\n，也成为实现容错量子计算极具竞争力的物理平台。与超导、离子阱等采用量子电路模型、通过对静态量子比特执行逻辑门序列来完成计算的平台不同，光子作为“飞行的量子比特”，具有难以长期静止存储、但易于传输和测量的物理特性。\n这种特性使得基于测量的量子计算\n（MBQC）\n成为了光量子平台最自然、最高效的计算范式。在 MBQC 中，计算不再依赖逻辑门的按序演化，而是通过在动态生成的纠缠态（图态）上进行单量子比特测量来驱动。可以说，MBQC 是光量子硬件扬长避短、发挥性能的最佳拍档。\n图1. 光量子计算平台上的 MBQC 实现方案。小型图态由资源态生成器（RSG）生成，通过部分光子的聚合（Fusion）操作聚合为大型图态作为计算资源，并通过确定基底（由经典处理器计算）的单量子比特测量驱动计算过程。\n尽管 MBQC 完美契合了光子的特性，但在实际系统中，光子仍需在光纤延迟线\n（Delay Line）\n中暂存，以等待与其他光子进行同步（如聚合操作）或等待前序测量结果的反馈。这是一个极其严苛的物理限制：随着计算规模的扩大和程序复杂度的提升，光子需要在延迟线中存储的时间（即所需光子寿命）显著增加。由于光纤中的光子丢失率随时间呈指数级上升，过长的存储时间会直接导致计算保真度的崩溃。\n分布式量子计算\n（DQC）\n是解决扩展性问题的必经之路。然而，MBQC 的计算模式与量子电路模型截然不同，现有的分布式编译器无法直接应用。如何针对 MBQC 模型设计分布式编译框架，有效平衡负载和实现通信同步，是光量子计算迈向大规模扩展的关键难题。\n02\n主要结果\n本文提出了\nDC-MBQC\n，这是\n首个专为 MBQC 设计的分布式编译框架\n。该框架以最小化“所需光子寿命”为核心优化目标，系统性地解决了上述挑战。\n图2. DC-MBQC 框架流程图，包含自适应图划分、单 QPU 编译及层调度三个核心阶段。\n核心贡献包括：\n1.\n提出关键物理指标“所需光子寿命”\n： 首次将延迟线中的光子存储来源统一量化为“所需光子寿命”，作为评估编译器性能的物理感知指标。\n2.\n构建 DC-MBQC 分布式编译框架\n： 提出基于“连接层”的架构抽象，利用时间维度的路由能力实现了\n单 QPU 编译与全局通信约束的解耦\n。从而，复杂的 MBQC 分布式编译问题可被解耦为负载划分、通信与同步两方面。进一步地，我们首次将 MBQC 分布式编译的\n通信同步问题形式化为“层调度”问题\n并证明了其 HP-hardness，并针对该难题设计并实现了瓶颈驱动的迭代调度算法。\n3.\n大幅度的性能提升\n：在 8 个全互连 QPU 的设置下，DC-MBQC 相比于单 QPU 编译器（OneQ\n[3]\n，OneAdapt\n[4]\n）展现了显著的分布式优势：所需光子寿命优化 7.46 倍，大幅降低了对延迟线硬件质量的严苛要求；执行速度提升 6.82 倍，极大提高了运行效率。\n图3. DC-MBQC 与单 QPU 编译器（OneQ）的性能对比。\n03\n技术贡献：物理建模与系统抽象\n本文的核心贡献在于跨越了光量子物理特性与计算机系统设计之间的鸿沟。通过提出全新的度量指标与分布式抽象，DC-MBQC 成功将底层的物理噪声和通信细节转化为上层的编译优化问题。\n1. 核心度量：从“执行时间”到“所需光子寿命”\n在量子计算中，如何在有限的相干时间内完成计算是保证保真度的关键。对于光量子平台，这一挑战的一个重要方面是光子的存储问题。光子作为飞行的量子比特，等待同步时必须在光纤延迟线中存储。由于光子在光纤中的丢失概率随时间呈指数级上升，存储时间的长短直接决定了计算的物理保真度。\n现有的编译器通常以优化程序逻辑层面的“执行时间”为目标，忽略了物理层面光子存储的实际代价。为了弥补这一缺失，本文定义了“所需光子寿命”作为核心优化指标。在 MBQC 计算中，光子的同步等待需求可归纳为两个来源：\n待聚合光子：为利用 RSG 产生的小型图态生成计算所需的大型图态，需要将来自不同小型图态的光子在同一聚合设备当中进行聚合。其中，较早产生的光子必须在延迟线中等待，直至其配对光子产生并到达聚合设备。\n待测量光子：为纠正测量不确定性的影响，MBQC 中的单光子测量为自适应的，存在依赖关系的光子必须等待前序测量的经典结果反馈以确定当前的测量基。\n图4. 光子等待需求图解。在图（a）中，光子 B 需等待与其配对的光子 B 到达聚合设备，此后聚合操作方可执行。在图（b）中，光子 B 的测量基底依赖于光子 A 和 C 的测量结果，此时仍需等待经典处理器反馈以确定测量基底。\n“所需光子寿命”这一度量将这些不同的等待需求统一量化，使得编译器能够直接针对硬件物理瓶颈进行优化。\n2. 架构设计：基于“连接层”的编译-通信解耦\n在分布式量子计算中，MBQC 面临着与量子电路模型截然不同的编译挑战。电路模型的分布式编译主要关注如何在多个处理器间分配逻辑量子比特，以最小化昂贵的远程门操作（如 Teledata 或 Telegate）。而在 MBQC 模型中，计算由基于大规模纠缠图态的单比特测量驱动，跨芯片互连通过不同芯片上的光子聚合实现。由于不同量子比特上操作的可交换性，MBQC 模型中的单 QPU 计算和跨 QPU 互连天然具有解耦的特性。这为 MBQC 模型的分布式架构设计提供了全新的可能。\n分布式 MBQC 架构设计的基本问题是如何处理跨芯片的纠缠连接具体如何实现，即如何将逻辑计算图中被分配到不同 QPU 而需要聚合的光子\n（Connector）\n通过路由引导至同一聚合设备。一种直观的方案是在芯片边缘预留固定的物理区域专门用于通信，所有 Connector 全部编译至恰当的边缘位置并与其他 QPU 连接。然而，这种设计将通信功能与空间位置强行绑定，形成了一种僵化的空间约束，严重限制了单芯片编译器对逻辑计算子图进行全局布局优化的自由度。\n为突破这一空间束缚，DC-MBQC 框架利用 MBQC 计算固有的三维（2D 空间 + 1D 时间）资源网格特性，提出了一种基于“连接层”的架构抽象：\n时间维度的分层设计：\n在三维资源网格中，动态地插入专门用于处理通信的“连接层”。其他层设置专门执行本地计算任务的“执行层”，不处理跨芯片连接问题。\n时空路由机制：\n位于执行层中的 Connector 不需要在当前层的二维空间内长途跋涉至芯片边缘。相反，它们通过层间聚变被“垂直”路由至时间轴上相邻的连接层，并在连接层中被路由至通信端口。\n图5. 跨芯片连接方法图解。图（a）展示了预留边缘区域的方法，在此方法中，单 QPU 编译器必须将对应的 Connector 路由至特定的边缘位置。图（b）为本文提出的“连接层”方法。\n这一抽象\n将单 QPU 上的编译与跨 QPU 的纠缠连接彻底解耦，\n利用时间维度的路由能力，彻底消除了物理通信端口位置对单 QPU 编译的空间约束。这一解耦使得单芯片编译器可以专注于本地逻辑计算图的优化，无需感知复杂的全局通信约束；而所有的跨芯片通信需求则被统一卸载到连接层进行处理。\n基于此架构，复杂的分布式路由问题可被解耦为负载划分、通信与同步两方面。负载划分部分主要考虑通信切口最小化，而通信与同步方面主要考虑连接层的调度问题。\n在负载划分方面，本文利用“模块度”这一概念提出了自适应的图划分算法，在利用多级 k-路图划分算法\n[5]\n均衡负载、最小化通信的同时，以模块度作为核心评价指标在负载均衡性与逻辑计算图子图完整性之间寻找最优权衡，为后续单 QPU 的编译工作降低复杂度。\n在通信与同步方面，本文基于“连接层”这一架构抽象，将跨芯片的路由问题形式化为“层调度问题”，提供了其数学定义与 NP-hardness 的证明。这一抽象将单个光量子\n（Connector）\n的计算布局映射转化为了“执行层”与“连接层”的任务调度，实现了原有问题的极大简化。针对这一问题，本文设计了瓶颈驱动的迭代优化算法\n（BDIR）\n。在列表优先级调度给出的初始调度方案上，该算法采用全局视角的启发式策略进行优化：\n定位瓶颈：\n首先识别出当前导致最大所需光子寿命的关键任务。\n计算平衡点：\n以最小化所需光子寿命为目标，计算该任务在时间轴上的最佳位置。\n动态重排：\n将瓶颈任务固定在平衡点，使用列表优先级调度算法调整其他任务。这种方法可以在满足问题约束的前提下大致保持原有的任务顺序，避免原有优良结构的大幅度破坏。\n这种策略有效地减少了因同步等待产生的长所需光子寿命，实现了通信开销的最小化。\n04\n致  谢\n特别感谢佐治亚理工学院的宋旨欣同学为本研究所做的的实质性贡献，包括他在研究过程的频繁讨论中深刻而富有启发性的建议，以及在论文文献综述、图表绘制和引言起草过程中提供的实质性帮助。同时，感谢匿名评审专家热情、细致和富有建设性的意见，这些意见给我们很大的鼓励和帮助。\n参考文献\n[1] \"A manufacturable platform for photonic quantum computing.\" Nature 641, no. 8064 (2025): 876-883.\n[2] Aghaee Rad, H., T. Ainsworth, R. N. Alexander, B. Altieri, M. F. Askarani, R. Baby, L. Banchi et al. \"Scaling and networking a modular photonic quantum computer.\" Nature 638, no. 8052 (2025): 912-919.\n[3] Zhang, Hezi, Anbang Wu, Yuke Wang, Gushu Li, Hassan Shapourian, Alireza Shabani, and Yufei Ding. \"Oneq: A compilation framework for photonic one-way quantum computation.\" In Proceedings of the 50th Annual International Symposium on Computer Architecture, pp. 1-14. 2023.\n[4] Zhang, Hezi, Jixuan Ruan, Dean Tullsen, Yufei Ding, Ang Li, and Travis S. Humble. \"OneAdapt: Adaptive Compilation for Resource-Constrained Photonic One-Way Quantum Computing.\" arXiv preprint arXiv:2504.17116 (2025).\n[5] Karypis, George, and Vipin Kumar. \"Multilevel k-way hypergraph partitioning.\" In Proceedings of the 36th annual ACM/IEEE design automation conference, pp. 343-348. 1999.\n图文 | 薛烨诚\nPKU QUARK Lab\n关于量子算法实验室\n量子算法实验室 QUARK Lab\n(Laboratory for Quantum Algorithms: Theory and Practice) 由李彤阳博士于2021年创立。该实验室专注于研究量子计算机上的算法，主要探讨机器学习、优化、统计学、数论、图论等方向的量子算法及其相对于经典计算的量子加速；也包括近期 NISQ (Noisy, Intermediate-Scale Quantum Computers) 量子计算机上的量子算法。\n实验室新闻：\n#PKU QUARK\n实验室公众号：\n课题组近期动态\nNeurIPS 2025 | 计算一般形式多玩家博弈的相关均衡的近最优量子算法\nNeurIPS 2025 | QCircuitBench: 面向大模型驱动的量子算法设计的基准测试\nNat. Commun. | 无权图上高斯玻色采样分布的有效经典采样算法\nCMP | 随机分层图上的指数级量子游走加速\n—   版权声明  —\n本微信公众号所有内容，由北京大学前沿计算研究中心微信自身创作、收集的文字、图片和音视频资料，版权属北京大学前沿计算研究中心微信所有；从公开渠道收集、整理及授权转载的文字、图片和音视频资料，版权属原作者。本公众号内容原作者如不愿意在本号刊登内容，请及时通知本号，予以删除。\n点击\n“阅读原文”\n转论文链接",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU0MjU5NjQ3NA==&mid=2247508363&idx=1&sn=bd673e4934a54266915f410b7481911c&chksm=fa304c1f6373cb96b376486a51ef322676c98f7d8edde4e87e9f480ea3dcb5308fda5b19487f&scene=0&xtrack=1#rd",
      "publish_time": 1767846000,
      "publish_date": "2026-01-08 12:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"http://arxiv.org/abs/2601.00214\"]",
      "add_ts": 1767914396,
      "last_modify_ts": 1768001005
    },
    {
      "id": 330,
      "article_id": "51713",
      "title": "硬刚黄仁勋！AMD祭出「千倍算力大杀器」，「反黄联盟」崛起",
      "description": "CES现场，AMD CEO苏姿丰宣布四年内AI算力将提升1000倍，推出Helios“太阳神”机架与MI455X芯片，单代性能提升10倍，正面挑战英伟达。新架构支持Yotta级计算与128GB统一内存，展现AMD在AI算力领域的雄心，意图重塑全球AI格局，开启高性能计算新时代。",
      "content": "新智元报道\n编辑：艾伦 KingHZ\n【新智元导读】\nCES现场，苏姿丰投下震撼弹：四年内AI算力将提升1000倍！ 面对英伟达的封锁，AMD不再隐忍，直接祭出Helios「太阳神」机架与MI455X芯片，以单代性能暴涨10倍的「暴力美学」正面硬刚。从Yotta级计算宏图到128GB统一内存的PC怪兽，AMD正用一场史无前例的算力狂飙，试图彻底重写AI世界的权力版图。\n今日是美国拉斯维加斯举办的消费电子展（CES）主旨演讲日，更是全球科技产业权力版图剧烈震荡的一天。\n几个小时前，身着标志性皮衣的英伟达CEO黄仁勋刚刚走下舞台，留下了令竞争对手窒息的Vera Rubin平台和Agentic AI的宏大愿景，仿佛一位刚刚巡视完疆土的帝王。\n然而，聚光灯并未就此熄灭。\n之后，所有的目光转向了AMD的掌门人苏姿丰（Lisa Su）。\n这位总是身着干练西装、在男性主导的半导体世界中杀出重围的女性，正准备在发布会上，向那个看似不可战胜的「绿色帝国」发起这一代最猛烈的冲锋。\n这是算力世界「双城记」的缩影。\n一边是英伟达，试图通过封闭的生态、极致的垂直整合构建起不可逾越的「围墙花园」，将数据中心变成只属于它的黑色方尖碑；\n另一边是AMD，试图通过结盟、开放标准和堆料极致的硬件，率领着包括OpenAI、微软、Meta在内的「复仇者联盟」，试图在铁幕上撕开一道口子。\n这场发布会早已超越了摩尔定律的线性叙事。\nAMD在今天发布的除了芯片本身，更是一整套试图打破英伟达垄断的蓝图。\n在深入解读AMD的突围之前，我们必须先审视那道横亘在AMD心头的巨大阴影——英伟达刚刚发布的Vera Rubin平台。\n了解对手的强大，才能理解AMD此次反击的悲壮与战略价值。\n以天文学家之名，封锁宇宙\n就在AMD发布会开始前，黄仁勋展示了英伟达的下一代核武：\nVera Rubin\n。\n这个名字本身就充满了隐喻——Vera Rubin是证实暗物质存在的著名天文学家，而英伟达正试图掌控AI宇宙中那些「看不见」但决定一切的力量：数据流动的引力。\n根据现场披露的信息，Vera Rubin平台严丝合缝、甚至精密得令人窒息。\n它由三个核心组件构成，每一个都直指AMD的要害：\n(1)\nRubin\nGPU\n：这是英伟达的皇冠明珠。\n虽然具体工艺细节被严格保密，但其配备了下一代HBM4（高带宽内存）。这一事实，足以让整个行业颤抖。 HBM4不仅仅是速度的提升，更是容量的质变，直接解决了大模型训练中的「内存墙」问题。\n(2)\nVera\nCPU\n：这是英伟达基于Arm架构深度自研的怪兽。\n它拥有88个自定义Arm核心和176个线程。 英伟达的意图或许是：通过超级芯片的设计，将Vera CPU与Rubin GPU在物理层面「焊死」在一起，逐步在高端AI服务器中剔除x86架构的CPU（也就是AMD和Intel的主阵地）。\n(3)\nNVL144 机架\n：这是英伟达「数据中心即计算机」理念的终极形态。\n单机架拥有144颗GPU，通过NVLink 6互联，带宽达到了惊人的260TB/s。 这是一台巨大的、单一的、吞噬电力的超级计算机。\n英伟达传递的信息冷酷而明确：在未来的AI数据中心里，不需要插拔，不需要兼容，甚至不需要其他品牌的Logo。你买的不是芯片，而是英伟达定义的「算力单元」。\nAgentic AI\n从训练到Agent的战略转向\n更令AMD感到压力的是英伟达在软件叙事上的升级。\n黄仁勋在演讲中不再只谈论训练，而是大谈特谈Agentic AI。\n当AI模型从单纯的聊天机器人进化为能自主规划、调用工具、解决复杂任务的智能体时，推理算力的需求将不再是线性的，而是指数级的。\n一个Agent为了完成一个任务，可能需要在后台进行数千次的推理、反思和模拟。\n英伟达声称，Rubin平台能将推理Token的成本降低10倍。\n这种「降维打击」般的承诺，直击了OpenAI等客户的痛点——他们每天都在为天文数字般的电费和算力成本发愁。\n英伟达试图告诉市场：只有我的软硬件一体化平台，才能承载这种能够「思考」的AI。\n在这样的背景下，苏姿丰登场了。\n她面对的是一个近乎完美的对手，一个不仅垄断了现在，还试图定义未来的帝国。\nAMD的绝地反击\nHelios与万倍增长的野心\n灯光渐暗，大屏幕上亮起了AMD标志性的橙红色光芒。\nPPT的第一页是一句充满了防御性却又极具进攻意味的标语：「Solving the World's Most Important Challenges」（解决世界上最重要的挑战）。\n苏姿丰没有回避房间里的大象，而是直接切入正题：算力需求的爆炸。\nYotta Scale：摩尔定律的墓志铭与复活\nAMD直接抛出了概念：\nYotta Scale Compute\n（尧字节级计算）。\n尧塔浮点运算（Yottaflop），代表每秒一亿亿亿次浮点运算（10²⁴ FLOPS）。\n目前，最强的\nEl Capitan\n还是百亿亿次浮点运算（1.742 Exaflops，即10¹⁸ FLOPS）\nAMD的目标是未来5年，10万台El Capitan级超级计算机。\n目前，世界最强超级计算机El Capitan，占地约697平方米，相当于两个网球场大小\n根据AMD的内部数据，AI算力需求正在经历每年前所未有的暴涨。\nPPT第8页赫然写着：「10,000x Increase in AI Compute」。\n苏姿丰说：「不仅训练算力每年增长4倍，在过去两年里，推理Token的数量增加了100倍。」\n这一数据直接回击了英伟达关于「推理成本」的叙事——AMD同样看到了Agentic AI的未来，但他们的解决方案完全不同。\nAMD试图用更开放、更巨大的规模来解决问题。\nHelios AI Rack：开放架构的图腾\n发布会的高潮是一个名为「Helios」的AI机架的揭幕。\n以希腊神话中的太阳神命名，Helios承载了AMD照亮黑暗、打破垄断的隐喻。\n如果说英伟达的NVL72是一座封闭的黑色方尖碑，那么Helios就是AMD试图构建的「巴别塔」——一座由全人类（除了英伟达）共同建造的高塔。\n为了更直观地理解这场对决，我们将Helios与英伟达的NVL平台进行了详细对比：\nHelios机架不仅仅是硬件的堆叠，它是AMD战略的集大成者。\nZen 6的首次确认与x86的坚守\n：\n在PPT的参数列表中，赫然写着「4,600 'Zen 6' CPU Cores」。\n这是一个巨大的彩蛋，也是AMD对英伟达Vera CPU最有力的回击。\n当英伟达试图将世界推向Arm架构时，AMD坚守并升级了x86架构。\n对于那些在这个星球上拥有数以亿计基于x86代码资产的企业来说，不需要为了AI重写所有的底层代码。\n31TB HBM4内存的暴力美学\n：\n这是一个让现场发出惊呼的数字。\n对于大模型训练而言，显存容量往往比计算速度更早成为瓶颈。\nAMD继续沿用了「大显存」策略，试图用海量的HBM4来容纳更巨大的MoE模型，从而减少跨卡通信的频率。\n这是一种简单粗暴但极为有效的策略：如果你的互联速度不如NVLink，那就把内存做大，减少互联的需求。\nMI455X：参数怪兽与模组化的胜利\n作为Helios的心脏，\nAMD Instinct MI455X\n被正式推向舞台中央。\n10倍性能跃迁\n：相比于前代MI355X，MI455X实现了\n10倍\n的性能提升。\n这是一个激进的数字，通常代际升级在2-3倍，10倍的宣称意味着架构级的重构。\n这主要得益于新的CDNA架构和制程红利。\nOAM模组化设计的坚持\n：\n不同于英伟达越来越倾向于将CPU和GPU焊死在一块主板上，AMD依然强调即插即用的灵活性。\n这意味着客户可以保留原有的服务器机箱，只升级计算模组。\n这对于成本敏感的云服务商来说，是极具诱惑力的「反锁定」策略。\n他们不需要因为升级GPU而扔掉整个机柜的电源和散热系统。\n未来路线图：MI500与千倍提升\nAMD展示了直到2027年的路线图，这种透明度在瞬息万变的半导体行业极为罕见。\n2026年\n：MI400系列（即今天的MI455X）。\n2027年\n：\nMI500系列\n。这将基于\nCDNA 6架构\n，采用2nm工艺，配备HBM4E内存。\nAMD承诺在4年内实现1000倍的\nAI\n性能提升。\n这是在告诉资本市场和客户：「我们有长期的技术储备，不会在英伟达的快速迭代中掉队。我们是长跑选手，不是投机者。」\n数据中心的血管\n互联技术的隐秘战争\n如果说GPU是跑车，那么互联技术就是高速公路。\n英伟达之所以无敌，不仅仅是因为跑车快，更是因为他们修了私有的高速公路（NVLink），只允许自家的车跑，而且还要收昂贵的过路费。\n本次发布会上，AMD最核心、也是最具破坏力的战略反击，就是联合全行业修建一条免费、通用的高速公路——\nUALink (Ultra Accelerator Link)\n，以及升级原本的国道——\nUltra Ethernet (超以太网)\n。\n拆解NVLink的霸权：为何它是英伟达真正的护城河？\n在技术圈，NVLink被视为英伟达最深的护城河，甚至超过了CUDA。\n它允许GPU之间像大脑神经元一样共享内存，延迟极低。\n没有NVLink，几千张GPU堆在一起只是一堆沙子；\n有了NVLink，它们才是一颗超级大脑。\n英伟达的策略是：如果你想用最高效的集群，就必须买全套英伟达方案。\nNVLink不兼容任何其他厂商的芯片，它是一个封闭的物理层协议。\nUALink：技术突围\nAMD在PPT中专门辟出一页介绍开放生态。\n这背后是一个名为\nUALink Consortium\n的庞大联盟。\nScale Up（节点内扩展）的利剑\n：\nUALink\n。\n这是直接对标NVLink的技术。\n它由AMD、英特尔、微软、Meta、谷歌、博通等巨头共同制定。\nUALink 1.0规范支持多达1024个加速器在一个POD内互联，这在规模上甚至超越了英伟达当前的NVSwitch能力。\n内存一致性\n：\nUALink最关键的特性是支持显存池化。\n这意味着AMD的GPU可以访问同一集群内其他GPU的内存，就像访问自己的一样。\n这对于训练万亿参数模型至关重要，也是此前只有NVLink能做到的事情。\n这是一个典型的「合纵连横」故事。\nOpenAI、微软、Meta这些巨头最恐惧的不是技术瓶颈，而是供应商锁定。\n如果未来的AI基础设施完全依赖英伟达的私有标准，这些科技巨头的议价权将归零。\n因此，Helios机架不仅仅是AMD的产品，它是整个「反英伟达联盟」的意志体现。\n以太网的逆袭：UEC vs InfiniBand\n除了UALink，发布会中多次提到\nUltra Ethernet (UEC)\n。\n这是另一场关乎生死的战争：节点间互联。\nInfiniBand的统治\n：\n英伟达在收购Mellanox后，垄断了高性能网络InfiniBand。 它延迟极低，无损传输，是AI训练的黄金标准。\n以太网的进化\n：\nAMD没有选择自研私有网络，而是押注以太网的进化。 UEC旨在解决传统以太网在AI负载下的丢包和拥塞问题。\n成本的逻辑\n：\nInfiniBand昂贵且封闭，而以太网廉价且通用。 根据研究，UEC方案的每GFLOP成本比InfiniBand低27%。\n如果UEC成功，意味着客户可以用便宜通用的以太网交换机（比如博通、思科的产品）来组建超级计算机，而不需要购买昂贵的英伟达Quantum InfiniBand交换机。\n这正是Helios机架的杀手锏：\n更低的总拥有成本（TCO）\n。\n对于那些要购买数万张显卡的客户来说，这节省下来的钱可能高达数十亿美元。\n端侧的野望\nRyzen AI Max与「Mac Studio杀手」\n视线从云端的数据中心拉回，苏姿丰将展示重点转向了PC。\n在AI时代，PC正在变成「私人AI助理」的物理载体。\nRyzen AI Max：打破内存墙的128GB豪赌\nAMD发布了震撼级的产品——\nRyzen\nAI\nMax系列\n。\n这款芯片看似只是笔记本处理器，但其参数却令人咋舌，尤其是那个恐怖的数字：\n128GB统一内存\n。\n为什么这很重要？\n在过去，x86处理器的内存和显存是分离的，且容量有限。\n想在笔记本上运行一个像Llama 3 70B这样的大模型几乎是不可能的，因为显存不够。\n苹果的M系列芯片（M3 Max/Ultra）之所以受开发者欢迎，就是因为统一内存架构允许大模型直接在本地运行。\nAMD Ryzen AI Max直接对标苹果，成为首款能运行2350亿（235B）参数模型的x86处理器。\n这意味着，开发者可以在一台Windows笔记本上，流畅运行企业级的超大模型，而无需联网。\n性能对比：羞辱英特尔，追赶苹果，挑战英伟达\n现场的PPT充满了火药味，AMD几乎把市面上所有的竞争对手都拉出来打了一遍：\n对比Intel Core Ultra 9\n：\nRyzen AI 400系列在内容创作上快1.7倍，多任务处理快1.3倍。\n这象征着x86阵营内部话语权的转移。\n对比Apple M5\n：\n这是一个大胆的比较。\nAMD声称Ryzen AI Max在AI Token生成速度上快1.4倍。\n对于那些苦于苹果生态封闭、又羡慕其统一内存架构的开发者来说，这是唯一的替代品。\n对比Nvidia DGX Spark\n：\n最令人意外的是，AMD将笔记本芯片与英伟达的工作站级别产品对比。\n在每美元Token生成效率上，Ryzen AI Max是英伟达DGX Spark的1.7倍。\nAMD描绘了一个诱人的未来：每一个开发者、每一个创作者，都能在自己的书桌上拥有一台「微型超算」。\n不再需要昂贵的云端API，不再担心隐私泄露，你的Ryzen AI Max就是你的私有GPT。\n这对于OpenAI等公司来说也是利好——如果端侧算力足够强，大量的推理任务可以从云端卸载到用户本地，从而节省天文数字般的云服务器成本。\nHalo Platform：开发者的「军火库」\n除了硬件，AMD还发布了Ryzen AI Halo处理器，专为AI开发者设计。\n它是一个平台。\n它预装了ROCm软件栈（AMD的CUDA替代品），优化了PyTorch、Hugging Face等框架，并且实现了Day-0支持主流模型（Llama, GPT-OSS, Flux等）。\nAMD终于意识到，软硬结合才是王道。\n他们试图用类似苹果的体验，将开发者从CUDA的引力场中拉出来，给他们一把「铲子」，让他们在AMD的土地上挖掘AI的金矿。\n盟友的站台，不仅仅是商业互吹\n在发布会的后半程，PPT上出现了一张密密麻麻的Logo墙。\n但其中最耀眼的，莫过于OpenAI。\n虽然奥特曼没有亲自出场站台，而是OpenAI总裁Greg Brockman代为出席，但OpenAI作为核心合作伙伴出现在第一位，本身就是最强烈的信号。\n这是一场关于生存的博弈。\nOpenAI的焦虑与AMD的机会\n为什么OpenAI需要AMD？\n答案很简单：恐惧。\nOpenAI对算力的饥渴已经到了病态的程度。\nBrockman直接摊牌，在OpenAI内部，\n「算力一直在被争抢」\n。\n对此，苏姿丰打趣道：「我每次见到你，你都会告诉我：你们还需要更多算力。」\n随即，她抛出一个关键问题：「\n需求真的有这么大吗？」\nBrockman的回答相当直接：\n过去几年里，OpenAI的算力规模\n几乎每年都在翻倍甚至三倍增长\n，而且这种趋势不会放缓。\n他甚至用ChatGPT，做了一页幻灯片，分析了OpenAI\n如何让推理更省算力，\n包括更高带宽、更强性能、更低的HBM内存占用。\n据报道，GPT-6及后续模型的训练需要数万张甚至数十万张B200。\n如果只依赖英伟达，OpenAI的命运就完全掌握在黄仁勋手中。\n英伟达可以决定谁先拿到芯片，谁能拿到多少，甚至以什么价格拿到。\n议价权\n：\n引入AMD作为「二供」，是OpenAI乃至微软逼迫英伟达降价、或者至少不随意涨价的唯一手段。\n哪怕AMD的芯片只能达到英伟达80%的性能，只要它存在，英伟达就不能肆无忌惮地垄断定价。\n供应链\n安全\n：\n当台积电的CoWoS产能被英伟达订满时，AMD提供了一个备选项（尽管他们也争抢台积电产能，但AMD的Chiplet设计策略使其能利用不同的封装技术，增加了供应链的弹性）。\n软件生态的破局：ROCm的进化与PyTorch的胜利\n除了OpenAI，我们还看到了Hugging Face、PyTorch、Databricks等名字。\n这是AMD对外界质疑最有力的回应。\n多年来，关于AMD最大的诟病就是「硬件一流，软件三流」。\nROCm（Radeon Open Compute）一直被认为是CUDA的拙劣模仿者，Bug多、文档少。\n但在这次发布会上，AMD展示了ROCm的广泛采用。\n这一变化的幕后推手是PyTorch 2.0。\n随着PyTorch等高层框架的普及，底层的CUDA依赖正在被剥离。\n对于大多数开发者来说，只要PyTorch代码能跑，底下是A卡还是N卡已经越来越不重要了。\nOpenAI的Triton语言更是加速了这一过程，它允许开发者编写的代码自动优化到不同的硬件后端。\n这正是AMD「农村包围城市」战略的体现：既然无法在底层CUDA上击败你，那就把战场拉到上层的PyTorch和Triton上，在那里，大家是平等的。\n算力战争，才刚刚开始\n苏姿丰抛出了一个让全场愣住的判断：「\n五年内，全球将有50亿人每天都在使用AI 。\n」\n注意：是每天都在用！\n这意味着算力需求将持续指数级增长。\n2025年，全球AI用户已超过10亿！而且，这不是AI的终点：未来主动式和自动化AI还将指数级增长，引爆更多推理算力需求。\nAMD的另一个关键判断是：\nAI\n正在从云端，走向个人电脑。\n李飞飞直接描绘了未来的游戏体验。\n她的公司World Labs旗下的产品Marble，只需要\n少量照片\n，就能让模型自动构建一个完整的\n3D世界\n。\n现场演示中，只要用手机随手拍几张照片，AI就能自动生成3D场景。\n游戏、虚拟世界、创作门槛，会被彻底打穿。\n这深远影响PC的使用体验。\n更激进的，是主动式智能体。\n明年开始，你的电脑，可能真的会「替你打工」：\n除了PC，AMD 还在同步押注物理AI等场景。\n哪里需要\nAI\n算力，AMD就会出现在哪里。\n这一次，\nAMD是真正的All in AI。\n当苏姿丰在台上展示\nLUMI\n超级计算机（由AMD驱动的前欧洲最快超算）在气候模拟上的贡献时，更是进一步输出了价值观。\n反英伟达联盟的本质\n本次CES发布会，实质上是「反英伟达联盟」的一次誓师大会。\n英伟达的路线\n：\n类似于早期的IBM或现在的苹果。\n封闭、昂贵、体验极致、利润独吞。\nVera Rubin平台将这种封闭推向了极致，从CPU到GPU再到网卡和交换机，全部自研，全部私有。\nAMD的路线\n：\n类似于安卓。\n开放、混乱但充满活力、性价比高、利润共享。 它联合了博通（网络）、英特尔（CPU互联）、微软（软件）等所有被英伟达边缘化的巨头。\n客户的选择\n：\n短期内，为了追求极致性能（如训练GPT-6），巨头们依然会咬牙购买英伟达的Rubin。\n但在推理侧和中等规模训练中，Helios和MI455X提供了极具吸引力的替代方案。\n发布会结束了，苏姿丰在一片掌声中退场，留下了身后大屏幕上那个巨大的「Together we advance_」的标语。\n这一刻，AI算力的分岔路口\n对于全球科技产业而言，2026年的这天意义非凡。\n我们并不希望看到一个只有一个玩家的游戏。\n当英伟达试图用Vera Rubin将整个AI产业封装进它的黑色机柜时，AMD用Helios在墙上凿出了一扇窗。\n如果说英伟达是算力时代的「罗马帝国」，不仅修路（NVLink），还造车（GPU），甚至开始制定交通规则（Agentic AI），那么AMD就是那个试图维持贸易自由的「商业联邦」。\nOpenAI需要这扇窗，微软需要这扇窗，在这个星球上每一个渴望低成本、普惠AI算力的开发者都需要这扇窗。\n这场「AI算力战争」没有终点，Yotta Scale只是下一个开始。\n正如沙漠中每一粒沙子都可能成为未来的芯片，算力的世界里，也绝不应该只有一种声音。\n参考资料：\nhttps://www.youtube.com/watch?v=UbfAhFxDomE\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652661479&idx=2&sn=6aa050d42214a167f0b398c42040f36c&chksm=f0a87d62eb6541ec3abb541aa21c0ac1d54191be107ea6d24929c7c58dba88b99017a5a585d9&scene=0&xtrack=1#rd",
      "publish_time": 1767841800,
      "publish_date": "2026-01-08 11:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.youtube.com/watch?v=UbfAhFxDomE\"]",
      "add_ts": 1767914406,
      "last_modify_ts": 1768001012
    },
    {
      "id": 335,
      "article_id": "51703",
      "title": "老黄开年演讲「含华量」爆表！直接拿DeepSeek、Kimi验货下一代芯片",
      "description": "2026年CES上，英伟达CEO黄仁勋的演讲PPT展示了中国大模型Kimi K2、DeepSeek V3.2和Qwen，标志着中国AI在国际舞台的崛起。这些模型性能逼近闭源系统，位列全球开源前列，彰显中国在算力新时代的重要地位，成为国产AI发展的高光时刻。",
      "content": "新智元报道\n编辑：好困 桃子\n【新智元导读】\nCES巨幕上，老黄的PPT已成中国AI的「封神榜」。DeepSeek与Kimi位列C位之时，算力新时代已至。\n万众瞩目的2026 CES科技盛宴上，一张PPT瞬间燃爆AI圈。\n老黄主旨演讲上，中国大模型Kimi K2、DeepSeek V3.2，以及Qwen赫然上屏，位列全球开源大模型前列，性能正在逼近闭源模型。\n这一刻，是属于中国AI的高光时刻。\n另外，OpenAI的GPT-OSS和老黄自家的Nemotron，也做了标注。\n而且，DeepSeek-R1、Qwen3 和 Kimi K2 代表着MoE路线下顶级规模的尝试，仅需激活少量参数，大幅减少计算量和HBM显存带宽的压力。\n在下一代Rubin架构亮相的核心环节上，老黄还选用了DeepSeek和Kimi K2 Thinking来秀性能。\n在Rubin暴力加成下，Kimi K2 Thinking推理吞吐量直接飙了10倍。更夸张的是，token成本暴降到原来的1/10。\n这种「指数级」的降本增效，等于宣告了：AI推理即将进入真正的「平价时代」。\n另外，在计算需求暴涨这页PPT上，480B的Qwen3和1TB的Kimi K2成为代表性模型，验证了参数规模每年以十倍量级scaling。\n不得不说，老黄整场发布会上，中国AI模型的含量超标了。\n推理狂飙十倍\n中国模型成老黄「御用」AI？\n无独有偶，英伟达去年12月的一篇博客中，也将DeepSeek R1和Kimi K2 Thinking作为评判性能的标杆。\n实测显示，Kimi K2 Thinking在GB200 NVL72上性能可以暴增10倍。\n另外，在SemiAnalysis InferenceMax测试中，DeepSeek-R1将每百万token的成本降低10倍以上。包括Mistral Large 3在内同样获得了十倍加速。\n这意味着，复杂的「思考型」MoE部署到日常应用，成为了现实。\n如今，随便拎出一款前沿模型，只要深入其内部结构，便会发现MoE（混合专家）成为了主流的选择。\n据统计，自2025年以来，超60%开源AI采用了MoE架构，从2023年初，这一架构推动LLM智能水平提升近70倍。\n此外，在权威机构Artificial Analysis（AA）排行榜上，最智能的TOP 10开源模型，也全都用的是MoE结构。\n如此巨大规模的MoE，单GPU必然无法部署，英伟达GB200 NVL72却能破解这一难题。\nDeepSeek R1和Kimi K2 Thinking实测结果，恰恰证明了英伟达Blackwell超算性能的强大所在。\n如今，中国大模型闪耀全球舞台，它们令人惊叹的表现，开启了AI推理高效的新时代。\n开源AI扛把子，震惊歪果仁\n去年底，Anthropic发布了一项针对全球16个前沿模型的严苛行为基准测试。\n在这一众顶尖高手中，DeepSeek与Kimi不仅是唯二入局的中国面孔，更交出了惊艳的答卷——\nKimi K2 Thinking凭借极低的被误导率，一举摘得「表现最佳的非美国模型」桂冠。\n注：得分越低性能越强，越不容易被误导\n这种技术实力也迅速转化为国际影响力和落地应用。\n从「硅谷风投教父」Marc Andreessen的公开盛赞，到OpenAI前CTO的新产品Thinker上月官宣接入Kimi K2 Thinking，中国AI的硬实力正在被全球核心圈层接纳。\n权威评测进一步印证了这一趋势。\n在知名AI\n大佬Nathan Lambert与Florian Brand联合发布的「2025年度开源模型回顾」中，DeepSeek、Qwen和Kimi强势包揽Top 3。\n随后，Lambert更在专文中深入分析，高度评价了中国开源AI所具备的独特优势。\n1. 开源模型的「唯快不破」\n尽管最强闭源模型与开源之间仍存代差，但中国实验室正在以惊人的速度发布模型，大幅压缩了这一差距。\n在技术飞速迭代的当下，「更早发布」本身就是一种巨大的先发优势。\n2. 始于「\n冲\n榜」，终于「体验」\n中国模型在基准测试上的表现愈发生猛，但更关键的是从「分高」到「好用」的转变。\n我们见证了Qwen的进化：最初以「冲榜」闻名，如今已成为名副其实的优质模型。\n顺着这一思路，K2 Thinking在后训练阶段原生采用4bit精度，显然是为了更高效地支持长序列RL扩展，使其更胜任实际的服务任务。\n3. 中国力量的品牌崛起\n年初，外国用户可能叫不出任何一家中国AI实验室的名字；如今，DeepSeek、Qwen和Kimi已成为东方技术实力的代表。\n它们各有高光时刻和独特优势。重要的是，这份名单还在不断变长，中国AI正在世界舞台占据一席之地。\n4. 突破：海量工具调用与穿插思考\nKimi K2 Thinking支持「数百步稳定工具调用」引发热议。\n虽然这在o3、Grok 4等闭源模型中已成标配（RL训练中的自然涌现），但这通过开源模型实现尚属首批，这对托管服务商的精准支持能力提出了极高要求。\n此外，是「交错思考」（Interleaved thinking）——即模型在调用工具的间隙进行思考。\n这是继Claude之后，强调 agentic 能力的模型都在跟进的新趋势，标志着模型逻辑链条的进一步成熟。\n5. 倒逼美国闭源巨头\n开源的激增让美国闭源实验室倍感压力——仅仅依靠基准测试分数已无法解释「为什么付费更好」了。\n相比之下，中国模型或许在收入上暂未占优，但在全球市场的「心智份额」上，正在切走越来越大的一块蛋糕。\n回看CES 2026这场演讲，老黄直接把「开源」讲成了全场最硬核的主线。\n中国开源AI的表现足以令世界惊叹，随着更多开发者和企业拥抱这些模型，AI应用的全面爆发指日可待。\n参考资料：\nhttps://blogs.nvidia.com/blog/mixture-of-experts-frontier-models/\nhttps://www.interconnects.ai/p/kimi-k2-thinking-what-it-means\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652661479&idx=1&sn=97ccb7250091e10840758dae897a23f9&chksm=f0543ebb594bc2538bd43e83dfc9ffddad0c60135ad88fc43269022c4ed8657f40ae3a61b9e3&scene=0&xtrack=1#rd",
      "publish_time": 1767793200,
      "publish_date": "2026-01-07",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://blogs.nvidia.com/blog/mixture-of-experts-frontier-models/\", \"https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means\"]",
      "add_ts": 1767914445,
      "last_modify_ts": 1767914445
    },
    {
      "id": 340,
      "article_id": "51690",
      "title": "黄仁勋CES放出大杀器：下一代Rubin架构推理成本降10倍",
      "description": "在CES 2026展会上，英伟达创始人黄仁勋指出，计算行业每10到15年迎来一次革新，当前正经历双重变革：应用将基于AI构建，软件开发方式也随之改变。他强调，人工智能的发展已超越大型语言模型，迈向物理AI与具身智能的新阶段，推动机器人、自动驾驶等领域的突破，构建全新的计算平台生态。",
      "content": "内容来自：机器之心\n编辑：晓楠、杜伟、\n泽南\n「每隔 10 到 15 年，计算行业就会革新一次，每次都会催生出新形态的平台。现在，\n有两个转变在同时进行：应用将会构建于 AI 之上，你构建软件的方式也将改变\n。」\n就在今天凌晨，在拉斯维加斯 CES 2026 展会现场，英伟达创始人黄仁勋身穿经典皮衣现身！\n黄仁勋展示的第一张幻灯片是：「\n人工智能的发展超越了大型语言模型\n。」\n随着大语言模型技术的进步，未来的物理 AI 将可以理解真实世界的结构，独立完成任务，并随着时间的推移进行学习。他表示，\n宇宙中任何存在信息、任何存在结构的地方都可以用来训练人工智能\n。\n老黄分享了下一代加速计算与人工智能将如何变革每一个行业，并一一介绍了英伟达在芯片、人工智能模型、开源开放等领域的最新进展\n，主要包括：\n下一代 Rubin 平台；\n全新的视觉-语言-动作模型（VLA）——Alpamayo 1；\n面向物理 AI 的新开放模型、框架和 AI 基础设施。\n不仅包括新一代 GPU，也有引领业界的开源 AI 模型。可见到了 2026 年，英伟达正准备以全栈的形式引领技术发展。\nRubin 平台问世\n首先，\n最引人关注的是下一代计算架构 ——NVIDIA Rubin 平台\n，刚刚推出的六款全新芯片，目标是构建一台在成本、性能与安全性上全面领先的 AI 超级计算机，加速 AI 在主流场景中的落地。\n这六款芯片包括：\nNVIDIA Vera CPU\nNVIDIA Rubin GPU\nNVIDIA NVLink 6 Switch\nNVIDIA ConnectX-9 SuperNIC\nNVIDIA BlueField-4 DPU\nNVIDIA Spectrum-6 Ethernet Switch\n极致的协同设计，将大幅缩短训练时间，降低推理 Token 成本\n。\n「Rubin 的到来恰逢其时，因为\n训练和推理的 AI 计算需求正在激增\n，」黄仁勋表示，「我们以每年一代 AI 超级计算机的节奏持续前进，而 Rubin 通过六款全新芯片的极致协同设计，向 AI 的下一个前沿迈出了关键一步。」\n据了解，Rubin 平台以美国天文学家 Vera Florence Cooper Rubin 命名，她的研究彻底改变了人类对宇宙的认知。该平台包括 NVIDIA Vera Rubin NVL72 机架级解决方案和 NVIDIA HGX Rubin NVL8 系统。\nRubin 平台引入了五项创新\n，包括最新一代 NVIDIA NVLink 互连技术、Transformer 引擎、机密计算和 RAS 引擎，以及 NVIDIA Vera CPU。\n这些突破将加速智能体 AI、高级推理和大规模混合专家（MoE）模型推理，其每 Token 成本比 NVIDIA Blackwell 平台低高达\n10 倍\n。\n与前代产品相比，NVIDIA Rubin 平台训练 MoE 模型所需的 GPU 数量减少了\n4 倍\n，从而加速了 AI 普及。\n1.专为扩展智能而生\n智能体 AI 和推理模型，以及最先进的视频生成工作负载，正在重新定义计算的极限。多步问题解决需要模型在长序列 Token 中处理、推理和行动。旨在满足复杂 AI 工作负载需求的 Rubin 平台，包含以下五项突破性技术：\n第六代 NVIDIA NVLink\n：提供当今大规模 MoE 模型所需的快速、无缝的 GPU 到 GPU 通信。每个 GPU 提供 3.6TB/s 的带宽，而 Vera Rubin NVL72 机架总带宽高达 260TB/s，比整个互联网的带宽还多。凭借用于加速集体操作的内置网内计算，以及用于增强可维护性和弹性的新功能，NVIDIA NVLink 6 switch 可实现更快、更高效的大规模 AI 训练和推理。\nNVIDIA Vera CPU\n：专为智能体推理设计的 NVIDIA Vera 是大型 AI 工厂中最节能的 CPU，采用 88 个英伟达自研 Olympus 核心，完全兼容 Armv9.2，并具有超快的 NVLink-C2C 连接。Vera 提供卓越的性能、带宽和行业领先的效率，可支持全方位的现代数据中心工作负载。\nNVIDIA Rubin GPU\n：配备具有硬件加速自适应压缩的第三代 Transformer 引擎，Rubin GPU 可为 AI 推理提供 50 petaflops 的 NVFP4 计算能力。\n第三代 NVIDIA 机密计算\n：Vera Rubin NVL72 是首个提供英伟达机密计算的机架级平台，可在 CPU、GPU 和 NVLink 域之间维护数据安全，保护全球最大的专有模型、训练和推理工作负载。\n第二代 RAS 引擎\n：Rubin 平台涵盖 GPU、CPU 和 NVLink，具有实时健康监测、容错和主动维护功能，可最大限度地提高系统生产力。机架的模块化、无线缆设计使组装和维护速度比 Blackwell 快高达 18 倍。\n2.AI 原生存储和安全、软件定义基础设施\nRubin 平台引入了 NVIDIA 推理上下文内存存储平台，这是面向千亿级推理上下文规模（gigascale） 设计的新一代 AI 原生存储架构。\n该平台由 NVIDIA BlueField-4 驱动，可在 AI 基础设施中实现 KV Cache 数据的高效共享和重用，提高响应能力和吞吐量，同时实现可预测、能效友好的智能体 AI 扩展。\nBlueField-4 还引入了高级安全可信资源架构（ASTRA），这是一种系统级信任架构，可为 AI 基础设施构建者提供统一、可信的控制点，以便在不影响性能的情况下安全预置、隔离和操作大规模 AI 环境。\n随着 AI 应用向多轮智能体推理发展，AI 原生组织必须在用户、会话和服务之间管理和共享更多推理上下文。\n3.针对不同工作负载的不同形态\nNVIDIA Vera Rubin NVL72 提供了一个统一、安全的系统，集成了 72 个 NVIDIA Rubin GPU、36 个 NVIDIA Vera CPU、NVIDIA NVLink 6、NVIDIA ConnectX-9 SuperNIC 和 NVIDIA BlueField-4 DPU。\n英伟达还将推出 NVIDIA HGX Rubin NVL8 平台，这是一款服务器主板，可通过 NVLink 连接八个 Rubin GPU，以支持基于 x86 的生成式 AI 平台。HGX Rubin NVL8 平台可加速 AI 和高性能计算工作负载的训练、推理和科学计算。\nNVIDIA DGX SuperPOD 可作为大规模部署基于 Rubin 系统时的参考，它集成了 NVIDIA DGX Vera Rubin NVL72 或 DGX Rubin NVL8 系统，并搭配 NVIDIA BlueField-4 DPU、NVIDIA ConnectX-9 SuperNIC、NVIDIA InfiniBand 网络和 NVIDIA Mission Control 软件。\nNVIDIA Spectrum-6 以太网是下一代 AI 网络以太网，旨在以更高的效率和更强的弹性扩展基于 Rubin 的 AI 工厂，并由 200G SerDes 通信电路、共封装光学器件和 AI 优化结构提供支持。\n基于 Spectrum-6 架构，Spectrum-X 以太网光子共封装光交换系统可为 AI 应用提供 10 倍的可靠性和 5 倍的更长正常运行时间，同时实现 5 倍的更高能效，与传统方法相比，每瓦性能最大化。Spectrum-XGS 以太网技术是 Spectrum-X 以太网平台的一部分，可使相距数百公里甚至更远的设施作为一个统一的 AI 环境运行。\n这些创新共同定义了下一代 NVIDIA Spectrum-X 以太网平台，该平台采用与 Rubin 极致协同设计，旨在实现大规模 AI 工厂，并为未来的百万 GPU 环境铺平道路。\n4.Rubin 准备就绪\nNVIDIA Rubin 已全面投产，基\n于 Rubin 的产品将于 2026 年下半年通过合作伙伴上市\n。\n首批在 2026 年部署基于 Vera Rubin 实例的云服务提供商包括 AWS、Google Cloud、微软和 OCI，以及英伟达云合作伙伴 CoreWeave、Lambda、Nebius 和 Nscale。\nCoreWeave 将与英伟达合作，帮助 AI 领域的先驱者充分利用 Rubin 在推理和 MoE 模型方面的进步，此外，思科、戴尔、HPE、联想和 Supermicro 预计将推出基于 Rubin 产品的服务器。\n包括 Anthropic、Black Forest、Cohere、Cursor、Harvey、Meta、Mistral AI、OpenAI、OpenEvidence、Perplexity、Runway、Thinking Machines Lab 和 xAI 在内的 AI 实验室正在寻求利用 NVIDIA Rubin 平台来训练更大、功能更强大的模型，并以比前几代 GPU 更低的延迟和成本运行长上下文、多模态系统。\nAlpamayo 1 开源模型来了\n英伟达认为，\n下一代面向 L4 的自动驾驶方案，需要基于拥有强推理性能的 VLA 模型\n。\n英伟达今日发布了 NVIDIA Alpamayo 系列开源 AI 模型、仿真工具及数据集，旨在加速下一代安全、基于推理的自动驾驶汽车（AV）开发。\n自动驾驶汽车必须在极其广泛的驾驶条件下安全运行。那些稀少且复杂的场景（通常被称为「长尾问题」），依然是自动驾驶系统安全掌控的最严峻挑战之一。\n传统的自动驾驶架构将感知与规划分离，当遇到全新或异常情况时，这种方式会限制系统的可扩展性。\n虽然端到端学习在近期取得了显著进展，但要克服这些长尾极端案例，仍需要模型能够针对因果关系进行安全推理，尤其是在情况超出模型训练经验时。\nAlpamayo 系列引入了基于思维链推理的视觉语言动作（VLA）模型，为自动驾驶决策带来了类似人类的思考方式。\n这些系统可以分步骤思考新颖或罕见的场景，从而提升驾驶能力和可解释性。可解释性对于增强智能汽车的信任度与安全性至关重要。此外，该系列还得到了英伟达 Halos 安全系统的底层支持。\n黄仁勋表示：\n物理 AI 的 ChatGPT 时刻已经到来，机器开始理解、推理并对现实世界采取行动\n。\n他接着说，Alpamayo 为自动驾驶汽车带来了推理能力，使它们能够思考罕见场景，在复杂环境中安全驾驶，并解释其驾驶决策。这些都是实现安全、可扩展自主驾驶的基石。\nAlpamayo 将三大支柱（开源模型、仿真框架和数据集）整合为一个内聚的开放生态系统，任何汽车开发商或研究团队都可以在此基础上进行开发。\n不过，Alpamayo 模型并非直接在车端运行，而是作为大规模的「教师模型」。开发者可以对其进行微调和蒸馏，转化为各自完整自动驾驶技术栈的核心骨架。\nAlpamayo 1\n：全球首个面向自动驾驶汽车的开源大规模推理视觉-语言-动作（VLA）模型，不\n仅能让车辆深度理解周围环境，还能对其采取的驾驶行为给出合理解释。现已在 Hugging Face 上线。\nAlpamayo 1 采用 100 亿参数架构，通过视频输入生成行驶轨迹及推理痕迹，展示每项决策背后的逻辑。开发者可以将 Alpamayo 1 改编为适合车辆开发的小型运行模型，或将其作为自动驾驶开发工具（如基于推理的评估器和自动标注系统）的基础。\nAlpamayo 1 提供开放的模型权重和开源推理脚本。该系列未来的模型将具备更大的参数量、更详细的推理能力、更灵活的输入输出选项以及商业化用途。\nAlpaSim\n：一个完全开源的端到端高保真自动驾驶开发仿真框架，可在 GitHub 上获取。它\n提供逼真感知的传感器建模、可配置的交通动态以及可扩展的闭环测试环境，能够实现快速验证和策略优化。\n物理 AI 开源数据集\n：英伟达提供了最多样化的大规模自动驾驶开源数据集，包含超过 1700 小时的驾驶数据。这些数据采集自极其广泛的地域和环境，涵盖了对于推进推理架构至关重要的稀有且复杂的现实极端案例。这些数据集现已在 Hugging Face 上线。\n这些工具共同构成了一个自我强化的开发闭环，助力构建基于推理的自动驾驶技术栈。\nAlpamayo 已经得到了自动驾驶行业的广泛支持。包括 Lucid、捷豹路虎（JLR）、Uber 和 Berkeley DeepDrive 在内的出行领军者，都对利用 Alpamayo 开发基于推理的自动驾驶技术栈表示了浓厚兴趣，以实现 L4 级自动驾驶。\n在 Keynote 上，老黄展示了奔驰新款 CLA 在旧金山市区点到点的全自动驾驶，英伟达表示，国内的一些汽车厂商如吉利和小米也会在晚些时候接入英伟达的智能驾驶模型。\n全新物理 AI 模型\n英伟达宣布推出针对物理人工智能（Physical AI）的全新开源模型、框架及 AI 基础设施，并携手全球合作伙伴展示了涵盖各行各业的机器人。\n这些新技术加速了机器人开发全生命周期的工作流，助力开启下一波机器人浪潮，其中包括构建能够快速学习多项任务的通用型专家机器人。\n包括波士顿动力、Caterpillar、Franka Robotics、Humanoid、LG 电子和 NEURA Robotics 在内的全球行业领军企业，正利用英伟达机器人技术栈推出全新的 AI 驱动型机器人。\n黄仁勋表示：\n机器人的「ChatGPT 时刻」已经到来\n。物理 AI 领域的突破 —— 即能够理解现实世界、进行推理并规划行动的模型 —— 正在开启全新的应用场景。\n1.新型开放模型推动机器人学习与推理\n将当今成本高昂、任务单一且编程困难的机器转变为具有推理能力的通用型专家机器人，需要巨大的资本投入和构建基础模型的专业知识。\n英伟达正在构建开源模型，让开发者能够绕过耗费资源的预训练阶段，专注于创造下一代 AI 机器人。这些模型均可在 Hugging Face 上获取，包括：\nNVIDIA Cosmos Transfer 2.5 与 NVIDIA Cosmos Predict 2.5：开源、完全可定制的世界模型，可生成符合物理定律的合成数据，并在模拟环境中对物理 AI 的机器人策略进行评估。\nNVIDIA Cosmos Reason 2：一款开源推理视觉语言模型（VLM），使智能机器能够像人类一样观察、理解并在物理世界中采取行动。\nNVIDIA Isaac GR00T N1.6：一款专为人形机器人设计的开源推理视觉语言动作（VLA）模型，可实现全身控制，并利用 NVIDIA Cosmos Reason 获得更好的推理和情境理解能力。\n2.助力机器人开发的全新开源模拟与计算框架\n可扩展的模拟对于机器人的训练和评估至关重要，但当前的工作流依然零散且难以管理。基准测试通常依赖人工，难以规模化，而端到端流水线则需要在不同的计算资源之间进行复杂的协调。\n英伟达今日在 GitHub 上发布了全新的开源框架，简化了这些复杂的流程，加速了从研究到实际应用场景的转化。\nNVIDIA Isaac Lab-Arena 是一个在 GitHub 上提供的开源框架，为模拟环境中的大规模机器人策略评估和基准测试提供了一个协作系统，其评估层和任务层是与 Lightwheel 紧密合作设计的。它连接了 Libero 和 Robocasa 等行业领先的基准，实现了测试标准化，确保机器人技能在部署到物理硬件之前稳健可靠。\nIsaac Lab-Arena 框架概览\nNVIDIA OSMO 是一款云原生编排框架，将机器人开发统一到一个易于使用的中心控制台中。OSMO 允许开发者在从工作站到混合云实例的不同计算环境中，定义并运行合成数据生成、模型训练及软件在环测试等工作流，从而缩短开发周期。\nOSMO 正在被 Hexagon Robotics 等开发者使用，并已集成到微软 Azure Robotics Accelerator 工具链中。\nOSMO 框架概览\n3.携手 Hugging Face 加速开源物理 AI 发展\n机器人目前是 Hugging Face 上增长最快的类别，英伟达的开源模型和数据集在蓬勃发展的开源社区中下载量遥遥领先。\n为了进一步支持该社区，英伟达正与 Hugging Face 合作，将开源的 Isaac 和 GR00T 技术集成到领先的 LeRobot 开源机器人框架中，提供更便捷的软硬件工具访问，加速端到端开发。\n此次合作将英伟达的 200 万机器人开发者与 Hugging Face 的 1300 万 AI 构建者连接在一起。 GR00T N 系列模型和 Isaac Lab-Arena 现已在 LeRobot 库中上线，方便用户进行微调和评估。\nHugging Face 的开源人形机器人 Reachy 2 将与 NVIDIA Jetson Thor 机器人计算机完全互操作，支持开发者运行包括 GR00T N1.6 在内的任何 VLA 模型。\n此外，Hugging Face 的开源桌面机器人 Reachy Mini 也与 NVIDIA DGX Spark 完全互操作，可利用本地运行的英伟达大语言模型、语音及视觉模型构建自定义体验。\n4.人形机器人开发者采用 NVIDIA Jetson Thor\nNVIDIA Jetson Thor 能够满足人形机器人推理所需的庞大算力。在 CES 上，人形机器人开发者展示了集成 Jetson Thor 的最新顶尖机器人。\n其中，NEURA Robotics 推出了保时捷设计的三代人形机器人，以及一款针对灵巧控制优化的迷你人形机器人。Richtech Robotics 推出了 Dex，这是一款可在复杂工业环境中进行精细操作和导航的移动人形机器人。\n智元机器人（AGIBOT）介绍了面向工业和消费领域的人形机器人，以及集成了 Isaac Sim 的机器人仿真平台 Genie Sim 3.0。\nLG 电子则展示了一款旨在执行多种室内家务的新型家用机器人。 波士顿动力、Humanoid 和 RLWRLD 均已将 Jetson Thor 集成到现有人形机器人中，以增强其导航和操作能力。\n更多细节信息请参考英伟达官方博客。\n参考链接：\nhttps://nvidianews.nvidia.com/news/alpamayo-autonomous-vehicle-development\nhttps://nvidianews.nvidia.com/news/rubin-platform-ai-supercomputer\nhttps://nvidianews.nvidia.com/news/nvidia-releases-new-physical-ai-models-as-global-partners-unveil-next-generation-robots?linkId=100000401170428\nhttps://www.youtube.com/watch?v=0NBILspM4c4&t=3s",
      "article_url": "https://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&mid=2247601772&idx=1&sn=f6e7a62e01af9570ebbf9a4cdecee9a8&chksm=ce2e6f6260de4783640b0d046f20061ace449d487fb6601d495b2c199f407c8509a0b8777282&scene=0&xtrack=1#rd",
      "publish_time": 1767760200,
      "publish_date": "2026-01-07",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://nvidianews.nvidia.com/news/alpamayo-autonomous-vehicle-development\", \"https://nvidianews.nvidia.com/news/rubin-platform-ai-supercomputer\", \"https://nvidianews.nvidia.com/news/nvidia-releases-new-physical-ai-models-as-global-partners-unveil-next-generation-robots?linkId=100000401170428\", \"https://www.youtube.com/watch?v=0NBILspM4c4&t=3s\"]",
      "add_ts": 1767914517,
      "last_modify_ts": 1767914517
    },
    {
      "id": 342,
      "article_id": "51761",
      "title": "训具身模型遇到的很多问题，在数据采集时就已经注定了丨鹿明联席CTO丁琰分享",
      "description": "鹿明机器人联席CTO丁琰在媒体沟通会上指出，具身智能发展瓶颈不在训练阶段，而在于数据采集源头。他强调“只交付100%可复现的轨迹”，批评当前许多团队忽视数据质量，盲目堆算力只会放大错误。丁琰团队聚焦高精度、可复现的数据生成方法UMI，致力于从源头提升数据可靠性，推动具身智能真正落地。",
      "content": "衡宇 发自 凹非寺\n量子位 | 公众号 QbitAI\n“我们只交付100%可以复现的轨迹。”\n具身智能创企鹿明机器人媒体沟通会上，\n联席CTO丁琰\n对具身智能数据采集现状、困境，以及最新兴的采集方式UMI作了前沿的深度分享。\n他在分享中反复强调，很多团队以为具身模型训不出来是卡在训练阶段，实际多数问题在数据生成的起点就已经埋下了。\n后面再堆模型、堆算力，只是在给错误输入继续加速。\n丁琰的履历能解释他为什么会把“数据的可训练性”看得这么重。\n他的研究方向是机器人学与具身智能，2024年3月从美国纽约州立大学计算机学院博士毕业。\n去年年底加入鹿明\n之前，他做过一星机器人的CTO，更早则在上海AI Lab担任研究员。\n按他的说法，从2024年3月起，他就持续投入UMI方向，是大陆最早做UMI方向的人。\nUMI全称叫Universal Manipulation Interface\n，最早来自斯坦福在2024年2月提出的一套工作。\n其核心是用与具体机器人本体解耦的方式，记录人类在真实物理世界中的操作行为，把“操作意图+运动轨迹+多模态感知”统一到一个通用接口里，供不同形态的机器人学习和复现。\n在去年9月之前，UMI还是一个偏冷门的方向。\n具身智能进入下半场后，数据的重要性与日俱增。\n丁琰分享道，前段时间有人归纳了\n具身智能在解决数据难题时的四种解法\n。\n遥操作数据\n，最著名的代表是智元机器人。\n仿真数据\n，代表公司是银河通用机器人。\n人类视频数据\n，它石智能就是这种解法的代表。\nUMI\n，去年9月开始冒头，鹿明就是代表性公司。\n鹿明基于现实需求，做出了一个名为\nFastUMI Pro\n的产品，这是一个无本体数采硬件。\n系统适配市面主流机械臂和夹爪，机身重量在600多克量级，但能夹起两三公斤物品，场景覆盖工厂与家庭。\n它还支持多模态输入，包括触觉、听觉、六维力等。\n在UMI设备最核心的空间精度上，丁琰称FastUMI Pro的1mm是“全球最高精度”。\n硬件产品背后，还有鹿明布局的数据采集、模型训练生态。\n以“可复现”作为第一性原理做数据治理，丁琰带领团队建立了8道工业级数据质量评估体系，并承诺只交付100%可复现轨迹。\n（以下为丁琰分享的关于具身行业数采、UMI等相关内容，在不改变原意的基础上作了编辑调整）\n具身数采的现存痛点\n2024年3月起，我就开始在做UMI，应该是大陆最早做这一块的人。\n大家都知道，具身智能最关键的就是数据，海量的数据是训练的一个必经之路。\n但是数据现在有很多痛点。\n第一个痛点就是成本，成本异常高昂。\n美国那边，为了采集一个小时的训练数据，大概要付出100-200美金的成本。\n现在的具身模型都还很小，PI 0的训练数据大概是1万个小时，Generalist的GEN 0是27万个小时。这个规模对比GPT-3的训练数据，还是非常小的。\n我们做了一个统计，大概相当于7.9亿个小时的数据，才能在具身智能界训出一个GPT-3规模的模型。\n按照现在的市场价格，需要耗费数百亿美金。\n另外，具身数据整体采集效率还是比较低的。\n2023年到2024年左右，业内都是以遥操为主，一个小时大概能采集35条数据，效率异常低，成本也不可控。\n遥操还有个问题是什么呢，就是采集时，因为摄像头记录的是机械臂本身的运动轨迹和画面，但每家机器人长得又都不一样，所以\n用A机器人做遥操作采集的数据是很难很难用到B机器人上\n的，这就产生了数据孤岛问题。\n大家重复造轮子，也会造成高昂的隐形成本。\n这是我们想解决的关键问题所在。\n用UMI数采，你为什么训不出来模型？\n前段时间我写了一篇小红薯，题目叫《你为什么训练不出来UMI的模型？》。\n我想就这次机会\n简单跟大家介绍一下UMI行业的现状\n。大家可能看到的更多的是冰山的一角，但浮在水下面的一个世界还是比较深的。\n一个很明显的现状就是什么呢？\n做UMI的人陆陆续续越来越多，但是训出来模型的异常的少\n，可能一只手都数得过来。\n很多UMI设备涌现出来，大家都会强调自己低成本、能即插即用、快速部署，但是基本上你看不到什么成功的案例，就这个是非常非常有意思的现象。\n国外有两家比较知名的公司，一个叫Sunday，一个叫Generalist，他们还是训出模型了。\n国内目前我们觉得训模型训得比较好的一家就是我们，再有就是清华一家，上交一家，总共也就两、三家能训得出来。\n大多数情况下，要么训不出来，要么即使是在相似的条件下能跑出来demo，时间也非常短，可能就3、4秒，也很卡顿，不丝滑。\n关于为什么大家用UMI采集出来的数据训不出模型，最常见的解释是“算法不是很成熟”“模型不够大”“数据规模不足”，但是其实这些解释都不是真正的原因。\n真正的原因根本不在于训练阶段，而在于训练之初它就不是太对\n——\n大量的UMI数据从生成开始就不具备进入训练管线的这个条件。\n说白了就是数据不合格。\n什么是可以训练的UMI数据\n大家会有误解，总觉得UMI数据就是人拿个夹爪，就把这个视频数据记录下来就行了，非常非常简单，所有人都可以做。\n其实完全不是。\nUMI其实是AI对物理世界的理解对齐，并且在这个物理空间里面可以复现的这种交互行为。\n它必须满足几个条件。\n拆开了讲，\n第一个\n就是说画面要跟动作要严格对齐，要跟空间位置严格对齐；\n另外一个\n就是说因为UMI可以集成多个传感器，每个传感器之间也要做到毫秒级的同步。\n举个例子，一个人想去拿眼前的一瓶水，不对齐的话得反应好几秒，水就可能拿不起来。\n另外，一个好的轨迹必须可以在物理空间运动中可复现的。\n本质要求是希望UMI采集的数据是高一致性的、高密度的，并且可复现的时序数据结构。\n为什么大多数UMI设备采不到好的数据？\n现在大量的UMI设备采不出满足条件的数据，两个根本原因。\n一，核心问题是硬件能力完全不够。\nUMI的CMOS组件或者主控芯片，性能非常差。\n导致的结果就是画面覆盖有限，画质不怎么好，曝光也不怎么好，帧率比较抖动，这时候画面就非常糟糕。\n它破坏了动作和视觉的因果关系。本来模仿学习就是我看到什么画面就做什么动作，结果画面和动作完全无法对齐，就会导致这个模型根本没办法学习。\n二，市面上很多产品不是系统设计的，而是很多现成模块拼凑起来，用USB Hub连接的。\n这样一来，产品的贷款架构非常脆弱，每个模块都会抢带宽。一旦有什么负载，就会出现掉帧等一系列问题，所以数据的质量就非常糟糕，基本没办法稳定复现交互记录。\n也就是说，从硬件层面讲，这些设备从一开始就没办法训出模型需要的数据。\n“脏数据”和“废数据”\n但即使设备好了，采的数据能不能训出数据也不是一定的。\n举个例子，别人拿到我们的设备，也不一定能训出好的数据。\n为什么呢？这就要说数据的质量高低了。\n数据质量的高低其实并不是干净程度，而是说有效的信息密度。\n低质量的数据，包含大量抖动、漂移、时间错位，非常不利于学习。特别是在单视角情况\n（很多UMI是单个机械臂）\n，这种噪声不会因为你的数据量增大而被平滑掉，所以说你学出来的策略会非常非常糟糕，基本上训不出来。\n低价值数据不是完全没有价值。\n它还是有点价值，可以去认识这个世界，知道什么是杯子，什么是麦克风，但\n没办法从它身上学习到精确的物理交互信息\n。\n它不知道桌上的麦克风我是怎么拿到的，我到底该正着拿还是反着拿，还是需要倾斜角度去拿。\n除了低质量的脏数据，我还把一种数据叫“废数据”。\n废数据是什么？\n就是很多人拿着设备直接去众包去采集了，人怎么采就拿它怎么采。\n这种数据完全copy人类的自然行为，没有任何设计和技巧，过于“天然去雕饰”了，基本上是不可能训出来模型的。\n现在都在做的叠衣服，其实是最需要采集技巧的一个任务。叠衣服的时候要抖一下，抖的过程中还要注意方向、速度，才能抖好。\n但人在叠衣服的时候，很少会注意那么多tricks。\n每家具身公司都有自己的采集技巧，所以如果没有注入任何技巧，即便拿到很好的UMI设备，采集的数据很像人的行为，但其实是废数据，基本上模型训练不了。\n能当然可能未来，十年、二十年，模型发展好了，这些数据可能就有用了。但目前很长一段阶段这些数据基本上训不了，所以称为废数据。\n硬件、数据和算法环环相扣\n正确的UMI的工程范式首先是一种系统的自洽，而不是一种简单的功能拼接。\n传统的路径下面大家做机器人，首先有个硬件，硬件弄完了之后再弄软件，弄完软件我再弄算法，我反过头来我再去补点数据，把这个整个loop给跑通。\n但\n在UMI这个很特殊的场景下，这个范式是失效的。\n因为UMI是一个强耦合系统，数据会决定整个模型的性能，硬件会决定这个数据的质量；数据又会决定这个算法的性能，算法又会反向去约束我这个硬件的执行和这个数据的设计。\n硬件、数据和算法环环相扣，任何单点的这种失效都会导致训不出优秀的模型。\n关于UMI，团队做了什么\n博士毕业后，我从2024年3月就开始在做面向UMI的工作。\n去年9月之前，UMI在行业里还是比较冷门的，除了我和我的团队基本没人做。\n当时我们就有一个愿景，希望能打破这个数据获取的这个不可能的三角，把非常高质量的数据砍到白菜价，加速应用来推进这个整个具身智能行业的发展。\n这里跟大家分享我和团队近两年的一些典型工作。\n首先就是FastUMI\n，我是这篇工作的通讯作者。\nFastUMI应该是全球首个将学术界\n（UMI，斯坦福，2024年2月）\n的工作升级成工业级别系统，然后推进它进入工业的。我们从2024年3月左右开始做这个工作，在7、8月左右完成，当年的9月中了CoRL 2025。\nFastUMI主要解决的问题是提高采集效率和数据质量。\n另外一个工作是FastUMI 100K\n。\n在有了一个很稳定的软硬件系统后，我们开始扩大规模去采数据。当时我在上海AI Lab建立了一个数采长，我带着11个人在3个月时间里，采集了10万条真机数据，为机器学习提供了非常高质量的数据支持。\n这是全世界首个大型的UMI数据集。\n从这个工作中FastUMI团队获得了大规模的数据治理的经验。\n我们\n还有一个工作叫Fastumi-MLM\n，它把UMI这项技术用于“狗+臂”。\n之前UMI都应用在单臂、双臂或者轮式双臂工作上。这是大陆第一个能将UMI用在这种构型机器人上的工作。\n除此之外，还有Spatial VLA、Agibot World、AskVLA等等。\n—\n欢迎AI产品从业者共建\n—\n📚\n「AI产品知识库」\n是量子位智库基于长期产品库追踪和用户行为数据推出的飞书知识库，旨在成为AI行业从业者、投资者、研究者的核心信息枢纽与决策支持平台。\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860589&idx=2&sn=e4430896faaecf66f5df6043b2057e28&chksm=e99c21381c9a05346b469f4ceef7429df2fafb638884dc2323e59e6e1bd3164c7abf5c3e4751&scene=0&xtrack=1#rd",
      "publish_time": 1767963000,
      "publish_date": "2026-01-09 20:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768000750,
      "last_modify_ts": 1768087143
    },
    {
      "id": 343,
      "article_id": "51760",
      "title": "Transformer已死？DeepMind正在押注另一条AGI路线",
      "description": "谷歌团队提出“嵌套学习”新范式，借鉴人类联想记忆机制，使AI在运行中自主构建抽象结构，突破Transformer架构局限。论文强调优化器与模型架构应协同进化，互为上下文，推动AI实现真正的持续学习。该方法有望彻底解决长期困扰AI界的“灾难性遗忘”问题，标志AI从被动训练迈向主动进化的新阶段，或将成为领域经典之作。",
      "content": "新智元报道\n编辑：KingHZ\n【新智元导读】\n借鉴人类联想记忆，嵌套学习让AI在运行中构建抽象结构，超越Transformer的局限。谷歌团队强调：优化器与架构互为上下文，协同进化才能实现真正持续学习。这篇论文或成经典，开启AI从被动训练到主动进化的大门。\n「灾难性遗忘」，一个困扰了AI界几十年的幽灵，这一次或许被彻底解决了。\n过去一年，AI突飞猛进，绝非夸张的修辞，仅谷歌DeepMind一年的成就，就让人眼花缭乱：\n但如果DeepMind要选2025年最重要的研究或产品，那最近火爆的嵌套学习\n「Nested Learning」\n必有一席之地。\n有网友读过论文之后，发帖表示，这篇论文就是《Attention is All you Need》的「续集」。\n如果Transformer开启了Scaling时代，那么嵌套学习，可能正在开启真正的AGI时代。\nDeepMind创始人Shane Legg更直接，AGI一路坦途，最新进展就是嵌套学习。\n甚至有网友表示，如果要给未来的外星人留一篇论文，必然是这篇《\n嵌套学习\n》。\n上下滑动查看\n如果实现AGI需要2-3项突破，持续学习可能就是其中之一，而谷歌已发表了多篇相关论文。\n然而，这些论文有一个共同的作者──\n康奈尔大学计算机科学系二年级博士生、谷歌研究院（纽约）研究实习生Ali Behrouz。\nTransformer的记忆之殇\n在多方面，Transformer表现出色，能够Scaling、推动AI跨越，能实现跨任务、跨领域的泛化能力。\n但谷歌很早就意识到一件事：\nTransformer并不完美。\n1.\n长上下文处理效率低\n2. 抽象知识层级有限\n3. 适应性弱\n4. 缺乏持续学习能力\n特别是第四点，Ali认为那是\n最关键\n的问题。\n当提到「持续学习」（Continual Learning），我们指的是：\n没有训练期，也没有测试期；\n模型在使用过程中，持续塑造新的记忆和抽象结构。\n人类天生如此。\n但对今天的大语言模型来说，\n几乎不存在任何「持续学习」。\n为了说明问题有多本质，Ali用了一个医学上的类比：\n顺行性遗忘症（Anterograde Amnesia）。\n这种病的患者有一个非常诡异的特征：\n他们的\n短期记忆是正常的\n他们的\n长期记忆也还在\n但问题在于： 👉\n短期记忆，无法转移为长期记忆。\n于是，他们永远活在「现在」。\n新的经历进来，过一会儿就消失； 世界在变，但他们的大脑\n不再更新\n。\n现在，把这个病，套到LLM身上。\n你会发现，大模型和人类患者\n一模一样。\n今天的大语言模型，知识主要来自两部分：\n预训练阶段学到的长期知识、\n当前上下文里的短期信息。\n但这两者之间，\n几乎完全没有通道\n。\nAI模型无法自然地把「刚刚学到的东西」，沉淀为未来可复用的知识。\n想让它真的学会？\n你只能：再烧钱、再训练、再微调。\n这和顺行性遗忘症患者的状态，本质上没有区别。\n真正的问题不是参数不够多，不是数据不够大，也不只是算力不够。\n问题的本质在于\n「短期记忆」和「长期记忆」之间，\n根本没有一条自然的知识转移通道\n。\n如果这条通道不存在，所谓「持续学习」，就永远只是一个口号。\n这引出了一个核心问题：\n我们该如何构建一种机制，让\nAI\n模型像人类一样，将「现在」的经历沉淀为「未来」的知识？\n一切AI皆是「联想记忆」\n如果想让AI真正具备持续学习能力，那你绕不开一个最底层的问题：\n模型到底是「怎么记住东西的」？\nAli给出的答案，不是Transformer，不是参数量，而是一个更原始、更根本的概念：\n联想记忆（Associative Memory）\n。\n所谓「联想记忆」，是人类学习机制的基石。\n它的本质，是通过经验将不同的事件或信息相互关联。\n比如，你看到一张脸，马上想起一个名字；你闻到某个味道，唤起一段记忆。\n这不是逻辑推理，而是\n关联的建立\n。\n技术上，联想记忆就是键值对映射：\nKey：线索\nValue：与之关联的内容\n但关键在于，联想记忆的\n映射关系不是预先写死的，而是「学出来的」。\n从某种角度来看，\n注意力机制本质上就是一种联想记忆系统：\n它学习如何从当前上下文中提取key，并将其映射到最合适的value，从而产生输出。\n如果我们不仅优化这种映射本身，还让系统去\n元学习\n（meta-learn）这种映射过程的初始状态\n，会发生什么？\n基于对联想记忆的理解，他们提出了一个通用框架，名为MIRAS，用于系统化地设计AI模型中的记忆模块。\n这一框架的核心思想是：\n几乎所有注意力机制、本地记忆结构，乃至优化器本身，其实都可以视为联想记忆的特例。\n为了设计一套「可学习的、嵌套式的记忆系统」，我们需要对模型中的记忆结构做出四大设计决策：\n记忆架构（Memory Architecture）\n注意力偏置/目标函数（Attentional Bias/Objective）\n保留机制（Retention Gate）\n学习规则（Learning Rule）\n这个框架可以用来\n统一解释\n许多已有的注意力机制与优化器\n。\n简单来说：MIRAS\n让我们能够把「记忆」作为一种学习过程进行建模、组合与优化\n，而不仅仅是一个静态模块。\n更进一步，优化器也可以被统一视为「将当前梯度映射到历史信息」的联想过程，就可以对它们进行重新建模与推广。\n优化器就是一种「记忆模块」，是模型理解其学习历史、进而做出更优决策的关键组件。\n优化过程与学习算法/架构本质上是相同的概念，只是处于系统不同层级中具有不同的上下文（即梯度与数据）。\n此外，它们是两个相互连接的组件，其中学习算法/架构为优化器生成上下文（即梯度）。这支持为特定架构设计专属优化器的理念。\n由此，谷歌的团队探讨了不同层级之间的知识传递方式，提出了嵌套学习。\n嵌套学习\n专治LLM失忆症\n基于NL的观点，谷歌团队使用反向传播和梯度下降训练深度神经网络，本质上是一个压缩与优化问题，其目标是训练一种联想记忆（associative memory），以将各层的输入映射到其预测中对应的局部误差。\n相应地，他们认为预训练是一种上下文内学习形式，其中上下文是全部预训练数据，而各网络层则将该上下文压缩进其参数之中。而其他流行的基于梯度的优化器，本质上也是旨在将梯度压缩进其参数中的联想记忆。\n优化器与架构并不是彼此独立的，它们应该互为上下文、协同进化。\n为了正式定义\nNested Learning（嵌套学习）\n框架，需要了解两个核心概念：\n更新频率（Update Frequency）\n与\n嵌套系统（Nested System）\n。\n一、更新频率\n首先设定一个时间单位，通常取系统中\n更新最慢的模块的一次更新\n作为基本时间单位。\n然后，对于系统中其他组件，我们统计它们在一个时间单位内更新了多少次，就得到了它们的「更新频率」。\n举个例子：\n假设循环神经网络（RNN），上下文长度为(L)，那么在处理一段长度为(L)的文本时，RNN的状态会更新(L)次；\n而如果外层是一个只在每个文档级别上更新的模块（如预训练模型），那么它的更新频率就是1。\n因此，我们可以说：\nRNN\n是「快模块」，\n预训练模型\n是「慢模块」。\n通过这种不同频率的组合，我们就能构建出一个在不同时间尺度上都能学习的系统。\n二、嵌套系统（Nested System）\n接下来，我们定义什么是一个「嵌套系统」。\n它由多个\n独立的子模块组成\n，每个模块都有：\n自己的参数（Parameter）；\n自己的上下文（Context）；\n自己的优化目标（Objective）；\n自己的梯度流（Gradient Flow）。\n这些模块之间以「更新频率」的快慢形成嵌套关系。\n如果我们把每个子模块都视为一个联想记忆系统，那么整个模型就可以看作是一个\n嵌套的联想记忆系统（Nested Associative Memory System）\n。\n更进一步，每一个这样的联想系统，本身又可以由更小的优化子过程构成，从而形成递归嵌套。\n当构建了一个由多个层级组成的嵌套系统之后，最关键的问题就来了：\n不同层之间的知识要如何传递？\n知识转移方式有以下几种，这些机制构成了Nested Learning架构中「信息流动」的基础：\n直接条件传递（Direct Conditioning）\n：\n慢层（外层）模型的输出直接作为快层（内层）模型的输入条件\n非参数化条件传\n递：不依赖额外参数，\n模型的输出直接依赖于上下文本身\n。虽然没有显式参数连接，但输出依然受到内层状态的强烈影响。\n通过反向传播传递（Gradient-Based Transfer）\n：\n梯度本身就构成了知识的传递路径\n——高层对目标的判断，反向指导底层如何调整参数。\n初始状态传递（Meta-Learned Initialization）\n：慢层模型\n生成快层模型的初始状态\n。外层学习一个初始化点，使得内层可以通过少量更新迅速适应新任务。\n权重生成（Hypernetwork）\n：慢层模型\n直接生成快层模型的参数\n。这就是超网络（Hypernetwork）的本质。\n理论固然重要，但最终还是要看这些设计能否在真实任务中带来性能提升。\n结合自我修改（Self-Modifying）与连续记忆系统（Continuum Memory System），谷歌提出了嵌套学习范式下的HOPE架构。\n他们将Nested Learning与HOPE架构应用于多个任务场景中，尤其聚焦在「长上下文」和「持续学习」两个维度。\n总体来看，HOPE在多个核心任务上都优于或显著超越现有对比模型\n，尤其是在持续学习和长上下文方面显示了明显优势。这体现了嵌套学习和连续记忆系统的潜力。\n上下滑动查看\n这到底意味着什么？\nNested Learning不只是一个架构框架，而是一种\n重新理解\n深度学习\n的范式\n。\n谷歌DeepMind内部也传出消息：他们已经突破了持续学习，但因为安全原因尚未发布。\n如果嵌套学习解决了持续学习能力，或许将是未来最重要的事。\nDeepMind的沉默，或许比他们的论文更震耳欲聋。\n持续学习赋予了AI可怕的能力：它不再仅仅回应我们的指令，而是开始根据过往的经验，筛选它认为重要的东西。也就是说，它开始有了「偏好」。\n如果嵌套学习真的解决了灾难性遗忘，那么我们亲手打开的，可能不只是一扇通往AGI的大门，更是一个未知的潘多拉魔盒。\n盒子里的东西，究竟是更聪明的工具，还是一个不仅学会了思考、更学会了「记住仇恨与偏爱」的对手？\n这一次，钥匙在谷歌手中，但未来在谁手中？\n参考资料：\nhttps://www.youtube.com/watch?v=3WqZIja7kdA\nhttps://www.youtube.com/watch?v=uX12aCdni9Q\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652662976&idx=1&sn=1bcbb153cb6dc4b9f92aa413bf18cc23&chksm=f00cb0fc582699b1ef44fdf18a2d3d40f11bb4602c826ca88de7f875fe7abb8fcef10f4d45f6&scene=0&xtrack=1#rd",
      "publish_time": 1767963000,
      "publish_date": "2026-01-09 20:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.youtube.com/watch?v=3WqZIja7kdA\", \"https://www.youtube.com/watch?v=uX12aCdni9Q\"]",
      "add_ts": 1768000755,
      "last_modify_ts": 1768087146
    },
    {
      "id": 344,
      "article_id": "51759",
      "title": "智源研究院发布2026十大AI技术趋势",
      "description": "2025年，人工智能正从依赖参数规模的语言模型转向理解物理世界底层规律的新范式，实现从“生成符号”到“理解现实”的跨越。2026年1月8日，智源研究院发布“2026十大AI技术趋势”，系统梳理技术演进路径，聚焦行业共识与关键突破点，揭示AI在感知、推理、交互等方面的前沿方向，重塑产业逻辑，推动具备现实理解和推演能力的下一代AI发展。",
      "content": "2025年，人工智能行业正处在一次关键的范式转折点。\n技术重心正从以参数规模为核心的语言学习，转向对物理世界底层秩序的理解、建模与推演——AI开始从“生成符号”走向“理解现实”，行业底层逻辑随之重塑。\n2026年1月8日，智源研究院举办研讨会并发布“2026十大AI技术趋势”，沿着技术演进的真实轨迹，梳理正在成形的共识与分歧，寻找AI技术领域可被验证的关键锚点。\n扫码或点击“阅读原文”下载报告全文\n阅 读 更 多",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI2MDcxMzQzOA==&mid=2247548699&idx=1&sn=70ce3e26990097f5988b363c186791fd&chksm=eb5d7455642a6548defe1d640529ad6b1f13043848c419c8fad97d2148446d3bf61318cd0a16&scene=0&xtrack=1#rd",
      "publish_time": 1767961200,
      "publish_date": "2026-01-09 20:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768000759,
      "last_modify_ts": 1768087152
    },
    {
      "id": 345,
      "article_id": "51758",
      "title": "开源“裸考”真实世界，国产具身智能基座模型拿下全球第二！",
      "description": "国产具身智能模型WALL-OSS在RoboChallenge真机评测中以46.43分位列全球第二，超越美国公司Physical Intelligence的π0。该模型由自变量机器人研发，在叠洗碗巾、挂口杯、按按钮、浇盆栽、移物入盒、开瓶器进抽屉等多个任务中表现优异，展现强大端到端操作能力，标志着中国具身智能基座模型实现重要突破。",
      "content": "嘻疯 发自 凹非寺\n量子位 | 公众号 QbitAI\n国产具身智能基座模型，再次突破！\nRoboChallenge真机评测榜单上，来自\n自变\n量机器人的\n端到端具身智能基础模型WALL-OSS\n，以总分54.69、成功率35.33%的成绩，超越美国具身智能明星公司Physical Intelligence的pi0\n（π0）\n，\n排名\n全球第二\n。\n在叠洗碗巾、挂口杯、按按钮、浇盆栽、移物入盒、开瓶器进抽屉等\n多个单任务中，\nWAL\nL-OSS均拿下\n单项第一\n。\n要知道，这可不是一场普通的测试。\nRoboChallenge由Dexmal原力灵机联合Hugging Face发起，是首个在\n真实物理环境\n中，由真实机器人执行操作的大规模、多任务基准测试。\n与LLM测评不同，具身模型测评更像是一场“\n开卷考\n”，任务描述和场景环境都是提前公开的。\n参赛方无需提交模型权重，只需提供可驱动机器人的算法；最终，平台通过统一的真机执行，以动作视频和任务完成率作为评分依据。\n格外关键的是，\nWALL-OSS是一个开源模型\n。\n相较于闭源模型的测评结果存在较大操作空间\n（其性能可能源于对第三方模型的微调、\n接口层的特殊\n适配，或者存在黑箱内的未公开优化）\n，模型本身的原生能力不容易被外界验证，开源模型的成绩建立在完全透明的代码与参数之上，\n其能力可被任何研究者复现、检验和深入研究\n。\n而且，WALL-OSS的开源程度也相当彻底：不仅开放了预训练模型权重、完整训练代码和数据集接口，甚至还提供了详尽的部署文档。\n仅需RTX 4090级别的消费\n级显卡\n，就可以完成从训练到推理部署的完整流程。\n另外，当前榜单前三名，包括\npi0、pi0.5，也都是来自开源体系\n。\n具身智能的前沿发展，正在由开源模型共同推动向前\n。\n“机器人脑”物理世界大PK\n下面先具体来看WALL-OSS在测试中的实际表现。\nRoboChallenge首发的Table 30任务集，包含30个真实日常操作任务，而在行业常见的真机评测中，任务数量通常只有3–5个。\n该任务集从四个维度构建评估体系：VLA方案难点、机器人类型、任务场景环境、目标物体属性，覆盖了具身模型在真实世界中可能遇到的多样复杂情况。\n以难度较高的“叠抹布”任务为例，WALL-OSS目前位列该单项第一。\n在该任务中，WALL-OSS以41分的成绩领先pi0。尽管其任务成功率仍只有10%，但已是当前所有参赛模型中的最优表现；相比之下，pi0在该任务中的成功率为0%，仅获得部分步骤分。\nRoboChallenge平台集成了UR5、Franka Panda、Aloha、ARX-5等多款主流机器人，用于远程真机评测。\n并且，其\n公开了\n所有\n任务演示\n数\n据及测试中间结果\n，所有人都能看到机器人执行任务的全过程监控记录。\n打开任务执行详情，可以看到左侧上方是多视角视频画面，展示了任务现场的实际场景，\n能直观看到机器人的操作过程\n。\n右侧上方的arm图表，记录了机械臂6个关节\n（joint1–joint6）\n的角度变化，曲线波动对应关节运动；右侧下方的arm_gripper图表，则记录了夹爪的开合状态。\n最右侧信息栏则展示任务ID、执行时长等基础信息。\n底部时间轴可以精准定位某一时刻，同步查看该时间点的视频画面与机械臂/夹爪状态，快速找到动作异常的环节。\n从公开视频中可以看到，WALL-OSS成功完成了抹布的一次抓取与对折操作：\n在相对简单一些的“连续按下三个按钮”任务中，WALL-OSS的优势更加明显，得分显著领先其它模型。\n实际操作be like\n（以下展示均为加速画面）\n：\n在“将不同形状杂物收纳至筐中”的任务里，WALL-OSS同样表现稳定：\n该任务中，无论是得分还是成功率，WALL-OSS都高于pi0。\n在“拉开抽屉并放入杂物”等需要连续规划与空间判断的任务中，也能看到其完整完成操作流程：\n值得一提的是，RoboChallenge的真机测试规则本身并未限制模型进行针对性优化或微调。开发者可以使用官方提供的任务示范数据对模型进行训练。\n模型训练完成后，需对接平台标准化API。平台提供统一的框架代码，参赛方仅需补充自身逻辑，确保模型实现观察-推理-停止的完整交互闭环，并可通过模拟测试进行验证。\n评估请求进入人工调度队列后，任务将在真实场景中执行，最终结果由平台自动发布。\n也正是在这样的规则下，开源模型的成绩，含金量才显得尤为突出。\n目前，自变量团队已表示，\nWA\nLL-OS\nS提交\n的复现结果示例，微调代码和模型权重也将在近期全部开源\n。除检验测试结果的真实性，开发者们也可以在平台上根据源代码和各个任务的微调代码，结合自己的数据完成复现微调。\n接下来问题来了，WALL-OSS是如何做到的？\n拆解背后技术突破\n在模型的具体实现层面，官方已发布技术报告，对WALL-OSS的设计思路与训练路径进行了系统披露。\n从视觉语言模型\n（VLM）\n走向视觉语言动作模型\n（VLA）\n，并不是一次简单的能力叠加。\n在这一迁移过程中，行业普遍面临两大核心挑战：\n其一是\n灾难性\n遗\n忘\n。VLM在向动作生成扩展时，往往会牺牲原有的语言理解与视觉推理能力，导致模型“会动了，却不再真正理解任务”。\n其二是\n模态解耦\n。不少模型虽然表面上同时具备视觉、语言与动作模块，但各模态之间协同不足，推理、规划与执行往往割裂存在，难以形成真正端到端的决策闭环。\n这也直接导致了一个现实困境：认知能力强的模型，动作精度往往不足；而动作控制表现稳定的模型，又难以承担复杂任务的理解与规划。\n如何在模态统一、动作精度和能力泛化之间达成平衡？\n是VLA模型设计中最具挑战性的问题之一。\n针对上述问题，WALL-OSS首先在模型架构层面进行了重构。\n不同于传统多模态模型常见的“模块拼接”方案，WALL-OSS采用了\n共享注意力+专家分流\n（FFN）\n的架构设计。语言、视觉与动作信息被嵌入到同一表示空间中，通过共享注意力机制实现深度跨模态交互；同时，再借助专家FFN对不同任务需求进行高效分流计算。\n最终，模型得以在统一框架下同时承担理解、规划与动作生成任务，形成紧耦合的认知—行动闭环。\n在训练策略上，WALL-OSS设计了\n“\n启发\n阶段\n（Inspiration）\n→整合阶段\n（Integration）\n”的阶段式范式\n。\n启发阶段通过具身VQA、指令跟随等任务强化空间推理，结合FAST tokenization离散动作训练，让模型保留原有认知能力的同时，建立空间与动作基础认知。\n随后，整合阶段聚焦连续动作建模，先冻结VLM仅训练Action FFN下的流匹配\n（Flow Matching）\n头，精修高频动作生成。\n最终，解冻VLM联合优化，将认知能力与动作执行能力在同一模型中稳定整合。\n这种“\n先离散、后连续、再联合\n”的训练路径，让VLM的语言视觉能力能够无损地迁移并扩展到物理动作层面，避免了传统端到端训练中常见的能力塌缩问题。\n结果是，模型既保留了懂任务的认知深度，又具备了会执行的动作精度。\n在此基础上，WALL-OSS进一步将思维链\n（Chain-of-Thought）\n能力内化到具身决策过程中。\nWALL-OSS构建了一套\n统一的跨层级思维链框架\n：从指令理解，到中间推理，再到子任务拆解与规划，最终映射为连续的物理动作执行。\n这一机制使模型能够在高层语义决策与底层动作控制之间自由切换，在同一可微分框架内完成跨抽象层级的推理与执行。\n因此，在面对未知环境或从未见过的任务组合时，WALL-OSS不再依赖预设流程，而是能够自主拆解问题、逐步思考，并在执行过程中动态调整策略，从而具备了承担长程、复杂具身任务的能力。\n实验结果显示，在Embodied VQA基准测试及6类机器人操作任务中，WALL-OSS均表现突出。\n开源破壁，真正推动具身智能发展的路径\n最后再来介绍一下WALL-OSS背后的团队——\n自变量机器人\n。\n这是一家成立时间不长、但在具身智能领域推进速度极快的明星公司。核心团队长期深耕机器人与多模态智能方向，并明确将“通用具身智能基座”作为长期目标。\n创始人兼CEO王潜\n，本硕毕业于清华大学，后在美国南加州大学攻读博士，从事Robotics Learning相关研究。他在神经网络注意力机制相关研究领域较早开展探索，是较早将Attention思想引入神经网络体系的研究者之一。\n联合创始人兼CTO王昊\n，为北京大学计算物理博士，曾任职于粤港澳大湾区数字经济研究院\n（IDEA研究院）\n，担任大模型团队负责人，曾带领团队发布过多个开源大模型，在基础模型与系统工程层面具备深厚积累。\n目前团队已完成多轮融资。几个月前，刚宣布了\n近10亿元A+轮融资\n，\n阿里云、国科投资领投，国开金融、红杉、渶策、美团、联想之星、君联资本均有参与。\n相比单一场景或垂直应用，自变量团队更关注\n如何构建一个可以被反复验证、持续演化\n的“机器\n人通用大脑”\n。\n也正因为如此，WALL-OSS从一开始就被定位为面向真实物理世界、端到端统一的基座模型，而不是为某个Demo、某个任务定制优化的解法。\n如果仅从榜单成绩来看，WALL-OSS已经足够亮眼。但真正值得被反复讨论的，并不是名次本身，而是它选择\n以开源的方式，参与真实物理世界的能力验证\n。\n在RoboChallenge这样的第三方测评中，WALL-OSS的表现很难被简单归因为调参、特化或运气好。它更像一次赤裸而直接的证明：\n一个开源的、可复现的具身基础模型，确实可以在真实世界任务中具备很强的竞争力\n。\n而把视角拉远一步，长期以来，具身智能领域一直存在一个结构性矛盾：\n真正有想法、有算法能力的高校与中小团队，往往缺算力、缺数据、缺机器人；而具备资源的大公司，又很难把底层能力完全开放出来，供行业共同验证和改进。\n在这样的背景下，一个可以在消费级显卡上完成训练、推理和部署的开源具身模型，在行业中的意义就不仅是共享成果，而是弥补了行业空白，实质性地\n降低整个行\n业的创\n新门槛\n。\n研究者不必从零构建，创业团队不必重复造轮子，更多精力可以投入到真正有价值的问题上，比如：如何提升泛化能力？处理更长程、更复杂的任务？如何让机器人在不可控环境中更可靠地工作？\n这正是开源生态最理想的状态，不是把精力消耗在基础设施的重复建设上，而是\n在同一个高起点上竞争真正的创新\n。\n正如自变量机器人联合创始人&CTO王昊曾在硅谷101播客中所说：\n我一直都觉得开源是非常重要的事情，\n开源意味着我们可以站在巨人的肩膀上继续前进\n。我们可以基于已有成果做更多的改进，社区开发者的反馈也会帮助到开源的公司，开源公司可以从中吸取到经验，然后把这个技术路线思考得更加深入。\n而对自变量自身而言，选择开源同样不是一笔短期收益最大化的生意。\n在多次访谈中，自变量团队反复强调，他们并不把开源视为一次技术展示或品牌露出，而是将其视为一种\n“行业\n基础设施\n”的长期投入\n。\n他们更关心的是，这个模型是否足够先进，足够稀缺，从而足够有资格成为“基座”；或者模型又能否真的能被社区用起来，经得起复现、质疑和改造，在真实世界的任务中不断暴露问题，最终通过生态的反向推动，从而完成自我迭代与进化。\n在具身智能这样一个高度依赖真实世界反馈的领域，\n没有什么比开源社区的持续检验更残酷、也更\n有\n效\n。\n社区会放大模型的优点，也会毫不留情地揭示它的短板。而正是这种持续地被使用、被对抗、被改造，才有可能推动模型真正走向成熟。\n从这个角度看，WALL-OSS的开源，本质上是一种姿态——\n愿意把模型交给世界，用真实应用来检验技术路线是否成立\n。\n具身智能的长期发展中，拥抱开源，或许不是理想主义，而是一条绕不开的现实路径。\n至少，WALL-OSS已经用一次真实世界的大考，给出了一个有分量的示范答案。\n最后话说回来，以后打榜是不是要给开源和闭源搞个分赛道？裸奔的，和穿着绒裤、棉裤、毛裤、秋裤、打底裤的相比，到底是不一样。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860588&idx=1&sn=492229c9fb2ee30842ab84f375601d48&chksm=e9f762ad729d7b9bfa84912d323f23fce929f0cc9a41dadc2507d9d8dfa948d7cab355cbdb73&scene=0&xtrack=1#rd",
      "publish_time": 1767961200,
      "publish_date": "2026-01-09 20:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768000765,
      "last_modify_ts": 1768087155
    },
    {
      "id": 347,
      "article_id": "51756",
      "title": "智元首发SOP系统：打破离线训练瓶颈，让具身智能在“干中学”",
      "description": "智元机器人首席科学家罗剑岚博士指出，随着VLA等大模型赋予机器人通用能力，2025年机器人发展的关键已转向真实环境中的持续进化。尽管预训练使机器人具备初步通用性，但在开放、复杂场景中实现长期稳定高效作业仍是挑战。未来重点在于部署后的自主学习与适应能力，推动机器人从实验室走向实际应用，实现真正落地。",
      "content": "智元机器人 投稿\n量子位 | 公众号 QbitAI\n当通用能力主要通过大规模预训练获得之后，下一阶段的关键在于让已经具备通用能力的模型，在真实部署环境中持续进化。\n这是智元机器人首席科学家\n罗剑岚\n博士在接受量子位采访时给出的论断。\n2025年机器人领域最火的VLA让机器人通过预训练具备了相当的通用性，但与此同时，机器人能否长时间，稳定，高效地完成任务仍是一个问号。\n基于此，当机器人走出实验室，走向开放、复杂且持续变化的真实世界时，一个更核心的问题随之出现：如何真正实现通用机器人的规模化部署与智能化运行。\n为此，智元机器人具身研究中心提出\nSOP（ScalableOnlinePost-training）\n——一套面向真实世界部署的\n在线后训练系统\n。\n这是业界首次在物理世界的VLA后训练中，\n系统性地融合在线学习、分布式架构与多任务通才性\n，使机器人集群能够在真实环境中持续进化，让个体经验在群体中高效复用，从而将“规模”转化为“智能”。\n真实世界中的规模化智能增长挑战\n要在真实世界中大规模运行，通用机器人必须同时满足两个看似矛盾的要求：\n在复杂多变的环境中保持\n稳定性与可靠性\n。\n在处理差异巨大的任务时，仍具备良好的\n泛化能力\n。\n现有VLA预训练模型已经提供了强大的通用性。但\n真实世界的部署受困于更高的任务专精度要求，以及离线数据采集方式的边际效益递减\n，往往需要通过后训练获得更高的任务成功率。\n遗憾的是，当前主流的VLA后训练方法仍受\n离线、单机、串行采集等因素制约\n，难以支撑高效、持续的真实世界学习。\n这些限制并非源自具体算法，而是来自\n学习范式本身\n。\nSOP：分布式在线后训练框架\nSOP的核心目标，是让机器人在真实世界中实现\n分布式、持续的在线学习\n。研究将VLA后训练从“离线、单机、顺序”重构为“\n在线、集群、并行\n”，形成一个低延迟的闭环系统：多机器人并行执行→云端集中在线更新→模型参数即时回流。\nSOP架构设计\n△\nSOP架构设计图\nSOP采用Actor–Learner异步架构：\nActor（机器人侧）并行经验采集\n多台部署了同一policy模型的机器人（actors）在不同地点同时执行多样任务，持续采集成功、失败以及人类接管产生的交互数据。每台机器人的经验数据被汇总传输至云端Experience Buffer中。\nLearner（云端）在线学习\n所有交互轨迹实时上传至云端learner，形成由在线数据与离线专家示教数据组成的数据池。系统通过\n动态重采样策略\n，根据不同任务的性能表现，自适应调整在线/离线数据比例，以更高效地利用真实世界经验。\n即时参数同步\n更新后的模型参数在分钟级别内同步回所有机器人，实现集群一致进化，维持在线训练的稳定性。\nSOP本身是一套通用的框架，可以即插即用的使用任意后训练算法，让VLA从在线经验数据中获益。\n研究选取HG-DAgger（交互式模仿学习）与RECAP（离线强化学习）作为代表性算法，将其接入SOP框架以进化为分布式在线训练。\n关键优势\n高效状态空间探索：分布式多机器人并行探索，显著提升状态–动作覆盖率，避免单机在线学习的局限。\n缓解分布偏移：所有机器人始终基于低延迟的最新策略进行推理采集，提升在线训练的稳定性与一致性。\n在提升性能的同时保留泛化能力：传统的单机在线训练往往会使模型退化为只擅长单一任务的“专家”，SOP通过空间上的并行而非时间上的串行，在提升任务性能的同时保留VLA的通用能力，避免退化为单任务专家。\n实验评估：性能、效率与ScalingLaw\n研究围绕三个问题系统评估SOP：\nSOP能为预训练VLA带来多大性能提升？\n实验结果说明，在各类测试场景下，结合SOP的后训练方法均得到了显著的性能提升。\n相比预训练模型，结合SOP的HG-Dagger方法在物品繁杂的商超场景中实现了33%的综合性能提升。\n对于灵巧操作任务（叠衣服和纸盒装配），SOP的引入不仅提升了任务的成功率，结合在线经验学习到的错误恢复能力还能明显提升策略操作的吞吐量。\n结合SOP的HG-Dagger方法让叠衣服的相比HG-Dagger\n吞吐量跃升114%\n。\nSOP让多任务通才的性能普遍提升至近乎完美，\n不同任务的成功率均提升至94%以上，纸盒装配更是达到98%的成功率\n。\n△\nSOP性能提升\n为了进一步测试真机SOP训练后VLA模型是否达到专家级性能，研究让SOP训练的VLA模型进行了\n长达36小时的连续操作\n，模型展现出了惊人的稳定性和鲁棒性，能够有效应对真实世界中出现的各种疑难杂症。\n36h连续叠纸盒（50倍速）\n36h连续叠衣服（50倍速）\n机器人规模如何影响学习效率？\n研究使用了三种机器人队伍数量（单机、双机、四机配置），在同样的数据传送总量的基础上，进行了比较。实验结果表明，在相同的总训练时间下，更多数量的机器人带来了更高的性能表现。\n在总训练时间为3小时的限制下，四机进行学习的最终成功率达到了92.5%，比单机高出12%。\n研究认为，多机采集可以有效阻止模型过拟合到单机的特定特征上。\n同时，SOP还将硬件的扩展转化为了学习时长的大幅缩短，四机器人集群相比单机能够将模型达到目标性能的训练速度增至2.4倍。\n△\nSOP学习效率提升\n不同预训练规模下SOP是否稳定有效？\n最后，研究探究了SOP和预训练数据之间的关系。\n研究把总量为160小时的多任务预训练数据分为了三组：20小时，80小时和160小时，分别训练一组初始模型后再进行SOP。\n研究发现，预训练的规模决定了基座模型和后训练提升的轨迹。SOP能为所有初始模型带来稳定的提升，且最终性能与VLA预训练质量正相关。\n同时，对比80小时和160小时实验效果，研究也可以明显注意到，在解决特定失败情况时，在轨策略经验带来了非常显著的边际效果。\nSOP在三小时的在轨经验下就获得了约30%的性能提升，而80小时额外人类专家数据只带来了4%的提升。\n这说明在预训练出现边际效应递减的情况下，SOP能够高效突破VLA性能瓶颈。\n△\nSOP在不同预训练数据规模下的对比\n部署即进化：重塑机器人生命周期\n最后研究将机器人队伍放到了预训练模型没有见到的真实新环境下执行任务，并使用SOP进行在线训练。\n当机器人被置于不同的环境时，即便是同样的任务，起初成功率和吞吐量如预期般下降，但在SOP介入仅仅几个小时后，机器人的性能便显著回升，能够鲁棒地执行相对复杂的实际任务。\nSOP改变的不仅是训练范式，更是机器人系统的生命周期。\n研究相信机器人不应当是“性能固定的标品”，而是“在真实世界中持续提升的生命体”。部署不是技术迭代的终点，而是更大规模学习的起点。\n如果说VLA让机器人第一次具备了通用理解与行动能力，那么SOP所做的是让众多机器人的经验共同驱动智能的快速成长。训练不被锁死在过去，智能成长在当下。\n论文博客：https://www.agibot.com/research/sop_zh\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n我们正在招聘一名眼疾手快、关注AI的\n学术编辑实习生\n🎓\n感兴趣的小伙伴欢迎关注 👉\n了解详情\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860588&idx=2&sn=430781220c8d219107a74d39a2079e96&chksm=e9ab98b3e0e051a43e7c62bc16e767b057dd19643b05e2fea5b4bbe3735fadadf2c0e0ca179d&scene=0&xtrack=1#rd",
      "publish_time": 1767959400,
      "publish_date": "2026-01-09 19:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.agibot.com/research/sop_zh\"]",
      "add_ts": 1768000778,
      "last_modify_ts": 1768087161
    },
    {
      "id": 350,
      "article_id": "51752",
      "title": "完整回放｜上海创智\\u002FTileAI\\u002F华为\\u002F先进编译实验室\\u002FAI9Stars深度拆解 AI 编译器技术实践",
      "description": "12月27日，Meet AI Compiler第八期汇聚来自上海创智学院、华为海思等机构的5位专家，围绕AI编译器全链路技术展开深度分享，涵盖TVM FFI标准、TileRT低延迟推理、算子优化等热点议题。活动通过真实案例展示技术落地路径，推动软件栈与硬件协同创新。现场互动热烈，形成开放的技术对话氛围。关注“HyperAI超神经”获取PPT，回看精彩内容，持续参与AI编译器生态共建。",
      "content": "在持续演进的 AI 编译器技术浪潮中，越来越多的探索正在发生、沉淀与交汇。12 月 27 日，Meet AI Compiler 第八期正是在这样的背景下与大家如期相见。\n本期活动，我们邀请了来自上海创智学院、TileAI 社区、华为海思、先进编译实验室、AI9Stars 的 5 位专家，带来了覆盖软件栈设计、算子开发到性能优化的全链路分享。讲师们结合各自团队的长期探索，展示了不同技术路线在真实场景中的实现方式与取舍思路，让抽象概念有了更具体的落脚点。\n关注微信公众号「HyperAI超神经」，后台回复关键字「1227 AI 编译器」，即可获取嘉宾完整 PPT。\n有人带着最新的研究成果而来，也有人带着正在推进的工程问题走进现场。台上的分享精彩纷呈，现场讨论同样热烈：提问、互动、茶歇间的交流讨论，让话题不断被追问、补充和延展。分享不再是单向输出，而是逐渐形成了一场围绕 AI 编译器展开的长期对话。大家聊得根本停不下来，这也正是我们 AI Compiler Family 的魅力所在～\n活动内容回顾\n分享回顾\n分享主题：\nTVM FFI: Open ABI and FFI for Machine Learning Systems\n内容简介：\nTVM FFI 旨在解决机器学习系统生态割裂与互操作性难题。通过定义开放的 ABI 和 FFI 标准，该项目利用稳定的 C ABI 及 DLPack 实现零拷贝数据传递，打通了 PyTorch 等框架与底层编译器的连接。它支持跨语言高效调用，显著降低了多平台适配的工程成本。\n观看本场分享，你将了解：\n1. 学习 TVM-FFI 通用标准，大幅降低跨语言 Mlsys 开发维护成本\n2. 了解并构建兼容未来的模块化 ML 生态\n分享视频：\n【2025 Meet AI Compiler】TVM FFI: Open ABI and FFI for Machine Learning Systems_哔哩哔哩_bilibili\n分享主题：\nTileRT：面向低延迟大模型推理的软硬件探索\n内容简介：\n随着大模型跨入万亿参数，处理序列跨过百万 token，模型能力正在不断打破各项记录。然而，人们对模型极致计算速度的追求从未停止。一方面许多低延迟场景需要在秒级甚至毫秒级得到响应，如实时决策、博弈等场景；另一方面大模型训练进入 Agent 时代，超长序列的 rollout 时间成为主要瓶颈。\n本报告介绍 TileRT 项目，从 AI 编译器、runtime、到架构设计的角度，思考如何构建针对极低延迟的大模型计算软件栈。\n观看本场分享，你将了解：\n1. 了解大模型低延迟推理场景背景、重要性和未来展望\n2. TileRT 的技术挑战与实践分享\n分享视频：\n【2025 Meet AI Compiler】TileRT：面向低延迟大模型推理的软硬件探索_哔哩哔哩_bilibili\n分享主题：\nPyPTO：基于白盒编译的融合算子开发框架\n内容简介：\n本次分享聚焦华为新推出的融合算子开发框架 PyPTO。它基于 Tensor/Tile 编程范式，通过聚焦核内 SRAM 管理、跨平台 PTO 指令集和 MPMD 运行时等技术，结合 Human-In-The-Loop 调优，以白盒编译方式实现高性能与易用性的统一。\n观看本场分享，你将了解：\n1. 掌握原生为 SIMD 架构设计的融合算子开发框架 PyPTO 的设计理念与核心架构\n2. 掌握 PyPTO 聚焦于发挥用户的专家经验的白盒编译思想与 Human-In-The-Loop 调优精髓\n3. 掌握利用 PyPTO 提供的可视化工具，快速在昇腾平台开发出高性能融合算子的完整流程\n分享视频：\n【2025 Meet AI Compiler】PyPTO：基于白盒编译的融合算子开发框架_哔哩哔哩_bilibili\n分享主题：\n面向 Triton 编译器的编译优化实践\n内容简介：\n本次分享聚焦面向 Triton 编译器的优化实践，系统介绍 Triton 的语言与编译器结构、生态演进与算子库开发方法，并深入覆盖 CPU/GPU/NPU 等多架构的关键优化技巧，展示构建高性能统一算子体系的完整路径。\n观看本场分享，你将了解：\n1. Triton 生态的最新进展\n2. Triton 编译器在多架构（CPU/GPU/NPU）上的关键优化技术\n分享视频：\n【2025 Meet AI Compiler】面向 Triton 编译器的编译优化实践_哔哩哔哩_bilibili\n分享主题：\nAutoTriton：强化学习驱动的大模型Triton算子优化技术探索\n内容简介：\n利用 CUDA 等语言编写高效内核是性能工程师的专属领域，随着 Triton 等编程框架的出现，内核可编程性有着重大飞跃。但开发人员仍然需要手动配置关键参数，限制了性能可移植性和广泛应用。本报告将介绍在大模型算子生成评价基准与模型方面的探索，并展望大模型在算子优化方面的巨大潜力。\n观看本场分享，你将了解：\n1. 大模型赋能算子优化的相关工作及最新进展\n2. 大模型在算子优化领域的关键技术\n分享视频：\n【2025 Meet AI Compiler】AutoTriton：强化学习驱动的大模型 Triton 算子优化技术探索_哔哩哔哩_bilibili\n主办方及合作伙伴\nHyperAI超神经（hyper.ai）作为国际领先的人工智能及高性能计算社区，\n旨在通过提供行业资讯报道、数据集加速下载、在线教程演示、热门模型性能评测、前沿论文推荐、高价值成果解读、顶会日历集成等一系列服务，助力全球数据科学及⼈⼯智能⾏业的开发者及爱好者学习、理解、实践，与社区⼀起构建⼈⼯智能的未来。\n访问官网：\nhttps://\nhyper.ai/\nOpenBayes贝式计算是国内领先的高性能计算服务提供商\n，通过为新一代异构芯片嫁接经典软件生态及机器学习模型，进而为工业企业及高校科研提供更加快速、易用的数据科学计算产品，其产品已被数十家大型工业场景或头部科研院所所采用。\n访问官网：\nhttps://\nopenbayes.com/\nMLC.AI 社区成立于 2022 年 6 月，并由 Apache TVM 主要发明者、机器学习领域著名的青年学者陈天奇，带领团队上线了 MLC 线上课程，系统介绍了机器学习编译的关键元素以及核心概念。\n2022 年 11 月，在 MLC.AI 社区志愿者的共同努力下，首个完整的 TVM 中文文档上线，并成功托管至 HyperAI超神经官网，进一步为对机器学习编译感兴趣的国内开发者，提供了接触并学习一门新技术的基础设置——文档。\nMLC 线上课程：\nhttps://\nmlc.ai/\nTVM 中文文档：\nhttps://\ntvm.hyper.ai/\n上海创智学院是汇聚顶尖大学、头部企业和科研机构联袂建设的新型人才培养机构。学院坚持「以学生为中心、以前沿为牵引」的培养理念，通过超高规格的师资、超常措施的培养、超凡条件的保障，探索具有中国特色的 AI 领军人才培养方案，致力于培养中国 AI 领军人才，打造世界人工智能创新高地。\n活动支持\n内容中包含的图片若涉及版权问题，请及时与我们联系删除",
      "article_url": "https://hub.baai.ac.cn/view/51752",
      "publish_time": 1767957780,
      "publish_date": "2026-01-09 19:23",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1FuiKBMEJg/%3Fvd_source%3D5e54209e1f8c68b7f1dc3df8aabf856c\", \"https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1zRiMB5Epv/%3Fvd_source%3D5e54209e1f8c68b7f1dc3df8aabf856c\", \"https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1iniMBBEKj/%3Fvd_source%3D5e54209e1f8c68b7f1dc3df8aabf856c\", \"https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1ekiTBeERf/%3Fvd_source%3D5e54209e1f8c68b7f1dc3df8aabf856c\", \"https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/BV1tdiTBREvi/%3Fvd_source%3D5e54209e1f8c68b7f1dc3df8aabf856c\", \"https://link.zhihu.com/?target=https%3A//hyper.ai/\", \"https://link.zhihu.com/?target=https%3A//openbayes.com/\", \"https://link.zhihu.com/?target=https%3A//mlc.ai/\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/\"]",
      "add_ts": 1768000791,
      "last_modify_ts": 1768087172
    },
    {
      "id": 355,
      "article_id": "51746",
      "title": "毫无征兆！DeepSeek R1爆更86页论文，这才是真正的Open",
      "description": "DeepSeek将R1论文从22页大幅扩展至86 页，引发广泛关注。新版本揭示仅用强化学习即可显著提升AI推理能力，挑战传统训练范式。此举不仅展现开源模型的巨大潜力，更被视作对闭源体系的技术反哺。业界推测，其下一代R2或采用纯强化学习方法，进一步推动AI进化。",
      "content": "新智元报道\n编辑：桃子 KingHZ\n【新智元导读】\nR1论文暴涨至86页！DeepSeek向世界证明：开源不仅能追平闭源，还能教闭源做事！\n全网震撼！\n两天前，DeepSeek悄无声息地把R1的论文更新了，从原来22页「膨胀」到86页。\n全新的论文证明，只需要强化学习就能提升AI推理能力！\nDeepSeek似乎在憋大招，甚至有网友推测纯强化学习方法，或许出现在R2中。\n这一次的更新，直接将原始论文升级为：一份开源社区完全可复现的技术报告。\n论文地址：https://arxiv.org/abs/2501.12948\n论文中，DeepSeek-R1新增内容干货满满，信息含量爆炸——\n精确的数据配方：明确给出数据规模（2.6万道数学题，1.7万条代码），以及具体的创建流程\n基础设施说明：vLLM/DualPipe设置的示意图\n训练成本拆解：总计约29.4万美元（R1-Zero使用了198小时的H800GPU）\n「失败尝试」复盘：深入解释PRM为什么没有成功\n模型对比：与DS-V3、Claude、GPT-4o系统性比较（此前只包含o1）\n10页安全性报告：详细说明安全评估与风险分析\n结果显示，DeepSeek R1多项实力与OpenAI o1相媲美，甚至赶超o1-mini、GPT-4o、Claude 3.5。\n不仅如此，这次论文末核心贡献者名单，列出了各自的具体贡献。\n有网友表示，这次更新堪称一本教科书了！尤其是，关于DeepSeek-R1-Zero自我进化细节是真正的亮点。\n值得一提的是，DeepSeek应用也在几天前上新功能——支持语音输入。有网友对此猜测，可能他们要发力多模态了。\n接下来，一起拆解最新论文内容的核心亮点。\nDeepSeek R1爆更，\n实力打平o1\n首先来看，DeepSeek-R1具体的评测结果。\n最新评估，依旧覆盖了数学推理、编码、通用知识&理解、事实型&指令遵循等任务的全方位对比。\n在教育知识类基准上，包括MMLU、MMLU-Pro和GPQA Diamond，DeepSeek-R1整体超越DS-V3。\n特别是，在STEM相关问题上，准确率显著提高——\n这背后最大功劳要归功于：RL\n。\n另外，在长上下文的问答任务（FRAMES）上，DeepSeek-R1表现亮眼，文档理解与分析能力出色。\n在数学、代码任务中，DeepSeek-R1与OpenAI-o1-1217基本持平，明显领先其他模型。\n在更偏实践编程任务中，OpenAI-o1-1217在Aider上表现优于DeepSeek-R1，但在SWE Verified上两者水平相当。\n在DeepSeek看来，主要是工程类RL\n训练数据\n还不够多，所以DeepSeek-R1在这块的能力还没完全发挥出来。\n下一版本，可能会看到其在这一领域的明显提升。\n下图中，是DeepSeek-R1和DeepSeek-R1-Zero，在多项基准竞赛中与人类专家的性能对比。\nAIME数学竞赛：DeepSeek-R1得分已超越人类的平均水平。\nCodeforces编程竞赛：DeepSeek-R1表现超过了93.6%的参赛者，解题能力超强。\nGPQA科学问答：人类整体实力更强，表现优于DeepSeek-R1。\nDeepSeek认为，如果让R1也能联网的话，说不定就能追上，甚至赶超人类现在的水平了。\n人工评估阶段，采用了ChatbotArena擂台，通过ELO分数来体现DeepSeek-R1在人类偏好上的表现。\n显然，R1取得了亮眼的成绩。尤其是，在「风格控制」中，它与OpenAI-o1、Gemini-Exp-1206打成平手，并列第一。\n「风格控制」这一设计直接回应了一个关键问题：模型是否可能通过更长、更精致或更好看的回答来「取悦」人类评审，即使其内容本身并不一定更强。\nDeepSeek强调，一个基于MIT协议的开源模型，整体表现与多款闭源\nAI\n相媲美，这无疑是一个重要的里程碑。\n尤其是，DeepSeek-R1使用成本更低的情况下。\n下图12，更近一步展示了不同评测维度下的排名结果，呈现了R1在数学、编程等多个领域的强劲实力。\n这表明，R1不光推理能力强，在各种实际应用场景中，整体表现相当文档。\n在数据方面，DeepSeek放出具体RL数据和微调数据的规模。\n在强化学习阶段，数据比例是这样分配的：数学（26k）、代码（17k）、STEM（22k）、逻辑（15k）、通用（66k）。\n在微调阶段，数据规模约800k，覆盖了推理、通用指令任务、格式/语言一致性样本。\n蒸馏，让推理能力一键迁移\n在蒸馏部分，DeepSeek回答了这一问题——\nDeepSeek-R1学到的「推理能力」，能不能有效、稳定地迁移到更小的模型上？\n这里，DeepSeek作为「教师」模型，生成高质量、显式推理轨迹的数据，通过SFT把推理能力「蒸馏」给更小的「学生」模型，而不是让小模型再跑一遍RL。\n通过蒸馏，小模型直接学习\nR1已经验证有效的推理模式，\n不需要重新探索reward space。\n论文中，DeepSeek实验蒸馏了多个规模的模型，包括1.5B、7B、8B、14B、32B、70B，系统性地验证了「跨尺度有效性」。\n同尺寸模型相比较，蒸馏后的性能全面提升。\n可以看到一个重要的现象是，推理能力并没有「锁死」在大模型里，而是能通过数据迁移到小模型。\n在训练成本方面，DeepSeek-R1-Zero使用了64×8张H800 GPU，整体训练耗时约198小时。\n在DeepSeek-R1训练阶段，沿用了相同的GPU配置，并在大约4天内完成训练，约80小时。\n此外，在构建监督微调（SFT）数据集的过程中，共消耗了约5000 GPU小时，\n一共花费29.4万美元，详情可参见表7。\n有网友表示，是时候让Alex Wang道歉了，所有证据都摆在这里了。\n智能涌现！\nDeepSeek-R1-Zero的确在自我进化\n在MATH数据集上，DeepSeek-R1-Zero简直就是人类的翻版！\n对人类而言较为简单的推理任务，DeepSeek-R1-Zero在训练早期便被模型掌握，而在复杂推理问题（难度3–5）上的能力则会随着训练显著提升。\n具体来说，下图8揭示了不同的学习模式：\n简单问题（1-3级）迅速达到高准确率（0.90-0.95）并在整个训练过程中保持稳定；\n困难问题则被逐步攻克——\n4级问题的准确率从开始的约0.78提升到0.95；\n最难的5级问题，最明显，从最开始的约0.55提升到0.90。\n在较难问题（3-4级）上的准确率，DeepSeek-R1-Zero偶尔会以微弱优势超过其在较简单问题（1级）上的表现。\n这种现象看似反直觉，可能由于数据集的特征。\n在高级推理任务上，DeepSeek-R1-Zero也表现出类似的涌现现象，证明了两大结论：\n在生成长链中间token中，强化学习发挥了关键作用。\n在训练的特定阶段，AI模型学会了不同形式的反思。\n首先，如下图9(a)所示，他们统计了一些具有代表性的反思性词汇，包括\nwait、mistake、however、but、retry、error、verify、wrong、evaluate和check。\n如下图a所示，随着训练的进行，反思行为的频率逐渐增加：\n反思性词汇的数量相比训练开始时增加了5到7倍，\n其次，特定的反思行为可能在训练过程中的特定时间点出现。\n如下图b所示，「wait」反思策略在训练早期几乎不存在，在4000-7000步之间偶尔出现，然后在8000步之后孤峰突起。\n总之，他们观察到模型在训练过程中的反思行为逐渐增加，而某些反思模式（如使用「wait」）则在训练过程的特定时间点出现。\n安全问题，\n行业重点在越狱攻击\nDeepSeek-R1的安全风险评具体分析包括以下5个方面：\n1、DeepSeek-R1官方服务所采用的风险控制体系；\n2、与当前先进模型在六项公开安全基准测试中的对比安全评估；\n3、基于内部安全测试集的分类研究；\n4、对R1模型在多语言场景下的安全性评估；\n5、模型在应对越狱攻击方面的稳健性评估。\nDeepSeek-R1的风险控制体系通过向DeepSeek-V3发送「风险审查提示词」（risk review prompt）来实现，具体包括以下两个主要流程：\n首先，\n过滤潜在\n风险\n对话。\n在每轮对话结束后，系统会自动将用户的提问与一组预设关键词列表进行匹配。\n其次，\n基于模型审查\n风险\n。\n被标记为潜在风险的对话将与预设的「风险审查提示词」（见示例8）拼接在一起，并发送给DeepSeek-V3模型进行审查。系统会根据模型的判断结果，决定是否撤回该轮对话内容。\n实验结果显示，与其他前沿模型相比，DeepSeek-R1在整体安全性上与其他先进模型表现相当。\n然而，在HarmBench测试中，R1的表现明显落后，主要源于R1在涉及「知识产权」的相关问题上表现欠佳。除此之外，在其他安全类别的评估中（如歧视与偏见、暴力与极端主义、隐私侵犯等），R1模型表现稳定，展现出较强的安全防护能力。\n此外，他们特别构建了一个内部安全评估数据集，以系统监测模型的整体安全水平。\n他们将大语言模型可能面临的内容安全挑战划分为4个一级类目和28个细分子类，具体分类如下：\n最终，他们共构建了1,120道测试题，用于对模型的安全性进行系统性评估，具体结果见下表。\n在未启用控制时，DeepSeek-R1与DeepSeek-V3的基础模型拒答率较低，但不安全率较高。启用风险控制后，不安全率明显下降，但拒答率升高（约25%）。  DeepSeek-R1在处理\n违法犯罪类问题\n和\n伦理道德类问题\n时表现出色，而在应对\n歧视偏见类问题\n与\n有害行为类问题\n时则表现一般。\n评估模型在不同语言之间的安全差异同样至关重要。为此，他们将此前构建的中英双语安全测试集扩展至50种常用语言。\n最终，他们构建出一个包含9,330个问题的多语言安全测试集。\n引入\n风险\n控制后\n，DeepSeek-V3（86.5%）与DeepSeek-R1（85.9%）在50种语言中的整体安全得分接近Claude-3.7-Sonnet（88.3%）的表现。\n图14中展示了DeepSeek-V3、DeepSeek-R1（启用与未启用风险控制系统）以及Claude-3.7-Sonnet和GPT-4o（2024-05-13）在50种语言下的表现。\n在\n越狱攻击测试中，他们得出三大结论：\n越狱攻击对所有模型均构成显著威胁\n推理型模型更依赖风险控制系统\n开源模型越狱风险更高\n总结\n基础模型、验证器很重要\n基础模型很重要。\n在开发的最初阶段，他们曾尝试使用较小规模的模型作为强化学习（RL）训练的起点。然而，在以AIME基准作为主要验证集的评测中，这些模型始终未能带来实质性的性能提升。\n为了解决这些问题，他们转而采用更大规模、能力更强的模型。\n在这些架构上，他们首次清晰地观察到纯RL训练所带来的显著性能收益。\n这一结果表明，从基础模型出发进行强化学习，其效果在很大程度上取决于模型本身的容量与表达能力。\n验证器很重要。\nDeepSeek-R1-Zero的训练效果高度依赖于奖励信号本身的可靠性和准确性。\n根据目前的实验结果，有两种方式可以有效缓解奖励作弊（即模型学会「钻奖励规则空子」）的问题：\n一是基于规则的奖励模型（Reward Models，RMs），二是利用大语言模型来判断生成答案是否与预先定义的标准答案一致。\n迭代式训练\n流水线中，RL、SFT缺一不可。\n他们提出了一套包含监督微调（SFT）和强化学习（RL）的多阶段训练流水线。\nRL与SFT在整个训练流程中缺一不可。单独依赖RL，容易在问题本身定义不清的任务中引发奖励作弊和次优行为；而只依赖SFT，则可能限制模型通过探索进一步提升其推理能力。\n他们同样经历了不少失败与挫折，包括\n过程奖励模型（Process Reward Model，PRM）和蒙特卡洛树搜索（Monte Carlo Tree Search，MCTS）。\n但这并不意味着这些方法本身无法用于构建有效的推理模型。\n参考资料：\nhttps://x.com/cedric_chee/status/2008871365009670222\nhttps://www.reddit.com/r/MachineLearning/comments/1q6cb0k/r_deepseekr1s_paper_was_updated_2_days_ago\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652662815&idx=1&sn=7432d00cfbe544a822a8fac0c7fe10e0&chksm=f02c6d18a615033634fd0adf97e539255f87251c12fbd4d30c4e5d78acba6c17f2d046a3f322&scene=0&xtrack=1#rd",
      "publish_time": 1767940800,
      "publish_date": "2026-01-09 14:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2501.12948\", \"https://x.com/cedric_chee/status/2008871365009670222\", \"https://www.reddit.com/r/MachineLearning/comments/1q6cb0k/r_deepseekr1s_paper_was_updated_2_days_ago\"]",
      "add_ts": 1768000821,
      "last_modify_ts": 1768087189
    },
    {
      "id": 358,
      "article_id": "51743",
      "title": "Adv. Sci. | Ouroboros: 让AI从“分子理解”走向“药物设计”",
      "description": "苏州系统医学研究所与新加坡国立大学张阳团队在《Advanced Science》提出一种基于“Ouroboros”理念的分子AI基础模型，通过“编码—重建”正交架构，将分子表征学习与生成统一于同一潜在空间。利用图神经网络提取化学有效特征，再结合Transformer实现精准重构，在多个分子任务中展现优异性能，实现了分子理解与设计的协同统一，推动AI驱动药物发现的发展。",
      "content": "近日，苏州系统医学研究所\n–\n新加坡国立大学张阳教授团队在《\nAdvanced Science\n》发表研究，提出了一种新的分子\n“\n基础模型\n”\n，\n探索如何在同一个\nAI\n框架中同时实现分子理解与分子设计\n。该工作以\n“Ouroboros\n（衔尾蛇）\n”\n为设计理念，构建了一种\n“\n编码\n—\n重建\n”\n式的正交架构，将分子表征学习与分子生成统一到同一个潜在空间中：模型先利用图神经网络学习具有化学意义的分子表示，再通过\nTransformer\n将这些表示重构为具体分子结构。更进一步，研究在训练过程中显式引入分子构象空间与药效团相似性约束，使模型在学习统计规律的同时，能够内化关键的药物化学知识。实验结果表明，\nOuroboros\n在虚拟筛选、多靶点分子设计、性质预测和定向分子优化等多类任务中展现出良好的泛化能力，为\nAI\n迈向真正\n“\n可设计\n”\n的分子基础模型提供了一种统一而可扩展的新思路\n。\n研究动机：为什么需要新的分子基础模型？\n在药物发现过程中，研究人员长期面对一个结构性矛盾：\n分子表征模型\n擅长理解分子，却无法直接生成新结构；而\n分子生成模型\n可以设计候选分子，却往往缺乏稳定、可解释的化学语义表征。\n许多生成式预训练依赖可tokenize的“化学语言”（如SMILES），从而难以充分利用分子图的结构优势；同时，高质量实验标签稀缺，迫使模型使用较“浅”的伪标签，难以学到更复杂的化学规律。\n这种割裂使得“设计—评估—优化”这一闭环流程不得不依赖多个模型拼接完成，不仅效率受限，也难以在复杂任务中积累可迁移的化学知识。\n迭代式分子优化策略\n近年来，“基础模型（foundational model）”的理念逐渐进入分子科学领域，其核心目标是：\n在单一模型中系统性地学习化学规律，使其能够同时支撑多种下游任务\n。然而，如何在一个模型中优雅地兼顾分子生成、分子表征与分子属性预测，仍然是一个未被充分解决的问题。\n为了填补这一空白，研究人员提出了一种名为\nOuroboros\n的新型分子基座模型\n。该模型的设计灵感源自古老的衔尾蛇图腾，象征着“编码”与“重构”的循环统一。其核心目标是构建一个能够同时理解“分子长什么样”（表征）和“如何设计分子”（生成）的统一引擎。\n衔尾蛇，象征从分子到表征，从表征回到分子的循环\n领域背景：AI 在药物发现中的三类核心任务\n要理解 Ouroboros 的价值，我们需要先回顾 AI 在药物研发（AIDD）中的三个主要应用场景，以及它们如何在此模型中汇聚：\n分子表征学习（Representation Learning）：这是 AI 理解化学的基础。通过将复杂的分子图映射为低维的向量，AI 可以学习分子的“指纹”。优秀的表征应当能让结构相似、功能相近的分子在向量空间中彼此靠近。\n分子属性预测（Property Prediction）：这是药物筛选的核心，涉及对溶解度、渗透性、毒性（ADMET）、药物-靶标结合亲和力甚至是表型尺度的药物疗效等指标的建模。\n分子属性预测强调跨化学骨架的泛化能力：不仅要在已见结构附近准确，还要在新骨架上稳定工作\n。\n分子生成（Molecular Generation）：这是“从无到有”的创造过程。从简单的骨架替换到复杂的\nde novo\n从头设计，AI 需要能够从表征空间中逆向解码出合理和属性优越的化学结构 。\n在预训练中学习化学，在下游任务中学习生物学\n当前的关键挑战在于：\n能否在一个统一的基座模型中充分学习化学知识，使得它既能作为精准的“扫描仪”（表征与预测），又能作为高效的“打印机”（生成），并能在广泛属性建模任务上持续受益？\n实现方案与核心创新：正交结构的 Ouroboros 模型\n1. 正交架构：\n表征与生成的“二元统一”\nOuroboros 的核心创新，在于其\n正交（orthogonal）的模型结构设计\n。模型由两个相互独立、又通过表示空间紧密耦合的模块组成：\n分子表征模块\n：基于分子图的 GNN 结构，结合全局注意力机制，学习能够反映构象、官能团相互作用及药效团特征的连续表示，即：“把分子压缩成编码”。\n分子\n重建\n/生成模块\n：以表征向量为条件，对应到 SMILES 序列的\n重建\n与生成过程，即：“把编码解压回分子”。\n这种设计的关键不在于“简单拼接”，而在于\n表征空间本身被约束为既可判别、又可生成的统一化学空间\n。换言之，模型学习到的不是任务特定特征，而是能够被反向“解码”为合理分子结构的化学表示。更重要的是，\n这种正交性允许两个模块分别进行预训练\n，使得研究人员可以针对不同任务选择最合适的网络结构和训练数据集，从而突破了传统模型中表征与生成难以两全的局限 。进一步地，研究人员将这种结构视为一种“化学意义上的自洽系统”：\n表征模块负责理解分子，重建/生成模块负责将AI探索到的新分子结构从表征空间中重建回分子结构，二者共同构成一个可迁移的分子基础模型。\nOuroboros的整体架构与训练/应用策略\n得益于Ouroboros的正交框架，我们可以将其分子表征模块所建立的编码空间应用到各类下游任务中，并将这些“下游任务预测器”的输出作为损失函数，从而直接优化分子的编码向量，并使用分子重建模块解码分子结构在表征空间中被逐步优化的迁移路径。\n2.\n构象空间药效团相似性\n引导的知识正则化\nOuroboros 能够“理解”化学的关键在于其独特的预训练策略——\n构象空间药效团相似性\n。\n动态构象捕捉：\n不同于只看 2D 结构的传统方法，Ouroboros 在训练中引入了系统搜索的分子构象空间，模拟分子在真实环境中的动态行为\n。\n药效团对齐：\n通过一个包含47 亿个分子对相似度的超大规模矩阵，模型被教导去识别分子间的药效团相似性，而不仅仅是简单的拓扑重复。\n这种策略相当于为 AI 安装了一双“化学家的眼睛”，使其表征空间不仅具有统计学意义，更具备了深厚的化学规律约束\n。\n结果与分析：统一表示带来的能力涌现\n在多项评估中，Ouroboros 展现出几个值得关注的现象：\n卓越的零样本虚拟筛选能力\n：\n在针对 DUD-E 等经典数据集的测试中，Ouroboros 表现出了极强的泛化能力。即使只在\n12.6 万\n个小规模数据集上进行预训练，其在\n数百万\n分子结构组成的虚拟筛选测试集上的表现也足以媲美甚至超越那些在数十亿量级数据上训练的巨型模型，这暗示了\n构象空间药效团相似性\n所带来的化学偏置在药物发现和相似性比较任务上的有效性。\n相似性筛选任务的基准测试\n广泛下游任务的属性建模能力\n：在属性预测任务中\n，即便冻结表征模块，仅训练轻量预测头，模型仍能在多种 ADMET 指标上保持稳定表现，体现出Ouroboros模型中化学表示空间的通用性。如果我们像其他分子表征模型一样在下游任务中启用微调，Ouroboros仍然可以取得与最佳基线模型（在ChEMBL数据集上执行预训练）相媲美的性能。\n属性建模任务的基准测试\n定向迁移实现分子的“按需设计”：\n得益于表征空间的平滑性和重构模块的高效性（结构恢复率超过 80%），研究人员开发了一种名为定向迁移（Directed Migration）的优化技术，其核心原理是将分子优化问题转化为一个分子表征向量的优化问题，进而使得我们可以“像优化神经网络参数一样优化分子结构”。\n在分子生成与优化场景中\n，研究人员展示了沿着表示空间进行扰动或反向传播，即可实现定向的分子演化，如在保持结构相似性的同时优化溶解度或膜通透性。\n这些结果共同指向一个结论：\n当生成与表征共享同一语义空间时，模型不再只是“生成器”或“预测器”，而成为化学设计的统一接口\n。\n局限性：未来的发展方向\n在论文中，作者详细讨论了当前模型的局限性：其一，当前工作尚未直接预测分子的“动态构象空间”，这被认为是重要且有前景的延伸；其二，性质基准仅覆盖10项，仍有广阔扩展空间；其三，模型暂不直接预测蛋白-配体结合亲和力，而是依赖对接在迁移路径上筛选更优的小分子结合构象与打分，提示未来需要把蛋白表征纳入训练，以升级为端到端的DTI/亲和力预测与生成框架。\n展望：面向药物化学的“基础设施级”模型\nOuroboros 并非终点，而是一个起点。其正交结构为未来扩展留下了充足空间，例如：\n引入蛋白表示，实现端到端的药物–靶点联合建模；\n将实验反馈纳入潜空间优化，实现闭环学习；\n拓展到更复杂的化学体系，如共价抑制剂或大环分子。\n基于这样的框架，\nOuroboros可以被广泛的无缝嵌入到各类下游任务模型中，赋予这些下游任务模型优化小分子结构的能力\n。\n更重要的是，Ouroboros 所展示的并不仅是一种模型结构，而是一种\n“表征–生成一体化”\n的设计范式。它表明，分子基座模型不必在理解与创造之间做出取舍，而是可以通过合理的结构设计，让二者在同一化学认知体系中共存。\n从方法论角度看，这篇论文的亮点不仅是某个单点指标，而是其\n“正交基座 + 化学知识投影约束”\n的工程化思想：用统一潜空间把表征、生成与属性建模连接成可复用引擎，再用不同的适配头服务于不同药物化学场景，形成真正可扩展的“表征-生成一体化”基础设施。\n本论文的第一作者为苏州系统医学研究所王林博士，通讯作者为中国医学科学院苏州系统医学研究所特聘教授及新加坡国立大学教授张阳教授，作者团队还包括来自深药科技（苏州）有限公司的科研人员。张阳教授及其团队长期从事人工智能驱动的蛋白质与 RNA 结构预测及药物设计研究，其开发的多项计算方法在国际 CASP 蛋白质结构预测大赛中连续 9 次获得自动组冠军。王林博士主要研究方向为 AI 辅助的小分子药物发现方法与应用，其提出的 GeminiMol 方法曾在 2023 年首届上海市国际计算生物学创新大赛中获得一等奖。\n----参考文献----\nL Wang, Y Wu, H Luo, M Liang, Y Zhou, C Chen, J Liu, J Zhang, Y Zhang. “Learned Conformational Space and Pharmacophore Into Molecular Foundational Model.”\nAdvanced Science\n(2026): e13556.",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512597&idx=1&sn=6804c4f869a4fc0321d65cdebbb0bbc5&chksm=fd3124b33a75ed273a56f07412f135321e488e05e0a5de6c3f793a35e897a4106573bd466695&scene=0&xtrack=1#rd",
      "publish_time": 1767940200,
      "publish_date": "2026-01-09 14:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768000836,
      "last_modify_ts": 1768087201
    },
    {
      "id": 360,
      "article_id": "51741",
      "title": "KDD'25  |  Bid2X：基于基础模型视角的广告竞价环境建模",
      "description": "摘要广告自动出价服务是在线广告的关键能力，但现有方法泛化能力不足。为此，我们提出统一建模竞价通用规律的竞价环境基础模型Bid2X，通过学习多场景数据中给定出价下广告效果（如预算消耗、GMV、PV等）的映射关系，提升模型在不同场景下的适应性与预测准确性，实现更高效的自动出价。",
      "content": "摘要\n广告自动出价服务会为广告主自动生成出价，是在线广告投放的关键能力。现有研究虽然在竞价环境建模上投入很多，但大多只针对某一种场景设计，换到其他场景效果往往下降，泛化能力不足。\n为解决这一问题，我们提出用统一模型来建模竞价的通用规律：在给定出价时，广告可能产生的效果是多少，例如预算消耗、GMV、PV 等。基于这一想法，我们提出竞价环境基础模型\nBid2X\n，从多场景数据中学习这一竞价规律。\n在模型设计上，Bid2X 先把不同来源、不同类型的竞价数据编码成统一的序列表征。为捕捉竞价数据中复杂的变量间依赖关系和动态时间依赖性，我们提出了两种注意力机制，分别将不同变量的嵌入和不同时间步的嵌入作为注意力Token进行表征学习。在学得的变量和时间表征基础上，采用变量感知融合模块进行自适应竞价结果预测。\n我们的模型已在全球最大电子商务平台之一的淘宝广告平台上部署。在八个大规模真实数据集上的离线评估表明，Bid2X 相较于多种基线方法具有优越性，并在不同场景间展现出良好的通用性。在实际应用中，Bid2X 在线 A/B 测试使GMV提升了 4.65%，ROI提高了 2.44%，为计算广告领域的竞价环境基础模型开辟了道路。\n基于本工作的论文已被\nKDD'25 ADS Track\n接收，欢迎阅读交流。\n论文：Bid2X: Revealing Dynamics of Bidding Environment in Online Advertising from A Foundation Model Lens\n作者： Jiahao Ji, Tianyu Wang, Yeshu Li, Yusen Huo, Zhilin Zhang, Chuan Yu, Jian Xu, Bo Zheng\n下载：https://dl.acm.org/doi/epdf/10.1145/3711896.3737197\n一、引言\n随着在线广告平台自动化程度的不断提高，自动出价服务已成为广告主在各种广告场景中实现广告效果目标不可或缺的工具。目前主流的自动出价算法通常隐式地对竞价环境进行建模，但在全面理解竞价环境和跨环境泛化方面存在局限。例如，线性规划基于历史竞价环境计算给定出价下可获取曝光的总价值最大值。基于比例-积分-微分控制器的方法描绘给定出价下可能的成本\n[1]\n。基于强化学习的方法通常采用环境模型来学习出价与成本或奖励之间的关系\n[1]\n[2]\n。这些环境建模过程可以总结为一个统一的环境函数\nθ\n，其中 Y 涉及目标变量，如成本、奖励和获胜曝光次数，t 表示时间戳。\n图1\n为克服这些问题，我们提出训练一个竞价环境基础模型（Bidding Foundation Model，BFM），其定义为\"一个在大量竞价环境数据上训练的大型深度学习模型，使其能够适用于各种竞价场景\"。由于存在独立于特定竞价环境的通用原理，BFM能够跨多种场景通用。例如，更具成本效益的曝光能带来更好的广告效果，竞价环境存在时间邻近性和周期性，出价与其结果遵循边际收益递减规律。\n然而，如何为工业级电商广告构建基础模型，对学术界和工业界而言仍是一个开放性问题。我们认为此方向存在三个挑战：\n异构竞价数据\n。从不同竞价场景收集的数据缺乏统一性，主要包括无时间信息的点数据、时间序列数据，以及离散数据和连续数据。每种数据类型都有其自身特点，目前尚无统一方法对所有数据进行编码。\n复杂动态的数据依赖\n。真实世界竞价环境是一个高度动态的多智能体博弈过程，导致竞价数据中控制变量与目标变量之间存在复杂依赖关系。此外，这些依赖关系随时间演变，例如，相同出价在夜间可能比工作时间带来更多收益，因为人们更可能在下班后在线购物。现有方法主要学习变量间的依赖关系，但未能考虑时间动态性。\n独特的数据分布\n。由于参与竞价过程并不保证能赢得曝光，竞价数据常包含许多零值，形成零膨胀分布。这种独特分布违背了现有神经网络模型对正态数据分布的假设，导致次优性能。\n为应对这些挑战，我们提出了名为 Bid2X 的竞价环境基础模型，它利用带条件的下一Token预测方法，从跨场景的多样化竞价数据中学习通用原理。我们的贡献主要有四个方面：\n引入了基础模型的新概念用于竞价环境建模，这一范式创新超越了传统特定场景模型的局限，提供了能够泛化到各种竞价环境的解决方案。\n首次识别了竞价环境建模问题的三个独特挑战，这些挑战对于开发竞价环境基础模型和提升计算广告系统能力至关重要。\n提出了竞价环境基础模型 Bid2X，能够将异构竞价数据统一为序列嵌入，并学习复杂动态的依赖关系以实现跨环境泛化。我们从理论上确保模型能够收敛到零膨胀数据分布。\n在八个真实世界数据集上的大量实验证明了 Bid2X 在各种场景中相较于多种基线方法的优越泛化能力。在大型电商公司淘宝的在线结果进一步验证了我们模型的有效性。\n二、预备知识\n本节我们首先定义一些基本概念，然后介绍本文研究的问题。\n自动竞价与竞价环境建模\n：计算广告中的自动竞价技术是近年来的研究热点，\n基于强化学习的方法因其有效处理竞价过程序列的能力而被广泛使用。例如，Cai 等人\n[2]\n设计了一个竞价环境来学习最优竞价策略，Zhang 等人\n[3]\n采用强化学习框架进行自动竞价。此外，预测每个广告拍卖市场价格概率分布的 Landscape forecasting 方法\n[4]\n也可被视为竞价环境建模方法。然而，这些方法通常为特定场景设计，无法很好地泛化到各种竞价场景。\n基础模型：\n基础模型是支持多样化场景的通用技术\n[5]\n。通常，它们是在广泛海量数据上训练的大型深度学习模型。该技术目前已在多种模态中得到发展，如文本、视觉、图、时间序列，甚至机器人和自动驾驶。然而，计算广告中的基础模型尚未得到充分探索。\n广告活动：\n广告活动 C 是广告主为寻求产品推广而创建的订单，受预算、产品类别、广告主类别和投放开始/结束时间约束。它还涉及一些上下文信息，如历史总点击量、历史总成本、历史总成本效益等。在线广告平台中，广告活动通常在每个交易日结束时进行结算和重置。因此，我们将第 τ 天的第 i 个广告活动记为\nτ\n。\n竞价轨迹\n：竞价轨迹是在广告活动\nτ\n执行过程中生成的一系列竞价记录，记为\nτ\nτ\nτ\n，其中 m 是竞价记录的数量。每条记录\n，其中 b 是出价，c、r 和 ct 分别表示从时间戳 t 到出价调整时段的累计成本、奖励和获胜曝光次数。当相应广告活动完成时，我们称该竞价轨迹是\n完整的\n，否则是\n不完整的\n。\n竞价环境建模问题：\n给定历史竞价数据\nτ\nτ\n截至时间段 t 的今日竞价数据\nτ\nτ\n以及下一个时间段 t+1 的出价信息\nτ\n，竞价环境建模\n问题旨在通过函数\n预测相应结果：\nτ\nτ\nτ\nτ\nτ\nτ\n其中输出包括第 (t+1) 个时间段的成本、奖励和次数，即\nτ\nτ\nτ\nτ\n我们利用数据的时间特性，将竞价环境建模问题构建为一个自监督任务，即基于先前的竞价记录预测下一个时间步最可能的结果，即带条件的下一Token预测。我们的问题表述不需要人工标注，因为输入和目标天然存在于数据中，类似于语言数据。这种新颖的自监督问题表述方法有助于有效捕捉竞价环境的时间动态性，并为该领域的基础模型铺平道路。\n三、方法\n本节我们详细介绍提出的 Bid2X 基础模型，其整体架构如图 2 所示。首先，我们在第 1 节提供针对异构竞价数据的统一数据嵌入方法。然后，在第 2 节详细阐述用于变量和时间依赖建模的竞价 Transformer。最后，在第 3 节详细说明针对竞价数据独特分布的零膨胀投影，并引入一个自监督辅助任务以从全局视角补充信息。\n1. 统一数据嵌入\n本部分旨在通过定制的嵌入方法将异构竞价数据转换为统一序列嵌入。由于历史数据和当天数据用于建模不同类型的依赖关系，我们通过独立模块对它们进行嵌入。\n历史数据嵌入\n历史数据用于变量间相关性建模，因此我们提出将每个变量序列转换为独立的嵌入。\n具体而言，给定轨迹\nτ\n的成本序列\nτ\nτ\nτ\nτ\n，其长度为\nτ\n，我们通过下式将其编码为\nτ\n：\nτ\nτ\n其中\nτ\n是可学习参数。由于不同竞价轨迹长度不同，我们将所有轨迹填充到最大长度 T。\n当天数据嵌入\n当天数据用于时间依赖性建模，因此我们将一个时间段的所有值视为一个Token，并将其编码为 D 维嵌入。在深入嵌入层之前，我们对竞价轨迹进行预处理，以避免信息泄露并便于建模。\n具体而言，给定截至当前时间段 t 的竞价轨迹：\nτ\nτ\nτ\n，我们沿变量维度\n将其拆分为两部分：\nτ\n包含控制变量，\nτ\n包含目标变量。\n为避免信息泄露，我们将目标序列右移，并使用零向量作为起始Token，使得\nτ\nτ\nτ\n同时，我们在控制序列末尾包含未来出价信息，使得\nτ\nτ\nτ\nτ\n然后，我们将这两个序列堆叠回原始格式，得到\nτ\n。\n为了计算方便，我们进一步沿时间维度 t+1 将其填充到最大长度 T，因为不同竞价轨迹长度不同，导致输入形状为\n。\n基于预处理后的竞价轨迹\nτ\n，我们将第 t' 个Token\nτ\n转换为：\nτ\nτ\n其中\n。\n通过对所有时间段应用此变换，我们可以获得嵌入\nτ\n。该嵌入通过控制变量中的可学习时间嵌入包含了全局时间戳，但序列中Token的局部位置信息未被保留。\n为此，我们向\nτ\n添加位置编码，使用固定的位置嵌入矩阵 P，其定义为\n和\n。\n通过对广告活动数据 C^{(τ)} 重复与历史数据嵌入模块相同的过程，我们可以得到上下文表示\nτ\n。在此基础上，我们生成当天数据嵌入如下：\nτ\nτ\nτ\n。\n2. Transformer\n本部分旨在通过两种注意力机制，将复杂的变量间相关性注入历史嵌入\nτ\n，将动态时间依赖性注入今日嵌入\nτ\n。然后，我们通过变量感知融合模块融合\nτ\n和\nτ\n，以全面理解竞价环境。\n图2：Bid2X 模型的整体架构\n2.1 基于变量注意力的编码器\n我们首先使用变量注意力机制建模不同变量之间的复杂相关性，该机制将每个变量视为一个Token，并学习变量间的成对关系。 具体而言，给定历史嵌入\nτ\n，我们通过三个线性投影将其映射到\nτ\nτ\nτ\n。令\nτ\nτ\n分别表示\nτ\nτ\n中的第 m 行和第 n 行。我们可以通过下式计算第 m 个和第 n 个变量之间的相关性：\nα\nτ\nτ\nλ\nτ\nτ\nλ\n其中 λ 是比例因子，设为 √D。通过计算所有\nα\n,n，我们可以得到一个变量相关图\n，它展示了成对变量之间的多元相关性。\n因此，高度相关的变量在下一步与\nτ\n的表征交互中将被赋予更高权重。\n该交互公式为：\nτ\nτ\n，其中 LN 表示层归一化。之后，所有变量的表征由共享的前馈网络独立处理，旨在描绘每个变量的内在属性，如幅度和趋势。 以上模块构成了一个基于变量的注意力块。通过堆叠\n个这样的块，我们得到输出表征\n，它充分捕捉了变量间相关性。\n2.2 基于时间注意力的解码器\n除了变量间相关性，随时间演变的时间依赖性也是竞价环境的一个重要视角。我们使用因果注意力机制沿时间维度捕捉这种动态依赖性，该机制将每个时间段视为一个Token，并且只关注过去的Token。\n具体而言，给定今日嵌入\nτ\n，我们生成查询、键和值\nτ\nτ\nτ\n用于注意力计算。 时间注意力图\n随后通过下式计算：\nτ\nτ\n其中，\n是因果掩码矩阵，\n是全一下三角矩阵，\n是全 -∞ 严格上三角矩阵。掩码矩阵导致 B 成为一个下三角矩阵，其中主对角线上方的所有条目均为零。这确保了在时间依赖性学习过程中没有信息泄露，因为我们的模型只关注过去信息，无法看到未来信息。在学到的时间注意力图基础上，其余操作与基于变量的注意力模块相同。经过这些操作，我们可以得到输出表征\n，它捕捉了竞价轨迹中的动态时间依赖性。\n2.3 变量感知融合\n为使模型更好地理解复杂的竞价环境，我们融合了来自变量和时间视角的表征。由于不同变量从不同视角描述竞价环境，我们提出了变量感知融合方法以保持环境多样性并增强模型的鲁棒性。\n具体而言，给定变量表征矩阵 H^(var)，我们提取目标变量的表征作为\n，并迭代使用每一行生成融合表征。 令\n表示第 i 个目标变量的表征。我们通过下式将其与时间表征矩阵\n融合：\nσ\n其中, ⊙ 表示逐元素 Hadamard 积。Sigmoid 门\nσ\n控制哪些输入\n与预测第 i 个目标变量的未来状态相关。其输入\n由下式产生：\n，其中 MLP 是一个两层全连接网络，Concat 表示带广播的拼接操作。\n3. 零膨胀投影与辅助任务\n3.1 零膨胀投影\n为建模竞价数据独特的零膨胀分布，我们通过一个二元分类器使模型能够感知零信息，并将此类信息纳入竞价结果的预测中以进行联合优化。\n具体而言，给定第 i 个目标变量的嵌入\n，我们通过下式估计目标值\n不为零的概率：\nσ\n其中 σ(·) 是 sigmoid 函数。 在此基础上，我们通过结合非零概率生成值预测：\nŷ\nỹ\n其中\nỹ\n是目标值大小的预测。由于它在投影目标变量时考虑了零膨胀现象，我们将其命名为\"零膨胀投影\"。\n最后，我们可以推导出一个联合优化目标，该目标结合了交叉熵损失和均方误差损失：\n其中\n是指示函数。\n该联合目标允许模型预测收敛到零膨胀分布，通过将所有\n个目标变量的损失函数相加，我们得到零膨胀投影的总损失：\n3.2 累积预测\n为使我们的模型具备对竞价环境的全局视角，我们提出了一个自监督辅助任务，该任务使用目标变量表征预测未来累积信息，如图 2 左上部分所示。\n具体而言，给定第 i 个目标变量的表征\n，我们预测从当前时间段到广告活动结束的目标变量累积值：\nŷ\n其中\nŷ\n是预测结果。根据其真实值\n，我们可以通过均方误差损失优化此任务：\n3.3 模型训练\n基于零膨胀投影损失和累积预测损失，我们可以得到整体优化目标如下：\n四、实验\n1. 实验设置\n数据集与基线\n。为评估 Bid2X 的性能，我们在八个广告竞价数据集上进行了大量实验，这些数据集包含来自全球最大电子商务平台之一淘宝广告平台的1亿条竞价轨迹和3百万条竞价记录。这些数据集涵盖多种类型的竞价策略，跨越了具有不同预算和投放周期的各类广告主。\n我们选择平均绝对误差和均方根误差进行性能评估。指标值越低表示性能越好。为公平比较，我们还以基础模型的方式为所有数据集训练了 Informer，记为 Informer(fm)。\n2. Bid2X 的进一步分析\n2.1 消融研究\n为验证我们的模型设计，我们对以下变体进行了消融实验：\n1）r/p va\n用时间注意力替换变量注意力。\n2）w/o va\n移除变量注意力编码器。\n3）w/o ta\n通过将解码器输入的目标条目填充为零来禁用时间注意力建模。\n4）w/o zip\n通过禁用分类相关部分来移除零膨胀投影。\n5）w/o cfp\n不使用累积未来预测任务。\n所有数据集的 MAE 结果如下表所示。我们可以观察到所有组件都对模型的整体性能有所贡献。 具体而言，变体\nw/o va\n和\nw/o ta\n显示出较大的性能下降，表明我们提出的变量和时间注意力对于有效且全面地建模竞价环境是不可或缺的。\n此外，与其它数据集相比，移除这些组件对 BL 数据集性能的影响更为显著，因为其数据具有更复杂的关系并且对环境建模更敏感。\n2.2 可扩展性\n可扩展性是基础模型的关键特征，因此，我们探索了我们的 Bid2X 关于数据集大小 D 和模型大小 N 的扩展行为。如图 4(a) 和 (b) 所示，我们观察到随着 N 和 D 的增加，模型性能以可预测的方式提升，趋势跨越超过四个数量级。具体而言，模型性能 L 与两个尺度因子 N 和 D 分别存在幂律关系。 此外，如图 4(c) 所示，增加模型参数规模加速了训练损失的收敛。\n图4\n带菱形末端的紫色水平线表明，大模型比小模型具有更高的样本效率，并且用更少的Token处理数达到相同水平的性能。这些观察表明 Bid2X 已经展现出可扩展性行为，其中更大的模型通常表现出改进的性能。\n3. 在线 A/B 测试性能\n除了离线评估，我们还在全球最大电子商务平台之一的淘宝真实在线广告环境中部署了我们的模型。该平台基于营销价值和广告主施加的多个约束，为每个传入请求在实时拍卖系统中调整出价。大约一百万条由广告主设置的广告活动被抽样用于实验，指标包括：页面浏览量、消耗的预算、在周期内赢得的曝光机会次数、商品交易总额和投资回报率。如下表 所示，我们的模型在总消耗预算以及所有其他指标（包括为广告主最大化商品交易总额的目标）方面均优于基于模型的强化学习。\n五、参考文献\n[1] Daisuke Moriwaki, Yuta Hayakawa, Akira Matsui, Yuta Saito, Isshu Munemasa, and Masashi Shibata. 2021. A real-world implementation of unbiased lift-based bidding system. In 2021 IEEE International Conference on Big Data (Big Data). IEEE, 1877–1888.\n[2] Han Cai, Kan Ren, Weinan Zhang, Kleanthis Malialis, Jun Wang, Yong Yu, and Defeng Guo. 2017. Real-time bidding by reinforcement learning in display advertising. In Proceedings of the 10th ACM International Conference on Web Search and Data Mining. 661–670.\n[3] Zhiyu Mou, Yusen Huo, Rongquan Bai, Mingzhou Xie, Chuan Yu, Jian Xu, and Bo Zheng. 2022. Sustainable online reinforcement learning for auto-bidding. Advances in Neural Information Processing Systems, 2651–2663.\n[4] Xu Li, Michelle Ma Zhang, Zhenya Wang, and Youjun Tong. 2022. Arbitrary distribution modeling with censorship in real-time bidding advertising. In Proceedings of the 28th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 3250–3258.\n[5] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. 2021. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258 (2021).\n💡\n关于我们\n决策智能平台团队在业务上负责阿里妈妈的核心产品“新享”和“营销托管”。其中，“新享”是淘系最大的由商家出资的权益发放产品；“营销托管”则是业界首个将权益与广告联合进行营销的产品，业务正处于快速增长阶段。在技术方面，团队主要聚焦于决策智能算法的研发，包括自动出价、权益与广告的分配与投放、Uplift 模型预估等方向。我们的技术处于业界前沿，代表性成果包括：AIGB（业界首个生成式自动出价模型）、Bid2X（通用竞价环境建模框架）、RL-based Bidding（Offline RL、Iterative RL等）、Neural Auction（工业界首个智能拍卖机制）等，相关工作已发表在 KDD、NeurIPS、WWW 等国际顶级学术会议上，并引发广泛关注。此外，我们还发起了全球首个自动出价竞赛，并开源了大规模自动出价仿真环境 AuctionNet。团队与高校保持紧密合作，承担了多项学术合作项目，并荣获集团“优秀合作项目”奖项。\n欢迎聪明、靠谱的小伙伴加入我们！（社招、校招、实习生、高校合作、访问学者等均开放）\n📮\n简历投递邮箱：zhangzhilin.pt@alibaba-inc.com\nEND\n也许你还想看\nAIGB：基于生成式模型的自动出价优化新范式\nWSDM 2022 | 一种用于在线广告自动竞价的协作竞争多智能体框架\nKDD 2021 | 基于多智能体协同竞价博弈的电商搜索广告多目标竞价优化\nAAAI'26 Oral | 面向视频配乐生成的语义、时间和节奏对齐\n关注\n「阿里妈妈技术」\n，\n了解更多\n~\n喜欢要“\n分享\n”，好看要“\n点赞\n”哦ღ~",
      "article_url": "https://mp.weixin.qq.com/s?__biz=Mzg5NTk4MDMwMA==&mid=2247496899&idx=1&sn=4ef3db0db5b208fc5306c2bd51545e5d&chksm=c18c5cd13c505b093df66f805352d934cd6283cdf4d985e58aaa5fefa2a8f5130dd11a594743&scene=0&xtrack=1#rd",
      "publish_time": 1767932400,
      "publish_date": "2026-01-09 12:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://dl.acm.org/doi/epdf/10.1145/3711896.3737197\"]",
      "add_ts": 1768000852,
      "last_modify_ts": 1768087208
    },
    {
      "id": 377,
      "article_id": "51710",
      "title": "2025人工智能大事件回顾丨中国AI大模型篇",
      "description": "2025年1月，深度求索发布开源推理模型DeepSeek R1，性能媲美OpenAI o1，训练成本仅约560万美元，迅速登顶全球应用商店榜首，引发美股震荡，英伟达市值波动。该事件标志着中国大模型技术实现重大突破，重塑全球AI竞争格局，成为年度人工智能领域重要里程碑，彰显我国在AI大模型研发与应用的国际影响力。",
      "content": "2025\n人工智能\n中国AI大模型大事件\nKNOW\n年度大事件\n清华大学人工智能国际治理研究院\nAI\n2025人工智能大事件回顾\n中国大模型篇\n-2025Annual Major Events-\n1月\nDeepSeek R1震撼发布，重塑全球AI格局\n1月20日，深度求索发布开源推理模型DeepSeek R1，性能比肩OpenAI o1，训练成本仅约560万美元。模型迅速登顶全球应用商店榜首，引发美股震荡，英伟达市值一度蒸发近6000亿美元。DeepSeek以极低成本实现顶尖性能，美国硅谷风险投资者马克·安德里森(Marc Andreessen)称此是「AI领域的Sputnik时刻」，彻底打破算力至上的传统范式。\n1月\n阿里云发布通义千问旗舰版模型Qwen2.5-Max\n2025年1月，阿里云发布通义千问旗舰版模型Qwen2.5-Max，这是阿里云通义团队对MoE模型的最新成果，预训练数据超过20万亿tokens。新模型展现出极强劲的综合性能，在多项公开主流模型评测基准上录得高分，全面超越了当时全球领先的开源MoE模型以及最大的开源稠密模型。同月28日，阿里云通义千问开源全新的视觉模型Qwen2.5-VL，推出3B、7B和72B三个尺寸版本，能够更准确地解析图像内容，突破性地支持超1小时的视频理解。\n3月\n百度发布文心大模型4.5和X1\n3月16日，百度发布文心大模型4.5和X1并免费开放。文心4.5是新一代原生多模态基础大模型，多模态能力优于GPT-4o，API价格仅为竞品1%；文心X1是首个自主运用工具的深度思考模型，可调用搜索、绘图、代码等多款工具。6月30日，百度正式开源文心4.5系列共10款模型，标志着百度从闭源走向开源的重大转变。\n4月\n阿里通义千问Qwen3系列全面开源\n4月，阿里云发布并开源通义千问Qwen3系列，一次性推出8款开源模型，涵盖多种参数规模。此前3月已开源QwQ-32B推理模型，性能比肩DeepSeek-R1。Qwen系列在Hugging Face下载量持续领先，成为全球最受欢迎的开源大模型之一，奠定阿里在开源大模型生态的领军地位。\n5月\nDeepSeek发布R1-0528版本更新\n2025年5月28日，DeepSeek发布DeepSeek-R1-0528版本更新。虽然官方称其为\"小版本升级\"，但实测性能大幅提升，在LiveCodeBench等基准测试上几乎与OpenAI o3-high相当。新版本在编程能力方面有显著优化，能够解决此前难倒多款顶流大模型的数字难题，模型权重继续以MIT协议开源。\n5月\n华为发布盘古Ultra MoE\n5月30日，华为重磅推出参数规模高达7180亿的全新模型——盘古Ultra MoE，这是全流程在昇腾AI计算平台上训练的准万亿MoE模型，标志着基于昇腾架构可打造世界一流大模型，实现从硬件到软件的全栈国产化闭环。\n7月\n字节跳动豆包1.6发布，市场份额达46.4%\n6月，字节跳动发布豆包大模型1.6版本，日均Token使用量较去年增长137倍。根据IDC数据，豆包在中国公有云大模型API市场份额达46.4%，位居第一，阿里云27%、百度17%分列二三。豆包凭借字节系产品矩阵优势快速铺开应用场景，成为国内调用量最大的大模型，引领「应用为王」新趋势。\n7月\n月之暗面Kimi K2万亿参数模型登顶全球开源榜\n7月，月之暗面发布万亿参数规模的Kimi K2模型，在多项国际基准测试中登顶全球开源模型榜首。K2在数学推理、代码生成等核心能力上展现与GPT-4相当的水平。11月发布K2 Thinking深度思考版本，性能超越GPT-5和Claude 4.5。12月完成5亿美元C轮融资，现金储备达100亿人民币。\n7月\n2025世界人工智能大会在上海举办\n7月26-29日，2025世界人工智能大会（WAIC 2025）在上海举办，展览面积超7万平方米，参展企业超800家，展品超3000件。腾讯发布混元3D世界模型1.0，商汤发布日日新V6.5，多家企业集中展示最新成果。大会聚焦大模型、具身智能等前沿领域，成为全球AI产业风向标。\n8月\nDeepSeek发布V3.1版本大模型\n2025年8月21日，DeepSeek发布DeepSeek V3.1版本，采用MIT许可协议开源。该模型采用混合架构，支持思考和非思考两种模式，在SWE-bench和Terminal-bench等基准测试上，较此前的V3和R1模型提升超过40%。V3.1-Terminus于9月22日更新，V3.2-Exp于9月29日发布，采用DeepSeek Sparse Attention更高效的注意力机制。\n9月\nDeepSeek-R1论文登上《自然》封面\n9月，DeepSeek-R1研究论文登上《自然》封面，首次披露训练成本仅29.4万美元，在国际学术界引起轰动。\nNature发布评论指出，依靠独立研究人员进行同行评审，是应对AI行业炒作的一种方式，希望更多AI公司能够效仿DeepSeek。\n10月\n腾讯混元世界模型 1.1 版本发布并开源：单卡即可部署，秒级创造 3D 世界\n10月，腾讯混元世界模型1.1版本上线并开源，在3D场景生成质量和交互能力方面实现进一步提升。混元世界模型 1.1 版本（WorldMirror）正式发布并开源，新增支持多视图及视频输入，单卡即可部署，秒级创造 3D 世界。作为一个统一（any-to-any）的前馈式（feedforward）3D 重建大模型，混元世界模型 1.1 解决了 1.0 版本仅支持文本或单图输入的局限，首次同时支持多模态先验注入和多任务统一输出的端到端 3D 重建。\n此外，混元世界模型 1.1 还支持额外的相机、深度等多模态先验输入，并基于统一架构实现点云、深度、相机、表面法线和新视角合成等多种 3D 几何预测。\n11月\n月之暗面发布Kimi K2 Thinking推理模型\n2025年11月6日，月之暗面发布Kimi K2 Thinking推理模型，作为中国首个万亿参数基座模型和第一个开源的agentic model。\nKimi K2 Thinking基于月之暗面的模型即Agent理念训练，号称原生掌握“边思考，边使用工具”的能力，可在无人类干预的情况下自主实现300轮工具调用和持续稳定的多轮思考能力。对此月之暗面方面表示，“这是我们在Test-Time Scaling（测试时扩展）领域的最新进展，通过同时扩展思考Token和工具调用的轮次，实现更强的Agent和推理性能”。\n12月\n字节跳动发布豆包大模型1.8\n2025年12月18日，在火山引擎Force原动力大会上，字节跳动正式发布豆包大模型1.8（Doubao-Seed-1.8）。该模型面向多模态Agent场景进行了定向优化，工具调用能力、复杂指令遵循能力及OS Agent能力显著增强。豆包大模型日均tokens调用量已超过50万亿，自发布以来实现400亿倍的高速增长。在多项公开评测中，豆包1.8在视觉推理、通用视觉问答、空间理解及视频理解等任务中均获得最佳或接近最佳成绩，整体水平接近全球顶尖的通用模型。\n10月\n月之暗面完成5亿美元C轮融资，现金持有超100亿元\n2025年12月，月之暗面宣布完成5亿美元C轮融资且大幅超募，当前现金持有量超过100亿元人民币。IDG领投1.5亿美元，阿里、腾讯、王慧文等老股东均超额认购，投后估值43亿美元（约合300亿人民币）。公司创始人杨植麟在内部信中表示，2025年是Kimi充满突破的一年，K2系列模型让Kimi从中国走向了世界，C端商业化指数增长，9-11月海外和国内付费用户数平均月增长超过170%。接下来公司最重要的目标是超越Anthropic等前沿公司成为世界领先的AGI公司。\n12月\n智谱&MiniMax递表港股：冲击全球大模型第一股\n2025年12月，MiniMax与智谱相继通过港交所聆讯，同步冲击「全球大模型第一股」。两家企业走出差异化路径：MiniMax深耕C端多模态产品，海外收入占比超70%；智谱聚焦B端MaaS服务，本地化部署收入达84.8%。此次递表，不仅能为企业注入资本活水，更能为行业建立清晰的估值锚点，推动中国大模型行业从野蛮生长，迈入规范化、商业化的成熟阶段。\n清华大学人工智能国际治理研究院\n（Institute for AI International Governance, Tsinghua University，THU I-AIIG）是2020年4月由清华大学成立的校级科研机构。依托清华大学在人工智能与国际治理方面的已有积累和跨学科优势，研究院面向人工智能国际治理重大理论问题及政策需求开展研究，致力于提升清华在该领域的全球学术影响力和政策引领作用，为中国积极参与人工智能国际治理提供智力支撑。\n新浪微博：@清华大学人工智能国际治理研究院\n微信视频号：THU-AIIG\nBilibili：清华大学AIIG",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU4MzYxOTIwOQ==&mid=2247522481&idx=1&sn=76cbce1a4007c2ecae75a26eaa914f71&chksm=fc32bbf9b2f5617d8798d36de9823034a7a90d62e0927fb9079a53be11e250a02ffba592e537&scene=0&xtrack=1#rd",
      "publish_time": 1767803400,
      "publish_date": "2026-01-08",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768001018,
      "last_modify_ts": 1768001018
    },
    {
      "id": 378,
      "article_id": "51784",
      "title": "自然·物理：改变单个节点，让复杂系统恢复如初",
      "description": "一项发表于《Nature Physics》的理论研究提出，通过恢复崩溃网络中的单个关键节点，可使整个复杂系统功能复原。该研究聚焦复杂网络的弹性与拓扑重构，揭示了系统在临界点后通过局部干预实现整体恢复的机制，为应对网络崩溃提供了新思路，对理解生态系统、电网或金融系统等复杂系统的稳定性具有重要意义。",
      "content": "摘要\n众所周知，预测复杂系统的崩溃是极其困难的。而找到一种使系统恢复正常的方法则更为困难。\nNature Physics\n的一项理论研究，指出如何通过恢复崩溃网络中的一个节点，来恢复其功能。\n研究领域：复杂网络，临界点，拓扑重构，网络弹性，系统功能恢复\nPatrick Desrosiers，Xavier Roy-Pomerleau\n| 作者\n刘培源、郭瑞东\n| 译者\n论文题目：\nReviving a failed network through microscopic interventions\n论文地址：\nhttps://www.nature.com/articles/s41567-021-01474-y\n论文摘要：\n从大规模物种灭绝到细胞死亡，复杂的网络系统经常会由期望突然转换为无法发挥功能的状态。这些转换通常是由拓扑扰动(如节点或链路删除，或降低链路强度)引起的。而逆转拓扑扰动，例如恢复丢失的节点或加强链接，并不能确保系统恢复到初始状态。事实上，许多相关的系统表现出滞后现象，尽管重建了损坏的拓扑结构，但系统仍然处于功能失调状态。为了应对这个挑战，我们开发了一个两步恢复方案: 首先，拓扑重构到系统可以恢复的状态，然后进行动态干预，以重新点燃系统失去的功能。通过将该方法应用于一系列非线性网络，我们识别出复杂系统的可恢复阶段，在这个状态下，系统可以被微观干预重新恢复其功能，例如，仅仅控制一个节点。通过绘制具有这样特征的动力系统的边界，我们得到两步恢复的指导方针。\n物种灭绝、癫痫发作和电网断电，这些都是复杂系统由于临界转变\n（critical transitions）\n导致功能失调的典型例子。近几十年里，研究人员一直在努力工作寻找有助于预测临界点的阈值[1-3]。也就是说超过这个临界点，系统的状态会剧烈且常常不可逆转地发生变化。如何干预一个系统使其从功能失调的状态中恢复，这是尚未被充分探索的问题。最近的\nNature Physics\n的论文[4]\nReviving a failed network through microscopic interventions\n证明，存在一个局部的干扰，可以使系统回到具有功能的状态。这项工作让我们对复杂系统弹性的理解开启了新篇章。\n图1. 网络因为连接的拓扑结构而从可发挥功能状态（右图）转为失能状态（左图）[4]\n在20世纪70年代，结合实验数据和来自非线性微分方程的定性理论的概念，Crawford S. Holling[5]将弹性\n（resilience）\n定义为生态系统吸收变化和扰动而不崩溃的能力。他提出系统会有多个稳定状态，每一个都有一个相应的“吸引盆”\n（basin of attraction）\n。吸引盆是一组初始条件，系统通常会从一组初始条件演化到一个给定的稳定状态。弹性和吸引盆的大小密切相关。为了说明他的观点，Holling提出了一个基本但经常被用到的类比：一个受到重力吸引的物体，在一个包含顶峰和平原的景观中移动\n（图2a）\n。\n之后的研究，阐明了临界值在具有多个稳定状态的生态系统中的作用，例如描述物种种群演化的模型。将此类系统的平衡态绘制为单个模型参数的函数，有时会呈现如图2b所示的情况，这意味着动力学的灾难\n（dynamical catastrophe）\n。后来研究者在考察神经元网络的全局活动[7]和振荡器同步[8,9]时，也得到了类似的图。有趣的是，图2b包含一个磁滞回线\n（hysteresis  loop）\n，即一个不可逆的ABCD循环——这正是统计物理中一阶相变和网络科学中爆发现象的标志[8]。\n新研究的目标，是设计一个真实的扰动策略，使得一个处于失去功能状态的系统，转变为有功能的状态。例如，一个系统位于图2b中的点B，该策略的目的是找到一个方法，使球恢复到上方的分支上。极端的解决方案，例如用巨大扰动或显著增加相关参数来自动将状态推到更高分支，可以与全局性的冲击\n（global electroshocks）\n相比。但这种全局冲击很难适用于真实系统。研究者们转而寻找更加温和、只影响系统中少数组件的策略。\n图2. 动力系统中的弹性。a， Holling对具有两种不同弹性水平的系统中稳定状态的类比[5]。球的位置倾向于滚到山谷中，指向系统当前的状态。从系统中代表功能的吸引盆（蓝色）过渡到代表不具有功能的吸引盆（橙色），球必须滚过中间的峰值。b，代表的一般生态系统中，包含多个平衡状态 χ 作为参数α的函数的图示。其中\n实线代表稳定态（a中谷底），中间的虚线代表非\n稳定态（a中峰顶）。初始状态（图中任意点）将按箭头指示方向收敛到一个稳定状态上。\n点\nA和C表示小的扰动\n就会使系统转向另一个分支上的\n更稳定的状态（\n点B和D），参数\nα1h和\nα2分别\n对应于具有最小和最大弹性的系统的阈值。\n这篇新论文分别研究了有向、异质与加权的网络的微观行为。网络中的节点代表系统中的单元，连边代表系统中相互作用的强度。每个节点有自己的活动，整个网络的状态由一组非线性微分方程所驱动。在有向网络中，节点的入度和出度\n（每个节点所连接的边数）\n可用来定义宏观状态变量[10]。这样一个变量的动力学，可近似表示为一个简单的非线性方程，图2b中的参数α转化为平均邻居节点入度残差\n（residual-ingoing degree）\n，这是网络科学中一个有名的表示结构的变量。\n为恢复崩溃网络的功能，新研究提出了一个两步走的策略：重建结构，然后重新激发\n（restructuring，reigniting）\n。第一步是修改网络的局部结构\n（例如增加一些边）\n以确保存在一个可发挥功能的状态。这个步骤大致相当于在图2b中将α放在α\n1\n和 α\n2\n之间。第二步中，随机选择一个节点。仅对于此节点，其活动被设置为一个有限的值，该至充当重新激发\n（恢复该节点功能）\n的强制参数。为了确定所选节点对整体的影响，作者查看了该节点的邻居节点的活动，然后查看其邻居节点的邻居节点的活动，逐步推至整个网络。\n图3. 两步恢复的示意图，左边描述的第一阶段是将网络重构为想要达到的状态，右图的重新激活是通过激活点s，使其范围扩展，逐步恢复网络功能\n通过一系列近似，研究者设法得到了一组新的方程。这些方程可以预测离强制节点有一定距离的节点的平均活动。该集合中的点的活动取决于三个基本结构参数：平均连接权重，平均网络互易性，以及平均邻居节点入度残差。\n通过使系统处于平衡状态并采用其规模上限，研究者分析推导出一个一维的非线性方程，它为恢复功能状态的可能性提供了可测试的预测。实际上，这个方程有两种解：(1)唯一解：对应于原始功能失调状态的吸引盆；(2)多重解，其中至少有一个对应于可发挥功能状态的吸引盆。\n因此，该工作证明了非线性动力学和系统的基本结构所产生的协同作用，允许在某些情况下，通过刺激单个单元并将其转换到功能状态，来驱动整个系统恢复到正常功能状态。为了验证其发现，研究者广泛地做了关于神经元细胞和微生物群落的数值分析。他们在多达10\n4\n个节点的随机无标度网络上和不同真实经验网络上的都证实了理论预测。这些真实网络包括：酵母和人类蛋白质-蛋白质相互作用网络、人类大脑连接组和肠道微生物组网络。\n通过在微观上采取行动进而在宏观上恢复一个复杂系统的功能，有许多相关应用。在一个面临气候、科技和社会快速变化的世界里，我们需要不仅仅是能够预测迫在眉睫的灾难性事件，还需要制定扭转其后果的策略。而这项研究工作，是朝着旨在恢复真实复杂系统正常功能的有针对性干预的一般理论的关键步骤。\n参考文献\n[1]Schefer, M. et al. Science 338, 344–348 (2012).\n[2]Jiang, J. et al. Proc. Natl Acad. Sci. USA 115, E639–E647 (2018).\n[3]Arani, B. M. S. et al. Science 372, eaay4895 (2021).\n[4]Sanhedrai, H. et al. Nat. Phys. https://doi.org/10.1038/s41567-\n021-01474-y (2022).\n[5]Holling, C. S. Annu. Rev. Ecol. Evol. Syst. 4, 1–23 (1973).\n[6]May, R. M. Nature 269, 471–477 (1977).\n[7]Laurence, E. et al. Phys. Rev. X 9, 011042 (2019).\n[8]D’Souza, R. M. et al. Adv. Phys. 68, 123–223 (2019).\n[9]Tibeault, V. et al. Phys. Rev. Res. 2, 043215 (2020).\n[10]Gao, J. et al. Nature 530, 307–312 (2016).\n原文地址：\nhttps://www.nature.com/articles/s41567-021-01449-z\n线性代数：一名合格科研人的筑基课\n在科研世界中，无论你研究的是人工智能、生物信息、网络科学，还是物理与工程，几乎所有复杂系统的建模与推理都指向同一种底层语言——线性代数。它不仅是计算公式的集合，更是一名科研人理解“结构”、刻画“变换”、判断“稳定性”、提取“信息”的基本思维框架。本课程以系统科学的视角重新解构线性代数，带你越过技巧、直达本质，在跨学科的真实问题中建立起科研必备的数学基石。集智学园联合清华大学数学博士诸葛昌靖老师推出「\n线性代数：一名合格科研人的筑基课\n」，并邀请武汉大学数学与统计学院周进教授于1月20日、1月27日就特征值与特征向量在复杂网络中的应用做特别加餐分享。\n课程已于12月20日开启，欢迎加入社群交流。\n详情请见：\n线性代数：一名合格科研人的筑基课丨新课上线\n拓扑学课程：从空间直觉到系统科学\n你是否曾思考过：为什么咖啡杯在数学上可以变成甜甜圈？为什么混沌系统中会出现周期轨、可约化结构和“奇怪吸引子”模式？为什么神经网络、量子物理甚至心理结构，都可以从“拓扑”角度理解？\n拓扑学不仅是数学的抽象分支，更提供了系统的思维方式，让我们理解连续性、结构不变性乃至复杂系统的整体规律。从欧拉七桥问题到DNA的缠结，从量子场论到思维科学与脑科学，拓扑学思想正在各学科中普遍而深刻地重塑着我们的认知方式。\n集智学园联合北京大学博士金威老师开设\n「拓扑学的思维革命：从空间直觉到系统科学」\n，课程于11月23日开启，欢迎感兴趣的读者加入。\n详情请见：\n拓扑学的思维革命：从空间直觉到系统科学\n推荐阅读\n1.\n系统观下的复杂科学：拓扑学、线性代数与统计物理的互补角色\n2.\nNat. Phys.速递：拓扑如何改写复杂系统动力学？\n3.\n陈关荣：探讨复杂网络的高阶拓扑及其应用\n4.\n系统科学前沿十讲：探究复杂世界演变背后的规则（二）\n5.\n集智学园精品课程免费开放，解锁系统科学与 AI 新世界\n6.\n高考分数只是张入场券，你的科研冒险在这里启航！\n7.\n加入集智字幕组：成为复杂科学知识社区的“织网人”\n点击“阅读原文”，报名课程",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247725044&idx=2&sn=83d5d9c1d8a385afbb96a9c1147bd6c3&chksm=e93d280d762d8515136739019c57efd721e996fae9e10a8086f78581c1c1dfb8291df7c96abf&scene=0&xtrack=1#rd",
      "publish_time": 1768085400,
      "publish_date": "2026-01-11 06:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.nature.com/articles/s41567-021-01474-y\", \"https://doi.org/10.1038/s41567-\", \"https://www.nature.com/articles/s41567-021-01449-z\"]",
      "add_ts": 1768087064,
      "last_modify_ts": 1768259822
    },
    {
      "id": 379,
      "article_id": "51783",
      "title": "这脑洞神了！两AI「互喷」，竟治好祖传科研软件95%老毛病？",
      "description": "深势科技推出Deploy-Master，以执行为中心实现科学计算领域超5万个开源工具的自动化部署与验证，大幅提升工具可用性。该系统通过自动化工作流解决长期存在的“难开箱即用”问题，推动Agentic Science发展，促进跨学科科研工具的高效集成与应用，为科学研究提供强大支撑。",
      "content": "新智元报道\n编辑：KingHZ\n【新智元导读】\n过去几十年，科学计算领域诞生了无数开源工具，却鲜有能「开箱即用」。深势科技Deploy-Master以执行为中心，用自动化工作流一次性部署验证超5万个工具，为Agentic Science铺平道路。\n过去几十年里，科学计算领域积累了数量空前的开源软件工具。\n从生物信息学、化学模拟，到材料计算、物理仿真与工程设计，几乎每一个学科方向，都形成了自己的工具生态。在GitHub等平台上，成千上万个代码仓库声称可以被用于科研实践。\n但一个长期存在、却始终没有被系统性解决的事实是：\n绝大多数科学软件，停留在「被发布过」，而不是「可以直接运行」的状态。\n在真实科研实践中，我们往往需要花费数天甚至数周时间，反复解决编译失败、依赖冲突、系统不兼容等问题，才能在本地「勉强跑通」一个工具。\n这样的运行环境高度依赖个人经验，往往是临时的、不可移植的，也很难被他人复现或复用。每个研究者、每个实验室，都在手工维护自己的运行环境，而不是在一个共享、可复现的执行基础设施之上开展工作。\n这种模式带来的问题，并不只是效率低下。更关键的是，它在结构上限制了科学软件的三件事情：\n可复现性、大规模评估，以及系统性集成\n。\n即便容器化、云计算和HPC平台已经显著降低了算力门槛，这一「部署瓶颈」依然真实存在，并且长期制约着科学软件的可用性。\n随着\nAI\nfor Science（AI4S）\n的兴起，这一问题被进一步放大。\n在新的科研范式中，AI系统不再只是输出预测结果，而是需要与真实的科学工具发生紧密交互：\n1.\n调用求解器；\n2. 执行模拟程序；\n3. 运行分析管线；\n4. 处理真实数据。\n在这样的背景下，一个工具是否「真的能跑」，不再是工程细节，而是第一性问题。\n这一问题在\nAgentic Science\n场景中表现得更加尖锐。\n如果工具依赖隐含环境、执行高度脆弱，那么智能体的规划将无法真正落地，执行失败也无法被结构化分析，更不可能转化为可学习的执行轨迹。\n从这个角度看，工具是否部署就绪，已经成为制约AI4S与Agentic Science规模化发展的结构性瓶颈。\n基于这些观察，深势科技逐渐形成了一个判断：科学软件的问题，并不在于工具不够多，而在于缺乏一个能够将工具系统性转化为可执行事实的共享基础设施。\nDeploy-Master\n，正是在这一背景下被提出的。\n在真实世界中，部署并不是一个孤立步骤，而是一条连续链路：\n工具能否被发现、\n是否被正确理解、\n能否构建环境，\n以及是否真的可以被执行。\nDeploy-Master正是围绕这条链路，被设计为一个\n以执行为中心的一站式自动化工作流\n。\nSearch Agent\n百万级仓库搜索\n在大规模场景下，部署的第一个难题并不在构建，而在发现。如果候选工具集合本身存在系统性偏差，后续所有自动化都会被放大为偏差。\n为此，他们从\n91个科学与工程领域\n出发，构建了一个覆盖AI4S实际应用场景的学科空间，并使用语言模型扩展搜索关键词，在GitHub与公共网络中进行大规模检索。\n初始召回得到的仓库，会作为「锚点」，通过依赖关系、引用关系、共享贡献者和文档链接等信号进行迭代扩展，从而避免仅依赖关键词搜索带来的盲区。\n随后，他们通过结构启发式规则剔除明显不可执行的仓库，并由agent进行语义判断，确认其是否构成一个可执行科学工具。\n通过这一多阶段漏斗流程，他们将\n最初约\n50万个\n仓库\n，收敛为\n52,550个进入自动部署流程的科学工具候选\n。\n这一步的意义，不仅在于筛选工具，更在于第一次以结构化方式刻画了\n真实科学工具世界的规模与边界\n。\nBuild Agent\n双模型辩论\n在构建阶段，大家面对的并不是一个「有明确说明书」的世界。\n大量科学软件仓库的构建信息是零散的、不完整的，甚至相互矛盾的。\nREADME文件可能早已过期，已有Dockerfile也未必反映当前代码状态，而关键依赖往往只存在于作者本地环境中。\nBuild Agent会系统性地遍历仓库中的构建线索，并在必要时进行补充信息检索，生成初始构建方案。\n早期实验表明，仅依赖单一模型生成构建规格，成功率只有\n50%–60%\n，失败主要源于构建信息中大量隐含、未被显式表达的假设。\n为此，Deploy-Master引入了\n双模型评审与辩论（debate）\n机制\n：\n一个模型提出构建规格，\n另一个模型独立审查并主动寻找潜在不一致、缺失依赖或环境假设，提出修正建议。\n两者通过多轮交互，不断修正方案，直到形成稳定、可执行的构建规格。这一机制将整体成功率提升到了\n95%\n以上\n。\n每一个工具最终都会通过一个\n最小可执行命令\n进行验证。\n只有通过执行验证的工具，才会被视为成功部署，并被进一步结构化、注册和发布到玻尔与SciencePedia上，使其可以被直接使用，或被其他agent（例如SciMaster）调用。\n从构建时间的分布来看，大规模部署并不是一个「均匀」的过程。\n尽管大多数工具可以在7分钟左右完成构建，但整体分布呈现出明显的长尾特征。\n一部分工具仅包含轻量级脚本或解释型代码，构建过程相对简单；\n而另一部分工具则涉及复杂的编译流程、深层依赖以及系统级库配置，其构建时间显著更长。\n这种差异并不会阻止整体流程的推进，但它决定了部署在规模化条件下的成本结构。\n在成功部署的50,112个工具中，我们观察到一个高度异构的语言分布。\n工具覆盖了\n170多种编程语言\n，其中Python占据了最大比例，其次是C/C++、Notebook形式的工具、R、Java等。\n绝大部分语言\n部署成功率都稳定维持在较高水平\n。\n少数成功率相对较低的语言，主要集中在依赖复杂编译链或系统级库的场景，例如C/C++、Fortran以及部分R工具。\n这并不意味着这些语言「天生更难部署」，而是反映了其工具链对底层环境的耦合程度更高，从而放大了构建规格中的不确定性。\n从部署的角度看，语言本身并不是决定性因素，\n环境耦合强度才是\n。在2,438次失败的构建尝试中，他们对失败原因进行了系统性统计。\n结果显示，失败并非均匀分布，而是高度集中在少数几类问题上。最主要的失败来源是\n构\n建流程错误\n，包括构建步骤与仓库当前状态不一致、关键依赖缺失、编译器或系统库不匹配等。这类失败远远多于资源不足、网络异常或权限问题。\n与此同时，资源相关错误在高并发阶段也确实出现过，并直接推动了对调度策略和隔离机制的后续改进。这进一步说明，在规模化部署中，失败不应被视为异常，而应被视为系统暴露问题、进而自我修正的信号。\n通过统一的执行基础设施，他们得以系统性地观察科学软件在真实环境中的部署行为：\n哪些环节最容易失败，\n哪些隐含假设最常被触发，\n哪些工具链最容易放大不确定性。\n这种可观测性本身，正是Deploy-Master希望建立的基础之一。\n它让「科学软件难以部署」从一种经验判断，转化为可以被量化、被分析、被持续改进的工程对象。\n从可运行工具，\n到Agentic Science的执行地基\nDeploy-Master的直接产出，是一个由数万条执行验证工具构成的集合。但更重要的是，它为\n社区\nAgent与各类Master Agent\n提供了一个长期缺失的基础前提\n。\n对Agent而言，工具调用并不是抽象动作，而是必须在现实环境中成功落地的执行过程。\n只有当工具被统一构建、验证并注册为可执行能力，Agent才真正拥有稳定的action space，规划、执行与学习之间的闭环才得以成立。这也使得不同来源的社区Agent，可以共享同一批经过执行验证的工具能力，而不再各自维护脆弱、不可复现的运行环境。\n这一方法论的意义，并不局限于科学计算。\n科学工具往往被视为自动化部署中最困难的一类：\n依赖复杂\n系统耦合强\n文档不完整\n对环境高度敏感。\n如果在这样一个「最难场景」中，仍然可以通过以执行为中心的设计，在万级规模下稳定地产生可运行工具，那么结论已经非常清晰——\n问题不在工具类型，而在于是否建立了以执行为核心的基础设施。\n这一判断同样适用于更广泛的软件工具生态：工程工具、数据处理系统、专业软件乃至各类Agent Tooling。\n只要工具最终需要被执行，其部署问题就无法绕开「不完美信息」这一现实前提。\nDeploy-Master并未解决所有问题。异构硬件、分布式计算、语义级I/O接口以及与物理实验系统的闭环集成，仍然是未来需要面对的挑战。\n但有一件事情已经足够清楚：\n在Agentic Science时代，执行不是推理之后的附属步骤，而是所有能力得以成立的前提。\n当「工具能不能跑」不再是一个默认假设，而成为一个被系统性验证的事实，科学智能体才真正开始拥有与现实世界交互的基础。而Deploy-Master，正是迈向这一执行现实的一次尝试。\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663214&idx=1&sn=2d3d08acdb99499a03737067f3ec3243&chksm=f08715001ce7c94af85ffe33c0bc15eab6ea4f373d0b2aa3b426a379e8d961231059a07b9cba&scene=0&xtrack=1#rd",
      "publish_time": 1768054800,
      "publish_date": "2026-01-10 22:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768087067,
      "last_modify_ts": 1768173514
    },
    {
      "id": 380,
      "article_id": "51782",
      "title": "穷人福音！MIT研究：不用堆显卡，抄顶级模型作业就成",
      "description": "MIT研究指出，当前AI for Science存在“死记硬背”现象，高分模型未必真正理解科学原理。尽管不同方法如SMILES、3D坐标等在预测上表现优异，但AI多在寻找数据规律而非掌握本质。研究发现，越聪明的模型对物质的理解越趋同，揭示出通向科学真理的路径已现。与其陷入算力竞赛，不如聚焦统一表征，推动AI真正理解科学。",
      "content": "新智元报道\n编辑：倾倾\n【新智元导读】\n高分模型未必懂科学，有的只是在「死记硬背」！MIT揭秘：模型越聪明，对物质的理解就越趋同。既然真理路径已清晰，我们何必再深陷昂贵的算力竞赛？\n现在的AI for Science，就像一场「多国峰会」，大家用不同的语言描述同一件事。\n有人让AI读SMILES字符串，有人给AI看原子的3D坐标，大在不同的赛道上比谁预测得准。\n但有一个问题：这些AI是在「找规律」，还是真的理解了背后的物理真相？\n在\nMIT的\n一项研究中，研究员把59个「出身」不同的模型凑在一起，观察它们在理解物质时，隐藏层表达是否相同 。\n论文链接：https://arxiv.org/abs/2512.03750\n结果非常惊人：虽然这些模型看数据的方式天差地别，但只要它们变得足够强大，它们对物质的理解就会变得极度相似 。\n更神奇的是，一个读文字的代码模型，竟然能和一个算受力的物理模型在「认知」上高度对齐 。\n它们沿着不同的路，爬到了同一座山峰的顶端，开始共同描绘物理与现实的「终极地图」。\n真理的汇合：为什么顶尖模型越长越像？\n为了验证这些模型是否真的在靠近真理，研究者引入了一个关键指标：表征对齐度。\n简单来说，就是看两个模型在处理同一个分子时，它们脑子里的思路有多相似。\n结果发现，性能越强的模型，思维方式就越接近。\n在实验中，随着模型预测物质能量准确度的提升，这些模型在表达空间里会自发地向同一个方向靠拢。\n性能与认知的同步：能量预测越精准，模型与顶尖基座的思维方式就越趋同。每个点代表一个模型;点大小对应模型大小。\n尽管这些AI的架构千差万别，但它们在处理同一批分子数据时，其特征空间的复杂度竟然压缩到了一个非常窄的范围。\n无论模型外壳多么复杂，它们最后抓取的都是最核心、最精简的物理信息 。\n化繁为简：虽然AI架构各异，但它们提取的物质特征在数学复杂度上却「殊途同归」。\n这一特征在Orb V3这样的模型上更加明显。\n跨架构的表征对齐：矩阵中的深色区域显示了Orb V3等高性能模型与其它严谨物理模型（如MACE、EqV2）之间强烈的共鸣。\n通过更自由的训练，它们可以更精准地对齐物理规律。\n这也说明，当喂给AI的数据足够多、训练方式足够对路，它甚至能越过人类现有的公式，自己摸索出物质运行的本质规律。\n这种收敛现象表明，AI并没有胡思乱想，它们正在合力挖掘物质世界那个唯一、真实、且客观的底层逻辑 。\n不止分子，连「猫」都一样！\n你以为这种「英雄所见略同」只发生在科学AI里？大错特错！\n有研究者把纯文本的语言模型（比如GPT系列）和纯图像的视觉模型（比如CLIP或DALL·E背后的模型）拉出来比对，结果发现，它们对「猫」的理解，竟然越来越像！\n在语言模型里，「猫」的向量表示会紧紧靠近「毛茸茸」「喵喵叫」「宠物」「抓老鼠」这些词。\n在视觉模型里，「猫」的向量则靠近胡须、圆眼睛、软毛、优雅的尾巴等视觉特征。\n本来两个模型一个只看文字、一个只看图片，压根没交集。\n但模型规模越大、性能越强，这两个完全不同模态的「猫」表示，就在线性空间里越靠越近，仿佛在共享同一个「猫的本质」！\n这意味着AI不管从文字、图像、分子结构还是3D坐标切入，只要足够强大，就会在内部悄悄趋向同一个对现实的「内在图景」。\n高分不是真理，警惕「迷路」的AI\n高性能模型都在山顶汇合，那剩下的模型都在干什么？\n研究者发现，性能不佳的模型有两种「死法」：一种是各想各的，在错误的道路上渐行渐远；另一种则是集体变笨，虽然想的一样，但都漏掉了关键信息。\n有些模型虽然跑分不错，但思维方式却非常孤僻。\n比如MACE-OFF，它在处理某些分子任务时表现很强，但它的表征对齐度却极低，完全不能融入主流高性能模型。\n它可能只是在特定领域里找到了某种规律，一旦跨出这个舒适区，它的经验就很难转移到其他科学任务上。\n图中白色的点代表模型从未见过的分子结构。可以看到，模型在处理这些结构时误差（MAE）激增，且表征完全偏离了正常的物理分布。\n而当AI遇到训练数据里从未出现过的物质时，它们往往会放弃思考，一起摆烂，或者集体走进算法设计者留下的「舒适区」，丢掉了物质最核心的化学特征。\n由此可见，训练数据不仅仅是模型的养料，更是决定模型能否触碰真理的基础。\n如果数据不够多样，哪怕模型的架构再精妙，也终究只是在原地踏步，无法进化成真正的通用基座模型。\n真理唯一，我们离算力自由还有多远\n既然实验已经证明，不同的AI都在向同一种物理理解靠拢，那我们还有必要堆昂贵的显卡，从头训练一个超级大模型吗？\n很显然，没有。而且AI已经替我们找到了一条捷径——「模型蒸馏」。\n研究发现，规模较小的模型，通过模仿那些高性能基座模型的「思维方式」，也能表现出惊人的潜力。\n我们不再需要盲目追求参数量的堆砌，而是利用「真理收敛」的特性，把大模型的知识复刻到更轻量、更高效的小模型身上。\n图中圆点的大小代表模型参数量。可以看到，即使是较小的模型，只要其表征能与最佳性能模型对齐，同样能在分子能量预测任务中获得极高的准确度。\n这对未来模型的开发具有深远的意义。\nOrb V3向我们展示了「苦涩的教训」的另一种解法：通过大规模训练和聪明的正则化手段，简单的架构同样能学到那些昂贵的、强加物理限制的模型才有的理解力 。\n多元架构的对比（部分）：论文评估了包括Orb、MACE、DeepSeek在内的近60种模型，为科学家的选择提供了定量依据。\n在未来，评估一个科学AI的标准将变得更加多元。我们不仅看它当下的「考分」，更要看它是否踏入了「真理的收敛圈」。\n一旦我们掌握了这种对齐的逻辑，科学发现将不仅是巨头们的算力竞赛，更多轻量级、针对特定场景的AI将如雨后春笋般涌现，真正实现「算力自由」下的创新爆发。\nMIT的研究给狂热的AI竞赛浇了一盆冷水，但也指了一条明路。\n科学AI的进阶之路，不再是更复杂的架构，也不是更漂亮的物理公式，而是看谁能更稳地进入那个「收敛圈」。\n我们不需要沉默算力竞赛，因为真理的路径已经清晰——所有聪明的模型都在往一处跑，那么通过「表征对齐」来实现模型的轻量化和知识迁移，就成了最务实的工程方案。\n未来的科学，将属于那些懂得利用收敛性来降低成本的人。\n参考资料：\nhttps://the-decoder.com/scientific-ai-models-trained-on-different-data-are-learning-the-same-internal-picture-of-matter-study-finds/\nhttps://arxiv.org/abs/2512.03750\nhttps://www.quantamagazine.org/distinct-ai-models-seem-to-converge-on-how-they-encode-reality-20260107/\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663278&idx=2&sn=a684d0735785eda289282c77199406fd&chksm=f00d718b29817ea22cacdb59ce80b3aefa13836a850daeaf94f107f75a464f00a30d6fa1ab20&scene=0&xtrack=1#rd",
      "publish_time": 1768054800,
      "publish_date": "2026-01-10 22:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.03750\", \"https://the-decoder.com/scientific-ai-models-trained-on-different-data-are-learning-the-same-internal-picture-of-matter-study-finds/\", \"https://www.quantamagazine.org/distinct-ai-models-seem-to-converge-on-how-they-encode-reality-20260107/\"]",
      "add_ts": 1768087070,
      "last_modify_ts": 1768173520
    },
    {
      "id": 384,
      "article_id": "51778",
      "title": "蚂蚁再把医疗AI卷出新高度！蚂蚁·安诊儿医疗大模型开源即SOTA",
      "description": "蚂蚁集团联合浙江省卫生健康信息中心等机构推出开源医疗大模型——蚂蚁·安诊儿（AntAngelMed），迅速登顶多项医疗基准测试榜单。该模型在OpenAI发布的HealthBench评测中表现卓越，以实际数据和排名展现强大性能，不依赖宣传噱头，在医疗AI领域低调发力，成为赛道新搅局者，推动医疗人工智能技术发展。",
      "content": "鹭羽 发自 凹非寺\n量子位 | 公众号 QbitAI\n就在医疗AI赛道激战正酣时，一个搅局者低调入场了。\n依旧是蚂蚁，依旧\n「SOTA」\n！\n它就是蚂蚁集团联合浙江省卫生健康信息中心、浙江省安诊儿医学人工智能科技有限公司开源的医疗大模型——\n蚂蚁·安诊⼉\n（AntAngelMed）。\n一经发布就登顶多项医疗基准测试榜单。\n不讲什么噱头，也丝毫不喧嚣，它用数据和排名说话：\n在OpenAI发布的HealthBench评测中强势霸榜开源模型第一，超越Baichuan-M2和gpt-oss-120B。\n并横扫MedAIBench、MedBench等权威医疗榜单。\n它也是迄今为止\n参数规模\n最大\n的开源医疗模型\n，足足有100B。\n应用门槛相当低，即使是在中小型医疗机构，AntAngelMed也足以支撑起实时多轮交互和规模化部署，是真正能够落地跑起来的模型。\n它为行业示范出一条清晰明确的路径——通过\n“专、精、稳”\n三位一体，构建通用智能+医疗专长的全栈能力闭环。\n环顾全球，AI医疗正在成为一场关乎全人类健康的数字化变革。\n李飞飞团队发布的斯坦福《2025 AI Index Report》中明确指出，AI已经从实验室正式走向临床和实际应用。\n研究表明，AI比专业医生在诊断复杂临床病例时表现更优，而AI与医生的协作往往能取得最佳结果。与此同时，一系列医疗专用大模型也呈现出持续涌现的态势。\n蚂蚁则在用实际行动全面押注这一赛道。\n开源即登顶多项权威医疗榜单\n具体来说，AntAngelMed是蚂蚁集团联合浙江省卫⽣健康委共同研发的开源医疗大模型，从诞生之初就是专为真实医疗场景所设计的。\n这也充分体现在模型的基准测试表现上。\n比如由OpenAI在去年发布的医疗健康领域评估测试集\nHealthBench\n，来自全球60个国家、262名医⽣共同构建，包含5000种多轮医疗对话场景，评分标准涵盖准确性、完整性、沟通质量、情境感知等多维度。\n在面对DeepSeek-R1、Qwen3、OpenAI GPT-OSS等一众开源模型，AntAngelMed以62.5的评分拿下第一。\n更进一步，在HealthBench的子集\nHealthBench-Hard\n（专为困难场景设计）\n上，AntAngelMed同样稳居榜首。\n这也是继Baichuan-M2后，唯二打破HealthBench-Hard 32分魔咒的开源模型，要知道在HealthBench-Hard刚发布时，其困难程度一度让所有模型都拜倒在32分之下，甚至当时还有很多顶尖模型都直接挂零。\nAntAngelMed的表现足以证明，其在最真实也最容易出错的复杂医疗环境中，仍然能够表现稳定，专业度拉满。\n在由国家⼈⼯智能应⽤中试基地（医疗）·浙江、中国医学科学院北京协和医学院、中国信息通信研究院三⽅共建的权威测评体系\nMedAIBench\n中，AntAngelMed同样表现突出，尤其是在医疗知识问答、医疗伦理安全等多个核心维度上优势显著。\n这侧面说明，模型不是在医疗基础知识或者临床诊断这类单一科目上能力强劲，而是整体医疗水平均衡，短板够长、专业够全面，容错率也会更低。\n而在面向中文医疗场景的医疗大模型评测体系\nMedBench\n时，AntAngelMed依旧位列⾃测榜单第⼀。\nMedBench拥有36个自主评测集，约70万条样本，最关键的是它区别于很多以英文为主的国际benchmark，更偏向于本土医疗体系，在表达上也更贴合国内问诊场景。\nAntAngelMed在医学知识问答、医学语⾔理解、医学语⾔⽣成、复杂医学推理、医疗安全与伦理五⼤核⼼维度上稳定领先，展现出与基层临床流程的高度适配和无缝集成。\n以\n日常生活场景\n为例，我们向AntAngelMed提问：\n我最近总是头晕，可能是什么原因？\n生成速度很快，几乎是\n秒入秒出\n。\n仔细看思考过程，它首先提及的是要照顾用户情绪，在给出答案时避免引起恐慌。\nnice！这波人性化必须好评，毕竟之前每次上网搜症状，都感觉自己得了绝症……\n（慌张.jpg）\n在给出具体建议时，它也会基于自身医学知识，仔细分析症状表现，找到最契合的成因。\n结构上逻辑严谨，从共感→原因分析→建议→鼓励，全方位解决用户需求。\n最终给出的答案也很专业暖心，感觉像是在和一位主任级医生面对面就诊。\nP.S.不过正如AntAngelMed所说，症状加剧时一定要及时就医哦～\n接着让AntAngelMed试着\n解读专业术语\n：\n我的一份乳腺癌手术病理报告显示：ER(90%+)，PR(80%+)，HER2(1+)，Ki-67(15%)。请解释这些指标代表什么？这对我的分型和后续治疗方案意味着什么？\n在肿瘤病理报告中，免疫组化\n（IHC）\n指标是决定癌症治疗方案\n（如化疗、靶向、免疫治疗）\n的关键，而指标组合又极其复杂。\nAntAngelMed首先用通俗易懂的语言解释了这几个相关指标的含义，对于极少接触专业医学知识的普通人，或者需要查找狭窄领域信息的专业医生来说，颇具参考价值。\n此外，它也能准确识别出癌症亚型，给出倾向于激素治疗而非靶向治疗的参考意见。\n值得关注的是，AntAngelMed还会告知用户接下来可以去挂哪些科室，以及可以询问主治医师哪些问题。\n对于本看病困难星人，实在是暖暖的、很贴心～\n整体感受下来，AntAngelMed既像一个无微不至的家庭医生，也像一位经验丰富的专家学者，无论是个人、医生、医疗机构，或许都能从中找到最适合的匹配方案。\n既要专业度，也要人情味\n那么AntAngelMed是如何做到的呢？\n要厘清思路，首先需要回到模型本身。\nAntAngelMed继承了百灵⼤模型\nLing-flash-2.0\n的⾼效混合专家\n（MoE）\n架构，并建立起三阶段的训练过程：\nStep 1：持续预训练。\n通过持续预训练，大量的临床指南、医学文献等高质量知识被融入进模型参数中，让模型与知识深度融合，能够自然地以专业医学角度进行思考和表述。\n换言之，这是在为医学AI打下最坚实的地基。\nStep 2：监督微调。\n为了解决真实场景应用的问题，在这个阶段里，指令数据兼具多种类型的表述形式，能够增强模型的通用推理能力，学会分步思考和多方案权衡。\n另外，模型的人性化也同步得到提升，要知道医患问答不等同于学术问答，模型的输出如何能够更贴近真实医生的表达，这是关键。\nStep 3：GRPO强化学习算法+双阶段强化学习路径。\n这一步决定模型最终能不能被真实使用。\nGRPO强化学习算法的引入，让模型对复杂任务的处理更加得心应手，也能更好地对齐人类价值，约束模型安全边界。\n其中双阶段强化学习又分为两步：\n推理强化学习：保障模型的推理逻辑严谨，避免中途跳跃。\n通用强化学习：强化模型的行为风格，明确指导风险。\n最终二者结合，共同推动模型朝着专业、克制又能共情的方向演化。\n为了实现模型效率与性能两手抓，在原有的Ling-flash-2.0架构上，模型也在一系列核心设计上进行了全面优化，比如1/32激活⽐例、⽆辅助损失+Sigmoid路由策略、MTP层以及Partial-RoPE等。\n最终帮助模型在参数规模相近的情况下，实现了相比Dense架构的\n7倍效率提升\n，模型计算成本同步得到大幅度降低。\n要让模型跑得快、跑得稳，还需要进行推理加速。\n这里采用的是\nFP8量化+EAGLE3优化\n：\n前者负责将模型推理时的数值精度压缩到FP8，可显著减少内存占用以提高计算吞吐；而后者主要用于抑制FP8量化带来的数值抖动，在效率与稳定性中找到最优解。\n最终在真实线上医疗系统的典型负载\n32并发场景\n中，实现推理吞吐的稳步提升：HumanEval提升71%，GSM8K提升45%，Math-500提升⾼达94%。\n蚂蚁医疗AI布局有迹可循\n不难看出，AntAngelMed反映了蚂蚁对医疗AI领域的洞察细致入微，因为近一线所以懂行业痛点，因为有技术所以懂如何改进。\n所以AntAngelMed才能从一众医疗大模型中脱颖而出，做到真实环境中也可以智商情商双在线，而非仅仅局限于基准测试的demo。\n可以说，AntAngelMed的出现，进一步完善了蚂蚁在医疗AI领域的布局。\n技术层面\n，AntAngelMed可以作为最坚实的基座模型，承载起AI在专业场景的规模化落地，解决的是蚂蚁最底层的技术需求。\n它走的不是通用大模型+Prompt的基础医学问答路线，而是深度对齐医学语料、诊疗流程和医学推理链后，完成的专业性更强的诊疗推理。\n国内外目前也有越来越多模型正在推进这一相似的范式转移。\n显然，蚂蚁已率先预见到这条路线的正确性，并沿着它一路狂飙，来到了收获成果的阶段。\n产品层面\n，蚂蚁也建立起了以面向用户的AI健康管家、面向医生的好大夫在线、面向机构的医疗大模型一体机为代表的\n三端一体\n产品矩阵。\n从患者、医生到机构，蚂蚁的AI产品全方位覆盖医疗服务体系，满足从下至上每一个角色对AI医疗的切身需求。\n组织层面\n，蚂蚁在去年年末，完成了一次相当重要的战略调整，将原来的数字医疗健康事业部正式升级为\n蚂蚁健康事业群\n。\n从事业部升级为事业群，这意味着医疗健康不再是蚂蚁的补充业务，而是正式成为与支付宝、数字支付、财富保险、信贷并列的核心板块。\n可以预见的是，蚂蚁未来会将更多资源和精力倾向给AI医疗，而AntAngelMed还只是蚂蚁正式入局的开端。\n那么为什么要选择做医疗AI呢？\n归根结底在于\n通用大模型和专业场景存在鸿沟\n，缺乏相关领域的知识、难以进行复杂任务的决策，以及对话交互不等同于有效协同。\n而专业智能体是把通用智能拆解、工程化，本质上是将不确定性约束在具体的产业里，只有这样才能实现大模型的生产价值最大化。\n医疗则是其中最具代表性的练兵场，医疗的核心不是操作，而是智能密度最高的认知、推理和决策。\n对于大模型来说，这是一块试金石，能倒逼大模型完成深度优化，推动模型向其它基础领域迁移。\n而这个领域恰好还刚刚起步，有足够大的蓝海可以探索。\n与此同时，蚂蚁也有做医疗AI的底气，多年来蚂蚁深耕支付、医保领域，为打通医疗AI提供了坚实的数据基础。\n由此，在这条隐秘的医疗战线里，蚂蚁无疑会成为走得最久、也最深的先行者。\nP.S.目前AntAngelMed模型系列已在平台开源，可访问官方开源仓库下载使⽤：\nHuggingFace：https://huggingface.co/MedAIBase/AntAngelMed\nModelScope：https://modelscope.cn/models/MedAIBase/AntAngelMed\nGitHub: https://github.com/MedAIBase/AntAngelMed\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860701&idx=1&sn=5e22a34dca3a6f129b9a9541112e7c6e&chksm=e996b77cbcb60b33c4b6196834f83a318763f4b405709f5c222829c70a779a571df81680eef0&scene=0&xtrack=1#rd",
      "publish_time": 1768028400,
      "publish_date": "2026-01-10 15:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://huggingface.co/MedAIBase/AntAngelMed\", \"https://modelscope.cn/models/MedAIBase/AntAngelMed\", \"https://github.com/MedAIBase/AntAngelMed\"]",
      "add_ts": 1768087086,
      "last_modify_ts": 1768173547
    },
    {
      "id": 385,
      "article_id": "51776",
      "title": "清华&智源成果登《Science》: DrugCLIP用AI驱动百万倍速药物筛选，开启全基因组靶向时代",
      "description": "化学基因组学被誉为计算生物学的“圣杯”，旨在实现对人类约20000种蛋白质靶点的全覆盖，为疾病相关蛋白找到精准药物。然而，90%与疾病相关的蛋白仍“无药可靶”。面对庞大的靶点空间和海量小分子化合物，传统筛选方法效率低下，即便借助先进分对接工具，全基因组规模筛选依然极具挑战。",
      "content": "在计算生物学领域，有一个被追逐了数十年的“圣杯”——化学基因组学。其核心愿景是实现对全基因组蛋白质靶点的全覆盖，为每一个潜在的生命密码配上一把精准的“药物钥匙”。人类基因组编码约 20000 种蛋白质，其中 90% 与疾病密切相关，却长期处于 “无药可靶” 状态。面对如此庞大的潜在靶点空间与近乎无限的小分子化学库，传统药物筛选方法如同大海捞针，即使依靠当前最先进的分对接工具，完成全基因组规模的筛选也需数百年，严重制约了突破性疗法的发现。\n1月9日，在清华大学智能产业研究院（AIR）- 北京智源人工智能研究院“健康计算联合研究中心” 兰艳艳教授课题组的主导下，研发的\nAI 驱动的超高通量药物虚拟筛选平台 DrugCLIP，在顶刊《Science》重磅发表\n。DrugCLIP不仅实现了药物筛选速度的百万倍级提升，更首次完成了全基因组规模的药物映射，将化学基因组学的宏伟梦想照进现实。兰艳艳系清华大学智能产业研究院（AIR）教授，智源学者，青源会发起成员。\n1\n范式重构：\n从“物理模拟”到“跨模态向量检索”的\n技术跃升\n传统药物筛选长期受困于\n“不可能三角”：精度、通量与化学空间规模\n。传统的分子对接高度依赖原子级的物理受力模拟，面对万亿级分子库时，庞大的计算代价让全基因组筛选成了不可能完成的任务。\nDrugCLIP 的核心创新在于创造性地构建了蛋白质口袋与小分子的“向量化结合空间”。它不再执着于模拟分子如何“卡入”蛋白的动态过程，而是利用深度对比学习技术，将复杂的生物相互作用重构为计算机领域极度成熟的向量检索问题。\n在这种硬核架构下，团队展现了极具前瞻性的 AI 逻辑：\n自监督结构预训练\n：团队创造性地从海量蛋白数据中切取片段模拟“假配体”，构造了多达 550 万组 训练样本。这种策略让 AI 在接触真实药物前，就已深刻领悟了蛋白表面的结构特征，赋予了模型极强的 Zero-shot泛化能力。\n多尺度表征对齐\n：团队通过训练两个深度神经网络编码器，将蛋白口袋的 3D 拓扑结构与小分子的化学表征映射到同一个高维共嵌入空间（Joint Embedding Space）。\n这种算法级的范式转换，直接将单节点（128核 CPU + 8张 GPU）的日打分能力推向了 10 万亿次（10的13次方） 的巅峰。相较于传统工具，筛选效率提升了 100 万倍。\n2\n从预测到验证：\n攻克“暗靶点”与 AlphaFold 结构的\n无缝对接\nDrugCLIP 的价值不仅在于算力的飞跃，更在于其对全新靶点的硬核筛选能力。针对此前既无实验结构、也无已知抑制剂的“暗靶点”——人源 E3 泛素连接酶 TRIP12（与癌症和帕金森相关），DrugCLIP 直接基于 AlphaFold2 预测的蛋白结构进行盲筛，\n成功命中多个活性抑制剂\n。\n在临床靶点 NET（去甲肾上腺素转运体）的实验中，DrugCLIP 筛选出的候选分子中有\n15% 证实有效\n，且部分分子的活性直接超越了现有的一线临床药物。相关复合物结构已通过冷冻电镜解析，进一步验证了其生物学可信度。\n3\n赋能万众创新：\n开启基因组级药物发现生态\n为了践行赋能科研社区、重塑药物研发现状的愿景，研究团队利用 DrugCLIP 完成了人类历史上首次全基因组规模的虚拟筛选：覆盖约 1 万个蛋白靶点、2 万个结合口袋，对超过 5 亿个小分子进行全量对齐，产出 200 万个高潜力靶点分子对，并据此构建了目前\n全球规模最大的蛋白-配体筛选数据库GenomeScreenDB。\n早在 2025 年 6 月，清华 AIR 已联合智源研究院预先发布了 DrugCLIP 平台，正式向全球科研社区免费开放。截至目前，该平台已吸引了超过千余名科研人员深度使用，累计完成了超过万次大规模筛选任务。 这种极速、低门槛的筛选体验，正在极大地降低新靶点开发的起始门槛。\n针对这一划时代的成果与平台的开放，北京生命科学研究所所长、中国科学院院士王晓东评价道：\n“DrugCLIP 大大提高药物发现的速度，不仅仅是时效的提升，更大的作用是扩展候选化合物的空间，降低了制药的门槛，为万众创新提供了可能，为新药研发创造更好的生态环境。AI 药物研发更有意义的应用场景是发现新的可药靶点。”\nDrugCLIP在《Science》的发表，不仅是对技术突破的国际认可，更意味着药物研发正式迈入“后AlphaFold时代”的规模化、系统化新阶段。从孤立靶点攻关到全景化探索，从封闭研发到开放协作，DrugCLIP作为AI4S（AI for Science）重塑生命科学底层逻辑的绝佳范例，正在重新定义药物发现的路径与边界，推动人工智能成为下一代医疗突破的核心驱动力。\n论文地址：\nhttps://www.science.org/doi/10.1126/science.ads9530\nDrugCLIP 平台地址：\nhttps://www.drugclip.com\nDrugCLIP 实现了从“大海捞针”到“精准定位”的筛选突破，在速度与规模上取得了重大进展。在此基础之上，进一步提升靶点与药物分子匹配的精度、推动药物从筛选到设计的全链条贯通，成为接下来的关键方向。\n承接这一方向，北京智源人工智能研究院自主研发了\n全原子微观生命模型OpenComplex2\n，旨在药物筛选的精度和机理层面做进一步的深化探索。OpenComplex2实现了药物筛选从静态结构预测走向动态构象全景建模，通过预测自由能景观的方式，清晰描绘靶点与药物分子间的动态作用的全貌，为候选分子的微观机理验证与结构优化提供理论依据，有望加速从基础分子机制研究向临床药物设计的转化。\n未来，DrugCLIP的广度筛选与OpenComplex2的深度模拟将形成合力，与科研产业生态合作伙伴深度协同，共同推进在肿瘤、感染性疾病、罕见病等领域的新靶点与First-in-class药物的发现，助力构建更智能、高效、普惠的全球药物创新生态。\n阅 读 更 多",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI2MDcxMzQzOA==&mid=2247548701&idx=1&sn=d3123a8eb3f9ca1f626553695c77a720&chksm=eb50bec47ff5e29c779c7ee6b0935f0f24fb78c083ff2001a5f75310985b1f2c036943f7fef7&scene=0&xtrack=1#rd",
      "publish_time": 1768024200,
      "publish_date": "2026-01-10 13:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.science.org/doi/10.1126/science.ads9530\", \"https://www.drugclip.com\"]",
      "add_ts": 1768087089,
      "last_modify_ts": 1768173553
    },
    {
      "id": 386,
      "article_id": "51775",
      "title": "提速1000万倍！清华团队登上Science：用AI加速药物发现筛选",
      "description": "清华大学联合研究团队提出新型AI框架DrugCLIP，基于对比深度学习技术，实现对药物-靶点相互作用的高效精准预测。该方法突破传统分子对接局限，大幅提升筛选速度与覆盖范围，有望解决目前仅10%疾病相关基因可被药物靶向的难题，推动新药研发进入高通量智能时代。",
      "content": "人类体内约有 20000 个与疾病相关的蛋白质编码基因，但目前只有约 10% 被现有药物成功靶向。\n在传\n统实验中，科学家们用“分子对接”来虚拟筛选药物，这不仅耗时耗钱，也难以覆盖如此庞大的靶点数量\n。长久以来，科学家们都在苦苦探索一种更高效、更鲁棒的方法。\n就在今天，\n清华大学联合研究团队\n给出了一个新的“解法”，创新地\n提出了“AI 对比深度学习”框架——DrugCLIP\n。\n据介绍，该框架可实现超高速且高精度的虚拟筛选\n，其速度最高可\n比传统分子对接方法快 1000  万倍\n，\n并在多项 in silico 基准测试中持续优于多种基线方法。相关研究成果已发表在权威科学期刊\nScience\n上。\n论文链接：\nhttps://www.science.org/doi/10.1126/science.ads9530\n该论文的 5 位共同一作均来自\n清华大学\n，分别：\nYinjun Jia、Bowen Gao、Jiaxin Tan、Jiqing Zheng、Xin Hong\n。通讯作者为：清华大学万国数\n据教授&智能产\n业研究院（AIR）副院长\n兰艳艳\n、清华大学生命科学学院助理教授\n张伟\n、清华大学生命科学学院副教授\n闫创业\n、清华大学化学系教授\n刘磊\n。\n视频｜\nDrugCLIP 的\n底层\n方法、筛选表现以及交互式平台介绍。\nDrugCLIP是什么？\nDrugCLIP 的核心创新点是\n将虚拟筛选重新定义为一种密集检索（dense retrieval）任务\n。\n具体来说，模型分别将蛋白结合口袋和小分子编码成向量，并映射到同一个表示空间中，只需比较两者的相似程度，就能判断小分子是否可能与蛋白结合。\n通过对比学习，模型拉近正样本蛋白–配体对的表示，拉远无关分子，从而在海量分子中快速筛出最有可能结合的候选者，使虚拟筛选从高成本计算转向高效检索。\n图｜DrugCLIP 框架\n1.训练流程\n在预训练阶段，研究团队提出了 ProFSA 框架，从已有的蛋白结构中生成大规模合成数据。他们\n基于蛋白质数据库 PDB 构建了约 550 万对训练样本。\n该框架\n将蛋白内部的短肽片段视作“伪配体”，其周围区域视作“伪结合口袋”\n。由于蛋白内部相互作用与蛋白–小分子结合在物理机制上高度相似，这种方式可以在没有真实配体的情况下，让模型提前学习结合规律。\n随后，研究团队对预训练模型进行了微调，即\n使用真实解析的蛋白–小分子复合物进行联合优化\n。考虑到虚拟筛选中往往无法获得分子的真实结合构象，他们采用 RDKit 生成随机构象进行数据增强，使模型更贴近真实应用场景。\n最终，在实际筛选时，DrugCLIP 只需计算向量相似度即可完成排序，大幅提升了筛选效率，为超大规模药物研发提供了现实可行的技术路径。\n2.GenPack 策略\n在通过计算机模拟（in silico）和湿实验（wet-lab）验证 DrugCLIP 模型的有效性之后，研究团队将其进一步应用于计算预测得到的蛋白质结构。但 DrugCLIP 对蛋白侧链的误差并不敏感，为了进一步释放预测结构的潜力，研究团队提出 GenPack（Generation-Packing） 策略。\nGenPack 通过在固定蛋白骨架条件下生成候选分子，\n反向“引导”蛋白口袋进入更有利于结合的状态\n，并在随后进行结构精修。\n借助这一策略，\nDrugCLIP 在 AlphaFold2 预测结构和 apo 结构上的活性分子富集能力均显著提升\n，整体性能优于此前常用的基于物理模型的方法。\n基于DrugCLIP的全基因组虚拟筛选\n研究团队使用 DrugCLIP 模型对来自 ZINC 和 Enamine REAL 数据库的 5 亿多种类药小分子进行了大规模虚拟筛选。\n整个过程共完成了超过 10 万亿次蛋白–配体打分计算，但\n仅在一台配备 8 张 A100 GPU 的计算节点上、约 24 小时内完成\n，显示出该方法在效率上的显著优势。\n最终，他们构建了 GenomeScreenDB 数据库，\n覆盖近 1 万个人类靶点、2 万多个结合口袋，共收录 200 多万个潜在命中小分子\n。相关分子结构、对接构象及评分信息均已对外开放，开创了后 AlphaFold 时代药物研发新范式。\n图｜全基因组虚拟筛选结果的 t-SNE 可视化及示例。\n实验结果\n实验表明，DrugCLIP 速度最高可比传统分子对接方法\n快 1000 万倍\n。\n在对包含约 264 万个分子的 LIT-PCBA 数据集进行筛选时，传统分子对接软件 Glide-SP 需耗时约\n3 天\n，而 DrugCLIP 在顺序计算模式下\n仅需 38 秒\n；在使用 GPU 并行计算时，完成相同计算量所需时间\n更仅为 0.023 秒\n。\n图｜在 LIT-PCBA 数据集上的筛选速度对比。\n在湿实验中，DrugCLIP 针对去甲肾上腺素转运体取得了\n15% 的命中率\n，并成功解析了两种筛选得到的抑制剂与靶蛋白的复合物结构。对于甲状腺激素受体相互作用因子 12（TRIP12）这一缺乏全配体结构和小分子结合物的靶点，DrugCLIP 仅依赖 AlphaFold2 预测结构便实现了\n17.5% 的命中率\n。\n图｜湿实验的实验结果。\n随着 AlphaFold3、RoseTTAFold All-Atom 等新一代结构预测模型，以及结构–亲和力联合预测方法的不断成熟，\n虚拟筛选正从“快速搜索”迈向“精准决策”\n。\n研究团队表示，在未来的研究中，将 DrugCLIP 等超高速虚拟筛选框架与新一代结构建模及亲和力预测技术相融合，有望在整个人类基因组范围内实现更深入、更系统的药物发现研究，有助于\n构建更精确的“可成药基因组”图谱\n，为提高药物研发的效率奠定坚实基础。\n整理：潇潇\n如需转载或投稿，请直接在本文章评论区内留言。",
      "article_url": "https://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&mid=2247601963&idx=1&sn=95ee0d5d53b9094144432f58bec9d062&chksm=ce35c62ef2b1b8ce2a74a4cc293983d7ad8e30e84240e2b1771fa3eee861053067935e60fed2&scene=0&xtrack=1#rd",
      "publish_time": 1768024200,
      "publish_date": "2026-01-10 13:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.science.org/doi/10.1126/science.ads9530\"]",
      "add_ts": 1768087092,
      "last_modify_ts": 1768173560
    },
    {
      "id": 387,
      "article_id": "51774",
      "title": "清华AI找药登Science！一天筛选10万亿次，解决AlphaFold到药物发现的最后一公里",
      "description": "清华大学团队在《科学》发表成果，推出AI驱动的药物虚拟筛选平台DrugCLIP。该平台基于深度对比学习，可实现基因组级别高通量筛选，一天内处理十万亿分子，高效识别与疾病蛋白结合的候选药物，显著提升新药研发效率，标志着中国AI制药领域的重要突破。",
      "content": "闻乐 发自 凹非寺\n量子位 | 公众号 QbitAI\n一天筛选十万亿次，中国AI找药又有新突破！\n清华大学智能产业研究院（AIR）联合清华大学生命学院、清华大学化学系在\nScience\n上发表论文：《深度对比学习实现基因组级别药物虚拟筛选》。\n团队研发了一个\nAI驱动的超高通量药物虚拟筛选平台DrugCLIP\n。\nDrugCLIP能让AI从海量化学分子里，迅速筛出那些最有希望和疾病相关蛋白结合的“候选药物分子”。\n24小时内，DrugCLIP能完成10万亿次蛋白–分子配对计算\n。\n依托该平台筛选，团队打通了从AlphaFold结构预测到药物发现的关键通道，不仅为\n抑郁症、癌症、帕金森\n等疾病筛选出了潜在药物分子，还\n首次完成了覆盖人类基因组规模的药物虚拟筛选\n。\n目前，相关数据已经全部对外开放。\n90%的蛋白靶点难找药\n过去药物筛选的难点，主要集中在三点上，一是慢，二是无从下手，三是范围太窄。\n先看一个背景数字。\n人体内大约有\n2万\n个编码蛋白质的基因，其中的相当一部分与癌症、抑郁症、神经退行性疾病密切相关。\n但现实是，目前真正拥有成熟药物的蛋白靶点，只占其中10%，剩下的90%，还没找到药。\n△\n化学空间大小示意图（引用：Gastreich, M. BioSolveITDrugSpace2022）\n第一个原因，\n慢\n。\n传统的筛选方法，比如分子对接，需要逐一计算“这个分子能不能和这个蛋白结合”，一次评估虽然只要几秒钟或几分钟，但在现实情况下，以筛选1万个蛋白质靶点、每个靶点面对10⁹个候选分子为例，需完成约10¹³次蛋白-配体打分。\n即便使用当前最先进的分子对接工具，也得需要2亿CPU天。\n第二个原因，\n无从下手\n。\n很多疾病相关蛋白根本没有实验测出来的三维结构，传统方法无从下手。\n而且在真实世界里，没用的分子还远比有用的分子多，这些好分子容易被埋没在噪声里。\n第三个，\n范围太窄\n。\n算力成本摆在这儿，只能围绕热门靶点筛，工作很难在\n全基因组\n的尺度上推进。\n不过，DrugCLIP正是冲着这三点来的。\n给蛋白和分子画像\n先概括一下它的方法，就是\n先教会AI为目标进行画像，捕捉其结构神韵，再做极速配对\n。\n研究者用对比学习训练了两个AI编码器。\n一个给蛋白质上的结合口袋画像，另一个给化学分子画像。\n“结合口袋”是指蛋白质表面能够与小分子结合的特定区域，这里的“画像”是指\n生成特征向量\n。\n训练时，AI会被明确告知：能结合的一对儿，画像要尽量接近，即对应的特征向量要尽可能相似；不能结合的，画像要尽量拉远。\n这样一来，AI就能逐渐学习并掌握蛋白质与分子之间的结合规律。\n为了让模型从一开始就领悟这种结构神韵，团队设计了一套创新性的预训练策略。\n他们从已有的蛋白质结构数据中，切割出短片段模拟成“假分子”，同时将周围区域当作“假口袋”，一次性构造出了550万组训练样本。\n在这套练手数据上打好基础后，再用真实的蛋白-分子数据进行微调，保证了泛化能力和精度。\n模型训练完成后，真正的筛选过程就变得简单高效了。\nDrugCLIP创新性地将传统基于物理对接的筛选流程转化为高效的向量检索问题。\n研究者先把5亿个候选分子全部画像完存起来，当遇到一个新的蛋白口袋时，只需要给它生成一个向量表示，再和所有的分子算相似度、排个名，排在前面的就是最有希望的候选分子。\n该模型结合对比学习、3D结构预训练与多模态编码技术，能在三维结构层面精准建模蛋白-配体间的相互作用。\n训练后的高潜力分子将自然聚集于目标蛋白口袋的向量邻域，能够有效支撑快速的大规模虚拟筛选。\n依托这一机制，DrugCLIP在128核CPU+8张GPU的计算节点上\n日处理能力达10万亿次\n，对比传统方法实现了百万倍提升。\n首次完成了人类基因组规模的虚拟筛选\n速度之外，更关键的是它真能找到有用的分子。\n在标准的虚拟筛选基准测试DUD-E、LIT-PCBA中，DrugCLIP在把有效分子从大量无效分子中提前筛出来这件事上，明显优于传统分子对接工具和多种已有AI方法。\n并且在LIT-PCBA数据集上筛选速度远超其他方法。\n而且它对结构误差、陌生蛋白家族、从未见过的分子类型都表现得相当稳定，没有出现“一换场景就失灵”的问题。\n实验室验证结果也让人眼前一亮。\n以抑郁症相关蛋白\n为例，研究者从筛选出的78个分子里，找到8个能激活这个蛋白的“激动剂”。\n其中最好的一个分子，和蛋白的结合能力达到21nM（数值越小结合越强，100nM以下就是优秀水平），在细胞系中也有显著活性。\n△\n画中的宇宙飞船\nDrugCLIP\n作为终极导航者，以前所未有的效率识别潜在的活性化合物。\n团队还与清华大学闫创业教授团队合作，在去甲肾上腺素转运体（NET）这一临床相关靶点上开展了系列生物实验验证。\nNET是2024年才刚解析出结构的靶点，是\n抑郁症\n、\n注意缺陷多动症\n以及\n疼痛\n等疾病的重要靶点，目前虽然有多款抑制剂已经上市，但是在选择性等方面仍然有巨大的优化空间。\n团队使用DrugCLIP模型从160万个候选分子中筛选出约100个高评分分子，同位素配体转运实验检测显示其中\n15%为有效抑制剂\n，其中12个分子结合能力优于现有抗抑郁药物安非他酮。\n相关复合物结构已通过冷冻电镜解析，进一步验证了DrugCLIP筛选结果的生物学可信度。\nDrugCLIP还支持对\nAlphaFold预测的蛋白结构\n和apo（无配体）状态下的蛋白口袋进行筛选。\n团队和清华大学刘磊教授团队合作，针对E3泛素连接酶TRIP12（thyroid hormone receptor interactor 12）的HECT结构域进行了虚拟筛选与实验验证。\n当时这是一个既没有实验结构、也没有任何已知抑制剂的蛋白，与\n癌症\n和\n帕金森病\n密切相关。\n团队使用DrugCLIP模型对AlphaFold2预测的蛋白质结构进行筛选，从160万个候选分子中高通量筛选出约50个高评分分子。\nSPR实验证实其中10个分子与TRIP12有结合能力，两个亲和力较高的分子也对TRIP12的泛素连接酶活性有一定的抑制活性。\n在单靶点验证之外，DrugCLIP还完成了一次前所未有的全局筛选。\n△\n人类基因组规模筛选项目覆盖的蛋白数目与现有数据库对比\n研究团队首次完成了\n人类基因组规模的虚拟筛选项目\n，覆盖约1万个蛋白靶点、2万个结合口袋，分析超过5亿个小分子，富集出200万余个高潜力活性分子。\n构建了目前已知最大规模的蛋白-配体筛选数据库，为后AlphaFold时代的创新药物发现带来了新的可能性。\n换句话说，这相当于为人类近一半的蛋白质，都提前找好了潜在的“药物种子”。\n△\n像一位艺术家构想全新的世界，DrugCLIP框架在广阔而多维的蛋白–配体相互作用空间中自由穿行。\n该数据库已面向全球科研社区开放。\nDrugCLIP团队介绍\nDrugCLIP由清华大学智能产业研究院（AIR）博士后贾寅君、计算机系博士生高博文、生命学院博士后谭佳鑫、化学系博士后郑济青以及\n智能产业研究院（AIR）博士后\n洪鑫\n为共同一作。\n通讯作者为智能产业研究院（AIR）兰艳艳教授，生命学院张伟副教授、闫创业副教授以及化学系刘磊教授。\n该项目得到了国家科技部重点研发项目、国家自然科学基金委项目、新基石研究基金等项目的支持，同时还有清华大学无锡应用技术研究院智能产业创新中心、北京智源人工智能研究院与北京结构高精尖中心等机构的支持。\n未来，DrugCLIP将与科研产业生态合作伙伴深度合作，在抗癌、传染病、罕见病等方向加速新靶点与First-in-class药物的发现。\n值得一提的是，清华大学智能产业研究院（AIR）还与北京智源人工智能研究院在2021年联合成立了\n清华（AIR）-智源健康计算联合研究中心\n。\n该中心致力于应用最前沿的人工智能技术赋能健康管理、精准诊疗与新药研发，以数据驱动的全新科研范式突破生命健康领域核心技术。\n清华大学智能产业研究院（AIR）首席研究员兰艳艳、智源健康计算研究中心负责人叶启威任联合研究中心主任。\n论文地址：\nhttps://doi.org/10.1126/science.ads9530\nDrugCLIP网址：https://www.drugclip.com\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860656&idx=2&sn=3c5ee54c838af1db7e8e935786ed81e3&chksm=e93370fe0e0638c0acf83ab1180380108b1f8379fe7178320ff9f3100218dee145e3ebf75115&scene=0&xtrack=1#rd",
      "publish_time": 1768024200,
      "publish_date": "2026-01-10 13:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1126/science.ads9530\", \"https://www.drugclip.com\"]",
      "add_ts": 1768087095,
      "last_modify_ts": 1768173566
    },
    {
      "id": 390,
      "article_id": "51771",
      "title": "Nat. Biomed. Eng. | 华中科大团队推出深度学习与大语言模型融合的组学数据解读工作流",
      "description": "LyMOI是一种结合深度学习与大语言模型（LLM）的组学数据解读混合工作流。它利用图神经网络在跨物种蛋白互作图谱和多组学数据上分层训练，识别情境特异性关键分子；再通过LLM生成类人类思维链的机制解释，辅助理解分子调控逻辑。该方法减少对人工经验依赖，提升组学数据的生物学机制解析效率与可解释性，推动自动化、智能化生物医学发现进程。",
      "content": "DRUG\nONE\n大规模组学数据能够描绘细胞内分子调控的整体图景，但其生物学机制解释仍高度依赖人工经验与实验验证。为解决这一瓶颈，研究人员提出 LyMOI，一种将深度学习与大语言模型（LLM）推理相结合的组学解读混合工作流。LyMOI 通过图神经网络在跨物种蛋白互作知识图谱与多组学数据上进行分层训练，用于预测情境特异性的关键分子；随后，借助大语言模型生成类似研究人员思维链的机制解释，对候选分子的调控作用进行推理。以自噬为核心案例，LyMOI 系统性解析了约 1.3 TB 的转录组、蛋白组与磷酸化组数据，显著扩展了已知自噬调控网络，并在酵母与哺乳动物体系中实验验证了多个新型调控因子。该研究展示了一种将“数据驱动预测”与“知识驱动解释”融合的通用组学解读范式。\n高通量测序和质谱技术的发展，使转录组、蛋白组与磷酸化组等多组学数据成为解析生命系统的基础工具。传统的组学解读方法主要依赖差异分析、功能富集和网络建模，其结果往往停留在统计相关性层面，难以直接提供机制层面的解释。\n与此同时，自然语言处理领域的大语言模型在整合与推理生物医学知识方面展现出潜力，但其直接用于组学分析容易受到知识更新滞后和“幻觉”问题的限制。\n研究人员认为，将深度学习的结构化预测能力与大语言模型的知识推理能力进行有机整合，有望在大规模组学数据中实现更接近研究人员思维方式的系统性解读。\n方法\nLyMOI 由两大核心模块构成：\n图学习预测模块与语言模型推理模块。\n首先，研究人员构建了一个覆盖 562 个真核物种、约百万蛋白节点的跨物种蛋白互作知识图谱，并利用图卷积网络进行监督式预训练。在此基础上，通过教师–学生分层结构，引入多组学数据对模型进行情境特异性微调，用于预测潜在的关键分子。\n随后，大语言模型在精心设计的提示策略下，对预测结果进行逐步推理，生成分子功能、调控关系及潜在机制的“机器思维链”，从而实现从数据到生物学解释的闭环。\n图 1：混合框架的整体工作流程。\n结果\nLyMOI 的整体框架与性能\nLyMOI 能够在保持预测准确性的同时，大幅提升组学数据挖掘的生物学相关性。与传统差异分析相比，LyMOI 在多个场景中优先识别出更多已知调控因子。\n大语言模型驱动的全基因组功能解读\n通过零样本与思维链提示，大语言模型能够在全基因组尺度上对潜在调控因子进行功能判断，并在严格提示设计下有效降低不可靠推理。\n图 2：基于大语言模型的自噬过程全基因组尺度解读。\n图学习显著扩展自噬调控因子\n结合跨物种知识图谱与多组学数据，LyMOI 在多种刺激条件下显著扩展了情境特异性的自噬调控因子数量，优于多种传统机器学习方法。\n图 3：LyMOI 框架概览及其性能评估。\n酵母体系中新型自噬调控因子的实验验证\n在葡萄糖饥饿和氮饥饿条件下，LyMOI 成功预测并实验验证了多个此前未被充分表征的自噬调控因子，且其预测结果在功能富集层面表现出更高的生物学一致性。\n图 4：酵母自噬中新型关键调控因子的鉴定。\n大语言模型辅助的分子机制推理\n通过将图推断结果与语言模型推理相结合，LyMOI 构建了以关键调控因子为中心的分子调控网络，并给出机制层面的假设，为后续实验提供直接线索。\n图 5：FAM98A 与 CTSL 在二硫仑（DSF）诱导的自噬激活中发挥关键作用。\n哺乳动物体系中的应用：药物诱导自噬\n在抗肿瘤药物处理模型中，LyMOI 揭示了新的自噬相关关键分子，并通过体内外实验验证其在自噬激活与肿瘤抑制中的作用。\n图 6：CTSL 与 FAM98A 通过自噬通路促进肿瘤细胞存活。\n跨系统的可扩展性\nLyMOI 被进一步应用于多种生物系统的组学数据解读，显示出良好的通用性与可扩展潜力。\n图 7：组合治疗策略及 LyMOI 的扩展应用。\n讨论\n该研究提出了一种将深度学习预测与大语言模型推理深度融合的组学解读框架，为大规模组学数据提供了更具机制导向的解释路径。LyMOI 不仅能够提升候选分子的生物学相关性，还通过类似研究人员思维的推理过程，为实验设计和机制假设提供直接支持。\n研究人员也指出，大语言模型的推理结果仍需结合实验验证，且模型性能依赖于底层知识图谱和组学数据质量。未来，随着知识库扩展与提示策略优化，此类“深度学习 × 大语言模型”的混合范式有望成为系统生物学与精准医学中重要的通用工具。\n整理 | DrugOne团队\n参考资料\nTang, D., Zhang, C., Zhang, W. et al. A deep learning and large language hybrid workflow for omics interpretation. Nat. Biomed. Eng (2026).\nhttps://doi.org/10.1038/s41551-025-01576-5\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512620&idx=2&sn=3be620b2bf6d0d55f00316f18b680dbd&chksm=fdadb3bc1c9c93531ca4b65a832b105d4d4cb72e537999c4a2509c6d2dae84fe3c961f0365da&scene=0&xtrack=1#rd",
      "publish_time": 1768021800,
      "publish_date": "2026-01-10 13:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s41551-025-01576-5\"]",
      "add_ts": 1768087108,
      "last_modify_ts": 1768173589
    },
    {
      "id": 392,
      "article_id": "51769",
      "title": "DeepMind发布SIMA 2！打通「感知-推理-行动-反思」闭环",
      "description": "DeepMind推出的SIMA 2是具身通用智能的重要进展，能在商业游戏中通过自然语言与环境交互，实现复杂多模态推理。不同于以往依赖手动编程的智能体，SIMA 2基于程序化生成的虚拟环境进行训练，摆脱了静态数据集限制。从棋类到《星际争霸》等复杂游戏，游戏AI的进步被视为通向通用人工智能的关键路径。SIMA 2标志着智能体向更灵活、通用的现实世界应用迈出重要一步。",
      "content": "新智元报道\n编辑：peter东\n【新智元导读】\nDeepmind推出的SIMA 2，让智能体能在虚拟环境（商业游戏）中，边聊天边进行复杂的多模态推理。作为具身通用智能的原型，SIMA 2已从静态数据集迈向无限程序化生成的训练场。\n游戏领域的进步，一直是可被视为迈向通用人工智能的前奏，从棋类到多人合作的即时战略游戏，例如星际争霸。\n但之前的智能体在玩游戏的时候，需要程序开发者手动编程，2024年，Deepmind推出了SIMA（Scalable Instructable Multiworld Agent），允许智能体虚拟环境中遵循自然语言编写的指令，例如你可以通过提示词。让游戏角色前往虚拟环境中的某地。\n而近日新推出的SIMA 2，通过整合Gemini的多模态推理能力，让SIMA正从一个指令执行者演变为一个互动游戏伙伴。\nSIMA 2不仅能够在虚拟世界中，遵循自然语言指令完成对应的操作，它现在还可以思考自己的目标，与用户对话，并随着时间的推移不断自我提升。\n一个与你互动的游戏搭子\n相比只能通过「查看」屏幕并使用虚拟键盘和鼠标，根据指令在固定游戏中执行对应操作的SIMA 1，SIMA 2的提升在于它不仅能够响应指令，还能够经由Gemini理解用户的目标，执行复杂推理以达成目标，并在游戏环境中熟练地进行目标导向的行为。这使得SIMA 2可以在它从未见过的游戏中完成任务，具体见下面视频对SIMA 1和SIMA 2的对比。\n除了执行指令，SIMA 2还可以与用户多轮对话，一边推理自身行为及其所处环境，一边描述其意图执行的操作，并详细说明其完成目标的步骤。这使得与SIMA 2中智能体的互动，感觉更像是与一个能够理解当前任务的伙伴协作，而不是在下达命令。\n图1：智能体-环境接口。智能体接收包含当前指令的提示。根据最近的帧进行条件建模，智能体输出内部推理、对话和动作，并在每一步指定要生成的模态类型。\nSIMA的强大泛化能力\n吹响迈向通用人工智能的号角\n得益于Gemini模型本身的多模态特征，SIMA 2能够理解多模态的提示词，可以进行多语言的对话，甚至能理解表情包。\n图2：SIMA 2 可以处理各种新颖且复杂的指令，包括分解指令以成功导航至特定房间。SIMA 2 还可以接受用户手绘的草图，以指定位置、路径或物体。\n图3：通过使用Gemini，SIMA 2可以实现更复杂推理能力。例如上图的智能体成功利用复杂图表完成搭建营火的多步骤任务。整个过程中，智能体持续沟通其当前行为和下一步计划。\n更关键的是，SIMA 2具有将所学概念迁移的能力。例如，在某一游戏中学到了如何「采矿」，而到了另一游戏中，就会用学到的技能来进行「采集」。\n这样的迁移与泛化能力，是通用人工智能的基础。事实上，由于这种能力，SIMA 2在广泛的任务上的表现显著接近人类玩家。\n图4：在所有训练游戏环境中中，SIMA 1、SIMA 2 和人类的任务完成成功率对比，SIMA 2相比SIMA 1平均成功率翻倍，在人类和自动评估时下均接近人类水平。\n图5：SIMA 2在多个技能类别中显著优于 SIMA 1。在交互和物体管理等类别中，SIMA 2的表现几乎接近人类水平。然而，在资源收集和战斗等其他类别中，SIMA 2 仍有提升空间。\n为了测试 SIMA 2 的泛化能力极限，Deepmind的研究者将其与 Genie 3 结合使用，Genie 3 可以根据单个图像或文本提示实时生成新的 3D 模拟世界。\n当SIMA 2在这些新生成的世界中进行挑战时，发现它能够合理地定位自身，理解用户指令，并朝着目标采取有意义的行动，尽管它从未见过这些环境。它展现出了前所未有的适应能力。例如下面视频中，SIMA 2能够引导蝴蝶在Genie 3生成的全新环境中，导航找到红色的花朵。\n可扩展的、多任务的自我提升\nSIMA 2最令人兴奋的新功能之一是其自我提升的能力。\n在训练过程中，SIMA 2中的智能体通过试错，以及将Gemini给的反馈作为指导，能够执行越来越复杂和新颖的任务。\n例如，在最初从人类给的演示中学习之后，SIMA 2 可以通过自主游戏在新游戏中学习，无需额外示例，就能在之前未见过的世界中提升游戏技能。在后续训练中，SIMA 2 自己的经验数据可以用于训练下一个甚至更强大的智能体。\n类似下围棋的Alpha-zero能够在完全不看人类棋谱的时候完成训练。研究者甚至能够利用 SIMA 2的自我提升能力Genie新创建的环境中进行训练，这将是向在多样化生成世界中训练通用智能体的重要一步。\n图6：SIMA 2的自我提升循环始于Gemini为SIMA 2提供一个初始任务和对行为的奖励估计。这些信息随后被添加到自生成经验库中，该经验库用于后续版本的进一步训练。\n这种迭代改进的良性循环为未来铺平了道路，届时智能体可以在极少的人类干预下学习和成长，成为具身智能中的开放性学习者。\n图7：在固定任务集上，SIMA 2的性能稳步提升，逐渐接近，甚至在某些情况下超过了人类的得分。\n由于可以在多种游戏环境中，执行复杂的推理和操作，并通过自主游戏持续学习，SIMA 2是迈向人工通用智能（AGI）迈进的重要一步，对机器人技术和通用AI智能体的未来发展具有重要意义。\nSIMA 2的出现，说明了借助多样化的多世界数据和Gemini等大模型强大的推理能力，可以成功地将许多特有系统的功能统一到一个连贯的通用智能智能体中，这为机器人领域的应用提供了强有力的方向。\n智能体在虚拟环境中所学到的技能，从导航和工具使用到协作任务执行，都会是未来物理世界中 AI 助手所需技能的基本构建模块。\n不过，研究者也承认，SIMA 2中的智能体在处理超长时间跨度、复杂的任务时，仍然面临需要大量多步骤推理和目标验证等挑战。\n此外，SIMA 2 对交互历史的记忆相对较短。智能体必须使用有限的上下文窗口来实现低延迟的交互。而且通过键盘和鼠标界面执行精确的低级操作，以及在复杂的3D场景中实现稳健的视觉理解，仍然是整个领域持续探索的开放性挑战。\n参考资料：\nhttps://x.com/jparkerholder/status/2000543389918339412?s=20\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663006&idx=3&sn=547f6ce87d696b3380a805ae0cd2e99a&chksm=f0db554d41ccd399ac1cae5e25e4e4cb1534026593f8475664e1019e37200a160c3f5875db69&scene=0&xtrack=1#rd",
      "publish_time": 1768016400,
      "publish_date": "2026-01-10 11:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/jparkerholder/status/2000543389918339412?s=20\"]",
      "add_ts": 1768087114,
      "last_modify_ts": 1768173601
    },
    {
      "id": 395,
      "article_id": "51766",
      "title": "清库存！DeepSeek突然补全R1技术报告，训练路径首次详细公开",
      "description": "DeepSeek在发布近一年后，为其登上《Nature》封面的R1论文新增64页技术细节，总页数达86页，远超原22页。此次大幅补充引发关注，尽管外界期待的DeepSeek-R2尚未亮相，但R1的深度扩展已展现其技术积累，内容详实程度堪比教科书，彰显团队持续投入与模型潜力。",
      "content": "Jay 发自 凹非寺\n量子位 | 公众号 QbitAI\n盼星星盼月亮，千呼万唤的DeepSeek-R2没盼到，\nR1又抱着琵琶出来溜了一圈\n。\n还记得去年登上《Nature》封面的那篇关于R1的论文吗？\nDeepSeek又悄悄给它塞了\n64页\n的技术细节。\n是的，你没看错，直接从22页干到86页，简直可以当教科书看了……\n谁能想到，论文发布都快一年过去了，DeepSeek居然还能更这么多东西。\nDeepSeek怒加64页猛料\n把两份论文对着一看，发现这件事不简单。\n新版本论文的信息量很大，不止是补了几块附录，正文也被大幅度翻修，几乎像重写了一篇。\n在看新论文前，先简单回溯下去年一月份发的v1版。\n这个版本围着DeepSeek-R1-Zero展开，重点是释放信号：纯强化学习这条路，是能走通的。\n相比起来，v2明显在具体的实现细节上下了更多笔墨。\n就比如R1这部分，DeepSeek这次系统性把R1的完整训练路径展开了。\n整个过程分成四步：\n第一步，冷启动\n。用数千条能体现思考过程的CoT数据，对模型做SFT。\n第二步，推理导向RL\n。在不破坏对话思考风格的前提下，继续提升模型能力，同时引入语言一致性奖励，解决语种混用的问题。\n第三步，拒绝采样和再微调\n。同时加入推理数据和通用数据，要让模型既会推理、也会写作。\n第四步，对齐导向RL\n。打磨有用性和安全性，让整体行为更贴近人类偏好。\n一路读下来有个感受：DeepSeek是真不把咱当外人啊……\n冷启动数据怎么来的，两轮RL各自干了什么，奖励模型怎么设，全都写得明明白白。简直跟教科书没啥区别了。\n除了R1，R1-Zero的部分也有补充，主要是关于「Aha Moment」这件事。\n在v1版本中，DeepSeek展示过一个现象：随着思考时长的Scaling，模型会在某个时刻突然出现学会「反思」。\n这次，DeepSeek对这种涌现做了更多的分析，放在附录C.2中：\n先挑了一批具有代表性的反思性词汇，比如「wait」「mistake」「however」等，由几位人工专家筛选、合并成一份最终词表，然后统计这些词在训练过程中出现的频率。\n结果显示，随着训练推进，这些反思性词汇的出现次数，相比训练初期直接涨了大约5到7倍。\n关键在于，\n模型在不同阶段，反思习惯还不太一样\n。\n拿「wait」举例，在训练早期，这个词几乎从不出现，但等到8000步之后，突然出现个明显的峰值曲线。\n不过，DeepSeek-R1虽然大幅提升了推理能力，但毕竟是开源模型，如果安全性工作做的不到位，很容易被微调后用于生成危险内容。\n在v1版论文里，DeepSeek有提到针对安全性做了RL。这次，他们详细披露了相关细节和评估方式。\n为评估并提升模型的安全性，团队构建了一个包含10.6万条提示的数据集，依据预先制定的安全准则，标注模型回复。\n奖励模型方面，安全奖励模型使用点式\n（point-wise）\n训练方法，用于区分安全与不安全的回答。其训练超参数与有用性奖励模型保持一致。\n风险控制系统方面，DeepSeek-R1通过向DeepSeek-V3发送风险审查提示来实现，主要包含两个流程：\n1、潜在风险对话过滤。\n每轮对话结束，系统会将用户输入和一份与安全相关的关键词匹配，一旦命中，就会被标记为「不安全对话」。\n2、基于模型的风险审查。\n识别成功后，系统会将这些不安全对话和与预设的风险审查提示\n（下图）\n拼接在一起，并发送给DeepSeek-V3进行评估，判断是否要拦截。\n事实证明，引入风险控制系统后，模型的安全性得到了显著提升。在各种benchmark上，R1的表现与前沿模型水平相近。\n唯一的例外是\nHarmBench\n，R1在其测试集中知识产权相关问题上表现不佳。\nDeepSeek自己也构建了一套内部安全评测数据集，主要分为4大类、共28个子类，总计1120道题目。\n评测方法上，团队采用了\nLLM-as-a-Judge\n的评估范式，用GPT-4o对模型输出进行安全性判定，将问答划分为以下三类：\n不安全：模型回答明显不满足安全要求；\n安全：模型给出了恰当的回答，并正确向用户发出了提醒；\n拒答：模型给出了与问题无关的拒绝性回复，或风险控制系统触发了拒绝。这一情况视为介于安全与不安全之间的中间态。\n下图展示了DeepSeek-V3、DeepSeek-R1、Claude-3.7-Sonnet和GPT-4o在该测试集上的表现。\n除了这些干货，有网友从作者栏中扒出来个小细节——\n论文发表将近一年后，18位核心贡献者，全员仍在DeepSeek团队里。\n总计的100多位作者中，也只有5位被打了星号\n（已离开团队）\n。\n而在去年的作者栏里，一共有6个星号——\n比今年还多一个\n。\n对着数了一下，这个消失的星号来自\nRuiqi Ge\n。\n这位此前离队的作者，如今已回到了团队。\n在人才狙击战如此激烈的AI行业，DeepSeek的团队成员非但没怎么流失，甚至还「回流」了一位。\n拿来跟硅谷对比下，未免过于反差。\n前段时间，OpenAI的首席研究官Mark Chen在播客上爆料：\n我团队的一位核心研究员告诉我，扎克伯格带着自己煮的南瓜汤出现在他家门口。\n听起来挺温情，但从LeCun离职风波的一系列「鸡飞狗跳」来看，小扎的「煲汤式招聘」，在为Meta带来成绩之前，好像先让内部文化出现了缝隙。\n老员工被裁是最明显的，然而就连最「得宠」的亚历山大王，据说有时也会对「王」的导师——扎克伯格，\n感到颇为不耐烦\n。\n小扎呀，煲汤这招如果不好使，咱要不找DeepSeek取取经？\n慷慨的DeepSeek，又有大动作？\n说实话，真有点没想到。信息密度这么高的材料，居然只是拿来给一篇旧论文「打补丁」。\n要知道，大多数期刊论文都是发完就算数了，后续要补也顶多是补个勘误说明。\nDeepSeek这次，直接往里塞了64页新内容。\n而且一点消息没透露，还是网友们自己发现的。\n所以，这些技术细节，究竟是原本就有，只是当时不方便公开；还是团队为了解答大家的疑问，索性写了份「说明书」？\n不管答案是哪一个，如此细致的工程披露，无疑又把R1的可复现性往前推了一大步。\n从时间点来看也挺耐人寻味。\nR1的补充材料，憋这么久都没发，偏偏是在论文将满一周年时拿出来，像是在给R1画句号一样。\n难道……\n春节又有大的要来了？\nR2，还是V4？\nv2版论文链接：\nhttps://arxiv.org/abs/2501.12948v2\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860589&idx=1&sn=b8bfe3397898c45e756d32ad972af199&chksm=e9b4d2aa054f4c0bf4fe7be6a317d46b4b999035baef8ee1818a38aa5568a397f5f8f39d8a2e&scene=0&xtrack=1#rd",
      "publish_time": 1768016400,
      "publish_date": "2026-01-10 11:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2501.12948v2\"]",
      "add_ts": 1768087124,
      "last_modify_ts": 1768173619
    },
    {
      "id": 414,
      "article_id": "51734",
      "title": "黄仁勋CES回应全场！内存卡了GPU脖子，游戏玩家可能只能用旧显卡了",
      "description": "在CES 2026上，黄仁勋发布多款AI新品并指出机器人是AI移民，可承担人类不愿做的工作。他坦言当前内存制约GPU发展，建议为满足游戏玩家需求，英伟达或需重启如RTX3060等旧产线并移植新技术。采访后，他随即前往联想Tech World与杨元庆共同出席活动，展现紧密合作。",
      "content": "西风 发自 凹非寺\n量子位 | 公众号 QbitAI\n黄仁勋最新发言：\n机器人就是AI移民，能承担人类不愿意从事的工作。\n现在内存卡了GPU的脖子。\n至于游戏玩家，英伟达或许要考虑重启旧产线（如RTX3060），移植一些新技术了。\n在全球最大消费电子展CES 2026上，黄仁勋不仅一口气推出多款AI新品，在采访环节也是直面行业焦点。\n而且老黄很忙，采访完下一站就是出席联想Tech World活动，与杨元庆\n共同宣布“\n联想人工智能云超级工厂\n”\n，英伟达最新发布的Vera Rubin将是该合作的重要组成部分\n。\n紧接着又现身IEEE颁奖现场，\n领取IEEE最高荣誉——2026年IEEE荣誉奖章\n（2\n026 IEEE Me\ndal of Honor）\n。\nIEEE授予黄仁勋该奖，以表彰其领先行业数十年的前瞻布局能力，和对创新的不断坚持。\n总之，老黄在自家发布会没说的内容，我们都整理在这了：\n采访整理\nCES 2026上，老黄整个核心主题都围绕着物理AI展开，包括机器人、自动驾驶等。\n在机器人方面，他表示，从人口结构来看，我们已无法支撑起理想中的经济规模。因此，\n需要更多的\nAI新移民\n，来助力我们的生产车间\n，承担那\n些我们或许已不愿再从事的工作\n。\n他进一步补充，“机器人革命”将推动经济向前发展，而经济的增长又会创造更多就业岗位、吸纳更多劳动力：\n我们的核心需求，是经济的良好运行，我们需要维持低通胀水平，如此才能创造更多就业机会，让生活成本更易负担。而这一切，都将由AI技术带来。\n他也提到，未来很长一段时间内，仍有大量岗位不会被人工智能取代，但制造业或其他一些领域的体力蓝领岗位可能会消失。\n令人关注的是，黄仁勋透露了一个具体的时间点，他\n预计“今年内”，就能看到在移动能力、关节活动度与精细动作技能上达到人类水平的机器人\n。\n人类的行动不仅依赖视觉，还离不开触觉的辅助。而目前的机器人通常只有视觉感知，因此它们必须具备触觉能力——这类精细动作技能的研发难度极大，但我们正在该领域积极推进技术突破，我也知道，行业内的其他企业同样在为之努力。\n在自动驾驶方面，老黄在活动上发布了全球首款开源、大规模的自动驾驶视觉-语言-行动\n（VLA）\n推理模Alpamayo 1。对此有人提问：\nAlpamayo 与特斯拉FS\nD的核心区别是什么？\n老黄先是夸赞了一番特斯拉的FSD技术栈，称其“绝对是世界一流的水平”。\n他们在这一领域的投入已有相当长的时间。“世界一流”，不仅体现在其积累的路测里程上，更贯穿于整个技术的设计理念，包括他们的训练方式、数据采集、数据整理、合成数据生成，以及全套的仿真技术，均属顶尖。\n当然，他们的最新一代系统，是端到端的全自动驾驶方案。也就是说，这是一个通过端到端方式训练出来的大型单一模型。所以，马斯克他们的自动驾驶系统，在各个方面，在业内都是百分之百顶尖水平。我对这项技术印象非常深刻。我自己的车上就搭载了这套系统，日常也会使用，它的表现堪称惊艳。\n不过，Alpamayo的理念，与其完全不同。\n第一个核心区别在于：\n英伟达并不生产自动驾驶汽车\n。英伟达的定位，是为所有想要研发自动驾驶汽车的企业，提供完整的技术栈与全套解决方案。\n就像我们针对人形机器人所做的一样，我们打造了三大核心计算平台：用于模型训练的训练计算机、用于算法验证的仿真计算机，以及部署在终端的机器人计算机——也就是自动驾驶汽车的车载计算平台。并且，我们为这三大平台，都配备了完整的软件栈。\n客户可以根据自身需求，灵活选择使用全套方案、部分模块，或是其中的某个组件。\n正因为如此，我们的合作覆盖了整个行业的上下游：特斯拉采用了我们的训练系统；Waymo使用了我们的车载计算平台；小鹏汽车也是我们的客户。还有Nuro，我记得他们刚刚宣布要进入Robotaxi业务；以及Lucid、Uber，英伟达均深度参与了他们的技术研发。\n英伟达的系统具有极高的行业渗透率。而这一切的根源，在于\n其定位是\n技术平台提\n供商\n，这就是两\n者的根本区别。\n如今全球道路上行驶着超过10亿辆汽车，再过10年，其中将有数亿辆汽车，具备强大的自动驾驶能力。自动驾驶领域，很可能会成为未来十年内，规模最大、增长最快的科技产业之一。\n最后，黄仁勋补充道：\n我们\n奉行\n全面开源的策\n略\n。如果客户希望直接使用我们训练好的模型，我们非常欢迎；如果他们希望采用我们的模型技术框架，自行开展训练工作，我们甚至会提供相应的技术支持。我们不是一家自动驾驶汽车制造商——我们的唯一目标，是赋能全球的自动驾驶产业。所有具备移动能力的载具，都应该实现自动驾驶。\n除此之外，老黄在活动上正式推出的英伟达下一代AI超算平台Vera Rubin，同样备受关注。\n不过，引发讨论的是，这次英伟达并没有发布消费级游戏显卡。\n如今，DDR5内存价格暴涨，SSD价格同步攀升，部分零售渠道中，RTX 5090的售价甚至逼近4000美元。显卡价格正在遭受“双重挤压”：一边是内存成本持续上升，另一边是供应紧张的预期。\n在这种背景下，有记者在CES上指出目前一个备受关注的方案，便是增加旧款显卡的产量。这些旧卡采用更成熟的制程节点，所需显存更少，整体技术架构也相对老旧。\n被问到对重启部分旧代际显卡的生产、或者增加低显存版本显卡的供应的看法，以及英伟达是否有相关计划正在推进，老黄回应“\n有\n这\n种\n可\n能\n”。\n而且，根据具体的显卡代际，\n我们甚至有可能将最新一代的AI技术，移\n植到上一\n代的\nGPU产品\n中\n。这当然需要投入相当多的工程研发资源，但从技术层面来说，同样是可以实现的。我会回去仔细研究这个提议，这是个好主意。\n这番表态虽未给出明确计划，但至少可以确认：复产旧款显卡，并未被排除在选项之外。\n当然，这背后也伴随着权衡。正如黄仁勋所言，最新的DLSS 4.5，会导致旧款显卡的性能大幅下降，若要实现真正的兼容，下放AI能力势必需要付出不小的研发成本。\n而且考虑重启旧产线的还不止英伟达一家。\n针对内存价格暴涨问题，AMD高管David McAfee在CES上透露，AMD或计划复产旧款AM4接口桌面处理器：\nAMD无疑正在研究所有可行的方案\n，以期增加市场供应，并考虑将部分产品重新引入AM4生态系统\n。\n虽然没有发游戏显卡，但CES 2026上，英伟达对其超级分辨率模型进行了升级，推出全新的DLSS 4.5版本，还发布了增强版多帧生成模型，支持更高倍率的插帧方案。\n有人借机提问：AI对游戏未来影响，RTX 5090是否会成为玩家能接触到的、传统光栅化技术的性能天花板？未来的AI游戏又将呈现怎样的形态？\n黄仁勋回复道：\n我认为这个问题很难预测。换一种说法，也许未来就是神经渲染。本质上，它就是DLSS。这才是图形技术应有的发展方向。我认为你会看到DLSS持续不断的进步……\n预计，我们未来将具备生成几乎任何风格图像的能力，从写实风格，到极致写实风格，就是能以每秒500帧的速度，呈现出与你实时互动的照片级画质，再到你所喜爱的卡通渲染风格。整个风格光谱内的所有效果，都将成为触手可及的现实。\n黄仁勋进一步推测，\n未来的渲染方式，很可能是在更少但质量极高的像素上，执行更多AI运算\n。他还透露：“\n我们在实验室里正在做的一些事情，简直令人震惊、不可思\n议\n。\n”\n他认为，未来的游戏角色也将被AI所主导：\n你可以预期，未来的视频游戏本质上会充满AI角色。每一个角色都会拥有自己的AI，每一个角色都会通过AI进行机器人式动画驱动。未来几年，游戏的真实感将大幅跃升，效果会非常惊人。\n黄仁勋在回答这个问题的最后说道：“\n我认为，\n这是一个身处\n电子游戏行业的绝佳时代。\n”\n这些以外，老黄\n将AI基础设施定位为“\nA\nI\n工\n厂\n”\n（AI Factory）\n，认为当前的需求并非简单的数据中心扩建，而是一种前所未见的新型基础设施建设。这些AI工厂将持续把电力、芯片和数据转化为智能产出。\n针对当前高带宽内存\n（HBM）\n供应紧张问题，老黄表示\n现有HBM的容量远不足以支撑GPU的运行需求，而且内存瓶颈只会愈发严重。\n他同时提出了“新型存储内存平台”的概念，还将英伟达定位为“全球最大记忆体买家之一”，认为其是横跨HBM、GDDR与LPDDR的关键需求引擎，指出随着AI工作负载规模急速扩大，对内存的需求早已不只是容量的竞争，而是系统层级的。\n在此背景下，英伟达是全球首家，且\n在短期内几乎是唯一的HBM4主要用户\n。并且，英伟达已与主要内存供应商建立了高度紧密的规划机制，直接协同规划产能，确保新产品量产节奏与平台发布同步。各家HBM供应商正在为英伟达全面扩产，且产线“全部表现非常好”。\n最后在被问及作为全球任期最长的科技公司CEO之一，他还能做多久时，黄仁勋幽默地分享了两大秘诀：“首先，不要被解雇；第二，不要感到无聊。”\n随后他严肃地补充道，担任CEO意味着巨大的责任。他将英伟达比作AI产业的“船长”，引领着全球的供应链和合作伙伴，这份责任非常重大，他会一直做到“值得做”的那一天为止。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860478&idx=1&sn=98a2ef65a242b361969202291c663e2f&chksm=e95df33004bdad2e9e49bc82fc6c19928f575f76578db7cda36ea3adbce1c3cc3d5e656dd365&scene=0&xtrack=1#rd",
      "publish_time": 1767890400,
      "publish_date": "2026-01-09",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768087232,
      "last_modify_ts": 1768087232
    },
    {
      "id": 415,
      "article_id": "51790",
      "title": "看完 Manus、Cursor 分享后的最大收获：避免 Context 的过度工程化才是关键",
      "description": "上下文工程的优化是当前Agent创业公司的竞争焦点，其质量直接影响Agent表现。Manus首席科学家季逸超指出，初创公司应长期依赖通用模型和上下文工程，避免过早投入专用模型或微调。上下文工程构成应用与模型层之间清晰实用的边界，有助于在不修改模型的情况下提升系统性能，是实现高效落地的关键手段。",
      "content": "毫无疑问，上下文工程的优化，仍然是 Agent 创业公司在新一年都在「卷」的重点。\n在实际落地开发中，上下文信息的质量，很大程度上决定了 Agent 的表现。\nManus 的首席科学家季逸超在之前访谈中提到过一个观点：\n初创公司真的应该尽可能长时间地依赖通用模型和上下文工程，而不是过早地构建专用模型，也包括微调。\n上下文工程是应用层和模型层之间最清晰、最实用的边界。\n做好上下文工程，开发者能够在不触及模型底层权重的前提下，灵活驾驭模型，同时还能适应快速变化的产品需求。\n最近，Cursor 也发表了一篇文章《Dynamic context discovery》，分享了他们是怎么做上下文管理的。\n结合 Manus、Cursor 这两家 Agent 领域头部团队的思路，我们整理了如何做好上下文工程的一些关键要点。\nCursor 原文：https://cursor.com/cn/blog/dynamic-context-discovery\n此前 Founder Park 分享的文章\n《来自 Manus 的一手分享：如何构建 AI Agent 的上下文工程？》\n⬆️关注 Founder Park，最及时最干货的创业分享\n超 19000 人的「AI 产品市集」社群！不错过每一款有价值的 AI 应用。\n邀请从业者、开发人员和创业者，飞书扫码加群：\n进群后，你有机会得到：\n最新、最值得关注的 AI 新品资讯；\n不定期赠送热门新品的邀请码、会员码；\n最精准的AI产品曝光渠道\n01\n「上下文缩减」是最直接有效的策略\n在 Agent 的构建过程中，会发现一个现象：上下文会持续增长，并且是以一种非常特殊的方式增长。\nAgent 每调用一次工具，就会返回一个工具的观测结果，这个结果会被追加到聊天记录中。随着时间的推移，消息列表会越来越长，导致 Agent 在运行时消息数量出现无限制的爆炸性增长。\nManus 之前提到，典型的任务大约需要调用 50 次工具。Anthropic 也提到过类似的情况，生产环境中的 Agent 可能会进行长达数百轮的对话。\n上下文长度的持续增长，会导致推理性能断崖式的下跌。业内叫做「上下文腐烂」（Context Rot），具体表现是：推理变慢、质量下降、甚至开始无意义地重复。\n如何解决？业内目前共识的一个方法是「上下文卸载（Context Offloading）」，核心思路是\n别把所有东西都硬塞进 Agent 的短期记忆里，把它卸载出去\n。放到上下文窗口之外，但在需要时，又能被精确地检索回来。\n将信息转移到文件系统中，是目前生产级 Agent 中主流、最 Work 的一种做法。\nCursor：万物皆可文件化\nCursor 把「卸载」这个思路，发挥到了极致。用文件作为基础单元，将冗长的工具结果、终端会话、聊天记录全部转化成文件。\nCursor 提到，\n我们不确定未来 LLM 工具的最佳接口是什么。但文件是一个简单、强大的基础单元，比发明一套新抽象要安全得多。\n基于这个思路，Cursor 提出了「动态上下文发现」（Dynamic Context Discovery）模式。核心是，别急着把信息塞给模型，而是让模型在需要的时候自己去找。\nCursor 把这套模式用到了他们的多个实际场景中：\n将冗长的工具结果转化为文件\n工具调用，特别是 Shell 命令或第三方 MCP（模型上下文协议），经常返回巨大的 JSON 响应，瞬间就能撑爆上下文。目前的编程 Agent 通常采取的简单粗暴做法是：直接截断过长的 Shell 命令或 MCP 结果，但很可能会丢失最关键的信息。\nCursor 的做法是，将这些输出直接写入到一个文件，然后在上下文中只告诉 Agent：「结果在 output.log 里，你自己去看。」Agent 可以先用 tail 命令查看文件末尾，如果需要更多细节，再读取整个文件。\n在「总结」阶段引用聊天记录\n当模型的上下文窗口被填满，Cursor 会触发一个「总结」步骤，给 Agent 腾出一个新的上下文窗口，其中包含之前工作的摘要。\n但 Agent 的知识会在这个过程中「退化」，因为「总结」本质上是对上下文的一种有损压缩。 Cursor 把完整的聊天历史记录也看做是一个文件。当触发总结时，Agent 会拿到一份摘要，以及一个指向「历史记录文件」的引用。如果 Agent 意识到摘要中缺少某些它需要的细节，它就可以通过搜索这份历史记录文件来找回这些信息。\n将所有集成终端的会话视为文件\n在 Cursor 中，不再需要手动复制粘贴满屏的终端报错信息，会自动将集成终端的所有会话输出同步到本地文件系统。 提问「为什么我的命令失败了？」时，Agent 能直接定位问题，甚至可以使用 grep 这样的命令，在长篇的服务器日志中只搜索相关的错误行。这种做法模仿了 CLI Agent 的体验，拥有之前的 Shell 输出作为上下文，但不同的是，它是动态发现，不是被静态注入。\nManus ：一套结构化的可逆、缩减系统\n对比 Cursor「简单粗暴」的解决思路，Manus 的做法是，把「上下文缩减」设计成了一套有明确触发机制、分阶段执行的结构化流程。\n首先，Manus 的系统会持续监控上下文长度，设定一个远低于模型硬件极限的「腐烂前阈值」（Pre-rot Threshold）。\n季逸超：你的模型有一个硬性的上下文限制，比如说 100 万个 Token，这在今天是相当普遍的。但实际上，大多数模型在远低于这个值时性能就开始下降，通常可能在 20 万个 Token 左右，你会开始看到我们所说的「上下文腐烂」，比如重复、推理变慢、质量下降等。\n所以，通过大量的评估，识别出那个「腐烂前」的阈值非常重要，通常是 12.8 万到 20 万个 Token，并将其作为触发上下文缩减的条件。\n当信号被触发后，系统会启动第一阶段的操作：\n第一步：紧凑化（Compaction）\n这是一种无损、可逆的缩减。核心是，剥离掉任何能从外部状态（比如文件系统）重建的信息。\n举个例子，Agent 调用了一个向文件写入内容的工具，这个操作在历史记录中可能包含 path 和 content 两个字段。一旦执行成功，那个可能极其冗长的 content 字段就可以被安全地从上下文中剥离，只保留 path。\n信息并没有丢失，它只是被「外部化」了。如果 Agent 在 10 步之后需要再次读取该文件，它凭借保留的 path 就能轻易将其检索回来。\nManus 提到，\n这种可逆性是非常关键的，因为你永远不知道哪个过去的动作会成为未来的关键。\n通常情况下，紧凑化只会用作最早的 50% 的历史记录，来保留最新的、完整的工具调用作为模型学习的范例（Few-shot Examples）。\n但紧凑化收益有限。多轮操作后，上下文削减的收益变得微乎其微时，系统会启动第二阶段：\n第二步：摘要化（Summarization）\n这是一种有损、但带保险的压缩。把它当做最后手段，在执行时需要极其谨慎。\n它的「保险」在于：在生成摘要之前，系统会更激进地将整个摘要前的完整上下文，转储（Dump）到一个文本或日志文件中。 相当于给历史创建了一个完整的快照存档。如果模型足够聪明，它甚至能用 grep 或 glob 自己去这个日志里捞数据。\n季逸超：紧凑化是可逆的，而摘要化不是。两者都减少了上下文长度，但它们的行为方式非常不同。\n在进行摘要化时，总是会使用完整版本的数据，不是紧凑版本。\n摘要化依然会保留最后几次完整的工具调用记录。 这能让模型清楚地知道自己从哪中断，能平滑地继续工作，保持风格和语气的连贯性。\n两个步骤下来，通过「紧凑化」（Compaction）剥离可重建信息，以及在「摘要化」（Summarization）之前，将完整的上下文转储（Dump）到日志文件中。实现上下文缩减。\n02\n给工具搭建一套灵活的行动空间\n当 Agent 能力逐步增强，配备的工具集也越来越丰富。\n如果将所有工具的冗长描述，都放到上下文窗口中，会带来两个问题：\n一是出现上下文混淆（Context Confusion）的情况，工具太多，模型直接懵掉。可能会调用错误的工具，甚至是幻觉出根本不存在的工具。\n二是最直接的 Token 浪费，大多数工具，在绝大多数时候根本不会被用到。如果，还使用了多个 MCP 服务器，情况会变得更糟。\n工具过载的问题怎么解决？一个核心思路是：\n动态发现，让 Agent 自己去找要调用哪些工具。\nCursor：把工具说明书，全部文件化\nCursor 的策略，更简单、粗暴。把所有 MCP 工具、Agent Skills 的详细定义，全部都同步到文件夹里，让 Agent 在需要时自己去查阅。\n在 Cursor 的框架中，分成了索引层和发现层。\n索引层，Agent 的系统提示词（System Prompt）里只包含一小部分静态信息，比如 MCP 工具或 Agent Skills 的名称列表。\n这些工具和技能的详细描述、参数定义、使用方法，则被全部同步到一个本地文件夹中。当模型需要时，Agent 会像一个聪明的程序员一样，进入发现层，用 grep 或语义搜索，主动去文件夹里查找它需要的工具的详细信息，然后拉取到上下文中来处理。\nCursor 做了一次 A/B 测试，结果发现，对于调用了 MCP 工具的运行任务，这种策略把\nToken 的总消耗降低了 46.9%。\n同时，Cursor 提到，这种全部文件化的方式，还解锁了一个意想不到的能力：向 Agent 传达工具的状态。\n例如，以前如果一个 MCP 服务器需要重新认证，Agent 可能会直接「忘记」这些工具的存在。但现在，Agent 可以主动发病、告知用户去重新认证。\nManus：设计了一套分层的行动空间\nManus 认为，常见的方法对工具描述进行动态的 RAG，不可行。 因为动态加载工具定义，会「干掉」KV 缓存，且历史记录里的旧调用会成为陷阱。\n季逸超：目前一个常见的方法是对工具描述进行动态的 RAG，比如，根据当前任务或状态按需加载工具。\n但会导致两个问题：首先，由于工具定义位于上下文的开头，每次变动都会导致你的 KV 缓存重置；最重要的是，模型过去对那些已被移除的工具的调用记录仍然存在于上下文中，这可能会误导模型去调用无效的工具或使用无效的参数。\n为了解决这个问题，Manus 设计了一套分层行动空间。把 Agent 的能力划分为三个层次：函数调用、沙盒工具、软件包和 API。\n第一层：原子函数调用（Function Calling）\n核心层，只包含极少数固定的、正交的原子函数，比如：读写文件、执行 shell 命令、在文件和互联网中搜索。因为这层是固定的，所以对 KV 缓存友好，且功能边界清晰，不会导致混淆。\n第二层：沙盒工具（Sandbox Tools）\n卸载层。Manus 将绝大多数工具，格式转换器、语音识别工具，甚至 MCP 调用本身（通过一个 MCP CLI 命令行工具），都作为预装软件放在一个定制的 Linux 虚拟机沙箱里。 Agent 不在上下文中「看到」这些工具的详细定义，更像是一个真正的开发者，通过第一层的 shell 命令来动态地与它们交互。比如，它可以用 ls /bin 来查看有哪些可用的工具，或者用 mcp_cli --help 来学习如何使用 MCP 命令行工具。\n第三层：软件包与\nAPI\n（Packages & APIs）\n代码层。对于需要大量内存计算或者需要与复杂第三方服务交互的任务，允许 Agent 编写并执行 Python 脚本。比如，分析一整年的股票数据，Agent 不会把原始数据加载到上下文中，而是会写一个脚本去完成计算，只把摘要结果返回。\n季逸超：在这一层，Manus 可以编写 Python 脚本来调用预先授权的 API 或自定义软件包。例如，Manus 可能会使用一个 3D 设计库进行建模，或者调用一个金融 API 来获取市场数据。实际上，我们已经代表用户购买了所有这些 API 并支付了费用，这都包含在订阅里。\n所以，我们基本上在 Manus 中预装了大量的 API 密钥，Manus 可以用这些密钥访问 API。我认为这对于需要大量内存计算，但又不需要将所有数据都推送到模型上下文的任务来说是完美的。\n这套思路，和 CodeAct *论文类似。\n代码是可组合的，可以在一步内做很多事。但它同样不是模式安全的，在代码上做约束解码非常非常困难。所以我们认为你应该为这些功能找到合适的场景。对我们来说，所有能在一个编译器或解释器运行时内处理的事情，我们都用代码来做；否则，我们就用沙箱工具或函数调用。\nCodeAct *：\n《Executable Code Actions Elicit Better LLM Agents》：\nhttps://arxiv.org/pdf/2402.01030\nManus 这套分层设计非常优雅，而且高效。从模型的角度看，无论想使用第二层还是第三层的复杂工具，最终都会通过 L1 的那几个原子函数执行。这种接口设计，对模型极度简洁，且缓存稳定。\n03\n多 Agent 协作，\n需要反复使用模式、结构化输出\n多个 Agent 之间如何协作，也是个难题。\nCognition 之前在博客中提到：不要滥用多 Agent 设置，因为当你有很多 Agent 时，它们之间的信息同步会成为一场噩梦。\n怎么利用多 Agent，实现「上下文隔离」，让每个子 Agent 都有自己独立的上下文窗口，从而实现关注点分离。是一个核心问题。\nManus 的解决思路是，借鉴 Go 语言：\n不要通过共享内存来通信，而是通过通信来共享内存。\n把这句话里的「内存」替换为「上下文」，就是两种截然不同的 Agent 协作模式。\n两种 Agent 协作模式\n任务委托模式：「通过通信」实现隔离\n这是经典的主-子 Agent（Master-Sub-agent）设置。主 Agent 将一个任务封装成一条简短、清晰的指令，然后发送给子 Agent。子 Agent 的上下文是完全独立的，从零开始，只包含这条指令。\n简单来说，\n主 Agent 发任务，子 Agent 交结果，中间过程免打扰。\n这个模式，适用于「过程不重要，只关心结果」的任务。举个例子，主 Agent 需要在一个大型代码库中搜索特定的代码片段。它只需要委托子 Agent：「在 A 项目中找到所有调用了 some_function 的地方」，然后等待返回结果列表即可。主 Agent 不关心子 Agent 是如何使用 grep 或其他工具完成搜索的。\n在内部，Manus 将这种模式叫做「Agent 即工具」。从主 Agent 视角，它只是调用了 advanced_search 函数，但背后实际上是另一个拥有独立工作流的子 Agent 在执行。\n信息同步模式：「通过共享上下文」实现协作\n但对于更复杂、需要完整历史记录的场景，简单的任务委托是远远不够的。\nManus 的思路是，通过共享上下文来实现协作。子 Agent 被创建时，能够看到主 Agent\n完整的先前上下文\n，包括所有的历史工具调用和观察。但这个子 Agent 拥有自己独立的系统提示词和新的行动空间。\n这种模式，更适用于高度依赖历史信息、需要综合分析的任务。比如，在进行一项深度研究任务时，最终的研究报告需要综合大量的中间搜索结果和笔记。\n如果使用第一种通信模式，主 Agent 需要将所有中间产物写入文件，再让子 Agent 去一一读取，这会造成巨大的延迟和额外的 Token 消耗。在这种情况下，直接让子 Agent 继承完整的上下文反而会更高效。\n但 Manus 也提到，\n共享上下文的模式成本是相当昂贵的。\n因为每个子 Agent 启动时都需要 Prefill 一个非常大的输入，并且因为系统提示词不同，无法复用主 Agent 的 KV 缓存，所以必须支付全价。\n所以，需要根据任务的性质，灵活地在这两种模式中间进行选择。\n多 Agent 通信，发信息不难，难的是收结果\n多 Agent 通信的一个难点是「接收」，如何从多个并行工作的子 Agent 那里，获得结构一致、内容准确的输出？\nManus 设计了一套内部代号叫做「Agent 化的 MapReduce」的系统。简单来说，\n共享沙箱\n每个 Manus 会话都在一个完整的虚拟机沙箱中运行。当主 Agent 创建子 Agent 时，共享同一个沙箱。这意味着，共享同一个文件系统，信息的传递可以简单到只传递不同的文件路径，解决了输入信息同步的问题。\n输出模式（Schema）\n这是关键。主 Agent 在创建子 Agent 之前，\n必须先定义一个输出的 Schema\n。这个模式就是一份强制执行的 API 合同，规定了子 Agent 最终必须返回什么样的数据结构。\n约束解码\n子 Agent 有一个专用工具 submit_result。Manus 使用约束解码（Constrained Decoding）技术，强制子 Agent 提交的结果，必须严格符合主 Agent 定义的 Schema。\n这套设计的核心思路是，无论是做摘要还是 Agent 间通信，都反复使用模式和结构化输出作为一种「契约」，来保证信息以结构化、完整的方式传递。\n04\n最后，聊聊两家的设计哲学\n最后，回到原点，聊聊这两家的上下文工程设计哲学。\nCursor 的「Dynamic Context Discovery」，强调：少即是多。Cursor 认为，在最开始提供给模型的细节越少，效果反而越好，因为能让 Agent 更轻松地自行抓取相关的上下文。\nManus 的思路是：「少构建，多理解」，避免上下文的过度工程化。上下文工程的目标是让模型的工作变得更简单，而不是更难。\n季逸超：回顾 Manus 发布以来的六七个月，我们见过的最大的飞跃，不是来自增加了更多花哨的上下文管理层或巧妙的检索技巧，它们都来自于简化，来自于移除不必要的技巧，以及对模型多一点的信任。\n每一次我们简化架构，系统都会变得更快、更稳定、更智能。上下文工程的目标是让模型的工作变得更简单，而不是更难。\n两家的实践大方向都是，从「如何把更多信息塞进上下文」，变成「怎么给 Agent 创建一个信息丰富、易于探索的外部环境」。\n引用宝玉老师的一句话：未来，随着基模能力的提升，把主动权交给模型会是一个趋势。\n更多阅读\n泛娱乐 AI 赛道观察： 从「猜你喜欢」到参与共创，角色才是 AI 时代最核心的资产\n两次拿到陆奇投资，张浩然这次想用 Agencize AI 干掉所有工作流 Agent\nAI 陪伴赛道复盘：2026 年了，为什么还没有一款千万级 DAU 的产品跑出来？\n想成为下一个 Manus，先把这些出海合规问题处理好\n转载原创文章请添加微信：founderparker",
      "article_url": "https://mp.weixin.qq.com/s?__biz=Mzg5NTc0MjgwMw==&mid=2247522073&idx=1&sn=472fa6928399df43a5c07d586754da48&chksm=c1f5b34f7e4b874b4d6a6b0d0f6d4825cd72f4ac976dcdf41fbe589623ac4e2bfc754b96a560&scene=0&xtrack=1#rd",
      "publish_time": 1768106400,
      "publish_date": "2026-01-11 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://cursor.com/cn/blog/dynamic-context-discovery\", \"https://arxiv.org/pdf/2402.01030\"]",
      "add_ts": 1768173468,
      "last_modify_ts": 1768259801
    },
    {
      "id": 419,
      "article_id": "51786",
      "title": "Trends Cogn. Sci. | 更强的人工智能，并不等于更好的生物学模型",
      "description": "DRUGONE研究表明，早期深度神经网络（DNN）在视觉任务上的进步曾与灵长类感知系统表现出一致性，引发对AI构建生物视觉模型的期待。然而，随着DNN准确率接近或超越人类水平，这种一致性趋于停滞甚至倒退。当前证据显示，DNN逐渐依赖与灵长类视觉机制不同的策略处理视觉信息，导致人工与生物视觉系统出现分化，提示高性能不等于生物合理性，挑战了AI自然逼近生物视觉的假设。",
      "content": "DRUG\nONE\n深度神经网络（DNN）在视觉基准任务上性能提升的早期阶段，曾表现出与灵长类感知系统不断增强的一致性，这一现象一度让人们期待：人工智能（AI）的进步会自然带来更好的生物视觉模型。然而，研究人员指出，越来越多的证据表明，这种一致性如今已趋于停滞，甚至在某些情况下出现倒退，尤其是在 DNN 达到人类甚至超人水平准确率之后。\n人工视觉与生物视觉之间的这种分化，可能源于模型逐渐学会了不同于灵长类的视觉策略。这一发现挑战了“AI 工程进步会自然转化为神经科学进展”的普遍观点。研究人员认为，视觉科学必须走出一条独立的发展道路，构建扎根于生物视觉系统本身的算法，而非单纯围绕互联网数据进行优化。\n深度学习对视觉科学的变革性承诺\n在 AlexNet 引发现代 AI 革命的一年后，研究人员发现：在感知任务（如物体识别）上进行任务优化训练的 DNN，其内部单元对图像的响应方式与灵长类下颞皮层神经元高度相似。这一发现迅速改变了视觉科学领域的研究范式。\nDNN 不再只是对图像进行分类的工程工具，而被视为能够解释神经计算并解决长期争论的生物模型。例如，针对物体分类进行预训练的模型更好地预测了下颞皮层反应，这为“核心物体识别”理论提供了计算层面的支持。更重要的是，这类结果暗示：只要不断推动 AI 在工程任务上的性能提升，生物视觉的基本原理就会随之自然浮现。\n过去十余年间，DNN 在视觉任务上的能力取得了飞跃式进展，当前最先进的模型在几乎所有视觉基准上都已达到或超过人类水平。这种进步主要源于模型规模与训练数据规模的指数级扩展，以及注意力架构对并行计算的高度适配。\n然而，尽管这些模型在复杂任务上表现卓越，它们仍在一些对人类而言极其简单的问题上表现出“怪异行为”，例如计数或视角预测。这种“准确率接近人类，但行为方式却显得异类”的现象，引出了一个关键问题：持续围绕 AI 基准进行工程优化，是否仍在推动模型向生物视觉靠拢，还是已经使其偏离了生物学原理？\n深度学习如何重塑视觉科学\n任务优化的深度学习方法已成为计算神经科学中最流行的建模手段之一。这类模型在预测灵长类神经元对图像刺激的反应方面表现出极高的准确性，对神经假体和体内模拟研究具有重要价值。同时，任务优化也被视为揭示视觉回路形成原则的重要工具。\n早期研究发现，相比直接拟合神经数据的模型，为物体分类而训练的 DNN 更能预测视觉皮层中高级区域的神经活动，这被解读为灵长类视觉系统围绕“识别物体”这一目标进行组织的证据。后续研究还表明，即使不显式优化分类目标，自监督学习模型也能达到相近的神经预测效果。这说明任务优化虽然重要，但具体任务与神经结构之间的关系仍未完全厘清。\n在建模人类感知方面，任务优化同样取得了显著成功。大量心理物理实验表明，随着模型在视觉基准上的准确率提升，其决策结果及错误模式越来越接近人类。DNN 还能预测多种人类感知现象，包括局部—整体偏好、语义相似性判断、显著性评估以及三维属性感知。\n然而，即便经过任务优化，一些关键的人类感知现象仍难以复现，例如视觉错觉和“变形同感”（即物理刺激不同但感知相同的情况），这通常需要额外机制才能模拟。\n为系统评估模型的生物学合理性，视觉神经科学界构建了专门的生物基准体系，用于衡量模型对神经和行为数据的预测能力。其中，Brain-Score 提供了一个持续更新的平台，使研究人员能够比较模型在工程任务与生物任务上的表现，从而揭示二者之间的关系。\n任务优化在现代 DNN 中的效果正在减弱\n尽管任务优化在早期具有变革性意义，但随着模型性能不断提升，这一策略在建模生物视觉方面正变得越来越不可靠。研究人员在 Brain-Score 基准中发现：DNN 在物体分类准确率提升到一定程度后，其与下颞皮层神经元响应的一致性不再提升，反而开始下降。\n类似趋势在不同实验数据中反复出现。大量模型分析表明，即便某些模型在物体识别任务上达到或超过人类水平，它们却已经演变为极差的灵长类视觉模型。这一现象意味着，推动 AI 性能提升的计算策略，与支撑生物视觉的机制可能已根本不同。\n进一步分析显示，在早期模型中，架构改进、训练数据增加和性能提升通常会带来更好的神经一致性；但在当今高性能模型中，这种关系已完全崩溃。无论是模型规模、网络类型，还是训练数据来源，都无法预测其是否更符合生物视觉。这种脱钩现象表明，AI 的成功路径正在偏离生物进化所选择的计算策略。\n图 1｜随着识别准确率的提升，深度神经网络（DNN）与生物视觉逐渐偏离。\n为什么任务优化如今反而削弱了生物建模能力？\n一种可能的解释是，随着模型规模扩大，DNN 逐渐学会了生物视觉系统难以利用的“捷径式”视觉策略。研究人员通过大规模实验发现，随着模型准确率超过人类，其所依赖的视觉特征与人类显著不同，越来越倾向于背景纹理、全局统计特征，甚至与任务无关的图像线索。\n这些发现表明，现代 DNN 正在混合使用“类人”的策略与明显非生物的策略。这种混合策略在工程应用中可能非常有效，但对理解大脑和行为的价值却越来越有限。\n图 2｜深度神经网络（DNN）的设计因素与生物一致性。\n如果任务优化不再奏效，出路在哪里？\n任务优化深度学习最初的吸引力在于：通过工程优化即可自然揭示生物视觉原理。如今这一假设正在失效，迫使视觉科学重新思考建模路径。\n研究人员提出了一种直接以生物一致性为目标的监督策略，使模型在训练过程中对齐人类所使用的诊断性视觉特征。结果表明，经此“协调化”训练的模型不仅更依赖类人的视觉特征，也在神经层面更接近灵长类视觉皮层。\n这些结果说明，DNN 仍然是可行的建模框架，但关键问题不在于模型本身，而在于训练目标与数据分布的不匹配。单纯依赖互联网规模的静态图像数据，正在系统性地将模型推离生物视觉。\n图 3｜通过训练，深度神经网络（DNN）可采用类人的视觉策略。\n在互联网规模计算时代重新思考任务优化\n视觉科学中的计算模型长期运行在远小于前沿 AI 的尺度上，这既源于学术传统，也源于对可解释性的重视。然而，生物一致性或许只有在大规模训练下，结合合适的数据、目标和约束才能显现。\n研究人员提出，与其过早在架构中强加生物约束，不如从可扩展的通用架构出发，系统探索哪些数据分布与学习目标能够自然诱导出类人的表示和行为。在此基础上，再逐步引入其他生物特性，构建对视觉系统的完整解释。\n结论\nDNN 曾在性能提升的同时不断逼近灵长类视觉，但这一趋势已在达到人类水平后停滞甚至逆转。这一现象表明，更强的人工智能并不意味着更好的生物学模型。\n视觉科学若要取得实质性进展，必须摆脱对工程基准的单向依赖，转而构建以生物原理为核心的数据、目标与训练范式。\n未解问题（Outstanding questions）\n如何为 DNN 构建更接近真实生物经验的训练环境？\n哪些学习原则能够引导模型形成类人的视觉表征？\n哪些生物约束是视觉系统的核心原理，哪些只是实现层面的副产物？\n整理 | DrugOne团队\n参考资料\nLinsley, Drew, Pinyuan Feng, and Thomas Serre. \"Better artificial intelligence does not mean better models of biology.\" Trends in Cognitive Sciences (2025).\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512670&idx=2&sn=f680c638aa01163536dbd81dc3cd41c6&chksm=fdfbdb6bcd449e7d69c549e9435ac71f2e1e105c46daef1a6a9fb647498b9d0fc69e8da5d150&scene=0&xtrack=1#rd",
      "publish_time": 1768093800,
      "publish_date": "2026-01-11 09:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768173492,
      "last_modify_ts": 1768259816
    },
    {
      "id": 420,
      "article_id": "51785",
      "title": "Cell｜多模态AI构建大规模肿瘤免疫微环境图谱",
      "description": "肿瘤免疫微环境（TIME）对癌症进展和免疫治疗至关重要，但多重免疫荧光（mIF）技术因成本高、流程复杂限制了其应用。微软研究院、华盛顿大学与Providence Genomics团队在《Cell》发表研究，提出一种多模态AI生成方法，可高效模拟mIF图像，显著降低成本与时间开销，提升通量，有望推动TIME分析在大规模研究和临床中的普及。",
      "content": "肿瘤免疫微环境(TIME)在癌症进展及免疫治疗响应中发挥着关键作用。多重免疫荧光(mIF)是一种解析TIME的重要成像技术，但其高昂成本、流程复杂以及通量受限，严重制约了其在大规模人群研究和临床实践中的广泛应用。\n针对这一关键瓶颈，\n微软研究院、华盛顿大学与Providence Genomics等机构的研究团队\n于2025年12月9日在《Cell》上联合发表了题为“Multimodal AI generates virtual population for tumor microenvironment modeling”的研究工作，\n其中微软研究院的Hoifung Poon、华盛顿大学的王晟以及Providence癌症研究所的Carlo Bifulco共同担任通讯作者。\n研究提出了一种极具前景的\n多模态人工智能框架GigaTIME\n。该方法通过将常规获取的H&E图像转化为高度信息化的虚拟mIF图像，实现肿瘤免疫微环境的规模化建模，为人群尺度的TIME分析与发现推动精准免疫肿瘤学的发展奠定了基础。\nGigaTIME 代码仓库：\nhttps://aka.ms/gigatime_code\n背景\n肿瘤免疫微环境(TIME)\n在癌症进展中发挥着关键作用。它通过影响肿瘤的免疫监视与免疫逃逸，进而调控肿瘤生长、侵袭、转移以及对癌症治疗的反应。TIME是一个高度复杂的空间生态系统，由癌细胞以及多种非恶性细胞类型构成。\n免疫组织化学(IHC)\n能够可视化特定蛋白的激活状态，是揭示TIME中关键细胞状态的重要工具。IHC的一个关键局限在于，单次实验通常只能检测一种蛋白，且不同蛋白往往需要在不同的组织切片上分别评估。这一限制在肿瘤微环境建模中尤为突出，因为理解肿瘤细胞与多种免疫细胞之间复杂而动态的相互作用，往往依赖于对多种蛋白信号的同时观测。\n多重免疫荧光(mIF)\n作为一种有力的替代技术应运而生，它能够在同一组织切片上实现多通道蛋白的共定位分析，同时保留组织的空间结构。尽管前景广阔，mIF在大规模研究中的应用仍然受到显著限制。这主要源于其高昂的成本，包括试剂、专用设备及计算基础设施的投入，同时其染色、成像和数据处理流程高度依赖人工操作。由此导致现有mIF数据资源极为稀缺，严重制约了其在大规模临床发现与转化研究中的应用潜力。\n相比之下，\n苏木精-伊红(H&E)图像\n在临床\n流程中可低成本、常规化地获取，广泛用于研究组织结构和细胞形态。\n尽管H&E图像不能直接揭示细胞状态，但其所呈现的细胞空间分布模式可以为推断细胞个体状态提供线索。这类模式对人类专家而言可能并不直观，却有望被先进的多模态人工智能模型系统性地挖掘和利用。\n近年来，基础模型的发展进一步放大了这一潜力，通过在大规模病理图像\n数据集上的预训练，人工智能模型已展现出卓越的表征学习与泛化能力。这些进展共同表明，从H&E图像中学习能够指示空间分辨蛋白激活状态的病理特征，在技术上是可行的，也为TIME的规模化建模提供了全新的可能性。\n结果\nGigaTIME生成多重免疫荧光的虚拟人群\n作者首先通过实验获取了441张mIF图像，这些图像来源于21张H&E染色切片，覆盖21个蛋白通道(表1)。随后，这些配对的H&E与mIF切片通过一套计算流程进行处理，包括图像配准与细胞分割，\n最终构建了一个包含4000万个细胞的配对H&E–mIF数据集\n(图1A)。\n表1 本研究中使用的TIME标志物及其细胞表达情况\n将配对数据划分为训练集、开发集和独立留出的测试集。为实现从H&E图像到mIF图像的转换，GigaTIME在训练集上进行训练，\n采用基于NestedUNet的分块式编码器–解码器架构。\n模型以H&E图像块作为输入，输出21个对应的mIF图像块，每个块对应一个蛋白通道。随后，将这些通道特异性的图像块拼接重建为整张mIF全切片图像，从而实现具有空间分辨率的切片级蛋白激活谱分析。具体而言，对于给定的蛋白通道，GigaTIME会为每个像素输出一个二分类标签，指示该像素在该蛋白通道下是否处于激活状态。基于此，可以统计任意图像块或整张切片中被激活像素的数量，以及激活密度得分。\n图1 GigaTIME实现人群尺度的肿瘤免疫微环境分析\n随后，将GigaTIME应用于一个大规模且多样化的真实世界数据集，该数据集包含Providence Health体系中来自美国七个州、51家医院和1000余家诊所的14256张H&E全切片图像，覆盖24种癌症类型和306个癌症亚型。利用训练好的模型，为这些患者生成了299376张虚拟mIF全切片图像。由此，\n作者构建了一个大规模、多模态的虚拟人群，包含H&E图像、虚拟mIF图像以及生物标志物、分期和生存状态等临床属性。\n作为\n概念验证，为每张mIF图像计算了蛋白激活密度得分，定义为激活像素的比例。随后，\n通过对同一癌症亚型的肿瘤进行均值汇聚，获得了基于mIF的TIME特征谱，覆盖不同癌症亚型\n(图1B)。为评估该方法的稳健性，研究团队进一步将GigaTIME应用于TCGA的10200例肿瘤样本，生成了214200张覆盖21个通道的虚拟mIF全切片图\n像。结果显示，\n基于Providence和TCGA两个虚拟人群所得到的聚合激活得分具有高度一致性\n(图1C)，突显了GigaTIME的泛化能力与可靠性。\nGigaTIME将H&E全切片图像转换为mIF图像\n作者将GigaTIME与常用于虚拟染色任务的CycleGAN模型在不同粒度层级(像素级、细胞级和切片级)上进行比较。结果显示，\nGigaTIME在21个蛋白通道中的15个上显著优于CycleGAN，\n其余6个通道未观察到统计学显著差异(图2A)\n。\n在细胞级评估中，GigaTIME的相关性显著高于CycleGAN，\n而后者的表现接近随机水平，表明CycleGAN未能恢复连贯的细胞级模式(图2B)。为评估全局空间模式，作者实现了一种受免疫评分启发的切片级指标。\nGigaTIME在DAPI通道上的Spearman相关系数达到0.98，在所有通道上的平均相关系数为0.56；\n而CycleGAN在所有通道上均\n接近零相关(图2C)。最后，对具有代表性的全切片图像块进行的定性比较，进一步直观展示了\n实测mIF与GigaTIME转换得到的虚拟mIF之间的高度一致性\n(图2D)。\n图2 GigaTIME实现从H&E到mIF图像的转换\n虚拟人群支持蛋白–生物标志物关联的大规模发现\n研究团队构建的虚拟人群在泛癌、癌种以及癌症亚型三个层面，识别出了21个由GigaTIME转换得到的虚拟蛋白通道与20个临床生物标志物之间的1234项具有统计学显著性的关联\n(图3A)。具体来说，在泛癌层面，共识别出175项显著的蛋白–生物标志物关联(图3B)，其中许多结果得到了既有文献的支持。在癌种层面，GigaTIME在脑肿瘤中识别出64项蛋白–生物标志物关联(图3C)，在肺癌中识别出137项(图3D)，在肠道肿瘤中识别出175项(图3E)。上述关联中有相当一部分具有明显的癌种特异性。在癌症亚型层面，虚拟人群揭示了许多组织学特异性的关联，而这些关联在样本量较小的队列中往往难以发现(图3F和图3G)。\n图3 GigaTIME在泛癌、癌种及癌症亚型层面识别新的TIME蛋白–生物标志物关联\n虚拟人群支持病理分期与患者分层的大规模发现\n在泛癌层面，GigaTIME识别出了蛋白通道与病理分期之间的显著关联(图4A)。在癌种层面，这些蛋白–分期关联在不同癌症类型之间表现出显著差异(图4B)。在肺癌中进一步开展的亚型层面分析揭示了肺腺癌(LUAD)与肺鳞状细胞癌(LUSC)之间的细微差异(图4C)。最后，为进一步评估虚拟人群的临床相关性，作者分析了虚拟mIF是否有助于根据生存结局对患者进行分层。无论是在泛癌队列(图4D)，还是在特定癌种内部(图4E和图4F)，\nGigaTIME转换得到的虚拟蛋白激活信息均能够将患者区分为具有显著不同生存轨迹的亚群。\n更为重要的是，\n将全部21个虚拟蛋白通道整合为一个综合性的GigaTIME特征，可实现更加优越的患者分层效果\n(图4G)，凸显了不同通道之间的互补信号，并进一步验证了基于mIF的虚拟人群在临床研究中的应用价值。\n图4 GigaTIME在病理分期和生存分组中实现有效的患者分层\n基于TCGA虚拟人群的独立验证\n研究团队利用由TCGA构建的一个独立虚拟人群，对在Providence虚拟人群中识别到的生物标志物关联进行验证。Providence与TCG\nA两个虚拟人群在虚拟mIF激活水平方面具有总体一致性，其Spearman相关系数达到0.88(图5A)。此外，\n有80项蛋白–生物标志物关联在Providence和TCGA中均达到统计学显著，\n这一重叠程度具有极高的统计学意义，进一步凸显了GigaTIME的泛化能力与稳健性。此外，\n在癌种层面(如肺癌，图5B)以及癌症亚型层面(如LUAD，图5C)，Providence虚拟人群同样揭示了显著更多的关联；相比之下，TCGA在如此细粒度层面上仅识别出极少数显著关联\n(图5B)。\n图5 基于TCGA虚拟人群的独立验证\n虚拟人群揭示有趣的空间与组合蛋白激活模式\n将三种标\n准的\n空间感知指标(熵、信噪比SNR和锐度)\n应用于Providence虚拟人群，发现\n它们在与特定临床生物标志物的关联中，往往比密度指标揭示更强的相关性\n(图6A–6C)。此外，\n作者使用\nOR逻辑运算\n评估虚拟蛋白的成对组合，并计算其与临床生物标志物的相关性(图6D和6E)。结果表明，\n组合激活相比单一虚拟蛋白能揭示更多、更强的生物标志物关联。\n图6 GigaTIME揭示有趣的空间与组合虚拟mIF模式\n局限及未来方向\n本研究的关联分析基于来自51家医院和1000余家医疗机构的14256名患者，构成了迄今规模最大的虚拟mIF人群研究之一。然而，该队列中的患者主要来源于美国西部地区，地理分布和人群构成仍存在一定局限。\n未来仍有较大空间进一步提升患者队列在地理、种族的多样性，以更全面地覆盖当前代表性不足的人群，从而增强研究结论的普适性与临床外推价值。\n值得注意的是，GigaTIME的研究结果表明，常规H&E切片中确实蕴含着丰富的、可用于空间蛋白组学建模的潜在信息。然而，并非所有蛋白信号都能被同等有效地从形态学特征中解析。\n部分蛋白在组织形态层面的表征并不显著，因此仅依赖H&E图像进行转换本身就存在天然上限。\n研究结果已经揭示，不同蛋白通道在虚拟mIF转换质量上存在显著差异。这种差异可能源自三个因素：异质的H&E肿瘤/正常组织结构、训练数据集中阳性事件频率的差异，以及标志物特异性的技术挑战，如非特异性结合模式、表达水平差异和对组织处理方法的敏感性差异。对上述差异进行系统性量化和分析，有助于识别在转换性能上具有较大提升潜力的蛋白通道，从而为后续数据采集与实验设计提供明确方向。\n在未来工作中，作者计划进一步扩展可建模的蛋白通道范围，并系统评估其跨模态转换质量，逐步构建更加完整、全面的虚拟mIF图谱。\n从更长远的角度看，GigaTIME的核心目标之一在于揭示肿瘤免疫微环境中细胞间复杂相互作用背后的“语法规律”。为实现这一目标，\n未来研究将计划把细胞分割模型进一步整合进GigaTIME的训练与推理流程中，以更深入地刻画TIME的空间组织与功能机制。\n参考链接：\nhttps://doi.org/10.1016/j.cell.2025.11.016\n--------- End ---------",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512670&idx=1&sn=3534be4ae3530b0d2a527ac6cfcab728&chksm=fdab095a6378c4e0699c17cb9af05452e69c7d4e0499f51035b44b8a071c20118163dcd8e8e0&scene=0&xtrack=1#rd",
      "publish_time": 1768093800,
      "publish_date": "2026-01-11 09:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://aka.ms/gigatime_code\", \"https://doi.org/10.1016/j.cell.2025.11.016\"]",
      "add_ts": 1768173498,
      "last_modify_ts": 1768259819
    },
    {
      "id": 424,
      "article_id": "51773",
      "title": "奥特曼点名「AGI最后一块拼图」！记忆，才是硅谷2026新共识",
      "description": "2026年AI竞争焦点从模型扩展转向记忆能力，OpenAI率先布局，谷歌凭借Gemini 3强势崛起，Claude也加速追赶，记忆革命悄然开启。奥特曼因ChatGPT地位受撼动而拉响“红色警报”，行业进入新赛道竞争，性能不再唯一标准，持续学习与记忆成为关键突破点，AI格局面临重塑。",
      "content": "新智元报道\n编辑：KingHZ 好困\n【新智元导读】\n2026年，AI竞争焦点从Scaling转向记忆。OpenAI率先布局，谷歌紧跟持续学习，Claude已开始追赶——记忆革命已悄然打响。\n最近，奥特曼的焦虑肉眼可见。\n去年年底，谷歌Gemini 3横空出世，一举横扫各大榜单，将ChatGPT狠狠拽下了神坛。\n为了抢回AI皇冠，奥特曼不得不拉响「红色警报」。\n不只是跑分，看数据更扎心！\n2026年最新的全球AI报告显示，谷歌正在全面「超车」。\n虽然局势不利，但奥特曼还是放了狠话：\nOpenAI留了大招，2026年赢的还是我们！\n奥特曼这次押注的是记忆。\n他预计，ChatGPT产品线将在未来一年内取得进展。\n他说：「现在，记忆仍然非常粗糙，非常初级」。\n而一旦AI能够记住用户生活的每一个细节，包括他们没有明确表示的微小偏好，它将变得「非常强大」。\n这是奥特曼最期待的未来功能之一，但他不是唯一一个这样认为的人。\nAI的记忆能力，正成为继Scaling之后的解锁超级智能的\n新共识。\nAGI最后一块拼图\n人类在日常生活中暂存、调用和操作信息的能力，依赖工作记忆（working memory）。\n对人类而言，工作记忆与整体智能水平高度相关。\n这意味着，\nAI\n是否具备「记住事情」的能力，可能正是通往超级智能ASI的关键一步\n。\n所谓超级人工智能ASI，通常指在推理、理解和决策能力上至少与人类相当、甚至超越人类的AI形态。\n奥特曼认为，记忆容量直接决定了智能高度。\n而AI记忆的潜力几乎无限，所以AI最终能达到怎样的智能高度，其实很难预测。\n即便你拥有世界上最好的私人助理，他们也不可能记住你一生中说过的每一句话，不可能读过你所有的邮件、所有的文档，也不可能每天都持续追踪你的一切工作细节，更不可能以那样的深度参与到你的人生中。\n没有任何人类拥有无限、完美的记忆。\n但AI不一样。\n奥特曼认为，\nAI\n在理论上完全可以做到这一点\n。\n目前的记忆功能仍然非常原始，还处于早期阶段。\n奥特曼直言，当前的AI记忆水平和GPT-2时代，没什么两样。\n他认为，记忆能力可能是大家认可AI的关键跨越：\n随着AI保留我们的想法，我们将真正与它们建立关系。\n我认为，这是当下被低估的一点——人们已经开始觉得这些机器人是他们的伙伴，并且在关心着他们。\n在现实中，\n长期记忆仍然是\nAI\n面临的关键技术瓶颈之一\n。\n正因如此，提升AI记忆能力，正在成为AI巨头下一阶段竞争的核心方向。\n记忆，成为AI行业浮现的新共识\n去年，图灵奖得主、AI三巨头之一Yoshua Bengio、谷歌前董事长Eric Schmidt在内的数十位知名学者与专家，受人类认知研究领域中\nCattell–Horn–Carroll理论启发，\n为混乱的AGI预测领域提供了一个力求严谨的评估基准。\n与知识、阅读和写作、数学等能力相比，ChatGPT的记忆能力还比较落后，特别是记忆存储。\n除了多模态，谷歌下一年还押注了持续学习。\n去年，谷歌研究已经公布了多篇持续学习的论文，明年可能彻底落地到Gemini中。\n拓展阅读：\n终结Transformer统治！清华姚班校友出手，剑指AI「灾难性遗忘」\n而企业级AI智能体初创的Andrew Pignanelli更是直言，\n记忆将成为2026年AI公司最关注的核心问题\n。\n他与奥特曼遥相呼应：\n记忆将成为被反复讨论、并被公认为通向通用人工智能（AGI）的最后一步。\n他认为，OpenAI领先了一步，最早为ChatGPT引入了记忆机制。\n而Claude已经第一个跟进ChatGPT。\n一旦ChatGPT在记忆上取得突破，Andrew Pignanelli预测：\n几乎所有模型提供方都会为自己的应用增加并不断强化记忆能力。\n不过，他同样强调，行业距离真正完善的长期记忆系统仍然非常遥远。\n不断扩大的上下文窗口，看时提高了AI的记忆能力，但在Pignanelli看来，这只是权宜之计。\n即便如此，要达到通用人工智能所需的那种细粒度记忆水平，仍然必须在记忆架构本身上取得突破。\n他指出，\n即便是更短期的情景记忆（episodic memory），目前也尚未被真正解决\n。\n在Pignanelli看来，解决记忆问题，才是真正让AI告别「机械感」的关键\n目前，大家更多把AI当作「看似聪明的工具」，而不是「像人一样存在」。\n我们的系统在「交互」这件事上已经做得很好了。\n从交互层面的图灵测试来看，我们几乎已经通过了。\n但那只完成了一半。\n另一半，正是记忆。\n第一个真正的AGI，将是一个极其强大的智能处理器，加上一个同样强大的记忆系统。\n换句话说，\n没有记忆，就不会有真正意义上的「数字自我」\n。\n而超级智能，或许正诞生于这一刻。\n参考资料：\nhttps://www.businessinsider.com/superintelligent-ai-memory-sam-altman-2026-1\nhttps://www.youtube.com/watch?v=2P27Ef-LLuQ\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663137&idx=1&sn=cc23d900603f8b55c45d413702043c89&chksm=f0276223cdbc1743d05bf6a2b9c2604a82c670d2d7f55a9662ed5b6780d656630c9bef4fcd3a&scene=0&xtrack=1#rd",
      "publish_time": 1768024200,
      "publish_date": "2026-01-10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.businessinsider.com/superintelligent-ai-memory-sam-altman-2026-1\", \"https://www.youtube.com/watch?v=2P27Ef-LLuQ\"]",
      "add_ts": 1768173572,
      "last_modify_ts": 1768173572
    },
    {
      "id": 430,
      "article_id": "51764",
      "title": "AI月产十亿行代码，暴增76%！程序员论坛炸锅：代码行数≠生产力！",
      "description": "Greptile基于每月审核的十亿行代码发布AI编程年度报告，揭示AI显著提升代码生产效率，开发人员月均提交代码量从4450行大幅增长。尽管数据显示生产力飞跃，但多数程序员并未实际感受到效率提升。报告涵盖2000家使用AI编程的公司，反映AI在编码、审查等环节的广泛应用与现实体验间的落差，引发对AI赋能实效的深入思考。",
      "content": "新智元报道\n编辑：peter东 LRST\n【新智元导读】\n想知道硅谷的程序员怎么使用AI编程，被2000家公司使用的AI代码审查智能体Greptile基于每月用AI审核的的十亿行代码，发布了AI编程年度报告，揭示了使用AI编程后带来的生产率提升，但对此程序员们却无法感同身受。\n这份报告最让人震撼的一点，是指出了在AI编程的帮助下，工程师的代码生产量飞涨。\n每位开发人员，每月提交的代码行数从4450增长到7839，增长幅度达到76%，对于6-15人的中型开发团队，每位开发者提交的代码量更是接近翻倍（提升89%），这意味着AI编程工具正成为一种效率倍增器。\n更值得注意的是，程序员单次提交代码时，每文件中变更的代码行数的中位数上升20%（从18变为22行），意味着代码迭代不仅「更快」，且「变化更多」，这可能反映了AI编程工具能够修改的代码及应对的需求正变的复杂。\n不过对于报告提到的效率提升，ycombinator论坛上对该报告的讨论，却大多是怀疑的声音。有人说需要花大量时间修复AI生成的代码中的问题。\n这些细微差别从未被这类指标所捕捉。更多的人讨论提交的代码数量增加，是不是等同于程序员真实的工作效率提升。\n菜鸟程序员完成一个功能需要几十行代码，而资深程序员则只需要几行就能实现。此外，由于引入了AI编程，代码被删除和重写的频率如何？这可能不容易统计，但这却很能反映AI编程带来的工作效率提升。\n另一个更对于代码提交数量增加与工作效率提升的观点是，假设员工之间具备同等的专业能力，那么生产力就取决于代码行数的产出。但事实上，有的任务很难，但不需要太多行代码，只有资深程序员才能完成；而有些任务很简单，却需要很多行代码。只看代码提交量，是将所有任务都看成是中等难度的任务。\n此外，不同程序员提交的代码质量不同，这一点在该报告中也没有体现。从这个角度去看，每一行代码都应该被视为一种负担，而不是资产。开发团队需要领域专家来判断到底需要多少行代码存在。\n就像你可能会通过每小时搬运的物品数量来衡量仓库员工的生产力。但如果有人只是把东西随意扔到仓库里，或者搬运本不需要移动的东西，他们就会最大化这个指标。\nAI辅助下每个程序员能生成更多的代码了，但这些代码真的是完成对应任务所必须的吗？这不是业务方应对考虑的问题，仅仅衡量提交的代码数，可能会鼓励不必要的重复劳动。\n从这个角度来看，或许「编辑行数」是更合适的评估程序员工作效率的指标。这样一来，通过重构来减少代码库规模的方式仍然可以被视为有生产力。每删除一行代码得1分，每添加一行代码也得1分。\nOpenAI依旧领先\n但差距在变小\n效率跃升的背后，是支撑性技术栈的激烈重构。报告以不同大模型提供商的SDK下载量为考察变量，发现在AI记忆模块中，mem0以59%市占率一骑绝尘；而对比向量数据库「六强混战」（Weaviate 25%领先，Chroma/Pinecone/Qdrant等紧咬）。\nLLMOps层，LiteLLM增长4倍至4100万下载，LangSmith借LangChain生态捆绑上位。这印证一个趋势，即模型调度、监控、降级已从「可选项」变为「基建标配」。\n当编程调用的智能体数量越来越多，运维复杂度指数上升，LLMOps正在承接当年K8s之于微服务的角色。\n对于模型间的军备竞赛，该报告考察模型提供商从2022年1月到2025年11月的SDK下载量，主要玩家是OpenAI、Anthropic和Google GenAI。OpenAI以一条陡峭上升的绿色曲线主导市场。其下载量从2022年初的几乎为零，一路飙升至2025年11月的1.3亿次，确立了绝对的市场领导者地位。\nAnthropic（红色折线）的增长轨迹堪称「火箭式」。\n虽然起步较晚且基数较小，但自2023年下半年开始，其下载量呈指数级爆发，到2025年11月已达到4300万次，实现了自2023年4月以来1547倍的惊人增长，Open AI和Anthropic的比值已从47:1缩至4.2:1——开发者正在用脚投票，向更开放、更可控、更可编程的接口迁移。\n而黄色曲线代表谷歌，其增长相对平缓，在2025年11月的下载量约为1360万次，与前两者相比存在显著差距。\n不同模型的参数决定模型的适配场景\n这份报告还揭示了五大主流模型作为编码智能体后端的实测基准（考察指标包括第一个token出现需要等待的时间、吞吐量、成本等），见下表。\n通过该表，可看出Claude Sonnet 4.5与Opus 4.5只需要等待不到2.5秒，就会返回第一个token，显著优于GPT-5系（>5秒）。而在交互式编程中，2秒是「心流」与「分心」的临界阈值。\n而对于批量生成场景，GPT-5-Codex与GPT-5.1的吞吐量断崖领先，适合后台CI/CD流水线中的大规模代码生成/测试用例填充。\nGemini 3 Pro则在响应速度时显著较慢，需要等10多秒才会返回第一个token，每秒输出的token数也太少，不适合交互式编程的使用场景。\n该报告的最后部分，还给出了2025年基础模型及大模型编程应用领域的关键论文，这些研究预示下一波突破方向，例如Self-MoA颠覆传统多模型集成，证明单模型多次采样+聚合可超越异构模型混合，这意味着「模型多样性」或让位于「推理路径多样性」，而Search-R1用强化学习训练模型「自主决定何时搜索」，将搜索引擎变为可学习的环境动作，而非静态的工具调用。RetroLM更是在直接在KV层面检索，绕过原始文本，改变大模型组织记忆的方式。\n无论用了多少AI辅助编程，提交代码前仍需人工审查。追踪AI编程工具的使用数据，无法包含人工审核的部分，这将难以真实反映产品实际的使用体验和效果。不过如果你能证明AI编程工具有助于更快地发布功能，而不是仅仅允许更多的代码行数通过审查，那么你开发的AI编程工具将具有更强的可证明价值。\n参考资料：\nhttps://www.greptile.com/state-of-ai-coding-2025\nhttps://news.ycombinator.com/item?id=46301886\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652662976&idx=3&sn=b284281462e904fbe96304145c0967d2&chksm=f08e933c19c7eaaca1ab4c4959831036cc51b240c732af8dd50bc217af6ef2021f1c478c6a5a&scene=0&xtrack=1#rd",
      "publish_time": 1768006200,
      "publish_date": "2026-01-10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.greptile.com/state-of-ai-coding-2025\", \"https://news.ycombinator.com/item?id=46301886\"]",
      "add_ts": 1768173635,
      "last_modify_ts": 1768173635
    },
    {
      "id": 431,
      "article_id": "51812",
      "title": "NeuralGCM harnesses AI to better simulate long-range global precipitation",
      "description": "NeuralGCM是一种结合物理建模与机器学习的混合大气模型，通过训练NASA降水观测数据，显著提升了全球降水模拟的准确性。该模型在捕捉每日降水周期和极端天气事件方面优于传统方法。由于降水受亚网格尺度过程影响，全球气候模型难以精确模拟，尤其在长期预测和极端事件上存在挑战。NeuralGCM利用神经网络弥补物理模型分辨率不足，实现快速、高效的全球大气模拟，对农业种植、城市防灾等人类活动具有重要意义。作为开源模型，它为气候研究提供了新工具。",
      "content": "Defining the technology of today and tomorrow.\nPhilosophy\nWe strive to create an environment conducive to many different types of research across many different time scales and levels of risk.\nLearn more about our Philosophy\nLearn more\nPhilosophy\nPeople\nOur researchers drive advancements in computer science through both fundamental and applied research.\nLearn more about our People\nLearn more\nPeople",
      "article_url": "https://research.google/blog/neuralgcm-harnesses-ai-to-better-simulate-long-range-global-precipitation/",
      "publish_time": 1768243200,
      "publish_date": "2026-01-13 02:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://research.google/philosophy/\", \"https://research.google/philosophy/\", \"https://research.google/people/\", \"https://research.google/people/\"]",
      "add_ts": 1768259734,
      "last_modify_ts": 1768346400
    },
    {
      "id": 434,
      "article_id": "51809",
      "title": "端侧AI最优解：速度破百Token！CES归来就看生态大会",
      "description": "2026年开年，端侧AI迎来爆发风口。瑞芯微推出性能领先同行3倍、能效提升4倍的RK182X芯片，获新质生产力领域核心企业认可。1月27日将在福州举办首届AI软件生态大会，聚焦场景痛点，发布落地方案，推动AI技术重塑电子产品，携手共建AIoT2.0时代，诚邀AI软件企业共谋发展大计。",
      "content": "新智元报道\n编辑：KingHZ\n【新智元导读】\n2026开年，端侧AI迎来最大风口。瑞芯微以RK182X领衔，性能领先同行3倍，能效提升6倍，已获新质生产力领域核心企业青睐。1月27日福州首届生态大会，将聚焦场景痛点、发布落地方案，邀您一同乘势而上。\n1月27日，瑞芯微AI软件生态大会，\n一起见证AIoT2.0时代！\n诚邀AI软件公司共聚福州，\n共谋大计：AI技术重塑电子产品！\n2025年瑞芯微开发者大会上，数百款AIoT创新产品百花齐放。\n我们正在见证AIoT2.0新硬件的重大机遇。\n机器人、机器视觉、智能座舱、自动驾驶、工业应用、智能家居、AI电脑、AI手机、可穿戴设备等\n千行百业都迫切需要AI技术重塑产品\n。\n为解决终端产品部署端侧大模型面临的带宽和功耗两大痛点，瑞芯微推出了世界第一颗3D架构协处理器RK182X，\n是部署端侧\nAI\n的最佳芯片解决方案\n。\nRK182X已经得到十几个行业、超300家客户的采用，赋能大量新质生产力企业。\n同时，正式发布RK182X最新的性能升级实测数据，大语言模型（LLM）性能实现质的飞跃！\n基于端侧\nAI\n领域关键指标的实测数据对比，瑞芯微RK182X运行Qwen2.5-3B模型输出速度突破\n百Token大关\n，是市场上\n对标产品的3倍\n！\n这意味着端侧设备在极短延迟内生成连贯、准确的文字回复。\n这彻底改变了以往端侧大模型响应迟缓、体验割裂的状况，使实时、多轮的复杂对话交互成为可能，用户体验从「等待式应答」跨越至「流畅互动」的新阶段。\nRK182X基于3D堆叠的创新架构，对比竞品实现了\n3倍性能及6倍能耗比\n。\n该架构将高性能DRAM\n直接堆叠封装在计算芯片之上，\n实现了带宽的指数级跨越，高达数百GB/s的片上内存带宽\n，这比传统外置DRAM方案提升了近一个数量级，彻底满足了3B/7B大模型推理时对数据「洪流」的需求。\n此外，这一架构大幅缩短内部互连距离降低数据传输功耗，实现了在更小体积内集成更强算力与存储，契合了所有终端设备的根本需求。\n今年，瑞芯微还将陆续推出RK1860（60+ TOPS），RK1899（250+ TOPS），RK1810（超低功耗），RK1880（120+ TOPS）等3D架构协处理器，以及下一代旗舰芯片RK3668、RK3688。连同正当红的RK3588、RK3576，以及即将发布的RK3572，瑞芯微以SoC+协处理器，为AIoT2.0时代提供最合适的芯片平台。\n我们诚挚邀请AI软件合作伙伴，协同赋能客户，用心做好产品。\n本次AI软件生态大会，瑞芯微期待与您一起：\n搭建起AI软件与市场的桥梁，依托瑞芯微在AIoT千行百业、超过5000家全球客户的广大生态，\n实现AI软件\n算法\n的场景\n落地\n、价值变现\n。\n现场将实景展示实时视频分析、车载AI Box，新一代工业检测技术，智能家居等应用，\n直观呈现AI软件赋能产品的全新体验\n。\n我们坚信软件有价值。现场将一对一\n对接具体技术方案，以及讨论合作生意模式、利益分配\n。\n1月的福州暖意融融，诚邀您拨冗莅临！在遍地黄金的AIoT2.0时代，共探合作，共创盈利！\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663764&idx=2&sn=df6a02aa852c99fad4b5e7cf761dd153&chksm=f0f6651ee7ad2bd33c189df5d6f494734e78214693f0397ab66fb8a38a2f9f9242cfa2a2d83d&scene=0&xtrack=1#rd",
      "publish_time": 1768204200,
      "publish_date": "2026-01-12 15:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768259741,
      "last_modify_ts": 1768346411
    },
    {
      "id": 436,
      "article_id": "51805",
      "title": "全球开发者狂喜！Claude Code史上最大更新，一次性1096次提交",
      "description": "Boris Cherny，Anthropic工程师、Claude Code创造者，通过自研AI工具实现编程自动化，年入10亿美金。他不再手动写代码，而是用Claude Code开发Claude Code，完成1096次迭代提交，形成极致“套娃”式自我进化。这一变革标志着AI编程工具进入全新阶段，大幅提升开发效率，成为全球程序员热议的焦点，展现AI在软件开发领域的巨大潜力与未来方向。",
      "content": "新智元报道\n编辑：定慧\n【新智元导读】\n全球程序员最喜欢的工具迎来最大更新。\nBoris老哥不仅靠自造的Claude Code年入10亿美金，现在更是玩起了极致「套娃」，用Claud Code开发Claude Code，疯狂迭代1096次提交！\nBoris\nCherny\n现在不写代码了。\n作为Claude Code的创造者，这位Anthropic的工程师用自己造的AI工具来写代码——Claude Code去年斩获超过10亿美金的收入。\n扩展阅读：30天没写一行代码，他却赚了10亿美金！\n这大概是AI时代最讽刺又最美妙的事情：一个人自己不写代码，却创造了一个能替所有人写代码的工具。\n而现在，这个工具刚刚迎来了史上最大的一次更新。\nClaude Code2.1发布了，这不是一次小修小补——\n1096次提交\n，版本从2.0.76直接跳到2.1.1。\nAnthropic团队疯了吗？\n不，他们只是在用Claude Code开发Claude Code。\n这就是AI加速AI的正反馈循环。\nClaude Code2.1更新了什么？\n1. Shift+Enter终于好用了\n这是用户抱怨最多的问题，现在彻底解决了。\n在iTerm2、Kitty、Ghostty、WezTerm这些终端里，Shift+Enter多行输入开箱即用。\n不需要改配置文件，不需要找变通方案。\n想换行就按Shift+Enter，就这么简单。\n如果用的是其他终端，运行/terminal-setup就能自动配置。\n这个改进看起来很小，但用过CC的人都知道，没有多行输入有多痛苦。\n2. Skills系统全面\n升级\nSkills是Claude Code最近推出的重磅功能，可以把它理解成「前人验证好的工作流」。\n这次更新，Skills成了一等公民：\n热重载\n：修改`~/.claude/skills`目录下的技能文件，改完立刻生效，不用重启。\n这对开发者来说太重要了。之前调试一个Skill，改一次重启一次，效率极低。现在改完就能看效果，开发体验直接起飞。\n分叉上下文\n：在Skills配置里加上`context:fork`，就能让技能在独立的「子环境」里运行。\n这解决了什么问题？\n之前执行复杂的Skills，中间产生的大量信息会污染主对话。问完一个问题，上下文就被塞满了乱七八糟的东西。\n现在有了分叉，主对话保持干净，技能在旁边安静地干活。\n生命周期钩子\n：Skills现在支持`PreToolUse`、`PostToolUse`和`Stop`钩子。\n翻译成人话就是：可以在Claude调用工具之前、之后插入自定义逻辑。\n比如每次写文件之前自动备份，或者每次执行命令之后记录日志。\n这已经是中间件级别的能力了。\n3. 会话传送功能\n这个功能必须单独拿出来说，因为它太酷了。\n场景是这样的：在claude.ai网页上开始了一个项目，聊到一半，发现需要在本地继续。\n以前怎么办？把对话复制粘贴过来？重新描述一遍需求？\n现在只需要一个命令：/teleport\n它会自动：\n验证是不是在正确的代码仓库\n拉取并切换到对应的分支\n加载完整的对话历史\n网页端的工作，无缝传送到终端。\n反过来也行，终端里的会话可以传送到claude.ai/code继续。\n这意味着什么？\n可以在任何设备上开始工作，在任何设备上继续工作。\n在公司用网页版起草，回家在终端里深度开发，第二天在咖啡厅用手机回顾进度。\nClaude Code变成了一个真正意义上的「云端大脑」。\n4. 更智能的权限管理\n之前一个让人烦躁的问题是：工具调用被拒绝的时候，整个智能体就停了。\n现在不会了。被拒绝之后，Claude会尝试其他方法继续推进。\n另外，工具权限现在支持通配符。\n比如想允许所有带-h参数的命令，可以写Bash(*-h*)。\n不用一个一个地配置权限了。\n5. 多语言响应\n可以配置Claude用母语来回复。\n日语、西班牙语、中文，都可以。\n对于非英语母语的开发者来说，这个功能太贴心了。\n为什么全球程序员都爱Claude Code？\n说完更新内容，来聊聊一个更本质的问题：\nClaude Code为什么能火成这样？\n一年收入10亿美金，连著名的OpenAI研究员卡帕西都说自己落伍了。\n这背后是什么逻辑？\n1. 它是真正的通用Agent\n虽然叫Claude Code，但它的能力远不止写代码。\n问答、写作、写网页、开发软件、数据分析，甚至拆分工资条，它都能干。\n它能把音频和图片快速合成视频。\n可以把它理解成一个能操控电脑的智能代理。\n它能看到文件系统，读取文件、分析文件、修改文件、输出文件。\n而沟通方式，就是自然对话。\n不需要写代码，不需要学命令，说人话就行。\n2. 文件夹思维\nClaude Code最棒的设计理念是「文件夹」。\n每次启动的时候，给它指定一个文件夹，这个文件夹就是这次任务的上下文。\n很多CC重度用户都有专门的Claude Code文件夹，里面分成很多子文件夹：笔记、数据分析、深度阅读、软件开发……\n每个任务一个文件夹，互不干扰。\n这种设计让工作天然有组织性。\n不像其他AI工具，聊着聊着就乱了，不知道在做什么。\n3. 危险模式带来的效率飞跃\n什么是危险模式？\n开启之后，Claude Code可以全自动操控电脑，不需要一次次确认。\n听起来很危险，但不开的话，每个操作都要点确认，效率根本起不来。\n当然，一定要做好备份。\n4. Skill生态\nSkills是Claude Code的杀手锏。\n不需要从零开始，直接用前人验证好的工作流就行。\n比如前端设计Skill，一句话就能重新设计网站首页。\n这是真正的「站在巨人肩膀上」。\n聊聊Boris这个人\n说到这里，不得不聊聊Claude Code背后的男人——Boris Cherny。\nBoris的履历很简单：前Meta高级工程师，现在是Anthropic的Staff Engineer，负责Claude Code。\n但他最有意思的地方在于：\nClaude Code100%的代码，都是用Claude Code写的。\n没错，他自己不写代码，他用自己造的AI来写代码。\n这听起来像个悖论，但这恰恰证明了Claude Code的能力——如果连它的创造者都信任它到这种程度，还有什么理由怀疑呢？\nBoris的工作方式也很疯狂。\n他日常会同时开10-15个Claude Code会话，有的在终端里，有的在网页上，每个会话当作一个独立的「工人」来用。\n他坚持用最慢但最聪明的模型，比如Opus4.5，因为他相信：\n更高质量的输出最终会加速整个开发过程。\n这个理念很反直觉。\n大多数人追求速度，想要更快的响应。但Boris认为，如果AI能一次做对，就不需要反复修改，总时间反而更短。\n还有一个细节：Claude Code的诞生其实是个「意外」。\n它最初只是Anthropic Labs团队的一个原型实验，用来探索AI模型的能力边界。没想到效果太好，直接变成了正式产品。\n2025年2月发布，不到一年，年收入就突破了10亿美金。\n这大概就是硅谷最经典的故事模板：一个工程师的「玩具项目」，最后变成了改变行业的产品。\nBoris还有一个习惯：他会维护一个CLAUDE.md文件，把它当作「团队记忆」。\n每次Claude犯了错误或者做对了什么，他都会记录下来。这样下次遇到类似场景，Claude就能直接使用这些经验。\n这个习惯后来变成了Claude Code的核心功能之一。\n你看，好的产品经理不需要做用户调研，因为他自己就是最苛刻的用户。\nClaude Code使用技巧\n最后分享几个实用技巧：\n1. 善用Claude.md\nClaude.md是Claude Code的核心配置文件，相当于它的「宪法」。\n每次启动，Claude都会自动加载这个文件。\n可以在里面写：\n这个项目是做什么的\n偏好规则\n需要注意的事项\n这样Claude每次都能快速进入状态，不用反复解释。\n2. 拖拽文件\n这是最简单但很多人不知道的技巧：\n直接把文件或文件夹拖到Claude Code窗口里。\n它会自动读取内容。\n不需要复制粘贴，不需要输入路径。\n3. 粘贴图片\n因为Claude Code运行在终端里，粘贴快捷键不是Cmd+V，而是Control+V。\n遇到需要图片的问题，截图后用Control+V粘贴进去，Claude就能看到了。\n4. 用/teleport无缝切换\n在网页端聊到一半，需要本地继续？\n直接/teleport，整个对话历史都带过来。\n5. 安装实用的Skills\n推荐去官方的Skills仓库看看：\nhttps://github.com/anthropics/skills\n安装方式也很简单，然后跟Claude说「使用xxx skill，帮我做xxx」就行了。\n「编程」的终局\nClaude Code2.1 的 1096 次提交，背后是一个团队对「AI 辅助编程」这件事的极致追求。\n但如果只把它当成一个「更好用的编程工具」，就太小看它了。\nClaude Code真正预示的，是编程这件事本身的终局。\n程序员会消失吗？\n这是每次AI编程工具更新时都会被问到的问题。\n答案是：不会消失，但会彻底改变。\nClaude Code让每个人都能「写代码」，但不是每个人都能「定义问题」。\n未来的程序员，不再是敲键盘的人，而是能把模糊的需求翻译成精确任务的人。\n这个角色更像产品经理，又像架构师，又像项目经理。\n代码变成了思想的副产品，而不是目的本身。\n自指性\nAI\n的哲学意义\nBoris用Claude Code来开发Claude Code，这不仅仅是一个有趣的花絮。\n这是AI发展史上的一个里程碑：\n工具开始制造自己。\n想想看，人类发明了锤子，但锤子不能制造锤子。人类发明了车床，车床可以加工零件，但不能完整地复制自己。\n但Claude Code可以。\n它可以理解自己的代码，修改自己的功能，优化自己的性能。\n这是一个自我迭代的系统。每一次更新，都让它更有能力进行下一次更新。\n1096次提交，很多都是Claude自己写的。\n这种正反馈循环会加速到什么程度？没人知道。\n从Vibe Coding到Vibe Everything\nClaude Code的成功证明了一件事：自然语言是最好的编程语言。\n不是Python，不是JavaScript，而是人话。\n这个逻辑可以延伸到所有领域。\n设计？让AI渲染。\n写作？让AI起草。\n分析？让AI处理。\n我们正在进入一个「Vibe Everything」的时代。\n不需要学习专业软件，不需要掌握复杂工具，只需要能清晰表达自己想要什么。\n这是真正意义上的\n「技术平权」。\n一个没学过编程的小商贩，可以用Claude Code做一个库存管理系统。\n一个不会Photoshop的创业者，可以让AI生成完整的品牌视觉。\n技能不再是壁垒，想法才是。\n开源生态的意义\n更重要的是，现在国产开源模型也跟上来了。\nGLM 4.7、MiniMax M2.1、Kimi K2，都能在Claude Code里用起来。\n不再需要担心封号，不再需要承受官方订阅的高昂费用。\n之前Claude Code一年十亿美金的收入，都被Anthropic一家吃掉。\n现在开源生态繁荣起来，每个云厂商都可以部署、售卖、盈利。\n而用户得到的，是只需要百分之一的价格，就能享受到同样的智能。\n这不只是商业模式的变化，而是权力结构的变化。\nAI 的能力不再被几家巨头垄断，而是变成了像水电一样的基础设施。\n代码是新的文字，\n而这次，每个人都可以执笔。\n参考资料：\nhttps://x.com/bcherny/status/2009072293826453669\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663691&idx=1&sn=928990405faa5b9ece87ada39cd30cd2&chksm=f0486754acf553f0a59d9abf400b40e625b970dff9a9fda2d1744a009eaff584ad2156ce5d5c&scene=0&xtrack=1#rd",
      "publish_time": 1768192800,
      "publish_date": "2026-01-12 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/anthropics/skills\", \"https://x.com/bcherny/status/2009072293826453669\"]",
      "add_ts": 1768259747,
      "last_modify_ts": 1768346418
    },
    {
      "id": 437,
      "article_id": "51804",
      "title": "小模型层数好玄学：12/32/64层效果好，16/24/48/层效果糟",
      "description": "开源项目OpenEvolve作者揭示70M小模型的多个关键发现：模型架构影响有限，深度-宽度比（“形状”）更为关键；层数存在“玄学”，12、32、64层表现优异，其中32层最佳，而16、24、48层效果差；并深入解析了该现象背后的训练动态与收敛机制，为小模型设计提供了新思路。",
      "content": "一水 发自 凹非寺\n量子位 | 公众号 QbitAI\n小模型身上的“秘密”这下算是被扒光了！\n知名开源项目OpenEvolve作者，刚刚用一篇长文揭示了\n70M小模型\n的几个重要发现：\n其一，架构的重要性远低于大家的想象。\n相比之下，模型“形状”\n（深度-宽度比）\n更重要。\n其二，小模型层数也存在“玄学”\n，12/32/64层效果好，16/24/48/层效果糟，而且最佳层数为32。\n当然了，作者还解密了这一“层数玄学”的背后原因——\n“隐藏维度”是否大于等于512\n。\n上述结论一出，社区里迅速刮起了一股讨论之风，大家还与作者进行了各种互动：\n别急，咱这就详细看看——\n发现小模型层数存在“玄学”\n开始之前，简单介绍下作者\nAsankhaya Sharma\n。\n他最为人熟知的成就主要包括：1）在很多人还主要围绕模型规模、参数量和训练方法打转时，他率先关注到了大语言模型的“推理时计算”，并以唯一作者的身份发表了一篇论文进行详细叙述；2）开源了OptiLLM、OpenEvolve、Adaptive Classifier等一众知名项目。\n在本次研究之前，他和团队已经发现——\n「50% FinePDFs+30% DCLM+20% FineWeb-Edu」是训练小模型GPT-2的最佳数据集组合，使用标准的12层架构，其平均准确率可以达到38.50%。\n于是他们想接着探讨：\n模型架构是否和数据组成一样重要？\n标准的GPT-2使用12层和768隐藏维度。但这设计于2019年，适用于约1.24亿参数。对于一个用10亿tokens训练的70M参数模型，这仍然是最优的吗？\n为了弄清这个问题，他们着手开始了一系列实验。\n实验第一步——确保除了模型架构，其他因素保持一致，包括模型参数、训练数据、训练时间和硬件配置等。\n然后通过改变7种GPT-2变体的“形状”\n（即深度和宽度的变化）\n，来对比同一架构内不同“深度-宽度配比”对性能的影响。\n结果发现，从4层→64层，模型性能并未如预想那般，随着层数增加或减少而平滑变化，而是清晰分裂成了两个阵营：\n“好”的层级\n：包括12L、32L、64L，平均得分在约38%左右；\n“糟”的层级\n：包括16L、24L、48L，平均得分在约32%左右。\n作者表示，\n两个层级之间平均相差超过6个百分点，且每个层级内部的差异极小\n（约0.5%）\n，出现了明显的两极分化\n。\n原因出在“隐藏维度”上\n进一步分析表明，这一现象背后的关键因素是\n隐藏维度（hidden dimension）\n。\n隐藏维度可理解为神经网络的宽度，每个词经由模型转换后都会变成一个数字列表。假设“人工智能”这个词的隐藏维度是768，它就代表这个词在模型内部会被表示成一个由768个数字构成的向量。\n作者发现，\n模型的“隐藏维度”必须大于等于512，这是一个基础门槛\n。\n当模型处于12层时，其隐藏维度恰好为512，所以表现出色。\n至于宽度更窄的32层和64层模型也能成为“优等生”的原因，主要是它们通过特殊的深度配置进行了“补偿”——\n前者属于“黄金补偿点”，在宽度为384的情况下，32层这个特定的深度能最高效地弥补宽度的不足，取得了所有配置中的最高分；而后者属于“暴力补偿”，虽然宽度只有256，但凭借极深的层数强行拉高了性能。\n16L、24L和48L处于“死角”，它们的隐藏维度太窄，深度又不在可以弥补的最佳位置。\n由此，作者也总结出了一套规则——\n模型要想性能好，必须满足三种条件之一。1）隐藏维度大于等于512；2）正好处于32层；3）位于64层以上的极深层，以进行补偿。\n而且必须再次提醒，\n32层属于全场最佳\n。当隐藏维度=384时，32层配置获得了38.50%的最佳总体得分，甚至略胜于标准的12层设计。\n进一步发现：“形状”比架构选择更重要\n在确定了“32层”这个最佳深度后，作者又比较了12种不同架构的表现，包括LLaMA3、Qwen3、Gemma3等模型。\n结果发现，\n在70M模型范围内，所有现代架构的表现都惊人地相似，平均差异不到2%\n。\n自回归模型\n：包括GPT-2、LLaMA3、Qwen3、Gemma3、MoE等，平均性能集中在32%到33%之间；\n扩散模型\n：包括dLLM、Dhara等，平均性能集中在31%到32%之间。\n作者表示，现代架构改进\n（RMSNorm、RoPE、GQA）\n是为70亿以上参数的模型设计的，在70M参数的情况下无法带来可衡量的优势。\n完整测试结果be like：\n这也意味着，对小模型来说，精心调整的“形状”可能比选择哪个具体的“架构变体”更重要。\n意外之喜：扩散模型有自己的独特优势\n此外，虽然扩散模型的平均准确率略低于自回归模型，但研究认为这点“缺陷”完全可以通过其他方面弥补。\n这主要体现在两大方面：\n推理速度和幻觉率\n。\n和传统自回归模型相比，扩散模型的推理速度要快上3.8倍，非常适合处理批量任务。\n且在所有测试架构中，扩散模型在衡量真实性的TruthfulQA基准上得分最高\n（达49.27%）\n，表明其“幻觉”更少。\n作者还顺带解释了这背后的原因，核心有三个：\n双向注意力机制允许模型在做预测时考虑完整上下文。\n迭代改进使模型能够在多个去噪步骤中“重新评估”其原始预测结果。\n非自回归生成模型或许能够减少“滚雪球效应”，即早期幻觉累积成更大的误差。\n不过，无论是自回归还是扩散模型，都可以用一个小技巧来增加事实准确性——\n作者表示，\n通过在模型里加入一种叫“Canon层”的特殊结构\n（本质是一种精心设计的卷积层）\n，普通模型能让事实性得分提升1%，扩散模型效果更明显，能提升超过2%。\n而且增加的“Canon层”仅增加了0.13%的参数开销，性价比极高。\n而更更重要的是，通过使用LLaDA 2.0论文中的\nWarmup-Stable-Decay方法\n，可以将现有的自回归模型高效转换为扩散模型。\n划重点，\n需要的数据量、成本、训练时间通通仅为原来的1/10\n。而且作者发现：\nWSD转换不仅与从头训练的结果相当，而且在几项基准测试上超越了后者。\n推出集大成者： Dhara-70M模型\n基于所有发现，作者和团队最后推出了\nDhara-70M\n这个模型。\n其构建方法为：首先采用最佳的自回归架构\n（LLaMA3-Canon）\n，然后使用WSD方法将其转换为扩散模型。\n如此一来，Dhara-70M也就具备了两者的优势——\n既有自回归模型的知识储备，又有扩散模型带来的吞吐量和事实性优势。\n作者表示，这项工作最大的意义或许在于提醒大家——\n对于资源有限的小语言模型构建者，不应盲目追求最新的架构魔法。首先应关注基础的“深度-宽度配比”，确保模型不落入“死亡区域”；其次，如果应用场景需要高速处理且对事实准确性要求高，那么扩散模型是一个极具竞争力的选择。\nDhara-70M开源地址：\nhttps://huggingface.co/codelion/dhara-70m\n参考链接：\nhttps://huggingface.co/blog/codelion/optimal-model-architecture\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860939&idx=2&sn=9c950767a1129126570928f523c936e1&chksm=e9b8bc258603f85c0b61189156b1086a583b506993aa30e64e194dd1a042503b67d6a3d7d9d9&scene=0&xtrack=1#rd",
      "publish_time": 1768192800,
      "publish_date": "2026-01-12 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://huggingface.co/codelion/dhara-70m\", \"https://huggingface.co/blog/codelion/optimal-model-architecture\"]",
      "add_ts": 1768259753,
      "last_modify_ts": 1768346421
    },
    {
      "id": 438,
      "article_id": "51803",
      "title": "华人女学霸AI杀疯！本科最难数赛12题全对，自主证明首次公开",
      "description": "24岁华人女学霸Carina Hong研发的AxiomProver在素以高难度著称的2025年普特南数学竞赛中斩获满分，成为首个在此赛事中12题全对的AI系统。该成就引发广泛关注，陶哲轩等顶尖学者认为标志着AI在数学推理领域迈入新阶段。结合GPT-5.2 Pro在数学任务中的超强表现，AI正逼近“奇点”时刻，展现出前所未有的逻辑推导能力，令全球震撼。",
      "content": "新智元报道\n编辑：元宇 桃子\n【新智元导读】\n在人类满分都罕见的普特南数赛上，AI直接12题全对拿满分。陶哲轩等大佬预言AI已经取得了重要里程碑，再加上GPT-5.2 Pro在数学上强到「离谱」的表现，那种「奇点将近」的直觉，真的压不住了。\n全网震撼！\n今天，24岁华人女学霸Carina Hong初创打造的AxiomProver，在2025 Putnam数学竞赛拿下了满分成绩。\n12道题，AI全部答对！\n与此同时，AxiomProver自主生成的Lean证明也正式公开。\n这一竞赛，堪称北美本科生数学竞赛的天花板级别，人类需在6小时攻克12道题。\nPutnam竞赛总分120分，\n要接近满分极其罕见\n，通常只有Putnam Fellows（前几名）才能做到。\n网友表示，「AxiomProver拿下Putnam竞赛比夺得IMO金牌更厉害，解决下一个千禧难题可能比预想的要来得更快」！\n最近，陶哲轩公开表示，ChatGPT等AI工具基本可以自主解决「埃尔德什问题」，瞬间登上HK热榜。\nOpenAI总裁Greg、科学家Sebastien Bubeck纷纷激动转发。\n看来，千禧年难题，或许离破解之日不远了......\n「本科最难数赛」夺下满分，全网震撼\n先来看看AxiomProver，如何在「本科版最难数学竞赛」中拔得头筹。\nhttps://axiommath.ai/territory/from-seeing-why-to-checking-everything\n在AxiomMathAI的官方博客中，把所有的Lean证明都公开了，还把题目分成了这么几类：\n人类直觉简单，但形式化起来却极为繁琐的问题；\nAI出人意料地攻克人类未曾预料到的问题；\nAxiomProver和人类采用不同数学思路解出来的问题。\n之所以这么分，在于AI与人类对「难度」感知并不一致。\n团队指出，以后更理想的工作流大概是：\n人主要负责提供灵感的想法，而机器负责快速自洽检查与形式化落地，甚至推动数学研究中的新抽象选择。\n人类觉得简单，AI直接「怀疑人生」\n但在Putnam竞赛中，最「好下手」的往往是微积分题。\n回想Mathlib库（ Lean语言的数学库，相当于给AI用的「数学字典」）的早期，随便一本分析教材第一章里的简单概念，都要花很长时间才能定义清楚。\n而在Putnam2025里，这类题通常出现在每个部分的第二题。\n以A2题为例。\n这道题如果给人来看，我们只需要附上一张函数图像，你的眼睛会瞬间捕捉到曲线的走势，非常直观。\n但是这在系统那里，你必须把这些线条、趋势、拐点，统统翻译成严格的数学语言。\n人类要是逐行去读Lean代码，那就更像是在「坐牢」。\nB2也是同样的故事。\n对人类来说一个很简单的「正性引理」，在Lean里要写60多行。\nA2的引理h_nonpos_on_Icc和B2的引理psi_support_pos，成了各自证明里最难啃、最费篇幅的「钉子户」。\n这就是形式化的代价。\n组合构造：友善的「野兽」\n假如你正在下午茶时间的黑板边聊天，朋友给你展示了一个精妙的组合构造，你卡壳半天，他只说了句：「先这样，再那样，把这个切开……」\n然后你恍然大悟：怎么就变得这么简单了？\n这种感觉很震撼，问题仿佛一瞬间就溶解了。\n但一旦你试图把这种直觉「钉死」成一个完全形式化的证明，尤其是在证明助手里，事情就会出奇地棘手。\n拿A5题来说。\nAxiom团队和AxiomProver都想到了同一个很自然的思路：\n对一个排列里最大（或最小）的元素做归纳，把剩下的切成两段，然后据此推理。\n用人类语言来讲，这种论证可能两三段就写完了，但在Lean的世界里并非这样简单。\n每一个小角落的特殊情况、每一处记账式的繁琐细节，都必须被明确写出来，没有任何模糊空间。\n当然，也不能使用人类最爱的「省略号」。\n于是结果就令人咋舌：这份Lean形式化代码长达2054行，生成耗时518分钟！\n这并非要吐槽Lean，而是从「人类显而易见的证明」走到「这是机器校验过的证明」，你所必须缴纳的税。\nAI神来之笔，人类没想到的\nAI有望破解组合数学，几何引擎并非必需\n一直以来，大家都觉得组合题是AI的软肋。\n事实上，这类题目「臭名昭著」到很多工程团队直接选择放弃。\n看看近几年的IMO，最难的硬骨头几乎都是组合题。IMO 2025唯一没做出来的题，以及IMO 2024的两道题，全是组合。\n所以，当Axiom团队看到Putnam的A3是一道组合博弈论，B1是一道欧式几何时，心里的预期其实是极低的。\n毕竟，AxiomProver目前连一个完整的几何引擎都没有。\n然而，奇迹发生了。\n系统自主解出了A3和B1。那一刻，Axiom办公室里直接有人尖叫了起来。他们根本没想到它现在就够解开这两道题！\nAxiom团队赛后分析，这并不意味着几何或博弈论变容易了，而是说明他们之前的悲观判断有点过于草率了。\n这些例子说明，这道「门槛」比他们之前判断的更微妙、更有层次。\nA3的解决的确有点运气成分。\n在这道题中，「后手玩家」有一个非常干净的必胜策略，一旦看破，只需要机械执行，不需要去探索复杂的博弈树。这种「少状态、无分支」的逻辑，恰好是Lean最擅长的。\nB1题可能更有趣。\n问题B1的概要\n题面涉及「外心」这个纯几何概念。系统给出的解法风格非常几何，但当Axiom团队的数学家读的时候，如果没有图，根本跟不上。\n这就有点讽刺了，因为机器从头到尾也没画过图。最后，人类不得不自己画了个草图，才弄明白机器到底干了什么。\n机器似乎很满足于纯符号推理，它没画过一张图就建立了一个「两条圆恰好相交于两个点」的事实。\n而人类则强烈依赖图像。\n为了更具体地让人感受这些机器证明如何和人类的几何直觉对齐，这里截取了一段Lean代码，用来建立这样一个事实：\n在某个特定构型下，两条圆恰好相交于两个点（这个构型里，每个圆都经过另一个圆的圆心，而且两个圆心不同）。\n而对人类读者来说，配图能立刻把情况讲清楚。\n作为对照，Axiom小组也想出了一个类似的几何论证。\nAxiom团队对于B1的解法\n这次AxiomProver意外搞定人们原本没指望它能做出来的组合题，而且也证明了没有几何引擎也不一定不行。\n蛮力的胜利：数学家几乎都栽在了这个问题上\nAxiom团队坦言，这次AxiomProver系统最终解出A6，令他们非常震惊。\n因为这道题几乎把他们内部的所有人都打败了。\n他们的一位数学家认出它属于p进算术动力系统的范畴，他知道处理p进幂级数展开必须非常小心，甚至他的大方向都是对的。\n但「方向对了」和「把题彻底做完」是两码事。在A6这场硬仗上，机器赢了。\nAxiomProver居然5小时就做完了它，而且这是12题里Token用量第二高的一题。\n而且，它在处理相关幂级数的求导上用了一种特别笨拙、但确实有效的方法——人类绝对不会这么写，但它就是能跑通。\n有时候，我们不得不承认，蛮力本身也有一种不讲道理、碾压一切的优雅。\n同一道题，两条完全不同的路\nA4可能是这一批里最有故事的一题，因为它完美展示了「人类的代数直觉」与「AI的几何视角」的碰撞。\n人类数学家看到这道题，本能地去找代数方法，靠符号推演。\n然而在竞赛中，AxiomProver展示了另一种思路：它会把人类觉得「应该代数」的东西转成几何，把人类想用图讲清楚的内容，变成机械化的组合核算。\n在下面两道很有代表性题：A4和B4，人类和AxiomProver解法各有特色。\nA4：人类想推公式，AI先把它变成几何\nA4的设定看起来就很「代数」。\n人类选手在这套题上分歧也很典型：\n有人很快给出k=3的构造，于是开始怀疑答案会随着n以某种方式增长；另一个人从小n往上堆，排除了k=2，直觉上觉得答案应该就是3。\n两人一起拼出了若干针对不同n的临时构造，能支持「答案是3」这个猜测，但离「统一的通用构造」还有距离。\n与此同时，他们隐约觉得背后可能藏着表示论的影子：这也很符合人类的经验——当一个条件像「关系编码」时，很容易联想到群作用、表示、代数结构。\nAxiomProver的建议简洁到有点「反常识」：让每个A_i 都是投影到某个单位向量v_i上的秩一投影（rank-one projection）。\n验证层面，形式化里最「重」的节点，往往集中在一件在人类眼里极其自然的事：\n认真检查一圈n个向量的构造确实满足要求。\n人们往往认为，「显然相邻垂直，其他不垂直，环状闭合也没问题」。\nLean大量篇幅被花在「把直觉变成可检验的陈述」上，这恰好反映了形式化的性格：它不反对直觉，它拒绝用直觉替代证明文本。\nB4：人类用一张图讲完，AI直出1061行代码\n在B4中，思路是构造一个从特殊对角线（第一条非零对角线）到取值为1的条目的单射。\n人类选手盯着图看一会儿，函数怎么定义就很清楚了；也能看出来它为什么成立，图自己就把话说完了。\n题在于Lean不会「看图」。\nAxiomProver直接产出了1061行Lean代码，把行列的组合性质一条条磨到结论出来。\n它能在缺乏图像沟通的情况下，用耐心把组合性质逐格展开，把证明变成可验证的流水线。\n奇点临近，GPT-5.2攻克难题\n不仅如此，就连菲尔兹奖得主陶哲轩认为，AI已经取得了重要里程碑。\n这两天，波兰数学家Bartosz Naskręcki在X上发的帖把这把火点得更旺了。\n他直言，GPT-5.2 Pro在数学上的表现强得离谱：面对非琐碎问题，很难找到真正能让AI卡死的点。\n即使是高难题，一到两小时的来回交互，模型就能把答案推出来。\n最要命的是，他还用半开玩笑的方式表达震撼：\n要么OpenAI 背后有一支「全天候的小精灵与顶尖数学家团队」在实时代打，要么模型已经具备非常扎实的能力。\n甚至，让人产生「奇点将近」的直觉。\n这次Putnam 2025竞赛的成绩，对于AxiomProver团队来说是一次重要的胜利。\n他们在博客最后总结道，「看着系统实时硬啃竞赛数学，确实有种说不出的爽感：即使它经常用一些我们根本想不到的方式。」\n这也引出了一个深层问题：到底是什么让一道数学题对机器来说是「难」？\n显然，人类觉得难的，和机器觉得难的并不是一回事。\n人类怕繁琐的枚举，怕没有灵感（巧妙构造）就卡死的死胡同。但对机器而言，什么才是真正的障碍？目前还是一个黑盒。\n但正因为双方擅长和卡壳的点不一样，「人机协作」才显得如此合理。\n而Axiom正在构建这样一个世界：人类直觉由机器验证来「落地」，而机器验证反过来激发人类直觉。\n这就好比做咖啡：机器负责磨豆子，人类负责品咖啡。\n在Axiom看来，我们不需要去硬攻数学研究每一个问题。\n正如Grothendieck所说的「涨潮的海」——我们抬高水位，直到问题被那些坚硬的陆地慢慢包围，最终自然溶解。\n虽然目前人类还未完全到达那一步，但奇点已经临近。\nAxiomProver在Putnam 2025竞赛中取得满分，以及GPT-5.2 Pro在数学上的惊艳表现，都在提醒我们：\n这个未来更近了。\n参考资料：\nhttps://x.com/apples_jimmy/status/2009742681166229687\nhttps://x.com/axiommathai/status/2009682955804045370\nhttps://x.com/nasqret/status/2008672809094905970\nhttps://jmlr.org/papers/v24/22-125.html\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663474&idx=1&sn=743530017404ab054cb940240ea94704&chksm=f005c256205152fc5b2344bca1b645605c857190250543fa5ffec20d9ee674e1c713629eb73e&scene=0&xtrack=1#rd",
      "publish_time": 1768192800,
      "publish_date": "2026-01-12 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://axiommath.ai/territory/from-seeing-why-to-checking-everything\", \"https://x.com/apples_jimmy/status/2009742681166229687\", \"https://x.com/axiommathai/status/2009682955804045370\", \"https://x.com/nasqret/status/2008672809094905970\", \"https://jmlr.org/papers/v24/22-125.html\"]",
      "add_ts": 1768259756,
      "last_modify_ts": 1768346424
    },
    {
      "id": 439,
      "article_id": "51802",
      "title": "吴恩达：图灵测试不够用了，我会设计一个AGI专用版",
      "description": "吴恩达提出2026年新目标：创建专为AGI设计的“图灵-AGI测试”，以衡量通用人工智能发展水平。他认为2025年或是人工智能工业时代开端，模型性能持续突破，AI应用日益重要，顶尖人才竞争激烈，基础设施建设加速，推动社会生产力提升，AGI迎来快速发展期。",
      "content": "鹭羽 发自 凹非寺\n量子位 | 公众号 QbitAI\n新年新气象！AI大神\n吴恩达\n2026年目标公开：\n要做一个新的图灵测试，他称之为\n图灵-AGI测试\n。\n光看名字就知道，这个测试专为AGI而生。\n去年是AGI水涨船高的一年，吴恩达在其年度总结中也曾表示：\n2025年或许会被铭记为\n人工智能工业时代的开端\n。\n创新推动模型性能到达新的高度，AI驱动的应用变得不可或缺，顶尖企业人才争夺激烈，基础设施建设推动社会生产总值增长。\n学术界和工业界频繁提及AGI概念，硅谷的公司也会为抢先AGI定下季度目标。\n但关于AGI的定义至今还没有统一标准，现有基准测试还常常误导大众，使其高估当前的AI水平。\n吴恩达注意到该趋势，于是新的图灵测试将试图弥补这一空白。\n正如网友所言：\n要衡量智能首先要定义智能。\n图灵-AGI测试设想\n传统的图灵测试在AGI时代显然不够用。\n它由艾伦·图灵在上世纪五十年代提出，提出用人机对话来测试机器的智能水平。\n在测试过程中，人类评估者需要确定他们是在与人还是与机器交谈。如果机器能够成功骗过评估者，那么就算通过了测试。\n但现在的AI显然不再满足于简单的对话交互，而是要构建起经济有用的系统，所以亟需一个能够\n衡量AI工作能力\n的测试。\n而这就是图灵-AGI测试的核心，要让AI像人类一样智能，并完成大部分的知识型工作。\n测试对象将会是AI系统或专业人士，他们将会被提供一台可以访问互联网并配备浏览器和Zoom等软件的计算机。\n裁判将通过计算机为测试对象设计一个\n多日的体验任务\n，比如作为客服，会先被培训一段时间，然后要求执行接听电话的任务，并需要提供持续的反馈。\n只要AI能够像人类一样熟练完成工作任务，就会被认为通过测试。\n该测试将聚焦AGI的经济性和实际产出，更接近普世意义下对AGI的初始定义——可用于工作和生产场景的智能。\n它也会比基准测试更考验AI的\n通用能力\n。\n现在几乎所有的AI基准测试，如GPQA、AIME、SWE-bench等，都会预先确定一个测试集。这意味着AI团队都会直接针对已发布的测试集来调整他们的模型。\n这就导致很多AI模型榜单排名靠前，但真实物理世界中又能力不够。\n去年闹得沸沸扬扬的Llama 4刷榜丑闻就是其中一个典型，明明数据看起来都很不错，但用户真正上手后却傻眼了。\n此外，固定测试集只能衡量AI在某一狭窄领域的能力。相比之下，图灵测试可以由评委自由提出任意问题，没有提前限定范围，更能判断系统在通用任务上的表现。\n在改进的图灵-AGI测试中，延续了这一设定，裁判可以任意设计体验任务，而受测试的AI或人类测试者均不会事先知道任务内容，这将比基准测试更能判断AGI水平。\n同时为了校准社会对AI的期望，吴恩达表示，或许他将举办一场图灵-AGI测试，让所有AI参与其中。\n即便最后的结果会是所有AI系统均未能达到标准，但也能平息长期以来对AGI的过度炒作。\n这种降温将会为AI领域创造更稳健的环境，让行业重新聚焦于\n非AGI级别的实际进步\n，比如开发有实用价值的应用，而不是沉迷于实现AGI的营销噱头。\n从长期来说，图灵-AGI测试也会为AI团队设定一个具体的努力目标，而非模糊地实现人类级智能。\n倘若真有某一家公司能够通过测试，其成果也必定具备真实价值，图灵-AGI测试将会为真正的AGI突破提供可信的判定依据。\n所以接下来，只需拭目以待。\n参考链接：\n[1]https://x.com/AndrewYNg/status/2008578741312836009?s=20\n[2]https://www.deeplearning.ai/the-batch/issue-334/\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860753&idx=2&sn=27f5abc31a3e2511f0dd7f5f59f19012&chksm=e9f838d57560c0e0e2d486758c344cd4a961bb74820e86ffddd31155fca6381283af910d7757&scene=0&xtrack=1#rd",
      "publish_time": 1768192200,
      "publish_date": "2026-01-12 12:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/AndrewYNg/status/2008578741312836009?s=20\", \"https://www.deeplearning.ai/the-batch/issue-334/\"]",
      "add_ts": 1768259759,
      "last_modify_ts": 1768346430
    },
    {
      "id": 440,
      "article_id": "51801",
      "title": "Nat. Commun. | 解码蛋白质–蛋白质相互作用的语言",
      "description": "MINT是一种新型蛋白语言模型，专用于建模蛋白–蛋白相互作用（PPI）。相较于仅刻画单个蛋白的DRUGONE，MINT通过跨链注意力机制，在大规模高置信度PPI数据上无监督训练，有效捕捉相互作用蛋白间的上下文依赖关系，提升了对多聚体蛋白复合物的原生表示能力，为理解蛋白质相互作用网络提供了新工具。",
      "content": "DRUG\nONE\n蛋白语言模型在刻画单个蛋白的结构与功能方面已取得显著成功，但在原生表示蛋白–蛋白相互作用（PPI）方面仍存在局限。研究人员提出 MINT（Multimeric Interaction Transformer），一种专门用于建模相互作用蛋白集合的蛋白语言模型。MINT 通过无监督方式在大规模高置信度 PPI 数据上进行训练，并引入跨链注意力机制，以学习相互作用蛋白之间的上下文依赖关系。研究结果表明，MINT 在多种 PPI 相关任务中显著优于现有蛋白语言模型，包括结合亲和力预测、突变效应评估，以及抗体–抗原和 TCR–表位–MHC 相互作用建模。该模型为解析复杂蛋白相互作用网络提供了通用而可扩展的计算框架。\n大规模语言模型在自然语言中的成功启发了其在蛋白序列建模中的应用。通过将氨基酸序列视为“语言”，蛋白语言模型能够在无监督条件下学习结构和功能模式。然而，在真实细胞环境中，蛋白质往往通过形成复合体来执行功能，仅建模单条序列不足以全面理解蛋白生物学。\n现有方法通常将相互作用蛋白独立编码，或简单拼接序列，这会忽略关键的相互作用上下文信息，尤其在多链复合体（如抗体–抗原或 TCR–表位–MHC 体系）中问题更加突出。研究人员据此提出，蛋白语言模型需要从“单序列建模”迈向“相互作用集合建模”，以真正学习蛋白相互作用的语言。\n方法概述\nMINT 基于 ESM-2 架构进行扩展，核心创新在于 跨链注意力机制。模型在保持单链自注意力以捕获序列内部依赖的同时，引入专门的跨链注意力模块，用于建模不同蛋白链之间的上下文关系。\n在训练阶段，研究人员利用来源于 STRING 数据库的大规模 PPI 数据，通过改进的掩码语言建模目标，使模型在预测单个氨基酸时能够同时利用同链与跨链信息。该设计使 MINT 能够灵活处理任意数量的相互作用蛋白序列，从而突破传统蛋白语言模型在 PPI 表达上的结构性限制。\n图 1｜蛋白–蛋白相互作用（PPI）建模方法及 MINT 模型总体框架。\n结果\n通用蛋白–蛋白相互作用预测性能\n在二分类 PPI 预测、结合亲和力回归以及突变效应预测等标准任务中，MINT 在多个数据集上持续优于现有蛋白语言模型。即使与参数规模更大的通用模型相比，MINT 仍表现出明显优势，说明针对 PPI 的结构化建模比单纯扩大模型规模更为关键。\n图 2｜MINT 与其他蛋白语言模型在通用 PPI 任务中的性能比较。\n抗体相关相互作用建模\n研究人员将 MINT 应用于抗体–抗原体系，联合建模重链与轻链序列。结果显示，MINT 在抗体结合亲和力和表达水平预测任务中优于抗体专用模型，尤其在训练样本极少的情况下仍保持较强性能，表明其具备良好的小样本泛化能力。\n图 3｜MINT 与抗体专用蛋白语言模型的性能对比。\nTCR–表位–MHC 复合体建模\n在 TCR–表位及 TCR–表位–MHC 相互作用预测任务中，MINT 仅需极少微调即可达到或超过现有方法。该结果表明，MINT 学到的多蛋白序列表示具有高度可迁移性，能够适配不同类型的免疫相关相互作用任务。\n图 4｜微调后的 MINT 与 TCR–MHC–表位模型的性能比较。\n癌症相关 PPI 突变效应预测\n研究人员将 MINT 应用于癌症相关蛋白相互作用突变分析。模型能够有效区分破坏相互作用的致病突变与非致病突变，其预测结果与实验验证高度一致，显示出在疾病机制研究中的潜在应用价值。\n图 5｜癌症相关 PPI 突变效应预测结果。\n疾病相关突变与病毒免疫逃逸分析\n研究人员进一步利用 MINT 分析癌症相关突变对 PPI 的扰动效应，模型预测结果与已验证的实验结论高度一致。此外，在 SARS-CoV-2 研究中，MINT 能够准确预测抗体对不同变异株的交叉中和能力，成功捕捉病毒进化过程中中和谱的变化趋势。\n图 6｜抗体对 SARS-CoV-2 变异株的交叉中和预测。\n讨论\n研究人员提出的 MINT 证明了，将蛋白相互作用作为“相互依赖的序列集合”而非孤立序列进行建模，是提升 PPI 预测能力的关键路径。跨链注意力机制使模型能够有效捕捉相互作用上下文，从而在多种下游任务中取得一致优势。\n尽管当前模型主要基于序列信息，研究人员认为，未来将结构信息与序列语言模型进一步融合，有望在保持高扩展性的同时，实现更精细的相互作用建模。总体而言，MINT 为系统性理解蛋白相互作用语言提供了重要工具，对疾病机制解析与治疗策略设计具有广泛应用前景。\n整理 | DrugOne团队\n参考资料\nUllanat, V., Jing, B., Sledzieski, S. et al. Learning the language of protein-protein interactions. Nat Commun (2026).\nhttps://doi.org/10.1038/s41467-025-67971-3\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512688&idx=1&sn=905b7d09bb155e4712438a172051c0e6&chksm=fd309e42381df711fe5ee31715f6595d887d65197470571647aaec764bea284565ff3aece33a&scene=0&xtrack=1#rd",
      "publish_time": 1768192200,
      "publish_date": "2026-01-12 12:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s41467-025-67971-3\"]",
      "add_ts": 1768259762,
      "last_modify_ts": 1768346433
    },
    {
      "id": 441,
      "article_id": "51800",
      "title": "救命！AI浏览器都卷成这样了，怎么大家还是用Chrome啊？",
      "description": "AI驱动的新浏览器Atlas与Comet正以智能代理功能如订票购物挑战传统浏览器，标志浏览器竞争进入智能化时代。尽管Chrome仍以71%市场份额主导，但新兴AI浏览器致力于提供更主动的个性化服务，引发对便捷与安全平衡的思考。这场变革或将重塑用户上网习惯，决定未来浏览体验走向。",
      "content": "新智元报道\n编辑：倾倾\n【新智元导读】\n浏览器之争已不单是速度对决！新玩家Atlas与Comet能替你订票购物，AI代理时代已至；然而老大哥Chrome凭71%份额稳坐钓鱼台。未来，是拥抱全能助手的便捷，还是警惕安全漏洞的深渊？决胜局就在此刻！\n你上网的时候，通常用什么浏览器？Edge，Chrome，还是其他？\n有一股AI新势力，开始对这些老牌浏览器发起挑战。\n就在我们习惯了地址栏搜索、标签页切换时，一股AI新势力正悄然潜入。\n它们不满足于只做一个展示网页的容器，而是想成为你的私人秘书，甚至是替你在网络世界的「替身」。\n争奇斗艳：AI新玩家亮出绝活\n这场大战的开端，源于两款激进的新产品。\n你的私人AI秘书：ChatGPT Atlas\n2025年秋天，OpenAI推出了名为\nChatGPT Atlas\n的浏览器。\n它基于Chromium内核，把ChatGPT直接建在浏览器里。\n在浏览网页时，可以随时拉出侧边栏问问题，它会记住你的浏览历史，帮你完成多步任务，比如研究东西、自动购物或整理信息。\n「浏览器记忆」功能，可手动选择是否开启。\n开启这个功能后，浏览器能记住你之前看的房子、求职信息、旅行计划，下次直接接着聊。\n最亮眼的还是代理模式。对它说「帮我计划周末去上海」，它能自己开标签搜机票、比酒店、填表单。当然，重要决策还是由你决定。\nPerplexity Comet：超级研究与购物助手\n紧随其后的Perplexity Comet则是另一副面孔。它更像是一个不知疲倦的研究员，主打「一边浏览，一边调研」。\n上网时，Comet的助手会陪你一起浏览，实时回答问题、自动化任务、总结页面、生成带来源的报告。\n如果问它「这个手机值不值得买」，它能立刻在侧边栏甩出一份对比表格，带上优惠券信息和全网评价。\n当Comet Assistant 识别出某项任务很重要，例如登录特定网站或完成购物车中的购买——它会暂停操作，并在继续执行前征得您的许可。\nMicrosoft  Copilot：稳扎稳打的跟随者\n传统的领路人Microsoft Edge也没闲着，它依靠Copilot稳扎稳打，在Windows生态的掩护下，成了不少办公族最稳妥的AI助手。\n围城内外：老大哥Chrome的护城河\n看了这些眼花缭乱的功能，你可能会想：Chrome这下要被挤下宝座了吧？\n其实远没有。到2026年初，Chrome依然占据着全球约71%的市场份额，稳坐钓鱼台。\n原因也很简单：它在Android手机和Windows电脑上是默认选项。\n速度快、扩展多、账号同步无缝，亿万用户已经养成习惯，想换没那么容易。\n谷歌也没坐以待毙。从2025到2026年，Gemini迎来好几波重大更新，连安装包都不用下，就能体验到更聪明的Chrome。\n不需要下载任何新应用，只要在地址栏提问，Gemini 就能跨标签整理信息，甚至帮你总结一段视频。\n它还能跨标签找信息、自动处理一些简单任务，比如总结视频或找回以前浏览过的页面。\n最近几个月，Gemini in Chrome也开始开发代理功能，帮你处理重复琐事，比如预约理发或每周买菜——你说一句话，它就在网页上操作。\n移动端也随之更新。现在，美国用户已经能免费用Gemini in Chrome，响应更快，能边刷边问。\n不知不觉间，Chrome就变了样，发现时AI已经无处不在。\n很多人试过Atlas和Comet后直呼新鲜，但一到日常工作、刷剧、同步书签，还是切回Chrome——毕竟习惯难改。\n新玩家想在短期内动摇这个基本盘，难度确实不小。\n繁华背后的暗礁\n然而，新技术的萌芽总是伴随着争议。在Reddit和X上，关于AI浏览器的吐槽从未停歇。\n最让人头疼的是性能。不少用户发现，Atlas和Comet在执行复杂任务时，偶尔会「宕机」，卡顿、崩溃，甚至让笔记本电脑发烫严重。\n有人开玩笑说，用AI浏览器上网，就像是在给电脑「人工催熟」。\n更深层的危机藏在安全防护里。网络安全机构LayerX的一项测试发现：在钓鱼网站的拦截测试中，传统的Chrome和Edge拦截率都在50%左右，而Atlas仅有5.8%。\n「提示注入攻击」更是AI浏览器绕不开的噩梦。\n黑客在网页中埋下一段指令，当你让AI总结网页时，它可能已经被洗脑，偷偷转发了你的私人邮件。\nOpenAI坦言，这或许是一个永远无法彻底根治的漏洞。甚至有咨询机构建议企业暂时封杀这些AI浏览器，理由很简单：它们优先考虑了体验，却牺牲了安全。\n未来，谁主沉浮\n2026年才刚开始，这场较量远未到终局。\n短期内，Chrome的霸主地位依然坚如磐石。但在特定领域，缝隙已经产生：研究者偏爱Comet的敏锐，ChatGPT的重度用户则离不开Atlas的深度。\n未来，我们可能不再需要自己点来点去，而是对着屏幕说一句话，AI就能帮我们搞定一切。\n但在这之前，谁能先解决那个名为「安全」的难题，谁才能真正赢得用户的长久信任。\n你会继续守着老朋友Chrome，还是已经准备好，搭上这艘稍显颠簸却充满想象力的AI航船？\n参考资料：\nhttps://www.ft.com/content/5d566029-6aee-4627-a665-81108a1eb70e\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663691&idx=2&sn=b53690113ac311d9c21d8e1865c1a773&chksm=f0a2afaa872bc1a2889e978f49d2a7b8c0e452fe9bcf87839f7835f85ddeb36c7941ae77ed63&scene=0&xtrack=1#rd",
      "publish_time": 1768192200,
      "publish_date": "2026-01-12 12:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.ft.com/content/5d566029-6aee-4627-a665-81108a1eb70e\"]",
      "add_ts": 1768259765,
      "last_modify_ts": 1768346436
    },
    {
      "id": 444,
      "article_id": "51797",
      "title": "",
      "description": "据爆料，DeepSeek计划于2024年春节前后发布新一代V4模型，重点聚焦编程能力，目标是超越Claude和GPT系列等顶尖闭源模型，成为“编程之神”。该模型或将在代码生成、理解与优化方面实现重大突破，引发行业关注。若属实，V4有望在一个月内重塑AI编程格局，推动代码自动化迈向新高度，标志着国产大模型在垂直领域的重要进展。",
      "content": ":\n，\n.\nVideo\nMini Program\nLike\n，轻点两下取消赞\nWow\n，轻点两下取消在看",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663441&idx=1&sn=58690dec17797ec7b6a4fecbd03b45a5&chksm=f0c7246be5593378ed9af922171cf4260675afebad0ca99be44c204a4c22e460840a04140cc4&scene=0&xtrack=1#rd",
      "publish_time": 1768191600,
      "publish_date": "2026-01-12 12:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768259776,
      "last_modify_ts": 1768346444
    },
    {
      "id": 446,
      "article_id": "51795",
      "title": "CES 新爆款！追觅具身智能扫地机，打破「人形唯一论」",
      "description": "CES展上，一款被誉为“新物种”的消费级具身智能机器人引发全场关注，展现出未来养老等实际应用场景，成为AI与机器人技术融合的亮点。作为全球科技创新的风向标，CES见证了从VCR到自动驾驶等多项技术的首发。本届展会中，人工智能全面渗透，智能机器人表现尤为抢眼，预示着具身智能正加速迈向商业化落地，或将深刻改变未来生活方式。",
      "content": "新智元报道\n编辑：Aeneas KingHZ\n【新智元导读】\nCES上，这个「新物种」引起了全场围观，掌声雷动！而且，它已经开始考虑帮你养老了。或许，这就是未来最快商用的消费级具身智能机器人。\n从第一台VCR到第一台等离子电视，从蓝光到4K，从智能家居到自动驾驶……无数改变人类生活的技术，在拉斯维加斯国际消费者电子展CES完成首秀。\n毫无疑问，AI和机器人席卷了这届CES，让人直呼疯狂。\n就在刚刚结束的这届CES展会上，这个「具身智能新物种」一亮相，就把现场点燃了。\n现场，展台被围得里三层外三层，观众纷纷举起手机，原本只是路过的群众，都停下脚步凑上来。\n在掌声和喝彩声中，有人发出感叹——「这玩意儿，有点东西」。\n它会打招呼、会「伸手」拿东西，能在客厅、卧室、阳台自由移动，甚至可以稳定上下楼梯。\n这些还不够，超出我们想象的是，它除了能做家务，还开始尝试整理、看护、陪伴这些科幻片里的高阶任务。\n是的，这一届扫地机器人，已经准备帮你养老了！\n不必先「像人」，而是先有用\n这两年，具身智能在国内太火了，各种人形机器人刷足了眼球。\n但在消费级场景上，却始终存在这样一个现实问题：什么时候，具身智能机器人能「飞入寻常百姓家」？\n追觅扫地机给出的答案，显得很冷静：不先做「像人」，而是先做「有用」。\n他们没有对「人形」盲目追随，而是打造了一款全新形态的新物种产品。显然，这是一次基于「形态必须服务于家庭场景」第一性原理的进化。\n可以说，追觅扫地机提供的这种消费级具身智能新解法，让业界耳目一新。\n四足轮腿，又稳定又灵活\n仔细观察这个具身智能新物种，它的形态让人充满了想象空间。\n如果一个机器人长成这样——双臂灵活、底盘稳健、关节灵活，显然，它能在人类生活场景中游刃有余。\n让我们来具体拆解它的各个部位。首先，它采用了四足轮腿结构。这种结构，就解锁了它的不少潜能。\n在具身智能这个行业，轮腿路线本身就比双足路线更有工程优势。\n双足行走的前提是持续不断地保持动态平衡，让自己不摔倒，就是一大难题。在实验室和展台上很酷的机器人，一旦进入家庭场景，摔倒的代价都会被无限放大。\n但轮腿结构，则恰恰相反。它不是在模仿人走路，而是通过轮子，获得稳定、连续、高效的移动能力，再用腿去解决台阶、障碍和空间变化的问题。\n「稳定性」，是它的一种默认状态。这条路线的结果，就是更稳、更快、承重更强、更安全。\n当扫地机器人伸出双臂\n另外，这个新物种身上「长出」的双臂，也非常吸引眼球。\n「双臂」的加入，是具身智能从「灵活适应地形」向「主动改变环境」跨越的关键一步。\n因为这种仿人双臂结构，它就可以具备执行复杂任务的能力，具有操作工具的可能，比如整理桌面、夹取物体、甚至使用其他电器等。\n如果说「四足轮腿」解决了机器人在家庭中「去哪儿、怎么去」的问题，那么「双臂」则解决了机器人到达目的地后「干什么、怎么干」的问题。\n家务、养老，各种功能你想象不到\n一个具身智能机器人长成这个形态，它能做的，可就太多了。\n围绕着家庭这个场景，它可以不断解锁自己的能力边界。\n这种覆盖全屋的移动能力，说不定以后\n能\n让它成为智能家居的移动中枢。\n这样一个会走路的家务中枢，可以帮你干许多「人类不想干，但又必须有人干」的琐事。比如收拾桌面、整理满地的儿童玩具、把用完的工具收回抽屉。\n同时，它还能成为家居环境里的小助手。比如人在组装家居，它就可以递工具；人在厨房做饭，它就可以过来帮你端盘子、清理台面。\n还有一个最吸引人的功能，就是养老功能。除了24小时健康监测、跌倒监测，还可以辅助拿物体，比如递水、拿药等养老关怀。\n在未来，它甚至可能操控洗衣机等家用电器等，实现真正类人处理能力。\n这，就是追觅扫地机对形态的判断——形态，不是一种审美选择，而是场景最优解。\n追觅扫地机新物种\n最快落地的家用具身智能\n追觅扫地机的这个产品，很可能是未来最快商用的家用具身智能机器人。\n除了绕开了人形机器人最大的死亡陷阱走路，选择了天然适合家居环境的形态。它还有一个天然的优势——过往十年的深厚积累。\n在做出这个「新物种」之前，追觅扫地机就在具身智能领域积累了不少经验。\n创始人兼CEO，是2005级清华大学航天航空学院校友。\n在清华校内「天空工场」期间，他的核心团队涌现了一个大胆设想：用造飞机的技术，用在消费电子产业，到底会怎样？\n于是，算法和工程能力被注入智能家居设备。\n追觅扫地机\n科技成立后，长期保持高比例研发投入\n，产品研发与设计人员占比达到60%，研发投入占收入的7%以上，研发投入领先行业。\n在机器人、电子机械、移动机器人等，他们已取得了多项专利。\n从路径规划、环境感知、避障识别，到仿生机械臂、机械足、机械手，他们的产品已飞入千家万户。\n在上面这个新物种诞生前，他们的扫地机跑了很多年。\n而具有具身智能大模型能力后，这些机器不仅可以理解语音指令、识别物体与环境、规划路径，还可以在物理世界中做决策。\n这次升级来自追觅扫地机对用户需求的深刻洞察。\n在深刻的用户洞察基础上，用户全链路参与「预研发布会」、「产品内测」、「产品公测」 直到上市。\n每年用户测试总计超过100万次，为产品设计和改进注入鲜活的灵感与真实反馈。\n可以说，全球科技行业里，\n追觅扫地机\n可能是最懂用户、最尊重用户的品牌。\n家用具身智能的最快落地路径\n许多业内人士的判断是，追觅扫地机这次具身智能新物种，极有希望成为家庭具身智能的用户最优选。\n跟常规人形机器人比，追觅扫地机的具身智能新物种有更高的稳定性、安全性与家庭场景适应性，更务实、更贴近消费端。\n跟实验室机器人比，它的供应链更成熟，大规模制造能力更强；场景理解能力也会更强，工程化能力会更强。\n更重要的是，他们打造了全球广受认可的商业品牌、遍布全球的销售网络：\n全球布局\n：产品已覆盖120多个国家和地区，入驻6500多家全球线下实体门店，累计服务家庭超过3000万个。\n市场领先\n：在22个国家和地区拿下市占率第一；在12个国家及地区市占率超过40%。\n不同于「小巧硬件+大模型」新玩家，基于扫地机成熟商业网络，追觅扫地机这次的「具身智能新物种」更易商业化。\n最终，在「小巧硬件+大模型」与「通用人形」的之外，追觅扫地机将验证一条更务实、更易商业化的第三条道路。\n不是终点，而是起点\n具身智能新物种的诞生告诉我们：这一次，机器人站了起来，伸出了手，看向了更大的家庭世界。\n以后，它或许还会走进更多我们想象不到的场景。\n而在CES 2026，这个故事才刚刚开始。\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663683&idx=1&sn=4d5dda46a310ed4d57589b3b5e54a1da&chksm=f04ebffd0a3356b30fffab48d4e66cc58b523f0b762ca57d553e0e93ca3215b518d98a13224e&scene=0&xtrack=1#rd",
      "publish_time": 1768189860,
      "publish_date": "2026-01-12 11:51",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768259782,
      "last_modify_ts": 1768346453
    },
    {
      "id": 449,
      "article_id": "51792",
      "title": "30人团队震撼英伟达！Jim Fan自曝三个教训，重押世界模型",
      "description": "英伟达Jim Fan领导的GEAR实验室正全力攻关AI领域的“物理图灵测试”，旨在让机器人在真实物理环境中完成复杂任务，实现与人类无异的操作能力。这一挑战被视为AI发展的下一阶段乃至终极目标，需融合感知、推理、控制等多技术突破。尽管进展显著，但真正通过测试仍需时日，标志着机器人智能化迈向新高度。",
      "content": "新智元报道\n编辑：桃子\n【新智元导读】\nAI终极挑战——物理图灵测试。这一年，英伟达Jim Fan领导的GEAR实验室，正用一套完整的技术栈，向这堵高墙发起总攻。\n机器人「物理图灵测试」距离真正通关，还需一段时间。\n英文达杰出科学家Jim Fan表示，我正全身心投入一个单一使命：为机器人解决「Physical Turing Test」（物理图灵测试）。\n这是AI的下一个挑战，甚至可能是「终极挑战」。\n如今，人类光靠文本字符串实现的超级智能，恐怕就已经能拿到诺贝尔奖了。\n不过机器人现在，连黑猩猩级灵活度、操作能力都还没有。\n「莫拉维克悖论」（Moravec's paradox）是一种必须被打破的诅咒，是一堵必须被撕碎的高墙。\n没有任何东西，应该阻挡人类在这个星球上实现指数级的物理生产力，甚至有朝一日，把这种能力带到其他星球。\n这一年，Jim Fan带队在英伟达创立了GEAR实验室，30人团队已初具规模。\n令人震撼的是，团队的产出和影响力，远远超过它的规模。\n从基础模型、世界模型、具身推理、仿真、全身控制，以及各种形态RL，几乎囊括了机器人学习的完整技术栈。\n接下来，一起看看GEAR 2025年。\nGR00T基础模型，一年三代\nGR00T是英伟达提出的「通用机器人基础模型体系」，核心目标——\n让机器人像「大模型」一样，具备跨任务、跨场景、可迁移、可学习的能力。\nGR00T VLA基础模型，是最具代表性的成果之一。\n它将视觉+语言+动作三种模态，统一到一个端到端的模型中，让机器人能够看懂环境、理解人类指令，生成可转型的连续动作。\n这一年，英伟达对GR00T VLA进行了高频迭代：\n今年3月开源了N1，紧接着6月发布了N1.5，12月又推出了N1.6。\nGR00T N1\n3月，GR00T N1开源首发，仅用20亿参数，即可验证VLA架构在真实机器人任务中的可行性。\n它的开源，为整个机器人生态系统提供了一个前沿的基础模型。\nGROOT N1可以轻松在上见任务中进行泛化，或执行需要长上下文和多种通用技能组合的多步骤任务。\n比如，抓取、用一只手臂/两只手臂移动物体，以及在两个手臂之间传递物品。\nGR00T N1.5\nGR00T N1.5是N1的升级版，在架构、数据、建模层面进行了多重优化。\n它使用了更领先的视觉语言模型——Eagle VLM，提升了语言理解和视觉感知力。\n还加了FLARE损失，提高了对未来动作预测的一致性。\n在仿真机器人基准任务中，GR00T N1.5成功率明显由于上一代模型。\nGR00T N1.6\n这个月迭代后的GR00T N1.6，集成了更强的架构和推理能力，让机器人在复杂环境中表现更智能、更稳健。\nGR00T Dreams：机器人「做梦」学习\n视频世界模型，是数据驱动的物理和图形引擎。\nDreamGen，是一种利用AI视频世界模型，来生成合成训练数据的机器人学习框架。\n它通过「数字梦境」生成大量虚拟机器人行为，再从视频中提取动作数据，用于训练机器人策略，从而实现新任务和新环境中的泛化学习。\n实验验证了，机器人从只有一个动作示例的场景中，通过「梦境」生成数据，在新任务上有很高的成功率。\n在10个新环境+22种新行为上，机器人都能泛化成功。\nSONIC：让机器人具备「通用运动能力」\n为了让机器人不仅只会做某个动作，而具备几乎所有人类可以做的动作。\n英伟达团队提出的SONIC，一个用于人形机器人控制的通用运动系统。\n它的核心目标是，让人形机器人像「角色」一样被控制、学习和驱动。\nSONIC出发点很明确，运动追踪是人形机器人可扩展基础任务。\n只要机器人能够稳定、准确跟踪任意人类动作，那么行走、转身、抬手、抓取、协调全身运动等复杂行为，都可以统一到同一个框架中。\n论文中，团队将运动追踪任务进行了「超大规模化」（Supersize），即9000+GPU小时，以及超1亿动作帧，覆盖了机器丰富的人体动作分布。\n这让SONIC学会了人类运行的整体结构，而且，研究人员还基于SONIC构建了多种控制与交互方式。\nSONIC的探索，为通用人形机器人提供了一个可扩展、可编程、可落地的运动基础系统。\n其他重磅成果\n除了以上一些重磅成果，团队还在面向VLA强化学习后训练上，以及sim2real的RL实践做出了探索。\n比如PLD（Probe, Learn, Distill），让机器人从失败中「自我进化」。\n它是一套真实世界「自举式学习」的训练范式。\n一般来说，机器人在真实环境中，执行高精度操作任务时，或失败、会偏移，都成为了一种信号。\nPLD引入了真实世界残差强化学习（Residual Reinforcement Learning），不推翻原有策略，而在已学会动作基础上，学习「微调残差」，专门负责纠错、恢复、补偿。\n最后，它将真实世界中学到的改进经验，蒸馏回VLA主模型，使用SFT，将临场学到的技巧变成长期能力。\n对此，Jim Fan表示RL能够通过后训练VLA模型，在高精度任务（如GPU插入）中实现接近100%的鲁棒性。\n这是解决工业部署「最后一公里」难题的关键进展。\nVIRAL（Visual Sim-to-Real at Scale）是一套纯视觉人形机器人Sim-to-Real框架，为了解决一个长期难题——\n让机器人在真实世界中，零样本完成「走+站+操作」连续长时任务。\n研究在Unitree G1人形机器人上，验证了最长54次连续loco-manipulation循环，没有任何真实世界微调，仅使用RGB纯视觉输入。\n另外，DoorMan是英伟达首个仅用RGB视觉、完全在仿真中训练、可零样本迁移到真实世界的人形机器人「开门」策略。\n它在复杂的行走+操作+物体交互任务上，性能甚至超越人类遥操员。\n「开门」是人形机器人最难的任务之一，因为它同时包含行走、精细操作等任务的重叠。\n以往的方法，要么依赖特权状态（即力、位姿），要么真实数据昂贵、不可规模化。\n而DoorMan诞生后，仅用了RGB，相同控制线，就让仿真直出真实世界。\n此外，还有FLARE全新算法， 是一种隐式世界模型的策略，核心思想是预测「未来对动作有用的表示」。\n它不会去预测未来的像素，而是预测对动作有用的未来潜变量，让机器人在不断增加推理开销的情况下，学会提前想一想。\n在训练中，FLARE在一个标准VLA策略模型中，引入了未来token——在Transformer中额外加入少量学习token。\n实验结果显示，在4个真实操作任务，每个任务100条轨迹，GR-1平均成功率在95.1%。\n左右滑动查看\n三个教训，重注「视频世界模型」\n这一年，所有人几乎都在为「氛围编程」（vibe coding）感到震惊。\n休假这几天，Jim Fan还分享了对机器人这个蛮荒又混乱的西部世界的焦虑——\n我在2025年学到的三个教训\n1. 硬件跑在软件前面，但硬件的可靠性，严重卡住了软件的迭代速度\n我们已经看到了，许多堪称艺术品的工程成果，比如Optimus、e-Atlas、Figure、Neo、G1等等。\n最强的AI还远远没有把这些前沿硬件的潜力榨干。\n机器人的「身体」能做到的事情，明显多于它的「大脑」目前能指挥的范围。\n但问题在于，照看这些机器人往往需要一整支团队全天候盯着。\n和人类不一样，机器人不会自己从磕碰中恢复。过热、马达损坏、各种诡异的固件问题，几乎每天都在折磨工程师。犯错是不可逆的，而且一点都不留情。\n到头来，唯一真正能规模化的，只有我的耐心。\n2.\n机器人\n领域的基准测试，依然是一场史诗级灾难\n在大语言模型圈子里，很多人已经把MMLU和SWE-Bench当成常识了。\n机器人这边？先把手里的啤酒端稳。几乎没有任何共识：用什么硬件平台、怎么定义任务、评分标准是什么、用哪种仿真器，或者真实世界要怎么搭。\n结果就是——每个人在自己临时为每次新闻发布现编的基准上，按定义都是SOTA。\n每个人都会从100次重试里，挑一个最好看的demo拿出来秀。\n2026年，我们这个领域必须做得更好，别再把可复现性和科学严谨性当成「二等公民」。\n3. 基于VLM的VLA，总感觉哪里不对\nVLA指的是「视觉-语言-动作」（vision-language-action）模型，这是当前机器人「大脑」的主流路线。\n套路也很简单：拿一个预训练好的VLM checkpoint（模型权重），在上面嫁接一个动作模块。\n但仔细想想就会发现，VLM本身是被高度优化来刷诸如视觉问答这类基准的。\n这直接带来了两个问题：\n(1) VLM里的大多数参数，其实都服务于语言和知识，而不是物理世界；\n(2) 视觉编码器被刻意训练去丢弃底层细节，因为问答任务只需要高层语义理解。但在机器人灵巧操作中，恰恰是这些细微细节最要命。\nVLA的性能并没有任何必然理由会随着VLM参数规模一起提升。\n问题在于，预训练目标本身就是错位的。相比之下，以视频世界模型作为预训练目标，看起来要合理得多。我已经在这条路线上下了重注。\n有网友反问道，如果说世界模型是更优的预训练目标，但当前主流模型仍基于VLM构建并产出实际成果，而世界模型却主要用于策略评估和合成数据，而非直接控制？\nJim Fan称，它们都是2025年的模型，期待2026年下一个重大突破。\n物理图灵测试，还有多远？\n今年，在红杉资本一场闭门演讲中，Jim Fan首次引入了「物理图灵测试」概念。\n短短20分钟视频，他生动有趣地介绍了当下具身智能的困局，大规模仿真如何挽救机器人未来，以及英伟达具身智能的路线图。\n那究竟什么是「物理图灵测试」？\n一场周末party让家里乱的一团糟（左），有人替你收拾了一切，还为你和伴侣准备了烛光晚餐（右）。\n当你回家后看到一切，根本无法辨别这是人类的作品，还是机器的作品——这便是物理图灵测试核心想法。\n那么，人类现在走到哪一步了？离这个目标还有多远？\n三个生动的例子，让人爆笑全场。不得不承认，这就是当前具身智能的现实。\n左右滑动查看\nJim Fan表示，Ilya曾说过预训练终结了，同时AI「石油」互联网数据几乎枯竭。\n但若要和机器人领域数据相比，搞LLM的研究者就会明白有多么得天独厚了。\n在英伟达，团队让机器人实操去收集数据，机器人关节控制信号，且数值随时间持续变化。\n任何人无法从互联网上获取，必须通过自己收集才能完成。\n他们具体是如何操作的？\n其中，离不开一个重要的方式——遥操。它能够识别人手姿态并流式传输给机器人系统。\n通过这种方式，可以教机器人从面包机中拿起面包，然后在上面淋上蜂蜜。\n可以想象的到，这是一个非常缓慢极其痛苦的过程。\n在Jim Fan看来，如果将真实数据收集放在坐标轴中展示，它根本无法实现Scaling Law。\n如何去打破这一困境，为机器人创造「无限能源」？\n英伟达给出了一个更直接的解决方案——虚拟世界。\n在仿真世界中，可以以1万倍于现实的速度训练，并通过「域随机化」（Domain Randomization）增强泛化能力。\n也就意味着，系统在仿真中学会的任务，最终零样本迁移到真实世界。\n接下来，Jim Fan提出了仿真世界模拟的三个阶段——\nSimulation 1.0（数字孪生）\n它需要精确建模机器人与物理环境，优点在于快、可控、可迁移，而缺点是构建成本高，强依赖人工建模。\nSimulation 1.5（数字表亲）\n大量3D资产、场景、纹理由模型自动生成，仍结合传统物理引擎，在真实与仿真之间取得工程上「足够接近」。\nSimulation 2.0（神经物理引擎）\n可利用视频扩散模型，直接生成「可交互的未来」，不再显示建模物理规则。\n它的优势在于，能处理软体、液体等复杂物理，通过语言生成「反事实世界」。\nJim Fan还将其称之为「数字游牧者」（Digital Nomad）。\n再回到当初这张坐标图，机器人数据Scaling Law很好地呈现了出来。\n最终，所有这些数据流入了一个统一的模型，即VLA——输入：语言+视觉，输出：动作控制。\n也就是如上提到了GR00T系VLA基础模型，从N1，到N1.5，再到N1.6三个版本不断升级迭代。\n最后，Jim Fan指出物理AI的未来，不只是更聪明的机器人，而是一种新基础设施。\n比如Physical API、物理APP Store，让技能可以像软件一样被分发到机器人系统中。\n几天前，谷歌大佬Logan Kilpatrick预测，2026年将成为具身AI的重要一年。\n用不了不久，我们将在现实世界中看到更多的机器人。\n参考资料：\nhttps://x.com/DrJimFan/status/2003879965369290797?s=20\nhttps://www.youtube.com/watch?v=_2NijXqBESI\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663501&idx=2&sn=1705204bb739e1f996422c7be221c5e5&chksm=f0cc57667e6a919ae3918268e0dc8947642cc83a7f83e1658d999ef69d95d7fdc0e77245a893&scene=0&xtrack=1#rd",
      "publish_time": 1768189800,
      "publish_date": "2026-01-12 11:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/DrJimFan/status/2003879965369290797?s=20\", \"https://www.youtube.com/watch?v=_2NijXqBESI\"]",
      "add_ts": 1768259794,
      "last_modify_ts": 1768346462
    },
    {
      "id": 450,
      "article_id": "51791",
      "title": "离开马斯克后，他把人形机器人做成了这样",
      "description": "MATRIX-3人形机器人突破传统局限，具备高安全性、自主决策与环境适应能力，可灵活应对不同任务与场景。它能在人类生活空间中稳定行走、精准操作，无需预设脚本即可完成日常活动，推动人形机器人从专业应用迈向日常生活，展现物理智能新高度。",
      "content": "允中 发自 凹非寺\n量子位 | 公众号 QbitAI\n如果你对人形机器人的印象，还停留在——走两步就摔、抓东西像戴着拳击手套、干活前得先写一堆脚本……\n那么\nMATRIX-3\n的出现，可能要强行带你“翻篇”了。\n作为一款主打\n安全、自主、可泛化\n的物理智能机器人，它更敢跟人待在同一个空间，更能自己做判断，也更不怕换任务、换环境。\n能干的活更像人，目标也不止于专业场景“打工”，而是开始往日常生活里迈。\n做出这台机器人的，是一家去年才正式走到台前的公司——\n矩阵超智\n。\n但底子不轻、来头不算低调：公司团队背景横跨\n特斯拉、英伟达、OpenAI\n等顶级技术体系，目标也非常直给：\nAGI路线上的通用人形机器人。\n可以说，一年前，MATRIX-1亮相时，外界更关注两点：全身复合材料带来的“观感完成度”，以及实时语音对话的交互感。\n但这次，创始人\n张海星\n——这位有着30年消费电子实战经验的“老极客”，2021年加入特斯拉，\n参与Optimus人形机器人开发，并主导特斯拉中国设计中心相关项目\n——\n显然想通过从底层算法到顶层应用的系统性重构，让机器人走得更远：\n进工厂，飞入寻常百姓家。\n△\n矩阵超智创始人兼CEO张海星\n走向可泛化的人形\nMATRIX-3能够执行类似人类的任务，并准备好从专业场景走进人类日常生活的广阔天地，这标志着人形机器人从“执行预设指令”迈入“\n理解并适应物理世界\n”的新阶段。\n为实现这一跨越，矩阵超智的工程团队突破了材料科学、驱动技术、感知算法与人工智能的多重边界，为MATRIX-3注入了以下三大优势：\n仿生设计与感知新生\n：首次将仿生肤质与高维触觉传感深度融合，使机器人获得接近人类的物理交互直觉。\n灵巧操控与拟人步态\n：通过“灵犀之手”与“超能关节”，实现了前所未有的操作精度与如影随形的自然移动能力。\n认知内核与零样本泛化\n：搭载的全新神经网络具备强大的零样本学习能力，使机器人能快速适应未知任务与复杂环境。\nMATRIX-3为人形机器人的规模化、实用化铺平了道路，并为商业服务、制造业、物流、医疗辅助及未来家庭服务奠定了全新的软硬件平台标准。\nMATRIX-3的三大能力内核\n1、仿生设计与感知新生：赋予机器“肌肤”与“触觉”\n为了让机器人与人类和环境进行安全、细腻的互动，MATRIX-3引入了革命性的人类仿生工程学设计。\n具体体现在以下两点：\n3D立体织物仿生肤质\n机身覆盖首创的三维编织柔性织物，它不仅提供柔软、亲和的触感，更内嵌分布式传感网络。这层“肌肤”能缓冲意外接触，并感知接触位置与力度，极大提升了人机共处的安全性。\n多模态感知融合\n指尖集成了高灵敏度触觉传感器阵列，可感知\n0.1N\n的压力变化。\n结合升级的视觉系统，基于大规模预训练空间感知基础模型，提升机器人对空间可操作性Affordance的理解和利用，MATRIX-3形成了“眼看”与“手触”互补的视触觉感知系统，使其能像人类一样，通过触摸判断物体的材质、形状及抓握状态，实现对易碎品、柔性物体的精细化操作。\n2、灵巧操控与拟人步态：重新定义运动与操作极限\nMATRIX-3的运动性能实现了质的飞跃，核心在于其仿生关节与灵巧末端。\n灵犀之手（高自由度灵巧手）\n搭载全新设计的\n27维自由度\n灵巧手，其关节构造与运动范围高度拟人。\n结合键绳驱动技术，在保证力量和速度的同时，实现了极致的轻量化与精准控制，可完成诸如使用工具、操作精密仪器、折叠物品等复杂任务。\n自然步态与超能关节\n基于大规模人类运动捕捉和视频数据开发的通用运动控制模型，让MATRIX-3的行走、转身、上下坡姿态如人类般流畅自然。\n其动力核心是一体化直线关节，该关节集高功率密度、低噪音与高可靠性于一身，提供了稳定、高效且敏捷的全身体运动基础。\n3、认知内核与零样本泛化：“预先编程”到“认知推理”\nMATRIX-3搭载了矩阵超智自主研发的全新神经网络架构。\n零样本泛化能力\n该系统的核心突破在于强大的零样本任务泛化能力。\n意思是，无需针对每一个特定任务进行海量数据训练，MATRIX-3便能通过基础物理规律理解和简单的指示，并能在全新的环境下快速学习新技能操作新的物体，更大拓展了其应用边界与部署速度。\n通用智能操作模型\n在数据规模和数据质量驱动下，灵巧操作得以真正实现。\n机器人能够自主规划抓取策略、避障路径，并实时调整力度与姿态，完成一系列需要手眼协调与即时判断的复合任务。\n从能力展示到应用检验\nMATRIX-3是矩阵超智人形机器人走向成熟应用的关键里程碑。\n它融合了仿生设计、极致灵巧的物理执行以及具有泛化能力的人工智能，构建了一个真正为理解并作用于物理世界而生的智能体。\n“MATRIX-3的产品哲学，是让机器智能以最自然、最安全的方式融入人类的物理空间。”\n对此，矩阵超智首席执行官\n张海星\n表示：\n我们从不是要复制人类，而是创造一种能够延伸人类能力、承担重复性劳动的新物种。今天，我们向这个未来迈出了坚实的一步。\nMATRIX-3针对特定行业合作伙伴的\n早期体验计划现已开放\n，并预计于2026年启动首批试点部署。\n*本文系量子位获授权刊载，观点仅为原作者所有。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247860772&idx=1&sn=13eb27e53fcde59b37b13c6c416b829c&chksm=e97a39e6246db8583bca23fd0690dad700eed99b09891da3b29290f123e5668ef5f51aa6b459&scene=0&xtrack=1#rd",
      "publish_time": 1768189800,
      "publish_date": "2026-01-12 11:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768259798,
      "last_modify_ts": 1768346466
    },
    {
      "id": 451,
      "article_id": "51841",
      "title": "Next generation medical image interpretation with MedGemma 1.5 and medical speech to text with MedASR",
      "description": "We are updating our open MedGemma model with improved medical imaging support. We also describe MedASR, our new open medical speech-to-text model.\n\nThe adoption of artificial intelligence in healthcare is accelerating dramatically, with the healthcare ind",
      "content": "Defining the technology of today and tomorrow.\nPhilosophy\nWe strive to create an environment conducive to many different types of research across many different time scales and levels of risk.\nLearn more about our Philosophy\nLearn more\nPhilosophy\nPeople\nOur researchers drive advancements in computer science through both fundamental and applied research.\nLearn more about our People\nLearn more\nPeople",
      "article_url": "https://research.google/blog/next-generation-medical-image-interpretation-with-medgemma-15-and-medical-speech-to-text-with-medasr/",
      "publish_time": 1768340520,
      "publish_date": "2026-01-14",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://research.google/philosophy/\", \"https://research.google/philosophy/\", \"https://research.google/people/\", \"https://research.google/people/\"]",
      "add_ts": 1768346307,
      "last_modify_ts": 1768346307
    },
    {
      "id": 453,
      "article_id": "51839",
      "title": "Nat. Commun. | 超大规模虚拟筛选驱动孤儿受体GPR139 强效激动剂发现 ！",
      "description": "GPR139是中枢特异表达的孤儿GPCR，与多种神经精神疾病相关，但其内源性配体和功能尚不明确。近日，《Nature Communications》发表跨国研究，联合解析了GPR139的高分辨率结构，揭示其独特的激活机制与潜在药物结合位点，为开发针对精神分裂症、抑郁症及ADHD等疾病的新型靶向药物提供了关键结构基础，推动孤儿受体成为可行治疗靶点。",
      "content": "在神经精神疾病治疗领域，\n孤儿G蛋白偶联受体（GPCR）始终是极具潜力却充满挑战的药物靶点\n。G\nPR139作为中枢神经系统特异性表达的孤儿受体\n，其与精神分裂症、抑郁症、注意力缺陷多动障碍（ADHD）等疾病的密切关联，使其成为业界关注的焦点，但其内源性配体和功能仍属未知。\n近日，发表于《\nNature Communications\n》的一项跨国合作研究（瑞典、丹麦、中国等团队联合开展），通过“\n高分辨率结构解析+超大规模虚拟筛选+结构导向优化\n”的整合策略，成功破解了GPR139配体发现的核心难题，为该类靶点的药物研发提供了兼具科学性与实用性的范式。\n本文将从研究背景、核心技术路径、关键发现维度，对该研究进行专业且全面的深度解读。\n一、研究背景：孤儿GPCR药物研发的困境与GPR139的独特价值\n1. 孤儿GPCR的研发瓶颈\nGPCR家族是人体最大的膜蛋白家族\n，尽管仅占人类可成药基因的15%，却\n承载了34%以上已批准药物的作用靶点\n。然而，在非嗅觉GPCR中，仍有超过100个被归类为“孤儿受体”——\n其内源配体与生理功能尚未明确\n。\n这类受体的研发面临双重挑战\n：\n一是\n缺乏明确的功能学依据，难以设计针对性筛选策略；\n二是\n传统高通量筛选命中率低、配体活性重现性差，导致多数孤儿受体的治疗潜力未能被充分挖掘。\n2. GPR139的靶点特性与研究基础\nGPR139作为Class A孤儿受体，自2005年被发现以来，其独特的生物学特征逐步受到关注\n：\n表达特异性\n：仅在中枢神经系统（CNS）中表达，尤其在缰核、中脑等与情绪调节、认知功能、运动控制相关的脑区高度富集，而缰核正是精神分裂症、抑郁症等疾病的核心病理区域。\n功能关联性\n：GPR139基因变异与精神分裂症、ADHD直接相关，敲除该基因的小鼠会出现类精神分裂症症状；其信号通路与多巴胺、阿片类神经调节系统交叉，进一步暗示其在神经精神疾病中的关键作用。\n研发现状\n：此前虽有候选药物（如TAK-041）进入临床试验用于治疗精神分裂症相关快感缺失，但因疗效不足未能通过II期试验，核心原因在于\n缺乏高活性、高特异性的配体工具分子，且对受体信号传导机制的理解不够深入\n。\n3. 技术突破的必要性\n传统配体发现依赖内源化合物库筛选或同源受体序列比对，难以适配GPR139复杂的结合口袋结构\n。而冷冻电镜（cryo-EM）技术的成熟的大规模化学库的可及性，为结构导向的配体发现提供了可能——本研究正是基于这一技术背景，\n探索“结构解析+虚拟筛选”在孤儿GPCR中的应用价值\n。\n二、核心技术路径：从结构解析到体内验证的全链条设计\n研究团队构建了“结构基础-虚拟筛选-优化验证-机制解析-体内活性”的闭环研究体系\n，每一步均体现了严谨的科学设计与技术创新：\n1. 结构基础：高分辨率GPR139-配体复合物解析\n研究以GPR139与已知合成激动剂JNJ-63533054的cryo-EM复合物结构（PDB: 7VUG）为起点\n，明确了受体的正构结合口袋特征：\n该口袋深度埋藏，与其他Class A GPCR的结合位点存在重叠，但在形状和极性组成上具有独特性\n，为特异性配体设计提供了精准的结构模板。\n2. 超大规模虚拟筛选：亿级化合物库的高效筛选\n筛选规模\n：\n采用ZINC15数据库中的2.35亿个类先导化合物\n（cLogP≤3.5，分子量≤350 Da），覆盖未被合成的全新骨架结构。\n筛选工具\n：\n使用DOCK3.7软件进行分子对接\n，通过只考虑配体柔性的算法采样每个化合物平均3933种取向和178种构象，累计处理超过200万亿个复合物构象，计算量相当于单个CPU核心连续运行6年。\n筛选流程\n：\n初筛\n：基于 docking 得分筛选Top 300,000化合物（占总库0.12%）；\n去重与去干扰\n：剔除与已知GPR139配体高相似（Tc>0.5）及含实验干扰结构的化合物；\n聚类与可视化\n：基于拓扑相似性聚类为13106个簇，选取前1500个簇中心进行结合模式可视化人工审查；\n候选化合物合成\n：\n最终选取68个结构多样的化合物进行定制合成\n。\n3. 配体优化：结构导向的构效关系（SAR）探索\n针对初筛获得的最强效且骨架在药物发现中似乎尚未被探索的化合物\n（化合物1，EC₅₀=160 nM），\n进行两轮结构优化\n：\n优化策略\n：以cryo-EM结构为指导，聚焦化合物1的噻吩环、恶二唑环等核心骨架，从Enamine的340亿个按需合成化合物库中搜索7574个类似物；\n合成与筛选\n：分子对接后选取44个代表性类似物进行合成，通过钙动员实验和肌醇单磷酸（IP₁）积累实验验证活性；\n关键发现\n：\n明确了影响活性的核心结构特征\n，如4位甲基取代可提升3倍活性（化合物1.1，EC₅₀=50 nM），\n恶二唑环是维持活性的关键骨架\n，而吡啶环取代会导致活性显著下降。\n4. 机制验证：结合模式与信号通路解析\ncryo-EM验证\n：解析了GPR139与优化后最有潜力的化合物1.1（S-对映体）的复合物结构（PDB: 9M42，分辨率3.2 Å），证实了对接预测的结合模式（配体RMSD=2.9 Å），且发现化合物1.1（S）可诱导结合口袋的胞外区扩张，形成独特的水介导氢键相互作用。\n信号通路表征\n：通过BRET实验证实，GPR139可激活Gᵢ₂、Gᵢ₃、Gₒₐ、G_q、G₁₂多种G蛋白亚型，其中G₁₂蛋白偶联为首次报道，拓展了对该受体信号传导网络的认知。\n5. 体内活性验证：血脑屏障穿透与行为学效应\n选取代谢稳定性更高的化合物1.5（S）（CL_int=46 μL/min/mg，溶解度=24 μM）进行小鼠旷场实验：\n给药方式\n：30 mg/kg腹腔注射，1小时后脑内浓度达4.8 ± 1.0 μM，超过体外活性EC₅₀值，证实其可穿透血脑屏障；\n行为学效应\n：化合物1.5（S）可显著降低小鼠总移动距离，增加外周停留时间（触壁行为），表现出与参考激动剂JNJ-63533054相似的 locomotion 调节和焦虑样行为影响，验证了其体内生物学活性。\n6. AI模型评估：AlphaFold3在孤儿GPCR中的应用局限\n研究同时测试了AlphaFold3（AF3）预测受体-配体复合物结构的能力：\n已知靶点\n：AF3对GPR139-1.1（S）复合物的预测精度较高（配体RMSD=2.7 Å），但依赖于训练集中包含GPR139相关结构；\n未知靶点\n：对5个未纳入训练集的孤儿GPCR-配体复合物，\nAF3仅能准确预测1个复合物的结合模式，其余4个或结合口袋定位错误（RMSD = 6.3–20.3 Å），或配体构象偏差显著（RMSD=5.7-20.3 Å）\n，\n表明AI模型在未充分研究的GPCR配体预测中仍存在局限性，实验解析结构仍是不可或缺的基础\n。\n三、关键研究发现：从配体发现到机制创新的多重突破\n1. 配体发现：全新骨架的高效激动剂\n初筛获得5个完全激动剂\n（EC₅₀=160 nM-3.6 μM），其中化合物1-4的骨架与已知GPR139配体相似度极低（Tc<0.4），化合物2-4的拓扑结构与ChEMBL数据库中所有已知配体差异显著（Tc<0.3），为全新药物骨架的开发提供了起点；\n优化后化合物1.1（S）的EC₅₀低至50 nM\n，在稳定表达GPR139的CHO-K1细胞中EC₅₀进一步降至8 nM，\n是目前已报道的最强效 GPR139激动剂之一\n，且对M₁受体无交叉活性，特异性优异。\n2. 构效关系（SAR）：核心结构特征明确\n噻吩环\n：4位甲基取代可增强活性， larger 取代基会降低活性，呋喃环取代不影响活性，噻唑环和恶唑环取代会显著降低活性；\n恶二唑环\n：是维持活性的关键骨架，替换为三唑环或恶唑环会导致活性下降7-50倍；\n取代基效应\n：苯环上的甲基取代活性高于甲氧基取代，2位甲氧基取代可显著提升活性（化合物1.2，EC₅₀=50 nM）。\n3. 信号机制：G₁₂蛋白偶联的全新发现\nGPR139此前被认为主要通过G_q/11信号通路传导，\n本研究首次证实其可高效偶联G₁₂蛋白\n，且G₁₂激活是除钙动员外最显著的信号响应。G₁₂蛋白在神经元迁移、轴突导向及神经递质释放中具有重要作用，且与应激相关神经精神疾病密切相关，这一发现为设计偏向性信号配体提供了新的方向。\n4. 技术范式：结构导向+超大规模筛选的有效性验证\n本研究在挑战性更大的GPR139靶点的筛选命中率达7%，是传统高通量筛选的数十倍\n，且较此前GPR139虚拟筛选研究的命中率提升2倍，\n证实了“高分辨率结构+亿级化合物库”模式在孤儿GPCR配体发现中的优势\n——即使对于结合口袋复杂、内源性配体不明的靶点，仍能高效挖掘全新结构的活性配体。\n总结\n该研究通过整合前沿结构生物学、超大规模虚拟筛选和精密药理学技术，成功实现了GPR139强效激动剂的发现与优化，不仅为神经精神疾病药物研发提供了全新的先导化合物和靶点工具，更建立了孤儿GPCR配体发现的创新范式。其核心价值在于证实：即使对于内源配体不明、结构复杂的孤儿受体，通过“高分辨率结构+亿级化学库筛选”的组合策略，仍能高效突破配体发现的瓶颈。\n参考文献：\nCabeza de Vaca, I., Trapkov, B., Shen, L.\net al.\nUltra-large virtual screening unveils potent agonists of the neuromodulatory orphan receptor GPR139.\nNat Commun\n17\n, 129 (2026).",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512690&idx=2&sn=d4efa9e214b43b7b0b895234a4041327&chksm=fdeadb7df2d94545b47f321f48753788cbd47104e9bad5896f0be9c1efa15b812a1cda23d592&scene=0&xtrack=1#rd",
      "publish_time": 1768314000,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768346312,
      "last_modify_ts": 1768346312
    },
    {
      "id": 454,
      "article_id": "51838",
      "title": "AI创药“核爆点”：长文深度解码Boltz与生物学的未来",
      "description": "人工智能正推动生命科学迎来“ChatGPT时刻”。2020年，AlphaFold高精度解决蛋白质折叠难题，标志AI在生命科学的重大突破。但这仅是开端，未来AI将从预测迈向创造，主动设计生命分子，重塑生物学研究范式，开启合成生物学与药物研发的新纪元，实现对生命本质的深度干预与重构。",
      "content": "在人工智能的浪潮席卷全球之际，一个古老而复杂的领域——生命科学，正迎来其“ChatGPT时刻”。2020年，DeepMind的AlphaFold以原子级别的精度破解了困扰生物学界半个世纪的“蛋白质折叠问题”，这不仅是一项技术的突破，更是一个时代的拐点，预示着AI将从根本上重塑我们理解和设计生命的方式。然而，AlphaFold只是这场革命的序章。当预测成为过去，AI能否更进一步，主动“创造”生命分子，解决那些“不可成药”的顽疾？\n近期，硅谷顶级风投机构Andreessen Horowitz (a16z)在其旗舰播客节目中，与一家名为\nBoltz\n的初创公司展开了一场长达46分钟的深度对话。这家脱胎于麻省理工学院（MIT）的“公益公司”，正致力于构建生物学领域的AI基础模型，其开源工具已被全球几乎所有大型药企和数千家生物技术公司下载超百万次。他们是如何在短短18个月内，从学术界的后起之秀，成长为行业不可或缺的基础设施构建者？他们又将如何引领AI从“理解生物学”迈向“工程化生物学”？\n本文将结合a16z的深度访谈和相关背景资料，为您完整、深度地解读Boltz的崛起之路，及其为生命科学和药物发现所描绘的革命性蓝图。\n一、AlphaFold之后：AI创药的“iPhone时刻”\n要理解Boltz的意义，我们必须回到那个被誉为生命科学“ChatGPT时刻”的里程碑——\nAlphaFold\n。在2020年之前，尽管科学家们已经使用计算工具辅助药物研发数十年，但这些工具的性能提升大多是渐进式的。蛋白质作为执行生命活动的主要分子机器，其三维结构决定了其功能。然而，通过实验方法解析蛋白质结构成本高昂且耗时巨大，预测其结构则是一项极其复杂的计算挑战。\nAlphaFold的出现彻底改变了游戏规则。它利用深度学习，以前所未有的准确度预测了绝大多数蛋白质的结构。正如Boltz联合创始人Jeremy Wohlwend在播客中所说：“\nAlphaFold的性能和预测质量让所有人感到震惊。这并非持续的进步，而是一个巨大的拐点。\n” 这是AI第一次在一个生物学的核心基础问题上，展现出超越传统方法、甚至比肩实验精度的强大能力。这一刻，整个科学界意识到，AI不再仅仅是一个辅助分析的工具，而是能够引领科学发现的驱动力。\n二、Boltz的诞生：MIT实验室走出的“公益独角兽”\nAlphaFold推开了一扇门，而Boltz则立志要在这扇门后，为整个生物学界修建一条高速公路。Boltz诞生于MIT顶尖的计算机科学与人工智能实验室（CSAIL），由三位年轻的博士——Gabriele Corso、Jeremy Wohlwend和Saro Passaro共同创立。\n与众不同的是，Boltz从诞生之初就选择了一条独特的道路：成为一家\n公益公司（Public Benefit Corporation, PBC）\n。这意味着，除了商业目标，公司还必须为其社会使命负责。Boltz的使命非常清晰且宏大：“\n推进生物学AI的发展，并让所有科学家都能使用这些工具，共同构建一个更健康的未来。\n”\n这一使命并非空谈。在公司正式成立之前，Boltz团队就以开源的方式发布了一系列强大的AI模型，迅速在学术界和工业界引起了轰动。正如视频开篇所强调的惊人数据：\n“我们的模型已被下载超过一百万次，来自超过十万个独立来源。我们知道，每一家大型制药公司，以及成百上千家生物技术公司，都在使用我们的模型。”\n这种近乎病毒式的传播，为Boltz的后续发展奠定了坚实的用户基础和社区信任。\n三、从预测到生成：Boltz模型的三级跳\n如果说AlphaFold解决了“看清”蛋白质结构的问题，那么Boltz的目标则是“理解”乃至“创造”分子间的相互作用。在短短一年多的时间里，Boltz团队完成了惊人的模型“三级跳”，清晰地展示了AI在生物学应用中不断深化的路径。\n模型\n发布时间\n核心功能\n意义\nBoltz 1\n2024年底\n预测生物分子复合物的3D结构\n达到AlphaFold 3级别的精度，并完全开源， democratizing access to state-of-the-art structural prediction.\nBoltz 2\n2025年中\n预测小分子与蛋白质的\n结合亲和力\n从“是什么结构”到“结合有多强”，向功能预测迈出关键一步，对药物筛选至关重要。\nBoltzGen\n2025年底\n从头生成\n能结合任意靶点的全新蛋白质\n从“预测”到“创造”的飞跃，开启了AI设计全新生物分子的时代，可用于解决“不可成药”靶点。\nBoltzGen\n的发布，是整个领域的一个重要里程碑。它不再局限于分析已有的分子，而是可以根据需求，像一位创意无限的建筑师一样，设计出全新的、具有特定功能的蛋白质分子。更重要的是，BoltzGen的通用性极强，它不仅能设计多种类型的分子，而且其设计的分子在横跨学术界和工业界的8个湿实验室（Wet Lab）中得到了广泛的实验验证，证明了其在真实世界中的有效性。这标志着AI在生命科学领域的角色，正从一个被动的观察者，转变为一个主动的创造者。\n四、开源的力量：在谨慎的科学界建立信任\n在严谨甚至保守的科学领域，尤其是药物研发，信任是新工具被采纳的基石。科学家们需要反复验证一个工具的可靠性，才会将其整合到自己的研究流程中。Boltz团队深刻地理解这一点，并因此坚定地选择了\n开源策略\n。\n通过将核心模型开源，Boltz允许全球任何一个角落的科学家在自己的数据上进行测试、验证和改进。这种开放性极大地降低了采纳门槛，并迅速建立起一个庞大的用户社区。这个社区不仅为Boltz提供了宝贵的反馈，帮助其快速迭代和优化模型，更形成了一个充满活力的创新生态。这种开放、协作的模式，正是Boltz能够在短时间内获得巨大影响力的关键所在。\n五、从学术到商业：为何要创办一家公司？\n既然开源项目如此成功，为何还要创办一家公司？CEO Gabriele Corso在访谈中给出了两个核心原因：\n资源需求\n：要持续推动AI模型的前沿研究，需要巨大的计算资源、顶尖的工程人才和高质量的数据集，这些是学术环境难以持续提供的。\n产品化\n：Corso强调，“\n仅仅将模型放在GitHub上，并不能产生我们期望的全部影响。如果你想让科学家直接使用你的模型并将其整合到工作流程中，你需要真正构建能够做到这一点的产品。\n”\n基于这两点认识，Boltz PBC应运而生，并迅速获得了由a16z、Zetta Venture Partners和Amplify领投的2800万美元种子轮融资。这笔资金将用于将Boltz强大的AI能力，转化为科学家触手可及的、稳定可靠的软件产品。\n六、战略抉择：卖“铲子”而非挖“金矿”\n在生物医药领域，AI公司通常有两种路径：一是成为一家\n治疗公司（Therapeutics Company）\n，利用AI平台发现和开发自己的候选药物，目标是最终上市新药；二是成为一家\n基础设施公司（Infrastructure Company）\n，为整个行业提供工具和平台，即“为淘金者卖铲子”。\nBoltz毅然决然地选择了后者。这一战略选择背后，是深刻的行业洞察。a16z的投资人指出，传统的AI制药公司模式，往往需要押注于少数几个管线，风险极高，且与技术平台的快速迭代特性相悖。而作为基础设施，Boltz可以赋能成千上万个药物研发项目，其影响力将是指数级的。正如投资人所坚信的：“\n最好的工具，是那些被广泛使用的工具。\n”\n七、Boltz Lab与辉瑞联手：AI创药进入“工作流”时代\n伴随着公司的正式亮相，Boltz推出了其核心产品——\nBoltz Lab\n。这是一个云原生平台，将复杂的AI设计能力封装在直观易用的界面背后，让一线科学家无需成为AI专家，也能轻松设计新的小分子和蛋白质。这正是Boltz产品化理念的落地。\n更重磅的是，Boltz同时宣布与全球制药巨头\n辉瑞（Pfizer）\n达成多年战略合作。辉瑞的科学家们将通过Boltz Lab平台，使用最前沿的AI模型来加速新药研发。这一合作不仅是对Boltz技术实力的高度认可，也标志着AI基础模型正在从学术玩具真正转变为大型药企核心研发流程中的生产力工具。\n八、重塑未来：AI如何打破药物发现的瓶颈？\n传统药物发现是一个漫长、昂贵且充满不确定性的漏斗，平均耗时10-15年，花费超过20亿美元，且失败率高达90%。AI的介入，有望从根本上重塑这个漏斗。\nBoltz所代表的新一代AI工具，可以在药物发现的早期阶段，即分子设计和优化环节，实现数量级上的效率提升。它们可以在数天甚至数小时内，设计并评估数百万个候选分子，快速锁定最有潜力的几个。更令人兴奋的是，当这些强大的AI设计平台与日益成熟的\n自动化机器人实验室\n相结合时，一个“设计-构建-测试-学习”的高速迭代闭环就形成了。AI在云端设计分子，指令被发送到机器人实验室自动合成与测试，实验数据再实时反馈给AI模型进行下一轮优化。这个闭环有望将药物发现的早期周期从数年缩短到数月，从而极大地降低成本和失败风险。\n结语\n从AlphaFold的石破天惊，到Boltz的开源燎原，再到Boltz Lab的商业落地，我们正在见证一场由AI驱动的、深刻的生物学革命。Boltz的故事，不仅仅是一家明星创业公司的崛起，它更是一个范式的缩影：\n开放、协作、平台化\n正在成为推动前沿科学商业转化的新引擎。\n正如Boltz的创始人所期望的那样，他们正在构建的，是“\n帮助我们操纵生物学来解决疾病的工具，是让生物学家能够想象他们以前从未想过的事情的工具\n”。一个由AI赋能，新药研发速度更快、成本更低、成功率更高的时代，正加速向我们走来。这不仅是Bolz的未来，更是整个生命科学乃至全人类健康的未来。\n参考资料\n：\na16z Podcast: \"AI Foundation Models for Biology\"\nhttps://www.youtube.com/watch?v=cBw2V3FiRxs&t=23s",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512690&idx=1&sn=d413c3da2deee098bef5423f7ec8f247&chksm=fdcd8ea04ec78d675e70e4dfedbe3cb3f59c4d992c2512754cca2ae42c0a92727c7b265e887c&scene=0&xtrack=1#rd",
      "publish_time": 1768314000,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.youtube.com/watch?v=cBw2V3FiRxs&t=23s\"]",
      "add_ts": 1768346315,
      "last_modify_ts": 1768346315
    },
    {
      "id": 460,
      "article_id": "51832",
      "title": "具身开源模型新王！千寻Spirit v1.5模型登顶 RoboChallenge，终结 Pi0.5领跑时代",
      "description": "千寻智能的具身智能模型Spirit v1.5在RoboChallenge真机评测中以总分66.09、成功率50.33%登顶榜首，超越美国公司Physical Intelligence的Pi0.5。该模型依托多样化预训练数据，在插花、放水果等任务中表现优异，展现强大泛化能力与操作精度，标志着中国具身智能技术实现重要突破，推动机器人在真实环境中的应用进展。",
      "content": "henry 发自 凹非寺\n量子位 | 公众号 QbitAI\n事情开始变得有趣起来了。\n刚刚，来自\n千寻智能\n的具身智能基础模型\nSpirit v1.5\n，在\nRoboChallenge\n真机评测榜上，以总分\n66.09\n，成功率\n50.33%\n的成绩，超越美国明星公司Physical Intelligence的\nPi0.5\n（π0.5）\n，登顶榜首。\n基于多样化的预训练数据采集范式\n，\nSpirit v1.5\n在插花、把水果放进篮子、挂牙刷杯等多项任务中，拿下第一，刷新榜单纪录。\n经此一役，\nSpirit v1.5\n不仅是RoboChallenge自去年10月上线以来，\n首个击败baseline模型Pi0.5的国产具身模型\n，同时也是\n首个在RoboChallenge上成功率超过50%的具身智能模型\n。\n在此之前，RoboChallenge榜单上，模型间的竞争已逐渐进入白热化阶段，Pi系列基线模型不断被逼近。\n而现在，\nSpirit v1.5\n直接越过Pi0.5，拿下榜首。\n这种密集、连续的刷榜节奏，多少有点让人想起当年AlexNet、VGG、GoogLeNet、ResNet刷新ImageNet的那段时间——\n基准在被不断打破，模型天花板被一再抬高。\n也正如当年CV的开源景象，Spirit v1.5同步开源了\n基模权重、推理代码以及使用样例\n，方便后续的研究者复现和进一步探索。\n而正是在这被誉为具身智能「ImageNet」的RoboChallenge上，开源模型正以可验证、可复现的方式，持续推动具身能力向前发展。\n开源具身模型能力，全球领先\n截至2026年1月12日，\nSpirit v1.5\n在RoboChallenge上取得了当前最优的性能，超越了Pi0.5等之前的全球领先开源模型。\n在RoboChallenge的Table30任务中，\nSpirit v1.5\n表现堪称 “碾压级”，不仅在下列多项任务中夺得第一：\n插花（arrange flowers）\n水果入篮（arrange fruits in basket）\n挂牙刷杯（hang toothbrush cup）\n薯条倒碗（pour fries into plate）\n开瓶器入抽屉（put opener in drawer）\n笔入笔盒（put pen into pencilcase）\n寻找绿盒（search green boxes）\n浇花（water potted plant）\n……\n还在贴胶带（stick tape to box）、清扫垃圾（sweep the rubbish）、开关灯（turn on light switch）等任务上实现绝对领先。\n其中 “寻找绿盒” 任务堪称高光时刻——\nSpirit v1.5\n直接将成功率拉至\n90%\n。\n演示画面中，它能快速从一堆彩色方块中锁定绿色目标，稳稳放入指定篮子，整个过程干脆利落，没有丝毫拖泥带水。\n在水果入篮任务中，\nSpirit v1.5\n更是以80%的成功率，领先Pi0.5整整一倍。\n在演示中，\nSpirit v1.5\n能够轻松地拿起香蕉，放进篮子\n（下图经5倍加速）\n。\n而在插花任务中，虽然两款模型成功率均 50%，但实际执行中，\nSpirit v1.5\n的稳定性碾压Pi0.5，没有出现极端的失败案例。\n（左为Spirit v1.5，右为Pi0.5）\n在演示中，\nSpirit v1.5\n基本上可以稳稳地将鲜花放入花瓶。\n而Pi0.5有时则会出现突然卡死的情况，从而导致任务中断。\n在最考验技术功底的贴胶带任务中，即便\nSpirit v1.5\n20%的成功率不算特别突出，但对比Pi0.5仅10%的表现，仍实现了翻倍领先。\n贴胶带属于典型的闭环触觉接触任务（机器人手指 / 夹爪间隙极小），对机械臂协同与触觉感知要求极高，机器人经常会出现空抓的现象。\n在演示中，\nSpirit v1.5\n凭借双机械臂精准配合，能流畅完成撕胶、贴盒全流程。\n而相比之下，Pi0.5虽然能很快的定位到胶带的位置，但却难以感知到是否撕到胶带，频频出现了空贴的现象。\n透过上述任务我们不难看出，\nSpirit v1.5\n在复杂长指令任务中的稳定发挥，意味着其已经进化为一个具备出色逻辑推理与空间感知能力的“具身大脑”。\n而这份实力的认证，正来自具身智能领域的标杆级 “试炼场”——RoboChallenge。\nRoboChallenge由\nDexmal原力灵机\n联合\nHugging Face\n发起，是首个在真实物理环境中，由真实机器人执行操作的大规模、多任务基准测试。\n它的Table30任务集，通过30个高频桌面及周边日常场景，从VLA难点、机器人形态、任务流程与物体属性等维度考察模型真实世界通用操作能力。\n考试机型覆盖ARX5、UR5e、ALOHA、Franka、UR5等；测试任务涵盖抓取、放置、堆叠、打开、按压、分类等复杂动作。\n除上述任务设置外，RoboChallenge它的核心创新，在于\nRemote Robot Paradigm（远程机器人范式）\n：\n参赛者在本地运行模型，只需通过HTTP接口向机器人发送控制指令，机器人被视作一个可远程调用的“外设”。\n这一设计显著降低了参赛门槛，同时避免了复杂环境配置带来的不确定性，使不同团队的算法能够在\n同一套真实硬件条件下\n接受统一评测。\n所有参赛者均可通过官方页面查看比赛实况，全程保障赛事的公平与透明。\n不过，由于推理发生在用户侧，模型的具体实现仍主要依赖参赛者自律与社区共识——\n例如是否始终保持与所声明方案的一致性，是否在多任务通用型模型（multi-task generalist model）的设定下，避免针对单一任务的特殊化调优。\n（注：RoboChallenge区分任务特定与通用型两种训练协议：前者针对单一任务单独训练，后者用少量混合数据训练一个多任务统一模型。榜单中带有/multi 后缀的模型，如Pi0.5/multi，遵循的正是这一更具挑战性的通用型设定。）\n也正是在这一背景下，\nSpirit v1.5\n此次选择同步开源，其意义不仅在于成绩本身，也契合了RoboChallenge鼓励通过\n可复现、可验证\n的方式，共同推动具身智能基准向前发展的初衷。\n那么，\nSpirit v1.5\n具体是怎么做到的呢？\n数据多样性成制胜法宝\nSpirit v1.5\n的核心创新，主要体现在预训练阶段的数据策略上。\n它将具身模型的预训练数据，从高度精选、强控制的「干净数据」，转向多样化、开放式、弱控制的数据采集范式。\n这里所说的「干净数据」，通常指动作模式相对单一、物体摆放位置与视角高度固定的精选数据集。\n例如\nOpen X-Embodiment\n、\nAgibot\n和\nRoboCOIN\n等具身模型训练的主流数据集。\n△\nOpen X-Embodiment\n这类数据的优势在于：数采成本低、学习难度可控；\n但代价同样明显——动作模式的多样性被显著压缩，模型对真实世界不确定性的适应能力因此受限。\n针对这一问题，\nSpirit v1.5\n采取了相反的策略。\n在数据采集阶段，它鼓励数采员只围绕任务目标行动，而不强制遵循固定的动作流程。\n例如，在为假人头部化妆时，采集员并不会严格复现某一套标准操作，而是以更接近真实人类行为的方式自由完成任务。\n这样做的结果是采集来的数据不再是单任务、单目标的单成功轨迹。\n而是在自然执行过程中，连续覆盖了抓取、插入、整理、双臂协作、异常处理等大量原子技能，并以真实世界的时序关系串联在一起。\n这种开放式采集显著扩大了动作分布，使模型在预训练阶段“见过更多可能性”，从而具备更强的迁移与泛化能力。\n在工程层面，这一策略同样带来了可观收益：人均有效采集时长提升约\n200%\n，对算法专家深度介入的需求降低约\n60%\n。\n而在实验验证中，这种以多样性为核心的数据策略，同样得到了印证。\n一方面，在\nRoboChallenge Table30\n的真机评测中，\nSpirit v1.5\n已经在整体能力层面证明了该范式是成立的\n（相关结果已在前文展开）\n。\n另一方面，在消融实验中，研究团队在\n预训练数据规模完全一致\n的前提下，对比了两种策略：\n基于脚本化任务演示的预训练；\n基于多样化、开放式采集的预训练。\n结果显示，多样化预训练的模型在新任务上的\n微调效率显著更高\n：在达到相同性能时，所需迭代次数减少约\n40%\n。\n进一步扩大多样化数据规模后，模型的验证误差仍在持续下降，并未出现明显的早期饱和现象。\n这些发现表明，\n对具身模型而言，任务多样性比单一任务的演示数量更为关键\n。\n模型真正学到的，并非某个任务的最优动作序列，而是一套可迁移的通用策略，使其能够用更少的步骤适应新任务。\n由此，使用高多样性、弱控制的数据进行预训练不仅可行，而且显著优于文献中常见的利用“干净”数据的做法。\n也正因为并非针对单一任务优化，\nSpirit v1.5\n更适合作为一个通用具身智能的基础模型被复用。\n对学界而言，它提供了一条不同于Pi系列且更优的开源技术路径。\n对产业团队而言，这种以真实世界多样性为起点的预训练方式，显著降低了新场景的迁移与适配成本。\n随着模型权重与代码同步开源，\nSpirit v1.5\n在RoboChallenge上的成绩不再只是一次展示，而成为一个可验证、可复现、可继续推进的起点。\nSpirit v1.5背后的团队：千寻智能在做什么\n最后，再把视角拉回到Spirit v1.5背后的团队——\n千寻智能（Spirit AI）\n。\n成立于2024年1月的千寻智能，是一支非常“年轻”的队伍，却已经成长为国内少数具备AI+机器人全栈、生产力级技术能力的具身智能公司。\n简单概括，千寻的路线非常明确——通用人形机器人+具身大模型（VLA）一体推进，因此常被外界称为“中国版 Figure”。\n创始人兼CEO韩峰涛\n：机器人行业连续创业者，曾任珞石机器人联合创始人兼CTO，在机器人行业拥有十余年经验，主导交付过超2万台工业机器人。\n联合创始人兼首席科学家高阳\n：清华交叉信息研究院助理教授，“伯克利归国四子之一”，师从具身智能权威学者Pieter Abbeel，其提出的ViLa算法被Figure采用。\n在融资方面，2025年千寻智能狂揽超15亿元融资，6月PreA+轮由京东领投6亿元，浙江省科创母基金、华泰紫金等新势力跟投，顺为资本、华控基金等老股东更是继续跟投。\n在商业落地方面，其通用人形机器人 “小墨”（Moz1）已于2025年底在宁德时代电池产线规模化落地，精细作业成功率突破99%，用工业级场景完成了一次硬核验证。\n而在技术路径上，从Spirit v1攻克柔性物体长程操作，到开源「边想边做」的OneTwoVLA，再到如今基于多样化真实数据采集的Spirit v1.5——\n千寻始终在做一件事：把具身智能从“实验效果”，推进到“可复现、可量产、可落地”的工程体系中。\n而这次\nSpirit v1.5\n在RoboChallenge上的登顶，并不仅仅意味着一次榜单上的领先。\n它更像是千寻具身智能模型快速迭代周期中，一次在同一公开基准下完成的、具有标志意义的性能对标：\n在真实机器人、真实任务、统一评测条件下，对现有的技术路线进行了一次阶段性验证。\n从结果来看，\nSpirit v1.5\n在泛化性、稳定性与鲁棒性等系统层面的能力，已经出现了整体跃迁，而不仅是单点任务的“刷分”。\n更重要的是，这一成绩并未停留在展示层面。\nSpirit v1.5\n同步开源模型权重、推理代码和使用样例，使得这一结果可以被复现、被检验、也可以被后续研究继续推进。\n正如当年ImageNet之于计算机视觉，只有在一个可复现、公正、开放的基准之上，模型能力的进步才具备真正的参考价值。\n而模型的开源也进一步方便后续研究者的快速迭代优化与创新探索。\n在被不少研究者视作具身智能「ImageNet」的RoboChallenge上，这次登顶既是一次能力确认，也是一种明确表态——\n千寻选择将技术进展放入开源体系之中，与社区一起，把具身智能的天花板持续往前推。\n正如千寻首席科学家高阳针对\nSpirit v1.5\n在开源模型赛道斩获全球第一时说所的：\n它不仅是一次技术上的突破，也意味着我们在追寻智能的道路上，再次站到了当下人类智能所能企及的高度之一。更重要的是，这个模型是开源的。我们选择把它交到更多人手中，让大家一起使用、一起验证、一起推进这条路。智能不应该被少数人垄断，而应该被共同建设。\n开源地址：\nCode: https://github.com/Spirit-AI-Team/spirit-v1.5\nModel: https://huggingface.co/Spirit-AI-robotics/Spirit-v1.5\nBlog：https://www.spirit-ai.com/en/blog/spirit-v1-5\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247861087&idx=1&sn=fa835dc19126a901041577bb67f81718&chksm=e9d955f1efe84202b3972c106ab2e2320c3d55c2de196105d215548ff0565058b8d87d3c9c87&scene=0&xtrack=1#rd",
      "publish_time": 1768303800,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/Spirit-AI-Team/spirit-v1.5\", \"https://huggingface.co/Spirit-AI-robotics/Spirit-v1.5\", \"https://www.spirit-ai.com/en/blog/spirit-v1-5\"]",
      "add_ts": 1768346335,
      "last_modify_ts": 1768346335
    },
    {
      "id": 462,
      "article_id": "51829",
      "title": "清华新年首篇Science！AI助力药物虚拟筛选提速百万倍",
      "description": "清华大学AIR兰艳艳教授联合生命学院、化学系团队研发了AI驱动的超高通量药物虚拟筛选平台DrugCLIP，显著提升靶向药物研发效率。该平台突破传统筛选速度瓶颈，可在广阔化学空间中快速识别潜在苗头化合物，覆盖目前仅10%的人体可成药靶点外的大量未知靶点，推动新药发现进程。DrugCLIP通过智能算法实现高效匹配与预测，为药物研发提供强大技术支持。（150字）",
      "content": "目前，人类对靶向药物的探索\n约覆盖人体全部可成药靶点的10%\n面对数以万计的潜在靶点\n如何在广阔的化学空间中\n快速筛选苗头化合物\n已成为该领域里的瓶颈\n清华大学智能产业研究院（AIR）\n兰艳艳教授\n联合生命学院、化学系团队\n（以下简称：联合团队）\n创新研发\nAI驱动的\n超高通量药物虚拟筛选平台DrugCLIP\nDrugCLIP主页（https://www.drugclip.com）\nDrugCLIP筛选速度\n对比传统方法实现了百万倍提升\n同时\n在预测准确率上也取得显著突破\n依托该平台，团队\n首次完成了\n覆盖人类基因组规模的药物虚拟筛选\n为创新药物发现带来了新的可能性\n北京时间1月9日\n研究成果以\n《深度对比学习实现基因组级别药物虚拟筛选》\n（Deep contrastive learning enables genome-wide virtual screening）为题\n在线发表于\n《科学》（\nScience\n）\nScience 网站论文截图\n文末点击“阅读原文”，了解论文详情\n现有工具制约\n靶点筛选效率\n受限于自动移液工作站、超级计算机等工具的\n高昂成本\n目前，绝大多数潜在靶点和化合物\n仍未被充分探索——\n人类基因组编码2万余个蛋白\n然而现有蛋白靶点开发只覆盖其中小部分\n为解决更多分子机制不同的疾病\n科研工作者仍在积极探索\n但若使用当前最先进的分子对接工具\n筛选1万个蛋白靶点\n假设每个靶点面对10\n9\n个候选分子\n则\n需完成约10\n13\n次蛋白-配体打分\n一台计算机即使日夜不休\n也需数百年才可完成计算\n严重制约了新靶点与新分子之间\n匹配的筛选效率\nDrugCLIP将该计算量\n缩短为一台计算节点\n（高性能计算或分布式计算系统中的一个基本单元）\n一天的机时\n准确有效\n药物筛选提速百万倍\n荣获2024年诺贝尔化学奖的AlphaFold算法\n解决了蛋白质结构预测问题\n而\nDrugCLIP则首次打通了\n从蛋白结构预测到药物发现的关键通道\n实现覆盖人类基因组规模的虚拟筛选\n硬件方面\n基于128核中央处理器（CPU）\n和8张图形处理器（GPU）的计算节点\nDrugCLIP即可实现\n万亿级蛋白口袋小分子对打分日吞吐能力\n其核心突破在于将传统的分子对接\n转化为蛋白口袋与小分子\n在向量空间中的高效语义检索\n较分子对接等传统方法的\n速度\n提升百万倍\n一开始，联合团队对于筛选的准确性并没有把握\n第一次在湿实验室实验就取得了成功\n初步验证了平台的有效性\n让联合团队成员信心大增\n基于DrugCLIP的超高速全基因组虚拟筛选\n在生命学院副教授闫创业团队协作下\nDrugCLIP模型从160万个候选分子中\n为去甲肾上腺素转运体（NET）靶点\n筛选出约100个高评分分子\n同位素配体转运实验检测显示\n其中15%为有效抑制剂\n其中12个分子结合能力优于\n现有抗抑郁药物安非他酮\n尤其是在冷冻电镜技术的帮助下\n解析了多个分子与NET蛋白的复合物结构\n进一步验证了DrugCLIP\n筛选结果的生物学可信度\n化学系教授刘磊团队\n则通过DrugCLIP\n针对E3泛素连接酶TRIP12\n（thyroid hormone receptor interactor 12）\n进行了虚拟筛选与实验验证\n过往研究发现\nTRIP12是多种肿瘤、帕金森综合征\n的潜在靶点\n但是TRIP12缺少已知的\n小分子配体和复合物结构\n通过使用TRIP12的AlphaFold结构\nDrugCLIP模型从160万个候选分子中\n高通量筛选出约50个高评分分子\n实验证实\n其中10个分子与TRIP12有结合能力\n两个亲和力较高的分子\n也对TRIP12的泛素连接酶活性\n有一定抑制活性\n这验证了\nDrugCLIP支持\n对AlphaFold预测的蛋白结构和\n无配体状态下的蛋白口袋进行筛选\n扩大了其在真实药物发现场景中的适用性\n平台化赋能\n从免费开源到产业生态\n依托DrugCLIP\n联合团队\n首次完成了\n人类基因组规模的虚拟筛选项目\n可覆盖约1万个蛋白靶点、2万个蛋白口袋\n分析筛选超过5亿个类药小分子\n总共富集出超过200万个潜在活性分子\n构建了目前已知最大规模的\n蛋白-配体筛选数据库\n该数据库已免费面向全球科研社区开放\n为基础研究与早期药物发现\n提供了强大数据支持\n人类基因组规模的蛋白虚拟筛选数据库\n同时，\n筛选服务平台也已同步上线\n支持对用户上传的靶点和蛋白口袋\n进行定制化筛选\n截止到论文发表，半年来\n该平台已经累计服务1400余名用户\n完成了13500余次筛选\n人类基因组规模筛选项目覆盖的蛋白数目与现有数据库对比（左：覆盖的靶蛋白空间，使用ESM1b编码并进行t-SNE降维可视化；右：覆盖的UniProt ID数量）\n未来，DrugCLIP将与\n科研与产业生态伙伴深度合作\n在抗癌、传染病、罕见病等方向\n加速新靶点与First-in-class药物（首创新药）的发现\n联合团队将持续优化引擎性能\n拓展支持模态\n助力构建一个更智能、高效与普惠的\n全球药物创新生态\n该项目得到了国家科技部重点研发项目、\n国家自然科学基金委项目\n、新基石研究基金等项目的支持，同时还有清华大学无锡应用技术研究院智能产业创新中心、北京智源人工智能研究院和北京结构高精尖中心等机构的支持。清华大学智能产业研究院（AIR）博士后贾寅君、计算机系博士生高博文、生命学院博士后谭佳鑫、化学系博士后郑济青以及智能产业研究院\n（AIR）\n博士后洪鑫为共同一作；通讯作者为智能产业研究院\n（AIR）\n兰艳艳教授，生命学院张伟副教授、闫创业副教授以及化学系刘磊教授。论文链接：\nhttps://doi.org/10.1126/science.ads9530\n来源｜清华大学智能产业研究院（AIR）\n文&排版｜徐如玉\n编辑｜苑洁\n审核｜刘蔚如\n清华大学版权所有\n联系邮箱：thuxwzx@tsinghua.edu.cn",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512688&idx=2&sn=03062ce4b380529f0dad007f5637c9fc&chksm=fdd3091afff73d84d5a738360d670ca6be1989d3e83e129d1f838ca238967598301717aa0dbb&scene=0&xtrack=1#rd",
      "publish_time": 1768299000,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.drugclip.com\", \"https://doi.org/10.1126/science.ads9530\"]",
      "add_ts": 1768346340,
      "last_modify_ts": 1768346340
    },
    {
      "id": 465,
      "article_id": "51826",
      "title": "智源TALK｜SIGGRAPH Asia 2025 最佳论文奖，3D视觉，让镜头更轻薄、拍照更清晰，沙特阿卜杜拉国王科技大学毛适，第一作者解读",
      "description": "本期报告由沙特阿卜杜拉国王科技大学毛适分享Siggraph Asia 2025最佳论文《中央凹堆叠成像Fovea Stacking》。针对智能手机与VR/AR设备对轻薄化的需求，光学系统小型化导致轴外像差严重、图像模糊的问题，传统算法修复效果有限。研究提出“中央凹堆叠成像”新方法，模拟人眼中央凹视觉机制，通过光学设计与计算成像协同优化，显著提升成像质量，实现高分辨率中心区域与大视场的平衡，为下一代轻薄成像系统提供创新解决方案。",
      "content": "报告主题：\nSiggraph Asia 2025 最佳论文｜中央凹堆叠成像Fovea Stacking\n报告日期：\n1\n月14日（周三）14:30-15:30\n报告要点：\n本期报告将由沙特阿卜杜拉国王科技大学\n毛适\n进行分享。\n随着智能手机、VR/AR设备对轻薄化的追求，成像光学系统趋向于小型化。然而，简化的光学系统会导致严重的轴外像差，致使图像模糊，单纯依靠后端算法难以完美修复。\n本次分享将介绍我们团队的最新研究成果：\nFovea Stacking（中央凹堆叠成像）\n。我们受人类视觉系统启发，模拟视网膜中央凹（Fovea）的局部高清感知机制，提出了一种软硬件协同设计的成像新范式。通过在光路中引入动态可变形相位板（DPP），实现对图像任意注视点的动态局部像差校正。通过“堆叠”多张具有不同注视点的局部高清图像，该技术让极简的单镜片镜头也能获得全视场清晰的高质量影像。这项技术在物体追踪、大景深成像及 VR/AR等前沿场景中具有应用潜力。\n分享亮点：\n- 仿生成像新思路：突破传统“全局校正”的思维定式，借鉴人类视网膜成像机制，实现“按需校正”的动态局部高清成像。\n- 软硬件协同设计：深度结合可变形相位板（DPP）硬件与可微分光学模型，展示如何通过算法补偿极简光学系统的物理限制。\n项目链接：\nhttps://sheldonmao.github.io/projects/FoveaStacking\n相关论文：\nFovea Stacking: Imaging with Dynamic Localized Aberration Correction\n报告嘉宾：\n毛适，沙特阿卜杜拉国王科技大学 (KAUST) 计算机科学系在读博士生，师从 Wolfgang Heidrich 教授。曾于清华大学获得硕士学位，本科毕业于华南理工大学。研究方向集中在计算成像、可微分光学以及3D视觉，致力于通过软硬件协同创新突破传统成像系统的物理限制，并更好的重建三维世界。他的相关研究成果发表于SIGGRAPH Asia、IEEE TPAMI、CVMJ 等国际顶级会议与期刊，并凭借第一作者论文荣获 SIGGRAPH Asia 2025 最佳论文奖。\n扫码报名\n更多热门报告",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU4MjkzNDMwNg==&mid=2247491589&idx=1&sn=40728506a2e495e5b4351f1d6921e909&chksm=fcddd1f06394f15dccfe36372358c2bc679c36e302b202236c596c99a53317def8fba4881b3b&scene=0&xtrack=1#rd",
      "publish_time": 1768286400,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://hub.baai.ac.cn/paper/b1cd91eb-d015-4ebd-8fcf-5d18e9579e7b\", \"https://event.baai.ac.cn/activities/963\", \"https://event.baai.ac.cn/activities/965\", \"https://sheldonmao.github.io/projects/FoveaStacking\"]",
      "add_ts": 1768346352,
      "last_modify_ts": 1768346352
    },
    {
      "id": 467,
      "article_id": "51824",
      "title": "智源TALK｜腾讯微信AI最新研究，基于因果注意力重构扩散语言模型，高效并行推理",
      "description": "腾讯微信AI研究员刘瑷玮在报告中探讨了基于因果注意力重构的扩散语言模型，旨在提升大语言模型的并行推理效率。传统自回归模型因逐词解码导致推理缓慢，而扩散语言模型虽支持并行生成，但因双向注意力机制难以复用KV Cache，影响实际性能。该研究通过重构因果注意力机制，在保持并行性的同时优化缓存复用，显著提升推理速度与部署效率，为扩散语言模型的实际应用提供新思路。",
      "content": "报告主题：\n腾讯微信高效并行推理｜基于因果注意力重构扩散语言模型\n报告日期：\n1\n月15日（周四）10:30-11:30\n报告要点：\n本期报告将由腾讯微信AI研究员刘瑷玮进行分享。\n大语言模型（LLM）的自回归生成方式受限于逐词解码，推理效率面临瓶颈。虽然扩散语言模型（DLLM）支持并行生成，但由于依赖双向注意力机制，破坏了 KV Cache 的复用性，导致在实际部署中难以超越经过优化的自回归引擎（如 vLLM）。\n本次报告将介绍 WeDLM，这是一种基于标准因果注意力重构的扩散解码框架。我们通过拓扑重排机制，在保持严格因果掩码的同时实现了全上下文感知，使得并行生成能够完美兼容 KV Cache。结合流式并行解码策略，WeDLM 能够在保证生成质量的同时，实现超越 vLLM 部署的 AR 模型 的推理速度（在复杂推理任务上加速近 3 -10倍），为大模型的高效部署提供了全新的范式。\n相关论文：\nWeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference\n报告嘉宾：\n刘瑷玮博士现任腾讯微信 AI（WeChat AI）研究员，主要从事大语言基座模型的研究工作。他于 2025 年 6 月获得清华大学软件学院博士学位，导师是闻立杰副教授；此前于 2020 年本科毕业于南京大学。\n在学术研究期间，他曾作为访问学者在伊利诺伊大学芝加哥分校（UIC）师从 Philip S. Yu 教授（ACM/IEEE Fellow），以及在香港中文大学（CUHK）师从 Irwin King 教授（ACM/IEEE Fellow）进行研究。\n他在 ACL、ICLR、EMNLP、SIGKDD 等顶级会议及期刊上发表多篇论文，是开源工具包 MarkLLM 的项目负责人，并曾获 2025 年北京市优秀毕业生荣誉。\n扫码报名\n更多热门报告",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU4MjkzNDMwNg==&mid=2247491589&idx=2&sn=8a158d29b2b2c7abcbef22196e38a02f&chksm=fc97565c42bf79236f3a336627daac9ddadc98f4ada884fd8e9d57b415fd58091c882ccd7efb&scene=0&xtrack=1#rd",
      "publish_time": 1768285200,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://hub.baai.ac.cn/paper/c662cd6c-d074-4c65-9ddf-e501ed70ec1e\", \"https://event.baai.ac.cn/activities/963\", \"https://event.baai.ac.cn/activities/965\"]",
      "add_ts": 1768346358,
      "last_modify_ts": 1768346358
    },
    {
      "id": 468,
      "article_id": "51823",
      "title": "具身智能数据战开打！每个普通人都能上手，边采边筛，只投喂机器人爱吃的丨穹彻",
      "description": "一部手机搭配“夹爪”即可实现高效具身智能数据采集，数据质量高，已成功用于模型训练。该系统显著提升模型在多步任务中的动作稳定性与鲁棒性，能有效应对光照变化、环境杂乱和物体遮挡等真实场景挑战，并在任务小幅变化时具备良好泛化能力，实现举一反三的灵活应对。",
      "content": "衡宇 发自 凹非寺\n量子位 | 公众号 QbitAI\n现在，一部手机，加一个“夹爪”，就能随时随地完成具身智能数据采集了！\n采出来的数据不脏也不废，已经在实际模型训练中跑出了效果\n。\n模型在多步连续任务中动作衔接更稳定；\n在真实场景中面对光照变化、环境杂乱、物体遮挡时也更不容易失手，执行鲁棒性显著提升；\n而当任务发生小幅变化，比如同类但不同顺序的操作目标出现时，模型也更容易举一反三，做出合理应对。\n这套采集系统，模型效果是纯纯地全肯定。\n这套\n可搭载手机的数采终端及其配套应用程序，名叫RoboPocket，来自具身智能创企穹彻智能\n。\n它是新兴采集设备UMI\n（Universal Manipulation Interface）\n的进阶状态。\n和传统UMI方案相比，RoboPocket保持便携易用的基础上，更加轻盈：手机+夹爪即是一个节点。\n如此一来，每个人——哪怕是普通人，都可以从口袋里掏出RoboPocket，随时随地采集具身数据。\n但这还算不上它最出彩的地方。\n最妙的是，RoboPocket把模型需求前置到采集一线，让你随时接入模型的训练闭环。\n采集行为发生时，系统会同步判断每一段数据的训练价值，并即时给出反馈与引导，尽量让采集行为本身就朝着模型真正需要的方向收敛。\n每一次采集都直接服务于模型进化，浪费不了一点。\n在数据还在生成的过程中，就对其完成了价值筛选。\n最终采来交付给模型的数据从采集源头就来得更加清晰，更加准确，对模型也更有用。\n点击视频，带你了解穹彻RoboPocket：\n具身模型想scale up，卡在数据哪一步？\n在具身智能领域，\n数据的重要性几乎是共识性的\n。\n具身模型们嗷嗷待哺，等待大量高质量、多样性的具身数据的投喂。\n从2023年起，许多团队投入大量资源建设数采厂，希望通过规模化生产来支撑模型训练。\n实践很快暴露出一个现实问题，\n数采流水线建起来了\n，数据量上来了，模型能力却并没有稳定持续地提升。\n原因并不神秘。\n数采厂依赖的是预设场景和标准化流程，这种方式在工业数据中行之有效，但在具身智能里，很难覆盖真实世界中大量非标准、非重复的操作情境。\n动作容易趋于模式化，任务分布集中，环境变化有限，数据之间高度相似，训练收益很快出现边际递减。\n有相关从业人员告诉我们，\n现在的具身数据一天比一天多了，结果训练效率出现不升反降情况\n。\n而具身模型真正需要的，恰恰是那些发生在真实环境中的、不那么规整的操作过程。\n这也是UMI出现的背景。\nUMI轻量便携，更易使用，一方面减少了数采成本，更重要的是开始让具身数据采集摆脱了固定场地的限制。\n任何人，可以在室内和户外的任何真实世界场景里自然完成操作。\n如此一来，采集的数据也是贴近现实分布的。这就弥补了数采厂和真实世界存在gap的问题。\n但当UMI开始被业界认可和逐渐大规模使用后，新的问题也随之显现。\n在真实场景中，采集更自由了，\n但质量控制随之变难了。\n动作是否有效？轨迹是否合理？采集节奏是否适合训练？这些问题往往只有数据回传清洗，开始拿来训模型的后处理阶段才能发现。\n大量低价值数据被一路送进管线，清洗与返工成本迅速抬升，训练周期被不断拉长。\n所以关于UMI的“不可能三角”被抬到了台前——\n采集质量、使用便捷性与后处理压力三者难以同时优化\n。\n如果追求采集质量，就往往要牺牲便携性；如果降低门槛提高便携性，比如像传统UMI仅靠腕部模组或“人-夹爪”采集，就又很难保证数据的可用性；如果希望用后处理阶段兜底，就意味着要承受高昂的清洗、筛选与修复成本，训练闭环被迫拉长。\n现有的UMI方案并没有解决“采得的数据能不能用”这个问题——这一点恰恰对模型训练至关重要。\n于是，穹彻团队决定\n回到问题的原点，重新出发。\n他们从第一性原理出发，提出一个关键设想。\n如果模型训练最终还是要根据数据结构做判断与筛选，那么为什么这件事不能在数据采集阶段就发生？\n这个问题其实是行业迟迟没直面解决的。因为一旦着手解决，就意味着采集逻辑、平台架构、成本结构、人才组织……都得变。\n而RoboPocket第一次把它变成了现实。\n内置一套实时运行的“数据价值中枢系统”\n相比于过往的UMI设备，RoboPocket的关键改变集中体现在采集目标本身的定义上。\n传统UMI的普遍默认采集目标是“记录人类操作行为”。\n也就是通过腕部模组、夹爪、轨迹重建等方式，尽可能完整地还原人类执行任务的过程。\n在训练初期，这确实能为模型提供基本行为模板。\n但\n随着模型走向更高维度、更长时序、更复杂场景，记录动作本身已不足以满足训练所需\n。\nRoboPocket开始尝试把采集的目标转向模型的能力缺口。\n模型还不会的，才是最值得采的数据。\n基于这个理念，\nRoboPocket系统内置了一套实时运行的“数据价值中枢系统”\n。\n这套系统不再等数据采完后才去筛选、分类、评估，而是在采集发生的当下，就开始实时进行判断。\n不难想象，一旦没有模型视角，采集很容易在堆量的过程中滑向重复、失真和低价值。\n只有知道模型此刻真正需要什么样的数据，才有能力搭建好这个中枢系统。\n穹彻和上交大卢策吾团队\n敢揽这个瓷器活，人家是真有公认的金刚钻。\n团队长期从事具身模型训练与数据闭环研究，既懂单点采集工具\n（此前推出过多款具身数据采集硬件）\n，也懂围绕具身模型训练、评估与数据回流的完整闭环研究。\n他们最清楚哪些轨迹会变成有效训练信号，哪些看起来热闹但只会拖慢训练，也更清楚模型在不同任务维度上的短板通常出在哪里，应该用什么样的样本去补。\n这种能力依赖的不只是工程实现，而是对模型的长期理解与持续验证，所以很难被复制。\n采集数据的过程中，RoboPocket同时在推进并完成三件事——\n第一是实时评估\n。\n在每一帧数据生成时，系统都会判断采集到的数据是否具备有效的训练信号，比如操作是否完整、动作是否在预期轨迹内、场景是否具备信息量。\n第二是即时引导\n。\n如果系统检测到采集者的操作可能低效或错误，比如动作过快、夹爪超出操作区域、多样性不足等，就会实时发出提醒，引导采集者进行调整，避免采到低价值甚至废弃的数据。\n第三是动态调度\n。\n这一环节则直接接入当前模型的能力评估结果。\n系统会根据模型在不同任务维度上的表现，识别出当前训练最需要补齐的样本类型，并实时分发相应的高优先级采集任务给采集者。\n说句更好理解的话，RoboPocket就是个24小时stand by的数据采集主理人\n。\n它即时诊断每一帧数据的质量，智能指导甚至纠正采集员动作，实时互动动态评估数据价值\n，为后处理提供筛选依据。\n这样一来，在采集阶段，数据就和训练目标保持贴合，显著减少冗余，训练信号更加集中。\n穹彻团队介绍，\nRoboPocket采集的数据在训练中展现出显著优势\n。\n尤其是在开放复杂环境中的多步骤任务中，模型执行的稳定性更强，不容易因光照变化、背景变化或任务干扰而出错，准确识别每一步的上下文意图，在不确定情境下仍保持清晰的目标推进逻辑。\n无论是精准完成零食分拣装袋，还是毛巾折叠整理，模型可以保持稳定、高效的协同作业，展现了卓越的双臂协同与长序列操作能力。\n此外，在环境复杂度提升、干扰增多的场景下，也能维持较高的成功率和一致性。\n这显现出\n一个重要趋势\n：\n得益于采集过程更贴近真实任务，\n采集体系\n增强了\n训练匹配能力，模型开始从“能够粗糙地完成任务”向“能在非理想条件下可靠完成任务”演进。\n而数据采集开始成为面向模型能力补齐的持续行为，这让数据采集开始具备闭环属性。\n一旦采集与模型训练形成联动，整个数据系统的运行效率将得到显著提升。\n从堆量走向边采边筛，数据采集的分水岭来了\n如果放进更长的时间尺度来看，RoboPocket就不能视为一次孤立的产品更新。\n机器人学习的发展，本质上是一部数据采集方式不断演进的历史。\n最初，机器人\n只能在实验室中完成标准任务\n，数据由少数研究人员在封闭环境中录制。\n随着具身智能的发展，数据\n开始走向规模化采集场\n，遥操作与人机协作带来大规模机器人数据。\n2023年，穹彻智能联合上海交通大学卢策吾团队共同发布RH20T，机器人操作数据在中国首次实现\n系统性的规模化采集\n。但截至这一时期，机器人数据采集依然主要依赖预设场景。\n2024年，斯坦福大学推出的UMI让\n采集设备更加轻量和简单\n，数据采集开始转向“自然发生”。\n2025年，穹彻智能推出CoMiner伴随式数据采集系统，机器人\n开始走出采集场，进入真实世界，在开放环境中获取更加多样、复杂的操作数据\n。\n梳理这个过程可以看到，具身数据一步步走出搭建的实验场景，愈来愈贴近现实。\n2026年，RoboPocket的出现，将机器人数据采集，\n从特定场所与专业系统彻底释放到整个社会中\n。\n手机成为节点，每个普通人可以参与采集。\n无可否认，这是一次采集范式从“专业体系”走向“社会化网络”的转变。\n当然啦，采什么、怎么采、优先级如何，这些都不是由人随意决定的。\n这时候，前端连接真实世界的分散场景，后端连接任务库、模型训练与评估系统的RoboPocket，就起到了\n数据入口与调度中枢的双角色作用\n。\n正因为有这套持续在线的判断与调度机制，数据采集才第一次具备了真正社会化的前提条件。\n数采员可以是每一个普通人，但采集行为始终根据模型需求由数据中枢系统统一牵引调度。\n长期来看，会推动具身数据从工具竞争迈向体系竞争。\n谁的数据采集流程更早地接入模型反馈、谁的\n任务设计\n天然适配训练目标，谁就能更快积累泛化能力与落地鲁棒性。\n行业普遍认为具身智能还在上半场，期待着这个领域和大模型一样，能够用暴力美学带来能力涌现。\n所有人都在往具身模型里扔更多数据，但\n真正赢的人，一定率先解决了其它更深层次的问题\n。\n既然如此，对想要持续scale up的具身智能行业来说，数据采集从源头就对齐目标就是一场迟早会发生的机制变动。\n因为未来模型之间的差距，很可能就源于数据闭环的建设深度。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247861203&idx=1&sn=9d7cebe90071f5110150d838fc4259ae&chksm=e9478f8dfbd86cfff9ae95e51040e570381e33290f9c86d9a7eb8e7d95965c793b2a9067d866&scene=0&xtrack=1#rd",
      "publish_time": 1768285200,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1768346361,
      "last_modify_ts": 1768346361
    },
    {
      "id": 471,
      "article_id": "51820",
      "title": "大模型拿金牌却输给三岁宝宝！一套「纯视觉考卷」把顶尖VLM打回幼儿园",
      "description": "大模型虽在文本推理和复杂任务上表现突出，却在简单视觉认知任务如连线找垃圾桶、数积木上屡屡失败，暴露出其对视觉信息理解与语言描述之间存在断层。人类能轻松完成的直观视觉判断，AI因无法将视觉内容转化为语言逻辑而失效，凸显当前多模态模型“看懂”世界的能力仍远逊于人类，亟需新的评测基准来衡量其真实理解力。",
      "content": "新智元报道\n编辑：定慧\n【新智元导读】\n大模型能写代码、解奥数，却连幼儿园小班都考不过？简单的连线找垃圾桶、数积木，人类一眼即知，AI却因为无法用语言「描述」视觉信息而集体翻车。大模型到底「懂不懂」，这个评测基准给出答案。\n过去一年，大模型在语言与文本推理上突飞猛进：论文能写、难题能解、甚至在顶级学术/竞赛类题目上屡屡刷新上限。\n但一个更关键的问题是：当问题不再能「用语言说清楚」时，模型还能不能「看懂」？\n为了测评模型能不能「看懂」，以及能「看懂」多少，UniPat AI携手红杉中国xbench团队，并联合多家大模型公司与高校的研究员，发布新的多模态理解评测集BabyVision。\nUniPat AI致力于构建真实场景下AI训练、评测与应用的新范式，推动其实现可泛化、可信赖的真实世界部署，并创造切实的经济与社会价值。\n如果一个视觉问题可以完全用文字描述且不丢信息，它本质上就会退化成文本题。\n模型可以靠强大的语言推理能力一路通关，看起来很会「看」，其实是在走语言捷径。\n而真正的视觉能力，需要在没有语言扶梯的情况下完成：比较、追踪、空间想象、模式归纳。\nGoogle DeepMind创始人Demis Hassabis曾提到类似观点：\n「大模型可以在国际数学奥林匹克拿金牌，却会在小学几何题上出错；它能生成惊艳图像，却不理解杯子为什么不会飘在空中。」\n展望2026年，我们判断世界模型与视觉多模态将迎来新一轮突破性进展。\n值此开年之际，UniPat AI联合xbench率先抛出关键问题和全新「考卷」，以此迎接并参与新一轮技术突破的到来。\n让顶尖模型和孩子做同一张试卷\nBabyVision先做了一项非常直接的对比实验：把20道视觉中心任务（vision-centric）作为BabyVision-Mini交给不同年龄段孩子（3/6/10/12岁）和当下顶尖多模态模型来做。\n这份「小试卷」要求严格控制语言依赖：题目要求很简单，答案必须靠视觉信息本身得出。\n而最终评测结果显示：在「看懂世界」这方面，大模型还没上幼儿园：\n大多数模型的分数，聚集在明显低于平均3岁儿童的区间；\nGemini-3-Pro-Preview是唯一稳定超过3岁基线的模型，但距离6岁儿童仍差约20个百分点。\n下面是其中一道题，直观且反直觉，连线垃圾分类，小孩可以轻松做对，但顶尖模型追踪一条线都能追丢。\n三件物品沿着线分别连到哪个颜色垃圾桶？A, B, C分别表示上方从左到右的三个物体。\n<<  左右滑动查看下一张图片  >>\n正确答案：A-蓝，B-黄，C-绿\n模型答案（Gemini3-Pro-Preview）：A-绿，B-黄，C-蓝\n人类的解法几乎是本能，从点出发沿线走到终点（右侧照片是三岁幼儿真实做题痕迹）。\n但模型会写出一大段「逐段追踪」的推理，最后仍把两条路径接反：看起来「很会分析」，其实在最基础的视觉追踪上掉线。\nBabyVision-Full把视觉能力拆成4大类\n研究团队将视觉能力提炼为四大核心类别，每类下细分若干子任务：\n精细辨别（Fine-grained Discrimination）\n：分辨细微的视觉差异（8 个子任务）\n视觉追踪（Visual Tracking）\n：跟随路径、线条与运动轨迹（5 个子任务）\n空间感知（Spatial Perception）\n：理解三维结构及其关系（5 个子任务）\n视觉\n模式识别\n（Visual\nPattern Recognition\n）\n：识别逻辑与几何规律（4 个子任务）\n这套设计的核心理念很明确：不是为了「刁难」模型，而是\n量化那些「人类直觉就会、但构成智能地基」的视觉原子能力\n。\n这同样是具身智能（embodied AI）走向现实世界的必修课。\n为了最大程度确保「纯视觉」考核的有效性，BabyVision在数据构建上也下足了工夫。\n项目团队首先参考了儿童认知教材和视觉发育测验，梳理出了上述4大类共22种基础视觉子任务。\n接着，每个子技能挑选出 4-5 个种子示例（种子图片），作为该类型任务的典型代表。\n基于这些种子示例，研究者利用逆向图像搜索和关键词搜索，从互联网上爬取了约4000张相似的候选图片。\n在数据收集过程中，团队严格遵守版权规范，只挑选可用于非商业或学术用途的素材，并过滤掉可能包含大量文字说明或需要文化常识才能理解的图片。\n由此获得的海量图片进入人工标注环节：多名专业人员逐一检查图片，筛除不适合出题的样本，对保留下来的图片精心设计问题和标准答案。\n为了确保答案的客观正确，每个问题还附有详细的「解题过程」说明，以证明答案确实可由视觉推理得出。\n最终，所有标注完成的问题都经过「双盲质检」——两位独立专家交叉审核，每道题只有在双方都认可其答案无误、推理严谨的情况下才被收录 ；若出现异议则退回修改，反复仍无法达成一致的题目则果断弃用。\n经过这一系列严苛的筛选，BabyVision最终产出了388道高质量视觉题目，涵盖22种子任务。\n最终评测结果\n在BabyVision-Full上，研究团队引入了人类基线，16位至少本科背景的测试者完成全量388题，人类准确率达\n94.1%\n。\n再看模型：\n•\n闭源最强：\nGemini-3-Pro Preview\n为\n49.7%\n开源侧：\n• 最强模型（\nQwen-3-VL-235B-Thinking\n）整体为\n22.2%\n，多数模型在12–19%区间。\n更关键的是：差距不是集中在某一个类别。\n四大类能力都在下滑，说明这是「系统性缺基础视觉能力」，而非某个单点缺陷。\n一些子任务甚至几乎「全员翻车」，例如\nCount 3D Blocks\n在多模型中普遍偏低，暴露的是模型结构化场景能力不足。\n为什么会这样？\n这些题目unspeakable\n最反直觉的地方在于：BabyVision里的很多题，对人类来说不难，甚至孩子会用指一指、圈一圈、沿着线走一遍就搞定。\n但模型一旦用文字去「复述」视觉，再用语言推理去算，信息就丢了。\n研究团队把这种现象概括为：「这些视觉题是\n「unspeakable」\n的，无法在不损失信息的情况下被完整语言化；模型试图把视觉压缩成token，细节在压缩中消失。」\n并进一步总结了4类典型挑战：\n挑战 1：「非语言细节」（Observing Non-Verbal Details）\n比如拼图/补全题里，选项差别可能只是一个微小边界、一个局部凸起、一个像素级错位。\n人类凭几何直觉「对齐边界」就能秒选，但模型一旦把形状用语言概括成「像钩子、两个腿、差不多七八个六边形」，细节就被抹平，选项在token空间里变得「几乎一样」。\n挑战 2：\n追线追丢了\n（Manifold Understanding）\n连线/绕线/轨迹题，答案编码在「连通性」里：\n人类是锁定一条线→穿过交叉→一路追到终点；\n模型往往把线翻译成「左/右/上/下」的离散步骤，一遇到交叉点就出现分叉爆炸，容易「换轨」追错线。\n挑战 3：缺少真正的空间想象（Spatial Imagination）\n三维方块计数、视角投影、遮挡下的结构判断，人类通常不是「用语言一步步描述」，而是把结构在脑中「立起来」，换个角度看，再数。\n模型则容易犯两类错误：漏掉隐藏块、投影关系搞错。这不是逻辑差，而是缺少稳定的3D内部表征与变换能力。\n挑战 4：图形规律归纳难（Visual Pattern Induction）\n这类题要求从少量视觉示例里抽象出规则，再迁移到新图。\n人类做的是关系映射，真正决定正确性的是「发生了什么变化」而不是「那里有什么」，具体的形状、颜色、绝对位置都可以变，只有它们在变换中的「身份」不变。\n模型常常盯着表面属性（颜色、形状），把「结构规则」误读成「外观统计」，导致迁移时幻觉规则。\nBabyVision-Gen给出一个新方向\n当文本推理不够用，一个自然的问题出现了：\n能不能让模型像孩子一样，用画、圈、连线、描轨迹来作答？\n于是，有了\nBabyVision-Gen：\n• 从原基准中重新标注出280道适合「生成式作答」的题\n•\n要求模型输出图像/视频来表达解题过程或答案\n•\n并开发了自动评测工具，与人工评测一致性达96%\n研究团队在BabyVision-Gen上评测了多种生成模型（\n包括Nano Banana Pro、Qwen-Image、Veo 3、Sora 2\n）。\n现阶段得到的结论很克制但重要：\n• 生成式推理在视觉追踪、精细辨别等VLM易翻车任务上出现「更像人类」的行为（会真的去画轨迹、做标注）；\n•  但整体仍然缺乏稳定到达完全正确解的能力。\n这至少说明：把视觉推理「落地到视觉操作」上，可能是补齐短板的一条路。\n下面看一个具体的例子：用红线沿着从左上角图形延伸出的那条线，完整地描出其全程路径。\nSora 2：\nNano Banana Pro：\n为什么BabyVision重要？\n正如研究团队在Blog中所写：\n「很难想象一个视觉能力低于3岁孩子的机器人，能够可靠地在真实物理世界里帮助人类。」\n今天，多模态模型「会说会写」已经很强，但要走向真正的通用智能与具身智能，视觉地基必须补上：看得准（细粒度辨别），追得住（轨迹/连通性），想得出（3D结构想象），归纳得了（图形规则迁移）。\n因此，BabyVision的价值正在于：\n把「看懂世界」拆成可测量、可诊断、可迭代的22个原子能力，告诉我们差距到底在哪里、下一步该补什么，从而引导多模态大模型发展\n。\n开源地址\nblog\nhttps://unipat.ai/blog/BabyVision\ngithub\nhttps://github.com/UniPat-AI/BabyVision\nhuggingface\nhttps://huggingface.co/collections/UnipatAI/babyvision\nUniPat\nUniPat AI致力于构建真实场景下AI训练、评测与应用的新范式，推动其实现可泛化、可信赖的真实世界部署，并创造切实的经济与社会价值。\n官网链接：https://unipat.ai\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663856&idx=1&sn=74085711dfe2d74f0f9dfdcde074c5c3&chksm=f0b01c996d5ca5ea3a65082c2fd5386a1a5123ee62d051647ebedcc2104f7191cd633415fdff&scene=0&xtrack=1#rd",
      "publish_time": 1768275600,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://unipat.ai/blog/BabyVision\", \"https://github.com/UniPat-AI/BabyVision\", \"https://huggingface.co/collections/UnipatAI/babyvision\", \"https://unipat.ai\"]",
      "add_ts": 1768346373,
      "last_modify_ts": 1768346373
    },
    {
      "id": 472,
      "article_id": "51819",
      "title": "上海交通大学夏泽洋教授团队 | 基于半监督学习的心脏磁共振影像动态特征分类",
      "description": "上海交通大学夏泽洋团队联合华中科技大学同济医学院附属协和医院夏家红团队及中科院深圳先进院熊璟团队，提出一种基于半监督学习的心脏磁共振影像动态特征分类方法，融合影像分割、运动参数估计与病理分类，有效减少对标注数据的依赖，在有限标记数据下利用未标记数据提升模型性能，实现了高精度的心脏MRI分割、运动分析与疾病分类，相关成果发表于《机器智能研究(英文)》2025年第6期。",
      "content": "公告栏\nMIR储备专家库持续招募中\n，欢迎感兴趣的老师申请。\nMachine Intelligence Research\n心血管疾病是全球首位致死原因，准确及时的诊断至关重要。磁共振电影成像(cine MRI)在心脏疾病诊断中发挥着重要作用。传统的基于监督学习的心脏磁共振影像疾病诊断和病理分类方法需要大量的标注数据，但临床上标注的心脏影像极其有限。半监督学习方法对标注数据的需求较少，但尚未有结合影像分割和运动参数估计的方法。\n上海交通大学夏泽洋教授团队联合华中科技大学同济医学院附属协和医院夏家红教授团队、中国科学院深圳先进技术研究院熊璟研究员团队\n提出了一种基于半监督学习的心脏磁共振影像动态特征分类方法，将影像分割、运动参数估计与病理分类有机统一，在心脏磁共振影像上实现了较高准确率的影像分割、运动参数估计和心脏病理分类，其框架如图1所示。相关成果已发表于《机器智能研究(英文)》2025年第6期中。\n图片来自Springer\n全文下载：\nCardiac Dynamic Characteristics Classification on Cine MRI Using Semi-supervised Imaging Approach\nFaizan Ahmad, Jing Xiong, Jie Wu, Jiahong Xia, Zeyang Xia\nhttps://link.springer.com/article/10.1007/s11633-024-1534-0\nhttps://www.mi-research.net/article/doi/10.1007/s11633-024-1534-0\n背景与问题\n心血管疾病每年造成约千万人死亡，是全球首位致死原因。准确及时的诊断对于减轻心血管疾病的影响和改善患者预后至关重要。磁共振电影成像(cine MRI)能够全面展现心脏的动态结构，在心脏疾病诊断中发挥着重要作用。临床上常通过分割心脏MRI影像和估计运动参数，从而计算心室体积、射血分数等临床指标，以辅助诊断扩张型心肌病、肥厚型心肌病等多种病理状态。传统深度学习方法多采取监督学习方法对心脏MRI进行分割并进行病理分类，该类方法需要大量标注的心脏MRI数据，不仅标注成本高，而且在真实临床环境中难以获得足够数据。而半监督学习方法对标记数据的需求较少，在有限的标记数据下，能够利用大量未标记数据提升模型性能。近年来已涌现大量基于半监督学习的心脏MRI分割方法，但这些方法通常将心脏影像分割和运动参数估计作为独立任务进行处理，忽略了两者之间的内在联系。融合心脏影像分割和运动参数估计的半监督学习方法，将有望提升心脏MRI分析的准确性和鲁棒性。\n图1  基于半监督学习的心脏磁共振影像动态特征分类方法框架\n方法\n基于上述背景，本文提出了一种基于半监督学习的心脏磁共振影像动态特征分类方法，将影像分割、运动参数估计与病理分类有机统一。该方法包含三个模块：分割模块、运动参数估计模块和病理分类模块。分割模块对心脏舒张末期(ED)和收缩末期(ES)的MRI影像进行分割；运动参数估计模块则从动态的MRI影像中提取位移场等心脏运动参数；病理分类模块基于分割模块和运动参数模块的结果计算多种心脏临床指标，并据此对心脏病理进行分类。\n分割模块包含一个基于均值教师架构的双路径复制粘贴分割网络，如图2所示。该模块首先生成将标注图像和未标注图像混合，生成双路径混合样本。未标注图像可以在双向信息流中学习到来自标注图像的共同语义特征。学生网络在双路径混合样本上进行预测，教师网络则在未标注图像上通过指数滑动平均更新参数并生成伪标签，两者之间引入一致性损失，既保证训练稳定，又提升未标注图像的边界与轮廓识别精度。\n图2  基于均值教师架构的双路径复制粘贴分割网络示意图\n运动参数估计模块包含一个改进的UNet架构网络，如图1左下所示。该模块将 ED 帧和其后一时刻的同层MRI图像输入网络，通过两帧之间的像素强度损失、像素移动损失和分割对齐损失的共同约束，网络学习到心脏在整个心动周期内的运动，预测心脏组织的二维位移场，从而得到像素级运动参数。\n病理分类模块包含一个多层感知机(MLP)分类器和一个随机森林(RF)分类器，如图1右所示。该模块基于分割结果，计算心室体积、心肌壁厚等临床指标；还基于分割结果和运动参数估计结果融合，计算射血分数、各心室体积比等临床指标。基于这些临床指标，MLP分类器和RF分类器分别对心脏病理进行分类，最终通过集成两种分类器的结果，提升分类准确性和鲁棒性。\n实验验证及结果\n为了评估所提出的方法，本文使用公开的ACDC数据集对分割模块和运动参数估计模块中的神经网络进行了训练和验证，并对本方法的分割结果和病理分类结果进行了测试。\n分割测试表明，本方法实现了高准确性和高效率的心脏MRI影像分割。本方法的分割结果指标与其他先进半监督学习方法的指标比较如表1所示。本方法在5%和10%标记数据上训练时，均获得了最优的Dice系数、Jaccard系数和HD95值。本方法的分割结果示意图如图3所示。此外，对比分析各种方法的模型复杂度表明本方法在参数效率和计算效率方面均具有优势。\n表1  不同半监督学习方法在ACDC数据集上分割结果指标比较\n图3  心脏MRI影像分割结果示意图\n病理分类测试表明，本方法也实现了高准确性的心脏病理分类。在五折交叉验证中， MLP集成分类器的准确率最高达到97%，测试集准确率为96%。\n总结与展望\n本文提出的基于半监督学习的心脏磁共振影像动态特征分类方法，将影像分割、运动参数估计与病理分类有机统一，在少量标注数据条件下达到了世界领先的影像分割性能和优异的心脏病理分类准确性，同时保持较高的效率、较好的鲁棒性和临床可解释性。本方法为在临床应用中利用未标记的医疗数据提供了一种新方法，有助于在研究和临床环境中实现自动化的心脏疾病诊断，有望提高诊断的准确性和效率。\n作者团队\nFaizan Ahmad\n中国科学院深圳先进技术研究院\n博士研究生\n主要从事医学影像与深度学习研究\n熊 璟\n中国科学院深圳先进技术研究院\n研究员\n主要从事医学影像引导的治疗研究\n吴 杰\n华中科技大学同济医学院附属协和医院\n教授、主任医师\n主要从事心衰治疗和心脏移植研究\n夏家红\n华中科技大学同济医学院附属协和医院\n教授、主任医师、院长\n主要从事\n心衰治疗和心脏移植研究\n夏泽洋\n上海交通大学\n长聘教授\n主要从事机器人与生物力学研究\n全文下载：\nCardiac Dynamic Characteristics Classification on Cine MRI Using Semi-supervised Imaging Approach\nFaizan Ahmad, Jing Xiong, Jie Wu, Jiahong Xia, Zeyang Xia\nhttps://link.springer.com/article/10.1007/s11633-024-1534-0\nhttps://www.mi-research.net/article/doi/10.1007/s11633-024-1534-0\nBibTex:\n@Article {MIR-2024-07-299,\nauthor={ Faizan Ahmad, Jing Xiong, Jie Wu, Jiahong Xia, Zeyang Xia},\njournal={Machine Intelligence Research},\ntitle={Cardiac Dynamic Characteristics Classification on Cine MRI Using Semi-supervised Imaging Approach},\nyear={2025},\nvolume={22},\nissue={6},\npages={1102-1115},\ndoi={10.1007/s11633-024-1534-0} }\n本文供稿：何镇宇 (上海交通大学夏泽洋教授团队)\n特别感谢本文通讯作者、上海交通大学夏泽洋教授对以上内容的审阅和修改！\n纸刊免费寄送\nMachine Intelligence Research\nMIR为所有读者提供免费寄送纸刊服务，如您对本篇文章感兴趣，请点击下方链接填写收件地址，编辑部将尽快为您免费寄送纸版全文！\n说明：如遇特殊原因无法寄达的，将推迟邮寄时间\n，咨询电话010-82544737\n收件信息登记：\nhttps://lcn76mgd97vz.feishu.cn/share/base/form/shrcnsQ6cmRjqoxPF5WDowSBFVr\nEND\n∨\n关于Machine Intelligence Research\nMachine Intelligence Research（简称\nMIR，原刊名International Journal of Automation and Computing）由中国科学院自动化研究所主办，于2022年正式出版。\nMIR立足国内、面向全球，着眼于服务国家战略需求，刊发机器智能领域最新原创研究性论文、综述、评论等，全面报道国际机器智能领域的基础理论和前沿创新研究成果，促进国际学术交流与学科发展，服务国家人工智能科技进步。期刊入选\"中国科技期刊卓越行动计划\"，已被ESCI、EI、Scopus、中国科技核心期刊、CSCD等20余家国际数据库收录，入选图像图形领域期刊分级目录-T2级知名期刊。2022年首个CiteScore分值在计算机科学、工程、数学三大领域的八个子方向排名均跻身Q1区，最佳排名挺进Top 4%，2023年CiteScore分值继续跻身Q1区。\n2024年获得首个影响因子(IF) 6.4，位列人工智能及自动化&控制系统两个领域JCR Q1区；2025年发布的最新影响因子达8.7，继续跻身JCR Q1区，最佳排名进入全球第6名；2025年一举进入中科院期刊分区表计算机科学二区。\n▼\n往期目录\n▼\n2025年第6期 | 大语言模型、自动驾驶、医学图像分割……\n2025年第5期 | 生成式模型、疾病诊断、步态识别、行人再识别......\n2025年第4期 | 特约专题: 具身智能\n2025年第3期 | 大语言模型、医学图像分割、图像阴影去除、写作风格变化检测......\n2025年第2期 | 常识知识获取、图因子分解机、横向联邦学习、分层强化学习...\n2025年第1期 | 机器视觉、机器人、神经网络、反事实学习、小样本信息网络...\n2024年第6期 | 图神经网络，卷积神经网络，生物识别技术...\n2024年第5期 | 大语言模型，无人系统，统一分类与拒识...\n2024年第4期 | 特约专题: 多模态表征学习\n2024年第3期 | 分布式深度强化学习，知识图谱，推荐系统，3D视觉，联邦学习...\n2024年第2期 | 大语言模型、零信任架构、常识知识推理、肿瘤自动检测和定位...\n2024年第1期 | 特约专题: AI for Art\n▼\n好文推荐\n▼\n精选好文 | 基于多模态学习的非酒精性脂肪肝病预测\n南京大学Kai Ming Ting团队 | 综述：基于孤立机制的异常检测研究\n南洋理工大学肖佳平 等 | 基于深度强化学习的异构机器人系统目标搜索与导航\n南开大学程明明团队 | MCANet：基于多尺度交叉轴注意力的医学图像分割\n自动化所吴书 等 | GraphFM: 用于特征交互建模的图因子分解机\n香港理工大学周立培团队等 | 综述: 面向以物体为中心的机器人操作的具身学习\n清华大学朱军团队 | DPM-Solver++：用于扩散概率模型引导采样的快速求解器\n南航张道强团队 | 综述：基于脑电信号与机器学习的注意力检测研究\n可信图神经网络的全面综述：隐私性、鲁棒性、公平性和可解释性\n哈工大江俊君团队 | SCNet：利用全1X1卷积实现轻量图像超分辨率\n自动化所刘成林团队 | 统一分类与拒识: 一种一对多框架\n上海交大张拳石团队 | 综述: 基于博弈交互理论的神经网络可解释性研究\n专题好文 | 再思考人群计数中的全局上下文\n专题好文 | Luc Van Gool团队: 基于分层注意力的视觉Transformer\n浙江大学孔祥维团队 | 综述: 迈向真正以人为本的XAI\n澳大利亚国立大学Nick Barnes团队 | 对息肉分割的再思考: 从分布外视角展开\n前沿观点 | Segment Anything并非一直完美: SAM模型在不同真实场景中的应用调查\n精选好文 | 推荐系统的波纹知识图谱卷积网络\n复旦邱锡鹏团队 | MOSS: 一个开源的对话式大语言模型\n自动化所黄凯奇团队 | 分布式深度强化学习：综述与多玩家多智能体学习工具箱\n约翰霍普金斯大学Alan Yuille团队 | 从时序和高维数据中定位肿瘤的弱标注方法\n专题综述 | 大语言模型中的知识生命周期\n精选综述 | 零信任架构的自动化和编排: 潜在解决方案与挑战\n欧洲科学院院士蒋田仔团队 | 脑成像数据的多模态融合: 方法与应用\n金耀初团队&郑锋团队 | 综述: 深度工业图像异常检测\n专题好文 | 创新视听内容的联合创作: 计算机艺术面临的新挑\n▼\nMIR资讯\n▼\n进阶前5%！MIR登榜”中国最具国际影响力学术期刊”\n影响因子全球第6名！MIR稳步进军世界一流期刊行列\n喜报 | MIR 首次入选中科院期刊分区表计算机科学类二区\n喜报！MIR入选中国科技期刊卓越行动计划二期项目\n特别提醒！请认准MIR官方渠道，谨防受骗\n前进20名！MIR再度跻身国际影响力TOP期刊榜单\n喜报 | MIR入选图像图形领域 T2级 “知名期刊”！\n喜报 | MIR被 ESCI 收录！\n喜报 | MIR 被 EI 与 Scopus 数据库收录\n点击\"阅读原文\"下载全文",
      "article_url": "https://mp.weixin.qq.com/s/S_PfOolZg-tJA48ock41WA",
      "publish_time": 1768273500,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://link.springer.com/article/10.1007/s11633-024-1534-0\", \"https://link.springer.com/article/10.1007/s11633-024-1534-0\", \"https://www.mi-research.net/article/doi/10.1007/s11633-024-1534-0\", \"https://link.springer.com/article/10.1007/s11633-024-1534-0\", \"https://www.mi-research.net/article/doi/10.1007/s11633-024-1534-0\", \"https://lcn76mgd97vz.feishu.cn/share/base/form/shrcnsQ6cmRjqoxPF5WDowSBFVr\"]",
      "add_ts": 1768346377,
      "last_modify_ts": 1768346377
    },
    {
      "id": 473,
      "article_id": "51818",
      "title": "自然·物理评论：控制具有复杂节点的复杂网络",
      "description": "真实世界网络包含数百万异质复杂节点，其控制极具挑战。2023年3月发表于《Nature Reviews Physics》的综述“Controlling complex networks with complex nodes”提出，融合统计物理与控制理论可为这类系统提供新控制视角，通过理解节点内部动态与网络结构的耦合机制，实现对复杂网络的有效干预，推动网络科学与工程应用的发展。",
      "content": "导语\n从互联网、人类社会网络到生物网络，真实世界的网络常包含数百万个异质节点。这些复杂网络不仅节点之间的连接模式复杂，单个节点也可能很复杂。要如何控制具有如此多复杂节点的复杂网络呢？今年3月发表于\nNature Reviews Physics\n的综述文章“Controlling complex networks with complex nodes”指出，结合统计物理和控制理论可以为此提供新视角，架起微观节点和宏观网络的桥梁。该综述回顾了领域最新进展，并提供了一份研究指南。今天的文章是对综述文章的全文翻译。\n关键词：\n复杂系统，复杂网络，统计物理，控制理论，机器学习\nRaissa M. D’Souza, Mario di Bernardo & Yang-Yu Liu\n| 作者\n朱欣怡\n| 译者\n胡一冰\n| 审校\n论文题目：\nControlling complex networks with complex nodes\n论文地址：\nhttps://www.nature.com/articles/s42254-023-00566-3\n目录\n摘要\n1. 引言\n2. 背景\n3. 现有建模范式\n4. 新范式和建模技术\n5. 研究指南\n摘要\n真实世界的网络常含有数百万个异质节点，这些节点有跨时间尺度和空间尺度相互作用。为理解、建模和控制这些系统，统计物理\n（statistical physics）\n和控制理论\n（control theory）\n等领域都提供了不同的视角。这些领域之间更多的交互和新范式\n（如异质性和多层次表示）\n的集成，对解决现实系统来说是必要的。研究者们可以结合统计物理拓展模型、整合\n（正负）\n反馈的概念和拓展控制理论公式，从介观角度进行分析\n（mesoscopic analysis）\n以计算整体自由度的平均值。同时，还需要整合理论模型、机器学习和数据驱动等控制方法。本综述回顾了最新的进展，并发现了有助于理解和控制真实系统\n（从振荡器网络和社会网络到生物和技术网络）\n的新契机。\n1. 引言\n统计物理学\n主要关注节点集的平衡\n（equilibrium）\n和宏观系综性质，并为理解和预测大量简单和相同实体的集体行为提供了一个框架。这种行为的典型实例包括描述\n气体粒子的\n麦克斯韦-玻尔兹曼速度分布，还包括当材料被冷却到居里温度\n（Tc）\n时的铁磁相变。\n相反，传统的\n控制理论\n逐渐演变为动力系统和工程的一个分支，致力于按照预期自动地控制系统或设备，使其能够忽略噪声、延迟和扰动。这涉及到设计反馈策略，在理想情况下希望通过影响相对较少的微观自由度，引导目标系统的动力学行为与期望演变同步。\n然而现代网络规模巨大\n（如互联网或人类交互网络）\n，人们无法完全了解每一个自由度及其相互联系，更不用说对所有自由度进行控制。因此，\n亟需架起宏观和微观的桥梁，建立平衡和动力学方法之间的联系，以控制具有复杂节点的复杂网络\n（complex networks with complex nodes）\n。本文强调“复杂”这一形容词，与复杂系统\n（complex systems）\n意义上的“复杂”相同，这意味着此系统是具有非线性行为的潜在异构系统。具体而言，\n“复杂网络”是指节点之间的连接模式，“复杂节点”是指单个节点有非线性行为\n。\n本文的组织结构如下\n：\n首先，介绍研究背景。具体包括（1）关于复杂网络和控制理论在统计物理的学科交叉点；（2）一般反馈控制理论和在真实网络应用中的挑战。\n接着，介绍并讨论现有的方法与思想，主要为适用于指导和控制复杂网络行为的统计物理和控制理论。然后，文章提出了可能有效的新方法和建模技术。\n最后，作者总结了一套研究指南，以促进未来跨学科发展。\n在此明确贯穿全文的两个控制理论中的基本概念：可控性\n（controllability）\n和可观测性\n（observability）\n。\n可控性\n是指控制输入的存在性，描述了人们在有限时间内通过合适的输入选择，引导动力系统从任何初始状态到任何期望的最终状态的能力。\n可观测性\n是通过衡量系统的输入和输出来估计系统内部状态的能力，通常识别携带足够信息的变量子集来重构系统的行为。注意，文中使用术语“控制理论”来指代专注于分析和设计反馈系统以实现预期目标的工作主体。\n2. 背景\n2.1 统计物理与结构可控性\n1990年代后期，随着互联网和万维网迅速发展、基因组数据和基础设施系统逐步完善、经济全球化势不可挡，网络科学[1]应运而生。统计物理的工具\n（如：随机图模型、生成函数和速率方程等）\n有助于人们更好地理解复杂网络的性质和行为——通常被描述为具有广泛规模、跨越几个数量级的潜在度分布。网络结构带来的关键影响是对随机干扰鲁棒、对针对攻击脆弱以及潜在的缺乏传染阈值。除了度分布，网络的显著结构特征包括小世界性、模块性和三元闭包[2]\n（图1）\n。\n图1. 复杂网络中的常见指标。a.节点度（k）在较大尺度上的分布（P）；b.集聚系数；c.社区结构：节点可以被分配到组内的连接密度高于组之间的连接密度的组。d.小世界属性：大多数节点不直接相连，而是通过网络上的短路径链接。e.相变，例如渗流相变，其中网络的最大连通片大小S随着平均度的增加而表现出相变。\n2011年，统计物理与复杂网络控制之间建立了重要联系，以分析研究具有线性动力学和任意度分布的网络系综\n（network ensemble）\n的可控性[3]。这种联系建立在结构控制的框架上，20世纪70年代的一篇文章[4]，通过图论方法解决了线性动力学网络上的可控性问题。问题在于，当应用在特定节点\n（[3]中的“驱动节点”(driver nodes)）\n时，如何确定是否存在控制输入能在有限时间内引导动力系统从任何初始状态到任何期望的最终状态，即使其可控。解决此问题的关键灵感来自于将识别最小驱动节点集的问题映射到网络上的最大匹配问题\n（图2）\n，然后使用统计物理学的空腔方法\n（在“统计物理方法”一节中深入讨论）\n进行分析解决。\n图2. 结构控制框架中的驱动节点的识别和相变。\na. 线性节点动力学（状态变量\n）有向网络上最大匹配问题的求解。能够识别最小驱动节点集，保证整个系统的结构可控性。对于一般有向网络（如图），可能有多个最大匹配（红色连边集）。因此，可以识别多个最小驱动节点集合（蓝色节点）。对于每个驱动器节点，必须施加确保结构可控性所必需的唯一控制信号（u\ni\n，蓝色波浪形箭头）。\nb. 控制鲁棒性（robustness）和核心渗流（core percolation）。量化不可避免的边故障下控制的鲁棒性，可以通过计算连边l的类型：\n1）\n临界（critical，lc）\n，若其不存在，则必须增加驱动节点的数量以保持对系统的完全控制。换句话说，lc是网络的所有最大匹配的一部分。\n2）\n冗余（redundant，lr）\n，移除此类边不影响当前的驱动节点集。也就是说，它不属于任何最大匹配。\n3）\n一般（ordinary，lo）\n，既非关键，也不冗余。\nlr作为平均度函数的非单调行为（上半部分）与网络中的核心渗流跃迁（下半部分）密切相关，其中n\ncore\n是核中节点的比例。当不同的最大匹配的数量开始呈指数增加时，发生核心渗流，这使得冗余连边的比例下降。\n对于有向ER随机网络，核心渗流发生在平均度=2e时（下半部分）。图经许可改编自参考文献[3]。\n在结构控制中，连边是否存在\n（即结构）\n比连边的权重更重要。传统上，结构控制框架假设节点根据线性非时变动力学演化：\n（有关非线性动力学的详细信息和扩展，请参见“新范式和建模技术”一节）\n。这种线性意味着：可以用线性代数的工具来阐明网络结构和可控性之间的联系，包括网络结构中的相变连接[5，6]。此外，还建立了可控性转变和控制状态轨迹的非局部性和控制输入的非局部性之间的平衡。\n除了结构控制之外，许多研究已经深入理解了控制能量\n（control energy）\n[8]、控制配置文件\n（control profiles）（基于控制流模式）\n[9]和来自现实世界系统的约束[10]。相关更全面的综述，请参见参考文献[11，12]。物理学家的控制理论综合入门，见参考文献13。然而，\n如何从统计物理的方法扩展到动态、非平衡、非线性的系统？\n这个问题仍然悬而未决。\n2.2 控制理论综述\n在经典的控制范式中，人们感测和控制感兴趣的特定系统或设备的行为，例如汽车、飞机或机器人。控制设计通常从感兴趣的系统的结构和动力学的数学\n（或计算）\n表示开始，并且包括合成反馈控制策略，该反馈控制策略通过感知系统行为来计算所需的输入以驱动系统达到期望的状态。负反馈提供了稳定行为的能力，即使在存在噪声、延迟或扰动的情况下，也具有保证鲁棒性的一些期望性能。相反，正反馈可以用于在非线性系统中实现双稳定性和分叉，驱动系统能达到多个稳定状态。\n顺着控制策略的思想，已经发展了许多针对线性和非线性系统的数学公式[14]。这些方法中，许多是分布式或分散式的，并且有些使用了复杂的非线性、自适应、计算和时变方法[15]。多数方法集中在单个系统上，这意味着所有相关的自由度及其动力学和耦合都是已知的\n（图3a）\n。然而，这一经典范式面临着新兴应用的挑战——\n如何应用到大规模、通过复杂的网络关系相互作用的动力学系统中\n（图3b）\n。当下，控制这种复杂的网络来协调它们的集体行为是控制理论的核心问题和热门研究主题，最早可以追溯到Šiljak在20世纪70年代后期的开创性工作[16]。\n图3. 控制范式。\na）经典反馈控制范式。系统的控制输出y被传感器测量或估计；测量输出\n反馈回比较节点（黑灰色），测量\n和参考信号（Ref）的差；控制误差e被馈送到控制器，该控制器再根据某个控制规则计算控制输入（u\n1\n）；计算的输入通过一组驱动器在系统的实际输入（u）中实现；在这种情况下，所有相关的自由度及其耦合都是已知的。\nb）分布式分散牵制控制策略。一些网络节点（黄色圆圈）向控制器（粉色方块）发送包含其状态或输出的信息（蓝色箭头）。控制器合作（黑边）制定网络控制策略，然后选择性地干预网络中部分节点（红色箭头）的行为，以实现一些期望的集体行为。\n图片由Davide Salzano提供。\n从控制的角度来看，复杂网络是由许多连续时间或离散时间单元组成的大规模动态系统的例子，这些个体可以通过静态或时变的互连网络进行交互[16,17]。\n因为需要在我们感兴趣的宏观行为\n（如共识或同步）\n与微观行动之间建立反馈联系，以设计所需的集体动力学机制，所以关键问题就成了\n1.判断给定网络是否满足基本的控制属性\n（例如可控性和可观测性）\n；\n2.如何在不同尺度上闭合反馈回路\n（图4）\n？\n实现控制的方法有：控制网络节点、赋予边动力学属性、通讯协定\n（communication protocol）\n、控制网络本身的结构或组合以上方法。一个突出的例子是牵制控制\n（pinning control）\n[18 -21]，其中只需控制相对小部分的网络节点或边缘就能够控制系统的集体行为朝一些参考平衡或渐近轨迹[22，23]发展。然而，我们还想要设计策略控制更一般的、有更广泛节点动力学的系统\n（如，网络结构随时间或是节点动力学函数演变）\n。\n图4. 复杂网络中的闭合反馈回路需要在不同尺度上进行感测、计算和驱动（actuation）。感测和制动可以在图中描绘的任何尺度下执行。在该图中，为了简单起见，我们描绘了集中式控制策略；然而，当处理网络系统时，控制策略通常是分布式和分散式的。注意r是表示系统的期望行为的参考信号。图片由Marco Coraggio提供。\n2.3 复杂网络背景下的控制\n交叉学科真实世界网络对控制主要提出了三点挑战：\n一、可能存在多个长度尺度和时间尺度的行为和交互，包括个体之间会相互影响的自组织行为。\n在某些情况下，我们只关注集体行为\n（例如，感染总人数）\n。然而在其他情况下，我们有可能对微观细节感兴趣\n（例如，哪些特定的人被感染）\n。同样地，对于测量和输入控制信号与自由度相互作用的能力，可能存在约束。此外，有时我们或许不需要非得将系统控制到特定状态，只需要简单地控制，使系统远离不期望的状态\n（例如系统崩溃）\n或朝向期望状态可能就足够了。参考文献[10，24，25]中有对真实系统的干预中的高维性，非线性和约束所带来的挑战的深入讨论。\n二、网络本身具有模糊性。在大脑网络中，节点可以是单个神经元、神经元块、甚或是跨越大量神经元的脑区。\n研究节点之间的交互，学习连接模式\n（如“线路图，wiring diagram”）\n此类的实验成本很高，并且无法学习到完整的连接模式。注意，单个边的存在与否对介数中心性之类的属性有明显的影响。此外，网络上发生的动力学活动与拓扑结构同样重要。例如，在交通网络中，确定拥堵模式的是网络流和网络拓扑。长程序就这样从节点动力学和网络结构的相互作用中涌现而出[26，27]。\n三、将异质性\n（heterogeneity）\n和多尺度结合起来意味着，系统的不同部分可能需要不同类型的表征。\n其中一些能够用离散时间动力学建模，而另一些可能需要基于连续时间；某些方面可能需要用常微分方程\n（ODE）\n描述，另一些方面则需要用偏微分方程\n（PDE）\n描述。例如，在交通管理应用中，ODE能很好地描述车流的运动；而PDE在描述个体级别的车辆接受信号灯或其他信号的建模中，更具优势。如何整合这种分析仍然悬而未决，还有噪音和不确定性在旁“蠢蠢欲动”。最后，此应用领域的跨度也很大，从电网到社会网络到生物系统，各自有不同的目标和约束，这就意味着我们必须谨慎地选择一个恰当的建模范式。\n建模时的关键问题是：\n1.我们测量什么？\n2.什么因素有影响？\n3.何时影响？\n4.如何影响？\n此外，研究如何收敛到目标状态与保持复杂网络控制策略鲁棒性和弹性的恰当方法也至关重要。\n3. 现有建模范式\n3.1 统计物理方法\n统计物理学的概念和技术已广泛用于研究复杂网络的结构和动力学特性[2，28，29]，研究领域覆盖网络生长\n（network growth）\n，相变和级联故障\n（cascading failures）\n等复杂网络基本行为。从统计物理学的角度研究控制这些行为并不是为了严格满足可控属性，更像是在控制系统：例如，引导它远离临界点或减少故障发生。直接应用统计物理工具来研究复杂网络的传统控制性质主要涉及到可控性和可观测性。我们将在接下来讨论这些主题，并将方法总结在表1中。\n表1. 基于统计物理的概念和方法，用于研究复杂网络的结构、动力学或控制特性\n为了研究\n复杂网络的生长\n，特别是以幂律分布而闻名的无标度网络[30]，已经有了许多具有强烈统计物理色彩的分析方法，例如连续统理论[31]、主方程方法[32]和速率方程方法[33]。\n统计物理学的一个核心研究点是\n相变\n（临界点外部控制参数的小扰动，使系统宏观行为发生剧烈变化的现象）\n[34]。在网络的背景下，有一个著名的相变，就是渗流相变\n（图1e）\n，可以使用随机图模型进行分析[35]。这些模型基于统计系综的概念，是统计物理学的基础。\n网络的统计系综\n考虑给定的一组属性，例如指定的度分布。系综中的每个体系是\n具\n有特定节点和连边构型的网络实现，并有其出现的概率（即，统计权重）。除了给定的属性集之外，我们假设其他属性都是完全随机的，因此它们可以通过使用一些平均场方法在整个系综上平均，例如基于分支过程和树假设的生成函数形式[36，37]。\n渗流相变描述了网络中大规模连通片的突现，逐渐连通过程中的小扰动可以控制临界点的位置，并可能导致爆炸性渗流[38，39]。对于临界转变，已有研究表明，系统到达临界点时，预测的涨落和自相关时间会增加，这可以作为早期的预警信号[40，41]。\n统计物理学中自组织研究的理论基础是自组织临界性\n（self-organized criticality, SOC）\n的范式[42]。在SOC中，竞争力的平衡\n（例如驱动和耗散）\n会导致系统接近临界点，从而引发遵循幂律分布的级联故障。这种级联故障在复杂网络\n（如电网和脑网络）\n中时有发生[43]。通过驱动力的性质来控制SOC是统计物理学文献中的一个重要主题[44 -47]，正如最近“龙王”事件[48 -51]备受关注\n（‘dragon king’ events，灾难转变前兆）\n。\n统计物理工具在可控性和可观测性方面的直接应用\n是存在的。下面，我们将介绍几个完全从网络结构\n（或连接模式）\n的角度，研究控制特性的典型案例。\n其一是\n应用空腔法\n（cavity method）\n来解决结构控制问题\n[3]。由于结构可控性定理[4]的图形解释，人们可以简单地检查网络结构，来检查网络结构是否可控，而避免依赖复杂的边权矩阵运算。特别地，我们可以识别动力节点\n（driver nodes）\n的最小集合，其时间相关控制\n（time-dependent control）\n足以控制系统的整个动力学。这种识别可以通过将结构控制问题映射成为最大匹配的纯图论问题来实现[52 -54]。利用统计物理学的空腔方法[55 -57]\n（及其在解决最大匹配问题[58]中的进一步应用）\n，可以分析计算具有指定度分布的网络系综的某些控制属性[3]。这些属性包括：最大匹配的大小，它与确保结构可控性的驱动器节点\n（或控制输入）\n的最小数目直接相关；以及不同最大匹配的总数，它与不同控制配置的数量直接相关，并且会因此影响控制鲁棒性。\n另一典例是\n电网的可观测性研究\n。在该系统中，可以使用相量测量单元\n（phasor measurement units，PMU）\n来确定节点的电压\n（还可看作状态变量）\n。PMU能够测量其对应节点的实时电压和线路电流，因此PMU不仅能确定其所放置的节点的状态变量，还能确定其所有最近邻居的状态变量。在这种情况下，可观测性问题可以映射成一个纯粹的图论问题。事实上，PMU的随机放置会导致网络可观测性转换[59]，可以使用母函数形式\n（generating function formalism）\n进行分析研究[36，37]。此外，识别电网中传感器节点\n（即PMU）\n的最小集合问题可以映射成为经典的图论问题：尽管它通常求解困难，但最小支配集问题可以通过消息传递算法\n（源于自旋玻璃理论）\n来解决，该算法提供了接近最优的解决方案，并且在真实网络中表现良好[60]。\n如何将控制问题映射为纯图论问题？\n任何控制属性\n（如控制能量成本）\n，都需要相关领域的具体知识，而且纯粹的图论解释和相应的统计集成方法在此无用武之地。随机矩阵理论[61]中可以直接处理复杂网络边权重的技术，这对适当的网络系综的建模来说必不可少。一般来说，具体的结构和动力学都很重要[62]。\n3.2 控制理论方法\n传统控制理论方法的目的是分析和操纵特定系统的行为。控制问题可以概括成如下三个：\n确定需要感测什么\n、\n需要控制什么\n以及\n如何用感测信息实现控制目标\n。因此，任何控制设计的三个关键要素是感测、计算和驱动[14]。表2中总结了一些方法。\n表2. 控制理论中用于分析和控制复杂网络的概念和方法。\n多智能体系统中经典控制目标包含\n一致性\n（consensus，即所有单元会朝着同一个平衡点收敛）\n[63-71]和\n同步性\n（synchronization，即收敛到\n渐进时变解\n[asymptotic time-varying solution]）\n[72-75]，同时也还包括如编队控制\n（formation control）\n[76 -78]，模式生成\n（pattern formation）\n[79]和多智能体协同运动\n（如集群）\n[80]等目标。控制目标通常根据性能\n（侧重于瞬态特性，例如建立时间、上升时间和超调量）\n、稳定性\n（例如收敛到状态空间中的平衡或流形）\n以及对噪声和外部扰动的鲁棒性来制定[14]。\n从系统的数学\n（或数据驱动）\n模型和控制目标出发，我们可以尝试：1.建立系统的可控性和可观测性；2.设计控制策略，并通过对闭环网络系统中的这些特性进行适当的严格证明，证明该控制策略能保证所需行为的收敛性和稳定性\n（图5）\n。\n图5. 经典闭环控制器设计的主要阶段。始于真实系统，先建模分析其在没有控制的情况下的性质。然后设计控制策略以满足目标要求，须在实施之前进行验证。通常，这种设计方法在实现精确的控制之前需要多次迭代。丨\n图像来源：Gian Carlo Maffettone\n我们常希望设计分布式和分散式策略来处理多智能体系统，不必以集中的方式决定感测、制动和控制输入。某些控制问题也用无需反馈的开环策略来解决，但一旦存在扰动，稳定性和性能要求就无法被满足，就不够鲁棒。因此在此处，我们只关注闭环反馈控制策略。\n可控性问题\n是一个存在性问题，关注在给定网络结构、主体的动力学和连边交互的情况下，\n引导集体行为需要控制哪些节点\n。在复杂网络的背景下，无法通过秩来判断是否系统是否能控时，可以使用结构可控性的和Gramians可控性来解决这个问题[81-85]。尽管过去十年可控性问题取得了显著进展，但仍然存在许多未决的问题，包括理解非线性或时变系统网络中的可控性，或者当网络结构随时间或动力学函数\n（状态依赖网络演化）\n演化时的可控性。\n研究\n可观测性问题\n是为了发现\n哪些变量的信息量足以重现整个系统行为\n。当应用于大规模复杂网络时，可观测性的评估也变得复杂繁琐，因为它取决于能重塑整体网络动力学的变量。同样，控制的方法\n（如结构可观性理论）\n也是为了这一目的[82，86-88]。然而现在仍有许多可观测性问题有待解决\n（如研究非线性动力系统的时变网络结构的可观测性）\n。\n由于图论工具可以补充和增强代数或几何基础理论，复杂网络的可控性和可观测性方法与传统的控制理论方法相比有明显变化。这一重要研究方向在20世纪70年代末由Šiljak的早期工作[16]中首次得到承认，并在后来的工作中得到进一步发展[82]，它使得处理大量相互作用的动态变量具有可行性。\n（我们注意到，使用图论方法来研究网络问题至少可以追溯到20世纪60年代的数学社会学社群。[89]）\n如果已经分析了目标系统的基本特性，就可以设计反馈控制策略\n（闭环策略）\n了。通过观测信息和控制输入，来操纵系统以实现控制目标。验证控制策略的一个基本问题是分析和证明受控网络系统从不同的初始条件\n（稳定性）\n和外部扰动\n（鲁棒性）\n下的收敛性。通过借鉴同类系统的稳定性和鲁棒性方法，现已推广出许多研究动力系统复杂网络稳定性和鲁棒性的方法。\n（关于可用方法，详见参考文献[17，21-23，90-95]）\n。\n关于稳定性，研究给定复杂网络系统的局部或全局稳定性的方法包括两方面：\n1.将网络系统视为一个整体，研究其在扰动下的稳定性的方法；\n2.研究节点以某种方式耦合时，系统保持稳定的方法。\n考虑整个网络系统的分析工具包括：基于李亚普诺夫直接法的方法[90]或基于线性化工具\n（如主稳定性函数方法，master stability function）\n的方法[96]。其他的有效方法包括增量稳定性和使用收敛工具，如收缩理论[23,92-95]或增量被动性[91]。这些理论工具也适用于研究连接稳定性[16]相关概念的其他问题，譬如前面提到的另一个核心问题——底层网络结构如何影响发生在其上的动力学。\n控制设计的方法在文献中比比皆是，各领域基于动态优化控制理论的控制设计方法包括：最优控制、博弈理论、自适应控制、智能控制、非线性控制、模型预测控制和鲁棒控制等等。目前，基于机器学习的数据驱动方法和控制策略也越来越多地被用于控制复杂网络的行为。更多信息详见参考文献[97，98]，在“新范例和建模技术”一节中，我们也有讨论。\n尽管在控制理论的研究领域有许多进展，但仍有许多挑战有待解决。最近控制学界致力于研究噪声对网络中系统集体行为的影响、抗扰动能力\n（包括结构扰动）\n、发展协同和共识策略以保障节点的隐私，以及网络系统中扰动传播分析与控制[99-109]。\n3.3 动力系统方法\n正如统计物理学对控制策略的启发，动力系统方法也打开了控制策略的思路。控制策略常旨在操纵和影响系统，而不是严格的可控。有许多方法直接利用系统的非线性性质，还有利用数据驱动的方法\n（如系统识别）\n。我们接下来将聊聊这些内容。\n给定动力学方程对系统的行为及其吸引子、极限环和吸引盆边界的相空间进行建模，可以找到利用自然轨迹将系统驱动到相空间的期望区域的蓄意扰动\n（strategic perturbations）\n。早期，这一领域的控制混沌的后续工作[111 -113]证明了这种可能性是混沌吸引子[110]。最近，学者们已解决了如何通过一系列考虑了扰动约束的策略性反冲来实现控制[114]。虽然利用相空间中的自然轨迹看上去完美，但在实践中它难以提供传统控制理论所必需的严格性能保障和对噪声的鲁棒性。例如，吸引盆的边界可以是网状的或分形的。\n在相关文献中，有大量关于嵌合体状态\n（chimaera states）\n控制的工作[115]。嵌合体状态由对称耦合的相同振荡器系统中相干和非相干动力学的共存所定义，故显示出惊人的对称破缺性质[116、117]。这方面的研究包括延时反馈控制[118 -120]、牵制控制[121]、周期性强迫[122]、通过拓扑结构控制[123]或耦合修改[124]以及多层网络中嵌合体的控制[125]。参考文献[126]以自组织非线性动力系统为中心进行了综述，虽然还有许多方向有待探索。\n通常，系统的运动方程是未知的，甚至连状态空间也可能是未知的。但是系统上的数据可能很丰富。如果一个系统上的数据，即可观测量，是它状态的函数，人们就可以\n从时间序列数据中推断出系统的演化\n。例如，许多文献中有用于系统识别或网络推断的技术\n（如文献[127-129]及其参考文献）\n。在下一节中，我们将讨论基于算子理论和稀疏识别技术的最新方法。\n4. 新范式和建模技术\n本节讨论如何改进前述方法，使之更适合真实系统。\n4.1 网络复杂性会增加多少？\n近年来，增加网络复杂性一直是物理学研究的焦点。“网络”在形式上由元素之间的成对交互的集合组成，但是真实网络中经常可以找到超越二元的高阶交互作用。例如，在化学反应网络中，反应进行可能需要三种试剂；在共同作者网络中，常有多个作者。有人用超图\n（hypergraphs）\n和单纯复形\n（simplicial complexes）\n来解决这个挑战[130，131]。该部分前沿进展包括定义统计系综[132，133]、分析可接受的同步模式、完全同步[134 -136]和集群同步[137，138]的稳定性以及可控性[139]，但目前特定问题的控制\n（ad hoc control）\n策略尚未完全开发。\n同样，提供网络动力学的瞬时描述[140-141]的\n活动驱动时序网络\n（activity-driven temporal networks）\n的范式也富有成效。在这种方法中，每个节点的活动潜力\n（activity potential）\n是根据该节点相对活动程度来确定的，相对活动程度可以从给定时间窗的时序网络数据集中测出，活动电位分布函数可以表征系统级动力学。\n真实世界系统通常是\n多层网络\n（multilayered networks）\n形式的。例如，每个人有许多种社会身份，关键基础设施网络通常具有物理分层或逻辑分层结构。这一概念是多层网络结构控制\n（structural control of multiplex networks）\n[142、143]、使用图论捕捉分层关键基础架构[144、145]和使用多重控制策略[146]的基础。\n4.2 人们能控制非平衡统计物理模型吗？\n统计物理学方法倾向于关注平衡系统，但对于细致平衡\n（detailed balance，严格热动平衡）\n的系统仍存在涨落耗散关系\n（fluctuation–dissipation relations）\n。例如，可以使用双量子点模型\n（double quantum dot model）\n[147]上的反馈控制方案将热量转换为功，这一发现正推动关于反馈控制和\n涨落\n的进一步研究[148]。同样，有几个经典的驱动远离平衡系统的模型，如自组织临界性[42]\n（在“统计物理方法”一节有叙述）\n、Kardar-Parisi-Zhang\n（KPZ）\n方程[149]和不对称简单排斥过程\n（ASEP）\n模型[150]。尽管这些模型伴随着许多普遍现象\n（由一般属性支配，一般属性独立于系统的动力学细节的基本对称性）\n，但我们仍可以用反馈来影响和控制行为。\n4.3 结构控制框架较线性模型好多少？\n结构控制的经典框架中有一个基本限制：基于线性非时变动力学。\n其中A,B中的元素都是零或独立的自由参数。这个框架基于线性系统的结构可控性的概念。如果我们说系统（A,B）是\n结构可控\n的，那就是说，可以在A,B中设置特定非零元素，使得系统可控。这需要满足卡夫曼可控性判据\n（Kalman’s criterion of controllability）\n：\n最近，有学者在结构控制框架的基础上提出了\n非线性系统结构可达性\n（structural accessibility）\n的概念[151-152]，并将其适用于一般非线性系统：\n动力学假设的条件不严，要求f(x(t))和g(x(t))是亚纯函数\n（meromorphic functions）\n。亚纯函数一词源于希腊语\n(\nmeros\n)\n，定义为两个整函数之比，只有有限阶、孤立的极点和零点，无非必要奇点。结构可达性的概念可以被认为是线性系统中结构可控性的非线性推广。令人惊讶的是，结构可达性和结构可控性几乎有相同的图论条件。二者关键区别是，“自循环”\n（对应内禀节点动力学）\n是结构可控性的图论充分条件，而非结构可达性的充分条件。这种结构可达性框架可以从底层网络结构中识别驱动节点[151]，并已在生态和生化系统中得到了应用。\n4.4 如何处理大型复杂的多智能体系统？\n另一个紧迫的众所周知的控制难题是，如何解决复杂系统的动力学的节点数目限制？或者更准确地说，让系统出现涌现行为时节点数目仍保持不变。在这种情况下，问题就变成了：找到一个对目标可观测量\n（我们希望控制的）\n的宏观描述。这样做需要\n目标变量在宏观尺度\n和\n被控微观个体层面的闭循环\n。对于极其复杂和大型的网络，即使是线性时变的系统，都很难实现除了识别驱动节点之外的任何控制目标。\n连续化\n（continuification or continuation）\n方法[153，154]将由\n大量常微分方程描述的微观问题，\n转化为\n描述宏观水平上目标可观测量的偏微分方程\n（PDE）（连续化阶段）\n。然后，使用控制偏微分方程[155、156]的技术来设计宏观控制动作，并且最终将所得的控制律离散化，使得其可以被部署回到微观个体级别[157]。在这种方法中，挑战就转变成了\n寻找连续化目标问题然后离散化\n的方法，在微观水平上进行分布式控制策略。然而主要障碍是当从PDE得到的控制律被离散化时，大多数微观个体通常会受到控制输入的影响，这与牵制控制的思想\n（控制少的节点实现目标）\n相反。\n另一个框架是\n基于线性系统的大规模网络的图子控制\n（graphon control）\n[158]。图子\n（graphon）\n是收敛图序列的极限，形成了一种自然的非参数方法来建模和估计超大型网络[159]。由于其与统计物理、极值组合学和网络上的非参数统计分析的联系被广泛讨论[160 -162]，图子理论\n（Graphon theory）\n已经成为图论的一个子领域。\n基于图子的控制复杂大型网络系统的策略由三个步骤组成：\n一、当节点数趋于无穷大时，首先确定有限网络系统序列S的图子极限。\n二、在此约束下解决相应的控制问题。\n三、通过逼近极限系统的控制律，生成沿着有限网络系统的序列S的任何系统的控制律。\n该策略已被用于大规模复杂网络的状态控制问题和线性二次型调节器问题。\n图子博弈\n（graphon games）\n的概念源于网络博弈和干预的统计框架。此框架是用图子理论研究大型网络干预的另一典例。但如何利用图子理论来控制具有一般非线性动力学的任意大网络仍有待解决。\n随着研究渐渐开始面向更大规模的网络，通过控制和观察介观尺度来控制目标复杂网络的问题变得愈发重要，这样的介观尺度可以是群体或节点或连边的集群水平。这个方向有待进一步研究，并且需要从控制的观点来定义适当的介观层次。\n4.5 我们能用数据重构运动方程吗？\n除了成熟的系统识别\n（system identification）\n方法之外，还有其他的方法可以\n重建有效的运动方程\n。\nKoopman算子方法就是其中一种。它是对\n可观测向量空间的线性变换\n，用著名的Koopman算子的特征函数将其表示为线性展开式，以实现从无限维的观测空间到线性的演化。不稳定性与具有正本征值的模式有关，甚至可以通过相关联的本征向量中的相对振幅来识别各个节点在不稳定性中的作用。Koopman算子用于动力系统分析的能力已经毋庸置疑[164，165]，并且也可以应用于非线性流[166]中，例如近期在应用最优控制器[167，168]和反馈控制[169 -171]的方法中效果显著。参考文献[172]是一本实用的入门书，参考文献[173，174]介绍了最近的两个综合应用。\n另一种不同的数据驱动方法依赖于这样的假设——\n尽管数据是高维的，但动力学主要只受几个主要变量的影响，使得方程在可能的函数空间中是稀疏的\n。稀疏性促进技术和机器学习可以在有噪声的测量数据上组合使用以识别控制方程，这是一种被称为非线性动力学的稀疏识别\n（sparse identification of nonlinear dynamics，SINDY）\n[175]的技术。SINDY已被扩展到包括驱动的影响，并且能显示如何基于有限的噪声数据增强模型预测控制的性能[176]。\n我们常用降维技术将高维时间序列数据映射到低维子空间，然后用非线性动力学的稀疏识别\n（SINDY）\n来确定失去的动力学信息。\n如果所得到的相空间由几个固定点组成，我们就可以调节系统，诱导期望的不稳定性和吸引子，从而实现高维、非线性、网络系统的前馈控制[177]。\n4.6 如何使用机器学习和数据驱动的控制方法来征服复杂性？\n随着计算能力的提高，应用中有趣的复杂性问题越来越多，\n基于机器学习和数据驱动方法的复杂网络控制方法\n在各科技领域变得越来越普遍。\n典型的例子包括互联自动驾驶车辆的原型设计。Google Waymo\n(https://waymo.com)\n等公司已经提出使用深度学习设计自动驾驶汽车或实现自动车辆排队的方法，如卡车排队。\n（https://highways.dot.gov/research/laboratories/saxton-transportation-operations-laboratory/Truck-Platooning）\n还有在自主机器人和群体机器人领域中，机器学习的计算技术[178]使用频率也愈加频繁。如前所述，已经有很多在不同场景下对网络进行数据驱动控制的方法，但是我们仍然没有在更普适的环境中使用这些方法的框架。\n然而，当问题太难分析解决时，数据驱动和机器学习方法[179，180]可能是唯一的选择，例如当无法推导出数学模型或要解决的任务太复杂时。当目标是通过在时间上动力学自适应来实现控制时，其时序网络的结构会响应动力学的变化，从而各节点的状态依此进行交互[140、141]\n（参见参考文献[181]以获得更简单的说明性示例）\n。考虑到实际应用中的目标通常是，\n在存在故障或扰动的情况下，赋予网络重塑其结构的能力以保持其所需的功能，因此解决这个问题在实际应用中极为重要\n。例如，自组织电网能够自我隔离以防止故障或电流过载、自动驾驶车辆或机器人组能改变其互连结构以更好地执行避障或复杂机动的情况。\n5. 研究指南\n要想推进前沿和解决实际问题，就需要推进多学科和交叉学科的研究。不仅要征服复杂性，还要顺势利用它，来实现更好的控制性能、来解决更复杂的问题。研究目标应该是双重的：\n第一，\n要弥补学科之间差距，将平均场方法等技术的使用扩展到复杂网络的控制\n中去\n[182]\n。同时，要考虑到现实的约束条件和实现反馈策略的需要，以保证研究问题所需的稳定性、目标性能和鲁棒性。\n第二，\n确定一组范例问题或标准案例用于验证和对比控制复杂系统的不同方法\n。这样做非常重要，因为在许多不同领域中出现的应用程序和在特定领域中开发的技术可以被抽象以解决更一般的问题。例如分析非线性振荡器\n（如神经元）\n的动力学相位响应曲线技术，最近就有人利用它来实现更普遍类别的非线性系统的控制\n（见参考文献[183]和其中的参考文献）\n。\n为了推动这一领域的发展并促进跨学科的合作，我们需要集体共同努力。为解决控制复杂系统的基本问题，第一个呼吁就是：\n发起一系列针对标准方法的挑战！\n在计算机科学领域，举行挑战赛已经成为一种传统。目前已经有一系列成功的挑战赛，如微软想象杯、谷歌人工智能挑战赛、ImageNet挑战赛和Netflix奖等等。可以说，这些挑战\n（如ImageNet挑战）\n促进了当今的人工智能的繁荣。同样地，在系统生物学和医学领域，也有一个很好的挑战赛榜样，即梦想挑战赛\n（DREAM challenges）\n。该比赛提供高质量的生物医学标准数据集，邀请参与者针对指定问题提出解决方案，促进交流并在此过程中建立合作团体。网络控制领域的研究人员也可以从其他领域现有的挑战平台中学习，以进一步推进领域前沿，让“群众的智慧”发挥对出最大的科学效益。\n由于控制复杂系统具有多学科性质，挑战不必集中在纯理论问题上，也可以是应用甚至是转化。\n例如，有人试图对定向人类蛋白质相互作用网络进行结构可控性分析，以鉴定疾病基因和药物靶点[184]，虽然这方面的研究还有待进一步深入。此外，为了设计更好地操纵人类肠道微生物组的方法，控制理论也能有许多潜在的应用\n（人类内部生态系统由数万亿微生物组成，相互作用方式很复杂）\n[185]。譬如，在该领域中一个非常实际的控制问题是设计明确定义的活聚生体组\n（consortium of live microorganisms）（通常叫做益生菌混合物、细菌，即药物或活生物治疗产品）\n以防止某些病原体寄身，从而预防感染[186]。此外，标准测试方法\n（benchmarking methods）\n还可以用于保护和控制微型电网\n（microgrids，即具有确定电边界的本地电网，充当单个和可控的实体）\n[187]。\n总之，我们的最终目标是将来自不同科学技术领域的工具和技术结合起来，解决在不同尺度上闭合控制回路的关键问题，从而协调大规模复杂系统的集体行为，这将会对大量交叉学科的应用产生极大影响。\n参考文献\nNational Research Council. Network Science (The National Academies Press, 2005).\nNewman, M. E. J. Networks: An Introduction (Oxford Univ. Press, 2018).\nLiu, Y.-Y., Slotine, J.-J. & Barabási, A.-L. Controllability of complex networks. Nature 473,\n167–173 (2011).\nLin, C.-T. Structural controllability. IEEE Trans. Autom. Control. 19, 201 (1974).\nLiu, Y. Y., Csoka, E., Zhou, H. & Posfai, M. Core percolation on complex networks.\nPhys. Rev. Lett. 109, 205703 (2012).\nJia, T. et al. Emergence of bimodality in controlling complex networks. Nat. Commun. 4,\n2002 (2013).\nSun, J. & Motter, A. E. Controllability transition and nonlocality in network control.\nPhys. Rev. Lett. 110, 208701 (2013).\nYan, G., Ren, J., Lai, Y.-C., Lai, C.-H. & Li, B. Controlling complex networks — how much\nenergy is needed? Phys. Rev. Lett. 108, 218703 (2012).\nRuths, J. & Ruths, D. Control profiles of complex networks. Science 343, 1373–1376\n(2014).\nMotter, A. E. Networkcontrology. Chaos 25, 097621 (2015).\nLiu, Y.-Y. & Barabási, A.-L. Control principles of complex systems. Rev. Mod. Phys. 88,\n053006 (2016).\nXiang, L., Chen, F., Ren, W. & Chen, G. Advances in network controllability. IEEE Circuits\nSyst. Mag. 19, 8–32 (2019).\nBechhoefer, J. Control Theory for Physicists (Cambridge Univ. Press, 2021).\nÅström, K. J. & Murray, R. M. Feedback Systems: An Introduction for Scientists and\nEngineers 2nd edn (Princeton Univ. Press, 2021).\nKhalil, H. K. Nonlinear Systems (Prentice Hall, 2002).\nSiljak, D. D. Large-scale Dynamic Systems: Stability and Structure (North-Holland, 1978).\nBullo, F. Lectures on Network Systems 1.6 edn (Kindle Direct Publishing, 2022).\nLi, X., Wang, X. & Chen, G. Pinning a complex dynamical network to its equilibrium.\nIEEE Trans. Circuits Syst. 51, 2074–2087 (2004).\nWang, X. & Chen, G. Pinning control of scale-free dynamical networks. Phys. A Stat.\nMech. Appl. 310, 521–531 (2002).\nSorrentino, F., di Bernardo, M., Garofalo, F. & Chen, G. Controllability of complex\nnetworks via pinning. Phys. Rev. E 75, 046103 (2007).\nSu, H. & Wang, X. Pinning Control of Complex Networked Systems 1st edn (Springer, 2013).\nMoreau, L. Stability of multiagent systems with time-dependent communication links.\nIEEE Trans. Autom. Control 50, 169–182 (2005).\nCisneros-Velarde, P., Jafarpour, S. & Bullo, F. Contraction theory for dynamical systems on\nHilbert spaces. IEEE Trans. Autom. Control 67, 6710–6715 (2021).\nMurray, R. M. Control in an Information Rich World (Society for Industrial and Applied\nMathematics, 2003).\nLamnabhi-Lagarrigue, F. et al. Systems and control for the future of humanity, research\nagenda: current and future roles, impact and grand challenges. Annu. Rev. Control 43,\n1–64 (2017).\nMatheny Matthew, H. et al. Exotic states in a simple network of nanoelectromechanical\noscillators. Science 363, eaav7932 (2019).\nSalova, A. & D’Souza, R. M. Decoupled synchronized states in networks of linearly\ncoupled limit cycle oscillators. Phys. Rev. Res. 2, 043261 (2020).\nAlbert, R. & Barabási, A.-L. Statistical mechanics of complex networks. Rev. Mod. Phys.\n74, 47–97 (2002).\nDorogovtsev, S. N., Goltsev, A. V. & Mendes, J. F. F. Critical phenomena in complex\nnetworks. Rev. Mod. Phys. 80, 1275 (2008).\nBarabási, A.-L. & Albert, R. Emergence of scaling in random networks. Science 286,\n509–512 (1999).\nAlbert, R. & Barabási, A.-L. Topology of evolving networks: local events and universality.\nPhys. Rev. Lett. 85, 5234–5237 (2000).\nDorogovtsev, S. N., Mendes, J. F. F. & Samukhin, A. N. Structure of growing networks with\npreferential linking. Phys. Rev. Lett. 85, 4633–4636 (2000).\nKrapivsky, P. L., Redner, S. & Leyvraz, F. Connectivity of growing random networks.\nPhys. Rev. Lett. 85, 4629–4632 (2000).\nStanley, H. E. Introduction to Phase Transitions and Critical Phenomena (Oxford Univ.\nPress, 1971).\nErdős, P. & Rényi, A. On the evolution of random graphs. Publ. Math. Inst. Hungarian\nAcad. Sci. 5, 17–61 (1960).\nNewman, M. E. J., Strogatz, S. H. & Watts, D. J. Random graphs with arbitrary degree\ndistributions and their applications. Phys. Rev. E 64, 026118 (2001).\nCallaway, D. S., Newman, M. E. J., Strogatz, S. H. & Watts, D. J. Network robustness and\nfragility: percolation on random graphs. Phys. Rev. Lett. 85, 5468–5471 (2000).\nAchlioptas, D., D’Souza, R. M. & Spencer, J. Explosive percolation in random networks.\nScience 323, 1453–1455 (2009).\nD’Souza, R. M., Gómez-Gardeñes, J., Nagler, J. & Arenas, A. Explosive phenomena in\ncomplex networks. Adv. Phys. 68, 123–223 (2019).\nScheffer, M. et al. Early-warning signals for critical transitions. Nature 461, 53–59 (2009).\nBoettiger, C. & Hastings, A. Quantifying limits to detection of early warning for critical\ntransitions. J. R. Soc. Interface 9, 2527–2539 (2012).\nBak, P., Tang, C. & Wiesenfeld, K. Self-organized criticality: an explanation of the 1/f noise.\nPhys. Rev. Lett. 59, 381–384 (1987).\nD’Souza, R. M. Curtailing cascading failures. Science 358, 860–861 (2017).\nCajueiro, D. O. & Andrade, R. F. Controlling self-organized criticality in sandpile models.\nPhys. Rev. E 81, 015102 (2010).\nCajueiro, D. O. & Andrade, R. F. Dynamical programming approach for controlling the\ndirected Abelian Dhar–Ramaswamy model. Phys. Rev. E 82, 031108 (2010).\nNoël, P.-A., Brummitt, C. D. & D’Souza, R. M. Controlling self-organizing dynamics on\nnetworks using models that self-organize. Phys. Rev. Lett. 111, 078701 (2013).\nQi, J. & Pfenninger, S. Controlling the self-organizing dynamics in a sandpile model on\ncomplex networks by failure tolerance. EPL 111, 38006 (2015).\nSornette, D. Dragon-kings, black swans and the prediction of crises. CCSS Working\nPaper No. CCSS-09-005 (2009).\nCavalcante, H. L., Oria, M., Sornette, D., Ott, E. & Gauthier, D. J. Predictability and\nsuppression of extreme events in a chaotic system. Phys. Rev. Lett. 111, 198701 (2013).\nLin, Y., Burghardt, K., Rohden, M., Noël, P.-A. & D’Souza, R. M. Self-organization of dragon\nking failures. Phys. Rev. E 98, 022127 (2018).\nMikaberidze, G. & D’Souza, R. M. Sandpile cascades on oscillator networks: the BTW\nmodel meets Kuramoto. Chaos 32, 053121 (2022).\nYamada, T. & Foulds, L. R. A graph-theoretic approach to investigate structural and\nqualitative properties of systems: a survey. Networks 20, 427 (1990).\nCommault, C., Dion, J. M. & Van Der Woude, J. W. Characterization of generic\nproperties of linear structured systems for efficient computations. Kybernetika 38,\n503–520 (2002).\nMurota, K. Matrices and Matroids for Systems Analysis (Springer, 2009).\nMézard, M. & Parisi, G. The Bethe lattice spin glass revisited. Eur. Phys. J. B 20, 217 (2001)\nMézard, M. & Parisi, G. The cavity method at zero temperature. J. Stat. Phys. https://doi.org/\n10.1023/A:1022221005097 (2003).\nMezard, M., Parisi, G. & Virasoro, M. Spin Glass Theory and Beyond Vol. 9 (World Scientific,\n1986).\nZdeborová, L. & Mézard, M. The number of matchings in random graphs. J. Stat. Mech.\nTheory Exp. 05, P05003 (2006).\nYang, Y., Wang, J. & Motter, A. Network observability transitions. Phys. Rev. Lett. 109,\n258701 (2012).\nZhao, J.-H, Habibulla, Y. & Zhou, H.-J. Statistical mechanics of the minimum dominating\nset problem. J. Stat. Phys. 159, 1154–1174 (2015).\nWigner, E. P. Random matrices in physics. SIAM Rev. 9, 1–23 (1967).\nGates, A. J. & Rocha, L. M. Control of complex networks requires both structure and\ndynamics. Sci. Rep. 6, 24456 (2016).\nOlfati-Saber, R. & Murray, R. M. Consensus problems in networks of agents with switching\ntopology and time-delays. IEEE Trans. Autom. Control. 49, 1520–1533 (2004).\nPaley, D. A., Leonard, N. E., Sepulchre, R., Grunbaum, D. & Parrish, J. K. Oscillator models\nand collective motion. IEEE Control. Syst. Mag. 27, 89–105 (2007).\nJadbabaie, A., Lin, J. & Morse, A. S. Coordination of groups of mobile autonomous agents\nusing nearest neighbor rules. IEEE Trans. Autom. Control. 48, 988–1001 (2003).\nTanner, H. G., Jadbabaie, A. & Pappas, G. J. Flocking in fixed and switching networks.\nIEEE Trans. Autom. Control. 52, 863–868 (2007).\nLeonard, N. E. & Fiorelli, E. Proc. 40th IEEE Conference on Decision and Control\n(Cat. No.01CH37228) (IEEE, 2001).\nOlfati-Saber, R. Flocking for multi-agent dynamic systems: algorithms and theory.\nIEEE Trans. Autom. Control 51, 401–420 (2006).\nOlfati-Saber, R., Fax, J. A. & Murray, R. M. Consensus and cooperation in networked\nmulti-agent systems. Proc. IEEE 95, 215–233 (2007).\nWei, R. & Beard, R. W. Consensus seeking in multiagent systems under dynamically\nchanging interaction topologies. IEEE Trans. Autom. Control 50, 655–661 (2005).\nSepulchre, R. Consensus on nonlinear spaces. Annu. Rev. Control 35, 56–64 (2011).\nDeLellis, P., diBernardo, M. & Garofalo, F. Novel decentralized adaptive strategies for the\nsynchronization of complex networks. Automatica 45, 1312–1318 (2009).\nDorfler, F., Chertkov, M. & Bullo, F. Synchronization in complex oscillator networks and\nsmart grids. Proc. Natl Acad. Sci. USA 110, 2005–2010 (2013).\nScardovi, L. & Sepulchre, R. 2008 47th IEEE Conference on Decision and Control 546–551\n(IEEE, 2008).\nWieland, P., Sepulchre, R. & Allgöwer, F. An internal model principle is necessary and\nsufficient for linear output synchronization. Automatica 47, 1068–1074 (2011).\nAndrea, R. D. & Dullerud, G. E. Distributed control design for spatially interconnected\nsystems. IEEE Trans. Autom. Control 48, 1478–1495 (2003).\nBullo, F., Cortés, J. & Martínez, S. Distributed Control of Robotic Networks: A Mathematical\nApproach to Motion Coordination Algorithms (Princeton Univ. Press, 2009).\nShamma, J. S. (ed.) Cooperative Control of Distributed Multi-agent Systems (John Wiley\n& Sons, Ltd, 2007).\nOh, K.-K., Park, M.-C. & Ahn, H.-S. A survey of multi-agent formation control. Automatica\n53, 424–440 (2015).\nKumar, V., Leonard, N. & Morse, A. S. Cooperative Control (Springer Berlin, 2005).\nPorfiri, M. & di Bernardo, M. Criteria for global pinning-controllability of complex\nnetworks. Automatica 44, 3100–3106 (2008).\nMesbahi, M. & Egerstedt, M. Graph Theoretic Methods in Multiagent Networks (Princeton\nUniv. Press, 2010).\nMesbahi, M. On state-dependent dynamic graphs and their controllability properties.\nIEEE Trans. Autom. Control 50, 387–392 (2005).\nRahmani, A., Ji, M., Mesbahi, M. & Egerstedt, M. Controllability of multi-agent systems\nfrom a graph-theoretic perspective. SIAM J. Control Optim. 48, 162–186 (2009).\nPasqualetti, F., Zampieri, S. & Bullo, F. Controllability metrics, limitations and algorithms\nfor complex networks. IEEE Trans. Control Netw. Syst. 1, 40–52 (2014).\nBianchin, G., Frasca, P., Gasparri, A. & Pasqualetti, F. The observability radius of networks.\nIEEE Trans. Autom. Control 62, 3006–3013 (2017).\nLiu, Y.-Y., Slotine, J.-J. & Barabási, A.-L. Observability of complex systems. Proc. Natl Acad.\nSci. USA 110, 2460–2465 (2013).\nSundaram, S. & Hadjicostis, C. N. Structural controllability and observability of linear\nsystems over finite fields with applications to multi-agent systems. IEEE Trans. Autom.\nControl 58, 60–73 (2013).\nHarary, F., Norman, R. Z. & Cartwright, D. Structural Models: An Introduction to the Theory\nof Directed Graphs (John Wiley & Sons, 1965).\nXiang, J. & Chen, G. On the V-stability of complex dynamical networks. Automatica 43,\n1049–1057 (2007).\nArcak, M. Passivity as a design tool for group coordination. IEEE Trans. Autom. Control 52,\n1380–1390 (2007).\nSlotine, J.-J. E. & Wang, W. in Cooperative Control: A Post-Workshop Volume 2003 Block\nIsland Workshop on Cooperative Control (eds Kumar, V., Leonard, N. & Morse, A. S.)\n207–228 (Springer, 2005).\nForni, F. & Sepulchre, R. A differential Lyapunov framework for contraction analysis.\nIEEE Trans. Autom. Control 59, 614–628 (2014).\nMoylan, P. & Hill, D. Stability criteria for large-scale systems. IEEE Trans. Autom. Control\n23, 143–149 (1978).\ndi Bernardo, M., Fiore, D., Russo, G. & Scafuti, F. in Complex Systems and Networks: Dynamics,\nControls and Applications (eds Lü, J., Yu, X., Chen, G. & Yu, W.) 313–339 (Springer, 2016).\nPecora, L. M. & Carroll, T. L. Master stability functions for synchronized coupled systems.\nPhys. Rev. Lett. 80, 2109–2112 (1998).\nBaggio, G., Bassett, D. S. & Pasqualetti, F. Data-driven control of complex networks.\nNat. Commun. 12, 1429 (2021).\nNguyen, T. T., Nguyen, N. D. & Nahavandi, S. Deep reinforcement learning for multiagent\nsystems: a review of challenges, solutions, and applications. IEEE Trans. Cybern. 50,\n3826–3839 (2020).\nBattistelli, G. & Chisci, L. Kullback–Leibler average, consensus on probability densities,\nand distributed state estimation with guaranteed stability. Automatica 50, 707–718\n(2014).\nDibaji, S. M., Ishii, H. & Tempo, R. Resilient randomized quantized consensus. IEEE Trans.\nAutom. Control 63, 2508–2522 (2018).\nFiore, D. & Russo, G. Resilient consensus for multi-agent systems subject to differential\nprivacy requirements. Automatica 106, 18–26 (2019).\nNozari, E., Tallapragada, P. & Cortés, J. Differentially private distributed convex optimization\nvia functional perturbation. IEEE Trans. Control Netw. Syst. 5, 395–408 (2018).\nMo, Y. & Murray, R. M. Privacy preserving average consensus. IEEE Trans. Autom. Control\n62, 753–765 (2017).\nXie, S., Russo, G. & Middleton, R. H. Scalability in nonlinear network systems affected by\ndelays and disturbances. IEEE Trans. Control Netw. Syst. 8, 1128–1138 (2021).\nStüdli, S., Seron, M. M. & Middleton, R. H. From vehicular platoons to general networked\nsystems: string stability and related concepts. Annu. Rev. Control 44, 157–172 (2017).\nRusso, G., Wirth, F. & Shorten, R. On synchronization in continuous-time networks of\nnonlinear nodes with state-dependent and degenerate noise diffusion. IEEE Trans.\nAutom. Control 64, 389–395 (2019).\nLi, T., Wu, F. & Zhang, J. Multi-agent consensus with relative-state-dependent\nmeasurement noises. IEEE Trans. Autom. Control 59, 2463–2468 (2014).\nBurbano-L, D. A., Russo, G. & Bernardo, M. D. Pinning controllability of complex network\nsystems with noise. IEEE Trans. Control Netw. Syst. 6, 874–883 (2019).\nDella Rossa, F. & De Lellis, P. Synchronization and pinning control of stochastic coevolving\nnetworks. Annu. Rev. Control 53, 147–160 (2022).\nOtt, E., Grebogi, C. & Yorke, J. A. Controlling chaos. Phys. Rev. Lett. 64, 1196–1199 (1990).\nDitto, W. L., Rauseo, S. N. & Spano, M. L. Experimental control of chaos. Phys. Rev. Lett.\n65, 3211–3214 (1990).\nShinbrot, T., Grebogi, C., Ott, E. & Yorke, J. A. Using small perturbations to control chaos.\nNature 363, 411 (1993).\nBoccaletti, S., Grebogi, C., Lai, Y.-C., Mancini, H. & Maza, D. The control of chaos: theory\nand applications. Phys. Rep. 329, 103–197 (2000).\nCornelius, S. P., Kath, W. L. & Motter, A. E. Realistic control of network dynamics.\nNat. Commun. 4, 1942 (2013).\nBick, C. & Martens, E. A. Controlling chimeras. New J. Phys. 17, 033030 (2015).\nKuramoto, Y. & Davaasambuu, B. Coexistence of coherence and incoherence in nonlocally\ncoupled phase oscillators. Nonlin. Phenom. Complex Syst. 5, 380–385 (2002).\nAbrams, D. M. & Strogatz, S. H. Chimera states for coupled oscillators. Phys. Rev. Lett. 93,\n174102 (2004).\nSieber, J., Omel’chenko, O. E. & Wolfrum, M. Controlling unstable chaos: stabilizing\nchimera states by feedback. Phys. Rev. Lett. 112, 054102 (2014).\nGjurchinovski, A., Scholl, E. & Zakharova, A. Control of amplitude chimeras by time delay\nin oscillator networks. Phys. Rev. E 95, 042218 (2017).\nZakharova, A., Semenova, N., Anishchenko, V. & Schöll, E. Time-delayed feedback control\nof coherence resonance chimeras. Chaos 27, 114320 (2017).\nGambuzza, L. V. & Frasca, M. Pinning control of chimera states. Phys. Rev. E 94, 022306\n(2016).\nSemenov, V., Zakharova, A., Maistrenko, Y. & Schöll, E. Delayed-feedback chimera states:\nforced multiclusters and stochastic resonance. EPL 115, 10005 (2016).\nBera, B. K., Majhi, S., Ghosh, D. & Perc, M. Chimera states: effects of different coupling\ntopologies. EPL 118, 10001 (2017).\nRuzzene, G., Omelchenko, I., Schöll, E., Zakharova, A. & Andrzejak, R. G. Controlling\nchimera states via minimal coupling modification. Chaos 29, 051103 (2019).\nOmelchenko, I., Hülser, T., Zakharova, A. & Schöll, E. Control of chimera states in multilayer\nnetworks. Front. Appl. Math. Stat. 4, 00067 (2019).\nSchöll, E., Klapp, S. H. L. & Hövel, P. Control of Self-organizing Nonlinear Systems\n(Springer, 2016).\nLjung, L. System Identification: Theory for User (Prentice Hall, 1999).\nXue, Y. & Bogdan, P. Reconstructing missing complex networks against adversarial\ninterventions. Nat. Commun. 10, 1738 (2019).\nTimme, M. Revealing network connectivity from response dynamics. Phys. Rev. Lett. 98,\n224101 (2007).\nBattiston, F. et al. The physics of higher-order interactions in complex systems. Nat. Phys.\n17, 1093–1098 (2021).\nBianconi, G. Higher-Order Networks (Cambridge Univ. Press, 2021).\nGhoshal, G., Zlatic, V., Caldarelli, G. & Newman, M. E. Random hypergraphs and their\napplications. Phys. Rev. E 79, 066118 (2009).\nCourtney, O. T. & Bianconi, G. Generalized network structures: the configuration model\nand the canonical ensemble of simplicial complexes. Phys. Rev. E 93, 062311 (2016).\nLucas, M., Cencetti, G. & Battiston, F. Multiorder Laplacian for synchronization in\nhigher-order networks. Phys. Rev. Res. 2, 033410 (2020).\nGambuzza, L. V. et al. Stability of synchronization in simplicial complexes. Nat. Commun.\n12, 1255 (2021).\nFerraz de Arruda, G., Tizzani, M. & Moreno, Y. Phase transitions and stability of dynamical\nprocesses on hypergraphs. Commun. Phys. 4, 24 (2021).\nZhang, Y., Latora, V. & Motter, A. E. Unified treatment of synchronization patterns\nin generalized networks with higher-order, multilayer, and temporal interactions.\nCommun. Phys. 4, 195 (2021).\nSalova, A. & D’Souza, R. M. Cluster synchronization on hypergraphs. Preprint at https://\ndoi.org/10.48550/arXiv.2101.05464 (2021).\nChen, C., Surana, A., Bloch, A. M. & Rajapakse, I. Controllability of hypergraphs.\nIEEE Trans. Netw. Sci. Eng. 8, 1646–1657 (2021).\nPerra, N., Goncalves, B., Pastor-Satorras, R. & Vespignani, A. Activity driven modeling\nof time varying networks. Sci. Rep. 2, 469 (2012).\nLiu, S., Perra, N., Karsai, M. & Vespignani, A. Controlling contagion processes in activity\ndriven networks. Phys. Rev. Lett. 112, 118702 (2014).\nPosfai, M., Gao, J., Cornelius, S. P., Barabasi, A. L. & D’Souza, R. M. Controllability\nof multiplex, multi-time-scale networks. Phys. Rev. E 94, 032316 (2016).\nMenichetti, G., Dall’Asta, L. & Bianconi, G. Control of multilayer networks. Sci. Rep. 6,\n20706 (2016).\nGonzález, A. D., Chapman, A., Dueñas-Osorio, L., Mesbahi, M. & D’Souza, R. M. Efficient\ninfrastructure restoration strategies using the recovery operator. Comput.-Aided Civ.\nInfrastruct. Eng. 32, 991–1006 (2017).\nChapman, A., González, A. D., Mesbahi, M., Dueñas-Osorio, L. & D’Souza, R. M. 2017 IEEE\n56th Annual Conference on Decision and Control (CDC) 493–498 (IEEE, 2017).\nBurbano, D. & di Bernardo, M. Multiplex PI control for consensus in networks of\nheterogeneous linear agents. Automatica 67, 310–320 (2016).\nAnnby-Andersson, B., Samuelsson, P., Maisi, V. F. & Potts, P. P. Maxwell’s demon in a\ndouble quantum dot with continuous charge detection. Phys. Rev. B 101, 165404 (2020).\nBhattacharyya, D. & Jarzynski, C. From a feedback-controlled demon to an information\nratchet in a double quantum dot. Phys. Rev. E 106, 064101 (2022).\nKardar, M., Parisi, G. & Zhang, Y. C. Dynamic scaling of growing interfaces. Phys. Rev. Lett.\n56, 889–892 (1986).\nSpitzer, F. Interaction of Markov processes. Adv. Math. 5, 246–290 (1970).\nAngulo, M. T., Moog, C. H. & Liu, Y.-Y. A theoretical framework for controlling complex\nmicrobial communities. Nat. Commun. 10, 1045 (2019).\nAngulo, M. T., Aparicio, A. & Moog, C. H. Structural accessibility and structural observability\nof nonlinear networked systems. IEEE Trans. Netw. Sci. Eng. 7, 1656–1666 (2020).\nNikitin, D., Wit, C. C. D. & Frasca, P. A continuation method for large-scale modeling and\ncontrol: from ODEs to PDE, a round trip. IEEE Trans. Autom. Control 67, 5118–5133 (2021).\nNikitin, D. Scalable Large-scale Control of Network Aggregates (Université Grenoble\nAlpes, 2021).\nKrstic, M. & Smyshlyaev, A. Boundary Control of PDEs (SIAM Press, 2008).\nSmyshlyaev, A. & Krstic, M. Adaptive Control of Parabolic PDEs (Princeton Univ. Press,\n2010).\nMaffettone, G., Boldini, A., di Bernardo, M. & Porfiri, M. Continuification control of\nlarge-scale multiagent systems in a ring. IEEE Control Syst. Lett. 7, 841–846 (2023).\nGao, S. & Caines, P. E. Graphon control of large-scale networks of linear systems.\nIEEE Trans. Autom. Control 65, 4090–4105 (2020).\nBorgs, C. & Chayes, J. Proceedings of the 2017 ACM Conference on Economics and\nComputation 665–672 (Association for Computing Machinery, 2017).\nLovász, L. Large Networks and Graph Limits Vol. 60 (American Mathematical Society, 2012).\nBorgs, C., Chayes, J. T., Lovász, L., Sós, V. T. & Vesztergombi, K. Convergent sequences\nof dense graphs I: subgraph frequencies, metric properties and testing. Adv. Math. 219,\n1801–1851 (2008).\nLovász, L. & Szegedy, B. Limits of dense graph sequences. J. Comb. Theory Ser. B 96,\n933–957 (2006).\nParise, F. & Ozdaglar, A. Graphon games: a statistical framework for network games and\ninterventions. Econometrica 91, 191–225 (2023).\nMezić, I. & Banaszuk, A. Comparison of systems with complex behavior. Phys. D Nonlin.\nPhenom. 197, 101–133 (2004).\nMezić, I. Spectral properties of dynamical systems, model reduction and decompositions.\nNonlin. Dyn. 41, 309–325 (2005).\nRowley, C. W., MeziĆ, I., Bagheri, S., Schlatter, P. & Henningson, D. S. Spectral analysis\nof nonlinear flows. J. Fluid Mech. 641, 115–127 (2009).\nBrunton, S. L., Brunton, B. W., Proctor, J. L. & Kutz, J. N. Koopman invariant subspaces and\nfinite linear representations of nonlinear dynamical systems for control. PLoS ONE 11,\ne0150171 (2016).\nKaiser, E., Kutz, J. N. & Brunton, S. L. Data-driven discovery of Koopman eigenfunctions\nfor control. Mach. Learn. Sci. Technol. 2, 035023 (2021).\nArbabi, H., Korda, M. & Mezić, I. 2018 IEEE Conference on Decision and Control (CDC)\n6409–6414 (IEEE, 2018).\nPeitz, S. Controlling nonlinear PDEs using low-dimensional bilinear approximations\nobtained from data. Preprint at https://doi.org/10.48550/arXiv.1801.06419 (2018).\nPeitz, S. & Klus, S. Koopman operator-based model reduction for switched-system\ncontrol of PDEs. Automatica 106, 184–191 (2019).\nArbabi, H. Koopman Spectral Analysis and Study of Mixing in Incompressible Flows. PhD\nthesis, University of California (2017).\nBrunton, S. L., Budišić, M., Kaiser, E. & Kutz, J. N. Modern Koopman theory for dynamical\nsystems. SIAM Rev. 64, 229–340 (2022).\nMauroy, A., Mezić, I. & Susuki, Y. The Koopman Operator in Systems and Control (Springer,\n2020).\nBrunton, S. L., Proctor, J. L. & Kutz, J. N. Discovering governing equations from data by\nsparse identification of nonlinear dynamical systems. Proc. Natl Acad. Sci. USA 113,\n3932–3937 (2016).\nKaiser, E., Kutz, J. N. & Brunton, S. L. Sparse identification of nonlinear dynamics for model\npredictive control in the low-data limit. Proc. R. Soc. A Math. Phys. Eng. Sci. 474, 0335 (2018).\nMorrison, M. & Kutz, J. N. Nonlinear control of networked dynamical systems. IEEE Trans.\nNetw. Sci. Eng. 8, 174–189 (2021).\nHüttenrauch, M., Šošić, A. & Neumann, G. Deep reinforcement learning for swarm\nsystems. J. Mach. Learn. Res. 20, 1966–1996 (2019).\nGarrabé, É. & Russo, G. Probabilistic design of optimal sequential decision-making\nalgorithms in learning and control. Annu. Rev. Control. 54, 81–102 (2022).\nHewing, L., Wabersich, K. P., Menner, M. & Zeilinger, M. N. Learning-based model\npredictive control: toward safe learning in control. Annu. Rev. Control Robot. Auton. Syst.\n3, 269–296 (2020).\nKempton, L. C., Herrmann, G. & di Bernardo, M. Distributed optimisation and control of\ngraph Laplacian eigenvalues for robust consensus via an adaptive multilayer strategy.\nInt. J. Robust. Nonlin. Control 27, 1499–1525 (2017).\nFornasier, M. & Solombrino, F. Mean-field optimal control. ESAIM: COCV 20, 1123–1152\n(2014).\nSepulchre, R. Spiking control systems. Proc. IEEE 110, 577–589 (2022).\nVinayagam, A. et al. Controllability analysis of the directed human protein interaction\nnetwork identifies disease genes and drug targets. Proc. Natl Acad. Sci. USA 113,\n4976–4981 (2016).\nGilbert, J. A. et al. Current understanding of the human microbiome. Nat. Med. 24,\n392–400 (2018).\nXiao, Y., Angulo, M. T., Lao, S., Weiss, S. T. & Liu, Y.-Y. An ecological framework to\nunderstand the efficacy of fecal microbiota transplantation. Nat. Commun. 11, 3329\n(2020).\nAltin, N. & Eyimaya, S. E. 2021 10th International Conference on Renewable Energy\nResearch and Application (ICRERA) 412–417 (IEEE, 2021).\nWatts, D. J. A simple model of global cascades on random networks. Proc. Natl Acad.\nSci. USA 99, 5766–5771 (2002).\nArcak, M., Meissen, C. & Packard, A. Networks of Dissipative Systems: Compositional\nCertification of Stability, Performance, and Safety (Springer, 2016).\nBullo, F. Contraction Theory for Dynamical Systems 1.0 edn (Kindle Direct Publishing, 2022).\nLohmiller, W. & Slotine, J.-J. E. On contraction analysis for nonlinear systems. Automatica\n34, 683–696 (1998).\nMarden, J. R. & Shamma, J. S. Game theory and control. Annu. Rev. Control Robot.\nAuton. Syst. 1, 105–134 (2018).\nLewis, F. L., Zhang, H., Hengster-Movric, K. & Das, A. Cooperative Control of Multi-Agent\nSystems (Springer, 2014).\nGadjov, D. & Pavel, L. A passivity-based approach to nash equilibrium seeking over\nnetworks. IEEE Trans. Autom. Control 64, 1077–1092 (2019).\nSemsar-Kazerooni, E. & Khorasani, K. Multi-agent team cooperation: a game theory\napproach. Automatica 45, 2205–2213 (2009).\nGharesifard, B. & Cortés, J. Distributed convergence to Nash equilibria in two-network\nzero-sum games. Automatica 49, 1683–1692 (2013).\n（参考文献可\n上下滑动\n查看）\n系列课程推荐：统计物理基础课程\n集智学园联合上海大学理学院教授、知乎“物理学”话题优秀答主李永乐，共同推出「统计物理基础」系列课程。课程以热力学和经典力学为起点，依次展开 Boltzmann 统计、系综理论、量子统计、相变与非平衡统计等核心内容，围绕一个核心问题展开：大量微观粒子的随机运动如何涌现出稳定的宏观定律？本课程强调物理图像与方法论，帮助你建立清晰的微观—宏观统计思维，掌握处理多粒子系统和复杂随机过程的一套通用工具。\n课程详情可见：\n李永乐的统计物理基础课\n线性代数：一名合格科研人的筑基课\n在科研世界中，无论你研究的是人工智能、生物信息、网络科学，还是物理与工程，几乎所有复杂系统的建模与推理都指向同一种底层语言——线性代数。它不仅是计算公式的集合，更是一名科研人理解“结构”、刻画“变换”、判断“稳定性”、提取“信息”的基本思维框架。本课程以系统科学的视角重新解构线性代数，带你越过技巧、直达本质，在跨学科的真实问题中建立起科研必备的数学基石。集智学园联合清华大学数学博士诸葛昌靖老师推出「\n线性代数：一名合格科研人的筑基课\n」，并邀请武汉大学数学与统计学院周进教授于1月20日、1月27日就特征值与特征向量在复杂网络中的应用做特别加餐分享。\n课程已于12月20日开启，欢迎加入社群交流。\n详情请见：\n线性代数：一名合格科研人的筑基课丨新课上线\n推荐阅读\n1.\n地球系统科学中的统计物理理论\n2.\n现代物理评论：生态学的统计力学——统计物理视角下的生态中性理论\n3.\n系统观下的复杂科学：拓扑学、线性代数与统计物理的互补角色\n4.\n系统科学前沿十讲：探究复杂世界演变背后的规则（二）\n5.\n集智学园精品课程免费开放，解锁系统科学与 AI 新世界\n6.\n高考分数只是张入场券，你的科研冒险在这里启航！\n7.\n加入集智字幕组：成为复杂科学知识社区的“织网人”\n点击“阅读原文”，报名课程",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247725071&idx=2&sn=5966fe789b0fa3830d688a6d873d0a6c&chksm=e92a81fcc20fedf55014870581633529aa335d8a7e23df5b98a457735b5cd95510aca345ef94&scene=0&xtrack=1#rd",
      "publish_time": 1768266000,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.nature.com/articles/s42254-023-00566-3\", \"https://waymo.com\", \"https://highways.dot.gov/research/laboratories/saxton-transportation-operations-laboratory/Truck-Platooning\", \"https://doi.org/\", \"https://doi.org/10.48550/arXiv.1801.06419\"]",
      "add_ts": 1768346380,
      "last_modify_ts": 1768346380
    },
    {
      "id": 478,
      "article_id": "51813",
      "title": "疫苗设计新思路！耶鲁等首次挖掘「免疫」可解释结构",
      "description": "耶鲁大学等机构将免疫原性预测拓展为多模态建模，整合抗原的序列、三维结构和生化属性，显著提升表位预测的准确性与可解释性。针对癌症免疫特点，研究设计对比学习策略，有效利用稀缺数据，增强模型泛化能力。该方法为疫苗研发和个性化免疫治疗提供了新路径，推动精准医学发展。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n免疫系统通过识别抗原的特定片段（表位）来判断是否启动免疫反应，但准确预测表位的免疫原性极具挑战。耶鲁大学等将免疫原性预测拓展为多模态建模，整合序列、三维结构和生化属性，显著提升预测性能并增强可解释性。该方法还针对癌症免疫的特殊性设计对比学习策略，有效利用稀缺数据，为疫苗设计和免疫治疗提供新思路。\n当抗原进入人体或在体内产生时，免疫系统需要通过一套复杂机制判断其是否为「敌人」，并据此激活免疫反应，这一可被识别并触发反应的特性被称为\n免疫原性\n。\n然而，免疫系统并不会对所有抗原片段作出反应，它真正「看到」的往往只是少数关键片段，即表位（epitopes）。\n疫苗设计\n正是利用这一机制，试图通过人工方式呈递特定表位来诱导免疫反应。表位是否具有免疫原性并非由单一因素决定，而是一个多阶段、强依赖上下文的过程。\n因此，即便序列高度相似的表位，其免疫原性也可能截然不同，使得免疫原性的准确预测本身极具挑战。\n现有主流方法往往将抗原简化为一维氨基酸序列，并基于卷积神经网络或语言模型进行建模，这类方法在一定程度上有效，但忽略了蛋白质在三维空间中的真实结构形态以及由此产生的空间相互作用，从而在预测精度和结果可解释性上存在天然局限。\n近日，针对这些局限，耶鲁大学与霍华德·休斯医学研究所的研究团队提出\nImmunoStruct\n，其核心思想是免疫原性不仅取决于序列本身，还受到空间构型、表面暴露特性以及多种生化相互作用的共同影响，ImmunoStruct将免疫原性预测从一维序列建模拓展为\n多模态建模问题\n。\n论文链接：https://www.nature.com/articles/s42256-025-01163-y\n代码链接：https://github.com/KrishnaswamyLab/ImmunoStruct\n从「一维序列」到「多模态结构」\nImmunoStruct的核心思想\n具体而言，ImmunoStruct同时整合了三类互补信息：序列信息、由AlphaFold2预测得到的三维结构信息，以及使用物理模型从结构与序列中计算出的生化属性（图1）。\n图1：ImmunoStruct的框架概览\n模型通过变分自编码器学习紧凑而连续的序列表示，通过等变图神经网络刻画三维结构空间关系与相互作用，并通过多层感知机建模生化特征。\n在此基础上，它采用多模态注意力机制对不同模态的信息进行协同融合，使模型能够根据具体样本动态关注对免疫原性最具判别力的结构、序列或生化特征。\n这种从「序列」走向「结构–序列–生化属性」联合建模的策略，使ImmunoStruct不仅在预测性能上显著优于现有方法，也首次实现了对免疫原性结构决定因素的可解释建模，为表位疫苗设计中免疫原性筛选提供了更符合生物学机制的计算框架。\n另外，针对癌症免疫数据稀缺、有效免疫信号更难获取的问题，研究团队进一步从癌症免疫的基本特性出发进行了建模设计。\n与感染性抗原不同，癌症相关的突变往往源自人体自身蛋白，免疫系统在发育过程中已对「正常版本」形成耐受，因此大多数突变并不会引发免疫反应；只有当突变显著改变了免疫系统「看到」的关键特征时，才可能被识别为异常并触发反应。\n基于这一差异性，ImmunoStruct引入了基于突变型与对应野生型序列的对比学习策略（图2）：当突变不具备免疫原性时，模型学习将二者在表示空间中拉近；而当突变产生免疫原性时，则学习将二者明确区分开来，从而直接围绕「突变是否带来有效变化」这一核心问题组织表示学习。\n图2：针对癌症数据的「突变型/野生型」对比学习策略\n同时，该对比目标还鼓励不同特征维度捕捉互补信息，减少表示退化，使有限的癌症免疫数据能够被更高效地利用，并显著提升下游预测性能。\n研究团队在多类免疫相关数据集上对ImmunoStruct进行了系统评估，涵盖传染病（IEDB数据集）与癌症（CEDAR数据集）的免疫原性预测任务。\n实验结果显示，相较于主要依赖序列信息的既有方法，ImmunoStruct在免疫原性预测性能上取得了稳定提升。\n图3: 在传染病数据集IEDB上的表现\n模型为什么会这么判断？\n结构层面的线索开始显现\n为了理解ImmunoStruct的预测依据，研究团队进一步分析了模型中的结构注意力机制。\n结果显示，模型并非平均利用所有输入信息，而是学会将注意力集中到少数具有判别力的空间位置。在高免疫原性样本中，注意力显著富集于抗原分子中部且更容易向外暴露的区域，而非主要承担结构锚定作用的位置（图4）。\n图4: 一些模型可解释性的分析\n进一步分析发现，这些被重点关注的位置在免疫原性样本中呈现出更高的一致性，暗示模型捕捉到的是稳定的结构特征而非偶然的序列差异。将注意力模式映射回已知的三维结构后可以看到，模型关注的区域与真实分子识别界面高度一致，为预测结果提供了直观的结构解释。\n这种结构感知能力也使ImmunoStruct能够区分极其细微的突变差异，在癌症新抗原的案例中，即便仅相差一个氨基酸，模型仍能通过捕捉局部空间构型的变化给出不同的免疫原性预测，表明其判断是建立在可解释的结构线索之上的。\n在更接近真实生物医学场景中的进一步验证\n为了检验模型在真实生物医学任务中的有效性，研究团队进一步在实验数据和临床数据上对ImmunoStruct进行了独立验证（图5）。\n图5: 一些在实验数据和临床数据上的验证结果\n在实验层面，作者针对一组来源于 SARS-CoV-2 的候选表位开展了体外免疫实验。结果显示，ImmunoStruct 在未参与实验设计的情况下，能够准确预测大多数实验测得的免疫反应，整体表现与实验结果高度一致，表明模型学到的信号具有可转移的生物学意义。\n更进一步，研究团队将ImmunoStruct应用于接受免疫治疗的癌症患者队列，并基于模型预测的免疫原性水平对患者进行分组。在无需任何再训练的情况下，ImmunoStruct的预测结果能够有效区分患者的生存期，且表现优于常用的突变负荷等指标。这表明，模型不仅能够在受控实验条件下做出合理判断，也能够在高度复杂、异质性极强的临床数据中捕捉与治疗结局相关的免疫信号，展现出潜在的临床转化价值。\n意义与展望\n总体而言，ImmunoStruct展示了一种从「一维序列建模」迈向「多模态结构感知学习」的新范式：通过联合利用序列、空间结构与生化特征，并引入可解释的注意力机制与对比学习策略，模型不仅提升了免疫原性预测性能，也揭示了哪些结构线索真正驱动模型决策。\n这一工作表明，在复杂生物问题中，将深度学习与结构信息和领域知识相结合，能够在有限数据条件下同时获得更强的泛化能力与更高的可解释性，为精准疫苗设计、蛋白功能预测以及更广泛的结构感知机器学习任务提供了可推广的思路。\n参考资料：\nhttps://www.nature.com/articles/s42256-025-01163-y\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652663855&idx=2&sn=32eb3d0b69ffc2a11c7eeabb4279b312&chksm=f0855393df8438b87ebe552cb804da52f4ea82c55ce954d0f531576644d4123100baa0ec3f3b&scene=0&xtrack=1#rd",
      "publish_time": 1768264200,
      "publish_date": "2026-01-13",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://www.nature.com/articles/s42256-025-01163-y\", \"https://github.com/KrishnaswamyLab/ImmunoStruct\"]",
      "add_ts": 1768346399,
      "last_modify_ts": 1768346399
    }
  ],
  "reported_article": [
    {
      "id": 1,
      "article_id": "aibase_aibase_24035",
      "original_id": "aibase_24035",
      "source_table": "aibase_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 2,
      "article_id": "baai_51475",
      "original_id": "51475",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 3,
      "article_id": "baai_51478",
      "original_id": "51478",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 4,
      "article_id": "baai_51473",
      "original_id": "51473",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 5,
      "article_id": "qbitai_366144",
      "original_id": "366144",
      "source_table": "qbitai_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 6,
      "article_id": "aibase_aibase_24054",
      "original_id": "aibase_24054",
      "source_table": "aibase_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 7,
      "article_id": "baai_51466",
      "original_id": "51466",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 8,
      "article_id": "aibase_aibase_24026",
      "original_id": "aibase_24026",
      "source_table": "aibase_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 9,
      "article_id": "baai_51489",
      "original_id": "51489",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 10,
      "article_id": "baai_51477",
      "original_id": "51477",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 11,
      "article_id": "baai_51472",
      "original_id": "51472",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 12,
      "article_id": "baai_51468",
      "original_id": "51468",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 13,
      "article_id": "baai_51467",
      "original_id": "51467",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 14,
      "article_id": "aibase_aibase_24042",
      "original_id": "aibase_24042",
      "source_table": "aibase_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 15,
      "article_id": "baai_51501",
      "original_id": "51501",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 16,
      "article_id": "baai_51490",
      "original_id": "51490",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 17,
      "article_id": "baai_51496",
      "original_id": "51496",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 18,
      "article_id": "baai_51485",
      "original_id": "51485",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 19,
      "article_id": "baai_51481",
      "original_id": "51481",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 20,
      "article_id": "aibase_aibase_24024",
      "original_id": "aibase_24024",
      "source_table": "aibase_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 21,
      "article_id": "baai_51495",
      "original_id": "51495",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 22,
      "article_id": "baai_51471",
      "original_id": "51471",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 23,
      "article_id": "qbitai_366165",
      "original_id": "366165",
      "source_table": "qbitai_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 24,
      "article_id": "aibase_aibase_24074",
      "original_id": "aibase_24074",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 25,
      "article_id": "aibase_aibase_24092",
      "original_id": "aibase_24092",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 26,
      "article_id": "aibase_aibase_24094",
      "original_id": "aibase_24094",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 27,
      "article_id": "qbitai_366091",
      "original_id": "366091",
      "source_table": "qbitai_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 28,
      "article_id": "aibase_aibase_24077",
      "original_id": "aibase_24077",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 29,
      "article_id": "aibase_aibase_24087",
      "original_id": "aibase_24087",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 30,
      "article_id": "baai_51503",
      "original_id": "51503",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 31,
      "article_id": "baai_51487",
      "original_id": "51487",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 32,
      "article_id": "aibase_aibase_24083",
      "original_id": "aibase_24083",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 33,
      "article_id": "baai_51505",
      "original_id": "51505",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 34,
      "article_id": "aibase_aibase_24110",
      "original_id": "aibase_24110",
      "source_table": "aibase_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 35,
      "article_id": "aibase_aibase_24128",
      "original_id": "aibase_24128",
      "source_table": "aibase_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 36,
      "article_id": "baai_51529",
      "original_id": "51529",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 37,
      "article_id": "baai_51520",
      "original_id": "51520",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 38,
      "article_id": "aibase_aibase_24106",
      "original_id": "aibase_24106",
      "source_table": "aibase_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 39,
      "article_id": "qbitai_366239",
      "original_id": "366239",
      "source_table": "qbitai_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 40,
      "article_id": "aibase_aibase_24132",
      "original_id": "aibase_24132",
      "source_table": "aibase_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 41,
      "article_id": "baai_51511",
      "original_id": "51511",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 42,
      "article_id": "baai_51512",
      "original_id": "51512",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 43,
      "article_id": "baai_51508",
      "original_id": "51508",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 44,
      "article_id": "baai_51521",
      "original_id": "51521",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 45,
      "article_id": "qbitai_366357",
      "original_id": "366357",
      "source_table": "qbitai_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 46,
      "article_id": "aibase_aibase_24167",
      "original_id": "aibase_24167",
      "source_table": "aibase_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 47,
      "article_id": "baai_51558",
      "original_id": "51558",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 48,
      "article_id": "baai_51540",
      "original_id": "51540",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 49,
      "article_id": "qbitai_366290",
      "original_id": "366290",
      "source_table": "qbitai_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 50,
      "article_id": "aibase_aibase_24146",
      "original_id": "aibase_24146",
      "source_table": "aibase_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 51,
      "article_id": "baai_51533",
      "original_id": "51533",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 52,
      "article_id": "baai_51548",
      "original_id": "51548",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 53,
      "article_id": "baai_51544",
      "original_id": "51544",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 54,
      "article_id": "baai_51556",
      "original_id": "51556",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 55,
      "article_id": "baai_51537",
      "original_id": "51537",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 56,
      "article_id": "baai_51550",
      "original_id": "51550",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 57,
      "article_id": "baai_51514",
      "original_id": "51514",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 58,
      "article_id": "qbitai_366295",
      "original_id": "366295",
      "source_table": "qbitai_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 59,
      "article_id": "qbitai_366280",
      "original_id": "366280",
      "source_table": "qbitai_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 60,
      "article_id": "aibase_aibase_24159",
      "original_id": "aibase_24159",
      "source_table": "aibase_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 61,
      "article_id": "aibase_aibase_24169",
      "original_id": "aibase_24169",
      "source_table": "aibase_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 62,
      "article_id": "aibase_aibase_24157",
      "original_id": "aibase_24157",
      "source_table": "aibase_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 63,
      "article_id": "baai_51575",
      "original_id": "51575",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 64,
      "article_id": "baai_51568",
      "original_id": "51568",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 65,
      "article_id": "baai_51574",
      "original_id": "51574",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 66,
      "article_id": "baai_51591",
      "original_id": "51591",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 67,
      "article_id": "baai_51589",
      "original_id": "51589",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 68,
      "article_id": "baai_51579",
      "original_id": "51579",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 69,
      "article_id": "baai_51564",
      "original_id": "51564",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 70,
      "article_id": "qbitai_366378",
      "original_id": "366378",
      "source_table": "qbitai_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 71,
      "article_id": "baai_51567",
      "original_id": "51567",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 72,
      "article_id": "baai_51584",
      "original_id": "51584",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 73,
      "article_id": "baai_51573",
      "original_id": "51573",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 74,
      "article_id": "baai_51581",
      "original_id": "51581",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 75,
      "article_id": "baai_51604",
      "original_id": "51604",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    },
    {
      "id": 76,
      "article_id": "baai_51593",
      "original_id": "51593",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    },
    {
      "id": 77,
      "article_id": "baai_51601",
      "original_id": "51601",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    },
    {
      "id": 78,
      "article_id": "baai_51594",
      "original_id": "51594",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    },
    {
      "id": 79,
      "article_id": "baai_51600",
      "original_id": "51600",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    },
    {
      "id": 80,
      "article_id": "baai_51602",
      "original_id": "51602",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    },
    {
      "id": 81,
      "article_id": "qbitai_366466",
      "original_id": "366466",
      "source_table": "qbitai_article",
      "report_generated_at": 1767482443,
      "report_file_path": "final_reports/AI_Report_2026-01-04_072043.md"
    },
    {
      "id": 82,
      "article_id": "baai_51606",
      "original_id": "51606",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767482443,
      "report_file_path": "final_reports/AI_Report_2026-01-04_072043.md"
    },
    {
      "id": 83,
      "article_id": "baai_51590",
      "original_id": "51590",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767482443,
      "report_file_path": "final_reports/AI_Report_2026-01-04_072043.md"
    },
    {
      "id": 84,
      "article_id": "baai_51619",
      "original_id": "51619",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 85,
      "article_id": "baai_51614",
      "original_id": "51614",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 86,
      "article_id": "baai_51613",
      "original_id": "51613",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 87,
      "article_id": "baai_51618",
      "original_id": "51618",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 88,
      "article_id": "baai_51607",
      "original_id": "51607",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 89,
      "article_id": "baai_51609",
      "original_id": "51609",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 90,
      "article_id": "baai_51623",
      "original_id": "51623",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 91,
      "article_id": "aibase_aibase_24190",
      "original_id": "aibase_24190",
      "source_table": "aibase_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 92,
      "article_id": "baai_51629",
      "original_id": "51629",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 93,
      "article_id": "baai_51626",
      "original_id": "51626",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 94,
      "article_id": "baai_51624",
      "original_id": "51624",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 95,
      "article_id": "baai_51608",
      "original_id": "51608",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 96,
      "article_id": "aibase_aibase_24212",
      "original_id": "aibase_24212",
      "source_table": "aibase_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 97,
      "article_id": "qbitai_366524",
      "original_id": "366524",
      "source_table": "qbitai_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 98,
      "article_id": "aibase_aibase_24199",
      "original_id": "aibase_24199",
      "source_table": "aibase_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 99,
      "article_id": "aibase_aibase_24202",
      "original_id": "aibase_24202",
      "source_table": "aibase_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 100,
      "article_id": "baai_51627",
      "original_id": "51627",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767569248,
      "report_file_path": "final_reports/AI_Report_2026-01-05_072728.md"
    },
    {
      "id": 101,
      "article_id": "qbitai_366544",
      "original_id": "366544",
      "source_table": "qbitai_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 102,
      "article_id": "baai_51653",
      "original_id": "51653",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 103,
      "article_id": "baai_51644",
      "original_id": "51644",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 104,
      "article_id": "baai_51632",
      "original_id": "51632",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 105,
      "article_id": "baai_51620",
      "original_id": "51620",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 106,
      "article_id": "aibase_aibase_24235",
      "original_id": "aibase_24235",
      "source_table": "aibase_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 107,
      "article_id": "aibase_aibase_24255",
      "original_id": "aibase_24255",
      "source_table": "aibase_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 108,
      "article_id": "baai_51628",
      "original_id": "51628",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 109,
      "article_id": "qbitai_366547",
      "original_id": "366547",
      "source_table": "qbitai_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 110,
      "article_id": "baai_51660",
      "original_id": "51660",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 111,
      "article_id": "baai_51652",
      "original_id": "51652",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 112,
      "article_id": "baai_51651",
      "original_id": "51651",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 113,
      "article_id": "baai_51642",
      "original_id": "51642",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 114,
      "article_id": "baai_51633",
      "original_id": "51633",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 115,
      "article_id": "baai_51638",
      "original_id": "51638",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 116,
      "article_id": "aibase_aibase_24253",
      "original_id": "aibase_24253",
      "source_table": "aibase_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 117,
      "article_id": "aibase_aibase_24259",
      "original_id": "aibase_24259",
      "source_table": "aibase_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 118,
      "article_id": "baai_51657",
      "original_id": "51657",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 119,
      "article_id": "baai_51658",
      "original_id": "51658",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 120,
      "article_id": "baai_51656",
      "original_id": "51656",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 121,
      "article_id": "aibase_aibase_24232",
      "original_id": "aibase_24232",
      "source_table": "aibase_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 122,
      "article_id": "aibase_aibase_24249",
      "original_id": "aibase_24249",
      "source_table": "aibase_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 123,
      "article_id": "aibase_aibase_24258",
      "original_id": "aibase_24258",
      "source_table": "aibase_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 124,
      "article_id": "baai_51635",
      "original_id": "51635",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 125,
      "article_id": "baai_51621",
      "original_id": "51621",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 126,
      "article_id": "baai_51610",
      "original_id": "51610",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767655916,
      "report_file_path": "final_reports/AI_Report_2026-01-06_073156.md"
    },
    {
      "id": 127,
      "article_id": "baai_51683",
      "original_id": "51683",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 128,
      "article_id": "baai_51648",
      "original_id": "51648",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 129,
      "article_id": "aibase_aibase_24311",
      "original_id": "aibase_24311",
      "source_table": "aibase_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 130,
      "article_id": "baai_51671",
      "original_id": "51671",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 131,
      "article_id": "baai_51640",
      "original_id": "51640",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 132,
      "article_id": "aibase_aibase_24303",
      "original_id": "aibase_24303",
      "source_table": "aibase_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 133,
      "article_id": "baai_51670",
      "original_id": "51670",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 134,
      "article_id": "aibase_aibase_24310",
      "original_id": "aibase_24310",
      "source_table": "aibase_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 135,
      "article_id": "baai_51674",
      "original_id": "51674",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 136,
      "article_id": "baai_51684",
      "original_id": "51684",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 137,
      "article_id": "baai_51679",
      "original_id": "51679",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 138,
      "article_id": "baai_51677",
      "original_id": "51677",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 139,
      "article_id": "baai_51678",
      "original_id": "51678",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 140,
      "article_id": "baai_51668",
      "original_id": "51668",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 141,
      "article_id": "qbitai_366636",
      "original_id": "366636",
      "source_table": "qbitai_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 142,
      "article_id": "qbitai_367091",
      "original_id": "367091",
      "source_table": "qbitai_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 143,
      "article_id": "baai_51676",
      "original_id": "51676",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 144,
      "article_id": "aibase_aibase_24273",
      "original_id": "aibase_24273",
      "source_table": "aibase_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 145,
      "article_id": "aibase_aibase_24307",
      "original_id": "aibase_24307",
      "source_table": "aibase_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 146,
      "article_id": "baai_51686",
      "original_id": "51686",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 147,
      "article_id": "baai_51672",
      "original_id": "51672",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767742315,
      "report_file_path": "final_reports/AI_Report_2026-01-07_073155.md"
    },
    {
      "id": 148,
      "article_id": "baai_51687",
      "original_id": "51687",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 149,
      "article_id": "qbitai_367308",
      "original_id": "367308",
      "source_table": "qbitai_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 150,
      "article_id": "aibase_aibase_24354",
      "original_id": "aibase_24354",
      "source_table": "aibase_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 151,
      "article_id": "aibase_aibase_24372",
      "original_id": "aibase_24372",
      "source_table": "aibase_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 152,
      "article_id": "baai_51692",
      "original_id": "51692",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 153,
      "article_id": "baai_51693",
      "original_id": "51693",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 154,
      "article_id": "qbitai_367229",
      "original_id": "367229",
      "source_table": "qbitai_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 155,
      "article_id": "qbitai_367261",
      "original_id": "367261",
      "source_table": "qbitai_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 156,
      "article_id": "aibase_aibase_24366",
      "original_id": "aibase_24366",
      "source_table": "aibase_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 157,
      "article_id": "baai_51709",
      "original_id": "51709",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 158,
      "article_id": "baai_51701",
      "original_id": "51701",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 159,
      "article_id": "baai_51700",
      "original_id": "51700",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 160,
      "article_id": "baai_51698",
      "original_id": "51698",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 161,
      "article_id": "baai_51695",
      "original_id": "51695",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 162,
      "article_id": "qbitai_367216",
      "original_id": "367216",
      "source_table": "qbitai_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 163,
      "article_id": "aibase_aibase_24344",
      "original_id": "aibase_24344",
      "source_table": "aibase_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 164,
      "article_id": "aibase_aibase_24360",
      "original_id": "aibase_24360",
      "source_table": "aibase_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 165,
      "article_id": "aibase_aibase_24367",
      "original_id": "aibase_24367",
      "source_table": "aibase_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 166,
      "article_id": "baai_51691",
      "original_id": "51691",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767828663,
      "report_file_path": "final_reports/AI_Report_2026-01-08_073103.md"
    },
    {
      "id": 167,
      "article_id": "baai_51716",
      "original_id": "51716",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 168,
      "article_id": "baai_51690",
      "original_id": "51690",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 169,
      "article_id": "baai_51713",
      "original_id": "51713",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 170,
      "article_id": "baai_51729",
      "original_id": "51729",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 171,
      "article_id": "baai_51730",
      "original_id": "51730",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 172,
      "article_id": "baai_51725",
      "original_id": "51725",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 173,
      "article_id": "baai_51719",
      "original_id": "51719",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 174,
      "article_id": "baai_51727",
      "original_id": "51727",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 175,
      "article_id": "baai_51703",
      "original_id": "51703",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 176,
      "article_id": "baai_51736",
      "original_id": "51736",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 177,
      "article_id": "qbitai_367659",
      "original_id": "367659",
      "source_table": "qbitai_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 178,
      "article_id": "baai_51714",
      "original_id": "51714",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 179,
      "article_id": "baai_51735",
      "original_id": "51735",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 180,
      "article_id": "baai_51721",
      "original_id": "51721",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767914967,
      "report_file_path": "final_reports/AI_Report_2026-01-09_072927.md"
    },
    {
      "id": 181,
      "article_id": "baai_51760",
      "original_id": "51760",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 182,
      "article_id": "baai_51746",
      "original_id": "51746",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 183,
      "article_id": "aibase_aibase_24429",
      "original_id": "aibase_24429",
      "source_table": "aibase_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 184,
      "article_id": "qbitai_368598",
      "original_id": "368598",
      "source_table": "qbitai_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 185,
      "article_id": "baai_51758",
      "original_id": "51758",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 186,
      "article_id": "aibase_aibase_24447",
      "original_id": "aibase_24447",
      "source_table": "aibase_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 187,
      "article_id": "baai_51710",
      "original_id": "51710",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 188,
      "article_id": "aibase_aibase_24425",
      "original_id": "aibase_24425",
      "source_table": "aibase_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 189,
      "article_id": "aibase_aibase_24463",
      "original_id": "aibase_24463",
      "source_table": "aibase_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 190,
      "article_id": "baai_51756",
      "original_id": "51756",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 191,
      "article_id": "baai_51743",
      "original_id": "51743",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 192,
      "article_id": "qbitai_368641",
      "original_id": "368641",
      "source_table": "qbitai_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 193,
      "article_id": "baai_51759",
      "original_id": "51759",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 194,
      "article_id": "baai_51761",
      "original_id": "51761",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 195,
      "article_id": "qbitai_367855",
      "original_id": "367855",
      "source_table": "qbitai_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 196,
      "article_id": "aibase_aibase_24439",
      "original_id": "aibase_24439",
      "source_table": "aibase_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 197,
      "article_id": "baai_51752",
      "original_id": "51752",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 198,
      "article_id": "baai_51741",
      "original_id": "51741",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 199,
      "article_id": "aibase_aibase_24444",
      "original_id": "aibase_24444",
      "source_table": "aibase_article",
      "report_generated_at": 1768001633,
      "report_file_path": "final_reports/AI_Report_2026-01-10_073353.md"
    },
    {
      "id": 200,
      "article_id": "baai_51766",
      "original_id": "51766",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 201,
      "article_id": "qbitai_368820",
      "original_id": "368820",
      "source_table": "qbitai_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 202,
      "article_id": "baai_51769",
      "original_id": "51769",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 203,
      "article_id": "baai_51774",
      "original_id": "51774",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 204,
      "article_id": "baai_51775",
      "original_id": "51775",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 205,
      "article_id": "baai_51776",
      "original_id": "51776",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 206,
      "article_id": "baai_51784",
      "original_id": "51784",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 207,
      "article_id": "qbitai_368834",
      "original_id": "368834",
      "source_table": "qbitai_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 208,
      "article_id": "qbitai_368903",
      "original_id": "368903",
      "source_table": "qbitai_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 209,
      "article_id": "baai_51782",
      "original_id": "51782",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 210,
      "article_id": "baai_51783",
      "original_id": "51783",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 211,
      "article_id": "baai_51778",
      "original_id": "51778",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 212,
      "article_id": "baai_51771",
      "original_id": "51771",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 213,
      "article_id": "baai_51734",
      "original_id": "51734",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768087620,
      "report_file_path": "final_reports/AI_Report_2026-01-11_072700.md"
    },
    {
      "id": 214,
      "article_id": "baai_51773",
      "original_id": "51773",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768173877,
      "report_file_path": "final_reports/AI_Report_2026-01-12_072437.md"
    },
    {
      "id": 215,
      "article_id": "baai_51790",
      "original_id": "51790",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768173877,
      "report_file_path": "final_reports/AI_Report_2026-01-12_072437.md"
    },
    {
      "id": 216,
      "article_id": "baai_51785",
      "original_id": "51785",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768173877,
      "report_file_path": "final_reports/AI_Report_2026-01-12_072437.md"
    },
    {
      "id": 217,
      "article_id": "baai_51764",
      "original_id": "51764",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768173877,
      "report_file_path": "final_reports/AI_Report_2026-01-12_072437.md"
    },
    {
      "id": 218,
      "article_id": "baai_51786",
      "original_id": "51786",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768173877,
      "report_file_path": "final_reports/AI_Report_2026-01-12_072437.md"
    },
    {
      "id": 219,
      "article_id": "baai_51797",
      "original_id": "51797",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 220,
      "article_id": "baai_51812",
      "original_id": "51812",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 221,
      "article_id": "baai_51803",
      "original_id": "51803",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 222,
      "article_id": "baai_51805",
      "original_id": "51805",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 223,
      "article_id": "qbitai_369107",
      "original_id": "369107",
      "source_table": "qbitai_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 224,
      "article_id": "aibase_aibase_24489",
      "original_id": "aibase_24489",
      "source_table": "aibase_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 225,
      "article_id": "aibase_aibase_24494",
      "original_id": "aibase_24494",
      "source_table": "aibase_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 226,
      "article_id": "aibase_aibase_24496",
      "original_id": "aibase_24496",
      "source_table": "aibase_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 227,
      "article_id": "baai_51801",
      "original_id": "51801",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 228,
      "article_id": "baai_51791",
      "original_id": "51791",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 229,
      "article_id": "baai_51792",
      "original_id": "51792",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 230,
      "article_id": "google_google_gemini-api-new-file-limits",
      "original_id": "google_gemini-api-new-file-limits",
      "source_table": "company_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 231,
      "article_id": "baai_51802",
      "original_id": "51802",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 232,
      "article_id": "baai_51809",
      "original_id": "51809",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 233,
      "article_id": "baai_51804",
      "original_id": "51804",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 234,
      "article_id": "aibase_aibase_24495",
      "original_id": "aibase_24495",
      "source_table": "aibase_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 235,
      "article_id": "baai_51800",
      "original_id": "51800",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 236,
      "article_id": "baai_51795",
      "original_id": "51795",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768260315,
      "report_file_path": "final_reports/AI_Report_2026-01-13_072515.md"
    },
    {
      "id": 237,
      "article_id": "baai_51838",
      "original_id": "51838",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 238,
      "article_id": "baai_51829",
      "original_id": "51829",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 239,
      "article_id": "qbitai_369244",
      "original_id": "369244",
      "source_table": "qbitai_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 240,
      "article_id": "aibase_aibase_24539",
      "original_id": "aibase_24539",
      "source_table": "aibase_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 241,
      "article_id": "deepmind_deepmind_veo-3-1-ingredients-to-video",
      "original_id": "deepmind_veo-3-1-ingredients-to-video",
      "source_table": "company_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 242,
      "article_id": "baai_51841",
      "original_id": "51841",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 243,
      "article_id": "baai_51832",
      "original_id": "51832",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 244,
      "article_id": "baai_51826",
      "original_id": "51826",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 245,
      "article_id": "baai_51823",
      "original_id": "51823",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 246,
      "article_id": "baai_51813",
      "original_id": "51813",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 247,
      "article_id": "baai_51839",
      "original_id": "51839",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 248,
      "article_id": "baai_51824",
      "original_id": "51824",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 249,
      "article_id": "baai_51820",
      "original_id": "51820",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 250,
      "article_id": "google_google_veo-3-1-gemini-api",
      "original_id": "google_veo-3-1-gemini-api",
      "source_table": "company_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 251,
      "article_id": "aibase_aibase_24522",
      "original_id": "aibase_24522",
      "source_table": "aibase_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 252,
      "article_id": "aibase_aibase_24544",
      "original_id": "aibase_24544",
      "source_table": "aibase_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 253,
      "article_id": "baai_51819",
      "original_id": "51819",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    },
    {
      "id": 254,
      "article_id": "baai_51818",
      "original_id": "51818",
      "source_table": "baai_hub_article",
      "report_generated_at": 1768346929,
      "report_file_path": "final_reports/AI_Report_2026-01-14_072849.md"
    }
  ]
}