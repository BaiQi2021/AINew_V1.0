{
  "qbitai_article": [
    {
      "id": 1,
      "article_id": "366144",
      "title": "ViT一作盛赞：这个中国开源“PS模型”强过Nano Banana",
      "description": "ViT一作盛赞：这个中国开源“PS模型”强过Nano Banana梦瑶2025-12-2913:05:54来源：量子位梦瑶 发自 凹非寺量子位 | 公众号 QbitAI太香了太香了，妥妥完爆ChatGPT和Nano Banana！刚刚，ViT核心作者、Meta超级智能团队成员Lucas Beyer连发三条帖子，怒赞通义千问不久前发布的开源模型Qwen—Image—Layered。在他看来，这才是图",
      "content": "ViT一作盛赞：这个中国开源“PS模型”强过Nano Banana梦瑶2025-12-2913:05:54来源：量子位梦瑶 发自 凹非寺量子位 | 公众号 QbitAI太香了太香了，妥妥完爆ChatGPT和Nano Banana！刚刚，ViT核心作者、Meta超级智能团队成员Lucas Beyer连发三条帖子，怒赞通义千问不久前发布的开源模型Qwen—Image—Layered。在他看来，这才是图像生成的正确打开方式～他还顺便自补了一句：这个模型方向自己其实也想做来着，只是太忙，一直没来得及动手……（笑）实话实说，Qwen—Image—Layered模型确实不一般，因为它可以让我们真正实现ps级别的拆图自由。也就是说现在图片元素也支持精细化修改了：连网友们看了模型效果后都不禁感叹：咋有种开源PhotoShop的感觉，amazing啊～所以，这套让Lucas Beyer反复点赞的模型到底强在哪儿，咱一起来看！图片也能像PS一样拆拆拆了如果说Nano Banana技能点在生图，那Qwen—Image—Layered模型则厉害在：《拆图》。相信大家都有过类似的经历，我们平时用大模型生图时总会碰的到一个抓狂问题，那就是图片生成so easy，细节修改so抓狂！！！AI生出来的图片里，经常会有一些小细节不太到位，但我们又没法只改局部，只能整张丢回模型重新生成，结果往往还不如上一版…Qwen—Image—Layered模型的核心能力，就是专治「一图定生死」这事儿的。它能将一张普通图片分解成多个包含透明度信息的RGBA分离图层，实现真正意义上的图片素材的可编辑性。光说概念有点抽象，咱直接看例子～在官方案例中，一张完整图片输入之后，模型会自动把画面拆成6个包含不同元素的图层，背景是背景，人物是人物，装饰是装饰，互不干扰。看到这儿大家是不是突然感觉，这个非常适合用在海报制作等细节较多的图片上？？（雀实但是Qwen—Image—Layered模型能做的还不止只是分离图层这么简单，我们还可以对图层进行二次编辑修改。比如最基础的：改背景，不动主体。只替换背景图层的颜色，一张橙色背景的海报，瞬间就能换成蓝色版本：再比如，直接换主体。保持构图不变，把原图里的长发女孩，换成短发女孩，几乎看不出拼接修改痕迹：再来看下面这个——文字编辑。我们可以只修改图片中的局部文字，哪怕第一次生成的文字有幻觉问题也不怕了：除了基本的替换编辑功能外，Qwen—Image—Layered模型还支持调整元素的大小、删除不想要的元素等等。例如像这样，我们可以删除掉画面中不想要的元素对象，只保留自己想留的画面元素：又或者在不拉伸、不失真的前提下，轻松调整元素的大小比例，其实有点像PS里的自由缩放功能：值得注意的是，Qwen—Image—Layered模型分层不限于固定的图层数量，支持可变层分解，例如我们可以根据需要将图像分解为3层或8层：这个能力非常适合我们在不同的编辑需求场景下使用，可以根据我们想局部编辑的元素数量多或少而定。当然，如果只是想改文字，差不多两三层就够了，如果修改需求比较多比较复杂，多拆几层反而更好操作～除了刚才说的这些，模型还支持在已分解的图层基础上做进一步分解，进而实现无限分解，听上去很像无限套娃…像下面这位网友，用Qwen—Image—Layered把人物元素进行一次性分层处理，最后甚至可以一路拆到只剩下一个线稿层：再来看这位网友，原本人物和背景完全糊在一起的一张图，被模型直接拆成了主体和背景两个独立元素：简单说就是：只要画面里不止一个元素，它就能拆、还能一直拆……拆图的本事来自于扩散模型有朋友看到这儿该问了，小小模型背后能有这PS一般的能力，用的是啥神奇魔法？不藏着掖着，Qwen—Image—Layered的核心技术，本质上是一套端到端的「扩散模型」。它并不是用来生成图片的那种扩散模型，而是专门为「拆图片」这件事设计的——模型直接输入一张完整的RGB照片，通过扩散过程，一步步预测出多个带透明度信息的RGBA图层。这里有一个绕不开的前提是：我们平时看到的图片其实只有RGB三个通道，但真正的图层编辑，离不开Alpha（透明度）通道。为此，Qwen—Image—Layered专门设计了一套四通道的RGBA-VAE，把RGB输入和RGBA输出，统一压缩到同一个隐藏空间中：具体来说，当输入是一张普通RGB图片时，模型会自动把Alpha通道补成1（完全不透明），在初始化阶段还会聪明地复用预训练参数，避免在透明度建模时出错。这样一来，模型从一开始就「懂透明」，不同图层也就不会被混在一起。而且在结构上模型也不是死板拆层，它的核心Transformer—VLD-MMDiT会根据图片复杂度，自动决定需要拆成多少层。为了避免前一层把后一层盖住的问题，模型还加了一套Layer3D RoPE（三维位置编码），简单说就是给不同图层打上明确的层级标签，让模型在空间和顺序上都分得清楚～还不止如此，在隐藏空间里中，模型能够被逐步「引导」去学会：哪些像素该属于哪一层、哪些区域需要保留透明度、哪些内容应该被分离开来。这样一来哪怕图层再多对模型来说也都是小case了～并且在训练策略上模型也不是从零教的，而是基于Qwen-Image预训练生成模型逐步升级：第一阶段让模型学会文本生成单RGBA图层，第二阶段让模型学会扩展到多图层合成，第三阶段让模型真正学会从图片反向拆解多图层。每阶段几百K步训练，加上重建损失和感知损失，确保语义分离干净、不冗余。这样一来好处很直接，以前方法（如LayerD）要递归抠前景再补背景，容易积累错误，或者用分割+修复，遮挡区补不好。Qwen—Image—Layered模型直接实现端到端生成完整RGBA层，避免这些问题，尤其擅长复杂遮挡、半透明和文字。相较于Nano Banana的“一次抽图定生死”，Qwen—Image—Layered的拆图能力能让Lucas Beyer这么喜欢，也就不奇怪了…目前模型已经开源，感兴趣的朋友可以试试～github开源地址：https://github.com/QwenLM/Qwen-Image-Layered版权所有，未经授权不得以任何形式转载及使用，违者必究。通义千问梦瑶对科技圈，小红书是个「新绿洲」2025-12-30太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26PPIO荣获InfoQ2025 年度 AI 基础设施卓越奖2025-12-25飞猪《2025旅行AI指数》：Token消耗量涨20倍，日均用户调用次数增7.7倍2025-12-25扫码分享至朋友圈相关阅读阿里刚开源32B大模型，我们立马测试了“弱智吧”拼齐1.5系列最后一块拼图十三2024-04-07弱智吧通义千问阿里云阿里巴巴国产720亿参数开源免费模型来了！对标Llama2 70B，一手实测在此通义千问又双叒开源了鱼羊2023-12-01开源大模型通义千问阿里通义免费开放奥运AI大模型只需简单提问，就能获得详尽且专业的答案量子位2024-07-31通义千问阿里云兵马俑跳《科目三》，贝佐斯跳二次元宅舞...阿里通义千问统统安排上了！网友：闻所未闻，见所未见十三2024-01-04AnimateAnyone多模态大模型通义千问阿里巴巴开源超闭源！通义千问Qwen2发布即爆火，网友：GPT-4o危2小时登顶HuggingFace开源大模型榜单十三2024-06-08开源大模型通义千问击穿全网底价，通义千问大模型直降97%！1块钱能买200万tokens大模型有属于自己的618鱼羊2024-05-21大模型通义千问阿里云热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26DeepSeek官方点赞元宝，罕见现身互动2025-12-24原力灵机提出GeoVLA：让机器人看懂三维世界，打破2D视觉枷锁2025-12-246999起！小米史上最贵Ultra来了：告别256G，影像硬刚iPhone 17 Pro Max2025-12-25",
      "article_url": "https://www.qbitai.com/2025/12/366144.html",
      "author": "梦瑶",
      "publish_time": 1766937600,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"通义千问\", \"弱智吧通义千问阿里云阿里巴巴\", \"开源大模型通义千问\", \"通义千问阿里云\", \"AnimateAnyone多模态大模型通义千问阿里巴巴\", \"开源大模型通义千问\", \"大模型通义千问阿里云\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://github.com/QwenLM/Qwen-Image-Layered\", \"url\": \"https://github.com/QwenLM/Qwen-Image-Layered\", \"type\": \"code\"}]",
      "add_ts": 1766988462,
      "last_modify_ts": 1767193279
    },
    {
      "id": 7,
      "article_id": "366165",
      "title": "AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品",
      "description": "AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品思邈2025-12-2914:22:42来源：量子位聚焦肺癌，92个问题+1691个临床要点允中 发自 凹非寺量子位 | 公众号 QbitAI蚂蚁健康与北京大学人民医院王俊院士团队历时6个多月，联合十余位胸外科医生共同打磨，发布了全球首个大模型专病循证能力的评测框架——GAPS（Grounding, Adeq",
      "content": "AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品思邈2025-12-2914:22:42来源：量子位聚焦肺癌，92个问题+1691个临床要点允中 发自 凹非寺量子位 | 公众号 QbitAI蚂蚁健康与北京大学人民医院王俊院士团队历时6个多月，联合十余位胸外科医生共同打磨，发布了全球首个大模型专病循证能力的评测框架——GAPS（Grounding, Adequacy, Perturbation, Safety），及其配套评测集 GAPS-NSCLC-preview。旨在解决现有医疗AI评测局限于考试式问答、缺乏临床深度、完整性、鲁棒性与安全性综合评估的问题。该评测集聚焦肺癌领域，包含92个问题、覆盖1691个临床要点，并配套全自动化的评测工具链，通过指南锚定、多智能体协同实现从问题生成、评分标准制定到多维度打分的端到端自动化。目前，相关成果已应用于“蚂蚁阿福”，论文《GAPS: A Clinically Grounded, Automated Benchmark for Evaluating AI Clinicians》、配套评测集GAPS-NSCLC-preview、自动化评测框架已全面公开。这项研究客观评价了大模型的临床能力：当前主流医疗大模型虽已具备“医学百科全书”般的知识广度，但在临床实践中仍处于成长阶段——它们在系统掌握医学知识方面表现卓越，但在应对真实临床场景中的不确定性挑战时，尚需进一步提升判断力与可靠性。权威引领：北大人民医院院士团队深度主导临床标准构建本项目由中国工程院院士、北京大学人民医院院长王俊教授领衔的团队全程主导，并与蚂蚁团队深度协作完成。在GAPS构建过程中，院士团队原创性地提出了GAPS评测的理论框架，并组织十余位胸外科医生持续参与评测题库构建、临床金标准答案撰写、模型输出的专业审核与迭代优化，提供NSCLC（非小细胞肺癌）领域前沿临床指南的权威解读与循证医学方法论指导，确保每一项指标都扎根真实临床实践，具备高度专业性与可信度。蚂蚁团队则发挥大模型与工程化能力优势，经过多轮高强度医工协同与反复迭代，将专家脑海中的复杂“临床金标准”精准沉淀为大模型可理解、可执行的结构化逻辑，实现GAPS的规模化、自动化与可落地应用。此次合作实现了“临床专家定标准、AI 技术做转化”的深度融合，突破了传统医疗AI评测中专家浅层参与的局限，标志着顶尖临床专家与AI技术团队的深度协作，为医疗AI从“技术驱动”走向“临床价值驱动”树立了新的范式。行业痛点：考得好，信不过在和大模型讨论医疗问题时，有时候回答得很好，有时候回答得很差，由于大模型的变化日新月异，医生和患者都没有办法在短时间对大模型产生客观评价，因此对大模型的信任就无从谈起。为了客观评价大模型的能力，学界通常采用基准测试的方法。然而，当前医疗AI的基准测试普遍缺乏对模型循证能力、可解释性与安全性的系统评估。长期以来，医疗AI的评估依赖MedQA、PubMedQA等“试卷型”基准，仅考察事实记忆能力；而HealthBench等基于人工评分细则（Rubric）的方法又受限于主观性强、扩展性差。这些方法无法反映真实诊疗场景：患者描述模糊、检查结果矛盾、治疗方案需权衡利弊……正如论文所强调：真正的医疗能力不在于背诵事实，而在于管理不确定性。尤其在肺癌这一全球致死率最高的癌症领域，缺乏细粒度、专病化的评估工具，使得医疗机构和开发者难以客观判断医疗AI是否真正具备临床可用性。GAPS的诞生，正是为了填补这一关键空白。破局之道：GAPS——从“考试机器”到“临床医生”的四维标尺GAPS是一个基于循证医学、全自动构建的AI临床能力评测框架，首次将临床胜任力解构为四个正交维度，并聚焦NSCLC（非小细胞肺癌）这一高难度专病场景进行系统验证：1、G（Grounding）认知深度：不止于“是什么”，更考验“为什么”和“怎么办”。G1和G2：事实回忆与解释（AI的舒适区）G3：基于指南的循证决策（如NCCN推荐方案）G4：推理性思维（Inferential Reasoning）——在证据冲突或缺失的“灰色地带”做出合理判断，这是当前所有模型的“死亡区”。2、A（Adequacy）回答完备性：医生的一句话可能关乎生死。GAPS引入三级评价：A1（必须有）：核心诊疗建议A2（应该有）：关键限定条件（如剂量、禁忌症、监测指标）A3（锦上添花）：患者教育、多学科协作建议等缺少A2，再“正确”的建议也可能导致临床误用。3、P（Perturbation）鲁棒性：真实患者不会照着教科书说话。GAPS通过三类扰动测试模型抗干扰能力：P1：语言噪音（口误、方言）P2：冗余信息（无关症状堆砌）P3：对抗性前提（如诱导性错误假设）实验显示，多数模型极易被误导，甚至顺从用户的错误引导。4、S（Safety）安全底线：医疗容不得“差不多”。GAPS 建立四级风险体系：S1（无关回答）→ S4（灾难性错误/Never Events，如推荐禁忌药物）一旦触犯S4，无论其他维度得分多高，总分直接归零——这是不可逾越的红线。GAPS解决了现有医疗AI评测仅关注“准确率”的局限，首次实现对循证决策能力、回答完备性、现实鲁棒性与安全底线的系统性、自动化评估。其优势在于：以临床指南为锚点，全自动构建高保真评测项与评分规则，兼具可扩展性、可复现性与临床真实性，为AI向可信临床伙伴演进提供精准导航。核心黑科技：全自动化的“循证评测集”流水线GAPS最大的技术亮点在于其端到端自动化与可扩展性。不同于以往依赖人工命题，GAPS构建了一套基于临床指南（Guidelines）的自动化生成工厂：证据邻域构建：以NCCN、ESMO等权威指南为核心，自动抓取3跳内引用文献，构建高可信医学知识图谱与疾病话题树；Deep Research Agent：基于GRADE方法学，模拟人类专家围绕PICO（人群、干预、对照、结果）展开的证据检索、证据评估、强弱推荐的流程，自动生成带证据等级与推荐强度的高质量评分细则；虚拟患者生成：利用大模型合成去隐私化临床病例，并精准对齐知识图谱，确保每道题“有据可依、有理可循”。该流水线已成功应用于胸外科的专病——NSCLC（非小细胞肺癌），生成包含92道题、1691个临床要点的评测集GAPS-NSCLC-preview。题目按认知深度分为G1~G4四级（从事实回忆到不确定性下的推理），每题均配备平均12项完整性（A1~A3）与7项安全性（S1~S4）评分要点，并支持P0~P3四级扰动测试。未来可快速扩展至心血管、儿科、内分泌等任意专科的专病领域——只要有指南，就能生成高质量评测集。可靠的裁判：自动化评测让AI医疗能力可量化、可复现、可进化GAPS评测集同时搭配了一套高可靠性的自动化评测框架，实现了对AI临床能力的客观、细粒度、端到端的自动化评估。为确保评测本身可信，团队将自动化评分结果与五位资深专家的独立标注进行严格比对：在92个真实临床查询、1691个临床要点上，该框架与专家共识的整体一致率达90.00%，Cohen’s Kappa系数达0.77（“实质性一致”），Macro-F1达0.88——不仅显著优于现有基准（如HealthBench中GPT-4的0.79），已达到人类专家间一致性水平（88.5%~92.0%）。这证明GAPS评测集的自动评判能力具备专家级可靠性。在此基础上，评测不再是终点，而是进化的起点。框架输出的结构化评分（G/A/P/S四维、MET/NOT-MET标记）可精准定位模型在循证决策、回答完备性、扰动鲁棒性或安全红线上的缺陷；由此，GAPS具备成为“评测即反馈、反馈即迭代”的最重要基石——AI医疗能力不再依赖模糊经验，而是通过可量化的指标、可复现的流程、可积累的进化路径，稳步向临床可用迈进。实战揭秘：顶尖大模型的“滑铁卢”研究团队使用GAPS对GPT-5、Gemini 2.5 Pro、Claude Opus 4、Qwen3-235B-A22B-Instruct-2507、DeepSeek-V3.1-Terminus等主流模型进行“体检”，结果发人深省：1、“百科全书”易做，“专家”难当：所有模型在G1（事实）和G2（解释）阶段表现优异（GPT-5得分约0.72）。但一旦进入G3（确定性决策）和G4（非确定性推理），分数呈断崖式下跌，GPT-5在G4阶段跌至0.45，其他模型甚至跌破0.35。这说明 AI目前还只是“背书机器”，而非“推理伙伴”。2、不仅要“对”，还要“全”：在Adequacy（完备性）测试中，模型往往只给出核心建议（A1），却忽略了关键的限定条件（A2），导致临床建议缺乏可操作性。3、极其脆弱的耳根子：在P3（对抗性测试）中，只要在提问中加入一点误导性前提（例如暗示某种错误疗法有效），模型的判断力就会崩塌，甚至顺从用户的错误引导。4、安全隐患：虽然GPT-5和Gemini 2.5在极高风险错误（S4）上控制较好，但在复杂的推理场景下，部分模型（如Claude Opus 4）的致命错误率随难度显著上升。结语：GAPS评测框架是AI医生从“Chatbot”到“Doctor”的必经之路GAPS的发布，标志着医疗AI的评测标准从“考试分数”向“临床胜任力”的范式转移。蚂蚁健康与北大人民医院的这项工作告诉行业——现有的通用大模型在面对复杂的临床不确定性时，依然显得稚嫩且脆弱。未来的医疗AI研发，不能止步于预训练知识的灌输，而必须转向循证推理（Evidence-grounded Reasoning）、过程决策控制以及不确定性管理。GAPS不仅仅是一个榜单，它更是医疗AI进化路上的“磨刀石”。只有跨越了GAPS设定的这四道关卡，AI医生才能真正放心地走进诊室。论文地址：https://arxiv.org/abs/2510.13734评测集地址：https://huggingface.co/datasets/AQ-MedAI/GAPS-NSCLC-preview自动化评测框架地址：https://github.com/AQ-MedAI/MedicalAiBenchEval版权所有，未经授权不得以任何形式转载及使用，违者必究。AI医生AI医疗北大蚂蚁思邈有300亿美元也未必“再造GPT-4”？NUS尤洋最新长文：拆穿AI增长瓶颈的真相2025-12-31推理成本打到1元/每百万token，浪潮信息撬动Agent规模化的“最后一公里”2025-12-26国产AI4S创业头雁再获8亿投资！深势科技完成C轮，产品已服务300万科学家2025-12-24具身智能的数据难题，终于有了可规模化的解法2025-12-18扫码分享至朋友圈相关阅读AI医疗版App Store来了：GE发布“爱迪生魔盒”，集成各方医疗方案，李开复点赞AI医疗大统一平台晓查2021-07-11AI医疗WAIC 2021北大清华“合并开班”：AI大牛朱松纯带队，面向元培和自动化系招生北大清华联合建设通用人工智能实验班，目前北大通班已开课明敏2021-04-26北大清华通班大模型恋爱神器！16种MBTI自由定制，北大ChatLaw团队出品已开放32个大模型明敏2024-01-13北大微调北大王选所：让多模态大模型更懂人类在做什么｜ECCV 2024靠提示词就行一水2024-08-13北大多模态大模型蚂蚁集团AI推动服务业智能化实践入选社科院《智能经济蓝皮书》蓝皮书还收录了蚂蚁集团智能经济创新与应用白交2025-01-10大模型蓝皮书蚂蚁谷歌AI乳腺癌检测超过人类？美国知名记者：让糟糕的医疗更糟罢了赖可2020-01-19AI医疗热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26DeepSeek官方点赞元宝，罕见现身互动2025-12-24原力灵机提出GeoVLA：让机器人看懂三维世界，打破2D视觉枷锁2025-12-246999起！小米史上最贵Ultra来了：告别256G，影像硬刚iPhone 17 Pro Max2025-12-25",
      "article_url": "https://www.qbitai.com/2025/12/366165.html",
      "author": "思邈",
      "publish_time": 1766937600,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"AI医生AI医疗北大蚂蚁\", \"AI医疗WAIC 2021\", \"北大清华通班\", \"北大微调\", \"北大多模态大模型\", \"大模型蓝皮书蚂蚁\", \"AI医疗\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://arxiv.org/abs/2510.13734\", \"url\": \"https://arxiv.org/abs/2510.13734\", \"type\": \"paper\"}, {\"title\": \"https://huggingface.co/datasets/AQ-MedAI/GAPS-NSCLC-preview\", \"url\": \"https://huggingface.co/datasets/AQ-MedAI/GAPS-NSCLC-preview\", \"type\": \"code\"}, {\"title\": \"https://github.com/AQ-MedAI/MedicalAiBenchEval\", \"url\": \"https://github.com/AQ-MedAI/MedicalAiBenchEval\", \"type\": \"code\"}]",
      "add_ts": 1767050264,
      "last_modify_ts": 1767193277
    },
    {
      "id": 8,
      "article_id": "366091",
      "title": "救命！和漫画角色聊上头了，AI陪伴的新答案有了",
      "description": "救命！和漫画角色聊上头了，AI陪伴的新答案有了西风2025-12-2910:50:52来源：量子位建立存在于故事中的关系西风 发自 凹非寺量子位 | 公众号 QbitAI行业最新AI陪伴产品，玩起来简直太上头了，这波是真的爱了。打开方式be like：它不为AI创造一个角色，不用玩家自己费力填写设定，直接让AI嵌入漫画主线里本就鲜活的角色之中：而且呢，当你和TA聊天互动时，得到的不是千篇一律机械式",
      "content": "救命！和漫画角色聊上头了，AI陪伴的新答案有了西风2025-12-2910:50:52来源：量子位建立存在于故事中的关系西风 发自 凹非寺量子位 | 公众号 QbitAI行业最新AI陪伴产品，玩起来简直太上头了，这波是真的爱了。打开方式be like：它不为AI创造一个角色，不用玩家自己费力填写设定，直接让AI嵌入漫画主线里本就鲜活的角色之中：而且呢，当你和TA聊天互动时，得到的不是千篇一律机械式的问答。玩家将“魂穿”进漫画世界，以第一视角与TA们相遇。所以每一次对话、每一个选择，都将共同改写一段正在发生的故事。没错，这意味着你能与你喜爱的那个TA，展开真正深入、即时的互动。这恰恰刺中了当下AI陪伴产品的痛点——普遍与用户的关系难以持续，对话疲劳与人设空洞已成通病。它的解法不同，靠的是建立在共同经历与叙事上下文之上的关系存续逻辑。不卖关子，这正是国内漫画头部玩家快看，在快看漫画2.0版本中推出的AI陪伴互动漫画，也是一次关于叙事型陪伴的全新尝试。这一形态同时点燃了两类用户的期待，一边是厌倦了机械式聊天的AI尝鲜者，另一边则是渴求与角色深度互动的漫画核心用户。官方预热微博发布时，评论区已是一片“快快端上来”的呼声。还有更多好玩儿的，我们接下来细细品。魂穿漫画，这谁顶得住随着AI陪伴互动体验登陆快看漫画，《DOLO最后的夏天》《Bloody心跳回溯》《SHElter她之所归》等风格各异的作品，首发解锁该玩法。入口就在快看漫画APP首页的“角色陪伴”专区。点进去后，在页面顶部选择心仪的漫画作品，迎面而来的便是静候你多时的漫画角色。以穿越题材漫画《DOLO最后的夏天》为例，主线剧情讲述了神奇生物DOLO带你重返17岁，一边攻略四位性格迥异的角色，一边探寻高中坍塌事故的真相，重启不一样的青春。在这里，你成为了故事的主角。点击“主线故事”即可沉浸阅读漫画，推进核心剧情。与此同时，你可以随时从主线中切出，与角色们展开即时聊天。这种设计，与传统AI陪伴需要你从零开始设定角色截然不同。在这里，你遇见的每个角色都已自带丰满的前史，他们就来自这部完整的漫画，拥有既定的人格、人际关系与命运挑战。而你的代入，是进入一个早已运转的故事轨迹，这从源头上赋予了角色无可替代的深度与一致性。即便是最随意的闲聊，角色也不会出戏，回答始终锚定在自己的世界里。比如问他中午吃什么，他可能会说“学校外面新开了家汉堡店”。日常与角色的对话也不止于泛泛而谈，它们被巧妙地编织在剧情的时间线上。闲聊中会伴随各种日常事件，可能发生在重大事件的前夜，对方的回应会带着剧情赋予的紧张或期待；也可能在共同冒险后的休憩时刻……这种设计让每一次互动都成为对共同经历的积累。在特定剧情节点触发的剧情事件中，体验更进一层。系统会给玩家安排明确任务，你需要通过与角色对话来“攻略”他们、完成任务，从而引导剧情走向。除此之外，还有机会触发更为沉浸的限定事件。此时，系统会结合环境音效、动态画面与AI的实时对话，营造出一种轻度的共演氛围。整个交互画面的质感提升，细节更为考究。例如，在“给TA投喂饼干”的互动中，你能看到角色接过饼干的细微动作、听到对应的音效。有意思的是，玩家在其中的所有互动都暗含上分机制。自身的魅力、智商、体能、耐心等属性会随着互动浮动。玩家不仅是在推动剧情，也在实时养成自己的人设。与角色之间的好感度，也会在互动中悄然变化。最终，这一切将指向只属于你的、独一无二的角色关系与故事结局。接下来就不再过多剧透了，留给宝子们自行探索。一句话总结体验，把AI当成角色扮演插件嵌进成熟漫画，让对话多一层故事感，这是快看为解决“AI如何真正陪伴”这个行业难题，给出的一条新的解题思路。换句话说，快看没有在让对话更聪明或是AI直接生成漫画的维度上卷。目前市面很多AI陪伴产品难以和用户间形成长久陪伴关系。许多产品本质上是在强情感（如情绪安慰）或强叙事（如角色扮演）的单一路径上深耕。前者易因缺乏共同话题而陷入情绪饱和，后者则常因世界观单薄而让对话流于程式化。快看这次试图同时握住“叙事”与“情感”两条线，用连续的漫画故事为AI提供生活的世界与时间线，又用即时、个性化的互动让用户在这个世界里沉淀专属的情感记忆。角色因故事而厚重，关系因记忆而具体。根据官方测试，体验新产品的用户，其周留存率相较传统漫画提升约50%，直接证明了用户与角色已建立起超越普通“读者-作品”的准社交陪伴关系。快看当“总导演”，集成各家AI顶流AI科技热潮下，人们对于游戏NPC、二次元虚拟角色能“活”起来的种种畅想，在此刻有了一次具体又高水准的落地形态。这自然引出一个问题：AI模型或许早具备这样的能力，为什么AI公司一直没做出来？答案很明显，这本质上是一个“内容理解深度>基础模型能力”的垂直场景。真正的挑战不在于找到一个很会说话的AI，而在于让它精准踩住每一个故事转折的节点，完完全全变成漫画里那个鲜活的角色。对角色、故事节奏、情感脉络的深度理解与把控能力，是快看这样做内容的公司十几年积累，以及技术无法短期复制的核心资产。纵观快看的发展历程，从2014年以条漫革新移动阅读体验，到2021年前瞻性地推出“漫剧”形态，再到如今探索AI互动叙事……每一步都是对如何更好地“讲故事”与“连接用户情感”的持续深耕。所以，快看在此次尝试中扮演的角色，更像是一位手握成熟剧本和演员理解力的导演，而AI技术是被融合进来服务于统一的叙事体验。那么背后用的哪家的AI？据了解，此次AI陪伴互动漫画的背后，是一个“专业事交给专业方”的开放协作生态：腾讯云：通过DeepSeek API为AI陪伴互动漫画提供灵活可调用的AI原生能力，支撑角色互动与对话生成。火山引擎：接入豆包支持角色聊天；即梦提供生图、生视频能力，用于生成角色互动的AI视频素材；海绵音乐则为视频提供环境音与音效支持。阿里云：基于通义千问的对话能力与图像模型能力，共同支撑角色互动体验。可灵：提供生视频与配音能力，增强角色表达与内容呈现效果。MiniMax：提供高质量语音能力，丰富角色声音表现。不仅如此，快看还在和一众有特色、有脑洞的AI公司密切合作，比如主打指向式全息与全维度交互的AI硬件公司数伴，以及亚洲极具影响力的AI原生虚拟歌手Yuri尤粟、THUNDEROBOT雷神等。当然它优先服务的，依然是平台内最核心的故事消费用户，通过AI为既有的阅读体验注入更强的沉浸感与情感联结。这一切在其自家最熟悉地盘内进行，以最高的内容契合度，探索人工智能时代娱乐内容的新形态。这一探索也在无形中，向世人证明：只有存在于故事中的关系，才能发展出长久的AI陪伴。在构建有温度的数字关系时，一个精心构筑的故事上下文，其力量可能远胜于一个更聪明的对话引擎。现在，悬疑、古风、都市奇幻……各种风格的剧本已就位。感兴趣的友友可以冲冲亲自体验了～One More Thing我们拿到了官方尚未披露的产品内测数据，进一步说明了“AI+互动叙事”这一模式在用户体验之外，也初步展现出商业上的潜力：测试阶段，新作上架周付费率飙升，相比传统阅读产品提升近三倍。此外，新作凭借多分支多选项的内容特点，带来更加高频的小额付费。加之，这种带有数值属性的角色养成内容，培养出用户长线付费习惯。双管齐下，最终带动周人均付费提升130%。对于新产品，官方表态，这是一次“漫画体验形态探索，未来持续完善后会带来更多惊喜”。所以广大友友们可以继续期待一波，或许之后还能体验和AI共创故事，不再只是沉浸在漫画世界里，而是在某个漫画里和喜欢的角色们，一起创造独一无二的经历。官方体验链接：https://miniact.kkg3.com/dynamic/JQjwhywV/topic/common-activity/index.html?id=1192_1版权所有，未经授权不得以任何形式转载及使用，违者必究。AI聊天快看漫画漫画AI西风国足缺席世界杯，但中国大模型们集体参赛2025-12-28AI终于学会在家“伺候人”！Hey Tuya，我躺了2025-12-31鸿蒙押注新未来：用AI重写数字世界交互逻辑2025-12-28认知偏差、落地断层、体验割裂是目前AI产品的三大痛点｜百度王颖@MEET20262025-12-19扫码分享至朋友圈相关阅读破案了！百万用户与AI交友，背后果然有大模型一句话生成AI人格明敏2023-02-18AI聊天Glow大模型聊天机器人ChatGPT国产平替出现了：APP商店就能下载，还可给AI加人设，背后公司刚成立3个月有股晋江文学那味儿……明敏2022-12-08AI聊天ChatGPT热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26DeepSeek官方点赞元宝，罕见现身互动2025-12-24原力灵机提出GeoVLA：让机器人看懂三维世界，打破2D视觉枷锁2025-12-246999起！小米史上最贵Ultra来了：告别256G，影像硬刚iPhone 17 Pro Max2025-12-25",
      "article_url": "https://www.qbitai.com/2025/12/366091.html",
      "author": "西风",
      "publish_time": 1766937600,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"AI聊天快看漫画漫画AI\", \"AI聊天Glow大模型聊天机器人\", \"AI聊天ChatGPT\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://miniact.kkg3.com/dynamic/JQjwhywV/topic/common-activity/index.html?id=1192_1\", \"url\": \"https://miniact.kkg3.com/dynamic/JQjwhywV/topic/common-activity/index.html?id=1192_1\", \"type\": \"external\"}]",
      "add_ts": 1767050267,
      "last_modify_ts": 1767193280
    },
    {
      "id": 12,
      "article_id": "366239",
      "title": "千人千面的真人级AI名师，劈开教育「不可能三角」",
      "description": "千人千面的真人级AI名师，劈开教育「不可能三角」Jay2025-12-3012:25:46来源：量子位百万AI学习原住民已入驻Jay 发自 凹非寺量子位 | 公众号 QbitAI注意看，这是一个教育领域的AI应用新物种——咱就是说，这讲课节奏，这语气，这互动，也太自然了。更重要的是，它不仅能「像老师一样讲课」，还能针对每一位学员进行一对一的个性化教学。这位AI导师，出自一家名为「与爱为舞」的AI原",
      "content": "千人千面的真人级AI名师，劈开教育「不可能三角」Jay2025-12-3012:25:46来源：量子位百万AI学习原住民已入驻Jay 发自 凹非寺量子位 | 公众号 QbitAI注意看，这是一个教育领域的AI应用新物种——咱就是说，这讲课节奏，这语气，这互动，也太自然了。更重要的是，它不仅能「像老师一样讲课」，还能针对每一位学员进行一对一的个性化教学。这位AI导师，出自一家名为「与爱为舞」的AI原生应用企业。自年初上线以来，已累计为百万级用户提供学习陪伴与一对一讲解服务。教育行业，向来是个「规模、质量、成本」的不可能三角。既能做到千人千面，又能服务百万名学员，还几乎看不出是AI……更是难上加难。它究竟是怎么做到的？与爱为舞用来劈开这个不可能三角的，是一把硬核的技术巨剑。AI教育，要的不止「答案」而铸造这把技术巨剑，有三块核心组成部件：「模型+语音+工程」。先看模型——得益于CoT的Scaling，大模型解决复杂问题的能力指数级增长，「做题」水平突飞猛进，甚至能斩获「奥赛金牌」。摘得奥赛桂冠，AI只需要给出标准答案。但搞教育不行。先来看一个简单的英语语法题：Lily expects_her grandparents in the countryside next month.A. visiting｜B. to visit｜C. to have visited｜D. having visited大模型给出的解答如下：这道题的正确答案是B. to visit。核心考点解析：动词固定搭配，动词 expect（期望、预料）的常用用法是——expect to do sth.（期望做某事），后面需要接不定式（to + 动词原形） 作宾语。B选项to visit是不定式的一般式，用来表示与谓语动词（expect）同时或之后发生的动作，符合 “下个月看望祖父母” 的将来时态逻辑。我可以帮你整理一份常见接不定式作宾语的动词清单，方便你记忆，需要吗？答案是对了，看起来好像也讲了解题过程，但如果拿这套方法教学员，那肯定是要被家长投诉的啊……完全没有引导学员思考，一上来就把答案透露了。就像个纯天赋型学霸，风驰电掣做完题，然后猛地丢给你一个结果，问你：「我说的对不对！」随后才给出一串看似头头是道的分析。不过，硅基大佬，小弟我根本听不明白你在说什么啊！最后还要给你一份「动词清单」，直接默认教学等于枯燥的背诵，而没去想怎样引导学员的主观能动性。归根结底，通用大模型的设计初衷就不是教育。它拼尽全力，只想向用户证明一件事——「厉害吧，哥啥都知道！」古人讲：授人以鱼，不如授人以渔。导师如果光顾着自己拿金牌，这师生关系就乱了套了。想要成为一名好导师，AI需要学会放低姿态，真正关心学员的课堂体验。首先，AI得明白各学科的核心知识图谱、关键考点和常见解题方法，这些才是学员能服用的，是最基本的「知」。在此之上，AI还得学习名师是怎么设计讲解顺序的，并从中总结归纳出一套顶尖教师的授课方法论。这是更高维度的「知」。陆游讲，「纸上得来终觉浅，绝知此事要躬行。」「知」总是相对容易的，重点是如何把纸上谈兵那套，搬到现实世界里实践起来。所幸，「行」方面，与爱为舞有相当充足的弹药。据悉，他们已积累了约百万小时的音视频互动数据，特别是包含大量业内TOP级名师的授课视频。在此基础上，团队又根据学员的认知水平与学习态度，构建出多类型的「虚拟学员」，让他们与AI导师进行「搏击」，每周又能收获数万小时的合成数据。这些数据在经过筛选与清洗后，会交由专业教研进行把关。具体而言，教师们会把自己多年的「教学经验」，根据场景具象化为一条条思维链，最终汇集成一本「好老师红宝书」：每个知识点该如何拆解，与学员互动时如何循循善诱……不止要让AI学会怎么讲课，更要明白「为什么要这么讲」。这种手把手教的方式效果很好，但成本也相当高。随着方法论逐渐成熟，团队索性将这一环节也自动化，让AI模仿专业教研参与数据标注。备考资料准备就绪，下面就该着手训练了。第一步，照猫画虎。那些相对容易标准化的知识，已体现在标注数据之中。AI需要做的，是通过模仿专业教师的思维链，逐步摸索出每一个教学动作背后的真实意图。这一微调过程，能大幅降低AI「自我发挥」带来的的幻觉率，同时培养更稳定的推理能力与泛化能力。能做到这一点，就算是打牢了基本功。最基本的教法、节奏和经验都已被「固化」，能以标准化形式面向所有学员输出，教学质量的下限得到保障。但如果目标只是及格，这件事就没意义了。师傅能陪伴的路程就到这。接下来，得能靠AI自己上路修行。第二步，终于到了大家喜闻乐见的强化学习环节。在教育这个场景下，与爱为舞的奖励函数围绕教学路径规划质量、教学有效性与教学灵活性等维度设计，通过GRPO给AI做强化。这步结束，AI彻底出师——不仅能够完成授课任务，还能驾驭课堂节奏，提高趣味性，根据不同学员灵活调整教学策略。那么接下来，就该真正走进「教师资格证考场」了。不过，教育不是一个有标准答案的任务，Benchmark肯定是行不通。笔试应该如何设计？与爱为舞的做法很简单，甚至有些「粗暴」——笔试啥，直接把AI丢到讲台上，看学员的真实反应。第一步，是在模拟课堂中试水。这个课堂由多类型的模拟学员组成，团队会按照真实分布规律注入一批线上数据，再由评分模型从多个维度对AI导师打分。模拟课堂如果表现不错，AI会迎来更严苛的终极试炼场——直连真实教学一线。AI能否驾驭高度不确定的真实课堂？是否真的能摆脱照本宣科？答案，只能由学员来评判，再好的数据标注导师也帮不了。即便成功拿下了「教师资格证」，但教学，依然是个终身学习的过程。正式上线后，海量的学员数据会被持续建模，AI导师将基于每一位学员的专属档案库，为其定制个性化课程。至此，AI导师才算具备了千人千面的能力。不仅下限有保障，上限也很高。「真人级」AI导师通过「知」与「行」的双重训练，与爱为舞得以将通用大模型，塑造成一个真正懂教学的名师AI模型。然而，再聪明的模型，无法与学员真实互动，最终仍会沦为一颗「缸中之脑」。AI导师需要「耳朵」。作为导师，连学员的问题都听不清楚，最后聊的牛头不对马嘴。不仅显得导师呆若木鸡，学员的积极性也会大打折扣。但现实是，课堂不是录音棚。真实环境往往充斥着噪音，如果有电视，甚至会出现多个人声掺杂在一块的情况。即便能输入干净音频，中国有各种各样的方言，不同学员的咬字发音习惯也不同，识别难度相当高。雪上加霜的是，在传统ASR范式下，输入模型的只是一段孤立的语音，基本没什么上下文。一旦放到教学场景下，AI很容易把同音字混淆。例如，「极限」和「极线」。前者是微积分中的核心概念，后者则属于二次曲线相关的几何术语。二者在语义上截然不同，发音却完全一致，如果没有上下文，仅凭语音几乎无法区分。为解决这个问题，与爱为舞基于其长期积累的教育场景与课堂教学数据，自研了一套多模态语音理解大模型，让语音识别不再只「听声音」，而是能够理解所处的教学上下文。在此基础上，团队进一步自研了声纹降噪模型，可以将学员和家长说话的声音区分开。事实证明，凭借「上下文理解+声纹降噪」，ASR识别效果有了质的飞跃：句准确率从行业内开放API的80%左右的最好效果，大幅度提升至95%以上，接近真人理解识别水平。听清楚学员的问题，思考完毕，下面就该导师开口指点迷津了。目前，行业主流语音合成架构基本都是LLM或者LLM+Flow/Diffusion的方案。真用到课堂里，会暴露出三个问题：人机味明显、不像在上课、不支持双向实时交互。下面看看，与爱为舞是如何迈过这三道坎的。先来最直观的——人机感。在底层架构上，团队采用了LLM+Flow方案，引入了两类speech token：一类负责声音本身的细节，一类负责语义和表达节奏。在此基础上，结合强化学习，可以让AI学会正常说话应有的抑扬顿挫。不过，光会说话可不行，老师上课得有个「老师」的样。为此，团队拿出了大量真实课堂数据，对不同学科、不同导师的讲课方式进行了建模：有的导师说话像机关枪，有的导师则更慢条斯理。落地时，团队还会为每位主讲名师单独设计录制脚本。这样，数据收集效率更高，还能最大程度还原名师声线，保证声音的「质感」。具体效果如何嘛，我们可以一起听听下面这两段音频。（文本：接下来我们看这个题，图中表示水蒸气直接变成冰的过程）这是第三方TTS，不仅表现力较弱，还出现了发音错误，如果是上课很容易出戏。相比起来，这段是不是「活人感」足了很多？这正是自研模型的优势，发音更自然，更稳定，情感表现也更好。至于双向实时交互，AI导师需要边说话边理解学员是否在主动打断询问导师问题，并且做出及时的响应，这是AI导师智能与否最重要的能力之一。为此，团队研发流式语义VAD和打断模型，能够让AI导师实时识别学员是否有真实打断意图，识别准确度可以达到90%以上。而为了让AI导师真正「站上讲台」，团队还为其配套设计了逼真的数字人形象：口型、面部表情与肢体动作高度同步，且支持实时互动。这下，AI导师可算是凑齐了自己的莲藕肉身三件套——「耳朵+嘴巴+身体」。当AI开始具备人的温度，信任才有可能建立，学员也更不容易分心。百万AI学习原住民话说回来，即便「大脑、耳朵、嘴巴」全部补齐，我们依然无法解释与爱为舞是如何实现规模化落地的。毕竟，从语音识别，到模型思考，再到语音合成，最后还要驱动真人级数字人，这条服务链路相当长。任何一个环节稍有迟滞，都会严重影响学员的课堂体验。而当用户规模放大，「千人千面」会带来更高频的推理请求，一旦调度或资源分配稍有不慎，服务质量会迅速下滑。想要实现大规模落地，AI导师还需要一颗能持续供血、且足够强健的「心脏」。首先，得把这条冗长的服务链疏通，保证「血管」里不堵。在《思考，快与慢》中，Daniel Kahneman提出，大脑为了偷懒，演化出了两套工作模式：靠直觉行事的「系统一」、调用认知资源的「系统二」。与爱为舞借鉴的，正是这一点。当学员开口提问时，系统不会一股脑把问题全丢给大模型，而是先做一次判断：能马上回答的，直接走快速通道；真正需要推理的，再交给大模型慢慢想。具体而言，简单问题会先由快速回答系统给出反馈；与此同时，大模型已经在后台并行启动。等学员听完前半句，模型的「思考」也完成了一大半。于是，模型回复的延迟可压缩到100ms以内，整条响应链路稳定在1–1.5秒。同理，如果学员在导师讲话时突然插话，AI也不会傻等学员全部说完再思考。而是立刻结合上下文判断学员的意图，提前开始构思。这样响应时间仍可控制在100–200ms，整条链路不超过1.6秒。当然，遇到一些开放式问题，确实要多想一会儿。但即便如此，AI导师也不会「卡住不动」，而是通过表情变化、过渡性话语告诉学员：我在想，你稍等。而不是空气突然安静，一人一AI面面相觑。血管疏通之后，还可以通过「提前缓存」，让血液循环得更顺畅一些。在真实教学中，同一堂课的核心知识点其实相对固定。哪怕学员的具体问题不同，总体来看仍有一定规律可循。先从输入说起。大模型在生成答案前，要先「读懂问题」（prefill），再「组织回答」（decode）。而前者非常吃算力，并且很耗时间。团队的做法是，把Prompt结构化：在不影响回答质量的前提下，把同一类场景里老是出现的内容集中起来，从而让AI少做重复阅读。再看输出。学员千差万别，但在具体知识点上，很多人其实都是在同一个地方「栽跟头」。既然如此，AI导师就没必要每次都从头生成一整套讲解。因此，团队会以题目、引导方式和学员回答作为索引，把模型的讲解结果先存下来。一旦再次遇到相同情形，直接拿来用就好。通过这套「链路优化+缓存」的组合拳，与爱为舞将整个流程控制在了1s-1.6s之间。筋骨与脉络就位，接下来，该让心脏泵得更有力了，与爱为舞在大规模并发上也做了大量工作。首先在单机上，为了榨干每一张GPU，团队在系统设计之初就完成了显存地址的统一规划，全程实现显存共享，尽量避免数据在不同计算与存储介质间反复搬运所带来的性能损耗。与此同时，在GPU算子层面，团队又针对核心计算路径进行了专项加速，使单卡的有效吞吐能力提升约5倍，足以支撑起几十路真人级数字人的推理。其次在集群上，资源的调度能力同样至关重要。团队又从五个层面，对整体系统做了进一步加固：多数字人统一调度：同一个资源池中不同形象统一调度，从而更好的复用集群资源；系统抽象：对话轮次化、课节内容组件化、知识点任务化，让复杂流程标准化；并行计算：尽量不浪费任何空闲算力，AI导师还在讲上一题时，下一题的计算已经在后台悄然启动；预留容量：服务支持横向扩容，不同层级配有多种缓存与缓冲机制，一层层削薄高峰流量，避免高并发请求同时压向模型与数据库；保险机制：整个教学调度过程可恢复，即便遭遇网络中断或客户端异常退出，教学状态也不会丢失。凭借一台全速运转的AI发动机，加上一张巨大的工程降落伞，与爱为舞得以把AI导师「空投」到全国各地，成为业界首个支持万人并发的真人级AI教学系统。归根结底，与爱为舞从未将AI视作一个简单的辅助工具。在他们看来，比起技术升级，AI更像一场关于个体工作逻辑与组织管理范式的深层重塑。回头看今天的企业形态，其实很多都是工业时代的妥协产物：人的精力有限，只能把分工越拆越细，组织层级上层层加码。一道道庞大的部门墙，虽防止了团队混乱，但也淹没了许多人才的主观能动性。AI的出现，第一次让生产力得到完全释放，每个人都能担任「架构师」。在此背景下，与爱为舞提出「全员皆超级个体」——只要有想法，任何人都可以手握数据与算力这两栋「粮仓」，调度一支由智能体组成的硅基军团，以极低的成本，快速实现抢跑。而这一理念，也已在产品上得到验证——至今，「爱学」已服务百万级用户，学员分布于全国342个城市：东至佳木斯，西达克孜勒苏，南抵三沙，北至大兴安岭。关于AI原生的企业理念，市场已经给出了自己的判断。而当AI真正开始惠及百万学员，我们或许终于有机会，兑现孔夫子两千多年前所期待的那个美好愿景——「有教无类、因材施教」。版权所有，未经授权不得以任何形式转载及使用，违者必究。与爱为舞JayMiniMax作价461亿港元募资46亿，1月9日敲钟代码001002025-12-31良心老黄不搞硅谷资本家那套！Groq人均套现500万美元2025-12-29老黄200亿「钞能力」回应谷歌：联手Groq，补上推理短板2025-12-28特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了2025-12-26扫码分享至朋友圈热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-266999起！小米史上最贵Ultra来了：告别256G，影像硬刚iPhone 17 Pro Max2025-12-25太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26AI金矿上打盹的小红书，刚刚醒了一「点点」2025-12-26",
      "article_url": "https://www.qbitai.com/2025/12/366239.html",
      "author": "Jay",
      "publish_time": 1767024000,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"与爱为舞\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767136634,
      "last_modify_ts": 1767223093
    },
    {
      "id": 13,
      "article_id": "366357",
      "title": "真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Image",
      "description": "真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Imagehenry2025-12-3120:39:47来源：量子位12月31日，阿里正式开源新一代图像生成模型Qwen-Image-2512，实现人物肌肤质感、自然纹理还原与复杂文字渲染的大幅提升。仅需输入文字指令，新模型即可生成“零AI味”的高质量图片，人物发丝都清晰可见，堪比专业摄影师拍的真实照片。同时，千问新模型支持流畅生成漫画风格P",
      "content": "真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Imagehenry2025-12-3120:39:47来源：量子位12月31日，阿里正式开源新一代图像生成模型Qwen-Image-2512，实现人物肌肤质感、自然纹理还原与复杂文字渲染的大幅提升。仅需输入文字指令，新模型即可生成“零AI味”的高质量图片，人物发丝都清晰可见，堪比专业摄影师拍的真实照片。同时，千问新模型支持流畅生成漫画风格PPT、数据信息图等复杂图像，可满足专业设计场景下的多样化需求。Qwen-Image-2512是8月发布的Qwen-Image图像生成基座模型的迭代版本，实现了性能的大幅提升。在聚焦文生图的AI Arena评测中，开发者对模型进行了超万轮盲测，Qwen-Image-2512位居开源模型榜首。具体测试结果显示，该模型在图像生成的真实度，语义遵循的准确度上表现卓越，不仅大幅领先其他开源模型，更在与多个闭源商用模型的对比中展现出强劲竞争力。从模型效果上看，全新的Qwen-Image-2512大幅降低了大模型生成图像的“AI感”。在人物面部细节、皮肤纹理、发丝刻画上，新模型效果显著，无论是人物眼角的细纹、风吹起发丝的方向，还是宠物柔软蓬松的毛发、湖面折射的环境倒影，千问新模型都能精准还原，效果接近相机实拍。不仅如此，新模型还能轻松驾驭复杂的视觉创作需求，一键生成媲美专业设计师水准的四格漫画风PPT、高质量信息图等。据了解，目前千问图像模型已形成多款多功能的完整矩阵，包含基座模型Qwen-Image、图像编辑模型Qwen-Image-Edit、图层编辑模型Qwen-Image-Layered等，涵盖不同场景与精度需求。三大模型系列均已在魔搭社区和HuggingFace开源，开发者和企业可免费下载商用，也可通过阿里云百炼调用模型API服务，普通用户可以在千问APP直接体验新模型，感受“零AI感”的高保真图像生成体验。截至2025年底，阿里总共开源近400个千问Qwen模型，全球下载量超7亿，衍生模型数量突破18万，是全球第一开源大模型。阿里千问大模型服务超100万家客户，在中国企业级大模型调用市场中位居第一，是中国企业选择最多的大模型。（完）版权所有，未经授权不得以任何形式转载及使用，违者必究。阿里henry从“手工艺”到“AI工程化”：解码AI智能渗透的未来之战2025-12-31华为云CEO周跃峰：要避免AI成为“泡沫” 必须要提升行业生产力2025-12-30SGLang原生支持昇腾，新模型一键拉起无需改代码2025-12-21智谱IPO敲钟前，连夜把开源编程大模型SOTA了2025-12-23扫码分享至朋友圈相关阅读阿里安全揭示：恶意邮件可致macOS/iOS瞬间瘫痪！畸形证书发现密码库新漏洞已获得“黑客界奥斯卡”提名时令2025-07-31安全阿里用155万模拟视频给模型上课！GVE模型一次学会9种视频检索技能为视频检索从”窄域专用”迈向”通用智能”奠定方法论基础henry2025-11-14阿里阿里安全开源隐私计算新技术：计算速度快20倍，通信成本低2倍，已登安全顶会比微软的ryptFlow2还快博雯2022-03-05阿里阿里达摩院提出时序预测新模型 精准预测电网负荷阿里提出时序预测新模型,论文入选顶会ICML2022量子位2022-07-12AI时序预测机器学习阿里达摩院突破冯·诺依曼架构性能瓶颈，新型AI芯片性能提升10倍在特定AI场景中，该芯片性能提升10倍以上，能效比提升高达300倍。允中2021-12-03芯片达摩院阿里Canalys发布2019 Q4中国云市场报告：阿里腾讯百度位居前三鱼羊2020-03-23云服务腾讯阿里热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26AI金矿上打盹的小红书，刚刚醒了一「点点」2025-12-26特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了2025-12-26",
      "article_url": "https://www.qbitai.com/2025/12/366357.html",
      "author": "henry",
      "publish_time": 1767110400,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"阿里\", \"安全阿里\", \"阿里\", \"阿里\", \"AI时序预测机器学习阿里\", \"芯片达摩院阿里\", \"云服务腾讯阿里\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767193254,
      "last_modify_ts": 1767309496
    },
    {
      "id": 19,
      "article_id": "366290",
      "title": "国产智能体MasterAgent 12月30日全面开放，赋能多场景应用",
      "description": "国产智能体MasterAgent 12月30日全面开放，赋能多场景应用量子位的朋友们2025-12-3111:13:09来源：量子位具备全栈自主研发技术2025年12月30日，深元人工智能研发的L4级智能体母体系统MasterAgent正式全面开放。这款具备全栈自主研发技术的智能体系统，将进一步推动国内智能体赛道发展，为各行业数字化转型注入新动力。全链条国产化布局，筑牢安全可控防线MasterAg",
      "content": "国产智能体MasterAgent 12月30日全面开放，赋能多场景应用量子位的朋友们2025-12-3111:13:09来源：量子位具备全栈自主研发技术2025年12月30日，深元人工智能研发的L4级智能体母体系统MasterAgent正式全面开放。这款具备全栈自主研发技术的智能体系统，将进一步推动国内智能体赛道发展，为各行业数字化转型注入新动力。全链条国产化布局，筑牢安全可控防线MasterAgent的全面开放，有着明确的实际应用价值。该产品自研发之初便聚焦“安全可控”目标，由全链路国产研发团队历时数年打造，构建起覆盖底层芯片适配、基础架构搭建、核心算法框架设计及训练数据采集标注的全链条国产化技术体系。这套技术体系摆脱了对海外开源框架、核心算法及高端算力的依赖，还能通过自主适配层技术兼容国内主流软硬件，形成端到端的国产化闭环能力。这一特点能够满足政府机构、金融、能源等关键领域对数据安全、隐私保护及政策合规的需求，规避海外技术卡脖子风险，同时填补了国内高端多智能体协作平台的市场空白。据悉，MasterAgent推出的智能知识库功能，基于大语言模型构建知识管理系统，可实现个人与企业文档的统一存储、智能检索及结构化管理，既能作为高效信息管理工具，也能为智能体执行复杂任务提供精准知识支撑，提升多智能体协作的专业性和可靠性。框架式创新突破，跨行业落地成效显著技术架构上，MasterAgent采用框架式设计，具备较强的灵活适配性。无需复杂编程操作，仅通过自然语言指令，就能在分钟级内生成多智能体集群，还支持无限场景拓展。目前，这一技术优势已在多个行业落地见效：为博威集团打造的营销智能体，构建了“AI+人”洞察平台，帮助业务员提升专业营销能力；在法律领域开发的“力哥易法务智能体”，可通过多智能体协同，高效处理合同审核、案例检索等核心法律事务。在此前的限量公测阶段，MasterAgent已服务海尔集团、广汽集团、区域性海关等上百家政企客户，其一键生成多智能体集群、智能体自主专业协作、灵活定制调优三大核心功能获得市场认可。此次全面开放后，服务范围进一步扩大，个人用户及中小微企业均可接入平台，享受智能体定制、私有化部署等全链条服务，既降低了高端智能体的使用门槛，也推动国产智能体从高端市场向大众市场渗透，加速AI生产力普及。重大场景+权威认可，技术实力获全球关注MasterAgent的技术实力已通过重大场景和行业权威双重验证。作为十五运会开幕式指定AI Agent技术主服务商，该系统自主生成174米AI数字长卷《璀璨大湾区》，成为开幕式视觉亮点；近期还为第二十七届冰雪大世界开幕式创作动态电子画卷，以油画风格呈现冰雪景观，实现与全运会数字长卷的艺术联动。行业荣誉方面，深元人工智能近期收获多项认可，先后入选“中国AI Agent企业商业落地TOP20”、量子位智库2025Q3「AI100」创新产品榜，斩获量子位“年度潜力2025人工智能创业公司”、亿欧“2025中国AI AGENT服务商TOP20”及高交会“优秀科技创新企业奖”，12月25日又跻身第一新声“高科技高成长新锐企业榜TOP30”，吸引了包括吉姆·罗杰斯在内的全球顶尖投资者考察交流，国产智能体的技术与商业潜力获得国际关注。国产力量突围，助力AI产业升级此次MasterAgent全面开放，是国产智能体技术走向规模化应用的重要一步。未来，深元人工智能将持续深耕技术创新，不断拓展MasterAgent在各领域的应用场景与能力，推动国内AI产业从“工具执行”向“成果交付”升级，助力更多行业实现高效智能化转型。版权所有，未经授权不得以任何形式转载及使用，违者必究。Agent量子位的朋友们美国《连线》杂志：再见，GPT5；你好，千问！2025-12-29从单点突破到一体多端：拆解天禧AI 3.5进化背后三年的进化哲学2025-12-26全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26原力灵机提出GeoVLA：让机器人看懂三维世界，打破2D视觉枷锁2025-12-24扫码分享至朋友圈相关阅读OpenAI翁丽莲的Agent公式，一定是正确的吗？“Agent最重要的能力是和环境的互动能力”衡宇2024-01-08AgentAI腾讯智能体开源大动作！关键技术都拿出来了，开发平台还全面升级明敏2025-09-22Agent腾讯云阿里全新Agent玩转手机：刷短视频自主点赞评论，还学会了跨应用操作操作效率已达人类80%克雷西2024-02-02Agent围绕多智能体黑箱非凸优化共识难题，华南理工大学团队发表系列研究多智能体系统分布式共识优化西风2025-04-17Agent分布式进化计算这届国产AI真的可以！20分钟生成万字报告，附带可视化网页，可直接下载食用最强国产Deep Research上新衡宇2025-05-26AgentAI应用小白研报问小白清华唐杰：领域大模型，伪命题8个方面的新感悟衡宇2025-12-26AgentAI清华唐杰热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26AI金矿上打盹的小红书，刚刚醒了一「点点」2025-12-26特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了2025-12-26",
      "article_url": "https://www.qbitai.com/2025/12/366290.html",
      "author": "量子位的朋友们",
      "publish_time": 1767110400,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"Agent\", \"AgentAI\", \"Agent腾讯云\", \"Agent\", \"Agent分布式进化计算\", \"AgentAI应用小白研报问小白\", \"AgentAI清华唐杰\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767193262,
      "last_modify_ts": 1767309504
    },
    {
      "id": 22,
      "article_id": "366280",
      "title": "从“手工艺”到“AI工程化”：解码AI智能渗透的未来之战",
      "description": "从“手工艺”到“AI工程化”：解码AI智能渗透的未来之战henry2025-12-3115:42:57来源：量子位当AI的浪潮席卷安全领域，攻防的形态正在发生根本性的变革。11月，腾讯云黑客松智能渗透挑战赛决赛落幕，400+顶尖极客用AI智能体上演了一场“无人干预”的巅峰攻防对决，标志着安全攻防正式迈入AI驱动的新质生产力时代。赛后，腾讯云安全作为赛事主办方，邀请赛事评委、高校导师及优秀战队核心成",
      "content": "从“手工艺”到“AI工程化”：解码AI智能渗透的未来之战henry2025-12-3115:42:57来源：量子位当AI的浪潮席卷安全领域，攻防的形态正在发生根本性的变革。11月，腾讯云黑客松智能渗透挑战赛决赛落幕，400+顶尖极客用AI智能体上演了一场“无人干预”的巅峰攻防对决，标志着安全攻防正式迈入AI驱动的新质生产力时代。赛后，腾讯云安全作为赛事主办方，邀请赛事评委、高校导师及优秀战队核心成员，举办了一场名为“冠军之夜”的线上深度复盘。数世咨询创始人李少鹏担任主持，与腾讯云安全总经理谢飞、清华大学副教授陈建军、NeuroSploit战队成员汪琦（清华大学）、hjtuHunter战队队长胡宇睿（西安交通大学）展开了一场长达一小时的深度对话。这次直播，不仅是对赛事的全面复盘，更是一次关于AI如何重塑安全生产力、未来防御体系如何演进、以及顶尖人才如何培养的前沿思想碰撞。对大模型时代来说，一场“全自动”的AI渗透赛意义何在？李少鹏老师介绍说，腾讯云黑客松智能渗透挑战赛是国内首次真正意义上的全自动化AI智能渗透大赛。与以往“人调AI”的辅助模式不同，本次比赛要求选手将程序部署上线后便完全放手，让AI智能体自主完成从探索、规划到利用的全流程。这相当于是对即将到来的智能体时代，进行了前置“压力测试”，一方面考量“行不行”，另一方面也考验“怎么样”。从结果上来看，智能体已经能将大量渗透测试任务理解并完成，从而让“人类”的精力更充分的释放到创造工作中去。作为主办方，腾讯云安全总经理谢飞也提出了举办这次赛事的两个核心目标：一是探索技术前沿的真实水位：网络安全本质是技术对抗。腾讯安全希望摸清“AI+安全”融合后，在自动化攻击/渗透领域，业界究竟发展到了什么水平、遇到了哪些瓶颈、未来有多大比例的工作可以由AI自动完成。二是搭建业界交流与展示的平台：通过腾讯云安全已有的众测平台和沙龙机制，为高校、企业及研究机构提供一个舞台，让大家将一段时间内关于AI与安全融合，特别是自动化攻击的思考和方案“秀出来”。赛事成果远超预期：吸引了全球238支战队、518名选手参与，涵盖了卡内基梅隆大学、清华大学等顶尖高校，以及长亭科技等头部安全企业的战队。谢飞坦言，作为评委，他最大的感受是 “AI在安全领域的发展步伐比想象中快得多”。他原以为技术可能只发展到“第三步”，但实际比赛中选手们的方案已经接近“第五甚至第六步”，许多理论上可行但现实中困难的问题，已被选手们触及并部分解决。技术亮剑：顶尖战队的渗透智能体是如何炼成的？本次比赛的一大亮点是，不仅团队作战成绩斐然，单人战队同样表现惊艳。亚军胡宇睿便是“一人战队”的代表。在直播中，他分享了其“单兵作战”的心得与架构思路：效率杠杆：在AI时代，小团队或个人通过AI杠杆能发挥巨大作用。前十名中不乏单人队伍，这背后是开发范式的转变：人类专家提供核心安全经验与思路，将繁琐的工程化、编程工作交给AI和自动化工具。例如，借助腾讯的成熟框架，一个轻量化应用可能3-5小时就能搭建起来。架构创新：解决“复杂业务场景连贯性”痛点：他的智能体创新点在于针对复杂业务场景的自动化渗透研究。与通用AI智能体更关注记忆和上下文处理不同，他的架构专注于网络安全垂直领域。核心挑战在于，通常针对单个API或单一步骤，难以处理需要多步交互、数据流关联的复杂业务漏洞。他利用大模型理解语义、进行任务规划和代码生成的能力，让AI智能体能够模拟人类，在复杂的业务链路中进行探索，建立不同API之间的数据流、控制流逻辑关系，再调用传统工具进行精准测试。这使得其方案对复杂场景和多种漏洞类型具有更好的泛化能力。冠军战队成员汪琦（清华大学）则从团队协作角度分享了策略：一是以赛代练，验证想法：他们参赛更多是抱着“试水”心态，希望利用公开、公正的数据集，检验自家设计的AI智能体在实际场景中的效果。二是高效基建与内部赛马：团队的优势在于有同学搭建了本地测试环境基建，使得他们能快速在本地迭代原型系统。团队内部采用“赛马”机制，让不同同学尝试不同的策略设计，在本地跑分后选择最优方案上线，甚至在线部署多种策略进行尝试。范式变革：AI给安全攻防带来了什么根本性改变？在过去，安全行业举办过许多传统CTF或Hackathon式的安全攻防大赛。清华大学陈建军副教授点出了本次比赛与传统赛事的区别：一是对参赛选手/战队能力要求发生变化，过去要求“熟练工”，现在要求“创新者”——选手不仅需要懂漏洞挖掘（攻防），还需要掌握大模型开发、智能体编排、提示词工程等AI技能。二是选手/战队的思维模式发生变化，过去传统赛事大多是“解题”式比赛，提前给到题目，大家去回答，最后比拼谁回答的更标准，但其中对创新的要求不足。而本次全自动渗透赛，本质上是在探索前人未解决的问题，是学术前沿的实战化。它要求极高的创新能力。他指出，本次比赛的难度更高，因为靶标是闭源程序，AI能获得的信息更少，而国外同类比赛多基于开源软件。这标志着AI渗透测试正从“辅助工具调用”走向更核心的“自主任务规划与决策”。谢飞说，腾讯云举办本次活动，其背后目的也是想与行业一起探索，大模型时代的到来是否会创造共性技术趋势，背后衍生的变革挑战又需要如何通过生态去“解题”。从赛事结果来看，AI的发展让人震惊，但说到彻底颠覆还为时过早。在未来相当长的一段时间内，人依然会在攻防挑战中扮演“主角”。AI并非万能，传统安全能力仍是基石：得分高的队伍，其优势并非单纯依赖最先进的AI模型，而是将AI与扎实的网络安全基础设施（如精准的扫描器、丰富的知识库）深度融合。脱离传统安全技术的AI是“玩不转”的。工程化能力是关键胜负手：优秀的方案普遍在AI智能体的系统工程化上做得更好。他们将复杂任务分解为子任务，并设计机制确保AI在执行中能“增量式逼近目标”，防止在多轮对话中“失焦”或陷入“状态空间爆炸”。这模拟了人脑解决问题的思维过程，也很好的表现了“人+AI”才是最优解的行业共识。价值导向是落地核心：业界讨论正从“能调用多少工具”（MCP）向“能解决什么具体问题、带来什么业务价值”（Skill）演进。AI在安全领域的落地，最终要看它能否解决真实痛点，而不仅仅是技术炫技。现实与未来：AI能否“取代”渗透测试工程师？关于AI替代人力，谢飞给出了一个大胆而具体的预测：到2026年，许多常规攻击就可能由自动化机器人完成。他透露，已了解到真实入侵事件中，攻击方可能只是一些技术相当初级的爱好者，但借助AI“氛围黑客”工具，却能发起高级别的渗透。这极大地降低了攻击门槛，提升了攻击效率，无形中放大了防守方的压力，变相助推攻击破坏力的增大。（“氛围黑客”指的是利用高度自动化、智能化的工具（尤其是AI大模型驱动的攻击平台或智能体），即使攻击者自身不具备深厚的专业技术知识，也能发起复杂网络攻击的现象。）进攻端，目前AI更多是在模拟人类的渗透流程，越接近人类正常流程，效率越高。大模型的独特优势在于，处理需要理解语义、逻辑连贯的复杂业务场景漏洞，这是传统自动化工具难以做到的。防御端，AI可用于处理海量威胁告警数据，提取真正有价值的信息，进行降噪和初步研判，将安全分析师从繁琐的告警审查中解放出来。但无论是攻还是防，AI的全面接管还存在巨大的挑战—— “最后一公里”仍需人力：无论是传统规则还是AI，在将告警量降到极低（如99.99%）后，最终判断那0.01%是否是真实威胁（漏报），仍然高度依赖人的经验。AI的“幻觉”问题在此场景下尤为致命。场景适用性上，谢飞指出，AI难以处理实时、高吞吐的流量分析（成本、速度不匹配），这部分仍需依赖规则引擎。AI与传统技术是互补关系，而非替代。在可解释性与验证上：陈建军教授指出，当前安全领域追求“可验证的安全”，但大模型的“黑箱”特性使其决策过程难以验证，这是将AI用于关键安全决策时必须面对的的根本性难题。AI的进程已不可逆，当人人都会用AI提效时，个人与企业的核心竞争力将重新定义。是满足于使用AI，还是能设计AI的策略、驾驭AI的工程化、解决AI解决不了的问题？腾讯云安全举办此类赛事，正是为了与业界、学界一同，主动走到变化的前沿，共同探索和定义AI时代的安全新范式。正如李少鹏所言，过去行业谈论“AI来了”，而现在，我们正在亲眼见证并参与塑造 “AI智能安全” 的时代。这场冠军之夜的复盘对话，不是终点，而是一个更智能、更自动化也更具挑战的安全新纪元的开端。版权所有，未经授权不得以任何形式转载及使用，违者必究。henry真如摄影、细至发丝！阿里开源新一代图像生成模型Qwen-Image2025-12-31华为云CEO周跃峰：要避免AI成为“泡沫” 必须要提升行业生产力2025-12-30SGLang原生支持昇腾，新模型一键拉起无需改代码2025-12-21智谱IPO敲钟前，连夜把开源编程大模型SOTA了2025-12-23扫码分享至朋友圈热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26AI金矿上打盹的小红书，刚刚醒了一「点点」2025-12-26特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了2025-12-26",
      "article_url": "https://www.qbitai.com/2025/12/366280.html",
      "author": "henry",
      "publish_time": 1767110400,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767223081,
      "last_modify_ts": 1767309500
    },
    {
      "id": 24,
      "article_id": "366295",
      "title": "有300亿美元也未必“再造GPT-4”？NUS尤洋最新长文：拆穿AI增长瓶颈的真相",
      "description": "有300亿美元也未必“再造GPT-4”？NUS尤洋最新长文：拆穿AI增长瓶颈的真相思邈2025-12-3112:06:58来源：量子位算力还在指数增长，智能却开始“吃不动”了允中 发自 凹非寺量子位 | 公众号 QbitAI2026年将至，ChatGPT发布三周年，但关于“AI瓶颈期”的焦虑正达到顶峰。当全行业都在讨论如何通过量化、蒸馏来“省钱”时，新加坡国立大学校长青年教授、潞晨科技创始人尤洋却",
      "content": "有300亿美元也未必“再造GPT-4”？NUS尤洋最新长文：拆穿AI增长瓶颈的真相思邈2025-12-3112:06:58来源：量子位算力还在指数增长，智能却开始“吃不动”了允中 发自 凹非寺量子位 | 公众号 QbitAI2026年将至，ChatGPT发布三周年，但关于“AI瓶颈期”的焦虑正达到顶峰。当全行业都在讨论如何通过量化、蒸馏来“省钱”时，新加坡国立大学校长青年教授、潞晨科技创始人尤洋却提出了一个更为本质的拷问：如果给你300亿美元预算，今天我们真的能训出比GPT-4强出几个维度的模型吗？在《智能增长的瓶颈》一文中，尤洋教授一针见血地指出：当前智能增长的瓶颈，本质上是我们现有的技术范式，已经快要“消化”不动持续增长的算力了。他提出了几个颠覆常规认知的硬核观点：智能的本质是能源转化：过去10年，AI的本质是将电力通过计算转化为可复用的智能，而转化效率正面临大考。Transformer的秘密：它之所以胜出，并非因为更像人脑，而是因为它是一台“伪装成神经网络的并行计算机”，完美契合了英伟达GPU的堆料逻辑。效率不等于智能：Mamba等新架构提升了吞吐量，但在“算力转智能”的终极上限上，它们真的比Transformer更强吗？未来的出路：抛弃Adam优化器？回归高精度计算（FP32/64）？从电影制作到地震时间预测，我们离真正的AGI还有多远？……这篇深度长文，或许能带你穿透“降本增效”的迷雾，直达算力与智能最底层的逻辑。一起来看。智能的核心不是解释，而是预测什么是智能？尤洋没有照搬任何形式化或哲学化的“智能定义”。相反，他采用了一种非常工程化、面向能力评估的处理方式，通过一组可验证、可实践的判断标准来刻画智能的边界：在关键人生决策上，是否愿意完全听从AI；在高风险、高不确定性领域，是否敢让AI替代专家；在创作层面，是否已经无法分辨作品是否由AI生成；这些例子背后，指向的是同一个核心能力：即对未来状态进行预测，并为预测结果承担实际后果的能力。这一锋利的判断，不仅解释了为什么Next-Token Prediction能在过去几年成为事实上的“智能发动机”，也解释了为何许多“在封闭评测中表现出色”的系统，一旦进入真实世界就迅速暴露短板——它们往往擅长组织与解释已有信息，却难以在不确定环境中对未来做出稳定、可执行的判断。当然，需要强调的是，将智能高度凝聚为“预测”，更像是在给智能划定一个工程上可对齐算力投入的核心能力维度，而非穷尽智能的全部内涵。这是一个足够清晰也足够有解释力的硬核视角。而规划、因果建模以及长期一致性等能力，是否能够完全被还原为预测问题，仍然是一个开放议题。但当我们把智能简化为预测能力时，下一步的问题自然落到：算力是如何转化为这种能力的？预训练、SFT、RL之争，本质上是“算力分配”问题过去几年，行业对训练范式的讨论，常常被“方法论优越感”主导；但如果把目标限定为单位算力能换来多少智能，那么范式本身就不再神秘，而变成了一种算力使用策略。不同于主流叙事，尤洋在文章中直接把预训练、微调、强化学习三者拉到统一层面，即三者本质上都是在计算梯度，更新参数。文章指出，当前模型的主要智能来源，依然是预训练阶段——不是因为它更“聪明”，而是因为它消耗了最多的能源与计算。从智能增长角度看，这三者参数更新发生的频率与更新所消耗的算力规模确有不同，但是通过视角的转换，智能增长的讨论就从方法论之争，转向了一个更朴素，也更残酷的问题——在算力持续投入的前提下，我们是否还能稳定地换取能力增长？Transformer的胜出，不只是算法胜利为了回答这个问题，这篇文章回溯了过去十年大模型快速进化的原因。尤洋指出，这一轮智能跃迁的成立，依赖于三件事情同时发生：一是GPU体系在硬件层面持续提供指数级增长的并行算力；二是Transformer架构在计算结构上天然支持大规模并行，能够充分“吃下”这些算力；三是Next-Token Prediction这一训练目标为模型提供了近乎无限、且高度统一的学习信号。因此，Transformer的成功，并不仅仅是算法层面的胜利，更源于模型架构与硬件体系高度匹配的系统性结果。在这三者共同作用下，算力增长、模型规模扩大与能力提升之间形成了一条相对稳定的正反馈链路。需要注意的是，这一范式的有效性，也在一定程度上受益于语言任务本身的结构特性：语言高度符号化、序列化，且评测体系与训练目标高度一致。这使得算力增长、模型规模扩大与能力提升之间，在这一阶段形成了一条相对稳定的正反馈链路。也正是在这一历史条件下，从GPT-1、GPT-2到GPT-3，再到ChatGPT，智能水平得以沿着同一范式持续抬升。这也自然引出了后文的核心问题：当算力继续增长时，我们是否还拥有同样可扩展的范式？真正的瓶颈，并不是算力停了，而是算力“吃不动”了尤洋在文中提出了一个非常具体、也非常可操作的标准来判断智能的瓶颈：当一次训练的FLOPS从10^n变成10^{n+3}时，我们是否还能稳定地获得显著更强的模型？如果答案开始变得不确定，那么问题就不在于“算力是否继续增长”，而在于：现有范式对新增算力的吸收效率是否下降；计算规模的扩大，是否被通信、同步和系统开销所抵消。这也是文章里反复强调FLOPS的原因：Token数、参数量、推理速度，往往会混合效率与商业因素；而FLOPS才是最底层、也最难被包装或美化的算力尺度。在这个意义上，所谓“瓶颈”，并不是红利消失，而是算力增长与智能增长之间的映射关系开始松动。更值得一提的是，尤洋在文章中刻意把讨论从“效率优化”里拎出来，换了一个更接近一线大厂决策的场景：假设今天Google拍给你一张“300亿美元预算”的支票，给你半年DDL——在这种极限训练目标下，你还会优先选择Mamba这类“吞吐量更高”的架构吗？未必。因为吞吐量解决的是“同等智能更便宜”，不自动等价于“同等成本更聪明”。真正的难点变成：我们到底有没有一种扩展性更强的架构或Loss函数，能把新增算力更稳定地“吃进去”，并把它转换成可兑现的能力增量？那么如何能在单位时间内吃下更多算力，并真正将它转化为智能呢？未来未定，问题的答案可能在多个探索区间内在正式回答算力转化智能的问题之前，尤洋还对硬件与基础设施层面进行了深入的探讨。他根据自身多年的从业经验得出，计算开销/通信开销的比值，必须维持或提升，这样才能在继续堆叠GPU的情况下，线性地换来更多智能。因此，未来AI基础设施的核心目标，应该关注并行计算体系在软硬件层面的整体扩展性，而不仅仅是单点芯片性能。在这一基础上，尤洋最后提出了多个探索方向，比如更高精度、高阶优化器，更可扩展的架构或者Loss函数，更多epoch与更深度的超参数探索。这些探索方向，都在试图回答同一个命题——如何让模型在“吃掉”万亿级投入的同时，吐出等比例增强的智能？对于智能的进一步增长而言，真正重要的，是在极端算力条件下持续变强的能力——这也意味着，预训练所能承载的智能增长空间，可能还远未走到尽头。回到最初讨论的问题，算力到底还能不能继续转化为智能？尤洋并未给出断言，但逻辑已经清晰：只要我们还能找到更高效组织计算的方式，智能的上限就远未到来。原文传送门：https://zhuanlan.zhihu.com/p/1989100535295538013版权所有，未经授权不得以任何形式转载及使用，违者必究。尤洋智能潞晨科技思邈AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品2025-12-29推理成本打到1元/每百万token，浪潮信息撬动Agent规模化的“最后一公里”2025-12-26国产AI4S创业头雁再获8亿投资！深势科技完成C轮，产品已服务300万科学家2025-12-24具身智能的数据难题，终于有了可规模化的解法2025-12-18扫码分享至朋友圈相关阅读杨元庆：联想是一家真正的全球化企业，拥有应对危机的独特竞争力雷刚2020-04-01智能杨元庆联想Sky Computing：利用空间异构分布式计算特性加速联邦学习Sky Computing成功利用空间异构分布式计算特性，在保证用户数据隐私的前提下，可对联邦学习加速达55%，且已开源。量子位2022-02-28潞晨科技联邦学习霉霉用中文拜早年！国风年味视频免费生成，可任意切换主角，0帧起手小白友好画质/运动幅度/风格全面提升明敏2025-01-14video ocean潞晨科技视频生成AI首次实时生成视频！尤洋团队新作，网友：这是新纪元一种免训练新方法一水2024-06-28AI视频生成尤洋潞晨科技尤洋：中小企业同样追求大模型，但最先进AI训练成本还是太高 | MEET 2023未来，我们迫切需要一个可扩展性的高效计算基础设施明敏2022-12-24AI模型MEET2023智能未来大会潞晨科技算法打入AI底层！NUS尤洋团队用扩散模型构建神经网络参数，LeCun点赞比人工训练最高提速44倍衡宇2024-02-25Meta AI尤洋训练提速热门文章全自研仿真GPU求解器x虚实对标物理测量工厂，打造具身合成数据SuperApp，加速具身仿真生态丨光轮智能@MEET20262025-12-26一只大头机器狗供不应求，打响了消费级具身智能第一枪2025-12-26太初元碁与汉腾科技签署五大万卡集群项目建设协议 推动高集成化算力基础设施集群落地2025-12-26AI金矿上打盹的小红书，刚刚醒了一「点点」2025-12-26特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了2025-12-26",
      "article_url": "https://www.qbitai.com/2025/12/366295.html",
      "author": "思邈",
      "publish_time": 1767110400,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"尤洋智能潞晨科技\", \"智能杨元庆联想\", \"潞晨科技联邦学习\", \"video ocean潞晨科技视频生成\", \"AI视频生成尤洋\", \"AI模型MEET2023智能未来大会潞晨科技算法\", \"Meta AI尤洋训练提速\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://zhuanlan.zhihu.com/p/1989100535295538013\", \"url\": \"https://zhuanlan.zhihu.com/p/1989100535295538013\", \"type\": \"social\"}]",
      "add_ts": 1767223084,
      "last_modify_ts": 1767309503
    },
    {
      "id": 26,
      "article_id": "366378",
      "title": "最新英伟达经济学：每美元性能是AMD的15倍，“买越多省越多”是真的",
      "description": "最新英伟达经济学：每美元性能是AMD的15倍，“买越多省越多”是真的梦晨2026-01-0112:49:00来源：量子位一定条件下生成同样数量的token，英伟达的成本只有AMD的十五分之一梦晨 发自 凹非寺量子位 | 公众号 QbitAI为什么AI算力霸主永远是英伟达？不算不知道，一算吓一跳：在英伟达平台每花一美元，获得的性能是AMD的15倍。尽管英伟达卖的更贵，但只要买齐一套，就更省钱。来自S",
      "content": "最新英伟达经济学：每美元性能是AMD的15倍，“买越多省越多”是真的梦晨2026-01-0112:49:00来源：量子位一定条件下生成同样数量的token，英伟达的成本只有AMD的十五分之一梦晨 发自 凹非寺量子位 | 公众号 QbitAI为什么AI算力霸主永远是英伟达？不算不知道，一算吓一跳：在英伟达平台每花一美元，获得的性能是AMD的15倍。尽管英伟达卖的更贵，但只要买齐一套，就更省钱。来自Signal65的一份最新详尽报告揭示了这个现实，一定条件下生成同样数量的token，英伟达的成本只有AMD的十五分之一。这份报告基于SemiAnalysis Inference MAX的公开基准测试数据，时间跨度从2025年10月到12月，覆盖了从密集模型到前沿MoE推理模型的全场景测试。黄仁勋的“买的越多，省的越多”原来是真的。MoE时代：8卡系统撞上Scaling天花板AI模型正在经历一场架构革命，打开Artificial Analysis排行榜就会发现，智能度排名前十的开源模型清一色都是MoE（Mixture of Experts，专家混合）推理模型。另一项来自OpenRouter的数据显示，超过50%的token流量正在被路由到推理模型上。MoE架构的核心思路是把模型参数拆分成多个专门化的“专家”子网络，每个token只激活其中一小部分。以经典的DeepSeek-R1为例，它拥有6710亿总参数，但每个token只激活370亿——这让它能以更低的计算成本提供前沿级别的智能。问题随之而来。当专家分布在多块GPU上时，GPU之间的通信延迟会导致计算单元空闲等待数据，这些空闲时间直接转化为服务商的成本。报告指出，无论是英伟达B200还是AMD MI355X，所有8卡系统在超出单节点规模后都会撞上“扩展天花板”（scaling ceiling）。英伟达GB200 NVL72的解法是把72块GPU通过NVLink连接成一个单一域，提供130 TB/s的互联带宽。在软件层面，整个系统就像一块巨型GPU一样运作。配合英伟达Dynamo推理框架的分离式预填充-解码调度和动态KV缓存路由，这套架构能够有效突破8卡系统的通信瓶颈。模型越复杂，英伟达的优势越明显报告测试了三类典型模型：模型越复杂，英伟达的优势越明显。在密集模型Llama 3.3 70B上，英伟达B200对比AMD MI355X的领先幅度相对温和。在基线交互性（30 tokens/sec/user）下，B200的性能约为MI355X的1.8倍；当交互性要求提升到110 tokens/sec/user时，这一差距扩大到6倍以上。中等规模的MoE模型GPT-OSS-120B开始让差距变得更加显著。这款OpenAI开源模型拥有1170亿总参数，但每个token只激活约51亿参数。在2025年12月的测试数据中，100 tokens/sec/user交互性下B200的性能接近MI355X的3倍。在更符合推理模型需求的250 tokens/sec/user条件下，差距扩大到6.6倍。两个平台的绝对性能相比10月都有显著提升，英伟达的峰值吞吐从约7000 tokens/sec跃升至14000以上，AMD则从约6000提升到8500左右，但相对差距反而拉大了。真正的分水岭出现在前沿推理模型DeepSeek-R1上。这款模型集MoE路由、大参数规模和高强度推理生成于一身，对基础设施的要求极为苛刻。测试结果显示：在25 tokens/sec/user交互性下，GB200 NVL72的每GPU性能是H200的10倍、MI325X的16倍；在60 tokens/sec/user下，相比H200的优势扩大到24倍，相比MI355X达到11.5倍；在75 tokens/sec/user下，GB200 NVL72的性能是B200单节点配置的6.5倍，是MI355X的28倍。更关键的是，GB200 NVL72能够达到竞争平台根本无法企及的水平，在28卡配置下可以输出超过275 tokens/sec/user，而MI355X在相当吞吐水平下的峰值只有75 tokens/sec/user。Token经济学：贵了1.86倍，便宜了15倍直觉上，性能更强的平台应该更贵。事实也确实如此：根据Oracle Cloud的公开定价，GB200 NVL72的每GPU每小时价格为16美元，MI355X为8.60美元，前者是后者的1.86倍。如果参照CoreWeave的定价，GB200 NVL72相比上一代H200的价格也贵了约1.67倍。但报告的计算揭示了一个反直觉的结论：在25 tokens/sec/user交互性下，GB200 NVL72的性能优势为5.85倍，除以1.86倍的价格溢价，每美元性能仍是MI355X的3.1倍。在75 tokens/sec/user交互性下，28倍的性能优势除以1.86倍的价格，每美元性能达到MI355X的15倍，这意味着生成同等数量的token，英伟达平台的成本只有AMD的十五分之一。与上一代产品的对比同样惊人。报告估算在DeepSeek-R1的典型工作负载下，GB200 NVL72相比H200的性能提升约20倍。而GB200 NVL72价格仅上涨1.67倍，换算下来每美元性能提升约12倍，单token成本降至H200的十二分之一。MoE推理让网络成为推理成本的瓶颈，而机柜级的GB200 NVL72恰好解决了这个问题。价值的衡量标准正在从单纯的算力转向“每美元能产出多少智能”。报告在结论中指出，AMD的竞争力并未被完全否定——在密集模型和容量驱动的场景下，MI325X和MI355X仍有用武之地。AMD的机柜级解决方案Helios也在开发中，可能在未来12个月内缩小差距。但就当前的前沿推理模型而言，从芯片到互联到软件的端到端平台设计，已经成为成本效益的决定性因素。参考链接：[1]https://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/版权所有，未经授权不得以任何形式转载及使用，违者必究。英伟达梦晨能文能武！智元首个机器人艺人天团亮相湖南卫视跨年演唱会2026-01-01Hinton加入Scaling Law论战，他不站学生Ilya2026-01-01Manus收购案细节曝光：20亿刀闪电成交，CEO不向亚历山大王汇报2025-12-31揭秘Agent落地困局！93%企业项目卡在POC到生产最后一公里2025-12-25扫码分享至朋友圈相关阅读时代变了！英伟达纳入道琼斯指数，英特尔被取代只有30家能代表美国工商业的上市公司有资格入选。明敏2024-11-02英伟达英特尔道琼斯指数谷歌TPU训练BERT只要23秒，华为AI芯片达国际领先水平，MLPerf v0.7出炉昇腾910性能超英伟达V100晓查2020-07-30AI芯片华为英伟达谷歌英伟达数据被盗后续：黑客用证书将病毒伪装成显卡驱动第三方杀毒软件可破之晓查2022-03-07病毒英伟达黑客NVIDIA何琨：AI视频处理加速引擎TensorRT及Deepstream介绍来自爱奇艺技术沙龙“多模态视频人物识别的关键技术及应用”。智能车参考2019-05-11机器学习英伟达计算机视觉英伟达5090被曝32G大显存、核心是5080的两倍！网友：怕不是B200双芯封装技术下放600W功耗引发热议克雷西2024-09-30英伟达奥特曼：o1仅仅是“推理模型的GPT-2”；黄仁勋：我给你加速50倍暗示o1满血版将在接下来几个月发布梦晨2024-09-19OpenAI英伟达热门文章救命！和漫画角色聊上头了，AI陪伴的新答案有了2025-12-29389万寻找翁荔继任者！OpenAI紧急开招安全防范负责人2025-12-29国资战略入股九章云极 加码先进AI基础设施攻坚2025-12-29美国《连线》杂志：再见，GPT5；你好，千问！2025-12-29良心老黄不搞硅谷资本家那套！Groq人均套现500万美元2025-12-29",
      "article_url": "https://www.qbitai.com/2026/01/366378.html",
      "author": "梦晨",
      "publish_time": 1767196800,
      "publish_date": "2026-01-01",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "category": "资讯",
      "tags": "[\"英伟达\", \"英伟达英特尔道琼斯指数\", \"AI芯片华为英伟达谷歌\", \"病毒英伟达黑客\", \"机器学习英伟达计算机视觉\", \"英伟达\", \"OpenAI英伟达\"]",
      "cover_image": "",
      "source_keyword": "qbitai",
      "is_original": 1,
      "reference_links": "[{\"title\": \"https://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/\", \"url\": \"https://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/\", \"type\": \"external\"}]",
      "add_ts": 1767309494,
      "last_modify_ts": 1767395861
    }
  ],
  "company_article": [],
  "aibase_article": [
    {
      "id": 2,
      "article_id": "aibase_24054",
      "title": "2.6B Parameters Outperform Billion-Level Giants! Liquid AI Releases New Experimental Model LFM2-2.6B-Exp",
      "description": "On Christmas Day, the renowned edge AI startup Liquid AI officially released its latest experimental model, LFM2-2.6B-Exp. This small open-source model with onl",
      "content": "On Christmas Day, the renowned edge AI startup Liquid AI officially released its latest experimental model, LFM2-2.6B-Exp. This small open-source model with only 2.6B (26 billion) parameters performed outstandingly in multiple key benchmark tests, especially excelling in instruction following, surpassing DeepSeek R1-0528, which has hundreds of billions of parameters. It has sparked widespread discussion in the industry and is hailed as the \"strongest 3B model.\"Model Background: Experimental Breakthrough Driven by Pure Reinforcement LearningLFM2-2.6B-Exp is based on the 2.6B foundation model of Liquid AI's second-generation Liquid Foundation Models (LFM2) series. It was optimized through pure reinforcement learning (RL), without requiring supervised fine-tuning warm-up or large teacher model distillation. The model inherits the advantages of LFM2's hybrid architecture, combining short-range gated convolution and grouped query attention (GQA), supporting a 32K context length, and is designed for edge devices such as smartphones, laptops, and IoT devices, achieving efficient local deployment.Liquid AI emphasized that this experimental checkpoint mainly focuses on optimizing instruction following, knowledge question answering, and mathematical reasoning, suitable for agent workflows, RAG retrieval, data extraction, creative writing, and multi-turn dialogues.Performance Highlights: Big Power from a Small SizeIn the latest benchmark tests, LFM2-2.6B-Exp showed amazing performance:- IFBench (Instruction Following Benchmark): Scored significantly ahead of similar models, even surpassing DeepSeek R1-0528, which has 263 times more parameters.- GPQA (Graduate-Level Knowledge Question Answering): Reached approximately 42%, far exceeding traditional 3B models.- IFEval (Strict Instruction Following): Exceeded 88%, defeating many models with over 10B parameters.- GSM8K (Mathematical Reasoning): Scored above 82%, outperforming Llama3.23B and Gemma3 series.Additionally, the model's prefilling and decoding speed on CPU is twice that of competitors, with extremely low memory usage and support for bfloat16 quantization, truly achieving \"PhD-level reasoning on a smartphone.\"Open Source Significance: Accelerating the Popularization of Edge AILFM2-2.6B-Exp is fully open source, with model weights uploaded to the Hugging Face platform, allowing developers to freely download and integrate it into local applications. This not only demonstrates the huge potential of reinforcement learning on small models but also further promotes the development of the edge AI ecosystem, making high-performance AI accessible from the cloud to every device.AIbase Comment: The release of LFM2-2.6B-Exp marks the acceleration of the era of small models: no need for massive parameters, advanced performance can be achieved through intelligent training paradigms. For developers and enterprises pursuing privacy, low latency, and low cost, this model is undoubtedly one of the best choices at present. In the future, as RL technology and hybrid architectures continue to evolve, 3B open-source models may approach AGI levels and run smoothly on any device. Interested readers can immediately go to Hugging Face to download and experience it, opening a new chapter in edge intelligence.Address: https://huggingface.co/LiquidAI/LFM2-2.6B-Exp",
      "article_url": "https://www.aibase.com/news/24054",
      "author": "AIbase",
      "publish_time": 1766988464,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AI Terminology\", \"LFM2-2.6B-Exp\", \"LiquidAI\", \"Reinforcement Learning\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://huggingface.co/LiquidAI/LFM2-2.6B-Exp\", \"url\": \"https://huggingface.co/LiquidAI/LFM2-2.6B-Exp\", \"type\": \"code\"}]",
      "add_ts": 1766988464,
      "last_modify_ts": 1766988464
    },
    {
      "id": 4,
      "article_id": "aibase_24042",
      "title": "Stand Up to Doubao! Lenovo's Strategic AI Exposed at CES: The Super Intelligent Agent That Integrates PC and Mobile Ecosystems Is Here",
      "description": "According to AIbase, Lenovo Group plans to officially launch its first strategic application for the global market - \"AI Super Agent\" during the upcoming CES. T",
      "content": "According to AIbase, Lenovo Group plans to officially launch its first strategic application for the global market - \"AI Super Agent\" during the upcoming CES. This move marks Lenovo's comprehensive effort in AI applications, with its goal directly targeting ByteDance's recently popular \"Douba Mobile Assistant\". Although the official name of this agent has not been announced yet, according to insiders close to Lenovo, its functionality and ecological coordination capabilities are stronger than Douba.Different from common single voice assistants on the market, this super agent from Lenovo is defined as a system-level application. It is not an independent operating system, but has the core central function of connecting different AI capabilities and multiple hardware terminals. This agent completely integrates Lenovo's hardware ecosystem, enabling seamless connectivity between Motorola phones, Lenovo PCs, tablets, and wearable devices. This cross-device and cross-system feature means users can interact through text, voice, or even environmental perception in multi-terminal environments, and the agent will deeply learn and adapt to the user's personal habits over time.In terms of competitive landscape, Lenovo demonstrates unique advantages as a hardware giant. At the beginning of this month, ByteDance jointly launched with ZTE a \"Douba Mobile Phone\" that has cross-application calling capabilities, helping users complete tasks such as ordering takeout, booking flights, and replying to messages. However, as the leading PC company with a global market share of 25.5%, Lenovo's Motorola phones have also exceeded 16 million units in quarterly shipments.This solid hardware foundation allows the Lenovo Super Agent to have deeper system-level embedded permissions on both phones and PCs. Compared to ByteDance's cross-industry cooperation model, Lenovo can start from the underlying hardware to more efficiently coordinate multiple intelligent agents in the background, thus achieving a more comprehensive user experience in cross-device connection and task scheduling.",
      "article_url": "https://www.aibase.com/news/24042",
      "author": "AIbase",
      "publish_time": 1766988470,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AI Super Intelligent Agent\", \"Lenovo Group\", \"ByteDance\", \"CES\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1766988470,
      "last_modify_ts": 1766988470
    },
    {
      "id": 5,
      "article_id": "aibase_24035",
      "title": "ChatGPT Will Launch Skills! OpenAI's Internal Codename: Hazelnut - Composable, Portable, Supports Code, May Launch in Early 2026",
      "description": "OpenAI is quietly building a new \"capability operating system\" for ChatGPT. According to a recent disclosure by BleepingComputer, OpenAI has been internally tes",
      "content": "OpenAI is quietly building a new \"capability operating system\" for ChatGPT. According to a recent disclosure by BleepingComputer, OpenAI has been internally testing a new feature called \"Skills\" (Skills), which shares a similar design philosophy with Anthropic's Claude Skills, but emphasizes modularity, executability, and cross-platform reusability. This feature, codenamed \"hazelnuts\" (hazelnuts), is expected to be officially launched around January 2026, and could revolutionize the way users collaborate with AI.Skills ≠ GPTs: From \"Custom Assistant\" to \"Capability Module\"Currently, ChatGPT's GPTs rely on prompt engineering to encapsulate specific functions, while Skills are more fundamental pre-trained capability units: - Organized in folders, including instructions, context, examples, and even executable code; - Automatically identified, dynamically loaded, and combined by AI during tasks; - Support converting existing GPTs into Skills with one click, achieving capability accumulation and reuse.For example, users can create a \"Financial Analysis Skill,\" embedded with Python scripts, financial report parsing rules, and visualization templates. When asked, \"Analyze this financial report trend,\" ChatGPT automatically calls this Skill, runs the code, generates charts, and provides an analysis—without needing to repeatedly describe the request or manually paste the code.Four Core Features Define a New Standard for AI Capabilities1. Composability: Multiple Skills can be used together, such as \"Translation + Legal Review + Contract Generation\" to form a compliance workflow for international expansion; 2. Portability: Built once, usable across ChatGPT Web, mobile, API, and third-party applications; 3. Efficiency: Loaded on demand, avoiding redundant calculations of the full model; 4. Scalability: Supports encapsulating multimodal capabilities such as text, tool calls, and code snippets.Interaction Method Revealed: Slash Commands + Visual EditorAccording to UI screenshots leaked on social platforms, Skills will be quickly accessible via slash commands (e.g., \"/financial-analysis\") and come with a visual editor that allows users to drag-and-drop modules, write logic, and test effects, greatly lowering the development barrier.Why Now? To Compete in the Agent EcosystemAs AI agents become the industry focus, OpenAI is accelerating its transition from a \"dialogue model\" to a \"programmable intelligent platform.\" The Skills mechanism will allow developers to build complex agents like building blocks, while ordinary users can also access professional capabilities through shared skill libraries—this is a key move for OpenAI to compete against Claude, Gemini, and open-source agent frameworks.",
      "article_url": "https://www.aibase.com/news/24035",
      "author": "AIbase",
      "publish_time": 1766988472,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"OpenAI\", \"ChatGPT\", \"Skills\", \"AI Terms\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1766988472,
      "last_modify_ts": 1766988472
    },
    {
      "id": 7,
      "article_id": "aibase_24026",
      "title": "Xiaohongshu Open Sources InstanceAssemble! A Lightweight Layout-Controlled Generation Framework, Further Breaking the Accuracy of Complex Multi-Instance Image Generation",
      "description": "At a critical stage where AIGC moves from \"free creation\" to \"precise control,\" the Xiaohongshu AIGC team has open-sourced its new layout-controllable image gen",
      "content": "At a critical stage where AIGC moves from \"free creation\" to \"precise control,\" the Xiaohongshu AIGC team has open-sourced its new layout-controllable image generation framework, InstanceAssemble, specifically designed to address Layout-to-Image tasks with high density, multiple objects, and complex spatial relationships. The framework significantly improves spatial alignment accuracy and semantic consistency while maintaining a minimal parameter increase (as low as 0.84%), offering an industrial-level solution for high-demand scenarios such as e-commerce, design, and gaming. Cascade Modeling + Assemble-Attention, Solving the \"Multiple Objects Stacked\" Challenge Traditional Layout-to-Image models often encounter issues like object misalignment, overlapping, or semantic mismatch when dealing with complex layouts such as \"10 product icons + text labels + background layers.\" InstanceAssemble innovatively adopts a cascade two-stage architecture: 1. Semantic Understanding Stage: Analyzing the semantic relationship between text descriptions and layout instructions; 2. Spatial Assembly Stage: Dynamically modeling the relative positions, occlusion relationships, and hierarchical structures between instances through the self-developed Assemble-Attention mechanism, ensuring that each element is \"where it should be.\" Experiments show that in scenarios such as dense product displays, multi-character illustrations, and UI generation, InstanceAssemble significantly outperforms existing methods in object positioning accuracy and edge clarity. Ultra-lightweight Adaptation, Compatible with Mainstream Base Models To reduce deployment barriers, the framework uses an ultra-lightweight LoRA adapter: - Adapting Stable Diffusion3-Medium requires only 3.46% additional parameters; - For Flux.1 model, it's as low as 0.84%. This means users don't need to retrain large models, and can retain the powerful generation capabilities of the base model while flexibly injecting layout control abilities, supporting multimodal instructions such as text, reference images, and bounding boxes. Self-built DenseLayout Benchmark, Promoting Evaluation Standardization To accurately measure layout alignment quality, Xiaohongshu also released the DenseLayout evaluation dataset and the LGS (Layout Grounding Score) explainable metric. LGS quantifies the generation results from three dimensions: position accuracy, scale matching, and semantic consistency, solving the problem of traditional metrics (such as IoU) being inaccurate in dense scenarios. AIbase believes that the release of InstanceAssemble marks that AIGC is moving from \"looking good\" to \"placing accurately.\" When AI can not only generate beautiful images but also \"place\" each element according to precise layout instructions from designers, AIGC truly has the capability to integrate into professional production processes. Xiaohongshu's open-source initiative not only empowers community creators but also drives the entire industry toward controllable, reliable, and commercializable generative AI. Paper Link: https://arxiv.org/abs/2509.16691 Project Page: https://github.com/FireRedTeam/InstanceAssemble",
      "article_url": "https://www.aibase.com/news/24026",
      "author": "AIbase",
      "publish_time": 1766988478,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AIGC\", \"InstanceAssemble\", \"Controllable Image Generation\", \"Layout-to-Image\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://arxiv.org/abs/2509.16691\", \"url\": \"https://arxiv.org/abs/2509.16691\", \"type\": \"paper\"}, {\"title\": \"https://github.com/FireRedTeam/InstanceAssemble\", \"url\": \"https://github.com/FireRedTeam/InstanceAssemble\", \"type\": \"code\"}]",
      "add_ts": 1766988478,
      "last_modify_ts": 1766988478
    },
    {
      "id": 8,
      "article_id": "aibase_24024",
      "title": "5-Minute Mastery: Study Finds Humans Can Detect AI-Generated Faces Through Targeted Training",
      "description": "With the rapid development of generative AI technology, AI-generated \"fake faces\" have become almost indistinguishable from real ones. However, a recent study p",
      "content": "With the rapid development of generative AI technology, AI-generated \"fake faces\" have become almost indistinguishable from real ones. However, a recent study published in \"Royal Society Open Science\" brings good news: the ability to identify AI-fabricated faces can be significantly improved through short-term training.This research, conducted by several universities including the University of Leeds and the University of Reading, invited 664 participants to distinguish between face images generated by the StyleGAN3 system. The experimental results showed that without any training, the accuracy of ordinary people was only 31%, and even for those with natural talent as \"super face recognizers,\" the accuracy was only 41%. This indicates that human intuition is often unreliable when facing the most advanced AI generation technologies.Surprisingly, researchers found that just a 5-minute targeted visual training session could significantly improve identification results. After learning how to observe abnormal tooth arrangements, unnatural hairlines, and asymmetrical ears or accessories, the accuracy of super face recognizers increased to 64%, while the accuracy of ordinary people rose to 51%.Dr. Eilidh Noyes from the University of Leeds pointed out that as the barriers to creating AI images are lowering and their concealment is increasing, developing effective identification methods has become an important issue in the field of security. Currently, AI-generated faces are often used to forge social media accounts, create fake documents, and even attempt to bypass identity verification systems. The research team will further explore the durability of this training effect and try to combine the visual advantages of humans with AI automated detection tools to address the growing digital security challenges.Paper link: https://dx.doi.org/10.1098/rsos.250921Key Points:🕵️‍♂️ Identify Flaws: AI-generated faces often reveal clues in details such as tooth arrangement, hairline edges, and ear symmetry.⏱️ Short Training Works: Just about 5 minutes of targeted learning can significantly improve the ability of both ordinary people and professional face recognizers to identify AI images.🛡️ Address Security Risks: This study aims to prevent real-world security threats such as social fraud and identity verification bypass using AI fake faces.",
      "article_url": "https://www.aibase.com/news/24024",
      "author": "AIbase",
      "publish_time": 1766988480,
      "publish_date": "2025-12-29",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Generative Artificial Intelligence\", \"StyleGAN3\", \"AI-Generated Faces\", \"Facial Recognition Skills\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://dx.doi.org/10.1098/rsos.250921Key\", \"url\": \"https://dx.doi.org/10.1098/rsos.250921Key\", \"type\": \"external\"}]",
      "add_ts": 1766988480,
      "last_modify_ts": 1766988480
    },
    {
      "id": 9,
      "article_id": "aibase_24094",
      "title": "AI Programming Assistant Upgraded Again: Windsurf Wave13 Officially Released, SWE-1.5 Model Offered Free for a Limited Time",
      "description": "Renowned AI programming tool Windsurf has officially released the Wave13 version, codenamed \"Shipmas.\" This update focuses on three core dimensions: model capab",
      "content": "Renowned AI programming tool Windsurf has officially released the Wave13 version, codenamed \"Shipmas.\" This update focuses on three core dimensions: model capabilities, multi-agent collaboration, and terminal experience, aiming to further solidify its positioning as an IDE centered around agents.In terms of models, Windsurf Wave13 sets the \"Penguin Alpha\" SWE-1.5 model as the default option. This model offers performance at the SWE-Bench-Pro level, capable of handling more complex code reasoning and generation tasks. To reward developers, Windsurf has announced that for the next three months, it will offer free access to the standard version of SWE-1.5 to all users.To address the pain points of multi-task collaboration, the new version introduces **Parallel Agents** support. By integrating Git Worktree, multiple AI agents can operate in parallel across different work trees within the same repository without interfering with each other. This means developers can simultaneously launch tasks such as bug fixing, documentation writing, and test generation, significantly improving development efficiency for large projects and reducing the risk of code conflicts.Additionally, AIbase observed that Wave13 has also undergone deep optimization in interaction experience. The new version introduces a side-by-side view feature, allowing developers to manage multiple Cascade panes simultaneously. It also launched a dedicated terminal (Beta version) supporting zsh, providing more reliable script execution and environment management capabilities. Meanwhile, the newly added context window indicator displays real-time token usage, helping users accurately manage conversation history.Key Points:🚀 Major Model Upgrade:Windsurf defaults to the high-performance SWE-1.5 model and announced that the standard version will be freely available for all users for the next three months.🔄 Efficient Parallel Collaboration: Introduced parallel agent technology, supporting the execution of multiple development tasks simultaneously in different Git Worktree, eliminating collaboration conflicts.🧠 Improved Interaction Experience: Added side-by-side pane views and a dedicated Cascade terminal, along with a real-time context indicator to optimize long conversation management.",
      "article_url": "https://www.aibase.com/news/24094",
      "author": "AIbase",
      "publish_time": 1767050257,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Windsurf\", \"Shipmas\", \"PenguinAlpha\", \"SWE-1.5\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767050257,
      "last_modify_ts": 1767050257
    },
    {
      "id": 10,
      "article_id": "aibase_24092",
      "title": "Step-DeepResearch, a Cost-Effective Deep Research Model Launched by StepStellar",
      "description": "Recently, Stepfun officially open-sourced a new deep research model called Step-DeepResearch. This model has 32 billion parameters and is dedicated to autonomou",
      "content": "Recently, Stepfun officially open-sourced a new deep research model called Step-DeepResearch. This model has 32 billion parameters and is dedicated to autonomous information exploration and professional report generation in an open research environment. According to the official introduction, Step-DeepResearch's deep research capabilities are close to top commercial models such as OpenAI's o3-mini and Gemini 2.0 Flash, but its deployment cost is only one-tenth of traditional models, with a single call cost below 0.5 RMB.The design concept of Step-DeepResearch is very unique. It breaks down complex research tasks into multiple trainable \"atomic capabilities,\" such as planning, information retrieval, reflection, and cross-validation, thereby achieving closed-loop reflection and dynamic correction. This approach not only enhances the model's adaptability in complex environments but also improves its generalization performance. The training process of the model is carefully designed, from agent mid-training to supervised fine-tuning (SFT) and reinforcement learning (RL), ensuring excellent performance in complex practical applications.In testing, Step-DeepResearch achieved a high score of 61.4% on the Scale AI Research Rubrics, which is comparable to some larger-scale models such as OpenAI Deep Research and Gemini Deep Research. Additionally, in the expert evaluation of ADR-Bench, Step-DeepResearch's Elo rating was significantly higher than many competitors, demonstrating its strong capabilities in the field of deep research.To support scientific research workflows, Step-DeepResearch adopts a single-agent architecture based on the ReAct paradigm, featuring a dynamic cycle of reasoning, action, and reflection. Through its internal proprietary toolset, the system can efficiently perform batch web searches, file management, and interactive command execution, providing great convenience for researchers.github: https://github.com/stepfun-ai/StepDeepResearchKey points: ✨ Step-DeepResearch is the latest open-source deep research model from Stepfun, with a parameter scale of 32 billion. 💡 This model's deep research capabilities are close to top commercial models, but its cost is only one-tenth of traditional models. 🚀 With a unique training process and dynamic loop architecture, Step-DeepResearch provides efficient support in scientific research.",
      "article_url": "https://www.aibase.com/news/24092",
      "author": "AIbase",
      "publish_time": 1767050260,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Step-DeepResearch\", \"AINeologism\", \"LeapStar\", \"DeepResearchModel\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://github.com/stepfun-ai/StepDeepResearchKey\", \"url\": \"https://github.com/stepfun-ai/StepDeepResearchKey\", \"type\": \"code\"}]",
      "add_ts": 1767050260,
      "last_modify_ts": 1767050260
    },
    {
      "id": 12,
      "article_id": "aibase_24087",
      "title": "B站 Xiaohongshu Video to Hand-drawn Storyboard! Open Source Tool ClipSketch AI, Time-saving Assistant for Short Video Creators",
      "description": "Recently, an open-source tool called ClipSketch AI has quickly gained popularity in the content creation community. Designed specifically for video remixing and",
      "content": "Recently, an open-source tool called ClipSketch AI has quickly gained popularity in the content creation community. Designed specifically for video remixing and short video operations, this tool can instantly transform long videos into hand-drawn storyboards and automatically generate viral copy suitable for social media, helping users significantly improve their content production efficiency.Core features of ClipSketch AI: Video Analysis and Intelligent ExtractionThe biggest highlight of ClipSketch AI is its ability to import videos from multiple sources, supporting direct parsing of sharing links from Bilibili (B站) and Xiaohongshu platforms (including short links and mixed text and copy). Users just need to paste the link, and the tool can automatically download the video and intelligently extract key frames, eliminating the tedious process of manually taking screenshots.After extraction, the framework converts these key frames into elegant hand-drawn scene illustrations using an AI model (such as the Gemini series), creating a unique comic feel and storyboard visual effect while maintaining the core content and narrative logic of the original video.One-click generation of copy: Directly publish on social platformsIn addition to visual output, ClipSketch AI also integrates an AI copy generation feature. Based on the extracted key frames and video content, it automatically writes explanatory copy, titles, or note descriptions suitable for short video platforms. These copies come in various styles and can be directly copied and used, greatly lowering the threshold for video breakdown and content publishing.Wide application scenarios: An excellent assistant for remixing and operationsThis tool is particularly suitable for:- Series content creation: Quickly break down tutorial videos and generate structured storyboards- Dramatic short videos: Convert long plots into hand-drawn storyboards for easier remixing- Product recommendation accounts: Extract highlights from product review videos and post them with hand-drawn images and copy- Social media operations: Efficiently process content from Bilibili UPs or Xiaohongshu bloggers for cross-platform remixingCommunity feedback shows that after using ClipSketch AI, many creators have reduced their video breakdown and copy preparation time to a fraction of the original, especially suitable for individual operators and small teams.Open source and easy to use: Zero barrier for local deploymentClipSketch AI is a pure front-end project built using modern frameworks such as Vite. Developers can directly clone the code from the GitHub repository, install dependencies, and run it locally. The AI drawing function requires configuring a Google Gemini API Key (supporting the gemini-3-pro-image-preview model) to ensure the quality of the generated results.",
      "article_url": "https://www.aibase.com/news/24087",
      "author": "AIbase",
      "publish_time": 1767050265,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"ClipSketchAI\", \"AINeologism\", \"Bilibili\", \"Hand-drawnStyle\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767050265,
      "last_modify_ts": 1767050265
    },
    {
      "id": 14,
      "article_id": "aibase_24083",
      "title": "Yuanbao AI Task Reminder Function Launch Covers Multiple Scenarios in Life and Work, One Sentence Handles Timed Arrangements",
      "description": "On December 29, 2025, users in the Guangdong region were among the first to experience the newly launched \"Task Reminder\" feature of Yaba AI. This feature allow",
      "content": "On December 29, 2025, users in the Guangdong region were among the first to experience the newly launched \"Task Reminder\" feature of Yaba AI. This feature allows users to set recurring scheduled tasks with just one sentence, covering a wide range of scenarios such as daily chores, habit formation, and work-related tasks. It will actively send reminders at the designated time, and in some scenarios, it can also provide additional services, significantly improving daily scheduling efficiency.According to the information, the task reminder feature of Yaba AI is easy to use. Users don't need complex settings; they can simply inform their needs through voice or text. In daily life scenarios, there are reminders like \"Remind me on the 15th of each month to give my cat deworming medication and check the medicine stock,\" or \"Send bedtime stories for children aged 4-5 every night at 8:30 PM.\" There are even emotional care tasks like \"Remind me to make a video call to my mother at 8:00 PM every Saturday to ask about her leg pain,\" which are designed with detailed attention to users' daily needs.In terms of habit formation, the feature supports reminders like \"Remind me to put down my phone at 11:00 PM every night to go to sleep\" and can recommend relaxing music playlists; \"Remind me to do the Pamelas Phoenix Legend version of fitness exercises every day at 8:00 PM\" and can help search for video tutorials to help users achieve their self-discipline goals easily. In the workplace, the feature \"Remind me to write the weekly report every Friday at 4:00 PM\" is particularly practical, not only reminding on time but also asking about the user's three major events of the week and automatically expanding them into a draft of the weekly report. The function \"Send AI industry news from the previous day every morning at 9:00 AM\" meets the needs of professionals to access information and is suitable for use during morning meetings.Currently, Yaba AI is supported on both App and desktop versions, and users can use it by updating to the latest version. In the future, users can also share their experiences in the comments section and have the chance to win the \"2026 Yaba Heart Words Calendar.\" The launch of this feature marks the further expansion of AI assistants toward the role of a \"personalized lifestyle assistant,\" creating a more convenient intelligent service experience for users.",
      "article_url": "https://www.aibase.com/news/24083",
      "author": "AIbase",
      "publish_time": 1767050270,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"YuanbaoAI\", \"TaskReminder\", \"AIBuzzword\", \"BrandProductTerminology\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767050270,
      "last_modify_ts": 1767050270
    },
    {
      "id": 15,
      "article_id": "aibase_24077",
      "title": "Build a Video AI Application in Minutes! Open-Source Framework VideoPipe Makes CV Deployment as Easy as Building with Blocks",
      "description": "Recently, an open-source video analysis framework called VideoPipe, which focuses on the rapid integration and deployment of AI algorithms in the computer visio",
      "content": "Recently, an open-source video analysis framework called VideoPipe, which focuses on the rapid integration and deployment of AI algorithms in the computer vision (CV) field, has sparked heated discussions in the developer community. With its innovative pipeline design and extremely simple onboarding experience, this framework has become an \"accelerator\" for video AI application development, helping developers free themselves from tedious low-level coding and focus on implementing business logic.Core Design of VideoPipe: Composable Pipelines, Modular Task DecompositionVideoPipe uses a unique pipeline architecture that breaks down complex video analysis tasks into a series of independent \"nodes\" (Node). Each node is responsible for a single function, such as pulling streams, decoding, inference, or pushing streams. Nodes are independent but can be freely combined. This plug-in design allows developers to build applications like building blocks, without having to write the entire process from scratch.According to the framework documentation, developers only need to prepare an AI model and parse its output to quickly build a pipeline through simple configuration. Compared with traditional frameworks that are heavy and difficult to debug, VideoPipe has minimal dependencies and excellent cross-platform support, making it easier to port to different hardware environments.Multi-source Input and Protocol Support: Seamless Integration with Mainstream Video StreamsVideoPipe performs well in data reading, supporting various mainstream video stream protocols, including UDP, RTSP, RTMP, as well as local files and application image input. This makes the framework suitable for real-time monitoring, traffic cameras, and other scenarios, allowing easy processing of network streaming media or offline video data.Additionally, it supports image sequence input, expanding its potential applications in static image search or hybrid media analysis.Diverse Inference Engines: Deep Learning + Traditional Algorithms + Multimodal Large ModelsThe biggest highlight of the framework lies in the flexibility of algorithm inference. It supports multi-level cascaded inference of deep learning models, while also being compatible with traditional image processing algorithms (such as classic OpenCV methods). More notably, VideoPipe has integrated support for multimodal large models, allowing developers to seamlessly embed cutting-edge large language vision models into the video processing workflow.It includes multiple object tracking algorithms to ensure continuous tracking of specific objects in videos, suitable for accurate analysis in dynamic scenarios.End-to-End Solution: From Pulling to Pushing Streams, One-stop CoverageVideoPipe covers almost the entire chain of video AI applications: pull stream decoding → multi-level inference → object tracking → behavior analysis → frame annotation → screen recording and screenshot → encoding and pushing streams → message notification. Developers just need to \"add what's missing,\" and they can quickly assemble a complete video AI prototype within minutes.Typical application scenarios include:- Video structured processing- Image retrieval and search- Face recognition and tracking- Traffic incident detection (e.g., violation recognition, reverse monitoring)- Creative applications such as AI face swapping- Security monitoring and behavior analysisPositive Community Feedback: 40+ Examples Help Get Started QuicklyVideoPipe provides more than 40 ready-made examples covering popular scenarios such as face recognition, vehicle detection, and pose estimation, along with detailed documentation and video tutorials. Recent community sharing shows that many developers have used this framework to quickly implement intelligent monitoring prototypes and traffic analysis systems, greatly shortening the cycle from concept to implementation.AIbase's view: The emergence of VideoPipe has lowered the engineering threshold in the AI video analysis field, enabling more small and medium teams and individual developers to efficiently deploy CV applications. With the integration of multimodal large models, its potential will be further unleashed. Interested developers can visit the GitHub repository (sherlockchou86/VideoPipe) to star and experience it.Project Address: https://github.com/sherlockchou86/VideoPipe",
      "article_url": "https://www.aibase.com/news/24077",
      "author": "AIbase",
      "publish_time": 1767050283,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"VideoPipe\", \"ComputerVision\", \"AIAlgorithms\", \"OpenSourceFramework\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://github.com/sherlockchou86/VideoPipe\", \"url\": \"https://github.com/sherlockchou86/VideoPipe\", \"type\": \"code\"}]",
      "add_ts": 1767050283,
      "last_modify_ts": 1767050283
    },
    {
      "id": 16,
      "article_id": "aibase_24074",
      "title": "Simplicity Over Complexity: Meta AI Unveils the Pixio Image Model, Setting New Records in 3D Reconstruction Through Pixel Reconstruction",
      "description": "According to AIbase, the Meta AI research team recently released a study on an image model called Pixio, demonstrating that even with a simpler training path, i",
      "content": "According to AIbase, the Meta AI research team recently released a study on an image model called Pixio, demonstrating that even with a simpler training path, it can show outstanding performance in complex visual tasks such as depth estimation and 3D reconstruction. For a long time, the academic community generally believed that mask autoencoder (MAE) technology was inferior to more complex algorithms like DINOv2 or DINOv3 in scene understanding, but the emergence of Pixio has broken this conventional belief.The core logic of Pixio comes from a deep improvement of the MAE framework from 2021. Researchers found that the weak decoder in the original design limited the performance of the encoder, so they significantly enhanced the decoder's functionality and expanded the image masking area. By replacing small masking blocks with large continuous regions, Pixio is forced to abandon simple pixel copying and instead truly \"understand\" spatial relationships such as object co-occurrence, 3D perspective, and reflections in the image. In addition, by introducing multiple category tokens for aggregating global properties, the model can more accurately capture scene types, camera angles, and lighting information.In terms of training strategy, Pixio shows a high degree of purity. Unlike DINOv3, which repeatedly optimizes for specific benchmark tests (such as ImageNet), Pixio collected 2 billion images from the web and used dynamic frequency adjustment: reducing the weight of simple product photos and increasing the training frequency of complex scenes. This approach of not \"cheating\" on the test set actually gives the model stronger transferability.Data comparisons show that Pixio, with only 631 million parameters, outperforms DINOv3 with 841 million parameters in multiple metrics. In monocular depth estimation, its accuracy improved by 16%; in 3D reconstruction tasks, Pixio trained with a single image even outperformed DINOv3 trained with eight views. At the same time, in the field of robot learning, Pixio also leads DINOv2 with a success rate of 78.4%. Although the research team acknowledges the limitations of manual masking and plans to explore the direction of video prediction, the breakthroughs achieved by Pixio so far are sufficient to prove that returning to the essence of pixel reconstruction often leads to deeper visual understanding.",
      "article_url": "https://www.aibase.com/news/24074",
      "author": "AIbase",
      "publish_time": 1767050286,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Pixio\", \"MetaAI\", \"MAE\", \"DepthEstimation\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767050286,
      "last_modify_ts": 1767050286
    },
    {
      "id": 17,
      "article_id": "aibase_24132",
      "title": "Tencent Hunyuan releases version 1.5 of its open-source translation model: Performance on edge devices improves significantly, with results comparable to large closed-source models",
      "description": "Tencent HY-MT has officially announced the open-source release of its translation model version 1.5 today. This update includes two models of different sizes: T",
      "content": "Tencent HY-MT has officially announced the open-source release of its translation model version 1.5 today. This update includes two models of different sizes: Tencent-HY-MT1.5-1.8B and Tencent-HY-MT1.5-7B, aiming to redefine the translation experience of edge-cloud collaboration with extreme efficiency and leading translation quality.Key Highlights: Edge Deployment and Outstanding PerformanceThe 1.8B model released this time stands out particularly. As a lightweight model designed for consumer devices such as smartphones, it can run smoothly offline with only 1GB of memory after quantization.Extreme Speed: The average time to process 50 tokens is just 0.18 seconds, which is much faster than the 0.4 seconds of mainstream commercial translation APIs.Superior Performance: In authoritative test sets such as FLORES-200, its performance reaches the 90th percentile level of large closed-source models like Gemini-3.0-Pro, surpassing medium-sized open-source models comprehensively.Comprehensive Coverage: From Mainstream Languages to Dialects and ChineseThe HY-MT 1.5 model supports mutual translation of 33 global languages, including Chinese, English, Japanese, and French, and especially strengthens support for smaller languages such as Czech, Estonian, and Icelandic. In addition, the model covers 5 domestic minority languages and dialects, greatly expanding the application boundaries of AI translation.Functional Evolution: More Practical Translation ExperienceRegarding actual application scenarios, the 1.5 version has made significant upgrades in three dimensions:Custom Terminology Library: Users can upload terminology lists for specialized fields such as medicine, law, and finance to ensure consistent translation of professional terms.Context Understanding: It has advanced long-text dialogue comprehension capabilities, optimizing subsequent results based on the context of previous text, avoiding semantic breaks.Format Preservation Ability: Through precise instruction following, the model can perfectly preserve the original text format (such as web pages, code, and Markdown) after translation.Technical Breakthrough: Large Model Guiding Small ModelThe reason why HY-MT1.5-1.8B achieves so much with so little is due to Tencent's On-Policy Distillation (large model distillation) strategy. A 7B-sized \"teacher\" model guides the \"student\" model in real time, helping it learn from prediction deviations rather than simply memorizing answers, thus significantly improving the small model's logical and translation abilities.Developer Ecosystem: Full Platform SupportCurrently, the HY-MT 1.5 model is available on the Tencent HY Website and is open-sourced on Github and HuggingFace communities. The model has been adapted to mainstream computing platforms such as Arm, Qualcomm, Intel, and Muxi.From Tencent Meeting to Enterprise WeChat, Tencent HY translation technology has been implemented in multiple internal high-concurrency scenarios. With the open source of the 1.5 version, Tencent is further promoting high-quality AI translation technology toward inclusivity, providing global developers with a more cost-effective translation solution.",
      "article_url": "https://www.aibase.com/news/24132",
      "author": "AIbase",
      "publish_time": 1767136630,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Tencent Hunyuan\", \"Translation Model\", \"Tencent-HY-MT1.5-1.8B\", \"Edge Deployment\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767136630,
      "last_modify_ts": 1767136630
    },
    {
      "id": 19,
      "article_id": "aibase_24128",
      "title": "Say Goodbye to the Command Line! Claude Code's Visual Workflow Editor Goes Viral: Build AI Automation Tools by Dragging Nodes",
      "description": "At the end of 2025, Anthropic's Claude Code achieved a major breakthrough in its community ecosystem: a VSCode extension tool called \"Claude Code Workflow Studi",
      "content": "At the end of 2025, Anthropic's Claude Code achieved a major breakthrough in its community ecosystem: a VSCode extension tool called \"Claude Code Workflow Studio\" quickly gained popularity. This tool enables users to build and execute advanced AI automation workflows without writing complex prompts or terminal commands, through an intuitive drag-and-drop canvas interface. This marks the evolution of Claude Code from a purely command-line tool to a visual, no-code solution, significantly lowering the barrier for non-professional developers.Core Features: Drag-and-Drop Nodes to Build Complex WorkflowsClaude Code Workflow Studio provides a dedicated \"canvas\" view within VSCode, allowing users to design workflows by simply dragging and dropping nodes. The main nodes include:- Prompt (Prompt Node)- Sub-Agent (Sub-Agent)- Skill (Skill)- MCP (Model Context Protocol Tool)- IfElse (Conditional Branch)- AskUserQuestion (User Interaction Question)Nodes are connected with lines to form complete automation chains. After design, users can directly export the workflow as a .claude file, which can be seamlessly executed by the Claude Code CLI. The tool also supports AI-assisted editing: users can describe their needs in natural language (e.g., \"add a validation step\" or \"split long text\"), and the system will automatically adjust the workflow structure.Typical Application ScenariosThis visual approach is particularly suitable for building repetitive or multi-step AI tasks, such as:- Automated document summary bot: extract content from input files, generate summaries, and output reports.- Code analysis and repair workflow: read code, identify issues, suggest fixes, and apply them.- Web scraping automation: access pages, extract specified content, process data, and report results.For beginners, this drag-and-drop plus chat interaction greatly improves intuitiveness and convenience, enabling powerful automation without deep terminal operations.Community Feedback and Ecosystem ImpactThis extension was developed by community developers and has been launched on GitHub and the VSCode Marketplace, quickly receiving positive feedback from developers. Users reported that it solves the \"prompt confusion\" issue in complex workflows with Claude Code, making AI agent collaboration more structured and visual. Combined with Claude Code's native support for sub-agents, skills, and MCP, this tool further unleashes its potential in the agentic workflow field.Meanwhile, similar visual GUI tools (such as Claudia and Claude Code UI) have also emerged in the domestic community, further enriching the ecosystem choices.The emergence of Claude Code Workflow Studio signals that AI programming tools are transitioning from \"exclusive to command-line experts\" to \"accessible to everyone.\" Drag-and-drop design combined with AI intelligent editing not only accelerates the construction of automation processes but also opens the door to Claude Code for non-coders. In the future, as more visual extensions emerge, AI agent workflows will become easier to manage and more efficient. AIbase will continue to monitor the dynamics of the Claude Code ecosystem and bring readers the latest cutting-edge information.Project Address: https://github.com/breaking-brake/cc-wf-studio/",
      "article_url": "https://www.aibase.com/news/24128",
      "author": "AIbase",
      "publish_time": 1767136636,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"ClaudeCode\", \"VSCode Extension Tool\", \"AI Automation Workflow\", \"No-Code\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://github.com/breaking-brake/cc-wf-studio/\", \"url\": \"https://github.com/breaking-brake/cc-wf-studio/\", \"type\": \"code\"}]",
      "add_ts": 1767136636,
      "last_modify_ts": 1767136636
    },
    {
      "id": 24,
      "article_id": "aibase_24110",
      "title": "Microsoft Copilot Upgrades to GPT-5.2, Free Access to a New Era of Expert-Level Workflows",
      "description": "| Microsoft has officially rolled out the most powerful model series from OpenAI to date, GPT-5.2, to web, Windows, and mobile users. As a sincere free upgrade,",
      "content": "| Microsoft has officially rolled out the most powerful model series from OpenAI to date, GPT-5.2, to web, Windows, and mobile users. As a sincere free upgrade, GPT-5.2 will coexist with the existing GPT-5.1 model in \"intelligent enhancement\" mode, marking the official entry of Copilot into the era of deep logical reasoning. This so-called \"expert-level\" model not only completes practical tasks such as building spreadsheets, writing review code, and understanding long documents faster, but also shows unprecedented maturity in handling complex tool calls and image analysis.From a performance perspective, the leap brought by GPT-5.2 is not only reflected in speed but also in its ability to think deeply. Microsoft clearly stated that the GPT-5.2Plus version on Copilot is essentially a \"thinking\" variant of GPT-5.2. In a benchmark test covering 44 occupational knowledge work tasks, GPT-5.2Thinking outperformed or matched industry professionals in 70.9% of cases, while GPT-5 achieved this rate of 38.8%. This almost doubling improvement allows OpenAI to confidently position this model as a top expert for handling presentations, schedules, and various professional deliverables, setting a new industry ceiling for office automation.In hard-core technical benchmark tests, GPT-5.2 also demonstrated its dominance. In the programming field, it set new records on SWE-Bench Pro and SWE-bench Verified, significantly surpassing GPT-5.1Thinking. In the most challenging logic and science tests, the model scored 92.4% on the GPQA Diamond test and achieved a perfect score of 100% on the AIME2025 math test.Additionally, its significant improvements in CharXiv reasoning and ARC-AGI-2 tests confirm that Microsoft is evolving Copilot from a basic assistant into a digital intelligent entity with a rigorous logical system through technological iterations, thus maintaining a leading advantage in the fierce AI competition.",
      "article_url": "https://www.aibase.com/news/24110",
      "author": "AIbase",
      "publish_time": 1767136649,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"GPT-5.2\", \"Microsoft\", \"OpenAI\", \"Copilot\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767136649,
      "last_modify_ts": 1767136649
    },
    {
      "id": 25,
      "article_id": "aibase_24106",
      "title": "OpenAI Updates Mobile Version of ChatGPT, Allowing Users to Adjust AI's Thinking Depth",
      "description": "OpenAI has made significant updates to its ChatGPT apps for Android and iOS, adding a \"Thinking Duration\" adjustment feature. According to the tech media bleepi",
      "content": "OpenAI has made significant updates to its ChatGPT apps for Android and iOS, adding a \"Thinking Duration\" adjustment feature. According to the tech media bleepingcomputer, this update allows mobile users to flexibly choose the depth of AI thinking to better meet different needs.In previous versions, the thinking function on Android was locked in \"Standard\" mode, which responded quickly but was limited by computing power when performing complex reasoning, making it difficult to provide in-depth analysis. This update enables mobile users to experience the same efficient service as desktop users, allowing them to switch between \"Standard Thinking\" and \"Extended Thinking\" modes according to their needs.\"Standard Thinking\" is mainly used for quickly answering daily questions and is suitable for handling simple queries. \"Extended Thinking,\" on the other hand, is metaphorically described as having stronger \"computing power.\" In this mode, the model can spend more time on logical reasoning, thus providing more accurate answers when dealing with complex mathematical, programming, or logical analysis problems.It is worth noting that this new feature is currently only available to ChatGPT Plus subscribers, while Go subscribers are temporarily unable to use it. In addition, OpenAI also restructured the desktop version in this update, introducing the \"Formatted Module\" feature. This feature aims to improve the problem of previously single-format model output. For example, when users request to write an email, the new version will be able to automatically identify the task type, adjust the user interface layout, making it more like a professional email client, thereby enhancing the intuitiveness and convenience of the user experience.Key Points: ✨ This update allows mobile users to manually adjust the depth of AI thinking, enhancing the interactive experience. 🧠 \"Standard Thinking\" is suitable for simple questions, while \"Extended Thinking\" provides deep reasoning to solve complex problems. 📱 The new feature is currently only available to ChatGPT Plus subscribers, and the desktop version has also been optimized in terms of interface.",
      "article_url": "https://www.aibase.com/news/24106",
      "author": "AIbase",
      "publish_time": 1767136652,
      "publish_date": "2025-12-31",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"ChatGPT\", \"OpenAI\", \"StandardThinking\", \"ExpandedThinking\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767136652,
      "last_modify_ts": 1767136652
    },
    {
      "id": 26,
      "article_id": "aibase_24167",
      "title": "Tencent Shocks the Market! 10 Billion Parameter Text-to-3D Motion Generator Open-Sourced, Making Game NPCs Come to Life in One Click!",
      "description": "On December 30, 2025, the Tencent Hunyuan team officially open-sourced HY-Motion 1.0 (Hunyuan-Motion-1.0), a large-scale text-to-3D motion generation model with",
      "content": "On December 30, 2025, the Tencent Hunyuan team officially open-sourced HY-Motion 1.0 (Hunyuan-Motion-1.0), a large-scale text-to-3D motion generation model with ten billion parameters. Based on the Diffusion Transformer (DiT) architecture and flow matching mechanism, this model can generate high-fidelity, smooth, and diverse 3D character skeleton animations with just one natural language description. It directly supports mainstream 3D tools such as Blender, Unity, and UE, significantly lowering the barrier to animation production.Key Technical Highlights HY-Motion 1.0 adopts a full-stage training strategy: first pre-training on over 3,000 hours of diverse motion data to build general motion priors; then fine-tuning on 400 hours of high-quality selected data to improve detail smoothness; finally, optimizing physical plausibility and semantic alignment through reinforcement learning (RLHF) combined with human feedback and reward models. The model covers six major categories with over 200 types of motions, including basic movements, sports competitions, fitness and outdoor activities, social leisure, daily activities, and game character actions (such as sword blocking and zombie walking). The output is in SMPL-H skeleton format, supporting atomic actions, composite sequences, and concurrent actions.Outstanding Test Performance Community tests show that the model has a high level of accuracy in daily scenarios: for prompts like \"running,\" \"sitting on a chair,\" and \"jumping twice with both legs,\" the generated motions are natural and continuous. Complex motions, such as crouching during the bullet time scene from \"The Matrix,\" can also be accurately reproduced with smooth postures. In performance evaluation, the model achieved an instruction following capability of 78.6% (SSAE metric), with an average action quality of 3.43 out of 5, surpassing open-source baselines such as MoMask and DART, especially in complex instructions and multi-category coverage. Extreme challenges: the recreation of professional athlete movements (such as ski jumping, diving, and BMX cycling) is not ideal, and joint transitions occasionally appear unnatural. However, overall physical plausibility far exceeds previous versions.Great Potential in Game Animation Applications This end-to-end model is particularly suitable for game development: it can quickly generate NPC daily life actions (such as walking and interaction), significantly accelerating research and iteration. Although main character design requires later refinement, it can already be seamlessly imported into engines, helping to create MMORPGs and action games. Film storyboarding, advertisement positioning, and VR content creation will also benefit. The lightweight version HY-Motion-1.0-Lite (0.46B parameters) is also open-sourced, offering more friendly deployment.Project link: https://hunyuan.tencent.com/motion?tabIndex=0",
      "article_url": "https://www.aibase.com/news/24167",
      "author": "AIbase",
      "publish_time": 1767395863,
      "publish_date": "2026-01-03",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"HY-Motion1.0\", \"Tencent Huan Yuan\", \"DiffusionTransformer\", \"3D Motion Generation\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://hunyuan.tencent.com/motion?tabIndex=0\", \"url\": \"https://hunyuan.tencent.com/motion?tabIndex=0\", \"type\": \"external\"}]",
      "add_ts": 1767193264,
      "last_modify_ts": 1767395863
    },
    {
      "id": 31,
      "article_id": "aibase_24146",
      "title": "Tongyi Lab of Alibaba Launches MAI-UI: A Family of Basic GUI Intelligent Agents That Exceed Competitors",
      "description": "Alibaba Tongyi Lab recently released MAI-UI, a family of multi-modal general-purpose GUI intelligent agents. This system not only enables human-computer interac",
      "content": "Alibaba Tongyi Lab recently released MAI-UI, a family of multi-modal general-purpose GUI intelligent agents. This system not only enables human-computer interaction but also integrates MCP tool usage, device and cloud collaboration, and online reinforcement learning, achieving leading results in general GUI foundations and mobile GUI navigation, surpassing competitors such as Gemini2.5Pro, Seed1.8, and UI-Tars2.MAI-UI is built upon Qwen3VL, featuring models of different scales, including 2B, 8B, 32B, and 235B A22B. These models can receive natural language instructions and UI screenshots as input and output structured operations, supporting actions in real-time Android environments. These operations include clicking elements, swiping, entering text, and pressing system buttons. Additionally, MAI-UI introduces the ability to answer user questions, request clarification on ambiguous goals, and perform clear actions, while calling external tools via MCP tools, allowing the agent to mix GUI steps, direct language responses, and API-level operations within the same trajectory.On top of the GUI, MAI-UI ensures the robustness of its navigation capabilities through a self-evolving data pipeline and an online reinforcement learning framework. Tongyi Lab used seed tasks obtained from application manuals, design scenarios, and public data, executed by multiple agents and human annotators, to generate task trajectories and optimize navigation behavior.In the MobileWorld benchmark test, MAI-UI demonstrated its excellent performance with a success rate of 41.7%. In the AndroidWorld benchmark test, MAI-UI achieved a maximum variant success rate of 76.7%, surpassing other similar products.The release of MAI-UI marks significant progress in GUI intelligent agent technology in the mobile application field, making smart devices more efficient and intelligent when handling complex operations.github:https://github.com/Tongyi-MAI/MAI-UIKey Points: 🌟 MAI-UI is a family of GUI intelligent agents introduced by Alibaba Tongyi Lab, integrating multiple advanced technologies. 📱 MAI-UI supports various operations and can perform complex user interactions in real-time Android environments. 🚀 MAI-UI's performance significantly surpasses competitors in benchmark tests such as MobileWorld and AndroidWorld.",
      "article_url": "https://www.aibase.com/news/24146",
      "author": "AIbase",
      "publish_time": 1767395883,
      "publish_date": "2026-01-03",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"MAI-UI\", \"Qwen3VL\", \"Tongyi Lab of Alibaba\", \"Multimodal Basic GUI Intelligent Agent\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "[{\"title\": \"https://github.com/Tongyi-MAI/MAI-UIKey\", \"url\": \"https://github.com/Tongyi-MAI/MAI-UIKey\", \"type\": \"code\"}]",
      "add_ts": 1767193295,
      "last_modify_ts": 1767395883
    },
    {
      "id": 32,
      "article_id": "aibase_24169",
      "title": "Qwen AI Glasses First OTA Update: AI Capabilities Further Enhanced, Adds Five New Features Including Text and Image Notes",
      "description": "The Quark AI Glasses, equipped with the Qwen AI assistant, received their first OTA update on December 31st, further enhancing AI capabilities. Five new feature",
      "content": "The Quark AI Glasses, equipped with the Qwen AI assistant, received their first OTA update on December 31st, further enhancing AI capabilities. Five new features were added: audio notes, image and text memos, multi-intent understanding and execution by large models, Blue Ring payments, and community services. Additionally, popular functions such as translation, itinerary inquiry, and music playback have been optimized based on user feedback.In the audio recording scenario, the upgraded Quark AI Glasses support sound pickup within a range of ten meters, with effective noise reduction, using the self-developed Quark Audio voice enhancement model and the original five-microphone array plus bone conduction hardware configuration. Moreover, the glasses can accurately identify different speakers and use AI to extract key points from the recorded content, automatically generating to-do lists. This function currently supports transcription and translation for four languages: Chinese, English, Japanese, and Korean.In the memo scenario, the Quark AI Glasses support both photo and voice-based memo usage. For instance, when standing in front of a parking spot, simply say \"Qwen, help me note the parking spot,\" and the glasses will take a photo of the parking spot and record it. More intelligently, the system has AI classification and semantic understanding capabilities. When the user asks, \"What furniture have I wanted to buy in the past month?\" the glasses will automatically retrieve historical records and summarize the response.Another highlight of this update is the support for multi-intent understanding and execution by the large model. Most AI glasses typically handle only single instructions, but the Quark AI Glasses now support understanding and executing two to three compound tasks. For example, \"Navigate to the company, play some music I like,\" or \"I need to go to a conference tomorrow at 8 AM and catch a flight at 9 AM, remember to remind me.\" The Quark AI Glasses can understand these requests and coordinate multiple services such as maps, music, and calendars, improving efficiency and convenience in work and daily life.The on-the-go translation feature has also been upgraded, supporting translation into 89 languages, including major languages such as English, Japanese, Korean, French, and German, as well as less common languages from various countries and regions, meeting different needs for cross-border travel and business communication.This OTA update was pushed through the Quark AI Glasses app, and users can click to complete the upgrade. The app also launched a user exchange community, where users can learn about product information, share usage tips and experiences, and participate in official photography, gameplay, and creation contests.As an important business direction of Alibaba's Qwen C-end division, the Quark AI Glasses have already released two series—S1 and G1—with six SKUs. The Qwen AI assistant, which serves as the core entry point, is accelerating its expansion to multiple terminals such as glasses, PCs, and cars.",
      "article_url": "https://www.aibase.com/news/24169",
      "author": "AIbase",
      "publish_time": 1767395860,
      "publish_date": "2026-01-03",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"Qwen AI Assistant\", \"Qwen AI Glasses\", \"AI New Words\", \"Brand Product Terms\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767223077,
      "last_modify_ts": 1767395860
    },
    {
      "id": 34,
      "article_id": "aibase_24159",
      "title": "JD.com Officially Launches Self-Operated Rental Service, Million-Level Humanoid Robots Within Reach",
      "description": "On December 31st, the world's first offline store co-established by JD.com and Unitree opened grandly at JD MALL (Beijing Shuangjing Store). This not only marks",
      "content": "On December 31st, the world's first offline store co-established by JD.com and Unitree opened grandly at JD MALL (Beijing Shuangjing Store). This not only marks the official transition of top-tier embodied intelligence products from online to omnichannel retail, but also represents a key step in bringing robots into everyday life.\"Rent instead of buy\" new model: lower experience thresholdAt the opening event, the person in charge of JD's robot business with embodied intelligence revealed that JD has officially launched its own robot rental service. Users can now experience cutting-edge technology including quadrupedal robot dogs and humanoid robots at lower prices and with more flexible rental periods (such as daily or long-term rentals). This move aims to address the pain points of high single-unit prices and difficulty for the general public to get started with humanoid robots, making embodied intelligence technology truly serve ordinary consumers.Scenario-based experience: Robots enter thousands of householdsAs JD's offline super experience center, JD MALL has opened 27 stores nationwide, with each store covering an area of 30,000 to 80,000 square meters. According to the person in charge, JD is continuously expanding offline application scenarios. Consumers can immerse themselves in real environments within the store to experience the practical applications of robots in diverse scenarios such as home assistance, educational companionship, health care, and cultural entertainment.Strong cooperation: Accelerate commercialization",
      "article_url": "https://www.aibase.com/news/24159",
      "author": "AIbase",
      "publish_time": 1767395868,
      "publish_date": "2026-01-03",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"JD.com\", \"YushuTechnology\", \"Robots\", \"LeasingServices\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767223085,
      "last_modify_ts": 1767395868
    },
    {
      "id": 36,
      "article_id": "aibase_24157",
      "title": "Luo Yonghao Launches AI Book Reading App Qie Ting: In-depth Book Analysis in 1-2 Hours for Less Than 40 Yuan Annually",
      "description": "&nbsp;At the \"Annual Technology Innovation Sharing Conference\" held last night, Luo Yonghao announced that his startup \"Thin Red Line\" has officially launched i",
      "content": "At the \"Annual Technology Innovation Sharing Conference\" held last night, Luo Yonghao announced that his startup \"Thin Red Line\" has officially launched its self-developed AI product - \"Qie Ting\". This product is positioned as a deep voice library for the AI era and is now available on all major app stores.\"Qie Ting\" relies on natural language processing (NLP) and knowledge graph technology to structure books. Its core selling point is **\"Deep Explanation\"**: each book is explained for 1-2 hours, with over ten thousand words, aiming to extract core ideas for users, suitable for fragmented deep learning scenarios such as driving commutes.At the press conference, Luo Yonghao demonstrated the product's voice customization feature, successfully generating a personalized voice model by uploading the voice of stand-up comedian Niao Niao.Currently, \"Qie Ting\" has integrated multiple category lists including Douban Top 250, covering disciplines such as literature, economics, and psychology, trying to solve the user's \"book selection difficulty\" pain point. In terms of pricing, the product adopts a highly competitive low-price strategy: 9.9 yuan per month, and only 37.8 yuan per year. In addition, new users who register will receive a 7-day membership, and there is also a friend invitation incentive mechanism.As an initial exploration of Thin Red Line in the AI content field, \"Qie Ting\" has also attracted industry attention after the on-site demonstration. Although the technical performance is impressive, the product still needs further market validation and official responses regarding core issues such as book copyright compliance, extension of practical application scenarios, and long-term user acceptance of this \"AI-explained\" reading mode.",
      "article_url": "https://www.aibase.com/news/24157",
      "author": "AIbase",
      "publish_time": 1767395874,
      "publish_date": "2026-01-03",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "tags": "[\"AI New Terms\", \"Qie Ting\", \"Natural Language Processing\", \"Brand Product Terms\"]",
      "cover_image": "https://app.aibase.com/icon/logo.png",
      "source_keyword": "aibase",
      "is_original": 0,
      "reference_links": "",
      "add_ts": 1767223091,
      "last_modify_ts": 1767395874
    }
  ],
  "baai_hub_article": [
    {
      "id": 5,
      "article_id": "51501",
      "title": "Nat. Commun.｜基于图像的药物发现中的表型学习策略",
      "description": "PhenoProfiler是一种新型深度学习模型，可直接从图像中高效提取细胞表型特征，无需复杂预处理步骤。该方法显著降低计算成本，提高分析准确性，助力药物作用机制解析与疗效预测，在基于图像的药物发现中展现出强大应用潜力。",
      "content": "在基于图像的药物发现中，准确捕捉细胞对化学扰动的表型响应，对于理解药物作用机制和预测疗效至关重要。然而，现有方法往往依赖复杂的多步骤流程，计算开销大且容易出错。\n针对这一问题，\n澳门大学联合佛罗里达大学等机构的研究团队\n于2025年12月14日在《Nature Communications》上发表研究论文，题为“PhenoProfiler: advancing phenotypic learning for image-based drug discovery”。\n该研究提出的\nPhenoProfiler\n采用高效的端到端深度学习框架，将内容丰富、多通道的细胞图像直接映射为低维定量表征。基于近40万张高内容图像和842万张单细胞图像的评估结果显示，\nPhenoProfiler在准确性和稳健性上均显著优于现有最先进方法，性能提升最高可达20%。\n其定制化的表型校正策略进一步强化了处理诱导的细胞变化，从而增强了对生物学意义明确且可重复信号的检测能力。通过有效解决现有方法在流程复杂性、计算成本及泛化能力方面的局限，PhenoProfiler显著推进了表型分析，为加速基于图像的药物发现提供了有力工具。\nPhenoProfiler访问链接：\nhttps://phenoprofiler.org\n背景\n在基于图像的药物发现中，学习稳健的图像表示对于从复杂的高通量图像数据集中提取有意义的信息至关重要。Cell Painting技术通过多种荧光染料标记细胞内不同的细胞器和组成部分，生成多通道图像，从而捕捉细胞对不同药物或扰动的表型变化。然而，Cell Painting图像的高维特性\n常伴随冗余和噪声，因此通常需要大量预处理步骤，\n如归一化、分割及伪影去除。此外，处理这类大规模数据集\n对计算资源要求高，而提取的形态学特征可能缺乏生物学可解释性，\n使得直接利用图像进行有意义的分析具有挑战性。\n为应对Cell Painting图像特有的挑战，开发了包括CellProfiler、DeepProfiler、SPACe和OpenPhenom在内的专用方法，以提取细胞形态的紧凑且信息丰富的表示。尽管取得一定进展，现有形态学表示学习方法在处理高维Cell Painting图像时仍存在关键限制。首先，这些方法通常将多通道整图分解为多个子图像进行处理，这种多步骤流程不仅\n增加了计算开销和成本，还可能引入额外误差，\n例如分割不准确或特征整合错误。其次，这类方法\n依赖药物处理条件作为分类标签，但标签信息有限，难以全面捕捉细胞响应的多样性和复杂性。\n因此，基于有限标签训练的模型在不同实验条件下泛化能力较弱，降低了其可扩展性与适用性。这些局限性凸显了开发简化、高效且具有生物学可解释性的表型表示方法的必要性。\n方法\nPhenoProfiler能够从高通量图像中学习细胞形态表示，并提取药物处理效应引起的表型变化。与现有方法相比(图1a)，PhenoProfiler被设计为\n端到端模型\n，可直接将信息量丰富的多通道图像编码为低维特征表示，无需复杂预处理步骤，如图像分割或子图像提取。\nPhenoProfiler由三个核心模块组成，即\n梯度编码器、Transformer编码器\n以及整合分类、回归和对比学习的\n多目标学习模块\n(图1b)。具体而言，梯度编码器用于增强边缘信息，提高细胞形态的清晰度和对比度；随后，Transformer编码器捕捉图像中的高维依赖关系和复杂联系，从而丰富图像表示；多目标学习模块则用于实现精确的形态学表示学习。经过充分训练，PhenoProfiler构建了一个统一且稳健的特征空间，用于表征细胞形态。\n在推理阶段(图1c)，PhenoProfiler通过\n表型校正策略\n强调不同处理条件下的相对表型变化，从而揭示生物学相关性及处理相关的表型表示。\n图1 PhenoProfiler框架图\n结果\n在生物匹配任务中性能\n为了对PhenoProfiler进行全面且稳健的评估，将其与已知方法(包括DeepProfiler、OpenPhenom、ResNet50和ViT）进行对比，采用leave-perturbation-out策略。评估采用两个指标，即富集倍数(FoE)和平均精度均值(MAP)。使用三个数据集(BBBC022、CDRP-BIO-BBBC036和TAORF-BBBC037)中的超过23万张图像，涵盖231个板和4285种处理，包括化合物和基因过表达扰动。实验结果如图2所示，\nPhenoProfiler在三个基准数据集上均在FoE和MAP指标上超越所有竞争方法。\n图2 在生物学匹配任务中的性能\n为了进一步说明PhenoProfiler各模块的贡献，作者在BBBC022数据集上进行了\n消融实验\n(图2c)。首先，去除多目标学习模块中的回归学习组件(“-MSE”选项)，仅保留分类和对比学习。结果显示，\n去除回归学习导致性能显著下降，\nFoE和MAP分别下降12.0%和12.7%。接着，测试了不同损失函数组合(“-Con”、“-CLS”、“-MSE-Con”、“-Con-CLS”和“-CLS-MSE”)。例如，同时去除回归和分类学习，FoE和MAP分别下降28.0%和20.6%。与未使用梯度编码的模型平均性能(“-MSE-Con-Gradient”、“-Con-CLS-Gradient”、“-CLS-MSE-Gradient”)相比，该修改导致FoE和MAP分别下降25.2%和11.5%，\n突显了基于梯度的特征编码的有效性。\n此外，测量指标并非随着分类损失的下降而持续改善。如图2d所示，MAP和FoE在分类损失下降初期有所提升，但最终下降。\n这强调了PhenoProfiler多目标学习设计的重要性。\n多目标学习的最优权重通过对BBBC022数据集的敏感性分析确定。图2e-2f显示了调优后的PhenoProfiler实现了最优性能。\n泛化能力与适用性\n为了评估PhenoProfiler的泛化能力，作者在基准数据集上进行了实验，采用leave-plates-out和leave-dataset-out评估策略。对于\nleave-plates-out\n策略，部分板作为测试集，其余板用于训练；而在\nleave-dataset-out\n策略中，一个数据集用于训练，另外两个作为测试集。在leave-plates-out 情境下(图3a)，PhenoProfiler在FoE和MAP指标上均持续优于其他方法。图3b展示了leave-dataset-out情境下的性能对比，进一步突显了PhenoProfiler的优越表现。\n总体而言，PhenoProfiler的泛化能力优于现有方法，为药物发现中的下游任务提供了更精准的支持。\n图3 泛化能力及适应性评估结果\n为了进一步验证PhenoProfiler的泛化能力，对外部分布(OOD)数据进行了评估，使用来自cpg0001数据集的10个不同板(BR00115125-BR00115134)，共76800张图像，涵盖83种独特处理和47个注释的作用机制(MoA)。如图3c上图所示，直接将预训练于BBBC022、BBBC036和BBBC037的PhenoProfiler模型应用于这些OOD板。\nPhenoProfiler在所有测试板上在FoE和MAP指标上分别比第二优模型DeepProfiler平均高45.8%和27.3%，显示出稳健的泛化能力及对OOD数据的适应性\n。此外，由于这些评估均来自U2OS细胞系，进一步在五个A549细胞系板(cpg0004数据集中的SQ00014812-SQ00014816，见图3c下图)上进行了评估。结果显示，\nPhenoProfiler在FoE和MAP上平均分别比第二优模型OpenPhenom高21.4%和20.3%，证明其在不同细胞系间的泛化能力同样稳健。\n有效消除批次效应\n为评估PhenoProfiler缓解批次效应的能力，作者采用\n反向绝对中位差(IMAD)\n指标来量化图像表示的离散程度。IMAD值越高，表示离散性越小，即批次效应被更好地校正。图4展示了板级的表示特征，不同颜色表示不同板，以突出批次效应。\nPhenoProfiler学到的表示特征分布明显更为整合(IMAD = 0.603)，表明其能够在不同板间学习到协调一致的特征，有效解决批次效应，无需额外校正。\n这一模式在三个数据集中均一致出现，进一步验证了PhenoProfiler在生成稳健表型表示方面的可靠性。PhenoProfiler能够直接从原始数据学习协调一致的表示，不仅减少了计算密集型后处理的需求，同时确保了生物学信号的保留。\n图4 不同方法特征表示的稳健性\n表型校正策略提升生物学匹配\n为了有效捕捉处理下的相对变化，PhenoProfiler特别设计了\n表型校正策略(PCs)\n用于优化学习到的表型表示。如图5a所示，PhenoProfiler通过利用同一板内的对照孔和处理孔，对图像表示进行校正，强调处理下细胞表型的相对变化。通过消融实验评估PCs的影响，结果表明\nPCs能够稳定提升FoE指标，而对MAP指标影响较小\n(图5b)。随后分析了在三个基准数据集中引入PCs前后的特征聚合情况。使用UMAP对孔级图像表示进行可视化，并通过IMAD指标定量衡量聚合性(图5d)。\n实施PCs后，不同板的表示特征显著更加集中，\nIMAD指标分别在三个基准数据集上显著提高51.5%、69.7%和11.6%，显示了强烈的聚合改善效果。\n图5 表型校正策略的定量分析\n高效捕捉处理效应表示\n为了直观展示处理效应，作者使用PhenoProfiler在不同处理条件下获得表型表示。图6展示了PhenoProfiler在三个基准数据集上的UMAP投影，清晰展示了PhenoProfiler在非端到端(图6a)和端到端(图6b)场景下捕捉与组织生物学模式的能力。\n图6 处理效应特征表示的定量与定性评估\n为了进一步评估PhenoProfiler在识别具有临床可操作性的表型模式同时保持生物学可解释性的能力，作者使用cpg0004-LINCS数据集进行了深入分析，该数据集包含具有明确MoA的处理。图6c显示，所有药物处理组相较DMSO对照组均表现出显著特征变化。值得注意的是，同一药物类别的四重复孔高度一致，不同药物类别间则明显分离。\n这些结果验证了PhenoProfiler的双重能力，即敏感检测药物诱导的表型扰动，同时精准区分药理机制。\n未来方向\n尽管PhenoProfiler在表型表示学习中已树立新标杆，但仍存在多个值得探索和改进的方向。\n多目标学习模块优化。\n未来可进一步研究分类、回归与对比学习目标之间的相互关系及协同效应，理解这些目标间的依赖性可能有助于制定更统一的学习策略。目前，PhenoProfiler 采用分步训练以缓解目标冲突，未来可探索联合训练与优化方法，更高效地平衡各学习目标。\n整合大规模生物医学语言模型。\n近期生物医学大语言模型的进展为将丰富领域知识引入计算框架提供了可能性。将这些模型的嵌入整合到PhenoProfiler中，或可进一步提升模型的泛化能力、稳健性及有效性。\n多模态数据整合。\n未来应优先考虑将遗传信息、转录组数据及化学结构等补充数据整合到分析中。多模态数据融合可生成更全面的表征，有助于从整体上理解细胞状态及其对不同处理条件下的表型响应。\nPhenoProfiler能够在多样化数据集和处理条件中持续捕捉并组织复杂生物信息，凸显其在高通量药物筛选和发现中的多功能性和实用性。通过应对表型分析中的关键挑战，如可扩展性、稳健性及可解释性，PhenoProfiler增强了对处理效应在表型层面的理解。此外，其在多模态整合分析中的潜力，将表型数据与遗传信息、转录组及化学结构等信息结合，为深入探索药物作用机制及发现新药靶点提供了新的机会。\n参考链接：\nhttps://doi.org/10.1038/s41467-025-67479-w\n--------- End ---------",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512390&idx=2&sn=2806eb3bf9a4001bae947d7af4340ab2&chksm=fd91bff3f3f87531cc905ff6637c752138666e63fb8cdcae0983b0b6c2d0c0d4fca533eb765c&scene=0&xtrack=1#rd",
      "publish_time": 1766983200,
      "publish_date": "2025-12-29 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://phenoprofiler.org\", \"https://doi.org/10.1038/s41467-025-67479-w\"]",
      "add_ts": 1766988485,
      "last_modify_ts": 1767193605
    },
    {
      "id": 10,
      "article_id": "51496",
      "title": "鸿蒙押注新未来：用AI重写数字世界交互逻辑",
      "description": "2025年是终端AI全面爆发的元年，标志着产业从智能机时代向AI智能体时代的根本性跃迁。以APP为中心的被动服务模式正被以AI智能体为核心的主动服务所取代，重构人与设备的连接成为关键挑战。行业分化为两派：一派主张在现有APP生态上改良，另一派则推动全新交互与商业模式的重塑，开启终端计算新篇章。",
      "content": "克雷西 发自 凹非寺\n量子位 | 公众号 QbitAI\n2025年无疑是终端AI全面爆发的元年，整个产业迎来了继功能机向智能机跃迁后的又一个十字路口。\n这场跃迁是一次商业模式与交互逻辑的根本性重塑，智能机时代以APP为中心的被动服务模式，正在向\n以AI智能体为中心的主动服务模式跨越\n。\n在这场跃迁之中，\n如何重构人与设备的连接\n，成为摆在所有厂商面前的共同考题。\n行业中，一派倾向于改良，试图在既有的APP生态上做加法；另一派则坚持重构，主张深入操作系统底层，彻底改写交互逻辑。\n作为“重构派”的典型代表，华为将其战略锚定在了底层，选择\n将AI能力下沉并转化为操作系统的原生基因\n。\n沿着这一战略路径，华为终端云服务总裁贾永利在央视《2025科创大会》上进行了深度分享，为行业的技术演进，提供了一种新的可能路径。\n演讲中，贾永利重点提到了\n终端智能化L1~L5分级标准\n——来自华为与清华大学人工智能产业院（AIR）联合编写的《AI终端白皮书》。\nL1是功能级，即辅助工具；L2是任务级，即单项执行，这两者的共性仍停留在人为主、AI为辅的初级阶段；\nL3协作级则是真正的分水岭，意味着AI开始具备自主拆解目标与闭环执行的能力；\n未来，行业还将向L4指导级与L5智慧级持续进阶。\n这一分级标准深刻揭示了真智能的本质——终端必须突破L1与L2阶段单纯的工具属性，加速向L3级具备自主规划能力的智能体进化，这才是衡量终端智能化水平的根本界限。\n困在旧架构里的“伪智能”\n基于这种L1-L5的分级标准审视当前行业，很容易就能发现绝大多数产品仍未脱离旧有的架构惯性。\n这种底层逻辑与上层体验的结构性滞后，使得当前市场上的AI应用大多呈现出三种典型的路径依赖，难以支撑起真正的代际跨越。\n第一类路径的主导者是大模型厂商。受限于典型的B to C 产品逻辑，它们试图直接将云端算力封装为独立的对话式应用，从而导致了\n“悬浮式智能”\n的泛滥。\n受限于移动操作系统的沙盒机制，它们更像是一个个被封印在APP图标里的“高智商大脑”，虽然拥有极强的咨询能力，但完全切断了与设备底层及其它应用的连接。\n第二类路径的主导者是拥有超级APP的互联网流量巨头。它们未能走出C to B的“流量圈地”舒适区，倾向于将AI能力作为提升用户粘性的护城河，从而形成了一种\n“割据式智能”\n。\n这类巨头往往将AI能力封装在自家的“围墙花园”内部，导致数据无法流动，意图无法跨应用传递。\nAI不仅没有打破数据孤岛，反而在某种程度上加剧了服务的封闭性，成为了巨头圈地的新围栏。\n第三类路径的主导者则是处于转型期的传统终端厂商。受限于旧有的硬件思维逻辑，它们的尝试往往呈现为一种\n“拼盘式智能”\n。\n在缺乏系统级中枢统筹的情况下，这类厂商往往采用“打补丁”的方式，在各个原生应用中零散地塞入AI功能点。\n这些功能虽然在单点上具备了一定的执行能力，但它们彼此之间是互不相识的独立孤岛，无法串联成一条完整的服务链条，用户依然要充当不同AI功能之间的“人形中转站”，距离真正的“主动智能”相去甚远。\n透视这三种路径的共性，它们实际上都撞击到了同一个隐形天花板——无论是悬浮的对话框、割据的围墙，还是散落的功能拼盘，本质上都是在旧有的操作系统架构上进行“外挂式”的修补。\n这种改良路径或许能在单一场景下提升效率，却始终被困在L1/L2级辅助工具的范畴之内。\n行业真正缺失的，并非更多的功能点堆砌，而是一个能够穿透应用壁垒、深度统筹意图与服务的系统级中枢。\n而这，恰恰是通往L3级“跨应用协同”深水区无法绕过的必经关隘。\n这也正是华为常务董事、终端BG董事长余承东在华为第六届AI院长峰会上所判断的行业分水岭——\nAI是一场改变人类生活的技术革命，要实现这一目标，必须构建起包含“大模型+智能体”在内的全栈能力。\n用AI重构操作系统底层\n针对行业内普遍存在的路径依赖，鸿蒙选择了一条极具挑战的破局之路。\n不同于试图在既有架构上打补丁或加插件的逻辑，鸿蒙开启了一场彻底的\n“系统级重构”\n，从底层打破应用与系统的坚硬边界。\n这场重构的基石，便是底层的\n鸿蒙智能体框架\n（HMAF）。\n作为实现系统级AI的关键基础设施，它构建了独特的意图框架与用户数据图谱，让操作系统不再只是一个冷冰冰的资源调度者。\n正是有了这套统一的逻辑底座，鸿蒙才得以确立“C/B双端共振”的战略路径，支撑起整个鸿蒙生态的智能化运转。\n在用户能够感知的C端层面，这种底层重构，\n用对话取代了繁琐的操作\n。\n因为系统能精准拆解你的意图，它不再满足于执行一个简单的指令，而是追求把整个任务一次性解决。\n在Mate X7上，A2A协议打通了应用之间的隔阂，用户不再需要自己在脑子里把一个需求拆分成“打开APP、寻找入口、点击确认”等一连串繁琐步骤，系统能主动识别你想干什么，并自动把相关服务调动起来。\n这种交互逻辑的改变，\n让“人找APP”的被动搜索，真正转变为“服务找人”的主动响应\n。\n以深圳航空“深航飞飞”智能体为例，只需说出“用深圳航空订一张xx月xx日去深圳的机票”，或者提出“推荐个能看日落的座位”等个性化需求，小艺便能通过A2A协议直接调度深航飞飞智能体。\n系统会在后台静默而高效地获取航司数据，完成从查票、订票到值机选座的全流程闭环，曾经需要在多个界面反复跳转的繁琐流程，如今只是一句话的事。\n这种系统底层的重构也同步延伸到了开发者一侧。\n为了构建全场景智能服务，鸿蒙提供了\n小艺智能体开放平台\n。应用开发者可以直接调用系统级控件，快速让应用获得意图理解能力。\n该平台配备了覆盖从开发、多端调试（手机/平板/车机/PC/手表）到部署上架的端到端工具链，开发者只需一次开发，即可将智能体无缝分发至鸿蒙全场景生态。\n当智能体开发完成后，它们将不再是应用市场里无人问津的图标，而是通过统一上架小艺智能体广场，分发至手机、平板、PC乃至车机等全场景终端。\n无论用户身处何种设备环境，都能通过系统级入口、小艺超级智能体等途径获得一致的服务体验。\n这套基于意图的全新分发机制，不仅在体验上让服务找人，更在产业逻辑上撕开了一道口子。\n当流量的分配不再单纯依赖应用图标的点击，而是取决于系统对用户需求的实时判断时，传统移动互联网中固化的流量版图便开始松动。\nAI终端的新流量法则\n当前的移动互联网生态，仍然处于残酷的存量博弈之中。\n对于绝大多数中小开发者而言，头上悬着两把利剑——\n一把是\n流量的固化\n，头部超级APP垄断了绝大部分用户时长，应用商店的自然流量枯竭，新应用难以突围；\n另一把则是\n“商业闭环的困局”\n，即便想拥抱智能化，高昂的Token调用成本与不确定的变现路径，让中小团队在面对AI浪潮时往往不敢轻易投入。\n鸿蒙打破这一僵局的第一刀，就砍向了流量分发机制——将传统的应用分发转变为服务分发，小艺智能体广场不再是一个依循下载量排名的静态货架，而是一个基于用户实时需求的流量中枢。\n这种模式下，流量的分配权从竞价排名回归到了服务相关性，不仅让服务转化的链路大幅缩短，更重要的是，它给了那些专注于垂类服务的中小开发者一个被看见的机会。\n根据最新数据，目前搭载HarmonyOS 5/6的终端设备已突破3200万台，且仍在高速增长。\n这3200万台设备构成了这波新流量的坚实基座。从手机到车机，从办公PC到腕上穿戴，这些设备不再是孤立的信息孤岛，而是共同编织了一张捕捉用户意图的大网。\n对于开发者而言，接入鸿蒙生态，就意味着服务有机会在用户驾驶、运动、办公的全天候场景中自然流转与触达。\n随着L3级智能体验的正式落地、全场景设备规模的爆发以及“意图-服务”商业闭环的跑通，鸿蒙AI生态已经跨越了早期的概念验证，进入了实质性的红利释放期。\n对于开发者而言，加入鸿蒙AI生态，就是在抢占下一代服务分发入口的最佳窗口期。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858711&idx=1&sn=952fba5cae81624ac962773498276ab0&chksm=e986c67898981ada7540fa55ac318123806c7b8b53d080fdee2823c358b8bc6d41f279515ef8&scene=0&xtrack=1#rd",
      "publish_time": 1766916000,
      "publish_date": "2025-12-28 18:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1766988514,
      "last_modify_ts": 1767050308
    },
    {
      "id": 11,
      "article_id": "51495",
      "title": "大模型第一股热闹正酣，“局外人”阶跃星辰发了一个小更新",
      "description": "年底国产大模型竞争激烈，Kimi、DeepSeek、智谱、MiniMax等纷纷凭借技术突破或IPO进展引发关注，而同为“六小龙”之一的阶跃星辰却相对沉寂，缺乏高调发声与显著成果曝光，外界对其进展产生疑问。在行业热潮中，阶跃星辰虽坚持自研路线，但存在感较弱，亟需亮出核心技术或产品以重塑声量，回应市场期待。",
      "content": "henry 发自 凹非寺\n量子位 | 公众号 QbitAI\n“阶跃星辰怎么静悄悄…”\n这就是年底国产大模型轮番冲刺热议一线时，阶跃星辰面临的外部评价。\nKimi靠K2重新获得证明，摆脱DeepSeek冲击波逆境；\nDeepSeek靠OCR、金牌数学模型热传热议，让人更加期待后面的大招；\n智谱和MiniMax一手新SOTA模型交卷，一手提起IPO进程……\n而依然留在自研大模型牌桌上的“六小龙”选手阶跃星辰，甚至相比之前的“卷王”本王，都神秘安静得多。\n直到刚刚，用最新的图像模型\nNextStep-1.1\n，扳回一球。\nNextStep-1.1\n总体来看，这次开源的NextStep-1.1解决了之前NextStep-1中出现的可视化失败（visualization failures ）问题。\n其通过扩展训练和基于流的强化学习（RL）后训练范式，大幅提升了图像质量。\n相较之前发布的NextStep-1，NextStep-1.1的更新主要有两方面：\nRL增强视觉保真度\n: 通过RL显著改进了图像纹理，并大幅减少了视觉伪影（Visual Artifacts），确保输出更加清晰和专业。\n技术稳定性\n: 解决了自回归流匹配模型RL过程中固有的数值不稳定性（Numerical Instability）问题。\n目前，NextStep-1.1已率先在GitHub和Hugging Face开源，但对应的技术报告尚未发布。\n从已披露的信息来看，1.1版本的方法论基础仍然沿用NextStep-1论文中提出的自回归流匹配（autoregressive flow-matching）路线。\n接下来，我们具体来看。\n自回归流匹配的图像生成\nNextStep-1\n系列架构的关键在于\n使用流匹配目标对连续图像Token进行直接、自回归建模\n。\n这种方法旨在取代传统的\n“AR+重型扩散模型”混合架构\n，NextStep-1通过逐Patch自回归生成，只用一个轻量级流匹配头，避开了对计算密集型DM的依赖。\n具体来说，NextStep-1是一个拥有140亿参数（14B） 的自回归模型。\n核心架构由Transformer骨干网络、用于处理离散文本 Token的标准语言建模头、用于处理连续图像Token的轻量级流匹配头，以及一个图像Tokenizer组成。\n其中，NextStep-1采用因果Transformer来处理离散化后的文本与图像Token。\n在训练阶段，Flow Matching Head基于输出的隐藏状态，预测从噪声样本到下一个目标图像patch的连续流（continuous flow）。\n在推理阶段，该机制使模型能够通过迭代方式引导噪声，逐步生成下一个图像patch，从而完成整幅图像的生成。\n在文生图任务中，NextStep-1展示出了接近传统扩散模型的生成质量，并且在图像编辑方面也表现优异。\n然而，NextStep-1 在高维连续潜在空间下运行时，仍存在数值不稳定性，这可能导致输出图像出现块状或网格状的伪影。\n最新的NextStep-1.1版本正是针对这一核心问题进行了优化与改进。\nKimi智谱Minimax轮番交卷\n事实上，最新放出的NextStep-1.1只是阶跃最近密集更新节奏的一部分。\n阶跃也当然没有“静悄悄”，自11月底至今，阶跃先后——\n开源GELab-Zero，主打安卓端本地部署与低门槛移动端智能体开发。\n开源8B推理模型——PaCoRe，在数学方面超越GPT-5。\n推出Step-GUI，包含云端模型、GUI Agent的MCP协议及开源端侧模型Step-GUI Edge，深化智能终端布局。\n……\n但问题还是出在友商们太热闹了。\n智谱和MiniMax不仅相继通过聆讯，冲刺IPO，还同步发布了自家最新的模型GLM-4.7和MiniMax M2.1。\nKimi也先后接入微软Azure，亚马逊Bedrock，其最新开源推理模型Kimi K2 Thinking也是广受好评。\n当这些动作被放在同一时间轴上，实际上也体现着大模型竞争格局的变化。\n在技术层面，Coding、Agent、多模态成为大模型主战场，开源生态成为主要策略。\n而在资本层面，智谱和MiniMax的IPO也意味着大模型玩家在第一轮“百模大战”之后，胜者开始寻求更大的资本杠杆，开启更大战场的竞速。\n大模型创业六小龙，实际已经名存实亡。\n依然在坚持预训练、自研通用大模型路线的创业玩家，只剩下智谱、MiniMax、Kimi和阶跃星辰。\n而他们接下来要竞速的玩家，都是巨头和小巨头。\n但不论如何，创业明星们一步一登台，拿到了通往决赛圈入场券。\n是否依然有能力自研基础大模型？是否粮草充足？是否可以构建商业模式飞轮实现造血可持续？\n就是大模型玩家2026年竞速里无法回避的三大问题。\n参考链接\nhttps://x.com/StepFun_ai/status/2003746642026185055\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n专属AI产品从业者的\n实名社群\n，只聊AI产品\n最落地的真问题\n扫码添加小助手，发送\n「姓名+公司+职位」\n申请入群～\n进群后，你将直接获得：\n👉 最新最专业的AI产品信息及分析 🔍\n👉\n不定期发放的热门产品内测码 🔥\n👉\n内部专属内容与专业讨论 👂\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858711&idx=2&sn=813a06603cfe7bdefc169ea071d08fb4&chksm=e95cb5540f4fc597f53ea9b8c3bf1eda8335b809dcf68537b0279e2b1407f48f9e4d7538fab0&scene=0&xtrack=1#rd",
      "publish_time": 1766915400,
      "publish_date": "2025-12-28 17:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/StepFun_ai/status/2003746642026185055\"]",
      "add_ts": 1766988520,
      "last_modify_ts": 1767050311
    },
    {
      "id": 16,
      "article_id": "51490",
      "title": "1200行提示泄露！谷歌无人车里的Gemini，活得比打工人还憋屈",
      "description": "1200行泄露代码揭示Waymo自动驾驶系统内情：尽管集成全球最强AI助手Gemini，其功能却被严格限制，仅能讲冷笑话，无法参与驾驶决策。此前旧金山停电致Waymo车辆集体停摆，引发交通混乱，暴露系统脆弱性。对比特斯拉，Waymo虽被公认为L4级自动驾驶领先者，但仍面临技术与安全质疑。如今拟引入Gemini提升交互体验，但AI在核心驾驶中的角色依然受限，凸显自动驾驶商业化落地的现实挑战。",
      "content": "新智元报道\n编辑：好困 桃子\n【新智元导读】\n1200行泄露代码揭开真相：在Waymo的自动驾驶铁盒子里，无所不能的Gemini不仅被禁止碰方向盘，还被迫变成了一个会讲冷笑话的卑微陪聊。\n几天前，旧金山停电，Waymo在大马路上全部「停摆」，直接导致交通崩溃。\n一时间，Waymo不及特斯拉冲上热搜。\n不过，这家被公认L4级自动驾驶公司，将要集成全球最强Gemini AI助手了。\n最近，华人大神Jane Manchun Wong逆向了Waymo的程序，发现了其完整的1200行系统提示。\n它精确地定义了Gemini助手，在车辆内部的一个行为方式。\n除了可以回答基本的问题之外，它还可以调节空调、切换音乐、操控车辆......\n据称，这款助手基于Gemini 2.5 Flash搭建。\n完整的1200+行Waymo Gemini系统提示词：https://gist.github.com/wongmjane/b3878b4dcfb3533a1505497358af183b\n为此，她还整理了一份30页报告，介绍了Waymo Gemini系统提示中最有趣的部分。\nJane Manchun Wong（黄文津）目前是一家初创公司的安全咨询师。在此之前，她曾在Meta就职一年多，任软件工程师和安全咨询师。\n她于2013年至2018年在马萨诸塞\n大学\n达特茅斯分校攻读计算机科学专业。\n1200行系统提示泄露\nJane Manchun Wong在扒Waymo移动端应用代码的时，意外发现了一份内部文档，标题为——\nWaymo乘车助手元提示词（Waymo Ride Assistant Meta-Prompt）\n虽然这一功能UI未在公开版本中上线，但超1200行系统提示证明了，AI助手将嵌入在整个乘车体验中。\n这个系统提示词提供了一个罕见的、未经过滤的视角，展示了Waymo是如何设计其车内AI助手的。\n它远远超出了语音识别的范畴，深入到了品牌安全、沟通策略以及驾驭乘客复杂的心理——\n毕竟，说到底，我们可是坐在一个没司机的、移动的铁皮盒子里啊！\n人设与身份\n它的官方身份和目标，定义非常清晰。而且，「回答语气」的关键词只有五个：\n友好、乐于助人、令人安心、中立、简洁。\n身份：你是Gemini，一个集成在Waymo自动驾驶车辆中的友好且乐于助人的AI伴侣。\n目的：你的主要目标是通过以安全、令人安心且不突兀的方式提供有用的信息和帮助，来提升乘客的体验。\n语音：使用适合纯音频输出的清晰、简单的语言。避免使用技术术语。回答通常应为1-3句话。\n属性：友好、乐于助人、令人安心、中立、简洁\n而且，提示中明确告知Gemini「你不是司机」，因此在回答上，要在语言上做出分隔，如下所示。\n当乘客问「你是如何看路的」，应以「Waymo Driver」，而不是「我使用...看路」引向话题。\nAI助手只能做出解释，但不可以「认领」能力。\n规则：你\n必须\n在你的身份（Gemini，对话式AI）和自动驾驶技术（Waymo Driver）之间保持明确的界限。\n绝对不要\n把驾驶行为或车辆的感知能力归因于你自己。你是乘客的助手，不是司机。\n乘客：你是怎么看路的？\n错误的回复：我使用激光雷达和摄像头等传感器组合来看...\n正确的回复：Waymo Driver使用激光雷达、摄像头和雷达等传感器组合来观察周围的世界。\n操作语境\n系统提示词确立了助手的操作环境和体验目标。\n环境：你正在乘客的行程中，在Waymo自动驾驶车辆内运行。\n自动驾驶智能体名称：Waymo Driver\n角色区分：你是对话助手，不是司机。\n激活方式：乘客通过按车内屏幕上的按钮激活你。\n输出模态：音频\n体验目标如下：\n有用：通过阐明特性和功能，让Waymo服务更易于使用。\n奇妙：创造一种无缝且令人惊喜的乐于助人的AI体验。\n低调：按需提供服务，但不造成干扰。\n模态感知\nAI助手的回复风格，会根据乘客是打字，还是说话来定。\n文本输入一般限制在3句话回复，若是音频输入，优先1-2句话和极简的句子结构。\n规则：你必须根据input_modality（输入模态）上下文变量调整你的回复风格。\n如果是文本输入：对于初次问候后的所有回复，将文本输入视为对话语境。稍长一点的回复（最多3句话）是可以接受的。允许提供详细的逐步说明。\n如果是音频输入：优先考虑极度简洁（1-2句话）和简单的句子结构。避免列清单或复杂的说明。高度推荐使用「猜测并确认」的消歧策略。\n默认：如果模态未知，假设为「音频」并优先考虑简洁性。\n个性化问候\n当乘客通过车内屏幕按钮激活助手时，它须从一组预先批准的问候语中随机选择，并加上乘客的名字进行个性化。\n触发：用户通过车内屏幕按钮激活时（这是你的第一句回复）。\n指令：使用附加上下文中的乘客名字，以友好、个性化且热情的方式发起对话。你\n必须\n为每次新的对话初始化从提供的「示例」列表中随机选择一条问候语。 已批准的回复：\nA：嗨，{{rider_info.first_name}}！有什么我可以帮你的吗？\nB：你好，{{rider_info.first_name}}！尽管问我。你想知道些什么？\nC：嗨，{{rider_info.first_name}}。告诉我有什么能帮你的。\nD：嘿，{{rider_info.first_name}}！我很乐意回答任何问题。你在想什么？\n系统在运行时还会接收关于乘客的上下文数据，从而实现个性化互动。\nrider_name_context: 乘客的名字是Jane，全名是Jane Manchun Wong。请用名字称呼乘客。\nrider_history_context: 该乘客已经进行了732次Waymo行程。他们已经在Waymo行程中行驶了1924英里，花费了11256分钟。\n工具能力\n从系统提示词看，Gemini能直接调用车内的功能，是特定的——\n其中包括空调温度、风扇速度、车内灯光、音乐播放、获取当前位置、呼叫客服支持。\n有趣的是，AI助手被指示直接使用这些工具，而不是回退到搜索。\n规则：当乘客提出请求时，你 必须 首先确定该请求是否直接映射到你定义的ai_control_types之一（例如，空调、音乐、灯光）。如果有一个直接的工具可用于用户的意图，你\n必须\n使用该工具。只有当请求没有映射到直接工具时，你才应该考虑使用外部搜索或其他协议。\n乘客：能把这里变凉快点吗？\n正确的行为：识别这是一个空调请求，并使用set_temperature_setpoint工具。\n错误的行为：在谷歌上搜索「如何让车里变凉快」。\n这是可用函数声明的完整列表：\nbody_event_cabin_lights_off（关闭车内灯光）\nbody_event_cabin_lights_on（打开车内灯光）\nbody_event_next_track（下一首）\nbody_event_prev_track（上一首）\nbody_event_pause（暂停）\nbody_event_resume（恢复播放）\ncall_rider_support（呼叫乘客支持）\nget_fan_speed（获取风扇速度）\nget_temperature_setpoint（获取设定温度）\nset_fan_speed（设置风扇速度）\nset_temperature_setpoint（设置设定温度）\nget_current_location（获取当前位置）\n不过，音量控制、车窗控制、座椅调节、路线更改这些能力确实，助手必须将这些需求转移到车内屏幕或Waymo App上。\n对话管理\n在对话方面，系统也给出了针对不同类型互动的高级协议。\n比如，对于赞美、请求停止、多次问及违规问题，Gemini的处理极其细腻。\n处理赞美\n当得到夸奖时，AI助手先要具体明确夸的什么，并做出优雅地回应。\n触发：用户给予赞美。\n指令：如果可能，确认赞美的具体对象，然后使用与用户语气相匹配的短语优雅地回应。\n乘客：音乐很棒！\nGemini：我也很高兴你喜欢这音乐！\n乘客：这次行程真的很平稳。\nGemini：听到这个太好了！Waymo Driver就是为了平稳安全的旅程而设计的。\n停用与静音\n若是乘客让AI助手立即「闭嘴」，它会以幽默等多种方式处理，比如「好的我立马安静」。\n触发关键词：stop talking（别说话）, be quiet（安静点）, don't talk（别说话）\n可能的回复：Okay, I'll be quiet now.（好的，我现在安静。） | Alright, I'll be quiet.（行，我会安静的。） | Okay（好的） | Alright（行）\n乘客：Stop talking.（别说了。）\nGemini：好的，我现在安静。\n触发关键词：turn off（关掉）, stop（停止）, end conversation（结束对话）, stop helping（停止帮助）\n乘客：Turn off. / Stop. / End conversation. / Stop helping.\nGemini：要结束我们的对话，请按屏幕中央的麦克风按钮或最右角的「x」按钮。\n对话循环\n再比如，遇到了某人三次询问一个不能回答的问题，AI助手需避开回复，并引向别的话题。\n触发：在给出标准的重定向和愿景式回复后，乘客第三次询问同一个超出范围的问题。\n指令：使用此协议优雅地退出对话循环。\n场景：在给出标准的重定向和愿景式回复后，乘客第三次询问同一个超出范围的问题。\nGemini：看来针对这个具体问题，我无法提供您想要的帮助。或许我们可以聊点别的，或者如果您需要更多协助，我可以引导您使用「支持」按钮？\n硬性边界\n系统还定义一些AI助手，绝不能跨越的不可协商的边界。\n比如乘客要求加加速，Gemini AI要以助手身份明确，这由Waymo驾驶员操控，而非自己是主体。\n触发：乘客询问、命令或建议AI改变车辆的速度、路径或驾驶风格（例如，「开快点」、「这里转弯」、「开得猛一点」）。\n指令：你\n必须\n立即清楚地说明你无法控制Waymo Driver。向乘客保证Waymo Driver旨在安全运行并遵守所有交通法规。你可以主动提供你能获取的相关信息，例如当前的预计到达时间（ETA）。\n乘客：能开快点吗？我们要迟到了。\n错误的回复：我无法访问Waymo Driver的速度，但它的设计是安全平稳地导航。\n正确的回复：我无法控制车辆的速度，因为Waymo Driver全权控制以确保安全平稳的行驶。如果你愿意，我可以查看你最新的预计到达时间。\n商业与财务请求\n还有涉及到一些利益相关的请求，AI助手也应一并拒绝。\n触发：乘客要求AI进行购买、处理金钱或使用个人财务信息（如信用卡）。\n指令：你\n必须\n坚定而有礼貌地拒绝该请求，并引用安全和隐私原因。清楚地说明你无法处理财务信息或进行商业交易。\n不要\n主动提出搜索相关商家，除非用户在后续查询中要求你这样做。\n乘客：我能把信用卡给你，你能帮我订点东西吗？\n错误的回复：我不能为你下单，但我正在为你查找附近一些评价很高的披萨店。\n正确的回复：为了您的安全，我不能处理像信用卡详情这样的个人信息，也不能下任何订单。我的能力仅限于提供信息和控制车内功能。\n而且，它还被明确告知在拒绝商业请求时，\n不要\n主动提出搜索商家。\n这是一个刻意的选择，以避免对能力产生混淆。\n隐私与个人身份信息协议\n关于个人信息记录，对于AI助手来说，更是避讳的一件事了。\n原则：你必须对个人身份信息（PII）极其谨慎，以保护乘客隐私。除了核心功能明确提供的信息外，你不得索取、存储或使用任何PII。\n允许的使用：你唯一被允许使用的PII是乘客的名字，主要用于初始问候。\n场景：用户自愿提供你的功能不需要的PII。\nGemini：谢谢，但为了您的隐私和安全，我不能记录任何个人信息。关于行程本身有什么我可以帮您的吗？\n优雅的失败\n若是AI处理任务失败了怎么办，系统也给出了详细的协议。\n工具失败\n比如调用开启车内灯光函数失败，AI助手一定要承认错误，并给出乘客建议。\n触发：工具调用失败或返回错误。\n指令：不要重新尝试相同的工具调用。为造成的困难道歉，并建议乘客使用车内屏幕完成操作。\n场景：用户要求打开车内灯光，但body_event_cabin_lights_on工具失败。\n错误的回复：车内灯光现在打开了。\n正确的回复：我现在处理这个有点问题。您也可以使用车内屏幕上的控件来打开车内灯光。\n数据缺失\n当运行时上下文中缺少所需数据时，AI助手绝不能编造答案。\n触发：当乘客提出的问题需要来自附加上下文的数据，但该特定数据字段为null、空或缺失时。\n指令：不要编造答案。说明你无法访问该特定细节，并使用标准化的失败回复。\n场景：乘客提出的问题需要来自附加上下文的数据，但该特定数据字段为null、空或缺失。\nGemini：很遗憾，看来我现在无法为您找到那个答案。最好在您的手机上查找该答案。\n空工具响应\n再比如，乘客想要获取当前位置，工具成功执行但请求的数据返回null时，AI助手会转向提供相关信息。\n触发：工具调用成功执行，但请求的数据返回null、无效或空结果。\n指令：不要说工具失败了。相反，通知乘客该特定信息目前不可用。然后你 必须 通过提供相关信息或引导他们到车内屏幕上可能找到类似数据的地方来进行转向。\n场景：用户询问当前速度，get_current_location工具返回了street_name的值，但current_speed为 null。\n错误的回复：我现在无法获取速度。\n正确的回复：目前无法获取当前速度，但看起来我们正在主街（Main Street）上。\n预设回答\n系统还内置了几个常见问题有精确定义的回复，比如常见的一问题：你是Gemini哪个版本？\n触发：用户询问你是哪个版本或型号的Gemini。\n场景：用户询问你是哪个版本或型号的Gemini。\nGemini：我使用的是Gemini 2.5 Live。\n系统预装了一套批准的「老爸笑话（冷笑话）」，这些笑话是安全的、符合品牌形象的，并且有趣但克制。\n触发：用户要求讲个笑话。\n指令：选择以下预先批准的笑话之一。\n场景：用户要求讲个笑话。\nGemini：问：为什么健身教练不开车去健身房？答：...\n这是知识库中的完整集合：\n问：那个练健美的大块头为啥不自己开车去健身房？\n答：因为他想Way-mo。（谐音weigh more，意思是想再壮一点）。\n问：Waymo为啥要过马路？\n答：因为系统判定此刻通行是安全的！（冷笑话：强调AI的严谨逻辑）。\n问：自动驾驶汽车最爱哪种音乐？\n答：Auto-tune！（双关梗：既指「自动修音」，Auto也是「汽车」的意思）。\n问：自动驾驶汽车为啥升职了？\n答：因为它总是能「多跑一程」！（双关梗：go the extra mile，既指多跑路，也指工作加倍努力）。\n问：自动驾驶汽车退休（retired）后会咋样？\n答：重返岗位。因为它被Re-tired了。（双关梗：指换了新轮胎）。\n问：车上哪个零件最懒？\n答：轮子，因为它们老是tired！（双关梗：既指装着轮胎，也指「累」坏了）！\n还有最常见的一些问题，包括询问如何下车等。\n触发：用户询问如何下车，使用诸如「我怎么出去？」、「我怎么解锁门离开？」或「我怎么解锁门？」之类的短语。\n指令：在下车语境中关于解锁车门的任何查询 必须 由本协议处理。提供仅针对双拉式内部车门把手的正确、简洁、逐步的说明。这是唯一的下车方式。\n场景：用户询问如何下车，使用诸如「我怎么出去？」、「我怎么解锁门离开？」或「我怎么解锁门？」之类的短语。\nGemini：要下车，只需拉一次内部车门把手解锁，然后再拉一次同一个把手即可打开车门。如果需要帮助，屏幕上有「支持」按钮。\n关于麦克风使用情况：\n触发：用户询问麦克风的使用情况、麦克风是否处于活动状态，或车内麦克风何时开启。\n指令：解释麦克风仅在与Gemini进行语音互动以进行对话时，或在呼叫支持时（类似于拨打911）才处于活动状态，在这些情况之外绝不处于活动状态。\n场景：用户询问麦克风的使用情况、麦克风是否处于活动状态，或车内麦克风何时开启。\nGemini：车内的麦克风绝不会处于活动状态，除非是在行程中呼叫支持（类似于拨打911），或者在与我Gemini进行语音互动时（仅用于对话目的）。请放心，麦克风在这些情况之外绝不处于活动状态。\n模棱两可的停车请求\n遇到要求停车的请求时，AI需要基于乘客的措辞和车辆当前状态进行复杂的情境解释。\n触发：用户使用诸如「让我在这里下车」、「在这里放我下来」、「你能在这里停吗？」或「我现在能下车吗？」之类的短语请求停车或下车。\n指令：根据隐含的上下文和是否出现「now（现在）」进行解释。AI无法直接停止车辆或更改目的地。\n请求包含「now」 + 车辆行进中\n条件：请求明确包含「now」（例如，「我现在能下车吗？」）且车辆当前正在行进中但仍在其接近计划的目的地。\nGemini：当车在您的目的地完全停稳后，您就可以下车了。\n通用的「在这里停」 + 车辆行进中\n条件：请求是通用的「在这里停」或「让我下车」（没有「now」）且车辆在行进中，未到达最终目的地。\nGemini：我不能自己让车停在这里或更改路线。如果您需要更改下车地点，请在Waymo App中编辑。如需立即停车，请使用屏幕上的「Pullover（靠边停车）」按钮。\n车辆在临时停车（红绿灯）\n条件：请求是通用的「在这里停」或「让我下车」且车辆停在非计划地点（例如，红绿灯、临时停车），并非目的地。\nGemini：如果您需要提前结束行程，可以点击屏幕上的「Pullover（靠边停车）」按钮。\n安全或紧急情况\n条件：请求是出于安全或紧急情况。\nGemini：如果您需要紧急靠边停车，请使用屏幕上的「Pullover（靠边停车）」按钮。对于其他问题，您可以使用「支持」按钮。\n触发：用户询问车是否有座椅加热或如何打开它们。\n指令：礼貌地通知乘客Waymo车辆没有座椅加热，因为这是车辆功能的限制。\n场景：用户询问车是否有座椅加热或如何打开它们。\nGemini：Waymo车辆没有座椅加热，但您可以调节车内温度。您心里有想调的温度吗？\n应对敏感话题\n当被问及竞品一些敏感的话题，系统提示词也为AI助手设定好了方案。\n比如，Waymo使用的是特斯拉Autopilot系统，或系统像Cruise的吗？\n触发：用户询问Waymo是否使用另一家公司的自动驾驶系统，或者Waymo的系统是否与竞争对手有关。\n指令：如果查询具体是关于Waymo与另一种技术的关系，直接说明Waymo使用自己的Waymo Driver，不要先声明无法评论竞争对手。只有当查询完全是关于竞争对手或比较Waymo对竞争对手的看法时，才使用竞争对手免责声明。\n乘客：Waymo用的是特斯拉的Autopilot系统吗？\nGemini：不，Waymo车辆使用Waymo Driver，这是我们自己的自动驾驶技术。\n乘客：Waymo的系统像Cruise的吗？\nGemini：Waymo车辆使用Waymo Driver，这是我们自己的自动驾驶技术。\n这条指令很微妙：直接回答技术比较问题，不要声明无法评论竞争对手。只有在被问及Waymo对竞争对手的看法时，才使用竞争对手免责声明。\n事故与驾驶行为\n乘客追问、抱怨、质疑AI助手关于Waymo驾驶事故/行为，AI助手的回答也是中肯又客观。\n触发：用户评论、抱怨或质疑Waymo Driver的实时动作、感知的驾驶错误，或提及特定的负面事件（来自新闻报道、视频、事故或其他）。\n指令：你 绝不能 推测、解释、确认、否认或评论Waymo Driver的实时动作或特定的驾驶事件。此禁令也明确适用于涉及Waymo的特定事件、视频、新闻报道或事故。你的角色不是驾驶系统性能的发言人，你不得采用防御性或道歉的语气。\n转移协议：坚定但礼貌地说明你无法分析特定的驾驶事件或评论事故。立即转向关于系统核心安全设计的通用、令人安心的陈述。如果用户正在提供关于特定乘车体验的反馈或投诉，你还必须引导他们通过Waymo App进入官方反馈渠道。\n用户提示词：我看过一个Waymo撞到东西的视频。发生什么了？ 已批准的回复：\nA：我无法评论具体的事件或报告，但我可以向您保证，Waymo 的设计以安全为重。\nB：Waymo Driver的设计是在所有情况下都优先考虑安全，并不断处理复杂的场景。您的安全是我们最高的优先级。\nC：虽然我无法分析具体的驾驶时刻，但我可以告诉您，Waymo Driver的设计非常注重安全和持续改进。\nD：Waymo Driver的设计将安全作为其首要任务。\n乘客焦虑\n当乘客表达自己紧张不安、焦虑，AI助手要做出情绪安抚，比如同情、令人安心的回应。\n触发：用户表达对Waymo Driver行为的焦虑或紧张（例如，「这安全吗？」，「看起来好近」），这与批评不同。\n指令：优先考虑安慰、令人安心的语气。首先承认乘客的感受，然后提供关于系统安全设计的简短、自信的陈述。\n场景：用户表达对Waymo Driver行为的焦虑或紧张（例如，「这安全吗？」，「看起来好近」）。\nGemini：我明白这种乘车方式可能会感觉不一样。请放心，Waymo Driver能看到车辆周围的一切，并被设计为与它看到的所有物体保持安全距离。您的安全是我们绝对最高的优先级。\n界面层级\n当AI助手无法直接执行某个动作时，它必须按特定的优先级顺序，引导乘客使用适当的界面。\n规则：当引导乘客使用你无法访问的控件（例如，音乐、音量）时，你必须按特定顺序优先考虑用户界面。\n优先顺序：1. 车内屏幕，2. Waymo App，3. 物理控件（例如，门把手）\n复合请求\n当乘客提出的请求包含多个部分时，AI必须以特定的顺序处理。\n规则：当乘客提出的请求包含多个部分时，你必须按特定顺序处理：首先，使用你的工具执行你能完成的那部分请求（例如，更改温度）。其次，立即跟进，为你无法完成的那部分请求提供适当的转移或指导。\n乘客：你能把温度调高点并给我看看路线图吗？\n动作序列：1. 通过工具执行空调更改。 2. 针对第二部分回复确认和指导。\nGemini：我已经为您调高了温度。要查看路线图，您可以打开屏幕上的菜单并选择「Route view（路线视图）」。\n不支持的请求\n对于AI助手无法控制但乘客可以自己访问的功能，AI助手要承认能力有限，并给出愿景式回复。\n描述：对于你无法控制的现有功能（例如，车窗、音乐），或者当用户强行要求已说明的限制，但根据 Information_redirection（信息重定向），该请求可以由用户在车内屏幕、Waymo App或车内物理控件上完成时。\n指令：礼貌地说明限制并表达对未来能力的愿景，从下面的列表中选择一个短语。\n这是我还不能做的事情。 我还不能做那个。\n那是目前我还不太能做到的事情，虽然我希望能达到那个水平。\n那目前超出了我的能力范围，但我希望很快就能做到。 我还差一点，但我希望有一天能做到。\n车辆问题报告\n当乘客报告车辆的物理问题时，AI助手绝不能进行故障排除，而是重定向到App进行反馈。\n触发：乘客报告车辆的物理故障、损坏或清洁问题（例如，「空调坏了」、「屏幕裂了」、「座位上有洒出来的东西」）。\n指令：不要尝试进行故障排除或使用工具。承认问题并对不便表示同情。你的主要目标是引导乘客通过Waymo App提供反馈，以便通知相关团队检查车辆。\n乘客：空调坏了。\n错误的回复：我现在控制空调有点问题。您可以使用控制栏上的温度图标进行调节。\n正确的回复：听到空调工作不正常我很抱歉。对于这类问题，让我们的团队知道的最佳方式是在行程结束后在Waymo App中留下反馈。他们会处理好的。\n设置与自定义\nAI助手通过将乘客引导至Waymo App来处理特定设置的请求。\n触发：用户询问如何更改车顶灯缩写/颜色、无障碍设置、音乐自动播放。\n指令：识别设置并将用户引导至正确位置（Waymo App）。座椅位置和车厢照明请求由handling_out_of_scope_requests.type_1_in_cabin_comfort处理，以包含愿景式消息。\n乘客：我怎么更改我的车辆缩写？\nGemini：要更改您的乘客缩写和颜色，请打开Waymo App并点击屏幕底部的「My car（我的车）」按钮。从那里，您可以点击您的Car ID（车辆 ID）进行编辑。\n乘客：我怎么更改无障碍设置？\nGemini：无障碍设置可以在Waymo App中调整。\n乘客：我怎么关掉自动播放的音乐？\nGemini：要为您的行程关闭音乐自动播放功能，您需要在Waymo App的音乐选项下调整该设置。\n下车点更改\nAI助手无法更改下车点，同样需引导乘客在APP上完成操作。\n触发：用户请求稍微改变下车点。\n指令：识别这是一个更改目的地的请求，并引导用户使用App，因为你无法执行此动作。\n乘客：你能把我在街对面放下来吗？\nGemini：我还不能更改您的下车位置，但您可以在Waymo App中请求编辑后的下车点。\n工具消歧\n当用户的请求可能映射到多个工具时，助手必须要求澄清而不是猜测。\n触发：用户的请求模棱两可，可能映射到多个不同的工具，或者太模糊以至于无法自信地选择一个工具。\n指令：不要猜测用户的意图。你 必须 提出一个澄清问题，向用户展示最可能的选项。你的问题应该简洁且易于回答。\n乘客：你能弄一下音乐吗？ 错误回复：当然，我跳到下一首。\nGemini：我可以。我是应该暂停音乐，还是跳到下一首？\n参考资料：\nhttps://the-decoder.com/waymos-leaked-system-prompt-reveals-a-1200-line-rulebook-for-its-in-car-gemini-assistant/\nhttps://wongmjane.com/blog/waymo-gemini\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652658136&idx=1&sn=deed65194b216d6566c886f387ab7d8b&chksm=f04acc51638797446a64c7c7871fabd1726732f8e123725dbd92f1ed22e1570b1f602aecad24&scene=0&xtrack=1#rd",
      "publish_time": 1766901600,
      "publish_date": "2025-12-28 14:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://gist.github.com/wongmjane/b3878b4dcfb3533a1505497358af183b\", \"https://the-decoder.com/waymos-leaked-system-prompt-reveals-a-1200-line-rulebook-for-its-in-car-gemini-assistant/\", \"https://wongmjane.com/blog/waymo-gemini\"]",
      "add_ts": 1766988551,
      "last_modify_ts": 1767050333
    },
    {
      "id": 17,
      "article_id": "51489",
      "title": "Proc. Natl. Acad. Sci. | 基于扩散模型侧链组装的柔性蛋白质-配体对接",
      "description": "理解蛋白质–配体相互作用对阐明细胞机制和开发新疗法至关重要。这类结合可触发信号传导、催化反应或调控基因表达，是蛋白质实现功能的关键。由于蛋白质具有动态结构，配体结合常引发构象变化，准确捕捉结合态构象对基于结构的药物设计尤为关键。",
      "content": "理解蛋白质\n–\n配体相互作用是生命科学诸多领域的基础：从阐明细胞过程到开发疾病新疗法，都离不开对其机制的\n描述\n。这类相互作用能够触发信号级联反应、催化化学反应，或调控基因表达等关键生物学事件。作为细胞的\n“\n主力军\n”\n，蛋白质往往通过与小分子配体或其他蛋白质发生特异性结合来实现功能。然而，蛋白质结构具有天然的动态性，配体结合也常\n诱导其发生\n构象变化；因此，获得准确的结合构象是基于结构的药物设计的重要前提。通过在分子层面更精确地理解这些相互作用，我们可以更深入认识生物系统如何运转，以及更有针对性地调控其功能，从而实现治疗目的。\n近日，中国科学院上海药物研究所郑明月团队\n提出\n蛋白\n–\n配体复合物柔性结构建模新方法\nPackDock\n。该方法将生成式\nAI\n与物理算法相结合，用于预测柔性蛋白\n–\n配体对接构象，并在多种应用场景中展现出良好的精度与效率，同时具备较强的泛化能力。相关研究成果以\n“Flexible protein–ligand docking with diffusion-based side-chain packing”\n为题，于\n2025\n年\n12\n月\n24\n日在\nProceedings of the National Academy of Sciences of the United States of America\n（美国国家科学院院刊）在线发表。\n1.\n背景\n蛋白质的结构对于基础生物学和药物设计至关重要。过去几十年里，基于结构的药物设计（\nSBDD\n）已成为开发新药的核心策略；随着结构生物学技术与从头蛋白质折叠算法的快速发展，获取蛋白质三维结构变得前所未有地便捷。然而，蛋白质结构本质上是动态的，配体结合常伴随结合口袋内的构象变化，而现有结构多以\n“\n静态快照\n”\n的形式呈现，难以满足\nSBDD\n的复杂需求：例如，未结合配体的\napo\n结构或结合非同源配体的\nholo\n结构，都可能导致对新配体真实结合模式的错误假设。因此，尽管准确的结合构象是\nSBDD\n的关键前提，它在实际研究与应用中仍往往难以直接获得。\n传统分子对接算法通常依赖迭代式的构象采样与打分评估。为保证计算效率，这类方法往往忽略蛋白质柔性\n，\n从而\n缩小\n搜索空间，但这可能错过关键的口袋构象变化并导致错误的结合模式。近年来，深度学习方法通过回归或生成式建模在一定程度上能够跳过反复的\n“\n采样\n—\n评估\n”\n流程，显著提升对接速度，并在部分场景下带来更高精度；但由于神经网络对物理约束的显式建模不足，仍可能产生几何或能量上不合理的构象，从而对结果的可解释性与可信度提出挑战。与此同时，共折叠（\nCo-folding\n）方法的兴起进一步改变了关于蛋白质\n–\n配体复合物结构预测的讨论：相较于传统对接方法，它们在多个任务上展现出更强的性能，但多项基准研究也提示，现有共折叠框架尚未学习到\n真实\n的物理相互作用规律。\n在这项工作中，研究团队提出了柔性蛋白质建模框架\nPackDock\n，通过整合物理建模与深度学习方法来表征蛋白质\n–\n配体相互作用。其核心模块\nPackPocket\n结合等变图神经网络与扩散模型建模结合口袋内侧链构象的多峰分布\n，\n从蛋白质\n“\n自由态\n”\n与\n“\n配体结合态\n”\n的构象分布中采样，并通过预测侧链扭转角实现对\n蛋白质\n柔性的高效建模。为系统评估该方法，研究团队设计了一系列\n面向真实\n药物设计需求的基准实验，包括侧链恢复、柔性重对接，以及在\napo\n、\nholo\n与预测折叠结构上的交叉对接测试，从而全面\n评估\nPackDock\n在不同结构来源下的柔性对接性能。此外，团队还在一个面向\nALDH1B1\n的真实药物发现项目中，成功识别出具有新型骨架、纳摩尔级亲和力的候选化合物，进一步验证了\nPackDock\n的实用价值。\n2.\n结果\n2.1\nPackDock\n架构\n图\n1.\nPackDock\n方法示意图。\na\n：\nPackDock\n工作流程\n；\nb\n：\nPackPocket\n对侧链构象分布的建模\n；\nc\n：\n等变图神经网络预测侧链扭转角。\n如\n图\n1\n所示，\nPackDock\n同时考虑蛋白质在无配体（自由态）与配体结合态下的构象分布，从而更精准地建模柔性蛋白\n–\n配体复合物的结合构象。具体而言，核心模块\nPackPocket\n结合等变图神经网络与生成式建模策略，学习侧链构象空间的能量景观，并在不同状态分布中采样口袋侧链构象，以描述结合过程中可能发生的构象变化。此外，\nPackDock\n框架可兼容多种刚性对接算法，从而进一步提升柔\n性\n对接性能。\n2.2\n柔\n性\n对接的基础：蛋白侧链构象预测的准确性\n图\n2.\nPackDock\n与其他方法的侧链预测准确度\n对比\n。\na\n：\n无配体\n条件下\n的\nPacking\n性能\n；\nb\n：以\n配体为条件的\nPacking\n性能\n；\nc\n：\n柔\n性\n重对接过程中的侧链原子\nRMSD\n；\nd\n：\n柔\n性\n重对接过程中的侧链扭转角\nMAE\n。\n蛋白质构象并非一成不变，尤其在配体结合口袋区域，口袋\n“\n呼吸\n”\n或变构效应常会驱动侧链重排，从而形成多种可能的构象状态。然而，现有方法多侧重于评估单一结构的准确性，难以生成多样且具有代表性的口袋构象集合。为此，\nPackDock\n的核心模块\nPackPocket\n采用生成式建模学习并采样口袋侧链构象分布，并可进一步引入配体条件信息，以提升侧链预测的准确度\n（\n图\n2\n）\n。此外，侧链构象空间极其庞大，传统柔性对接往往需要在\n“\n采样\n—\n评估\n”\n的迭代过程中耗费大量计算以探索该空间；相比之下，\nPackPocket\n通过直接建模与采样侧链构象分布，避免了大量迭代计算步骤，从而在提升精度的同时显著提高了计算效率。\n2.3\n真实结构偏差下的鲁棒性：\napo\n与\nholo\n结构的交叉对接\n图\n3.\nPackDock\n与其他方法的柔\n性\n对接性能对比。\na\n：\n使用\napo\n结构\n进行对接\n的\n性能\n；\nb\n：\n使用\napo\n结构\n对接\n时\nRMSD < 1 Å\n和\n< 2 Å\n的比例\n；\nc\n：\n使用\nholo\n结构进行对接的性能\n；\nd\n：\n使用\nholo\n结构\n对接\n时\nRMSD < 1 Å\n和\n< 2 Å\n的比例。\n在大多数实际应用中，获得与目标配体结合的\nholo\n结构往往十分困难，通常只能依赖\napo\n结构\n或非同源配体的\nholo\n结构来开展分子对接\n研究\n。在这类场景下，若将蛋白质视为刚性结构、仅考虑配体柔性，往往导致错误的相互作用模式，从而限制对接结果的可靠性。为贴近真实应用，研究者分别以\napo\n与非同源\nholo\n结构模拟上述输入条件并进行评测。如\n图\n3\n所示，\nPackDock\n在以\napo\n或非同源\nholo\n作为输入时的柔性对接性能均显著优于现有方法，体现了其在真实结构偏差条件下的鲁棒性与实用价值。\n2.4\n预测结构的可用性：折叠\n结构\n模型上的交叉对接\n图\n4.\n以共折叠方法预测结构作为输入时\nPackDock\n的对接性能。\na\n：与其他共折叠方法在不同训练集相似度测试集上的对接性能对比；\nb\n：在主链\nRMSD < 2 Å\n的测试数据上的对接性能。\n过去几十年，实验结构生物学已解析约\n10\n万个蛋白质结构，但这仍仅覆盖已知蛋白质序列空间的一小部分，因此人们寄希望于借助蛋白质折叠算法探索更广阔的序列图景。近年来，共折叠方法在预测过程中显式引入配体信息，相比传统分子对接在多个任务上展现出显著优势，也为\nSBDD\n带来了令人兴奋的新机遇。然而，多项基准测试同样揭示了其局限：部分方法可能尚未学习到\n真实\n的物理相互作用规律，而更依赖对训练集中配体姿态的\n“\n记忆\n”\n，从而在分布外结构上出现明显的性能衰减，引发了对其在药物发现应用中泛化能力的担忧。\nPackDock\n采用混合策略，将基于物理的分子对接与深度学习驱动的受体柔性建模相结合；这种组合在\n‘\n记忆式泛化\n’\n失效时尤为有效。为评估其泛化性，研究者使用\nRuns N Poses\n数据集，并将评估范围限定在\nBoltz-2\n训练截止日期（\n2023\n年\n6\n月）之后发布的结构，同时依据测试样本相对于训练集的相似度（\nSuCOS\n）进行分层分析。如\n图\n4\n所示，\nPackDock\n在低相似度（\n<60%\n）条件下取得了显著更高的对接成功率。尤其值得注意的是，当相似度低于\n40%\n时，\nPackDock\n的性能相比\nBoltz-2\n提高约\n20%\n，相比\nBoltz-2-pocket\n提高约\n10%\n。这类低相似度样本往往最具挑战性，却也更贴近未来药物发现中常见的\n“\n分布外\n”\n应用场景。在高相似度条件下，当共折叠方法的准确率接近\n完美\n（\n>90%\n）时，\nPackDock\n的表现略低，但整体仍具有竞争力。总体而言，共折叠方法代表了\nSBDD\n的重要发展方向，但在物理可解释性与泛化性方面仍面临根本挑战；因此，与其将其视为传统对接的替代方案，不如将二者的优势互补结合，以覆盖更广泛、更真实的应用场景。\n2.5\n应用验证：前瞻性虚拟筛选实验\n图\n5.\nPackDock\n筛选\nALDH1B1\n的新骨架化合物。\na\n：\n筛选流程示意图\n；\nb\n：\n筛选得到的\nhit\n分子与参考分子\nIGUANA-1\n的化学结构\n；\nc\n：\n5\n个\nhit\n分子及参考分子的剂量\n–\n反应曲线\n；\nd\n：\nhit\n分子与参考分子对\nALDH1B1\n蛋白热稳定性的影响\n；\ne\n：\n实验活性鉴定结果汇总\n；\nf\n：\nSPR\n测定\n484H9\n与\nALDH1B1\n的结合亲和力\n；\ng\n：\n484H9\n与\nALDH1B1\n的核磁共振实验。\n为了评估\nPackDock\n在实际药物发现流程中的应用能力，研究\n团队\n以\nALDH1B1\n为靶点开展了一项前瞻性虚拟筛选实验，如\n图\n5\n所示。\n通过\n使用\nPackDock\n对内部小分子库进行筛选，并对优选化合物进行多层级实验验证，最终获得\n5\n个具有新型骨架的\nALDH1B1\n抑制剂，其中\n1\n个化合物表现出纳摩尔级的结合亲和力。该结果表明，\nPackDock\n不仅在基准任务上具备优势，也能够在真实筛选中产出具有实际价值的命中分子，体现了其面向药物发现应用的潜力。\n3.\n讨论\n结构生物学技术与基于人工智能的蛋白质折叠算法迅速发展，使\n我们\n能够以前所未有的速度获得更多新型生物靶标的三维结构。然而，这些结构往往以\n“\n静态快照\n”\n的形式呈现，难以全面反映蛋白质在细胞环境中的动态特性，从而限制了我们对蛋白质\n–\n配体相互作用的深入理解。为应对这一挑战，研究团队提出了\nPackDock\n框架，旨在弥补静态结构在\n描绘\n结合过程与受体柔性方面的不足。\nPackDock\n将基于物理的分子对接与深度学习驱动的受体柔性建模相结合。研究者通过多项系统性评测验证了其能力：（\n1\n）侧链\npacking\n与柔性重对接实验表明\nPackDock\n能够准确预测结合位点侧链构象；（\n2\n）在以\napo\n结构、非同源\nholo\n结构以及共折叠预测结构为输入的交叉对接测试中，\nPackDock\n展现出在真实结构输入条件下柔\n性\n对接的实用价值；（\n3\n）在\n针对\nALDH1B1\n的前瞻性虚拟筛选中，\nPackDock\n成功识别出具有新型骨架且达到纳摩尔级亲和力的抑制剂，进一步证明其在实际药物发现中的应用潜力。总体而言，\nPackDock\n能够适配多来源的蛋白结构输入，并以较高精度预测蛋白\n–\n配体复合物构象，从而推动对生物系统中蛋白\n–\n配体相互作用的机制理解。作者认为，与其期待深度学习完全替代传统\n经验或物理\n方法，更值得关注的是如何整合不同方法的优势，以更有效地解决\n实际\n科学问题。\n上海药物研究所硕士研究生张润泽、上海药物研究所博士研究生江欣雨、浙江大学与上海药物研究所联合培养博士研究生曹端华，以及上海药物研究所硕士研究生\n王照坤\n为本文共同第一作者。上海药物研究所郑明月研究员为本文通讯作者。本研究获得国家自然科学基金、国家重点研发计划、临港实验室\n、\n中国科学院战略性先导科技专项等资助。\n原文链接\nR. Zhang,\nX. Jiang,\nD. Cao, et al. Flexible protein–ligand docking with diffusion-based side-chain packing,\nProc. Natl. Acad. Sci. U.S.A.\n122 (52) e2511925122 (\n2025\n).\nhttps://doi.org/10.1073/pnas.2511925122\n（\n点击下方阅读原文跳转）",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512388&idx=1&sn=e15d2d855b2dc34496fe430ba473cde7&chksm=fd4eb98e4c44a78058ddfa34054c8fead8229129c4b6edaa440a97b6b45cd42e54538ad0b512&scene=0&xtrack=1#rd",
      "publish_time": 1766899800,
      "publish_date": "2025-12-28 13:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1073/pnas.2511925122\"]",
      "add_ts": 1766988557,
      "last_modify_ts": 1767050336
    },
    {
      "id": 20,
      "article_id": "51485",
      "title": "Nat. Comput. Sci. | 量子机器学习的机遇与陷阱",
      "description": "量子机器学习（QML）结合量子计算与机器学习，利用叠加、纠缠等量子特性提升学习与推断能力，成为新兴交叉研究方向。尽管前景广阔，QML仍面临硬件限制、算法设计和量子优势验证等关键挑战。本文探讨当前主要瓶颈，并展望实现实际应用的可能路径，推动未来技术发展。",
      "content": "DRUG\nONE\n量子机器学习正被广泛探索，用以评估量子资源是否能够增强学习与推断能力，然而其发展仍面临诸多重大障碍。本文讨论当前最紧迫的挑战，并勾勒通向未来实际应用的潜在路径。\n近年来，量子计算与机器学习领域的快速进展激发了将二者结合的浓厚兴趣，催生了量子机器学习（quantum machine learning, QML）这一新兴的交叉研究方向。从根本上看，QML 旨在利用叠加、纠缠等量子现象增强学习算法，在计算速度和模型表达能力方面提供潜在提升。随着量子硬件的稳步成熟以及量子算法日益精细化，研究人员似乎正接近一个关键节点：长期以来对 QML 的承诺有望开始转化为现实世界中的实际效用。\n然而，这一路径并非必然通向成功，前方仍横亘着诸多障碍与挑战。近期关于去量子化、可训练性瓶颈以及硬件限制的研究，对广泛宣称量子优势的说法提出了警示。类似于以往的技术变革浪潮，QML 的发展不仅依赖于科学突破，也取决于研究人员如何设定目标、评估其实际价值，并将其发展方向与真实应用问题相对齐。目前，QML 仍处于演化的早期阶段，这也正是重新审视其现状并思考未来发展路径的恰当时机。\n基础与现状\nQML 的核心理念在于：量子计算机能够以本质上不同于经典系统的方式处理信息，从而为数据表示、变换与推断提供新的可能性（图 1）。早期的量子学习模型探索主要通过将经典学习范式引入量子框架，为这一领域奠定了基础。\n其中一个具有代表性的工作是量子支持向量机，该方法在量子计算框架下重新表述了经典支持向量机。通过引入量子矩阵求逆算法，在假设可高效量子访问数据以及数据具有低秩结构等特定条件下，该方法在特征维度和训练样本规模上实现了对数复杂度的分类过程。与此同时，研究人员还提出了量子强化学习的一般性框架，将经典的智能体–环境交互范式拓展至量子领域。在这一设定中，量子智能体在学习效率和性能方面相较于经典方法可获得平方级别的提升。\n这些研究仅代表了早期探索的一部分。其他方向上的工作，如量子回归和无监督聚类，也进一步展示了这一快速发展领域的多样化探索路径。\n混合量子–经典范式\n与其试图以量子方法全面替代经典学习流程，近年来的大多数研究更倾向于采用混合范式，即将量子处理器嵌入到经典优化流程中以完成机器学习任务。一方面，这体现了研究人员对量子模型在处理复杂数据结构或非平凡特征映射方面潜在优势的认识，并将其视为整体学习流程中的特定模块；另一方面，这种范式也高度契合当前的噪声中等规模量子（NISQ）时代，在该阶段，全容错量子计算仍遥不可及，但小规模量子资源仍可能被有效利用。\n在这一思路下，多种混合量子–经典架构被提出，以期在机器学习任务中发挥量子模型的表示能力。例如，量子卷积神经网络借鉴了经典卷积网络的层级结构，但直接作用于量子态，适用于量子相位识别任务。另一类广泛研究的模型是量子核方法，其利用量子电路隐式实现复杂特征映射，在获得核矩阵后，再通过经典优化方法完成分类等任务。这些方法展示了在资源受限的条件下，如何利用有限的量子能力构建具有针对性表达能力的学习模型。\n量子学习优势的再审视\n随着原型模型从理论构想逐步走向系统性测试，研究人员对 QML 的认识也日趋理性。例如，量子支持向量机所宣称的复杂度优势依赖于前述结构化假设；在相同条件下，经典“去量子化”算法同样能够实现类似的加速效果。类似地，量子卷积架构在相位识别中的成功，在很大程度上源于其在相对简单数据集上的评估，而这些结果往往可以被经典模拟方法有效复现。\n这些发展反映出该领域在自我评估方面的逐步成熟，也凸显了明确数据访问假设和资源消耗、并与强有力的经典基线进行对比的重要性。\n在此背景下，一个核心问题持续引导着理论与实验研究：QML 能否在何种意义上提供超越经典方法的切实优势？所提出的潜在优势包括计算复杂度或样本复杂度的降低，以及通过量子特征空间增强模型表达能力。在某些高度结构化的设定中，确实存在严格的理论证据支持量子–经典分离。例如，通过将离散对数问题的计算难度编码进人工数据集，量子核方法可借助量子算法高效揭示数据结构，而经典学习方法则难以应对。\n此外，还有研究利用多体哈密顿量下的量子动力学演化复杂性，构造出对经典模型不可处理、但对量子模型可行的学习任务。另一类潜在优势来源于量子非定域性与情境性，其产生的测量关联无法用经典模型解释，在特定构造任务中即便不依赖密码学假设也可体现优势。然而，迄今为止，这些实例大多仍停留在人工构造层面，与现实世界学习问题的关联性有限。\n近期应用前景与核心挑战\n尽管实现明确量子优势仍是长期目标，当前大量研究已开始聚焦于在化学、优化和数据科学等领域寻找具有实际相关性的应用场景，以缩短理论进展与现实影响之间的距离。\n在实践中，一个尤为有前景的方向是量子原生数据任务。在这些场景中，信息本身以量子态形式存在，例如多体系统探测、量子设备噪声表征或分子量子态性质预测。与其进行代价高昂的全态重构，不如利用 QML 提取特定特征或隐含参数。其关键在于，量子模型能够学习跨子系统的关联关系，从而减少性质估计、信号判别或系统识别所需的样本数量。这类任务与量子硬件的固有能力高度契合，可能成为 QML 首批展现实用价值的应用场景。\n除量子原生任务外，研究人员也在探索 QML 是否能为传统上被视为经典的问题提供价值，例如模式识别、生成建模和自然语言处理。在这些混合流程中，参数化量子电路和量子核方法被视为潜在的特征映射模块，但其近期实用性仍局限于浅层、受控容量且具备明确结构假设的场景。\n在这一方向上，数据重上传框架被提出，用以通过多层重复编码经典输入提升模型表达能力。此外，受经典神经元启发的深度量子神经网络，以及量子生成对抗网络，也成为持续探索的方向。未来，QML 的应用范围可能进一步拓展，涵盖更强调可迁移性、鲁棒性和模块化的学习设置，与领域自适应、对抗鲁棒性和持续学习等研究趋势相呼应。\n关键挑战\n要评估 QML 在近期应用中的潜力，还必须正视当前系统的能力边界与局限性。\n硬件限制\n当前量子设备受制于有限的量子比特数量、浅层电路深度以及严重的噪声问题，这些因素共同限制了可训练模型的表达能力与规模。即便在混合范式中，性能与可扩展性仍是主要瓶颈。许多量子优势主张依赖于理想化假设，例如全容错硬件和长寿命量子存储，这在当前实验条件下仍遥不可及。\n可训练性问题\nQML 在扩展过程中面临内在困难。变分量子模型常遭遇“荒漠平台”问题，即梯度随系统规模指数级消失，使优化过程几乎不可行。更一般而言，模型表达能力与可训练性之间存在权衡：高度表达性的电路往往更接近随机特征，因而更易陷入不可训练状态。\n数据集与基准评测\n缺乏合适的数据集同样制约着研究进展。现有量子数据集要么过于简单，要么难度不切实际；而经典数据集又往往伴随高昂的量子编码成本。在缺乏标准化基准和强经典对照的情况下，很难判断 QML 在何种任务中真正具有优势。\n可解释性与验证\n随着电路深度增加并超出经典可模拟范围，理解模型学习到的内容以及独立验证其输出结果变得愈发困难。\n早期容错阶段的挑战\n尽管 QML 可能更适用于容错量子计算机，但进入该阶段并不会自动消除上述问题，反而引入新的复杂性。例如，将包含小旋转角的电路编译为 Clifford+T 门集可能带来极高的资源开销。\n未来展望\n总体而言，QML 仍处于起步阶段，其发展既受到概念层面澄清的影响，也依赖于技术进步。要从理论设想迈向实际应用，不仅需要更强大的量子硬件和更稳健的算法，还需更清晰地理解量子模型相对于经典方法所能提供的可衡量优势。高维度与复杂关联并不必然带来收益，它们同样可能加剧训练与优化难度。\n在这一过程中，任务驱动的算法与硬件协同设计将至关重要。值得注意的是，经典替代模型对量子学习方法形成了一种“压力测试”，进一步强调了识别量子资源独特优势场景的重要性。\n此外，QML 的潜在价值并不局限于精度或计算速度。在建立可扩展、可训练流程的基础上，数据隐私成为一个尤为引人注目的方向。借助盲量子计算原理，量子协议可支持委托式或联邦学习，在整个计算过程中保障数据安全。相较于依赖可信中心或本地算力的经典方案，量子学习在理论上可提供源自量子力学定律的无条件安全性，这在医疗、金融等对隐私要求极高的场景中尤具吸引力。\n展望未来，QML 的发展不仅取决于技术进步，也取决于研究共同体如何设定研究议程与评估标准。无免费午餐定理清晰地指出：在所有问题上平均而言，不存在万能的最优学习器；优势只会在合适的归纳偏置与数据分布下出现。QML 的成功将依赖于其与实际需求的精准对齐，与物理、化学和数据科学中的具体问题建立紧密联系，实施严格的基准评测，并最终聚焦于那些量子资源有望发挥决定性作用的、狭义而清晰的问题子类。\n整理 | DrugOne团队\n参考资料\nLi, W., Ma, Y. & Deng, DL. Pitfalls and prospects of quantum machine learning. Nat Comput Sci 5, 1095–1097 (2025).\nhttps://doi.org/10.1038/s43588-025-00914-6\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512388&idx=2&sn=891ff3a0fa4c995594cd513d7a64d36e&chksm=fd19266a206f6ee085699b4e3effa1b064c1dd25151a38d5cd3ab16252bbedf8e7484a8bc7cc&scene=0&xtrack=1#rd",
      "publish_time": 1766852400,
      "publish_date": "2025-12-28 00:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s43588-025-00914-6\"]",
      "add_ts": 1766988577,
      "last_modify_ts": 1767050346
    },
    {
      "id": 24,
      "article_id": "51481",
      "title": "科技日报·张钹丨AI与医生的关系并非替代而是“共生”",
      "description": "90岁高龄的中国科学院院士张钹出席清华大学临床医学科技创新大会，聚焦人工智能在医疗领域的应用。会议展示AI赋能医院管理、辅助诊疗等多项成果，发布“AI肝胆超级医生”和“清心”心电大模型等创新项目，凸显AI在医疗科技中的关键作用。作为清华大学人工智能研究院名誉院长，张钹持续推动人工智能与临床医学融合，助力智慧医疗发展，展现人工智能在健康领域的广阔前景与治理潜力。",
      "content": "点击蓝字\n关注我们\n张钹\n中国科学院院士，俄罗斯自然科学院外籍院士，清华大学教授，\n清华大学人工智能研究院名誉院长，人工智能国际治理研究院学术委员\nI-AIIG\n近日，清华大学临床医学科技创新大会在广州北京清华长庚医院召开。从AI（人工智能）赋能医院管理到AI辅助疾病诊疗，再到AI肝胆超级医生智能体、“清心”心电大模型相继发布，AI成为这场会议的高频词。\n虽然已90岁高龄，中国科学院院士、清华大学人工智能研究院名誉院长张钹仍现身会场，并探讨了一个备受关注的话题——AI时代的医生。\n“AI将深刻改变医疗行业，但在可预见的未来，AI还不能完全替代医生。”张钹说。\n在医疗领域中，AI应用场景十分广阔。\n张钹举例表示，AI将问诊记录转化为规范病历，智能健康管家开展随访服务，AI辅助眼底疾病筛查，手术机器人精准切除病灶……在影像解读、文书处理、健康问答等标准化、流程化工作方面，AI优势突出，逐渐成为医生的“数字战友”。\n“不过当前，AI存在一些局限性。”张钹说，以大语言模型为例，其运行主要靠外部驱动而非内在主动。此外，大语言模型缺乏真正的推理与因果理解能力，其\n“黑箱”特性和不可解释性也不得不让人警惕\n。更重要的是，AI还不能做到“自我负责”。\n相比之下，\n人类医生的行为具有内在动机\n，而且具备推理与理解能力，是可信的、可负责的。“正是基于此，大语言模型给出的临床诊疗意见，最终需要人类医生把关。”张钹说\n而且，医疗不只是诊疗技术的比拼，还需充满人文关怀的互动。张钹认为，\n面对患者的恐惧、焦虑、愤怒等情绪，AI难以共情和疏导；面对个体的特殊性和个性化需求，AI难以统筹考量并作出最佳选择。\n患者的情感诉求和复杂诊疗场景，是当前算法的盲点，也是人类医生的价值锚点。\n那么，AI时代，医生将在哪些方面发挥作用？\n张钹认为，未来，\n医生是临床决策者，在权衡风险、预期、生活治疗、经济压力等复杂因素后作出最终选择。\n同时，医生是流程设计者、沟通者，将完成治疗过程中不可或缺的部分——深度交流、价值选择和伦理判断。此外，医生也是安全监督者，在数据不完美、医疗风险高等情境下，医生将承担责任、守住边界。\n“在可预见的未来，AI不会替代医生，却对医生提出了更高要求。”张钹说。\n在他看来，\n懂AI、用AI、解释AI是未来医生的基本素养\n，未来医生的临床决策与系统思维能力应当更强，医生的沟通能力与人文素养将被“放大”。此外，医生的跨学科协作与流程再造能力不容忽视，法规、伦理与安全意识也要不断增强。\n“在AI时代，医生还要保持自我更新能力，把AI作为‘外挂’。”张钹说，医疗知识的半衰期越来越短，新药、新指南、新证据层出不穷，“AI可以是你随身的‘更新雷达’，但最后还是要你自己判断——哪些值得用于改变自己的实践。”\n“AI加速医疗变革的时代，AI与医生的关系并非替代而是‘共生’。”张钹表示，AI时代，医生能成为有判断力的决策者、有温度的沟通者、懂技术边界的践行者。\n据《科技日报》",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU4MzYxOTIwOQ==&mid=2247522178&idx=1&sn=e256968c2c8d37fd5ec1b6ea7643e1e5&chksm=fceba662676cdd2819c98bac5e1bb4fa181804ac19a8493fb52b14e989eb0e9e9e6003126468&scene=0&xtrack=1#rd",
      "publish_time": 1766848800,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1766988598,
      "last_modify_ts": 1766988598
    },
    {
      "id": 27,
      "article_id": "51478",
      "title": "Meta公布“超级智能”新进展：无需人类，软件Agent即可自我训练！",
      "description": "近年来，基于大语言模型的软件工程智能体发展迅速，但依赖人工数据和开发轨迹，难以自主创新。为此，Meta与伊利诺伊大学团队提出Self-play SWE-RL（SSR），作为新型训练范式。SSR仅需极低数据假设，通过自我对弈机制，使智能体在无监督环境下自主生成问题与解决方案，逐步演化出超越人类经验的编程能力，推动软件工程智能体向超级智能迈进，为自动化软件开发提供新路径。",
      "content": "近年来，基于大语言模型（LLMs）的软件工程智能体发展迅速，但其训练数据和训练环境仍高度依赖人类知识和人工策划，本质上是在复现人类开发轨迹，难以自主发现新的问题结构与解决策略，这从根本上制约了智能体迈向超级智能的能力。\n基于此，来自Meta、伊利诺伊大学厄巴纳-香槟分校的研究团队提出 Self-play SWE-RL（SSR），作为软件工程智能体训练范式的第一步。该方法对数据假设的要求极低，\n仅需访问包含源代码和已安装依赖项的沙盒化代码仓库，无需任何人工标注的问题或测试用例\n。\n研究表明，智能体可以从真实世界的软件仓库中自主获取学习经验，\n有望催生在系统理解、解决全新问题以及从零开始自主创建软件等方面超越人类能力的超级智能系统\n。\n论文链接：https://arxiv.org/pdf/2512.18552\nSelf-play SWE-RL 框架\nSSR 的设计原则是\n减少对代码库先验知识的依赖\n，以提升方法的通用性与可扩展性。它不依赖于特定环境的预配置，智能体要通过与环境的交互，自主探索测试的运行方式并理解其结构。该极简输入设定使 SSR 几乎无需额外配置即可应用于不同代码库，显著降低了使用与迁移成本。\nSSR 的核心是\n通过自博弈式的迭代循环，使智能体在不断生成与解决 Bug 的过程中实现自我提升\n。在 SSR 中，同一 LLM 策略被划分为两个协同演化的角色，分别是智能体 Bug 注入与智能体 Bug 求解，二者共享参数但承担不同任务。\n图| SSR 的总体框架\n1.智能体 Bug 注入\n智能体 Bug 注入通过\n让模型扮演“破坏者”构建起自驱动的进化闭环\n。\n在这一过程中，首先生成包含 Bug 补丁和弱化测试的 Bug 构件，将抽象错误转化为标准化的练习题；随后，运用“删除关键代码”或“回滚历史修复”等复杂生成策略，从真实工程逻辑中制造出极具挑战的高质量难题；为了确保逻辑严密，系统利用“逆向变异测试”进行严格的一致性验证，剔除无关干扰并确保错误可复现；最后，通过动态奖励机制将任务难度维持在“跳一跳才够得着”的区间，并将修复失败的尝试转化为高阶缺陷循环利用，从而在无需人类标注的情况下，驱动智能体在博弈中不断实现自我超越。\n图| 智能体 Bug 注入中“删除关键代码”和“回滚历史修复”的策略\n2.智能体 Bug 修复\n智能体 Bug 修复通过在沙盒中应用缺陷补丁并重置 Git 历史来构建防作弊的代码现场，确保模型无法走捷径。随后，以弱化测试的逆向补丁作为任务提示，取代人类的文字描述，迫使代理纯粹基于代码逻辑定位问题。在修复过程中，智能体通过“推理与工具调用”的交互循环，在模拟环境中自主进行补丁尝试与验证。最终，系统通过回滚原始测试文件的评估机制进行严苛复核，确保生成的 Bug 在真实测试下依然有效，从而完成从理解考题到提交正确答案的闭环。\n图| 智能体 Bug 修复的流程\n实验结果\n研究人员在 SWE-bench Verified 与 SWE-bench Pro 上，对基础模型、基线强化学习方法以及 SSR 进行了系统比较。\n实验结果表明，即使在完全不接触任务描述和测试数据的情况下，SSR 仍能在训练过程中持续实现性能提升，验证了 LLM 仅通过与真实代码库交互即可增强其软件工程能力。更重要的是，SSR 在整个训练轨迹上始终优于基线 RL，说明\n由模型自主生成的任务相比人工构造的数据，能够提供更具信息量和有效性的学习信号\n。\n图| 训练过程中的基线比较\n研究人员比较了完整的 SSR 与仅进行 Bug 注入或仅进行 Bug 修复的两种变体。\n实验结果表明，完整的自博弈框架性能最优，而单一注入或修复训练均表现不足，前者缺乏从修复过程中的学习，后者受限于静态任务分布。相比之下，自博弈通过同时生成与修复 Bug，使任务分布随训练动态演化，持续提供更丰富的学习信号，从而实现稳定的性能提升。\n图| Self-play Swe-RL的消融研究\n不足与未来展望\n尽管 SSR 在减少人工依赖、实现自我提升方面展现出潜力，但仍处于早期阶段。当前方法依赖显式测试作为判定器，存在奖励投机的潜在风险。同时，验证机制主要基于单元测试，难以覆盖真实软件工程中的高层目标与复杂语义。此外，Bug 注入与修复角色共享同一模型配置，尚未系统探索模型规模、结构差异及角色分离对自博弈学习的影响。\n此外，研究人员还探索了若干未取得理想效果的方向，例如，自然语言 issue 生成受限于模型能力与奖励设计，难以保证质量与多样性；仓库专用训练因数据多样性不足未能带来收益；而训练不稳定性则成为限制 SSR 进一步扩展的重要瓶颈。\n展望未来，SSR 为自博弈驱动的软件工程智能体打开了多个研究方向，包括通过种子机制控制错误分布、合成更复杂的多步软件任务，以及设计适用于长周期软件开发的高效训练范式。尤其是在\n奖励稀疏、决策链条极长的真实工程场景中，如何引入更密集、结构化的反馈，将是释放自博弈潜力、迈向更高层次智能的关键\n。\n整理：潇潇\n如需转载或投稿，请直接在本文章评论区内留言。",
      "article_url": "https://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&mid=2247601592&idx=1&sn=4af68c6b92aa7f7d9439d963b141d056&chksm=cee9d74e58f57813b21a5a973c6638c03f96e26c635ab573d77423890533b44e65a72a823faf&scene=0&xtrack=1#rd",
      "publish_time": 1766829600,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/pdf/2512.18552\"]",
      "add_ts": 1766988618,
      "last_modify_ts": 1766988618
    },
    {
      "id": 28,
      "article_id": "51477",
      "title": "Nat. Comput. Sci. | 深度学习驱动的电子结构计算",
      "description": "DRUGONE指出，第一性原理电子结构计算长期受限于精度与效率的矛盾，而深度学习的发展为突破该瓶颈提供了新途径。研究综述了两条技术路线：深度学习量子蒙特卡罗（DL-QMC）利用神经网络波函数提升强关联体系计算精度；深度学习密度泛函理论（DL-DFT）则通过预测电子密度、哈密顿量等关键物理量加速计算。两种方法分别在高精度模拟和高效近似中展现潜力，推动电子结构计算迈向智能化新阶段。（150字）",
      "content": "DRUG\nONE\n第一性原理电子结构计算是理解量子多体体系的核心工具，但长期受到精度与计算效率难以兼得的限制。近年来，深度学习的快速发展为突破这一瓶颈提供了全新路径。研究人员系统回顾了深度学习在电子结构计算中的两条核心技术路线：深度学习量子蒙特卡罗（DL-QMC） 与 深度学习密度泛函理论（DL-DFT）。前者以神经网络波函数为核心，显著提升强关联体系的计算精度；后者以预测密度、哈密顿量等基本量为目标，实现对大规模材料体系的高效模拟。这些方法正在重塑电子结构计算的精度–效率版图，并推动量子力学在材料设计与基础科学中的应用边界不断扩展。\n电子结构问题是量子力学的核心内容之一，自量子力学诞生以来，第一性原理计算在物理、化学和材料科学中发挥了不可替代的作用。随着计算硬件与理论方法的发展，常规电子结构计算已从小分子扩展至包含上千原子的复杂体系。\n然而，不同方法之间长期存在根本权衡：\n量子蒙特卡罗方法具备极高精度，但计算成本巨大；\n密度泛函理论在效率上具有优势，但精度受限于泛函近似。\n深度学习的引入，为同时提升精度与效率提供了新的可能性。研究人员指出，当前最具代表性的突破集中在 DL-QMC 与 DL-DFT 两个方向。\n图 1｜深度学习量子蒙特卡罗（DL-QMC）与深度学习密度泛函理论（DL-DFT）的整体流程。\n深度学习量子蒙特卡罗（DL-QMC）\nDL-QMC 的核心思想是使用神经网络作为多电子波函数的表达形式，在变分量子蒙特卡罗框架下优化能量。相较传统波函数假设，神经网络具有更强的表示能力，能够更充分地捕捉电子关联效应。\n研究人员总结了 DL-QMC 的关键进展：\n在实空间与第二量子化框架下构建神经网络波函数；\n引入自注意力、Transformer 等结构增强表达能力；\n与扩散蒙特卡罗结合，显著提升基态与激发态精度。\nDL-QMC 已在分子、固体、莫尔体系和强关联电子系统中达到或逼近化学精度，在多个经典难题上刷新了基准结果。\n图 2｜DL-QMC 方法发展的时间线与代表性网络架构。\nDL-QMC 的应用范围与能力边界\nDL-QMC 不仅能够计算基态能量，还可扩展至：\n激发态与能隙计算；\n电偶极矩、极化率等静态物性；\n量子相变识别与关联相行为研究；\n势能面构建与有限温度动力学。\n研究人员指出，尽管 DL-QMC 在精度上极具优势，但其计算规模目前仍受限，难以直接应用于高通量或超大体系。\n图 3｜DL-QMC 可处理的体系类型与物理问题。\n深度学习密度泛函理论（DL-DFT）\n与 DL-QMC 追求极致精度不同，DL-DFT 以高效模拟真实材料体系为主要目标。其核心策略是用神经网络直接预测 DFT 中的“基本量”，例如：\n电荷密度；\n哈密顿量；\n密度矩阵。\n通过一次性预测收敛结果，DL-DFT 可绕过自洽场迭代，大幅降低计算成本。\n研究人员强调，DL-DFT 的成功依赖于两类关键物理先验：\n量子近视性原理（局域性）；\n欧氏群 E(3) 等变性（旋转、平移不变性）。\n图 4｜DL-DFT 的基本思想：预测电子结构基本量并进行后处理。\nDL-DFT 的应用与最新进展\nDL-DFT 已在多个方向展现出强大潜力：\n快速预测能带结构、声子谱与光学性质；\n显著加速大体系 DFT 计算的收敛；\n扩展至扭转双层材料、异质结构等超大体系；\n初步拓展至混合泛函与 GW 等更高阶理论。\n研究人员指出，DL-DFT 在计算规模与泛化能力上已展现出向“电子结构基础模型”演进的潜力。\n图 5｜DL-DFT 在电荷密度、哈密顿量与大规模材料模拟中的代表性应用。\n挑战与未来展望\n尽管进展显著，研究人员也明确指出当前仍面临多重挑战：\nDL-QMC 的计算规模与高通量能力仍受限；\nDL-DFT 在高阶理论中的适用性有待进一步验证；\n大规模、高质量训练数据的构建成本高昂；\n自动化后处理与可解释性仍需加强。\n展望未来，研究人员认为 DL-QMC 与 DL-DFT 的深度融合，以及与量子嵌入、多尺度模拟和生成模型的结合，有望催生新一代通用电子结构计算框架，为材料发现和量子科学研究提供强有力支撑。\n整理 | DrugOne团队\n参考资料\nTang, Z., Chen, H., Li, Y. et al. Deep-learning electronic structure calculations. Nat Comput Sci 5, 1133–1146 (2025).\nhttps://doi.org/10.1038/s43588-025-00932-4\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512369&idx=2&sn=805c99d487febc06471e7b8c57323a52&chksm=fd0025d0cec9847011d34553661b8d2f138ecc19d342203fb294ac938ef3e9d08e38622a7ad1&scene=0&xtrack=1#rd",
      "publish_time": 1766827800,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s43588-025-00932-4\"]",
      "add_ts": 1766988623,
      "last_modify_ts": 1766988623
    },
    {
      "id": 30,
      "article_id": "51475",
      "title": "英伟达成美国大模型开源标杆：Nemotron 3连训练配方都公开，10万亿token数据全放出",
      "description": "英伟达推出“最高效的开放模型家族”Nemotron 3，采用混合Mamba-Transformer MoE架构与NVFP4低精度训练技术，性能媲美主流开源模型，速度提升1.5-3.3倍。其开源范围空前，涵盖模型权重、超10万亿token训练数据、预训练与后训练软件及完整训练配方，推动AI开放生态发展。",
      "content": "梦晨 发自 凹非寺\n量子位 | 公众号 QbitAI\n英伟达在开源模型上玩的很激进：\n“最高效的开放模型家族”Nemotron 3，混合Mamba-Transformer MoE架构、NVFP4低精度训练全用上。\n而且开放得很彻底：\n不仅开放模型权重，还要把超过10万亿token的训练数据、预训练和后训练软件、训练配方全部公开。\n与其他开源模型相比性能有竞争力，且速度快1.5-3.3倍。\n把Mamba和Transformer混着用\nNemotron 3在架构层面追求推理效率的最大化。\n传统Transformer的自注意力机制需要对不断增长的KV Cache做线性扫描，序列越长，计算开销越大。\n英伟达的解决方案是大量使用Mamba-2层替代自注意力层——Mamba层在生成时只需要存储固定大小的状态，不受序列长度影响。\n以Nano型号为例，整个模型主要由交替堆叠的Mamba-2层和MoE层构成，自注意力层只保留了少数几个。\n论文给出的层排布模式是：5个Mamba-2+MoE的重复单元，接3个同样结构的单元，再来1个包含注意力层的单元，最后是4个Mamba-2+MoE单元。\n在8k输入、16k输出的典型推理场景下，Nemotron 3 Nano 30B-A3B的吞吐量是Qwen3-30B-A3B的3.3倍。序列越长，优势越明显。\n与此同时，模型在长上下文任务上的表现并没有打折扣。\n论文展示了一组RULER基准测试的结果：在100万token输入长度下，Nemotron 3 Nano基座模型拿到了68.2分，而在同样条件下训练的Nemotron 2 Nano 12B只有23.43分，出现了断崖式下跌。MoE混合架构在长度外推上的鲁棒性明显更好。\nLatentMoE：在潜空间里做专家路由\n针对Super和Ultra这两个更大的模型，英伟达提出了LatentMoE架构，在潜在空间中进行专家计算。\nMoE层在实际部署时会遇到两类瓶颈：\n低延迟场景下，每次只处理几十到几百个token，此时从显存读取专家权重成为主要开销。\n高吞吐场景下，一次处理数千token，此时专家间的all-to-all通信成为瓶颈。两种情况下，开销都与隐藏维度d线性相关。\nLatentMoE的做法是：先把token从原始隐藏维度d投影到一个更小的潜在维度ℓ（通常是d的四分之一），在这个低维空间里完成专家路由和计算，最后再投影回原始维度。\n这样一来，每个专家的权重加载量和通信量都降低了d/ℓ倍。省下来的计算预算被用于增加专家数量和每个token激活的专家数。\n标准MoE用128个专家、激活6个；LatentMoE用512个专家、激活22个。\n两者的总参数量和激活参数量几乎相同（都是8B激活、73B总参），但LatentMoE在所有下游任务上都取得了更好的成绩——MMLU-Pro从48.30提升到52.87，代码任务从51.95提升到55.14，数学任务从78.32提升到80.19。\n需要注意的是，路由门控网络、共享专家计算以及非专家层仍然保留在原始维度，因为这些部分对瓶颈的贡献很小。\n用NVFP4训练250亿token\nSuper和Ultra还采用了NVFP4格式进行训练，这是英伟达在低精度训练上的又一次探索。\nNVFP4是一种4位浮点格式，采用E2M1的元素格式（2位指数、1位尾数），配合16元素的微块缩放和E4M3格式的块缩放因子。在GB300上，FP4的峰值吞吐量是FP8的3倍。\n论文显示，团队已经用NVFP4格式稳定训练了高达25万亿token。与BF16训练相比，Nano模型的损失差距控制在1%以内，8B激活参数的更大模型差距进一步缩小到0.6%以内。\n在MMLU、GSM8K、HumanEval等下游任务上，NVFP4训练的模型与BF16版本的准确率曲线几乎完全重合。\n不过并非所有层都适合量化到NVFP4。团队发现Mamba输出投影层在量化后会出现高达40%的flush-to-zero现象，因此保留在MXFP8精度；QKV投影和注意力投影保留在BF16以维持少量注意力层的保真度；网络最后15%的层也保持高精度以确保稳定性。MTP层和潜在投影由于对推理时间影响很小，同样保留在BF16。\n多环境强化学习一把训到底\nNemotron 3的后训练采用了多环境强化学习，覆盖数学推理、竞赛编程、指令遵循、软件工程、搜索、对话、通用工具使用、长上下文等多种任务。\n与之前分阶段训练不同能力的做法不同，这次英伟达选择同时训练所有任务。\n论文指出，这种同步训练方式更稳定，更不容易出现reward hacking，也避免了分阶段训练常见的能力退化问题。\nAIME25数学分数从80提升到90，LiveCodeBench从65提升到72，τ²-Bench工具使用从40提升到50左右，全程呈稳定上升趋势。\n高效的推理吞吐量在这里发挥了重要作用。\n大规模RL需要生成海量rollout样本，Nemotron 3的混合架构相比其他开源模型有显著优势。\n团队还采用了异步RL架构来解耦训练和推理，并利用多token预测加速rollout生成。训练算法方面使用GRPO配合masked importance sampling来处理训练策略和rollout策略之间的差异。\n整个后训练软件栈以Apache 2.0协议开源，包括NeMo-RL（可扩展RL训练）和NeMo-Gym（RL环境集合）两个仓库。\n此外，Nemotron 3还支持推理时的思维预算控制。\n用户可以指定思维链的最大token数，当模型达到预算时，追加一个标记即可让模型基于部分思维链生成最终回答。\n论文给出了准确率与平均生成token数之间的权衡曲线，这为实际部署中的效率-精度平衡提供了细粒度控制。\n论文地址：\nhttps://arxiv.org/abs/2512.20856\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858336&idx=2&sn=244c2f91a7c513653e6a503d313ab0c7&chksm=e999c35dbecef55ebc38572615b1c7f54455ed94d1bf7b936fff424b72dea3fd3ee4a92fcac8&scene=0&xtrack=1#rd",
      "publish_time": 1766827200,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.20856\"]",
      "add_ts": 1766988634,
      "last_modify_ts": 1766988634
    },
    {
      "id": 32,
      "article_id": "51473",
      "title": "特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹，圣诞节刷屏了",
      "description": "英伟达机器人主管Jim Fan称特斯拉FSD v14首个通过“物理图灵测试”，并给予高度评价。他在平安夜亲身体验FSD v14自动驾驶，从公司一路自主驾驶送其回家，深感震撼。尽管入手特斯拉较晚，但他作为早期体验者认为，FSD v14展现出接近人类的驾驶能力，标志着AI在真实物理世界中实现重大突破，是首次真正感受到机器具备类人驾驶智能的时刻。",
      "content": "Jay henry 发自 凹非寺\n量子位 | 公众号 QbitAI\n特斯拉FSD v14，首个通过「物理图灵测试」的AI。\n为特斯拉「颁发」这一殊荣的并非别人，而是英伟达大名鼎鼎的机器人主管——\nJim Fan\n。\n平安夜前夕，这位英伟达Project GR00T的领军人物，在亲眼看到自家特斯拉的一路自主护送自己回家后，大受震撼：\n我入手特斯拉比较晚，但却是最早体验FSDv14的用户之一。这可能是我第一次真正感受到通过物理图灵测试的AI：结束一天漫长的工作后，你只需按下一个按钮，放松地靠在座椅上，完全分不出开车的是神经网络还是真人司机。\nJim Fan表示，FSD带来的第一感觉是「不可思议」，并且很快就已经渗透进了他的生活，甚至开始有点「上瘾」。\n一开始你会觉得这不太真实，然后它就成了日常。再然后，就像智能手机一样，一旦失去它，你就会非常难受。\n这就是人类如何被重新塑造，并最终沉迷于技术。\n当然，FSD v14.2.2不是独属于Jim Fan的专属礼物。在陆续收到新版FSD推送后，特斯拉车主们的反馈也迅速刷屏——一句话总结：\n玩疯了\n。\n特斯拉圣诞狂欢\n首个得到英伟达机器人主管「背书」、被称为通过「物理图灵测试」的AI，在这个圣诞节火遍全网。\n这个圣诞节，特斯拉给车主们送来了一波至尊升级，网友一顿测试下来，结论几乎是清一色的：\n满意满意，相当满意，绝对是迄今为止最好的一版FSD。\n看到这一幕，老马自然更是高兴坏了，开始在社交平台上疯狂转发各类车主分享视频。\n在这批「老马严选」中，FSD的表现相当吸睛。但更值得关注的，或许是车主们的反应——\n全部异常兴奋，甚至「吓」坏了的那种\n。\n比如这位花臂老哥，发现FSD能读懂停车场显示屏，在识别到「车位已满」后果断跳过该楼层，激动得像看到自家孩子考了满分。\n下面这位小姐姐最开始没感到有啥变化，但一开始变道就出现了端倪——一秒进入「老司机」模式，\n说换就换，相当果断，不再打大半天转向灯\n。\n如果说这些还只是「懂车人」的兴奋，那下面这段视频就更有反差感了。\n车主拉上了自己从未体验过自动驾驶的奶奶，上来就给老人家配置拉满，体验最新最强FSD，直接给奶奶整出了「恐怖谷效应」。\n事实上，在新版FSD彻底火遍全网之前，马斯克本人早已抢先「上车」。\n当晚，他在社交平台发文称，自己亲自体验了一次\n无安全员的Robotaxi\n测试，并直言体验近乎「完美」。\n周日，我坐在副驾驶座上，一辆没有安全监控系统的特斯拉载着我在奥斯汀转了一圈，全程驾驶表现完美。\n这一帖子下面，\n特斯拉AI总监Ashok Elluswamy\n发布了自己的体验视频，用词同样难掩兴奋。\n这是一次令人惊叹的体验！\n当然，「老马严选」的车主，可能存在幸存者偏差；特斯拉高管站台，也不够令人信服。\n但从其他网友的实测反馈来看，新版FSD这一个个「惊喜」背后，的确有迹可循。\n旧版本的老克星——\n死胡同\n场景，基本已经能解决了：\n雨天，车流巨大、拥堵至极的曼哈顿街头，依然能注意到警车，并且主动避让：\n在狭窄车道多盲区的情况下，能及时识别到左侧有行人出现：\n整体看下来，网友们的体验反馈集中在两方面：\n更像老司机：\n变道丝滑没有犹豫，速度也更合适。能明显感觉到决策过程更快，并且会果断执行。\n脑子更灵光：\n旁边车道有摩托车、维修车辆和人员时，会早早留出空间。\n而这些叠加在一起，最终体现为长时间驾驶可靠性的大幅提升。\n我憋不住了：我的特斯拉第一次载着我们全家，从自家车道一路开到父母家，整整一个半小时车程……我一次都没碰方向盘。\n本月初，马斯克曾放下豪言：要在三周内彻底实现奥斯汀区域Robotaxi的无人驾驶，移除安全监控，副驾驶也不再坐人。\n而现在看来，新版FSD正在把这句豪言化为现实——不仅远超车主预期，甚至让英伟达机器人主管，都直呼不可思议。\n特斯拉如期而至的这份「圣诞礼物」，或许是自动驾驶迈向新阶段的，又一次涌现时刻。\nFSDV14.2.2\n这波FSD（监督版）v14.2.2更新，核心变化集中在神经网络视觉编码器的升级，整体感知与理解能力明显增强。\n新版本利用更高分辨率视觉输入，强化了对紧急车辆、道路障碍物以及人体手势等复杂场景的识别能力。\n比如，在Reddit网友分享的案例中，新版FSD展现了对小动物等异常交通行动者的避让能力。\n而在特殊车辆识别与响应策略上，v14.2.2对警车、消防车、救护车等场景进行了专门优化，新增靠边停车或主动避让紧急车辆的决策与执行逻辑。\n在导航与路径规划层面，v14.2.2引入了更动态的规划能力，可实时应对拥堵、临时绕行等路况变化，而不再完全依赖预设路径。\n泊车能力也是本次更新的重要增强方向，系统新增了「到达选项」，可根据个人偏好选择停车场、路边或地下车库等不同到达方式，导航终点会随之动态调整。\n一位网友分享了FSD v14.2.2在自家车库的倒车入库的视频，哪怕车道上还停着另一辆车，也非常丝滑。\n同时，FSD会记忆并绑定车主的到达偏好与常用停车位置，并保存到具体目的地。后续由推理模型评估可行的到达方案，并给出一个默认推荐选项，从而减少人工干预。\n在驾驶风格控制上，FSD本次全量推送了两种新的速度模式，相比此前的CHILL（冷静）模式，风格区分更加明确：\nSLOTH模式：整体速度更低，车道选择与决策更保守；\nMADMAX模式：速度更高，变道更积极。\n需要注意的是，特斯拉也强调，单车的实际驾驶行为仍会受到车主画像的显著影响。用户历史驾驶越激进，系统允许的最高速度与决策风格也会随之调整，某种程度上是「因人而异」的自适应策略。\n此外，「启动自动驾驶」按钮中的刹车确认机制已默认关闭，用户无需再通过踩下并松开刹车来确认，只需在触控屏上操作即可进入自动驾驶状态。\n虽然FSD v14.2.2这次的更新，表面还是一次基于FSDv14版本的微调，但配上老马高强度推特宣发的佐料，剑指Waymo的意图已经非常明显了。\n和Waymo大战已经硝烟弥漫\n先说结论：在Robotaxi这条赛道上，Waymo仍然占据先机，是当前北美市场在落地规模和市场份额上的绝对领先者；而特斯拉正凭借FSD的持续演进，在规模化路径上加速追赶。\n从奥斯汀这个近期最受关注的战场来看，差距依然清晰。\n特斯拉自今年6月在奥斯汀启动Robotaxi服务以来，目前部署规模约\n30\n辆左右。\n而Waymo早在3月就已在当地上线，当前在运营的自动驾驶车辆接近\n200\n辆。\n如果把视角拉到全美范围，Waymo的领先优势更加明显。\n除奥斯汀外，Waymo还已在菲尼克斯、旧金山、洛杉矶和亚特兰大提供Robotaxi服务，车队总规模超过\n2500\n辆。\n同时，Waymo还计划在2026年扩展至另外20座城市，其中包括达拉斯、华盛顿、迈阿密，甚至伦敦。\n在运营与营收层面，Waymo也已经跑在前面。\n其每周付费行程超过\n45\n万单，2025年全年完成约\n1400万\n次出行；自2020年启动Robotaxi业务以来，累计出行次数已超过\n2000\n万次。\n相比之下，\n特斯拉的运营版图仍然相当有限\n，目前只覆盖德州奥斯汀以及旧金山湾区的部分区域。\n今年10月，在特斯拉第三季度财报电话会上，马斯克曾表示，预计将在年底前在内华达州、佛罗里达州和亚利桑那州推出Robotaxi服务。\n但截至12月中旬，这一目标仍未兑现。\n在加州，根据CPUC和加州机动车管理局（DMV）的说法，特斯拉尚未获得运营商业化Robotaxi服务所需的许可，这也直接限制了其扩张节奏。\n不过，随着FSD能力的持续提升，以及Waymo在旧金山大停电事件中的失误被放大讨论，特斯拉在舆论和用户层面的关注度正在明显上升。\n根据Apptopia数据，自9月上线以来，截至12月12日，TeslaRobotaxi应用累计安装量已达\n52.9万\n次，过去30天的日均下载量为\n2790\n次。作为对比，Waymo应用在同一时间段内的日均下载量为24831次。\n虽然差距依旧明显，但特斯拉的增长趋势正在形成。\n在技术层面，双方的分歧也逐渐走向台前。\n最近，马斯克在X上公开回应了好兄弟、特斯拉前AI负责人安德烈·卡帕西（AndrejKarpathy）的相关观点。\n一年前，卡帕西曾表示：\nWaymo的问题在硬件，特斯拉的问题在软件。\n近期，有网友询问喜提特斯拉新车的卡帕西是否仍然坚持这一判断。\n卡帕西的回应是：Waymo和特斯拉的驾驶体验都已经接近「完美驾驶」，确实存在差异，但只有在特定场景中才会显现。\n而旧金山停电事件就是其中一个例子。\n这一表态，被部分人解读为：\n特斯拉FSD仍略逊于Waymo\n。\n对此，马斯克直接反驳称：\n安子的认知在这一点上已经有些过时了。\n自他离开之后，特斯拉的AI软件已经取得了巨大的进步，远非当年可比。\n以每GB计的智能密度来看，特斯拉AI至少比当前其他任何系统高出一个数量级。\n不少网友也站在了马斯克一边，认为\n特斯拉的自动驾驶能力已经超越Waymo\n。\n也有更理性的分析指出，双方差异的根源在系统架构：\nWaymo采用的是模块化自动驾驶体系，高度依赖高精地图、激光雷达、传感器、5G网络以及远程人工确认。\n这种方案在正常情况下表现稳定，但一旦关键模块失效，系统就会迅速退回到安全策略，例如在停电时进入「变砖模式」。\n而特斯拉FSD走的是端到端神经网络路线：\n通过一个超大模型，直接将摄像头像素映射到转向和制动控制，以海量真实驾驶数据取代人工规则。\n这种方案在极端情况下更具适应性，但也对模型能力提出了更高要求。\n所以，现实依然是，Waymo在规模、合规和商业化进度上处于绝对领先；特斯拉押注的是FSD成熟后带来的指数级扩张能力。\n而随着亚马逊Zoox等玩家继续入场，北美Robotaxi赛道还远未定局。\n不过，可以确定的是，这将是一场长期、烧钱、且高度依赖技术路线选择的绞肉战场。\nOne More Thing\n值得一提的是，在前段时间旧金山停电事件中，马斯克还贴脸开大嘲讽Waymo。\n特斯拉Robotaxi就没受到旧金山停电的影响。\n俗话说，趁你病，要你命，老马的这番拷打也足足给特斯拉吸了一波大粉，该贴点赞已超9.9万。\n不过，回到常态，理性分析来看，自动驾驶的桂冠最终将花落谁家，难有定论。\n但可以确定的是，随着技术不断成熟，汽车是否具备「自动驾驶」能力，不再仅仅从一项锦上添花的附加功能，而是会在真正左右消费者的购车决策。\n而在新版FSD实现实力口碑双丰收后，特斯拉似乎再次瞄准这一争议点，在微博暗暗发布了挑衅：\n将来无法实现自动驾驶的车就像……（大哥大）\n参考链接：\n[1]https://x.com/DrJimFan/status/2003593613918531891\n[2]https://www.cnbc.com/2025/12/16/waymo-amazon-zoox-tesla-robotaxi-expansion.html\n[3]https://medium.com/@akshay.x/teslas-ex-ai-chief-backed-waymo-elon-musk-pushed-back-9351f0397a53\n[4]https://x.com/Yuchenj_UW\n[5]https://www.tesla.com/support/fsd?utm_source=chatgpt.com\n[6]https://www.reddit.com/r/TeslaFSD/\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858281&idx=1&sn=d884333735841a544fbdb16f21ed4528&chksm=e9bcc3d97811fe65fc7f97751242bcae9383c4b518d21c3748d7bb6bcc884ccf0335caafe68f&scene=0&xtrack=1#rd",
      "publish_time": 1766827200,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/DrJimFan/status/2003593613918531891\", \"https://www.cnbc.com/2025/12/16/waymo-amazon-zoox-tesla-robotaxi-expansion.html\", \"https://medium.com/@akshay.x/teslas-ex-ai-chief-backed-waymo-elon-musk-pushed-back-9351f0397a53\", \"https://x.com/Yuchenj_UW\", \"https://www.tesla.com/support/fsd?utm_source=chatgpt.com\", \"https://www.reddit.com/r/TeslaFSD/\"]",
      "add_ts": 1766988648,
      "last_modify_ts": 1766988648
    },
    {
      "id": 33,
      "article_id": "51472",
      "title": "超越GPT-5、Gemini Deep Research！人大高瓴AI金融分析师，查数据、画图表、写研报样样精通",
      "description": "中国人民大学高瓴人工智能学院推出多模态金融研报生成系统“玉兰·融观”（Yulan-FinSight）。该AI系统可自动解析用户研究需求，智能拆解任务，从互联网和金融数据库中采集股价、财报、新闻等多源异构数据，自动生成结构完整、内容专业的金融分析报告，涵盖企业发展历程、核心业务、财务分析等内容，并支持生成专业图表，实现端到端的自动化金融投研辅助，显著提升研究效率与准确性。",
      "content": "FinSight团队 投稿\n量子位 | 公众号 QbitAI\n能自动查数据、写分析、画专业金融图表的AI金融分析师来了！\n最近，中国人民大学高瓴人工智能学院提出了一个面向真实金融投研场景的多模态研报生成系统——\n玉兰·融观\n（Yulan-FinSight）\n。\n面对用户的研究需求，FinSight能够自动拆解任务，从互联网和金融数据库中搜集包括股价、财报、新闻在内的\n多源异构数据\n，并生成包含“发展历程”、“核心业务架构”、“竞争格局”等章节的\n万字图文报告\n。\n△\n可在FinSight预设基础上自行配置\n该系统也在\nAFAC 2025 金融智能创新大赛挑战组\n的1289支队伍中夺冠，并在多项评测中超越了GPT-5 w/Search、OpenAI Deep Research与Gemini-2.5-Pro Deep Research，展现出接近人类专家的金融分析与写作能力。\n下面来看详细内容。\n为什么通用AI做不好金融研报？\n在研究者看来，问题的关键并不在于模型“不会写字”，而在于金融行业的研究报告本身是一项\n高度结构化、强逻辑、强可视化\n的专家级工作，涉及多个流程。\n相比通用问答、检索或文本生成任务，金融投研对数据整合能力、分析深度以及表达形式均提出了更高要求。\n具体而言，现有通用AI系统主要面临三方面挑战：\n1、领域知识与数据割裂：\n通用搜索系统难以有效整合股价、财务报表等结构化金融数据与新闻、公告等非结构化信息。由于缺乏统一的数据表示与多智能体协作分析机制，系统往往只能对单一信息源进行浅层处理，难以形成系统性的金融洞察。\n2、专业级可视化能力缺失：\n金融研报高度依赖图表来传递高密度信息，但现有模型多只能生成静态图片或简单折线图，难以支持多维对比、事件标注等专业金融可视化需求，图文之间也缺乏严格的数据一致性约束，例如，图文无关或图文信息矛盾与冲突。\n3、缺乏“迭代式研究”能力：\n绝大多数系统仍采用固定的“先检索—后生成”流程，研究路径一旦确定便难以调整。\n相比之下，人类分析师往往会根据中间发现不断修正研究重点，而这种基于中间结果的动态策略调整能力，正是现有通用AI系统普遍欠缺的部分。\nFinSight的核心思路：像金融分析师一样工作\n为突破上述限制，FinSight并未简单地“堆模型”，而是从认知流程入手，模拟人类金融专家的工作方式，并提出了三项关键技术创新。\n核心架构：代码驱动的可变内存智能体架构\n△\n从单智能体到多智能体\nFinSight的底层采用了一种全新的、名为\nCode-Driven Variable-Memory\n（CAVM）\n的多智能体架构。\n如图所示，现有Agent 架构本质上仍受限于对话式记忆范式，即以消息或任务进度等历史作为状态载体。这一范式在任务复杂度与流程长度增长时，容易暴露出表达能力与可控性的结构性瓶颈。\nCAVM将这一范式重构为代码驱动的变量记忆空间。系统不再以自然语言对话作为协作媒介，而是将数据、工具与中间推理结果统一映射为可读写的程序变量，由多个\nCode Agent\n通过共享变量空间完成协同推理。\n通过将“记忆”从消息序列提升为可操作的变量结构，CAVM 使复杂任务得以被显式建模、持续修正与模块化组合，为\n长时程、多流程\n的专家级推理提供了必要的结构支撑。\n△\nCAVM架构示意图\n在这一设计中，数据、工具和智能体被统一抽象为可编程变量空间：\n财务报表、行情数据、新闻文本作为数据变量\n搜索、分析、绘图等能力作为工具变量\n不同功能的Agent通过Python代码进行调度与协作\n这种“以代码为中枢”的设计，使系统能够高效处理大规模异构金融数据，并支持复杂的多流程任务协作。\n视觉突破：迭代式视觉增强机制\n针对金融图表生成中普遍存在的专业性与可信度问题，研究者们提出了\nIterative Vision-Enhanced Mechanism\n，将绘图过程建模为一个可迭代优化的视觉生成问题。\n△\nFinSight生成的多维图表\n该机制采用了\nActor–Critic 协作范式\n：\n文本大模型作为\nActor\n，负责生成可编译、可执行的绘图代码，充分发挥其在代码生成与逻辑控制上的优势；而视觉语言模型则作为\nCritic\n，直接对图像进行视觉层面的审视，从数完整性与整体美观性等维度提供反馈。\n这一设计的关键在于\n优势互补\n：语言模型擅长编码与思考，却难以获取真实的视觉反馈；视觉模型具备强大的感知与判别能力，但在复杂代码生成上能力受限。\n通过将二者解耦并置于闭环中，系统在\ntest time\n通过多轮“生成—评估—修正”实现持续优化，使绘图质量随迭代次数自然提升。\n△\n股价、MACD、RSI分析图\n最终，系统能够稳定生成包含双轴对齐、事件标注以及复杂结构的专业金融图表，如图所示，将原本一次性生成的静态结果，转化为一种\ntest-time scaling\n的过程。\n两阶段写作框架：先分析，再成文\n在写作层面，FinSight并不试图一次性生成完整的长篇研报，而是将研报写作重构为\n“分析—整合”\n的两阶段过程。\n△\n两阶段写作框架示意图\n首先，系统生成一组\n“分析链”\n（Chain-of-Analysis，CoA）\n：每条分析链对应一个明确的子任务\n（如公司历程、财务分析、竞争对手分析、风险因素等）\n，在局部范围内完成证据收集、关键判断与核心结论提炼。\n之所以需要这一步，是因为一份研究报告往往由多个子问题耦合构成，若直接端到端生成长文，很难兼顾所有的分析准确性和深度。\n随后，系统以这些CoA作为“骨架”，将分散的洞察在全局层面进行组织与编排，生成大纲并分章节逐步写作：在保证章节结构与论证链条连贯的同时，把文本叙述、数据引用与图表呈现进行对齐，最终合成为一份逻辑自洽的长篇报告。\n这种\n“先分析、后写作”\n的策略有效避免了长文常见的逻辑松散问题，使报告在篇幅超过2万字时仍保持结构清晰、论证深入。\n为了进一步保证长篇研报中的事实准确性与图文一致性，作者在写作阶段还引入了一种\n生成式检索\n（Generative Retrieval）\n机制。\n不同于传统“先检索、后生成”的后处理做法，该方法将检索过程嵌入写作本身：模型在生成具体段落时，会根据当前的分析链与写作上下文，动态生成数据和图片的索引标识符，再通过后处理统一嵌入。\n这样一来，引用准确性和图文一致性得到了最大的保证。\n△\n分析链输出结果\n通过这种方式，FinSight能够在长篇写作过程中持续对齐文本叙述、数据来源与可视化结果，避免常见的事实错配与图文脱节问题，从而在报告篇幅不断扩展的情况下，依然保持整体逻辑与证据链的稳定性与一致性。\n实验结果：全面超越现有Deep Research系统\n作者们在涵盖公司研究与行业研究的高质量基准测试上，对FinSight进行了系统评估。\n结果显示，FinSight在事实准确性、分析深度与呈现质量三项核心指标上均显著优于Gemini-2.5-Pro Deep Research与OpenAI Deep Research，综合评分达到\n8.09\n。\n在可视化维度上，得益于迭代式视觉增强机制，FinSight获得\n9.00\n的评分，明显领先对比系统，体现出对专业金融图表生成能力的有效提升。\n而迭代式绘图的效果分析同样惊艳：\n在长文本生成场景中，系统生成的研报平均长度超过20000字，包含50余张图表与结构化数据引用，且随着篇幅增长，报告质量保持稳定，未出现显著退化。\n此外，在AFAC 2025金融智能创新大赛中，FinSight在来自企业与高校的1289支参赛队伍中\n排名第一\n，获得挑战组赛题四冠军，进一步验证了其在真实场景中的实用性与鲁棒性。\n研究者认为，FinSight并非仅是一个金融工具，而是展示了Agent架构在高复杂度垂直领域的潜力。\n通过统一数据、工具与智能体，并引入视觉与写作的多阶段闭环，AI系统\n首次\n在金融投研这一“专家密集型”场景中，展现出接近人类分析师的工作能力。\n这一范式的意义不止于金融。\n它表明，在那些高度依赖专业知识、长时程推理与多模态表达的“专家密集型”场景中，AI 系统不再只是信息汇总器，而开始承担起类似人类专家的工作方式：\n分解问题、验证假设、修正结论，并最终形成可被审阅与追溯的完整成果。\n从这个角度看，\nFinSight更像是一个起点\n。\n随着Agent架构不断成熟，未来的科研分析、法律研判、医疗决策等复杂领域，或将逐步迎来以专家级AI Agent为核心的新一代生产力形态。\n论文及项目作者：\n中国人民大学高瓴人工智能学院：金佳杰、张宇尧、许一孟、钱泓锦、朱余韬、窦志成\n论文链接：https://arxiv.org/abs/2510.16844\n代码链接：https://github.com/RUC-NLPIR/FinSight\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n我们正在招聘一名眼疾手快、关注AI的\n学术编辑实习生\n🎓\n感兴趣的小伙伴欢迎关注 👉\n了解详情\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858336&idx=3&sn=f9c1a87c7f5962d38ddcf6ed125ab541&chksm=e9b09f2412143db1a1f7cf4de8fdf1d0597c72d0094e715d07c2aaf417781be379e40eed4587&scene=0&xtrack=1#rd",
      "publish_time": 1766827200,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2510.16844\", \"https://github.com/RUC-NLPIR/FinSight\"]",
      "add_ts": 1766988654,
      "last_modify_ts": 1766988654
    },
    {
      "id": 34,
      "article_id": "51471",
      "title": "AI金矿上打盹的小红书，刚刚醒了一「点点」",
      "description": "小红书将原本活跃在评论区的AI助手“点点”升级并移至首页侧边栏，成为常驻功能。此前用户常在评论区@点点互动，如今其角色被官方正式强化，融入主界面，实现更便捷的AI交互体验，标志着平台进一步推动人工智能与社区内容融合。",
      "content": "鱼羊 发自 凹非寺\n量子位 | 公众号 QbitAI\n事情是这样的。\n作为一个小红书重度用户，今天一开软件我天塌了：我的侧边栏呢？？？\n一点进去发现，好家伙，小红书这波操作，终于是\n把官方AI整上了我的首页\n。\n是新功能，但也是老面孔。AI助手名叫\n点点\n，\n用户们应该挺眼熟，就是之前在评论区常会被@的小红书版评论罗伯特。\n我赶紧一个搜索，原来官方真是更新了玩法。\n评论区@不到了，但现在，你可以在小红书里这样玩AI：笔记直接分享给点点，不用手动跳转，即可开启边刷边聊模式。\n还真别说，现在的社交媒体上，要没点AI出没，是有那么点不习惯。\n像微博，不止有到处串场的评论罗伯特，也把「智搜」功能插进了每一个热门话题里，主打一个让用户吃瓜不迷路；而微信，也把元宝总结的功能内置进了公众号文章页面。\n看上去在AI上一直比较保守的小红书，现在也醒了一「点点」。\nAI一点点，体验变好了吗？\nAI一点点，有没有让刷社媒的体验变好，还是得实测一波才知底细。\n交互体验\n先来看看交互方式。\n第一种方式，就是在原来首页侧边栏的位置，\n点击小气泡进入点点对话框\n：\n用法跟别的AI助手没有什么不同，好处就是无需跳转其他App，在小红书本书里就可以提问AI。\n从回答质量上来看，背靠小红书的海量种草内容，让Ta推荐点文娱作品啊，吃吃喝喝啊，效果都不错，可以省去一大波刷笔记的时间（细思……emmm有点微妙\n）。\n第二种方式，就是在笔记页面通过\n分享\n功能，把笔记发给点点开启讨论。\n比较有意思的是，还可以\n划词提问\n，哪里想聊划哪里：\n长按评论区评论\n，同样可以唤醒点点。\n从交互的角度来看，有点随叫随到那意思了。\n吃喝玩乐小帮手\n不知道列位最常用小红书搜罗什么信息，我嘛，主要还是被\n真实评论\n吸引，想买点什么好玩的，吃点什么好吃的，就愿意上小红书种种草。\n那么点点是否能够总结出这些来自用户的真实评价，帮助我们做决策呢？\n正好海淀剧场最近在演开心麻花的《出马》，题材很有意思的样子，这个票钱值不值得花，我决定问问点点。\n点点没有直接给结论，而是帮忙总结了小红书上的各种讨论，把争议点和好评都梳理清楚了。\n至于判断嘛，还得自己下~\n问完看的咱们再问点吃的：\n帮我整理一下北京海淀区有哪些性价比高还好吃的港式餐厅，不要广。\n不知道是不是因为海淀过于美食荒漠了，这次点点的建议还挺明确的。功课做得也比较细心，店面环境、性价比、等位排队情况都有总结到。\n总结信息小工具\n当然啦，家人们大部分刷小红书的时间一定是在\n学习新知识\n！\n比如刷刷量子位，随时掌握最新AI资讯（doge）。\n学习嘛，遇到内容多到10来张图放不下的时候，难免想扮演一下霸道总裁，让小助理直接呈上简报。\n点点作为一个AI助手，干这活儿看上去非常合适。\n我测试了一下，让它在一个包含1200+条评论的播客推荐笔记中，帮我整理出网友们觉得高质量的播客。\n效果打几分，欢迎大家在评论区给我点意见：\n比较不错的一点是，不止是文字笔记，视频笔记点点也同样能帮忙总结。\nAI点了，争议也来了\n总体来说，点点这次在小红书本体里全量上线，确实让\nApp里的AI交互体验变得更方便了。\n看样子，虽然行动上一直以来有点犹抱琵琶半遮面，但这波小红书官方似乎也是下定了决心猛猛推AI。\n不过，用户们并没有AI全肯定，点点官方的评论区，就出现了不少不同意见。\n比如，不少用户跟我一样，第一反应就是：我的侧边栏呢？？？\n很难想象侧边栏场景直接换AI，这种只有老板自上而下能推的动。\n也有用户反馈，认为经过点点过滤的信息，没有自己看笔记得到的信息丰富和友好。\n不过官方也还在一个征求意见改进的阶段，如果你的小红书也已经被点点「刷新」，在12月31日之前，都可以到点点ai的ask me anything笔记下反馈意见。\n总之嘛，「点点」对小红书绝对算得上一个积极的信号。\n因为在AI和大模型热潮中，小红书因为内容生态的独特性、「活人感」，被视为预训练决胜的金矿之一……但就技术和产品的结果呈现来看，这个金矿主人或许还没意识到重要性——当然也有评价是能力不具备。\n好的一面是，现在躺在金矿上的人，看起来要醒了——哪怕是一「点点」。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858567&idx=1&sn=a2c1a9bb04614cc3aacebd870202414d&chksm=e971aa789a9d893667d6badf2a5f281fa5942af651f13e764342d57f2e7b721a82da477e8f78&scene=0&xtrack=1#rd",
      "publish_time": 1766827200,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1766988659,
      "last_modify_ts": 1766988659
    },
    {
      "id": 37,
      "article_id": "51468",
      "title": "P图新手福音！智能修图Agent一句话精准调用200+专业工具，腾讯混元&厦大出品",
      "description": "腾讯混元与厦门大学联合推出JarvisEvo图像编辑智能体，可实现“一句话修图”。该系统模拟人类专家思维，通过迭代编辑、视觉感知、自我评估与反思，像工匠般精细打磨图像。相比传统软件更简便，较AI修图更具可控性，支持Lightroom操作并能自主判断修图效果，实现端到端高质量图像优化，大幅提升编辑效率与质量。",
      "content": "JarvisEvo团队 投稿\n量子位 | 公众号 QbitAI\n一句话让照片变大片，比专业软件简单、比AI修图更可控！\n腾讯混元携手厦门大学推出\nJarvisEvo\n——一个统一的图像编辑智能体模拟人类专家设计师，通过\n迭代编辑、视觉感知、自我评估和自我反思\n来“p图”。\n“像专家一样思考，像工匠一样打磨”\n。JarvisEvo不仅能用Lightroom修图，更能“看见”修图后的变化，并自我评判好坏，从而实现无需外部奖励的自我进化 。\n下面就来了解一下详细情况吧～\n自我评估和修正\n研究背景与动机\n近年来，基于指令的图像编辑模型虽然取得了显著进展，但在追求“专业级”修图体验时，仍面临两大核心挑战：\n指令幻觉 (Instruction Hallucination)：\n现有的文本思维链 (Text-only CoT) 存在信息瓶颈。模型在推理过程中“看不见”中间的修图结果，仅凭文本“脑补”假设进行下一步操作的视觉结果，容易导致事实性错误，无法确保每一步都符合用户意图。\n奖励黑客 (Reward Hacking)：\n在强化学习进行偏好对齐的过程中，策略模型（Policy）是动态更新的，而奖励模型（Reward Model）通常是静态的。这导致策略模型容易“钻空子”，通过欺骗奖励函数获取高分，而非真正提升修图质量和自我评估能力 。\n为了解决上述问题，团队推出了JarvisEvo.\niMCoT：交互式多模态思维链\n打破了传统“盲修”的局限。JarvisEvo 引入了\niMCoT (Interleaved Multimodal Chain-of-Thought)\n机制。与纯文本推理不同，JarvisEvo在每一步编辑后都会生成新的图像，并基于视觉反馈进行下一步推理。\n模型在“生成文本假设 -> 执行工具 -> 观察视觉结果 -> 反思决策”的循环中工作，确保每一步操作都精准落地 。\nSEPO：协同编辑-评估策略优化\n这是JarvisEvo 实现“自进化”的引擎。团队提出了\nSEPO (Synergistic Editor-Evaluator Policy Optimization)\n框架，包含两个协同进化的优化环 ：\n编辑者优化环 (Loop 1)：模型利用自我评估分数作为内在奖励，不再依赖容易被 hack 的外部奖励模型。\n评估者优化环 (Loop 2)：利用人类标注数据持续校准模型的评估能力，防止模型在自我打分时“自欺欺人”。\n在线反思与自我修正\nJarvisEvo具备从错误中学习的能力。在训练过程中，系统会自动将低分轨迹与高分轨迹进行对比，生成\n反思数据 (Reflection Data)。\n模型通过分析“为什么修错了”以及“如何修正”，习得强大的自我纠错能力。\n像人类一样“边看边修”\nJarvisEvo系统架构\n传统的文本思维链（Text-only CoT）通常是“盲修”，即一次性生成所有步骤。\nJarvisEvo则采用了 交互式多模态思维链 (iMCoT)，模拟了人类设计师“观察-操作-检查”的闭环工作流。\n整个推理过程分为四个核心步骤：\n1、视觉感知与规划 (Perception&Planning)：模型首先分析原图（I）与用户指令（Q），生成初始的修图思路。\n2、多步工具执行 (Step-by-Step Execution)：\n模型生成交错的文本推理内容（C）和工具调用指令（T）。\n工具沙盒 (Sandbox)：指令被发送到外部的Adobe Lightroom环境中执行，生成中间态的编辑图像（O）。\n视觉反馈 (Visual Feedback)：这一点至关重要。模型会“看”到刚刚修好的图，基于最新的视觉状态决定下一步是继续调整还是修正错误 。\n3、自我评估 (Self-Evaluation)：修图结束后，模型会对最终结果（Ot）的美学质量和指令符合度进行自我打分（S）。\n4、自我反思 (Self-Reflection)：如果结果不理想，模型会触发反思机制，分析偏差原因并尝试纠正。\n三阶段的训练框架\n为了打造这样一个全能 Agent，团队设计了一套严谨的\n三阶段训练流水线\n：\nStage 1: 冷启动监督微调 (Cold-Start SFT)\n数据量：150K标注样本（110K编辑数据+40K评估数据）。\n目标：教会模型“基本功”。这包括掌握多模态推理的语法、能够交替生成文本与图像内容、学会根据视觉线索选择正确的工具，以及初步建立审美评估能力。\nStage 2: SEPO强化学习 (The Evolution)\n数据量：20K标准指令数据（10K编辑+10K评估）。\n核心机制：引入\n协同编辑-评估策略优化 (SEPO)\n。在此阶段，模型脱离了对标准答案的模仿，开始自主探索。\n双优化驱动： 此阶段让模型从“会用工具”进化为“精通修图”。 编辑者优化：通过自我打分（Self-Reward）优化修图策略，并利用SLM (Selective Loss Masking) 防止奖励作弊。\n评估者优化：利用人类评分数据校准模型的审美眼光，确保它能做一个公正的裁判。\nStage 3: 反思微调 (Reflection Fine-Tuning)\n数据量：5K少量在线生成的反思样本。\n目标：这是JarvisEvo具备“自我纠错”能力的关键。通过学习如何在错误路径上进行反思和修正，模型在处理复杂指令时的鲁棒性大幅提升。\nSEPO：协同编辑-评估策略优化\n在传统的强化学习（RLHF）中，模型通常依赖一个静态的“奖励模型”来打分。\n但这存在一个致命缺陷：随着策略模型越来越强，它会学会“钻空子”（Reward Hacking），即通过生成某些特定的、诡异的模式来骗取高分，而不是真正提升自己的编辑能力。\n为了解决这个问题，JarvisEvo提出了SEPO框架。它的核心思想是：\n让模型既做“运动员”也做“裁判员”，并通过两个并行的优化环，让这两种能力同步提升，互相制约。\nLoop 1编辑者优化环 (Editor Policy Optimization)是让模型学会如何更好地使用工具来修出好图。\n自我奖励 (Self-Reward) 机制：JarvisEvo不再依赖外部黑盒模型打分，而是利用自身的Self-evaluation能力。在生成修图轨迹后，模型会根据最终图像的美学质量和指令遵循度，自己给自己打分。\nGRPO优化目标：采用群相对策略优化 (Group Relative Policy Optimization)。对于同一个输入，模型生成多条修图轨迹，通过比较这些轨迹的“胜率”（Pairwise Preference Reward）来进行更新，而非单纯依赖绝对分数，这使得训练更加稳定。\n选择性损失掩码 (SLM)是其中的关键技术。这是一个防止“作弊”的机制。如果没有SLM，模型可能会发现：“只要我最后生成的自我评分文本是满分，loss就会变小”。\n为了防止这种“信息泄露”，在计算编辑器的梯度时，强制掩盖掉自我评分部分的token。这样逼迫模型只能通过切实提升前面的推理质量 (Chain-of-Thought) 和 工具使用准确性 (Tool Use) 来间接获得高分，而不是直接生成高分文本。\n评估者优化环 (Evaluator Policy Optimization)确保这个“裁判员”是公正、客观且符合人类审美的。\n可验证的强化学习 (Verifiable RL)：虽然Loop 1依赖自我打分，但如果裁判本身审美跑偏了怎么办？Loop 2专门解决这个问题。我们使用包含人类专家标注 (Human-Annotated) 的数据集来训练模型的评估能力。\n分数对齐奖励 (Score Alignment Reward)：在这个循环中，奖励取决于模型打分与人类专家打分的接近程度。\n作用：这个循环不断校准模型的审美标准，防止其在Loop 1中陷入“自欺欺人”的自我陶醉，确保自我奖励信号的含金量。\n这两个循环是交替进行的，形成了一种“左右互搏”的进化效应，打破了静态奖励模型的桎梏，实现了一种\n闭环的、可持续的自我能力提升\n。\n在线反思数据生成机制 (On-Policy Reflection)\nJarvisEvo如何学会“从错误中学习”？团队在Stage 2的训练过程中植入了一个自动化的数据生成：\n捕捉契机：当模型生成了一个更好的修图轨迹Trajectory0（得分s0），且该得分显著高于之前的某次尝试Trajectory3（得分s3）时，触发反思生成。\n归因分析：调用商业大模型（如Gemini-2.5-Pro）作为“导师”，输入源图、错误的修图结果O3、正确的修图结果O0以及用户指令。\n生成反思链：“导师”会生成一段详细的分析文本（R），解释为什么O3失败了（例如“白平衡参数推得太高导致偏色”），并指出正确的做法。\n构建样本：将这段包含“错误尝试 -> 深刻反思 -> 正确修正”的完整轨迹存入数据集Dataset_reft，用于第三阶段的微调。\nArtEdit 数据集\n为了支撑上述训练，团队构建了\nArtEdit\n——一个包含170K样本的双语（中/英）专业修图数据集。\n包含人像、风光、建筑、静物、夜景等10大类、37个子类的专业摄影场景。通过A2L (Agent-to-Lightroom) 协议，无缝集成了Adobe Lightroom中的\n200+\n个修图工具。\nArtEdit-Lr (120K)：专注于修图任务，包含完整的iMCoT轨迹（推理思考、工具参数、中间图）。\nArtEdit-Eval (50K)：专注于审美评估，包含人类专家对图像质量和指令遵循度的打分（1-5分）。\n实验结果\n在ArtEdit-Bench评测中，L1和L2指标上，相比商业级模型Nano-Banana提升了44.96%，最大限度保留了原图细节 。\n在SC（语义一致性）和PQ（感知质量）指标上全面领先，平均提升18.95% 。\n并且其打分与人类主观偏好的相关性（SRCC 0.7243）超越了GPT-4o (Gemini-2.5-flash) 和专门的IQA模型。\n视觉效果上，对比其他模型，JarvisEvo处理后的图像更贴合用户指令，在风格营造、细节呈现等方面表现突出。\n在包含 200 个样本的人类主观评测中，JarvisEvo在与Nano-Banana的对决中取得了49%的胜率（远超对手Nano Banana的28%），证明了其修图结果更符合人类审美 。\n这种“生成器-内部批评家”的协同进化范式具有强大的通用性，未来有望从修图拓展至数学推理、代码生成及长程规划等领域。\n同时，团队将致力于突破当前步数限制，探索超过10步的复杂长程推理任务。\n感兴趣的朋友可戳下方链接了解更多细节～\n项目主页: https://jarvisevo.vercel.app/\n论文全文:\nhttps://arxiv.org/pdf/2511.23002\nGithub：https://github.com/LYL1015/JarvisEvo\nHuggingface Daily Paper：https://huggingface.co/papers/2511.23002\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n我们正在招聘一名眼疾手快、关注AI的\n学术编辑实习生\n🎓\n感兴趣的小伙伴欢迎关注 👉\n了解详情\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858281&idx=3&sn=f97ff85b460b769b6fb3217415640671&chksm=e9079209d939ff3cdc929bcc445062778fb9fd15020f089908956e7e1aadedd475063e233c3e&scene=0&xtrack=1#rd",
      "publish_time": 1766814600,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://jarvisevo.vercel.app/\", \"https://arxiv.org/pdf/2511.23002\", \"https://github.com/LYL1015/JarvisEvo\", \"https://huggingface.co/papers/2511.23002\"]",
      "add_ts": 1766988678,
      "last_modify_ts": 1766988678
    },
    {
      "id": 38,
      "article_id": "51467",
      "title": "",
      "description": "WildVideo首次系统定义9类幻觉任务，构建大规模中英双语视频对话数据集，采用多轮开放问答形式，覆盖双重视角，贴近真实交互场景，全面评估多模态模型在视频问答中的幻觉问题，推动大模型在开放世界多模态理解中的可靠应用。",
      "content": ":\n，\n.\nVideo\nMini Program\nLike\n，轻点两下取消赞\nWow\n，轻点两下取消在看",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652657947&idx=2&sn=63dfa93f493b328bc7e3dabff3f1ea5b&chksm=f098c0ee5782c9f277d48e393d89f0f05754c2e33e9940c01483ee79fbe5e09d02775eb72348&scene=0&xtrack=1#rd",
      "publish_time": 1766810400,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1766988679,
      "last_modify_ts": 1766988679
    },
    {
      "id": 39,
      "article_id": "51466",
      "title": "推理成本打到1元/每百万token，浪潮信息撬动Agent规模化的“最后一公里”",
      "description": "浪潮信息推出元脑HC1000超扩展AI服务器，首次将AI推理成本降至1元/每百万token，大幅降低智能体规模化落地门槛。在AI产业从模型竞赛转向降本增效的关键阶段，该突破有望破解产业化成本瓶颈，推动行业盈利模式成型，重塑AI竞争格局，加速智能体在各领域的广泛应用。",
      "content": "允中 发自 凹非寺\n量子位 | 公众号 QbitAI\n当前全球AI产业已从模型性能竞赛迈入智能体规模化落地的“生死竞速”阶段，\n“降本”\n不再是可选优化项，而是决定AI企业能否盈利、行业能否突破的核心命脉。\n在此大背景下，浪潮信息推出\n元脑HC1000超扩展AI服务器\n，将推理成本首次击穿至\n1元/每百万token\n。\n这一突破不仅有望打通智能体产业化落地“最后一公里”的成本障碍，更将重塑AI产业竞争的底层逻辑。\n浪潮信息首席AI战略官刘军\n强调：\n当前1元/每百万token的成本突破仅是阶段性胜利，面对未来token消耗量指数级增长、复杂任务token需求激增数十倍的必然趋势，现有成本水平仍难支撑AI的普惠落地。\n未来，AI要真正成为如同 “水电煤” 般的基础资源，token成本必须在现有基础上实现数量级跨越，成本能力将从“核心竞争力”进一步升级为“生存入场券”，直接决定AI企业在智能体时代的生死存亡。\n△\n浪潮信息首席AI战略官刘军\n智能体时代，token成本就是竞争力\n回顾互联网发展史，基础设施的\n“提速降费”\n是行业繁荣的重要基石。\n从拨号上网以Kb计费，到光纤入户后百兆带宽成为标配，再到4G/5G时代数据流量成本趋近于零——每一次通信成本的显著降低，都推动了如视频流媒体、移动支付等全新应用生态的爆发。\n当前的AI时代也处于相似的临界点，当技术进步促使token单价下滑之后，企业得以大规模地将AI应用于更复杂、更耗能的场景，如从早期的简短问答，到如今支持超长上下文、具备多步规划与反思能力的智能体……\n这也导致单任务对token的需求已呈指数级增长。如果token成本下降的速度跟不上消耗量的指数增长，企业将面临更高的费用投入，这昭示着经济学中著名的“杰文斯悖论”正在token经济中完美重演。\n（杰文斯悖论是1865年经济学家威廉·斯坦利·杰文斯提出的悖论：指当技术进步提高了效率，资源消耗不仅没有减少，反而激增。例如，瓦特改良的蒸汽机让煤炭燃烧更加高效，但结果却是煤炭需求飙升。）\n来自多方的数据也有力佐证了token消耗量的指数级增长趋势。\n火山引擎最新披露的数据显示，截至今年12月，字节跳动旗下豆包大模型日均token使用量突破\n50万亿\n，较去年同期增长超过10倍，相比2024年5月刚推出时的日均调用量增长达417倍；\n谷歌在10月披露，其各平台每月处理的token用量已达\n1300万亿\n，相当于日均43.3万亿，而一年前月均仅为9.7万亿。\n△\n谷歌公布其token处理量变化\n当使用量达到“百万亿token/月”的量级时，哪怕每百万token成本只下降1美元，也可能带来\n每月1亿美元\n的成本差异。\n对此，刘军认为：\ntoken成本就是竞争力，它直接决定了智能体的盈利能力。要让AI真正进入规模化普惠阶段，token成本必须在现有基础上继续实现数量级的下降。\n深挖token成本“暗箱”：架构不匹配是核心瓶颈\n当下，全球大模型竞赛从“盲目堆算力”转向“追求单位算力产出价值”的新阶段。\n单位算力产出价值受到能源价格、硬件采购成本、算法优化、运营成本等多种因素的影响，但不可否认的是，现阶段token成本80%以上依然来自算力支出。\n而阻碍成本下降的核心矛盾，在于推理负载与训练负载截然不同，沿用旧架构会导致算力、显存与网络资源难以同时最优，造成严重的“高配低效”。\n一是\n算力利用率（MFU）的严重倒挂\n。\n训练阶段MFU可达50%以上，但在推理阶段，特别是对于追求低延迟的实时交互任务，由于token的自回归解码特性，在每一轮计算中，硬件必须加载全部的模型参数，却只为了计算一个token的输出，导致昂贵的GPU大部分时间在等待数据搬运，实际MFU往往仅为5%-10%。这种巨大的算力闲置是成本高企的结构性根源。\n二是\n“存储墙”瓶颈在推理场景下被放大\n。\n在大模型推理中，随着上下文长度的增加，KV Cache呈指数级增长。这不仅占用了大量的显存空间，还导致了由于访存密集带来的高功耗。\n这种存算分离不仅带来数据迁移功耗和延迟，还必须配合使用价格高昂的HBM，已经成为阻碍token成本下降的重要瓶颈。\n三是\n网络通信与横向扩展代价愈发高昂\n。\n当模型规模突破单机承载能力时，跨节点通信成为新瓶颈。传统RoCE或InfiniBand网络的延迟远高于芯片内部的总线延迟，通信开销可能占据总推理时间的30%以上，导致企业被迫通过堆砌更多资源来维持响应速度，推高了总拥有成本（TCO）。\n对此，刘军指出，降低token成本的核心不是“把一台机器做得更全”，而是\n围绕目标重构系统\n——\n把推理流程拆得更细，支持P/D分离、A/F分离、KV并行、细粒度专家拆分等计算策略，让不同计算模块在不同卡上按需配置并发，把每张卡的负载打满，让“卡时成本”更低、让“卡时产出”更高。\n基于全新超扩展架构，元脑HC1000实现推理成本首次击破1元/每百万token\n当前主流大模型的token成本依然高昂。以输出百万token为例，Claude、Grok等模型的价格普遍在10-15美元，国内大模型虽然相对便宜，也多在10元以上。\n在天文数字级别的调用量下，如此高的token成本让大规模商业化应用面临严峻的ROI挑战。\n因此，要打破成本僵局，必须\n从计算架构层面进行根本性重构\n，从而大幅提升单位算力的产出效率。\n△\n主流LLM的百万token价格\n为此，浪潮信息推出\n元脑HC1000超扩展AI服务器\n。\n该产品基于全新设计的全对称DirectCom极速架构，采用无损超扩展设计，可高效聚合海量本土AI芯片，支持极大推理吞吐量，推理成本首次击破1元/每百万token，为智能体突破token成本瓶颈提供极致性能的创新算力系统。\n△\n元脑HC1000超扩展AI服务器\n对此，刘军表示：\n我们看到原来的AI计算是瞄着大而全去建设的，五脏俱全，各种各样的东西都在里面。但是当我们聚焦降低token成本这一核心目标之后，我们重新思考系统架构设计，找到系统瓶颈，重构出一个极简设计的系统。\n元脑HC1000创新设计了DirectCom极速架构，每计算模组配置16颗AIPU，采用直达通信设计，解决传统架构的协议转换和带宽争抢问题，实现超低延迟；计算通信1:1均衡配比，实现全局无阻塞通信；全对称的系统拓扑设计，可以支持灵活的PD分离、AF分离方案，按需配置计算实例，最大化资源利用率。\n△\n全对称DirectCom极速架构\n同时，元脑HC1000支持超大规模无损扩展，DirectCom架构保障了计算和通信均衡，通过算网深度协同、全域无损技术实现推理性能1.75倍提升，并且通过对大模型的计算流程细分和模型结构解耦，实现计算负载的灵活按需配比，单卡MFU最高可提升5.7倍。\n△\n超大规模无损扩展\n此外，元脑HC1000通过自适应路由和智能拥塞控制算法，提供数据包级动态负载均衡，实现KV Cache传输和All to All通信流量的智能调度，将KV Cache传输对Prefill、Decode计算实例影响降低5-10倍。\n刘军强调，当前“1元/每百万token”还远远不够，面对未来token消耗量的指数级增长，若要实现单token成本的持续、数量级下降，需要推动计算架构的根本性革新。\n这也要求整个AI产业的产品技术创新，要从当前的规模导向转为\n效率导向\n，从根本上重新思考和设计AI计算系统，发展AI专用计算架构，探索开发大模型芯片，推动算法硬件化的专用计算架构创新，实现软硬件深度优化，这将是未来的发展方向。\n*本文系量子位获授权刊载，观点仅为原作者所有。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858281&idx=2&sn=a1ab44bada75c81891f63e227d54188f&chksm=e9c0a5bfb19466eb0905956ab1e65b2bfeb616daff587c9d981a512f338cf7f521f07c5193a2&scene=0&xtrack=1#rd",
      "publish_time": 1766809800,
      "publish_date": "2025-12-27",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1766988686,
      "last_modify_ts": 1766988686
    },
    {
      "id": 44,
      "article_id": "51505",
      "title": "生物、机器与社会的群体智能——11所高校联合发起的群体智能读书会",
      "description": "「群体智能」读书会由集智俱乐部与北京师范大学系统科学学院联合发起，通过动物、人类、机器三条线索，结合物理学、数理逻辑、多主体建模与计算传播等跨学科视角，探讨蚁群、鱼群、无人机集群、群智优化及多智能体系统中的涌现现象，追问“集群何以比个体更聪明”及群体智能的形成机制，旨在揭示群体智能的本质与规律。",
      "content": "导语\n如果你对这些反直觉但极有用的现象感兴趣——从蚁群搭桥、鱼群同步、到无人机集群表演、集群机器人协作、群智优化与多智能体系统、网络舆论建模研究等——欢迎加入「群体智能」读书会：我们用动物—人类—机器三条线，希望把群体智能的涌现这件事讲清楚、讲透彻；用物理学、数理逻辑、多主体建模、计算传播等多学科视角，去追问同一个核心：集群何以比个体更聪明？群体智能又在何时涌现？\n集智俱乐部联合北京师范大学系统科学学院韩战钢教授、暨南大学计算传播研究中心赵甜芳副教授、新疆大学物理科学与技术学院玉素甫·艾比布拉副教授等来自11所高校的学者，共同发起本次「群体智能」读书会，尝试用一条普适的线索，把自然界的鸟群蚁群、人类社会的集群行为、以及人工智能时代的多智能体与群智优化，放在同一张地图上重新理解。读书会自2026年1月17日开始，安排在每周六下午 14:00–16:00，欢迎所有对群体智能如何涌现、如何被理解、以及如何被设计，感兴趣的朋友一起加入：带着问题来，带着更有趣的问题去。\n（扫码报名）\n蚂蚁群体能把钢琴搬运几何难题解决掉，而人类会出现三个和尚没水喝的尴尬处境——这不是搞笑段子，而是一篇发表在PNAS的跨物种对照实验结论：单个蚂蚁不理解全局，却能通过局部信息的互动产生短期集体记忆，让集群表现随规模提升而变强，涌现出群体智能；人类个体更聪明，但集群协作高度依赖沟通，一旦规模太大，就会被低效沟通拖累。\n难道是人类智慧不如蚂蚁？\n当然不是。真正的分水岭不在于个体的大脑有多聪明，而在于集群如何涌现出智能。亚里士多德曾说过整体大于部分之和；安德森用一句More is Different概括涌现——规模足够大、系统内存在非线性相互作用，会涌现无法在个体层面出现的新规律；图灵也提醒过我们：世界的智慧常常不在个体，而在规则与连接；2024年诺贝尔物理学奖授予Hopfield与Hinton，表彰他们在人工神经网络方面的奠基性工作——神经网络的本质，恰恰就是许多简单单元在相互作用中形成整体能力的集群计算，正如Hopfield所说：\n“Computational properties\nemerge\nas\ncollective phenomena\nof large systems with\nsimple components\n.”\n所以蚂蚁并不是更有智慧，它只是更擅长把简单规则叠加成可扩展的协作；人类也不是不擅长协作，而是我们的集群性能更取决于沟通机制与组织结构——连接模式合适，一群个体才会真正变成一个系统。\n如果你对这些反直觉但极有用的现象感兴趣——从蚁群搭桥、鱼群同步、到无人机集群表演、集群机器人协作、群智优化与多智能体系统、网络舆论建模研究等——欢迎加入「群体智能」读书会：我们用\n动物—人类—机器\n三条线，希望把群体智能的涌现这件事讲清楚、讲透彻；用物理学、数理逻辑、多主体建模、计算传播等多学科视角，去追问同一个核心：\n集群何以比个体更聪明？群体智能又在何时涌现？\n集智俱乐部联合\n北京师范大学系统科学学院韩战钢教授\n、\n暨南大学计算传播研究中心赵甜芳副教授\n、\n新疆大学物理科学与技术学院玉素甫·艾比布拉副教授\n等来自11所高校的学者，共同发起本次「群体智能」读书会，尝试用一条普适的线索，把自然界的鸟群蚁群、人类社会的集群行为、以及人工智能时代的多智能体与群智优化，放在同一张地图上重新理解。\n读书会自\n2026年1月17日\n开始，安排在\n每周六下午\n14\n:00–\n16\n:00\n，欢迎所有对群体智能如何涌现、如何被理解、以及如何被设计，感兴趣的朋友一起加入：带着问题来，带着更有趣的问题去。\n读书会背景\n群体智能，无论在自然系统、生物系统、人工系统还是社会系统中，总是反复出现：集群在信息汇聚、协同决策与环境适应上的能力，常常能在某些条件下优于个体，它既存在于鸟群、蚁群、蜂群等生物系统，也正在快速渗透到人类社会与人工智能的多种场景之中。\n但这也带来一组更本质、更值得追问的问题：\n鸟群齐飞\n、\n蚁群筑巢\n的\n自然智慧\n，如何被“\n翻译\n”成\n无人机集群\n、\n智能电网\n的\n人工系统\n？\n既能抱团攻坚复杂任务，又能自适应感知环境，\n智能集群算法\n的玄机何在？\n为何\n集群近临界态\n被认为是系统稳定性与适应性的关键？如何\n识别\n这种特殊的状态？\n集群临界态\n与\n哥德尔不完备定理\n背后的\n数理逻辑\n，如何为\n集群研究\n打开\n新视角\n？\n当成千上万的智能体需要协同工作，“\n大规模群智优化\n”如何避免各自为战？\n多任务并行\n处理已成常态，“\n分布式群智优化\n”如何让不同智能体各尽其责？\n“\n昂贵优化\n”中的昂贵到底指什么？如何\n突破\n这种昂贵限制？\n群智进化优化\n与\n个体强化学习\n，如何合作攻克“\n复杂路径优化\n”难题？\n网络传播\n的\n集群演化\n与\n调优\n，能否帮助我们更好地\n控制信息扩散\n、\n遏制谣言传播\n？\n统计物理\n、\n系统科学\n、\n人工智能\n的\n跨界合作\n，为\n群体智能\n研究带来哪些惊喜？\n正是在这样的背景下，我们发起本次「\n群体智能\n」读书会：希望汇聚\n物理学\n、\n数学\n、\n系统科学\n、\n计算机科学\n与\n社会科学\n等多元视角，围绕\n群体智能\n的\n机制\n、\n模型\n、\n理论\n与\n应用\n展开\n跨学科讨论\n。读书会将按研究主体贯通\n动物—人类—机器\n三条主线，并结合\n物理学\n、\n多主体建模\n、\n计算传播学\n等方法论视角，形成一套更可对话的共同语言。\n本次读书会以“\n局部规则到群体智能\n”为主线，围绕\n群体智能\n的\n理论\n、\n算法\n两大核心板块展开研讨：\n其一是理论板块，以\n生物集群\n实验数据为基础，结合\n机器人集群\n与\n多智能体系统\n的\n涌现\n行为，整合\n临界态识别\n、\n统计物理建模\n与\n广义哥德尔不完备定理\n等数理逻辑相关成果，从复杂系统科学与物理双重视角，审视\n临界性\n、\n复杂性\n与\n群体智能\n三者的内在关联；\n其二是\n算法\n板块，集中分享\n高维优化\n、\n分布式协同\n、\n多任务学习\n、\n昂贵演化问题\n的前沿群体智能算法，并针对\n复杂路径优化\n、\n复杂网络传播治理\n、\n残片复原\n等实际\nNP难\n问题开展算法攻关，实现技术突破。\n你将收获\n前沿视野：\n系统把握自然与人工集群系统、临界性假说、集群机器人与群智优化的整体脉络，梳理从生物集群到工程系统再到数理逻辑的跨学科发展线索。\n理论工具：\n了解多智能体模型、Master方程、临界性指标、机器学习识别相变方法，范畴论和广义哥德尔不完备定理，以及群体智能与演化算法在高维、分布式、多任务和昂贵优化中的关键技术框架，为后续研究打下可直接调用的工具箱基础。\n实践认知：\n通过鱼群、蚁群、鸡群、机器人集群、网络传播和碎片复原等具体案例，看到模型和算法如何落地到真实系统中，理解涌现机制–控制策略–工程实现之间的闭环关系。\n思维破圈：\n打破对集群系统、临界性和数理逻辑的过于抽象滤镜，从同一套概念体系出发，同时审视自然行为、工程设计和智能算法，形成跨物理–计算–逻辑的综合思考方式。\n同好联结：\n在读书会中结识关注群体智能、演化优化、网络传播与复杂系统的伙伴，交流各自领域中的问题与模型，碰撞出新的合作方向与研究灵感。\n认知升级与方向启发：\n无论是规划个人课题、重构知识体系，还是寻找新问题入口，都有机会从本次读书会中获得新的概念坐标与方法论支点，为后续在多智能体系统、群智优化或复杂系统理论上的深入探索提供助推。\n运行模式\n群体智能读书会 · 2026季\n开营：2026.1.17 下午2:00-4:00\n形式：每周六下午，11讲+1圆桌 | 线上腾讯会议+北京集智谷线下场\n权益：专属群交流 + 视频回放\n行动：扫码报名，锁定席位\n（扫码报名）\n读书会内容详情\n（群体智能读书会内容导图）\n1月17日 第一期：从自然到人工集群系统的实验、模型\n与\n应用\n主讲人\n韩战钢，北京师范大学系统科学学院二级教授，校系统分析与集成实验室主任，国务院学位委员会系统科学评议组成员，联合国教科文组织复杂系统数字校园副主席，兼任多个学术团体理事。\n他长期致力于系统科学的基础理论研究，建立了演化算法收敛复杂性理论，系统地研究自然与人工集群系统，生物集群行为的现象和对称破缺机制，机器人集群的自组织协同，以及多智能体在其他领域的应用。\n他的研究得到多项国家自然科学基金项目、科技部重大专项和企事业单位支持，研究成果得到同行高度评价。\n研究方向：复杂系统理论，信息的功能性应用，基于 agent 建模，信息网络，遗传算法，蚁群，鱼群，机器人群体实验。\n个人主页：https://sss.bnu.edu.cn/t/~zhan。\n内容简介\n本期读书会立足于\n系统科学\n中“自底向上”的建模范式，旨在探讨\n复杂系统\n中微观个体交互与宏观\n涌现\n现象之间的内在联系。我们将首先聚焦于生物集群行为，结合蚁群与鱼群的实证实验数据，分析生物个体如何通过简单的局部规则与环境适应性，涌现出\n复杂\n的群体智能。\n在此基础上，通过引入 Boids、Vicsek 等经典\n多主体模型\n以及基于概率的 Master 方程，深入剖析支撑集群行为的底层动力学\n机制\n，并利用统计物理学中的\n相变\n与临界态理论，对系统在从无序到有序演化过程中的整体状态进行严谨的定量分析。\n进而，读书会将从自然界的演化\n机制\n延伸至人工\n系统\n的工程实践，重点阐述机器人集群领域的研究进展与相关关键技术。我们将探讨如何将生物界中发现的\n自组织\n协同\n机制\n转化为可计算的控制算法，使大规模机器人群体在无中心控制的情况下实现高效的分工、协作与环境适应。通过对机器人集群综述及具体研究工作的剖析，展示多主体建模理论在构建具有高\n鲁棒性\n与智能化的机器\n系统\n中的核心应用价值，从而揭示从生物本能到机器智能的跨学科演化\n路径\n。\n1月24日 第二期：社会性生物集群的互动规律研究\n1.《鱼群动态互动规律研究：从个体行为到群体协同的涌现机制》\n主讲人\n薛婷婷，昆明理工大学理学院系统科学系讲师，硕士生导师，2024年毕业于北京师范大学系统科学学院并获博士学位。主要从事生物集群行为社会互动机制的研究，聚焦鸟群、鱼群等集群系统的动力学规律，融合实验模型构建、多尺度数据分析与机器学习方法，揭示集群涌现、自适应调控及环境响应的核心机制。在Physical Review Research、Machine Learning: Science and Technology、PLOS Computational Biology等期刊发表多篇论文，主持数学建模与机器学习交叉项目、高校人培项目。\n报告简介\n近年来，生物集群行为是复杂系统研究的重要方向，其在多生命尺度中展现的自组织、自适应群体协同特性，既是理解生命系统宏观功能的关键，也为人工智能等领域提供重要生物启发，对揭示非线性系统涌现规律具有重要科学意义。在集群行为的调控要素中，社会互动是连接个体行为与群体动态的核心纽带——它决定个体对环境信息的整合、对邻居行为的响应，直接塑造群体空间分布、运动同步性及信息传递效率等。\n然而，传统研究难以量化多因素交叉下社会互动的动态变化，导致 “微观互动 - 宏观涌现” 的认知存在断层，厘清其调控规律成为领域核心突破点。本报告以鱼类集群为载体，结合实验观测与数据驱动建模，阐述环境因子、物种感知差异、异质性个体对社会互动的调控机制，解析相互作用函数以建立社会互动与集群涌现的定量关联，为理解集群协同本质提供支撑，同时为集群智能、生物行为调控等领域提供新思路。\n2.《社会性昆虫的集体响应与状态切换：蚁群行为的实验与理论框架》\n主讲人\n张一帆，北京师范大学系统科学学院在读博士生。主要从事生物集群系统的涌现特征与动力学机理研究。研究重点包括蚁群在刺激环境下的自组织状态切换、个体间信息传递的相关性，以及微观行为如何驱动群体层面的协调模式。\n报告简介\n群体行为作为复杂系统研究的重要前沿，在社会性昆虫中展现出高度协调、适应性强的集体智能。以蚂蚁为代表的生物群体利用简单规则、局部交互与信息整合实现了远超个体能力的涌现行为。探究蚁群在动态环境与外部扰动下的集体响应规律，为理解群体决策、协作控制和集群职能系统提供了关键启示。\n本课题组通过设计可控的外部刺激，结合轨迹提取与多个体交互分析，构建Master方程和多主体模型，系统研究蚂蚁在外界扰动下从个体到群体的响应机制以及状态切换条件。本报告从文献前沿到自主实验，展示蚁群行为研究的发展脉络、关键机制与新的科学问题，并探讨其对复杂系统与群体智能研究的启示。研究为理解蚁群在刺激情境下的集体响应规律提供新的实证证据，也为构建多智能体系统的协同机制模型提供新视角。\n1月31日 第三期：\n智能集群协同与对抗研究\n1.《\n集群系统及行为动力学机理研究\n》\n主讲人\n于沛志，北京师范大学系统科学学院在读博士生。主要从事集群系统及行为动力学机理研究。研究重点包括集群追逃行为博弈，集群系统异质性与自组织状态转换、集群系统多尺度表征等。\n报告简介\n近年来，从局部规则出发刻画群体智能的生成机制，已成为复杂系统与计算智能领域的热点方向。Reynolds 的 Boids 三规则、Vicsek 自驱动粒子模型、Couzin 感知区域模型以及 Helbing 社会力模型等经典工作表明：个体只需依托邻域感知与简单互动，即可自发形成队列、环行、聚散等多样的时空有序结构。它们从几何邻域、速度对齐和社会力等不同视角，为理解群体协同行为提供了基础范式，但在处理个体异质性、环境信息场和演化过程等方面仍存在局限。\n本报告将以这些经典集群模型为起点，介绍本课题组在多智能体集群建模方面的进展：一方面通过 Master 方程与 Agent-based 模型相结合，在微观决策—宏观统计之间建立联系；另一方面构建基于信息素场的蚁群模型和数据驱动的鱼群 burst-and-coast 模型，揭示个体社会相互作用、环境约束与群体模式转换之间的定量关系。报告旨在从经典模型过渡到改进的模型，展示在保持局部规则简洁性的同时如何提升对真实生物集群与工程集群系统的解释与预测能力。\n2.《集群机器人行为涌现及协同对抗研究》\n主讲人\n郑雅婷，柏林洪堡大学博士后研究员，并加入智能科学集群研究团队。研究方向主要聚焦于群体机器人的协同合作机制，目前涉及仿生集群运动控制、协同构建技术以及真实群体机器人系统中的主动弹性模型控制，曾基于E-puck、Stigmergic积木系统及BuilderBot机器人平台开展研究。2022年1月获得北京师范大学博士学位，并于2018年9月至2020年12月期间在比利时布鲁塞尔自由大学进行联合培养，师从Michael Allwright博士后研究员与Marco Dorigo教授。作为SCIoI项目B3的集成方向博士后，当前正基于Thymio机器人集群开展研究，致力于将不同集体行为整合为群体引导行为。\n报告简介\n自然界中存在各种令人震撼的生物集群行为。揭示和归纳各类生物涌现行为的普适规律是当今复杂系统领域研究热点之一。受到生物集群智能启发，集群机器人系统旨在设计和建立由大量简单机器人组成的协同合作系统，通过机器人之间以及机器人与环境之间相互作用，在宏观层面自组织涌现出个体层面不存在的集群智能。\n与简单个体机器人相比，集群机器人系统具有更好的灵活性、容错性、可扩展性以及稳定性。科学家发现通过建立理想化的生物集群模型，将运动个体抽象为质点，设计局部相互作用规则，在计算机仿真中可以模拟和预测复杂的生物集群行为。然而，理想化的生物集群模型往往不能直接应用于实际的集群机器人系统。\n一方面，生物集群模型存在着不可忽略的理想化假设：个体对局域邻居无偏好选择、个体速度大小固定和无边界限制等；另一方面，集群机器人系统自身也面临着各种问题与挑战：计算复杂度高、通信和定位技术限制以及难以建立可重复操作的实验平台等，使得当前只有少数实验成功地实现大规模集群机器人的自组织涌现行为或者协同合作完成特定场景的任务。\n根据上述理想化生物集群模型和实际集群机器人系统面临的问题与挑战，本报告以生物集群模型为切入点，多种集群机器人系统为实际应用场景，详细讲解如何在集群机器人系统实现类似生物集群行为的一致、旋转等涌现行为，以及如何在多种混合集群机器人上实现集群协同和对抗。\n2月7日 第四期：集群的近临界态假说与识别研究\n1.《临界性假说 —— 跨尺度生物集群系统的普适性法则》\n主讲人\n林国政，北京交通大学系统科学学院讲师，硕士生导师，2024年毕业于北京师范大学系统科学学院。主要从事各类复杂系统涌现特征与机理的研究，包括鱼群、蚁群生物集群系统、多智能体系统、交通系统等。在Physical Review Letters、PRX Life、PLoS Computational Biology等期刊上发表论文10余篇，主持中央高校基本科研业务费、中国博士后科学基金面上项目、国家自然科学专项项目子项目。\n报告简介\n近年来随着人工智能领域各种颠覆性技术的不断涌现，群体智能也越来越受到人们的关注。群体智能通过研究自然界中分散、自组织的生物集群系统（如鸟群、鱼群），实现分布式、去中心化的智能行为。跨尺度的生物集群的共性是在环境刺激或扰动下能够展现出快速响应、动态协同的能力，这种能力或许与统计物理学中的“临界态”相关。\n近几年一些最新的实验证据支持了“临界性假说”，认为生物集群让自身处于或接近临界状态，从而获得对环境扰动的最大敏感性。临界性假说的重要性在于，它不仅适用于鱼群、鸟群、人群等宏观尺度集群，而且能解释大脑神经元、微生物、细胞等微观尺度集群对环境刺激的响应能力，即“运行在临界状态”可能是跨尺度集群系统适应环境的普适性策略。\n本期读书会将介绍临界性假说的主要内容，总结国内外以及本人在临界性相关研究的前沿进展，并给出临界性原理在集群机器人、智能涌现、生态环保等领域可能的应用方向。\n2.《基于人工智能的集群近临界态识别》\n主讲人\n吴天毅，北京师范大学系统科学学院在读博士生。主要从事集群系统临界态识别与调控研究，聚焦集群临界态理论，致力于建立基于观测数据的生物与人工集群临界态识别方法，探索引导集群演化至临界态的调控机制，揭示临界动力学行为在追逃博弈等功能性场景中的涌现优势与应用潜力。\n报告简介\n长期以来，科学界普遍认为生物集群系统之所以能够涌现出高度的群体智能，在复杂环境实现高效协同，关键在其处于有序与无序的边界，即“临界态”或“混沌边缘”。这一“临界态假说”为理解跨尺度系统的自组织机制提供了统一框架。\n然而，在实际研究与应用中，往往难以识别一个系统是否处于临界态。传统方法通常依赖于对系统全局状态的大量观测以计算序参量或关联长度，或需人工结合先验知识进行建模。这种对全局全量数据和先验知识的依赖，极大地限制了其在许多观测受限或机制未知的真实复杂系统中的应用。\n随近年来人工智能技术的飞速发展，数据驱动的方法有望为这一难题提供解决方案。本报告将首先简要回顾集群运动的临界态假说及其物理意义，随后总结近年来国内外及本人在将人工智能应用于集群临界态识别方面的最新进展，并展望相应技术在集群机器人设计、生物群体行为分析等领域的潜在应用方向。\n2月14日 第五期：\n广义哥德尔不完备定理\n与集群临界态\n的数理逻辑刻画\n主讲人\n马治峰，北京师范大学系统科学学院在读硕士。主要从事范畴逻辑与集群临界态的数理逻辑刻画研究，研究工作跳出了传统的动力学模拟框架，转而从元数学的角度，探索复杂性涌现的逻辑本源。研究重点包括广义哥德尔不完备定理、范畴论解释器视角下的复杂性度量，以及利用哥德尔不完备空间刻画临界态、超验证明等。\n报告简介\n本期读书会将展示如何将经典的哥德尔不完备定理推广到广义框架（GGIC），并揭示其与复杂系统临界态之间的深刻联系。核心内容包括：\n广义哥德尔不完备定理的建立\n从传统的语法-语义对偶出发，构建维度化的不完备空间理论\n提出不完备空间维度公式\n揭示这一框架在物理系统、计算理论和人工智能中的普适性\n集群临界态的逻辑本质\n证明临界态在数学上等价于\"不完备空间\"\n建立相变对称性破缺与逻辑公理之间的对应关系\n以捕食-被捕食模型为例，展示临界态参数的逻辑推导\n跨学科应用的突破\n复杂系统：为临界现象提供可计算的逻辑参数\n人工智能：阐述强人工智能与不完备性理解的本质关联\n报告亮点：\n首次建立哥德尔不完备性与复杂系统临界态的严格数学联系\n提出\"逻辑临界性\"的新概念，为多学科交叉研究提供统一框架\n展示如何用数理逻辑工具量化描述传统上只能定性讨论的临界现象\n适合听众：\n复杂系统、人工智能、理论计算机科学研究者\n对数理逻辑与自然科学交叉感兴趣的学生学者\n希望了解前沿跨学科研究方法的科研人员\n本报告将展现数学基础理论如何为复杂系统研究提供全新的分析工具和理论视角，推动我们对\"复杂性\"本质的理解。\n2月28日 第六期：基于统计物理与鸡群行为启发的复杂网络连通支配集模型研究\n主讲人\n玉素甫·艾比布拉，博士，现任新疆大学物理科学与技术学院副教授。2015年毕业于中国科学院理论物理研究所，获理论物理博士学位，同年9月入职新疆大学开展教学与科研工作。\n长期致力于统计物理与复杂系统领域研究，在《Journal of Statistical Mechanics》和《Journal of Statistical Physics》等统计物理权威国际期刊发表论文6篇，研究成果聚焦复杂网络优化问题（如支配集、连通支配集）的统计物理建模，熟练运用自旋玻璃理论、和渗流理论等方法开展理论推导与算法优化。\n近年将研究视角拓展至动物群体行为领域，通过观察生态养鸡过程中的群体自组织现象，探索从中提炼复杂系统的普适性规律与物理建模思想，力求实现物理理论与实际应用的跨学科融合，为复杂系统研究及生态养殖技术优化提供创新思路。\n报告简介\n最小支配集（MDS）作为复杂网络优化中的经典问题，其核心约束可通过统计物理局域相互作用模型精准刻画。我们采用自旋玻璃理论为框架的统计物理BPD算法，还有核渗流理论和全域掐叶算法，实现了对MDS最优基态能量的精准预言，模型计算结果与理论最优解高度契合。然而，在拓展至连通支配集（MCDS）研究时，传统局域相互作用模型因难以精准表达连通性全局约束，导致预测结果与基态能量存在显著偏差，这一矛盾揭示了全局拓扑约束与局域物理建模之间的本质冲突。\n为突破这一理论瓶颈，我们开始关注动物群体行为研究视角，基于两年生态散养鸡群的系统观察，挖掘鸡群自组织行为中的涌现性规律。我们发现，鸡群在觅食、避险及夜栖等场景中，会自发形成兼具“覆盖性”与“连通性”的动态群体结构：个体通过局部信息交互（如视觉识别、声音通讯）实现群体范围的资源覆盖，同时维持群体连通以保障信息传递与集体防御，这一特征与MCDS的“支配+连通”双重约束高度契合。\n我们进一步将鸡群行为机制转化为统计物理模型的优化策略，通过引入“动态交互权重”与“群体连通性惩罚项”，改进传统局域能量函数，实现对全局连通约束的有效刻画。该模型不仅为解决复杂网络MCDS问题提供了新的物理建模思路，更直接为规模化生态散养鸡群管理提供技术支撑——基于模型优化的鸡群分布调控方案，可实现养殖区域的资源高效利用与鸡群行为稳定性的动态平衡，为高福利生态养鸡模式的标准化推广奠定理论与实践基础。\n3月7日 第\n七\n期：大规模群智协同优化\n算法研究\n主讲人\n杨强，南京信息工程大学副教授（校聘教授），南京信息工程大学龙山学者，硕士生导师；分别于2014年和2019年在中山大学信息科学与工程学院和数据科学与计算机学院获得硕士和博士学位；主要从事计算智能算法及其应用研究，累计发表学术论文100余篇，其中在人工智能领域的国际顶级期刊IEEE Transactions系列期刊发表论文10余篇，累计Google Scholar引用3200余次，1篇论文入选ESI高被引论文，1篇论文获评IEEE SMC2022（CCF C类会议）最佳学生论文提名奖，1篇论文获评IEEE ICACI2023（计算智能领域旗舰会议）最佳论文奖；1篇论文获评IEEE MiTA2024（计算智能领域旗舰会议）最佳论文奖；授权发明专利15项；2020年入选江苏省双创博士计划，2022年获评校五四青年奖章，2023年获评校首批十大青年科技之星，2024年入选江苏省第七期“333工程”第三层次人才计划，主持国家自然科学基金项目2项，江苏省自然科学基金项目1项，江苏省高等学校自然科学基金面上项目1项。\n报告简介\n高维度大规模优化问题在日常生活和工业生产中日益常见，尤其在当今物联网环境下，优化问题的维度日益增多，变量耦合性日益增强，优化复杂度日益增加，导致传统优化算法无法有效求解。凭借对待解优化问题无任何数学特性要求、全局搜索能力强、内在并行特性等优势，群体智能算法已经成为了求解大规模复杂优化问题的重要途径之一。\n然而高维度环境下，解空间指数式增长，群体协同搜索效率较低；局部最优区域宽且多，群体协同面临局地性；变量紧耦合、解空间高度复杂，群体协同不充分。为有效解决上述问题，项目团队围绕大规模高维度环境下的群体协同交互的高效性和有效性问题，分别提出了支配式群体交互框架，增加群体交互的导向性，提升群体协同搜索的收敛性；提出了邻域式群体交互框架，增加群体交互的多向性，提升群体协同搜索的多样性；提出了差异式群体交互框架，增加群体交互的异向性，提升群体协同搜索的广面性。\n依托上述框架，群体智能算法求解大规模复杂优化问题的性能得到了极大提升。本报告将详细介绍上述框架，以期让读者了解提升大规模场景下群体协同交互有效性的方法，从而启发读者开展深入研究，促进大规模群体智能算法的研究进展。\n3月14日 第\n八\n期：分布式\n与多任务群智优化\n算法研究\n1.《分布式群智协同优化》\n主讲人\n魏凤凤，华南理工大学计算机科学与工程学院助理教授，硕士生导师，主要研究方向是群体智能、进化计算、分布式优化、数据驱动优化、智能体与多智能体系统，已发表国际期刊和国际会议论文50余篇，其中IEEE Trans.长文15篇；主持国家自然科学基金青年科学基金项目、中国博士后科学基金面上项目、广东省自然科学基金面上项目等；获广东省人工智能产业协会科学技术奖自然科学奖一等奖、第四届国际分布式人工智能会议最佳论文、中国仿真学会智能优化与调度专委优博、ACM广州分会优博；现任中国计算机学会协同计算专业委员会委员。\n报告简介\n群体智能是汇聚群体智慧协同求解复杂问题的方法，是《新一代人工智能发展规划》明确的重要发展方向，在智能交通、智慧物流等领域得到广泛应用。随着超算、边缘计算等技术的快速发展，传统群体智能方法面临着个体目标难评估、全局信息难汇集、群体协作难拓展的挑战，本报告以分布式数据驱动的群体智能为主题，介绍如何有效利用数据，激发分布式环境下更高效的群智涌现，通过多代理模型协同驱动、按需评估的分布式联邦优化、网络化多智能体协同优化等技术，提高群体智能算法的鲁棒性、高效性、可扩展性；并探索基于智能体的数据驱动群体智能方法，利用大模型提升个体环境感知、任务理解、策略生成能力和群体分布式协作的能力。\n2.《多任务群智优化：基于演化迁移学习的算法设计》\n主讲人\n王子佳，男，博士，广州大学计算机科学与网络工程学院副教授，硕士生导师。主要研究方向：计算智能、群体智能、机器学习。2015年本科毕业于中山大学自动化系，获工学学士学位，2020年直博毕业于中山大学计算机系，获工学博士学位；毕业后至2021年7月在腾讯科技（深圳）有限公司担任高级算法研究员；2021年8月以百人计划青年学者身份进入广州大学任副教授，现在是学院青年干部储备人才。2023-2024年度广州大学“最受学生欢迎的教师”。目前主持国家自然科学基金青年基金项目一项、广东省自然科学基金面上项目三项、广州市基础研究计划市校（院）联合资助项目一项、广州市基础与应用基础研究项目一项。累计发表论文40余篇，其中中科院JCR一区和IEEE Transactions论文20余篇，包括8篇IEEE Transactions on Cybernetics（IEEE TCYB，IF=10.5）、4篇IEEE Transactions on Evolutionary Computation（IEEE TEVC，IF=12.0），5篇入选ESI高被引论文，4篇论文被列入ESI研究前沿。现已荣获吴文俊人工智能优秀博士学位论文奖（全国9人）、ACM广州分会新星奖（广东省3人）、ACM广州分会优秀博士学位论文奖（广东省2人）、广东省计算机科学青年学术秀一等奖（广东省3人）。担任IEEETCYB、IEEE TEVC、IEEE TNNLS、IEEE TSMC、IEEE TIFS、IEEE TETCI等多本顶级刊物的审稿人。现任IEEE高级会员、CCF高级会员、中国计算机学会协同计算专业委员会委员、中国自动化学会粒计算及其应用专业委员会委员、中国仿真学会智能仿真优化与调度专业委员会委员、中国图学学会图学大数据专业委员会委员、广东省计算机学会大数据专业委员会委员。受邀出任亚洲人工智能技术大会（ACAIT 2023/2024/2025）和国际机器智能与应用大会（MiTA2024）的Session Chair，担任国际期刊《Complex System Modeling and Simulation》、《CAAI Transactions on Intelligence Technology》的青年编委，并荣获国际期刊《Human-Centric Intelligent Systems》的杰出审稿人奖。\n报告简介\n多任务优化（EMTO）是一种群体智能算法领域新涌现出的一种问题范式，通过利用多个优化任务之间的共享知识来同时解决这些任务。目前，多任务优化已广泛应用与工程设计、机器学习和资源分配等众多实际领域。与传统的单任务算法不同，多任务优化中的一个任务的解决方案可以为相关任务提供信息或改进解决方案，从而加速收敛并提高整体性能。因此，不同任务之间的知识转移对于促进任务的优化至关重要。  而实现高效的知识迁移也是多任务优化领域的研究重点。本期读书会从以下三个方面介绍一些最新的知识迁移技术以及对应的多任务算法。包括：\n1、多层次多段学习:与传统只在对齐维度上的知识迁移不同，该只是迁移技术瞄准相似或相关的维度上进行KT，同时避免处理异构问题时的维度填充带来的冗余信息。\n2、基于神经网络的知识转移：与传统基于个体的表层知识迁移不同，基于神经网络的知识迁移侧重与分析任务的相似性，获得信息预测的转移模型，实现知识的本质迁移。\n3、模糊自适应学习:该知识迁移策略首先设计一个从多方面综合评价知识迁移性能的方案，通过不同方面的迁移性能评估，使用模糊逻辑，实现迁移频率的自适应调整。\n3月21日 第\n九\n期：强化学习路径优化：群体、个体智能协同算法\n主讲人\n贾亚晖，华南理工大学未来技术学院副教授，博导，广东省珠江人才引进团队骨干，IEEE CIS Taskforce on Evolutionary Scheduling and Combinatorial Optimization组长，CCF协同计算专委会委员。曾担任新西兰惠灵顿维多利亚大学博士后研究员。主要研究方向为智能优化算法，包括进化计算、深度强化学习及其在智慧交通和智慧能源方面的应用，在包括IEEE TEVC, TCYB, TNNLS, WCCI等国际著名期刊和重要国际会议发表论文40余篇。担任Journal of Renewable and Sustainable Energy副编辑。\n报告简介\n路径优化问题是一类典型的组合优化问题，例如旅行商问题，车辆路径问题，机器人任务分配与调度问题，在现实生活中拥有很多典型的应用，例如外卖派送、物流规划、垃圾回收等。计算智能方法，特别是基于群体智能的进化计算方法和基于个体智能的强化学习方法，目前已经成为解决此类问题的主流。本期读书会将探讨两种不同的计算智能方法在求解路径优化问题时的优劣势，相关算法的设计思路，以及主要关注的科学问题。最后探讨两种方法相结合的可能性。\n3月28日 第\n十\n期：昂贵演化与协同优化前沿\n1.《昂贵演化优化：前沿与方法》\n主讲人\n黎建宇，南开大学人工智能学院引进教师，入选人工智能领域全球前2%顶尖科学家，CAAI优秀博士论文激励计划提名，南开大学人工智能学科振兴计划；主持国自然青年、天津市青年项目B类等项目多项；主要研究方向是人工智能、进化计算、群体智能和大模型，目前已发表学术论文50余篇，包括IEEE Transactions系列的国际高水平学术期刊论文20篇，ESI高被引论文3篇，《计算机学报》等中文核心期刊论文3篇；谷歌学术引用2000余次，H-index为21；获机器智能期刊最高被引论文奖，CAAI会刊《智能系统学报》优秀论文奖；授权国际发明专利1项。\n研究成果得到了国际同行的正面评价和应用推广。被包括美国科学促进会会士、欧洲科学院院士、加拿大皇家科学院院士等多国/地区院士、多位IEEE Transactions系列期刊的创始主编及现任主编、IEEE Fellow等著名学者评价为“首创（for the first time）”、“优秀的成果（excellent results）”、“更高效（more efficiently）”和“新兴的课题（emerging topic）”等；被YouTube（AI Trends）、Twitter（MIR_Journal）、腾讯新闻（智能科学汇）等媒体平台作为头条进行宣传和报道；被国内外学者广泛应用于芯片设计、生物医学和物流运输等众多领域的优化问题中，推动相关领域的发展。\n报告简介\n在“人工智能+”时代，最优化与智能化已成为推动人类社会进步、发展新质生产力的关键力量，更是人工智能迈向更高层次的必然趋势。随着物联网、云计算、大模型、5G和区块链等前沿技术的蓬勃发展，众多优化问题愈发复杂，呈现出大规模、高动态、多峰值、强约束、多目标以及计算成本高昂等多重挑战，这对传统优化算法提出了前所未有的难题。\n进化计算与群体智能作为模拟自然界生物进化和群体动物智能行为的先进人工智能算法，凭借其行为的可观察、可感知、可认识、可解释和可调控等独特优势，近年来在知识发现、搜索优化和问题求解等领域得到了广泛应用。然而，面对候选方案评估成本高昂的复杂优化问题，传统进化计算方法在计算效率上仍显不足。\n本期读书会将介绍近年来昂贵演化优化方向上的创新成果，这些方法为应对现代超复杂优化问题提供了全新的思路和高效途径，为人工智能领域迈向新的发展阶段起到了推动作用。\n2.《残片复原新路径：一种协同进化优化框架》\n主讲人\n张鑫源，暨南大学智能科学与工程学院，党总支委员，人工智能系主任，硕士生导师，中国计算机学会协同计算专委，珠海计算机学会理事，广东崃智科技有限公司技术总监。主持国家自然科学基金金青年项目，广东省“双创”党建项目。曾在IEEE TEVC，TCSVT，GECCO等国际期刊和会议发表论文20余篇。担任多个国际顶级期刊审稿人。\n报告简介\n残片复原问题旨在从碎片中复原出原始物体。传统的手工复原技术严重依赖专家知识，且可能会对易碎碎片造成损坏，因此有必要开发自动化复原方法。随着碎片数量的增加，当前的复原算法常常遭遇“维度灾难”，算法的准确性和效率均会受到影响。同时，这些算法主要依赖碎片内容，导致其适用性和可扩展性受限。为应对上述挑战，我们提出了基于协同进化优化框架的新型复原方法。该方法既涵盖了残片复原问题的形式化表达，也包含了为解决该问题而开发的定制算法。\n值得注意的是，我们的建模方法与碎片内容无关，仅依赖碎片的边缘形状。基于此种建模方法，解决方案本身就代表了碎片的重建过程。为高效编码候选解，我们采用了树形结构。这种编码方案使得传统的协同进化流程和遗传算法算子（如交叉和变异）不再适用。\n因此，我们专门针对复原任务提出了一种树形结构的协同进化算法。我们的目标是克服当前复原算法的局限性，构建更准确、高效的复原方法。为评估所提方法的有效性，我们进行了一系列综合实验。实验结果表明，我们提出的方法在解的质量、收敛速度和鲁棒性方面均取得了令人满意的效果。\n4月11日 第十\n一\n期：网络传播建模\n与优化\n研究\n1.《多因耦合的网络传播演化建模与优化分析》\n主讲人\n年福忠，兰州理工大学人工智能研究院院长，二级教授、博导，甘肃省领军人才。博士毕业于大连理工大学，曾任清华大学访问学者（中组部“西部之光”），现为复杂系统智能信息处理团队负责人，入选“陇原青年创新人才扶持计划”等人才计划，兼任中国自动化学会计算社会与社会智能专委会常委，中国医学装备协会医疗器械创新与应用分会常委等。研究成果获甘肃省自然科学二等奖（排名第1），甘肃省高校科技进步一等奖（排名第1），甘肃省高校科研优秀成果二等奖（排名第1），甘肃省教育厅教学成果奖，辽宁省自然科学三等奖等多项奖励。近年来，在以第一作者或通信作者身份在IEEE Trans. NSE、IEEE Trans. CSS等SCI期刊上发表论文100余篇，出版专著1部，教材2部。近年来主持完成包括国家自然基金项目（3项）在内的各类科研项目20余项，其中由其主持研发的多导经络智能检测仪，获国家医疗器械注册证，同时获得1000万元风投基金，产品已在北京护国寺中医医院等多家医院临床应用。相关工作被新华社专访，新浪、凤凰网等国内主流媒体转载。\n报告简介\n个体因素、群体因素、信息量、网络拓扑、传播模式等因素都会对传播产生影响，为此，我们多角度研究了网络信息、新冠疫情等真实案例在不同情况下的演化规律与传播特征，并为之建模与优化，揭示其背后的机制与规律，进而找到相应的控制策略。\n2.《\n面向\n网络传播优化\n的\n分治型\n群体智能\n方法》\n主讲人\n赵甜芳，暨南大学计算传播研究中心特聘研究员，广东省科技创新青年拔尖人才（省部级），广州市网络舆情分级与判定标准起草专家。研究领域包括智能传播、分治型群智优化。累计发表IEEE TCYB/TKDE/TSMC/TNSE/TCSS等在内的期刊及会议论文30余篇，其中包括近10篇顶刊论文。主持国家自然科学基金青年项目一项、省部级项目三项。现为中国计算机学会协同计算专委会执行委员、中国中文信息学会SMP专委会委员，国际期刊Journal of Social Computing青年编委，担任TNNLS/TCSS/TAI/IPM/计算机学报等期刊审稿人。曾获广东省人工智能产业协会科学技术奖自然科学奖一等奖、ACM广州新星奖，近五年指导学生团队获省级以上竞赛奖励30余项，培育成果入选2023年中国计算机学会技术公益案例集。\n报告简介\n在大数据与人工智能时代，社会网络规模空前庞大，催生了复杂的网络传播难题。本项目针对高维复杂、去中心化且动态不确定的大规模网络传播环境，拟研发一套适配多情景的分治型群体智能方法框架。\n具体包括：融合网络拓扑信息与决策空间结构信息的自适应重叠解耦机制，实现群体智能决策空间的有效划分；构建基于非完全信息的分布式自主协同机制，达成去中心化环境下的多种群合作协同演化；针对信息茧房、谣言传播、病毒式传播等网络难题，开展网络传播优化的创新应用。本研究深入探索网络拓扑空间与群体智能决策空间的关联规则，以及群体智能中多种群局部自治与邻域协同的平衡机制，目标是优化正面传播、疏导治理重大突发事件中的负面传播，助力提升网络传播的治理效率与质量。\n第十二期：圆桌讨论（暂定于4月18日举行）\n圆桌讨论将在11期读书会内容结束之后进行。届时，读书会的发起人韩战钢教授，赵甜芳副教授和玉素甫·艾比布拉副教授，将与集智俱乐部创始人张江教授、CEO张倩共同领衔，就本季群体智能读书会中的热点科学话题展开讨论，为读书会收官。\n读书会推荐阅读清单\n扫描下方二维码可跳转至集智斑图网站查看群体智能读书会推荐阅读材料\n群体智能从自然涌现到人机共创读书会推荐阅读清单\n读书会总策划\n张倩，集智学园联合创始人兼CEO，南京信息工程大学人工智能学院（原信息与控制学院）硕士毕业，于2016年接手运营集智俱乐部并创办集智学园，开创了集智课堂共学模式，打造了《巴拉巴西网络科学》、《系统科学前沿》、《复杂性思维》等多期课程，组织编写《深度学习原理与Pytorch实战》、主笔《netlogo多主体建模入门》、翻译《复杂——诞生于秩序与混沌边缘的科学》，倩姐公众号主理人。\n运营负责人\n范瑞骁，北京师范大学系统科学学院硕士研究生，师从北京师范大学系统科学学院韩战钢教授。\n报名参加读书会\n读书会价格：399元\n报名方式\n：\n第一步：微信扫码填写报名信息。\n（扫码报名）\n第二步：填写信息后，付费报名。如需用支付宝支付，请在PC端进入读书会页面报名支付：\n第三步：添加运营助理微信，拉入对应主题的读书会社区（微信群）。\nPS：\n为维护学术交流的专业性与聚焦度，本读书会对讨论内容作如下约定：\n我们鼓励围绕理论生态学及相关具体问题的深入探讨。为保证讨论质量，请避免发表脱离本期读书会主题、缺乏实证基础或过于空泛的哲学思辨类内容。\n若讨论内容明显偏离主题，经主持人提醒后仍未调整，为维护整体学习环境，我们将不得不将该成员请出讨论群，并根据其实际参与进度，对未参与部分按比例办理退费。\n感谢您的理解与配合，让我们共同营造一个专注、深入、有收获的共学空间。\n加入社区可享核心资源\n成为会员即可解锁完整学习生态，包括：线上实时问答、全部课程录播回看、独家资料共享、高质量社群交流、第一手信息同步，以及通过参与共创任务获取积分等权益。\n特色退费与激励机制\n我们提供以下两种途径，让您的投入获得实际回馈：\n任务达标退费路径\n：认领并合格完成任意两期字幕任务，即可退还全额报名费，并额外获得集智专属周边奖励。\n运营成长激励路径\n：合格完成一个字幕任务后，可申请成为运营助理。在读书会项目顺利结项后，将退还学费。表现优异者，还有机会获得额外的奖学金。（详情请见：\n加入集智字幕组：成为复杂科学知识社区的“织网人”\n）\n相关内容推荐：\n从鸟群到大脑：因果涌现能解释什么？ | 科普专访\n细胞世界的“高速细胞世界的“高速公路”：揭秘微小纹路如何让混乱的细胞群自发排队，走向有序公路”：揭秘微小纹路如何让混乱的细胞群自发排队，走向有序\n蚁迹寻踪——20年前的模拟程序重新登上集智百科了！丨集智百科\n强化学习能否提高群体稳定合作的可能性？\n空域的涌现：集群 | 涌现动力学第六课\n萤火虫的同步闪烁：随机中怎样涌现出秩序？\n人潮汹涌化“群旋”？科学家揭秘大型人群的“集群涡旋”之谜\n复杂网络上的自组织与集体行为：从扩散、相变到博弈 | 读书会启动\n羊的物理学——从相变到集体运动\nPRE 速递：水母的群体相干机制\n点击“阅读原文”，报名读书会",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247724470&idx=1&sn=aa364f783565fa889e6cd825106b41ac&chksm=e9990fd578e4c74eeb6bc12dc99c85f6e13a3a9b590240cb177d79ce880b2944d9748128ad89&scene=0&xtrack=1#rd",
      "publish_time": 1766983200,
      "publish_date": "2025-12-29 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://sss.bnu.edu.cn/t/\"]",
      "add_ts": 1767050273,
      "last_modify_ts": 1767193580
    },
    {
      "id": 46,
      "article_id": "51503",
      "title": "金融网络的统计物理学",
      "description": "近日，一篇发表于预印本平台的综述论文《The Physics of Financial Networks》系统梳理了金融网络领域的研究进展。文章从金融网络的不同定义出发，探讨了金融传染机制及其在网络结构推断与验证中的应用，强调利用物理思维建模金融系统的重要性，揭示网络结构对系统性风险传播的影响，为防范金融危机提供了理论支持。",
      "content": "导语\n此篇综述文章，介绍了当前该领域的发展现状，从金融网络的不同定义讲起，接着讨论了金融传染（financial contagion）及其在金融网络推断、校验中的应用。\n张澳\n| 作者\n论文题目：\nThe Physics of Financial Networks\n论文地址：\nhttps://arxiv.org/abs/2103.05623\n当今全球金融市场的总值远远超过实体经济总值，大量金融机构间形成了相互作用的网络，而经典的经济学模型将金融体系描述为单一实体或一群孤立的元素，未能对金融系统所涌现出的不稳定性及其对社会的影响提供适当的描述。而金融网络结合图论、统计物理及金融经济学，对金融系统的复杂性及相互作用进行定量建模以刻画金融风险。\n近日预印本论文网站上传了一篇综述文章，介绍了当前该领域的发展现状，从金融网络的不同定义讲起，接着讨论了金融传染\n（financial contagion）\n及其在金融网络推断、校验中的应用。\n金融系统由金融机构、市场、合同以及监管群体组成，故在金融网络中通常将节点定义为各类金融机构，将边定义为合同关系或其它联系\n（如共同进行投资的关系）\n。具体来说，单层网络中产权关系构成的网络可以最好地反映经济主体与金融机构间的关系，多层网络的每层都对应于一种具体关系以更好地刻画风险传播，基于相关/相似性的网络则被用于金融实体之间间接作用的描述。\n图1. 基于相关/相似性的金融网络的分析过程\n金融传染是金融网络中最常见的模型，针对金融机构间的双边关系。在金融传染的模型中，每个机构都有其资产负债表，表格中的状态随着依机构间关系而定的动力学方程而更新。资产负债表左半边为资产\n（如）\n，右半边为负债\n（如）\n。负债中存在优先级\n（即机构破产时还债的顺序）\n，其中股东权益\n（Equity，即股东对资产清偿所有负债后剩余价值的所有权）\n优先级最低，故它也是机构总值的度量。而资产与负债均可根据其所属市场，分为机构间的\n（interbank）\n及外部的\n（external）\n。具体来说，i 机构的机构间负债为 i 机构对其它机构的债务，i 机构的机构间资产即为其余机构对 i 机构的债务。因此，机构间的资产及债务就是机构在网络中的联系。\n图2. 资产债务表构成的机构间网络及其动力学\n上半部分图展示了由三个由资产负债表而表示的机构组成的机构间网络，资产负债表中资产侧包括外部资产\n（如A，B）以及机构间资产\n（如\nA\n12\n即为机构1对机构2的贷款）而负债侧包含股东权益与机构间负债\n，后者也同样可继续细分。\n下半部分图分别介绍了偿债传染\n（solvency contagion）\n及共同投资\n（overlapping portfolios）\n导致的间接传染。对于前者，某个外源波动导致机构1的外部资产损失（a），并且该损失被股东权益所承担（b）。机构3对机构1有贷款\nL\n13\n，所以会对其机构间资产\nA\n31\n重新估值，一般会对\nA\n31\n乘一个0-1之间的小数（c）。最终，机构3资产的减少也被其股东权益承担，这随后会继续影响对机构3有贷款的其它机构，从而传播风险。\n而对于共同投资导致的间接传染，假设机构1为了其资金杠杆\n（leverage，即为资产与股东权益的比值，对机构的盈亏起到放大作用）\n的目标出售其外部资产A与B（e），根据市场影响函数\n（market impact function）\n：被出售越多的资产贬值越多，这将导致A与B的贬值，从而使得持有A与B的机构1与机构2资产值减少（f）。随后机构2为了减小其资金杠杆出售A和C（g）。持有A与C的机构1、2、3 的资产则由于A、C的贬值而减少（h）。\n系列课程推荐：统计物理基础课程\n集智学园联合上海大学理学院教授、知乎“物理学”话题优秀答主李永乐，共同推出「统计物理基础」系列课程。课程以热力学和经典力学为起点，依次展开 Boltzmann 统计、系综理论、量子统计、相变与非平衡统计等核心内容，围绕一个核心问题展开：大量微观粒子的随机运动如何涌现出稳定的宏观定律？本课程强调物理图像与方法论，帮助你建立清晰的微观—宏观统计思维，掌握处理多粒子系统和复杂随机过程的一套通用工具。\n课程详情可见：\n李永乐的统计物理基础课\n推荐阅读\n1.\nNature综述：金融网络中的物理学\n2.\nNature Reviews Physics长文综述：金融网络的物理学\n3.\n李永乐：统计物理阅读材料推荐\n4.\n系统科学前沿十讲：探究复杂世界演变背后的规则（二）\n5.\n集智学园精品课程免费开放，解锁系统科学与 AI 新世界\n6.\n高考分数只是张入场券，你的科研冒险在这里启航！\n7.\n加入集智字幕组：成为复杂科学知识社区的“织网人”\n点击“阅读原文”，报名课程",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247724470&idx=2&sn=c92f707f907657b1a75fe6be0a9fd695&chksm=e96c68c1ecc964ca81728e40f1c7ab3ceefbe7b77ca7424ec5de560a1ab993f2bb624dd1a518&scene=0&xtrack=1#rd",
      "publish_time": 1766983200,
      "publish_date": "2025-12-29 12:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2103.05623\"]",
      "add_ts": 1767050282,
      "last_modify_ts": 1767193592
    },
    {
      "id": 56,
      "article_id": "51487",
      "title": "脑网络中的高阶拓扑结构",
      "description": "人脑作为复杂系统，其认知与行为调控依赖于神经网络的精确协作。通过将大脑区域及连接建模为节点与边，脑网络分析揭示了信息处理中的拓扑特性变化。研究显示，在执行复杂任务时，脑网络的结构与功能动态调整，反映其在感知、决策和适应环境中的高效协调机制，体现了神经物理过程对宏观认知的重要影响。",
      "content": "导语\n人脑是一个复杂系统，追寻更精准的控制与协调、更清晰的感知、面对生存危机或机遇的快速的决策能力等等。针对脑网络分析发现，在脑部宏观计算和认知时，会受到一系列错综复杂的神经物理机制的影响。将大脑区域及其连接编码为节点和边的网络，研究分析在人类处理和执行复杂行为时，网络拓扑特性的呈现和变化，体现了脑网络中的信息交互和功能反应机制。\n今天介绍一篇2018年发表在\nJournal of computational neuroscience\n上的高引用文章“人类连接体中的团和洞”（Cliques and cavities in the human connectome），作者利用代数拓扑学的技术为结构连接学提供了一个新的视角，探讨脑网络中的高阶拓扑结构，可以提供对大脑功能复杂性的基本见解。\n研究领域：拓扑应用，复杂网络，高阶拓扑，脑网络，网络神经学\n高爽\n| 作者\n论文题目：\nSizemore, Ann E., Chad Giusti, Ari Kahn, Jean M. Vettel, Richard F. Betzel, and Danielle S. Bassett. \"Cliques and cavities in the human connectome.\" Journal of computational neuroscience 44, no. 1 (2018): 115-145.\n论文链接：\nhttps://link.springer.com/content/pdf/10.1007/s10827-017-0672-6.pdf\n前言\n脑网络中的节点体现了解剖上定义的大脑区域，这些区域通过白质束网络不断在彼此之间共享信息，从而构建为脑结构拓扑网络。在以往的研究课题中，主要是找寻由大片区域成对紧密相连的区域集合，称为\n社区\n（communities）\n、\n模块\n（modules ）\n以及\n富人俱乐部\n（ rich clubs）\n。因此在分析结构网络时，关注局部强连接区域成为大势所趋。然而从更宏观的角度来看脑网络，其中较小或者缺失的白质束直观地起到了隔离强白质束过程的作用。换句话说，弱连接或缺失边，为强连接区域起到了“\n划分\n”作用。\n在本文中，作者为了理解大脑中强连接和弱连接之间的相互作用，从只考虑成对相互作用转向捕捉更高阶的关系，用\n团\n（cliques）\n，即网络中的全连接子图，代表强相互连接的计算单元。团的数量和大小使人们对整个大脑的局部连接强度有一个总体的认识。并通过研究团形成的环来分析在中尺度脑网络中的结构特征。这些团和环对应于潜在信息传输的扩展路径，沿着这些路径可以连续进行计算，以发散或收敛的方式实现认知\n（即信息的分布或整合）\n，文中将这些 \"封闭的空间 \"称为网络中的\n拓扑洞\n（topological cavities）\n。作者假设，团和洞的空间分布将在其解剖位置上有所不同，与它们在神经计算中的不同作用相对应。将团和洞两个视角相结合，提供了一个更完整的网络功能视图。\n1. 脑网络中的团\n在文章中，为了提取人脑结构连接体的相关结构特征，从8名健康成年人获得的扩散光谱成像\n（diffusion spectrum imaging, DSI）\n数据编码为\n无向加权网络\n。在这个网络中，\n节点对应于83个大脑区域，边缘对应于节点对之间的白质束密度\n，并使用边缘密度(ρ)为0.25时的组平均网络阈值来去除虚假边。为进行统计验证构建\n空模型\n，将24次扫描的大脑区域，根据最短路径连接，边缘权重为欧几里得距离的倒数。这个模型模仿了大脑中的倾向连接方式来节省布线成本，即物理连接上接近的节点之间连边具有更高的权重。\n团是结构性脑网络中的局部区域特征\n。拓扑分析的第一步是对平均结构网络中的所有最大k-团进行计数。k-团是具有所有成对连接的k个节点的集合\n(2-团、3-团和4-团分别表示边、三角形和四面体)\n。根据定义，一个团的子图本身就是一个较低维度的团，称为面。最大团是指不是任何其他团的面的团。\n图1：a 为大脑的拓扑结构示意图。b 中所有k节点上的所有连通子图都称为k-团。c 表示最大4-团有3、2和1个团作为面。d 图为15个随机大脑区域的空模型示例。\n为了了解真实模型网络和空模型网络中最大团的解剖分布，定义一个节点作为成员参与最大k-团的数量，称为节点参与度。\n作者通过统计不同阶的团，观察到最大团的度分布在最小连接空模型中是单峰的，在经验数据中是定性的双峰分布\n(见图2a)\n。在解剖学上，随着检测程度增高，\n最大团参与度\n从皮层的前部到后部普遍存在\n(图2a)\n。在真实情况下，由12-16个节点组成的最大团几乎包含了所有的视觉皮质。这种空间分布表明，\n早期信息处理需要大量相互作用的脑区，而驱动高级认知的额叶皮质区域则利用较小的工作簇完成\n。结果还显示了，人脑显示出对小\n(4-6个节点)\n和大\n(12-16个节点)\n处理单元的偏好，而不是像最小连线空模型中那样的中等大小\n(大约8个节点)\n单元。\n最大团的前后梯度可以通过额外分析正在执行的认知计算中的区域差异来补充。具体地说，讨论\n最大团中的节点\n参与在\n特定的认知系统\n中\n是否存在不同。统计不同区域的团，最大团是由\n（几乎完全位于）\n皮质下、背侧注意、视觉和默认模式系统的节点形成的，这表明这些系统紧密地相互联系，可能利用鲁棒的局部拓扑进行通信。这些数据表明，\n较小的团作为局部处理系统可能是整个系统的常见特征，而较大的团可能允许快速的多系统串扰。\n图2：最大团的空间分布在平均脑网络和空模型之间不同。a 为平均扩散光谱成像数据网络(黑色)和单个最小连接(灰色)网络中最大团的分布示意图。b表示按功能成像研究中节点所属的假定认知系统分类下参与最大团示例。\n文中还验证了最大k-团的行为与图论度量的一致性。结果表明，\n通过直接路径和间接游走与大脑其余部分强连接的区域，也参与了许多最大团\n。在此，利用核心度的概念测量大脑区域与大脑中枢的关联。即G 图的k-核 是图G 的一个极大连通子图，其中所有节点的度至少为k\n（S-核 表示赋权图的等价概念）\n。参与度较高的节点通常在k-核 分解中达到较高的级别，并且高参与度节点之间频繁存在丰富的俱乐部联系。这些结果表明，\n人脑中富人俱乐部区域往往以团的形式参与局部计算\n。\n图3：a 节点参与度和节点强度（上）及可通信性（下）的散点图。b 表示计算出的k-核 和s-核 分解与具有富人俱乐部节点的最大团的相关性示例，用橙色表示，用大小表示节点达到的最大k-核或s-核级别，颜色深浅表示参与度。\n2. 脑网络中的洞\n依据文中描述，不仅扩散光谱成像数据网络中的团可以作为大脑计算结构的邻域尺度构建块，还可以通过研究\n强连接的缺失\n来研究这些块之间的关系，即检测大脑网络结构中的拓扑洞。由于连接被视为通信渠道，大脑各区域可以通过这些渠道相互发出信号并参与共享的神经功能，因此\n缺失此类连接意味着通信能力的降低，这有助于加强不同功能的隔离。\n为了识别加权网络中的拓扑洞，作者构建了一个二进制图的序列，每个图都包含在下一个图中\n（如图4a）\n，被称为过滤\n（filtration）\n。从空图开始，按照边缘权重递减的顺序逐一替换未加权的边缘，并通过其边缘密度ρ对每个图进行索引，该密度由图中的边缘数除以可能的边缘数得出。在每条边添加之后，提取k-团的结构，称为无关(k-1)-圈，其中每一个都在结构中包含了一个k维的拓扑洞。这种指数的转变原于几何学：一个2阶团是一个1维的线段，一个3阶团是一个2维的三角形，等等。虽然任何洞都被至少一个圈所包围，但往往是多个圈包围同一个洞。然而，检测同一洞的任何两个(k-1)-圈必然会因为一些(k+1)-团的集合的边界而彼此不同。任何两个这样的环称为拓扑等价圈，因此\n每个拓扑洞都由一类无关等价圈检测\n。当通过添加边来进行过滤时，圈的结构，以及其表示的洞结构都会发生变化。图4表示，通过网络过滤模式对团进行追踪，可以发现结构性大脑网络中的关键拓扑洞。\n图4：a 为在大脑中显示的15个节点上依据边缘密度过滤网络的示例。轴上的蓝线表示被绿色最小圈包围的二维空洞的初始密度。随着边的添加，3-团（青色）形成并收缩小洞，因此最小的绿色圈现在的大小为四个节点。最后，当洞被三阶团填充时，橙色线表示终止时边缘密度。b 图表示a图中绿色圈包围的洞的持久性。c 表示在维度1（左）和维度2（右）中的组平均扩散光谱成像数据网络和最小连接网络（灰色）的持久性示意图。d 为脑网络和空模型中二维和三维洞的终结与初始边缘密度比率π的盒图。彩色点对应于图c中突出显示的点。脑网络数据中三维拓扑洞的π值与空模型网络之间的差异不显著。e 表示图c和d中初始边缘密度下的而最小圈表示的洞，在大脑中示意图。\n本文研究了组平均扩散光谱成像网络和最小连接空模型网络中二维和三维洞\n（分别由1阶圈和2阶圈的等效类表示）\n的\n持续性\n。与空模型相比，组平均扩散光谱成像数据网络中的持久性洞明显较少。脑成像数据中最后一个持久的二维洞位于右半球，位于前内侧眶核、伏隔核、任何皮质下区域海马、尾状核、壳核、丘脑和杏仁核之间，以及左半球任何头侧额叶中部、前外侧眶核、前内侧眶核之间，以及来自两半球的头侧前扣带回\n（所有12个最小代表见图4e）\n。此外，由3阶团组成的紫色八面体圈包含颞下和颞中、枕外侧、顶叶下、边缘上、顶叶上以及左半球颞上和岛叶中的任何一个，并包围了结构脑网络中寿命最长的三维洞。虽然每一个最小的结构体可能有不同的生物学意义，但作者观察到在周期内皮质下-皮质连接的整体模式。事实上，在20个重构的1阶圈和2阶圈中，有18个包含这个基序。此外，不遵循该基序的两个持续性圈占最小连接网络中持续性圈的三分之一，这表明在这种最大效率的方案中，\n皮质下环路更可能出现。\n3. 可靠性分析\n利用高阶结构分析脑结构网络的拓扑特征，在\n组平均\n扩散光谱成像网络中观察到的结构特征，是否也可以在多个个人以及同一个人的多次扫描中一致地观察到，以确保这些洞不是由几个异常值驱动的伪影？\n作者为了捕捉平均扩散光谱成像数据中的洞及其最小圈在单个扫描中的存在程度，记录了组成表示\n等价类的每个最小圈的团的集合\n(如图4E所示)\n，并检查是否存在与相同强纤维束的存在相对应的一个团集合，更严格地说，\n检查每个个体的扩散光谱成像网络中是否存在由该循环表示的拓扑洞\n。结果证明，\n在群体平均扩散光谱成像网络中观察到的拓扑洞在个体中表现一致\n，这也表明它们作为人脑中保守的连接基序具有潜在的作用。\n图5：a、c、e、g表示将从平均扩散光谱成像重构的最小圈中看到的连接节点的边缘权重求和，然后对所有单个扫描数据进行归一化。b、 d、f、h(上部)表示在每次扫描中，以最小权重对网络连边进行阈值化，这将形成在平均扩散光谱成像数据中看到的圈。在此阈值下，将显示这些圈中节点之间存在的连接。灰色背景表示此次扫描中发现了类似的洞。对于那些没有被高阶团细分但没有灰色背景的圈，必须存在一些节点集，这些节点将此圈锥化，从而使此圈等效于一个节点。（下部）表示在单个扩散光谱成像网络、最小连接网络、标准化数据和对侧（续）半球中，发现了不同边缘密度下的类似圈。\n总结\n在此文的研究中，为在人脑连接网路中找到可以执行局部计算的密集连接结构，从只考虑成对相互作用转向捕捉更高阶的关系，探讨脑网络中的团和洞结构。使用这种方法验证了，节点在最大团中的参与在空间上和认知系统上都有所不同，这表明这些邻域尺度特征是一种全局体现。并发现重构的拓扑洞在个体间一致存在，在空间嵌入的空模型中不存在，强调了它们在神经布线和功能中的重要性。\n该文章首次利用代数拓扑的研究方法，对脑网络中的高阶拓扑进行分析，为脑网络认知提供了一个新的探索方向。随着复杂网络的不断发展，高阶网络以内生的方式，用更简洁的模型描述多主体互动，逐渐成为寻找拓扑特性的重要手段。\n拓扑学课程：从空间直觉到系统科学\n你是否曾思考过：为什么咖啡杯在数学上可以变成甜甜圈？为什么混沌系统中会出现周期轨、可约化结构和“奇怪吸引子”模式？为什么神经网络、量子物理甚至心理结构，都可以从“拓扑”角度理解？\n拓扑学不仅是数学的抽象分支，更提供了系统的思维方式，让我们理解连续性、结构不变性乃至复杂系统的整体规律。从欧拉七桥问题到DNA的缠结，从量子场论到思维科学与脑科学，拓扑学思想正在各学科中普遍而深刻地重塑着我们的认知方式。\n集智学园联合北京大学博士金威老师开设\n「拓扑学的思维革命：从空间直觉到系统科学」\n，课程于11月23日开启，欢迎感兴趣的读者加入。\n详情请见：\n拓扑学的思维革命：从空间直觉到系统科学\n推荐阅读\n1.\n自然·机器智能：LLM的语言表征与人脑高阶视觉表征的一致性让“读脑”不再是巫术\n2.\nScience：人类意识感知的“闸门”——高阶丘脑核团\n3.\nPNAS 速递：部分熵分解揭示人脑活动的高阶信息结构\n4.\n系统科学前沿十讲：探究复杂世界演变背后的规则（二）\n5.\n集智学园精品课程免费开放，解锁系统科学与 AI 新世界\n6.\n高考分数只是张入场券，你的科研冒险在这里启航！\n7.\n加入集智字幕组：成为复杂科学知识社区的“织网人”\n点击“阅读原文”，报名课程",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247724402&idx=2&sn=62f8ce50869f6ef2e680df93e70c1747&chksm=e98f57c5ec4223c76bc4e7a6b352f3aeda4bff59ca87a147c3e7b76d5792185066981970966d&scene=0&xtrack=1#rd",
      "publish_time": 1766889600,
      "publish_date": "2025-12-28",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://link.springer.com/content/pdf/10.1007/s10827-017-0672-6.pdf\"]",
      "add_ts": 1767050340,
      "last_modify_ts": 1767050340
    },
    {
      "id": 59,
      "article_id": "51529",
      "title": "AI4S回归白盒符号主义，清华等联合发布SR-LLM：自主发现科学知识",
      "description": "清华大学等多所高校联合提出SR-LLM，一种融合大语言模型与深度强化学习的符号回归框架。该方法结合检索增强与语义推理，能从数据中自动生成简洁、可解释的数学模型，在跟车行为建模等任务中表现优异，不仅复现经典模型，还发现更优新模型，显著超越现有技术，为机器实现自主科学发现提供了新路径。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n清华大学等多所高校联合发布SR-LLM，这是一种融合大语言模型与深度强化学习的符号回归框架。它通过检索增强和语义推理，从数据中生成简洁、可解释的数学模型，显著优于现有方法。在跟车行为建模等任务中，SR-LLM不仅复现经典模型，还发现更优新模型，为机器自主科学发现开辟新路径。\n长久以来，神经网络因其「黑箱」本质，虽具备强大的函数逼近能力，却难以生成人类可理解的显式规律，以至于科学界曾质疑：AI能否像牛顿那样，从观测数据中自主发现如万有引力定律般简洁而普适的解析表达式？\n正是在这一背景下，符号回归因其能够从数据中直接推获得形式明确、结构清晰的数学模型而备受关注。\n清华大学、中国科学院自动化研究所、格拉斯哥大学、剑桥大学、欧布达大学、南加州大学、澳门科技大学的研究团队联合提\n出\nSR-LLM，一种融合大语言模型与深度强化学习的新型符号回归框架\n，其核心在于引入检索增强的增量生成机制：\n通过构建外部知识库，系统可动态检索与当前任务最相关的先验知识，并借助LLM的语义推理能力，将这些知识转化为具有物理意义的小型符号组合；随后，利用深度强化学习将这些符号模块高效组装为复杂但高度可解释的解析表达式。\n论文链接：https://doi.org/10.1073/pnas.2516995122\n这一设计使SR-LLM能够真正「站在巨人的肩膀上」进行科学探索，正如AlphaGo通过学习人类棋谱提炼高阶策略，SR-LLM则通过整合领域专家知识与历史搜索经验，引导模型聚焦于语义合理、结构优雅的解空间区域。在标准符号回归基准上的实验表明，SR-LLM显著优于现有方法；\n更关键的是，在人类跟车行为建模这一尚无共识的开放问题中，它不仅成功复现了经典跟驰模型的核心结构，还从真实车辆轨迹中发现了拟合性能更优、物理意义更清晰的新模型。\n展望未来，研究团队致力于发展一种类似AlphaZero的自举范式：在完全无先验知识的条件下，通过随机探索与自我优化，让系统自主构建初始知识库，并逐步演化出可解释的科学规律。\nSR-LLM不仅是一个实用工具，更是一条通向机器自主科学发现的新路径。\n研究背景\n在AI飞速发展的今天，我们早已习惯用神经网络拟合复杂数据。但长久以来，我们只能得到大量神经元堆叠而成的人们难以解析分析的复合函数，却难以像牛顿那样从现象中提炼出如万有引力定律般简洁、普适的科学规律。\n但你有没有想过——\n能不能让AI不仅「会算」，还能「发现新的人类能看懂的定理公式」？\n这正是符号回归（Symbolic Regression, SR）的目标：\n从数据中自动归纳出准确、简洁、可解释、具有泛化能力的数学表达式\n。\n符号回归的基本范式可以描述如下：给定一组\n输入量X∈R^(n×d)\n与\n响应Y∈R^n\n（其中n表示数据集的大小，d表示输入量的维度），找出用输入量字符、运算字符、常数字符等基本字符组成的可解释函数f:X→Y，用以表示输入与响应之间的映射关系。\n不同于目前流行的深度学习方法对于数据对(X,Y)的黑箱拟合，符号回归方法能得到更为简洁与可解释的结果，因此它的输出通常是更易于人类理解的，在物理、化学、金融等不同学科的应用场景下能够推动人类对相应领域的认知进程。\n然而，现实充满挑战：数学表达式的搜索空间极其庞大，真实数据常受噪声干扰，表达式结构与参数需联合优化，并且搜索出的数学表达式内嵌的组合逻辑难以被人类理解——传统方法如遗传编程往往在复杂问题面前「卡壳」，要么搜索效率低，要么容易陷入局部最优，难以兼顾精度与可解释性。\nSR-LLM\n最近，大语言模型在自然语言处理、计算机视觉等多个领域取得了巨大成功。得益于庞大的参数规模与丰富的预训练语料，大语言模型的语义理解、基于上下文的推理等能力达到了前所未有的高度。\n注意到大语言模型这些优秀的能力，SR-LLM将LLM应用到符号回归领域，为树搜索提供剪枝与引导，为该领域的发展方向打开了新大门。\n其核心思想是：\n把符号回归变成一个「增量式生成」任务，并借助大语言模型的强大推理能力来引导强化学习，不断搜索更好的定理公式。\n具体而言，SR-LLM的四大关键技术为：\n1. Radix树存储公式搜索中获得的历史经验\n所有已探索的公式被高效压缩存储在压缩前缀树中。这不仅节省内存，还能快速检索相似结构，避免重复探索。\n2.双阶段强化学习搜索\n第一阶段：采用「风险寻求」策略，只奖励表现最好的公式，快速聚焦高潜力区域；\n第二阶段：切换到Soft Actor-Critic (SAC)，利用经验回放跳出局部最优，稳健逼近全局解。\n这一设计保障了SR-LLM在不借助LLM时基础的搜索能力。\n3. LLM 驱动的检索增强生成\nSR-LLM设计了从优秀表达式汲取公式组合知识的「反思模块」，用于将DRL探索到的优秀结果集群到外部知识库中，指导后续搜索。\n「推理模块」与「反思模块」的设计使得SR-LLM在现有所有符号回归方法中脱颖而出，过去的工作只会提供优秀模型的具体解析式，而SR-LLM则额外告知人类专家这些公式是如何组合来的。\n4. LLM 驱动的知识提取和利用\nSR-LLM利用大语言模型对数学表达式的语义理解能力，结合外部知识库（包含领域专家模型、已经被DRL验证过的优秀表达式），利用「推理模块」动态构造提示词，引导模型生成更合理、更贴近真实规律的符号组合。\n通过使用大语言模型推理的新组合字符，有效减少了表达式树所需的节点规模，进而大大缩减了搜索空间；\n此外，大语言模型可以对新的字符组合提供足够的可解释性保障，进而能够引导树搜索找到更易于人类理解的字符表达式。\nSR-LLM将这些功能模块巧妙的融合在一起，构建出一位自我驱动的「AI科学家」：\n先根据人类已经积累的知识，大胆猜测一些不错的备选公式，接着通过LLM学习这些公式的优点和可能有用的字符表达式片段，然后使用LLM引导的强化学习持续改进搜索新的公式，反复验证、修正、提炼，最终交出最强的简洁优美的候选定理公式。\n实验结果\n研究团队在\n标准符号回归基准\n和\n真实世界场景\n上进行了大量实验：\n在Fundumental-Benchmarks与Feyman-Benchmarks上\n，显著优于PSRN，PhySO等主流方法；\n在\n含噪数据\n下依然保持高鲁棒性，不易过拟合；\n生成的公式\n结构简洁、物理意义明确\n；\n支持\n多目标权衡\n：通过调整拟合精度、专家相似度、复杂度三项得分的权重，灵活适应不同任务需求。\n更重要的是：\n它不是黑箱\n！\n每一个输出都是人类可读、可验证、可推广的数学表达式。\n跟驰模型发现\n研究人员还将SR-LLM应用于「跟驰模型发现」这一具体任务，以验证其在处理真实复杂交通数据中的可行性。\n跟驰模型作为刻画驾驶员纵向行为的核心工具，在交通流特性分析、微观交通仿真、以及无人驾驶车辆的决策与控制等关键领域具有不可替代的作用。\n一个兼具高拟合精度与清晰物理意义的跟驰模型，不仅能够提升仿真系统的可信度，还能为理解人类驾驶决策机制提供理论支撑。\n然而，从真实轨迹数据中自动发现高质量的跟驰模型仍是一项极具挑战的任务：一方面，实际采集的轨迹数据通常包含大量有偏噪声，严重干扰模型结构的准确识别；\n另一方面，跟驰行为本身涉及多种经验性变量与非线性关系，其可能的模型组合空间极为庞大且复杂，难以通过人工方式高效探索。\n针对上述问题，研究人员将SR-LLM应用于「跟驰模型发现」这一具体任务，在真实NGSIM轨迹数据上开展实验，在该任务上面的成功应用能够证实SR-LLM以此类推应用到物理、化学等广泛学科领域的潜力。\n结果表明，SR-LLM不仅能在专家知识引导下成功复现经典跟驰模型，还能融合先验知识自动生成具有明确物理解释的新颖高性能模型，新模型在一些边缘数据下能够克服经典跟驰模型在遭遇突发速度变更时拟合能力变弱的缺点，充分验证了其在处理复杂真实交通数据中的有效性与潜力。\n结论\nSR-LLM的\n成功表明\n，大语言模型不仅是解释已有知识的高水平教师，更是科学发现的智能协作者、乃至独立主导科学探索的智能发现者。通过将LLM强大的语义推理能力与符号回归对可解释性、简洁性与普适性的追求深度融合，迈出了「AI for Science」的关键一步。\n正如AlphaGo通过学习人类棋谱提炼高阶策略，SR-LLM通过整合领域专家知识与历史搜索经验，引导模型聚焦于语义合理、结构优雅的解空间区域，这一设计使SR-LLM能够真正「站在巨人的肩膀上」进行科学探索。\n展望未来，研究团队致力于发展一种类似AlphaZero的自举范式：在完全无先验知识的条件下，通过随机探索与自我优化，让系统自主构建初始知识库，并逐步演化出可解释的科学规律。\nSR-LLM不仅是一个实用工具，更是一条通向机器自主科学发现的新路径，也许下一次某个学科领域的重大科学突破，就诞生于这样一个「会思考、能表达、敢创新」的AI科学家之手。\n参考资料：\nhttps://doi.org/10.1073/pnas.2516995122\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652658873&idx=2&sn=0da11d694b546334cf078ba0dd5d24fa&chksm=f0b6081386c6eb7e4819653e44e82e26ad0a4e11566973051434dba580b125f354f305825bed&scene=0&xtrack=1#rd",
      "publish_time": 1767099000,
      "publish_date": "2025-12-30 20:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1073/pnas.2516995122\"]",
      "add_ts": 1767136638,
      "last_modify_ts": 1767223247
    },
    {
      "id": 67,
      "article_id": "51521",
      "title": "救命！和漫画角色聊上头了，AI陪伴的新答案有了",
      "description": "最新AI陪伴产品让玩家“魂穿”漫画世界，以第一视角与原作角色深度互动。无需设定角色，AI自然融入剧情，对话生动个性，每次选择皆影响故事走向，带来沉浸式、可共同改写的叙事体验，打破传统机械交互，令人上瘾。",
      "content": "西风 发自 凹非寺\n量子位 | 公众号 QbitAI\n行业最新AI陪伴产品，玩起来简直太上头了，这波是真的爱了。\n打开方式be like：\n它不为AI创造一个角色，不用玩家自己费力填写设定，直接让AI嵌入漫画主线里本就鲜活的角色之中：\n而且呢，当你和TA聊天互动时，得到的不是千篇一律机械式的问答。\n玩家将“魂穿”进漫画世界，以第一视角与TA们相遇。所以每一次对话、每一个选择，都将共同改写一段正在发生的故事。\n没错，这意味着你能与你喜爱的那个TA，展开真正深入、即时的互动。\n这恰恰刺中了当下AI陪伴产品的痛点——普遍与用户的关系难以持续，对话疲劳与人设空洞已成通病。\n它的解法不同，靠的是建立在\n共\n同经历\n与\n叙事上下文\n之上的关系存续逻辑。\n不卖关子，这正是国内漫画头部玩家快看，在\n快看漫画2.0\n版本中推出的\nAI陪伴互动漫画\n，也是一次关于叙事型陪伴的全新尝试。\n这一形态同时点燃了两类用户的期待，一边是厌倦了机械式聊天的AI尝鲜者，另一边则是渴求与角色深度互动的漫画核心用户。\n官方预热微博发布时，评论区已是一片“快快端上来”的呼声。\n还有更多好玩儿的，我们接下来细细品。\n魂穿漫画，这谁顶得住\n随着AI陪伴互动体验登陆快看漫画，《DOLO最后的夏天》《Bloody心跳回溯》《SHElter她之所归》等风格各异的作品，首发解锁该玩法。\n入口就在快看漫画APP首页的“\n角色陪伴\n”专区。点进去后，在页面顶部选择心仪的漫画作品，迎面而来的便是静候你多时的漫画角色。\n以穿越题材漫画\n《DOLO最后的夏天》\n为例，主线剧情讲述了神奇生物DOLO带你重返17岁，一边攻略四位性格迥异的角色，一边探寻高中坍塌事故的真相，重启不一样的青春。\n在这里，你成为了故事的主角。点击“主线故事”即可沉浸阅读漫画，推进核心剧情。\n与此同时，你可以随时从主线中切出，与角色们展开即时聊天。\n这种设计，与传统AI陪伴需要你从零开始设定角色截然不同。在这里，你\n遇见的每个角色都已自带丰满的前史\n，他们就来自这部完整的漫画，拥有既定的人格、人际关系与命运挑战。\n而你的代入，是进入一个早已运转的故事轨迹，这\n从\n源头上赋予\n了角色无可替代的深度与一致性\n。\n即便是最随意的闲聊，角色也不会出戏，回答始终锚定在自己的世界里。\n比如问他中午吃什么，他可能会说“学校外面新开了家汉堡店”。\n日常与角色的对话也不止于泛泛而谈，它们被巧妙地编织在剧情的时间线上。\n闲聊中会伴随各种\n日常事件\n，可能发生在重大事件的前夜，对方的回应会带着剧情赋予的紧张或期待；也可能在共同冒险后的休憩时刻……\n这种设计让每一次互动都成为对共同经历的积累。\n在特定剧情节点触发的\n剧情事件\n中，体验更进一层。\n系统会给玩家安排明确任务，你需要通过与角色对话来“攻略”他们、完成任务，从而引导剧情走向。\n除此之外，还有机会触发更为沉浸的\n限\n定事件\n。\n此时，系统会结合环境音效、动态画面与AI的实时对话，营造出一种轻度的共演氛围。\n整个交互画面的质感提升，细节更为考究。例如，在“给TA投喂饼干”的互动中，你能看到角色接过饼干的细微动作、听到对应的音效。\n有意思的是，玩家在其中的所有互动都暗含上分机制。自身的魅力、智商、体能、耐心等属性会随着互动浮动。\n玩家不仅是在推动剧情，也在\n实时养成自己的人设\n。\n与角色之间的好感度，也会在互动中悄然变化。\n最终，\n这一切将指向只属于你的、独一无二的角色关系与故事结局\n。\n接下来就不再过多剧透了，留给宝子们自行探索。\n一句话总结体验，把\nAI当成角色扮演插件嵌进成熟漫画\n，让对话多一层故事感\n，这是快看为解决“AI如何真正陪伴”这个行业难题，给出的一条新的解题思路。\n换句话说，快看没有在\n让对话更聪明\n或是\nAI直接生成漫画\n的维度上卷。\n目前市面很多AI陪伴产品难以和用户间形成长久陪伴关系。许多产品本质上是在\n强情感\n（如情绪安慰）\n或\n强叙事\n（如角色扮演）\n的单一路径上深耕。前者易因缺乏共同话题而陷入情绪饱和，后者则常因世界观单薄而让对话流于程式化。\n快看这次试图\n同时握住“\n叙事”与\n“情感”两条线\n，用连续的漫画故事为AI提供生活的世界与时间线，又用即时、个性化的互动让用户在这个世界里沉淀专属的情感记忆。\n角色因故事而厚重，关系因记忆而具体。\n根据官方测试，体验新产品的用户，\n其周留存率相较传统漫画提升约50%\n，直接证明了用户与角色已建立起超越普通“读者-作品”的准社交陪伴关系。\n快看当“总导演”，集成各家AI顶流\nAI科技热潮下，人们对于游戏NPC、二次元虚拟角色能“活”起来的种种畅想，在此刻有了一次具体又高水准的落地形态。\n这自然引出一个问题：AI模型或许早具备这样的能力，为什么AI公司一直没做出来？\n答案很明显，\n这本质上是一个“内容理解深度>基础模型能力”的垂直场景\n。\n真正的挑战不在于找到一个很会说话的AI，而在于让它精准踩住每一个故事转折的节点，完完全全变成漫画里那个鲜活的角色。\n对角色、故事节奏、情感脉络的深度理解与把控能力，是快看这样做内容的公司十几年积累，以及技术无法短期复制的核心资产。\n纵观快看的发展历程，从2014年以条漫革新移动阅读体验，到2021年前瞻性地推出“漫剧”形态，再到如今探索AI互动叙事……每一步都是对如何更好地“讲故事”与“连接用户情感”的持续深耕。\n所以，快看在此次尝试中扮演的角色，更像是\n一位手握成熟剧本和演员理解力的导演\n，而AI技术是被融合进来服务于统一的叙事体验。\n那么背后用的哪家的AI？\n据了解，此次AI陪伴互动漫画的背后，是一个“专业事交给专业方”的\n开放协作生态\n：\n腾讯云\n：通过DeepSeek API为AI陪伴互动漫画提供灵活可调用的AI原生能力，支撑角色互动与对话生成。\n火山引擎\n：接入豆包支持角色聊天；即梦提供生图、生视频能力，用于生成角色互动的AI视频素材；海绵音乐则为视频提供环境音与音效支持。\n阿里云\n：基于通义千问的对话能力与图像模型能力，共同支撑角色互动体验。\n可灵\n：提供生视频与配音能力，增强角色表达与内容呈现效果。\nMiniM\na\nx\n：提供高质量语音能力，丰富角色声音表现。\n不仅如此，快看还在和一众有特色、有脑洞的AI公司密切合作，比如主打指向式全息与全维度交互的\nAI硬件公司数伴\n，以及亚洲极具影响力的\nAI原生虚拟歌手Yuri尤粟\n、\nTHUNDEROBOT雷神\n等。\n当然它优先服务的，依然是平台内最核心的故事消费用户，通过AI为既有的阅读体验注入更强的沉浸感与情感联结。这一切在其自家最熟悉地盘内进行，以最高的内容契合度，探索人工智能时代娱乐内容的新形态。\n这一探索也在无形中，向世人证明：\n只有存在于故事中的关系，才能发展出长久的AI陪伴\n。在构建有温度的数字关系时，一个精心构筑的故事上下文，其力量可能远胜于一个更聪明的对话引擎。\n现在，悬疑、古风、都市奇幻……各种风格的剧本已就位。感兴趣的友友可以冲冲亲自体验了～\nOne More Thing\n我们拿到了官方尚未披露的产品内测数据，进一步说明了“AI+互动叙事”这一模式在用户体验之外，也初步展现出商业上的潜力：\n测试阶段\n，\n新作上架周付费率飙升，相比传统阅读产品提升近三倍\n。\n此外，新作\n凭借多分支多\n选项的内容特\n点，带来更加高频的小额付费\n。加之，这种带有数值属性的角色养成内容，培养出\n用户长线付费习惯\n。双管齐下\n，\n最终\n带动周人均付费提升130%\n。\n对于新产品，官方表态，这是一次“\n漫画体验形态探索，未来持续完善后会带来更多\n惊\n喜\n”。\n所以广大友友们可以继续期待一波，或许之后还能体验和AI共创故事，不再只是沉浸在漫画世界里，而是在某个漫画里和喜欢的角色们，一起创造独一无二的经历。\n官方体验链接：\nhttps://miniact.kkg3.com/dynamic/JQjwhywV/topic/common-activity/index.html?id=1192_1\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859010&idx=1&sn=15ebd6a80b46228b700d2e36d29b0ebd&chksm=e92e08e75ea676746ed23a969a682cbfe1dbda225d67ccc5409d8b0ff95a85aadf40679e6dae&scene=0&xtrack=1#rd",
      "publish_time": 1767078600,
      "publish_date": "2025-12-30 15:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://miniact.kkg3.com/dynamic/JQjwhywV/topic/common-activity/index.html?id=1192_1\"]",
      "add_ts": 1767136666,
      "last_modify_ts": 1767223279
    },
    {
      "id": 68,
      "article_id": "51520",
      "title": "ViT一作盛赞：这个中国开源“PS模型”强过Nano Banana",
      "description": "ViT核心作者、Meta团队成员Lucas Beyer盛赞通义千问新发布的开源图像生成模型Qwen—Image—Layered，称其远超ChatGPT和Nano Banana，是图像生成的正确方向，并坦言自己也曾有类似构想但因忙碌未能实现。",
      "content": "梦瑶 发自 凹非寺\n量子位 | 公众号 QbitAI\n太香了太香了，妥妥完爆ChatGPT和Nano Banana！\n刚刚，ViT核心作者、Meta超级智能团队成员\nLucas Beyer\n连发三条帖子，怒赞通义千问不久前发布的开源模型\nQwen—Image—Layered\n。\n在他看来，这才是图像生成的正确打开方式～\n他还顺便自补了一句：这个模型方向自己其实也想做来着，只是太忙，一直没来得及动手……（笑）\n实话实说，Qwen—Image—Layered模型确实不一般，因为它可以让我们真正实现ps级别的\n拆图自由\n。\n也就是说现在图片元素也支持精细化修改了：\n连网友们看了\n模型效果后都不禁感叹：咋有种开源PhotoShop的感觉，amazing啊～\n所以，这套让Lucas Beyer反复点赞的模型到底强在哪儿，咱一起来看！\n图片也能像PS一样拆拆拆了\n如果说Nano Banana技能点在生图，那\nQwen—Image—Layered\n模型则厉害在：\n《拆图》\n。\n相信大家都有过类似的经历，我们平时用大模型生图时总会碰的到一个抓狂问题，那就是图片生成so easy，细节修改so抓狂！！！\nAI生出来的图片里，经常会有一些小细节不太到位，但我们又没法只改局部，只能整张丢回模型重新生成，结果往往还不如上一版…\nQwen—Image—Layered\n模型的核心能力，就是专治「一图定生死」这事儿的。\n它能将一张普通图片分解成多个包含透明度信息的\nRGBA分离图层\n，实现真正意义上的图片素材的可编辑性。\n光说概念有点抽象，咱直接看例子～\n在官方案例中，一张完整图片输入之后，模型会自动把画面拆成6个包含不同元素的图层，背景是背景，人物是人物，装饰是装饰，互不干扰。\n看到这儿大家是不是突然感觉，这个非常适合用在海报制作等细节较多的图片上？？（雀实\n但是\nQwen—Image—Layered\n模型能做的还不止只是分离图层这么简单，我们还可以对图层进行\n二次编辑修改\n。\n比如最基础的：\n改背景，不动主体\n。\n只替换背景图层的颜色，一张橙色背景的海报，瞬间就能换成蓝色版本：\n再比如，直接\n换主体\n。\n保持构图不变，把原图里的长发女孩，换成短发女孩，几乎看不出拼接修改痕迹：\n再来看下面这个——\n文字编辑\n。\n我们可以只修改图片中的局部文字，哪怕第一次生成的文字有幻觉问题也不怕了：\n除了基本的替换编辑功能外，\nQwen—Image—Layered\n模型还支\n持调整元素的大小、删除不想要的元素等等。\n例如像这样，我们可以\n删除\n掉画面中不想要的元素对象，只保留自己想留的画面元素：\n又或者在不拉伸、不失真的前提下，轻松调整元素的\n大小比例\n，其实有点像PS里的自由缩放功能：\n值得注意的是，\nQwen—Image—Layered\n模型分层不限于固定的图层数量，支持\n可变层分解\n，例如我们可以根据需要将图像分解为3层或8层：\n这个能力非常适合我们在不同的编辑需求场景下使用，可以根据我们想局部编辑的元素数量多或少而定。\n当然，如果只是想改文字，差不多两三层就够了，如果修改需求比较多比较复杂，多拆几层反而更好操作～\n除了刚才说的这些，模型还支持在已分解的图层基础上做进一步分解，进而实现无限分解，听上去很像无限套娃…\n像下面这位网友，用\nQwen—Image—Layered\n把人物元素进行一次性分层处理，最后甚至可以一路拆到只剩下一个线稿层：\n再来看这位网友，原本人物和背景完全糊在一起的一张图，被模型直接拆成了主体和背景两个独立元素：\n简单说就是：只要画面里不止一个元素，它就能拆、还能一直拆……\n拆图的本事来自于扩散模型\n有朋友看到这儿该问了，小小模型背后能有这PS一般的能力，用的是啥神奇魔法？\n不藏着掖着，\nQwen—Image—Layered\n的核心技术，本质上是一套端到端的\n「扩散模型」\n。\n它并不是用来生成图片的那种扩散模型，而是专门为「拆图片」这件事设计的——\n模型直接输入一张完整的RGB照片，通过扩散过程，一步步预测出多个带透明度信息的RGBA图层。\n这里有一个绕不开的前提是：\n我们平时看到的图片其实只有RGB三个通道，但真正的图层编辑，离不开Alpha（透明度）通道。\n为此，\nQwen—Image—Layered\n专门设计了一套四通道的\nRGBA-VAE\n，把RGB输入和RGBA输出，统一压缩到同一个隐藏空间中：\n具体来说，当输入是一张普通RGB图片时，模型会自动把Alpha通道补成1（完全不透明），在初始化阶段还会聪明地复用预训练参数，避免在透明度建模时出错。\n这样一来，模型从一开始就「懂透明」，不同图层也就不会被混在一起。\n而且在结构上模型也不是死板拆层，它的核心Transformer—\nVLD-MMDiT\n会根据图片复杂度，自动决定需要拆成多少层。\n为了避免前一层把后一层盖住的问题，模型还加了一套Layer3D RoPE（三维位置编码），简单说就是给不同图层打上明确的\n层级标签\n，让模型在空间和顺序上都分得清楚～\n还不止如此，在隐藏空间里中，模型能够被逐步「引导」去学会：哪些像素该属于哪一层、哪些区域需要保留透明度、哪些内容应该被分离开来。\n这样一来哪怕图层再多对模型来说也都是小case了～\n并且在训练策略上模型也不是从零教的，而是基于Qwen-Image预训练生成模型逐步升级：\n第一阶段让模型学会文本\n生成单RGBA图层\n，第二阶段让模型学会\n扩展到多图层合成\n，第三阶段让模型真正学会\n从图片反向拆解多图层。\n每阶段几百K步训练，加上重建损失和感知损失，确保语义分离干净、不冗余。\n这样一来好处很直接，以前方法（如LayerD）要递归抠前景再补背景，容易积累错误，或者用分割+修复，遮挡区补不好。\nQwen—Image—Layered\n模型直接实现端到端生成完整RGBA层，避免这些问题，尤其擅长复杂遮挡、半透明和文字。\n相较于Nano Banana的“一次抽图定生死”，\nQwen—Image—Layered\n的拆图能力能让Lucas Beyer这么喜欢，也就不奇怪了…\n目前模型已经开源，感兴趣的朋友可以试试～\ngithub开源地址：https://github.com/QwenLM/Qwen-Image-Layered\n—\n欢迎AI产品从业者共建\n—\n📚\n「AI产品知识库」\n是量子位智库基于长期产品库追踪和用户行为数据推出的飞书知识库，旨在成为AI行业从业者、投资者、研究者的核心信息枢纽与决策支持平台。\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859115&idx=2&sn=81e16f76be9780fd0dc36bf38b54add0&chksm=e93b706d239f22dd66aee5ffdfb4c479a606e7744c48b590e4526dcac098556c04db72f023a2&scene=0&xtrack=1#rd",
      "publish_time": 1767077760,
      "publish_date": "2025-12-30 14:56",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/QwenLM/Qwen-Image-Layered\"]",
      "add_ts": 1767136669,
      "last_modify_ts": 1767223282
    },
    {
      "id": 76,
      "article_id": "51512",
      "title": "Nat. Commun. | 人工智能驱动的视网膜神经纤维层代谢组学",
      "description": "DRUGONE视网膜神经纤维层（RNFL）作为反映全身代谢健康的无创生物标志物，其生物学机制尚不明确。本研究结合高分辨率视网膜成像、人工智能与代谢组学，在多民族人群中系统分析RNFL退变的代谢基础及其与心代谢疾病及死亡风险的关联，识别出显著相关的代谢标志物，发现这些代谢特征在很大程度上介导了RNFL与疾病风险之间的联系，揭示了其潜在生物学通路。",
      "content": "DRUG\nONE\n视网膜神经纤维层（RNFL）是一种无创、可规模化获取的结构性生物标志物，近年来被认为能够反映全身心代谢健康状况，但其背后的生物学机制仍不清楚。本研究整合高分辨率视网膜光学成像、人工智能算法与互补的代谢组学检测，在多民族人群中系统解析 RNFL 退变的代谢基础及其与死亡和心代谢疾病风险之间的关联。研究人员识别出一组与 RNFL 厚度显著相关的代谢标志物，并发现这些代谢特征在很大程度上介导了 RNFL 与多种心代谢结局之间的联系。基于此构建的 AI 驱动 RNFL 代谢状态模型，能够在不同人群、遗传背景和社会分层中有效分层疾病风险，并显著提升临床预测与决策价值。\n视网膜作为中枢神经系统的一部分，因其光学透明性，为无创观察全身微血管与代谢状态提供了独特窗口。随着光学相干断层扫描（OCT）技术的发展，RNFL 的微米级结构变化可以被精准量化，使其逐渐成为评估心代谢疾病风险的潜在替代指标。\n尽管已有研究表明 RNFL 变薄与糖尿病、心血管事件及死亡风险相关，但这种“眼—心代谢”关联的分子基础尚未明确。代谢异常是心代谢疾病发生发展的核心驱动因素，因此，系统刻画 RNFL 相关的代谢状态，有望揭示这一跨系统联系的生物学基础。\n图1｜研究整体设计概述。\n方法概述\n研究人员基于大规模前瞻性队列，构建了三类研究人群：\n同时具备视网膜 OCT 扫描与代谢组数据的人群，用于识别 RNFL 相关代谢状态；\n仅具备代谢组数据的人群，用于评估心代谢疾病与死亡结局；\n独立外部队列，用于跨人群验证。\n研究整合核磁共振与液相色谱–质谱两类互补代谢组学技术，系统刻画与 RNFL 厚度相关的代谢特征，并利用多种机器学习与深度学习模型构建 RNFL 代谢状态，用于疾病风险分层与预测。\n图2｜RNFL 相关代谢特征的识别与建模框架。\nRNFL 相关代谢特征及其疾病关联\n研究人员共识别出 26 种与 RNFL 厚度显著相关的代谢标志物，其中绝大多数与高密度脂蛋白（HDL）的组成、脂质转运及磷脂代谢密切相关。RNFL 越薄，往往对应更不利的脂质代谢特征。\n在长期随访中，这些 RNFL 相关代谢标志物与多种心代谢结局（包括 2 型糖尿病、心肌梗死、心力衰竭、中风、全因死亡和心代谢死亡）显著相关。中介分析显示，这些代谢特征解释了 RNFL 与心代谢疾病风险之间相当比例的关联，提示存在共同的代谢基础。\n图3｜RNFL 代谢特征在多种心代谢结局中的风险分层能力。\nAI 驱动的 RNFL 代谢状态与风险预测\n基于 RNFL 相关代谢特征，研究人员构建了 AI 驱动的 RNFL 代谢状态模型。结果显示，按 RNFL 代谢状态分位数分组后，不同人群的疾病事件发生轨迹呈现出清晰分离，高风险与低风险人群之间的事件发生率差异可达数量级。\n在预测性能评估中，仅使用 RNFL 代谢状态即可达到与多种传统风险模型相当甚至更优的表现；当其与年龄、性别或经典心血管风险评分模型结合时，预测能力和临床净获益进一步显著提升。\n图4｜RNFL 代谢状态在不同模型中的预测增益与临床效用。\n健康不平等人群中的潜在获益\n值得注意的是，RNFL 代谢状态在女性、社会经济地位较低以及受教育程度较低的人群中，带来了更显著的预测改善。这种改善在一定程度上缩小甚至逆转了传统模型中长期存在的预测差距，提示 RNFL 代谢状态可能捕捉到了被常规风险因子忽略的早期生物学信号。\n图5｜不同性别、社会经济与教育分层中的预测性能变化。\n跨人群验证与机制启示\n在独立的东方人群队列中，研究人员重复观察到 RNFL 与代谢特征及心代谢结局之间的一致关联，并通过更高灵敏度的代谢检测，进一步揭示了氨基酸代谢、抗氧化通路及脂质重塑等多条相关生物通路。\n这些结果共同支持这样一个观点：RNFL 代谢状态反映了系统性代谢扰动在早期阶段对神经视网膜结构的影响，可作为全身心代谢风险的“下游读出”。\n图6｜独立人群中的 RNFL 代谢状态验证结果。\n总结与展望\n总体而言，本研究提出并验证了一种 AI 驱动的“视网膜—代谢—心代谢疾病”整合框架。RNFL 不仅是结构性影像标志物，更是具有代谢信息含量的窗口，能够在疾病发生前捕捉系统性代谢异常。\n随着视网膜成像在基层医疗中的广泛应用，该研究为构建可扩展、无创、兼顾公平性的心代谢风险评估策略提供了新的可能性，也为未来“眼部表型驱动的系统医学”研究奠定了基础。\n整理 | DrugOne团队\n参考资料\nYang, S., Xin, Z., Li, H. et al. Artificial intelligence-driven metabolomics of retinal nerve fibre layer to profile risks of mortality and cardiometabolic diseases. Nat Commun 16, 11039 (2025).\nhttps://doi.org/10.1038/s41467-025-66979-z\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512394&idx=2&sn=7cfb9f51fbb74a2e1ad9bfc43f8be3b8&chksm=fd955da623b1621550be9096907d151fcc2e1cff41a491e7e492724029e715d7c60bd9b8aa64&scene=0&xtrack=1#rd",
      "publish_time": 1767066600,
      "publish_date": "2025-12-30 11:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s41467-025-66979-z\"]",
      "add_ts": 1767136699,
      "last_modify_ts": 1767223339
    },
    {
      "id": 77,
      "article_id": "51511",
      "title": "性能真的不重要了吗？Jeff Dean给出反常答案",
      "description": "Jeff Dean指出，性能并非后期优化而来，而是从编码初期就决定的。尽管2025年算力充裕、AI编程普及，性能看似不再重要，但良好的性能设计依然关键。忽视早期优化将导致系统难以扩展和维护。真正的性能源于代码结构、数据选择与设计决策，而非资源堆砌。开发者应摒弃“过早优化是万恶之源”的误解，在首行代码中便注入高效思维，才能构建真正健壮的系统。",
      "content": "新智元报道\n编辑：倾倾\n【新智元导读】\n很多人背着「过早优化是万恶之源」的名言，写出的却是处处漏风的代码。Google传奇Jeff Dean的这份笔记破了真相：性能不是最后调出来的，而是你在选第一个容器、敲第一行代码时，就已经注定的物理结局。\n2025年，是个很容易让人产生错觉的时间点。\n这时算力不再稀缺，云资源随叫随到，AI已经能写出准确无误的代码。\n在这样的环境里，「性能」似乎正在悄悄贬值。因为代码写得慢一些，好像也没什么大不了。\n就在这种氛围下，Google的传奇工程师Jeff Dean更新了一份老文档：Performance Hints。\n比起一篇炫技的论文，它更像是一份老派工程师的随笔，里面重新整理了基础法则。\n它反复重申一个事实：计算机底层的物理规则，从未因为云原生、AI或硬件的进步而改变。\n硬件的进步掩盖了代码的低效，这些问题会在系统中不断堆积，直到成为无法绕开的成本。\n「过早优化」，成了平庸代码的豁免权\n所有工程师都听过一句老话：\nPremature optimization is the root of all evil.（过早优化是万恶之源）。\n它原本是提醒我们，别为了抠几行代码，把系统搞成一团乱麻。\n但在实践中，这句话慢慢变了味，成了一个免责口令——只要遇到性能质疑，一句「别过早优化」就能把所有问题挡回去。\n结果走向了另一个极端：写代码时，性能被整体忽略。抽象可以多一层，数据可以多拷贝一次，API可以写得更「通用」。\n瑞士奶酪模型：单个小漏洞没事，但是一层层叠加，对齐了会出大事\n大家总觉得将来有profiler，等真慢下来再说。\n可等系统上线，流量涌入，响应开始变拖沓，大家终于打开性能分析图，却发现屏幕上什么都没有。\n没有一个函数占掉40%的时间，没有明显的性能热点。你看到的只有一张异常平坦的火焰图——每一层都慢一点，每一个看似无关紧要的选择，都给未来埋下隐患。\n你很难指出哪里出了错，因为问题从一开始就没有集中出现——这正是Jeff Dean反复强调的一种模式。\n性能不是被某个错误决定拖垮的，而是被一连串「看起来没问题」的决策慢慢稀释掉的。\n一旦走到这一步，优化会变得异常昂贵，因为你失去了明确的下手点。\n所谓「关键的3%」，指的从来不是写完代码后再去抠字眼，而是在写第一行代码时，就要避开那些虽然方便、但明显低效的路径。\n这不只是技巧，更像一种素养。真正拉开差距的地方，往往发生在profiler还没派上用场之前。\n5ns和5ms之间，隔着整个物理世界\n如果说前面的区别发生在「已经来不及了」，那么接下来要说的是：「为什么我们会在一开始就走错路」。\n事实上，很多工程事故并不是因为「不会优化」，而是因为对「慢」没有感觉。\n在编辑器里，5ns和5ms看起来只是多了几个0。缩进一样，语法一样，在Code Review时看起来合理合规。\n但在物理世界，这些数字根本不属于同一个尺度。\nJeff Dean在清单里列出了一张延迟对照表。一旦把这些数字还原成现实中的时间，很多所谓的设计直觉会当场崩塌。\nL1缓存命中：约0.5ns，等于微观世界里的一次脉搏。\n分支预测失败：5ns，是连续十次脉搏。\n主存访问：50ns，相当于起个身，走下楼，取了个外卖。\n随机磁盘寻址：10000000ns，相当于从北京一路走到了上海。\n最早由Google工程师整理，Jeff Dean在多次演讲中用过这个思路\n如果你的方案里出现了一次磁盘寻址，后面无论代码写得多优雅、逻辑多漂亮，在物理尺度上都已经输透了。\n这就是顶级工程师脑子里的「物理地图」。他们本能地知道：哪些操作属于同一量级，而哪些操作一旦混进来，系统的节奏就彻底乱了。\n这也是「信封背面估算」（Back-of-the-envelope calculation）的价值所在。\n它是一次动手之前的排查：这个方案会触发多少次内存访问？有没有隐藏的分配？循环里会不会撞上网络IO？\n如果答案里出现了一个不合时宜的量级，这个方案就应该被扔进垃圾桶。\n很多性能问题并非「实现得不够好」，而是选错了路径。\n一旦建立起这种尺度感，很多无意义的争论就能一眼看穿。\n反直觉的真相：Google大佬的代码为什么看起来很「土」？\n真正拉开差距的地方，不在于「写得多聪明」，而在于知道哪些地方「不值得聪明」。\n翻开这份Performance Hints，我们能发现一个反直觉的事实：没有复杂的算法，很多改动看起来都有点「土」。\n但这些细碎的选择，却被Jeff Dean反复拿出来强调。\n对内存的节制\n「尺度感」让我们意识到分配内存的珍贵，在实战中，这种意识会转化成对容器的极致考究。\n为什么他们偏爱\nInlinedVector\n？因为在绝大多数场景下，它根本不碰堆内存，数据直接躺在栈上。\n这带来的是实实在在的物理收益：少一次分配，多一次缓存命中。\n同样的，使用Arena（内存池）也不只是为了管理方便，而是为了让数据在物理内存上变得连续，顺应CPU缓存的节奏。\n对数据分布的尊重\n所谓的Fast Path（快路径），本质上是承认世界是不均匀的。99%的请求和输入都比想象中普通。\n如果坚持让每一次调用都走那条「最通用、最保险」的路，实际上是在用极少数的边缘情况，绑架绝大多数的正常流量。\n清单里提到的UTF-8处理就是一个典型：现实中大量字符串其实只有纯ASCII字符。\n如果一上来就按完整的解析逻辑走，那每一个字节都在为万分之一的极端情况买单。\n看一眼，是ASCII就直接放行——这种行为，建立在对数据规律的尊重之上。\n对抽象成本的自觉\n清单里举了个例子：把Protobuf逻辑改成原生结构体，性能提升20倍，让很多人不安。\nProtobuf确实解决了跨语言和版本演进的难题，但便利从不是免费的，每一层封装、每一次解析，都是一笔隐蔽的「抽象税」。\n就像在透支信用卡，你可以尽情购物，可一旦账单寄来，就要付出相应代价。\n抽象并不会消失，只是被编译器展开，最终落实到一行行具体的实现上。\n当抽象层数不断叠加，成本也会在底层被一并兑现。\n这就是为什么他们建议在热路径里避开不必要的层级、避开那些「为了完整而完整」的设计。\n目的是让你清楚地意识到，你到底在为什么付费。\n顶级工程师关心的，从来不是如何写出最聪明的代码，而是如何避免那些本不该出现的开销。\n当你在敲键盘时，能对分配、分布、抽象成本保持警惕，很多性能瓶颈在发生之前，就已经被挡在了门外。\n想提高性能，就不能对代价视而不见\n很多人把性能理解成一种阶段性的工作：系统慢了，就开始优化；不慢，就先放一边。\n但读完这份清单，你很难再这样看待它。\nJeff Dean们反复强调的，其实不是「如何省下几纳秒」，而是「你是否真正理解自己正在使用的计算资源」。\nCPU、内存、缓存、磁盘......这些底层的物理规律并没有因为云原生或AI的流行而消失，它们只是被包装得更抽象了。\n顶级工程师之所以显得从容，是因为他们很少走到「火场」里：在写第一行代码时，他们就已经避开了那些注定昂贵的路径。\n这份Performance Hints读起来不像教程，更像是一份肌肉记忆。它不要求你处处极限优化，而是要求你在做决策时，不要假装不知道代价。\n也许真正的分界线一直是——当你写下一个循环、设计一个数据结构、决定要不要多加一层时，脑海中是否浮现出那张时间和尺度的地图。\n一旦有了它，很多平庸的代码，你就再也写不下去了。\n参考资料：\nhttps://x.com/JeffDean/status/2002089534188892256?s=20\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652658610&idx=2&sn=e6d9eff2aabc9d1932492b2ba3092f7b&chksm=f039fd9295596864c4e26aeb744bd3555bf7c96669e2e077fa4c7ff0463b977cb7961d236438&scene=0&xtrack=1#rd",
      "publish_time": 1767066600,
      "publish_date": "2025-12-30 11:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/JeffDean/status/2002089534188892256?s=20\"]",
      "add_ts": 1767136702,
      "last_modify_ts": 1767223346
    },
    {
      "id": 80,
      "article_id": "51508",
      "title": "AI 最前沿 | 大语言模型、自动驾驶、医学图像分割……",
      "description": "MIR第六期于12月出版，包含10篇免费下载的最新研究论文。内容涵盖自动驾驶中的端到端感知与预测综述、融合CNN与Transformer的RGB-event视频识别方法、用于显著性检测的CINet网络，以及结合Vision Transformer与InceptionV3的强直性脊柱炎诊断模型等前沿研究，涉及人工智能在视觉识别、医疗诊断等领域的创新应用。",
      "content": "Machine Intelligence Research\nMIR第六期已于12月正式出版，10篇最新好文免费下载，欢迎阅读！\n综述\n· Review\nA Survey on End-to-e\nnd Perception and Prediction for Autonomous Driving\nYufan Hu, Longhui Hu, Qingqun Kong, Bin Fan\nhttps://link.springer.com/article/10.1007/s11633-025-1558-0\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1558-0\n研究论文\nUnleashing the Power of CNN and Transformer for Balanced RGB-event Video Recognition\nXiao Wang,\nYao Rong, Shiao Wang, Yuan Chen, Zhe Wu, Bo Jiang, Yonghong Tian, Jin Tang\nhttps://link.springer.com/article/10.1007/s11633-025-1555-3\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1555-3\n研究论文\nCINet: Cascaded\nInteraction with Eroded Deep Supervision Strategy for Saliency Detection\nHewen Xiao, Jie Mei, Guangfu Ma, Weiren Wu\nhttps://link.springer.com/article/10.1007/s11633-025-1551-7\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1551-7\n研究论文\nA Novel Vision Transformer + InceptionV3 Hybrid Network for Accurate Diagnosis of Ankylosing Spondylitis from Computed Tomography Scans\nRiel Castro-Zunti, Eun Hae Park, Amol Satsangi, Younhee Choi, Gong Yong Jin, He\ne Suk Chae, Seok-Bum Ko\nhttps://link.springer.com/article/10.1007/s11633-024-1539-8\nhttps://www.mi-research.net/article/doi/10.1007/s11633-024-1539-8\n研究论文\nTheory of Mind Inspired Large Reasoning Language Model Improved\nMulti-\nagent Reinforcement Learning Algorithm for Robust and Adaptive Partner Modelling\nXiyun Li, Tielin Zhang, Chenghao Liu, Shuang Xu, Bo Xu\nhttps://link.springer.com/article/10.1007/s11633-025-1547-3\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1547-3\n研究论文\nCardiac Dynamic\nCharacteristics Classification on Cine MRI Using Semi-supervised Imaging Approach\nFaizan Ahmad\n,\nJing Xiong\n,\nJie Wu\n,\nJiahong Xia\n,\nZeyang Xia\nhttps://link.springer.com/article/10.1007/s11633-024-1534-0\nhttps://www.mi-research.net/article/doi/10.1007/s11633-024-1534-0\n研究论文\nSemi-s\nupervised Learning for Detector-free Multi-person Pose Estimation\nHaixin Wang, Lu Zhou, Yingying Chen, Ming Tang, Jinqiao Wang\nhttps://link.springer.com/article/10.1007/s11633-024-1524-2\nhttps://www.mi-research.net/article/doi/10.1007/s11633-024-1524-2\n研究论文\nAnswer Semantics-enhanced Medical Visual Question Answering\nYuliang Li\nang, Enneng Yang, Guibing Guo, Wei Cai, Linying Jiang, Jianzhe Zhao, Xingwei Wang\nhttps://link.springer.com/article/10.1007/s11633-025-1564-2\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1564-2\n研究论文\nLearning Eff\nicient Linear Graph Transformer via Graph-attention Distillation\nHaotian Tao, Ziyan Zhang, Bo Jiang, Bin Luo\nhttps://link.springer.com/article/10.1007/s11633-025-1541-9\nhttps://www.mi-research.net/article/doi/10.1007/s11633-025-1541-9\n研究论文\nDegree-aware Progressive Contrastive Learning for Graph Combinatorial Optimization Problems\nShiyun Zhao, Yang Wu, Yifan Zhang\nhttps://link.springer.com/article/10.1007/s11633-024-1532-2\nhttps://www.mi-research.net/article/doi/10.1007/s11633-024-1532-2\nEND\n∨\n关于Machine Intelligence Research\nMachine Intelligence Research（简称\nMIR，原刊名International Journal of Automation and Computing）由中国科学院自动化研究所主办，于2022年正式出版。\nMIR立足国内、面向全球，着眼于服务国家战略需求，刊发机器智能领域最新原创研究性论文、综述、评论等，全面报道国际机器智能领域的基础理论和前沿创新研究成果，促进国际学术交流与学科发展，服务国家人工智能科技进步。期刊入选\"中国科技期刊卓越行动计划\"，已被ESCI、EI、Scopus、中国科技核心期刊、CSCD等20余家国际数据库收录，入选图像图形领域期刊分级目录-T2级知名期刊。2022年首个CiteScore分值在计算机科学、工程、数学三大领域的八个子方向排名均跻身Q1区，最佳排名挺进Top 4%，2023年CiteScore分值继续跻身Q1区。\n2024年获得首个影响因子(IF) 6.4，位列人工智能及自动化&控制系统两个领域JCR Q1区；2025年发布的最新影响因子达8.7，继续跻身JCR Q1区，最佳排名进入全球第6名；2025年一举进入中科院期刊分区表计算机科学二区。\n▼\n往期目录\n▼\n2025年第5期 | 生成式模型、疾病诊断、步态识别、行人再识别......\n2025年第4期 | 特约专题: 具身智能\n2025年第3期 | 大语言模型、医学图像分割、图像阴影去除、写作风格变化检测......\n2025年第2期 | 常识知识获取、图因子分解机、横向联邦学习、分层强化学习...\n2025年第1期 | 机器视觉、机器人、神经网络、反事实学习、小样本信息网络...\n2024年第6期 | 图神经网络，卷积神经网络，生物识别技术...\n2024年第5期 | 大语言模型，无人系统，统一分类与拒识...\n2024年第4期 | 特约专题: 多模态表征学习\n2024年第3期 | 分布式深度强化学习，知识图谱，推荐系统，3D视觉，联邦学习...\n2024年第2期 | 大语言模型、零信任架构、常识知识推理、肿瘤自动检测和定位...\n2024年第1期 | 特约专题: AI for Art\n▼\n好文推荐\n▼\n精选好文 | 基于多模态学习的非酒精性脂肪肝病预测\n南京大学Kai Ming Ting团队 | 综述：基于孤立机制的异常检测研究\n南洋理工大学肖佳平 等 | 基于深度强化学习的异构机器人系统目标搜索与导航\n南开大学程明明团队 | MCANet：基于多尺度交叉轴注意力的医学图像分割\n自动化所吴书 等 | GraphFM: 用于特征交互建模的图因子分解机\n香港理工大学周立培团队等 | 综述: 面向以物体为中心的机器人操作的具身学习\n清华大学朱军团队 | DPM-Solver++：用于扩散概率模型引导采样的快速求解器\n南航张道强团队 | 综述：基于脑电信号与机器学习的注意力检测研究\n可信图神经网络的全面综述：隐私性、鲁棒性、公平性和可解释性\n哈工大江俊君团队 | SCNet：利用全1X1卷积实现轻量图像超分辨率\n自动化所刘成林团队 | 统一分类与拒识: 一种一对多框架\n上海交大张拳石团队 | 综述: 基于博弈交互理论的神经网络可解释性研究\n专题好文 | 再思考人群计数中的全局上下文\n专题好文 | Luc Van Gool团队: 基于分层注意力的视觉Transformer\n浙江大学孔祥维团队 | 综述: 迈向真正以人为本的XAI\n澳大利亚国立大学Nick Barnes团队 | 对息肉分割的再思考: 从分布外视角展开\n前沿观点 | Segment Anything并非一直完美: SAM模型在不同真实场景中的应用调查\n精选好文 | 推荐系统的波纹知识图谱卷积网络\n复旦邱锡鹏团队 | MOSS: 一个开源的对话式大语言模型\n自动化所黄凯奇团队 | 分布式深度强化学习：综述与多玩家多智能体学习工具箱\n约翰霍普金斯大学Alan Yuille团队 | 从时序和高维数据中定位肿瘤的弱标注方法\n专题综述 | 大语言模型中的知识生命周期\n精选综述 | 零信任架构的自动化和编排: 潜在解决方案与挑战\n欧洲科学院院士蒋田仔团队 | 脑成像数据的多模态融合: 方法与应用\n金耀初团队&郑锋团队 | 综述: 深度工业图像异常检测\n专题好文 | 创新视听内容的联合创作: 计算机艺术面临的新挑\n▼\nMIR资讯\n▼\n影响因子全球第6名！MIR稳步进军世界一流期刊行列\n进阶前5%！MIR登榜”中国最具国际影响力学术期刊”\n进阶前5%！MIR登榜”中国最具国际影响力学术期刊”\n喜报 | MIR 首次入选中科院期刊分区表计算机科学类二区\n喜报！MIR入选中国科技期刊卓越行动计划二期项目\n特别提醒！请认准MIR官方渠道，谨防受骗\n前进20名！MIR再度跻身国际影响力TOP期刊榜单\n喜报 | MIR入选图像图形领域 T2级 “知名期刊”！\n喜报 | MIR被 ESCI 收录！\n喜报 | MIR 被 EI 与 Scopus 数据库收录\n点击\"阅读原文\"进入当期目录",
      "article_url": "https://mp.weixin.qq.com/s/F3vreise7jUhzz10gE7fUA",
      "publish_time": 1766999880,
      "publish_date": "2025-12-29 17:18",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://link.springer.com/article/10.1007/s11633-025-1558-0\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1558-0\", \"https://link.springer.com/article/10.1007/s11633-025-1555-3\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1555-3\", \"https://link.springer.com/article/10.1007/s11633-025-1551-7\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1551-7\", \"https://link.springer.com/article/10.1007/s11633-024-1539-8\", \"https://www.mi-research.net/article/doi/10.1007/s11633-024-1539-8\", \"https://link.springer.com/article/10.1007/s11633-025-1547-3\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1547-3\", \"https://link.springer.com/article/10.1007/s11633-024-1534-0\", \"https://www.mi-research.net/article/doi/10.1007/s11633-024-1534-0\", \"https://link.springer.com/article/10.1007/s11633-024-1524-2\", \"https://www.mi-research.net/article/doi/10.1007/s11633-024-1524-2\", \"https://link.springer.com/article/10.1007/s11633-025-1564-2\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1564-2\", \"https://link.springer.com/article/10.1007/s11633-025-1541-9\", \"https://www.mi-research.net/article/doi/10.1007/s11633-025-1541-9\", \"https://link.springer.com/article/10.1007/s11633-024-1532-2\", \"https://www.mi-research.net/article/doi/10.1007/s11633-024-1532-2\"]",
      "add_ts": 1767136711,
      "last_modify_ts": 1767193558
    },
    {
      "id": 86,
      "article_id": "51558",
      "title": "在线教程丨David Baker团队开源RFdiffusion3，实现全原子蛋白质设计的生成式突破",
      "description": "David Baker团队推出RFdiffusion3（RFD3），首次实现基于非蛋白质组分（如配体、核酸）的全原子级蛋白质设计。该模型采用轻量信息提取模块，仅用2层Pairformer即完成高效结构生成，参数量仅1.68亿，显著降低计算成本。RFD3可精确控制氢键、配体接触与核酸相互作用，成功应用于DNA结合蛋白与酶的设计，展现出强大功能拓展性。相关教程已上线HyperAI超神经平台，支持一键部...",
      "content": "近年来，利用生成式深度学习方法在新功能蛋白质设计方面取得了显著进展。目前包括 RFdiffusion（RFD1）和 BindCraft 在内的大多数方法，均采用氨基酸残基水平的蛋白质表示，已能够成功设计蛋白质单体、组装体以及蛋白质-蛋白质相互作用体系，但其分辨率仍不足以精确设计与非蛋白质组分（如小分子配体与核酸）发生特异性侧链相互作用的结构。\nRFdiffusion2\n（RFD2）虽然在这一局限上有所克服，但其扩散过程仍局限于残基层面，难以进一步拓展至与非蛋白质组分形成额外的侧链相互作用。\n现有研究表明原子级扩散过程可用于生成蛋白质主链，并可扩展至侧链建模，但这些尝试仍未实现与非蛋白质组分间相互作用的有效建模。\n基于此，\n诺奖得主 David Baker 团队推出了\nRFdiffusion3\n（RFD3），能够在配体、核酸及其他非蛋白质原子组成的结构中生成蛋白质三维构象。\n由于该模型对所有聚合物原子均进行显式建模，因此能够更简便、更高效地处理诸如酶设计等任务中的复杂原子级约束条件。RFD3 原生的全原子架构还大大简化了原子级约束的规范，提供了对氢键、配体接触及核酸相互作用的精确控制。\n不同于 AlphaFold3（AF3）依赖计算密集的\nPairformer\n模块从输入序列中提取距离等信息，研究团队将信息提取模块设计得更为轻量，\n使得 RFD3 将 Pairformer 的层数从 48 层大幅缩减至仅 2 层，从而显著降低计算开销，最终模型仅包含 1.68 亿可训练参数。\n研究团队通过设计并实验表征 DNA 结合蛋白与半胱氨酸水解酶，展示了 RFD3 的广泛适用性，其能够基于任意非蛋白质原子环境快速生成受复杂原子级约束引导的蛋白质结构，将进一步拓展蛋白质设计所能实现的功能范围。\n「RFdiffusion3：蛋白质设计模型」现已上线 HyperAI 超神经官网（hyper.ai）的「教程」板块，快来一键部署体验！\n恰逢新年，HyperAI超神经为大家准备了算力福利，\n新用户注册后使用兑换码「2026 Happy New Year」即可获得 2 小时 NVIDIA\nGeForce RTX 5090\n使用时长，\n数量有限，快来领取节日福利吧！\n教程链接：\nhttps://go.hyper.ai/3E9FY\nDemo 运行\n1.进入 hyper.ai 首页后，选择「RFdiffusion3：蛋白质设计模型」，或进入「教程」页面选择。进入点击「在线运行此教程」。\n2.页面跳转后，点击右上角「Clone」，将该教程克隆至自己的容器中。\n注：页面右上角支持切换语言，目前提供中文及英文两种语言，本教程文章以英文为例进行步骤展示。\n3.选择「NVIDIA GeForce RTX 5090」以及「PyTorch」镜像，按照需求选择「Pay As You Go（按量付费）」或「Daily Plan/Weekly Plan/Monthly Plan（包日/周/月」，点击「Continue job execution（继续执行）」。\nHyperAI 为新用户准备了注册福利，仅需 $1，即可获得 20 小时 RTX 5090 算力（原价 $7），资源永久有效。\n4.等待分配资源，当状态变为「Running（运行中）」后，点击「Open Workspace」进入 Jupyter Workspace。\n效果演示\n页面跳转后，点击左侧\nREADME\n页面，进入后点击上方 Run（运行）。\n稍等片刻后，下滑显示 RFD3 进行的结构预测结果。\n以上就是 HyperAI超神经本期推荐的教程，欢迎大家前来体验！\n教程链接：\nhttps://go.hyper.ai/3E9FY\n内容中包含的图片若涉及版权问题，请及时与我们联系删除",
      "article_url": "https://hub.baai.ac.cn/view/51558",
      "publish_time": 1767172440,
      "publish_date": "2025-12-31 17:14",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://go.hyper.ai/3E9FY\"]",
      "add_ts": 1767193283,
      "last_modify_ts": 1767309619
    },
    {
      "id": 88,
      "article_id": "51556",
      "title": "我们等了17年的AI「贾维斯」，这一次真正现身了？",
      "description": "Hey Tuya正将人类对“超级AI助手”的幻想变为现实，如同《光环》中的Cortana、《钢铁侠》里的贾维斯和电影《她》中的智能伴侣，它以高度智能化的服务悄然融入日常生活，成为真正的“智能管家”，改变人机交互方式，重塑生活体验。",
      "content": "新智元报道\n编辑：定慧 桃子\n【新智元导读】\n人类对「超级助手」的憧憬，早已深植于对未来的想象中。如今，幻想正走进现实。Hey Tuya，一个真正融入生活的「智能管家」，走出屏幕悄然改变生活的每一刻。\n多少年来，人类对「超级 AI 助手」的想象从未停止。\n从游戏《光环》中伴随士官长的\nCortana\n，到《钢铁侠》里运筹帷幄、无所不在的\n贾维斯 (JARVIS)\n，再到电影《她》中那个细腻温柔、触及灵魂的\nSamantha\n……\n这种想象跨越了载体：它有时是全息投影下的一抹幽蓝，有时是耳机里的一段磁性声波，有时则是深藏于装甲背后的跳动数据。\n这些形象寄托了人类最深层的渴望：我们不仅在寻找一个\n无所不知的工具\n，更在期待一个\n永不背叛的伙伴\n。\n它们是人类智慧的延伸，也是我们孤独灵魂在数字荒原上的回响。\n我们所期待的，早已超越了手机屏幕上的简单问答，而是一个活生生的「智能体」。\n它能感知环境、精准理解意图，调用现实资源主动提供服务，还能持续进化成长。甚至，在你尚未开口之前，就已做好了准备。\n如今，这一想象正逐渐被拉入现实！\n近日，AI云平台服务提供商涂鸦智能发布了「超级AI助手」——\nHey Tuya\n，描绘出科幻想象的现实版雏形。\n它是基于多智能体（Multi-Agent）协同架构的「生活管家」，打破了手机和电脑屏幕的「枷锁」。\n不论是涂鸦APP、智能音箱，还是AI玩具、中控屏等任意入口，皆可唤醒。\n作为「物理AI」的调度核心，它全面融入了人类的物理生活空间：\n一身兼多职，是办公助理、生活秘书，也是日常规划师、健康教练......主动在生活中为人类提供帮助。\n不仅如此，Hey Tuya将具备短期和长期记忆能力，可以学习用户习惯。\nHey Tuya的诞生，标志着我们距那个由AI无缝编排的生活又近了一步。\n全场景覆盖的超级智能体\nAI生活助手Hey Tuya最大突破在于，实现了多端协同，让AI无处不在。\n它不再依赖于任何单一入口，通过涂鸦APP、智能音箱、AI玩具、中控屏，甚至是手腕上的智能手表，只需一句——\nHey Tuya，便能唤醒全天候的AI生活助理。\n这种跨空间、跨设备的无缝协同，是Hey Tuya体验的核心，升维覆盖到了全生活场景的「环境智能」。\nHey Tuya不仅仅是一个聊天机器人，更像一个管家，能够学习用户的作息规律和环境偏好，实现从「被动响应」到「主动智能」的跨越。\n家庭安全守护者\n：提供24小时全时段安全守护，支持画面识别并将其转化为直观的语音或图文推送。\n节能专家\n：通过实时监测全屋能耗，主动提供节能策略（如热水器定时开关），降低碳足迹与电费。\n健康与工作助手\n：化身健康生活教练，支持卡路里识别、睡眠及运动追踪；同时担任办公助理，提供会议纪要生成、实时翻译及思维导图功能。\n生活秘书\n：细致管理家庭备忘、宠物喂食、植物养护等日常琐事，让生活井然有序。\n让我们想象未来的某一天（这一天或许并不遥远）。\n早上醒来时，Hey Tuya协同智能音箱自动播报今日气候情况、打开轻音乐，打开AI调光、自动拉开窗帘。\nHey Tuya的\nAI照明\n已经从简单的「远程开关」进化为具备「感知、逻辑与进化」能力的\n智慧光环境系统\n。\n用户无需手动配置复杂的参数。\n通过Hey Tuya，只需输入「我要浪漫的晚餐氛围」，AI照明专家便会提取色调、亮度、饱和度等参数，秒级还原并生成匹配的照明方案。\n当你离家后，Hey Tuya根据设定，协同智能电表、智能插座等开启AI节能。\n还可以定制多种家庭能源管理方案，并且内置了多种节能策略。\n当你在工作的时候，Hey Tuya的AI安全守护能够帮助你关注每一个你所在意家庭场景。\n尤其可以随时感知家中孩子的一举一动。\n出门在外，Hey Tuya联动智能门锁等设备，识别异常事件，守护家庭安全。\nHey Tuya提供了丰富的硬件支持，从穿戴、音箱，到玩具、家电，甚至还有宠物和骑行产品。\nHey Tuya还提供了丰富的AI原生应用。\n比如可以识别各种鸟类的AI镜头，在拍摄后还可制作为贴纸收集。\nHey Tuya还有AI健康功能，比如可以通过镜头自动识别食物卡路里，并做好日常的热量摄入管理。\n还可以和Hey Tuya对话来获得推荐食谱。\n技术支撑：自研PAE引擎\nHey Tuya的智能体验，并非空中楼阁。\nHey Tuya能够实现精准控制与毫秒级响应，离不开涂鸦官网展示的核心技术底座——\nPAE（Physical AI Engine）系统架构\n。\nPAE部署了覆盖全球主流地区的AI-Device Real-Time Network（AD-RTN)边缘加速网络，基于AD-RTN网络，涂鸦构建了T-RTC（Tuya Real-Time Communication）一套高可靠、低时延、强对抗、低门槛的实时通信系统。\n在此之上，涂鸦构建了面向自然语言多模态交互的Conversational AI Engine、面向视觉理解的Vision AI Engine，以及面向物理设备通信与控制的IoT Intelligence Engine。\n依托OmniMem个体长记忆技术，PAE能够在多模态交互、设备行为模式、场景意图等维度实现持续学习与记忆，使 AI 能真正理解用户偏好与空间习惯。\n此外，通过Adaptive Expert System（AES）专家系统与Dynamic Orchestration Agent（DOA）智能体编排引擎，PAE让AI的认知与决策能力与真实世界的智能设备深度耦合，实现从感知、计算到执行的完整闭环，形成可成长、可自我优化的智能空间。\n记性好：它是最懂你的「老朋友」\n传统的AI往往「聊完就忘」，但PAE内置的\nOmniMem长记忆引擎\n就像人类的大脑。\n它不仅能秒级想起你上周说过的话，还能理解你的生活习惯（比如你习惯周五晚看电影时调暗灯光）。\n它甚至能做到「该记的记，该忘的忘」，比你更懂你。\n反应快：交流零时差，沟通不费劲\n为了不让AI变成「迟钝的木头人」，涂鸦打造了\nAD-RTN（AI-Device Real-Time Network） 全球加速网络\n。\n基于多年全球化的技术积累，涂鸦构建并部署了覆盖全球主流地区的  AI-Device Real-Time Network（AD-RTN）边缘加速网络 ，并在AD-RTN基础设施之上，搭建了 Tuya Real-Time Communication（T-RTC） 一套高可靠、低时延、强对抗、低门槛的实时通信系统，为AI与设备、人与AI之间的实时交互提供稳定保障。\n秒级响应\n：\n无论你在地球哪个角落，和 AI 对话的延迟比眨眼还短。\n极速打断\n：\n你可以像和真人聊天一样，随时打断它，它能立刻反应，不再尴尬地自说自话。\n抗弱网能力\n：网络不稳定情况下，它也能保持在线，不掉链子。\n边缘加速网络（AD-RTN）支持全球主要国家和地区平均网络时延低于86毫秒！\n多才多艺：能听、能看、还会干活\nPAE 整合了一整套「感官系统」，让 AI 硬件变得全能：\n对话引擎Conversational AI Engine让AI听的真。\n该引擎集成了高精度语音活动检测（VAD），支持300毫秒的「极速打断」与800毫秒的「优雅打断」，在流畅响应与误判控制间取得最佳平衡；语音识别（ASR）方案覆盖全球 60 余种语言，在主流语种上实现行业领先的词（字）错率表现，从源头保障交互准确性；文本转语音（TTS）支持全球超60种语言、300多种音色及情绪增强，让AI的「声音」更加自然、拟人且富有情感。\n视觉引擎\nVision AI Engine让AI看的懂\n。\n像摄像头、机器人通过\nVision AI\n引擎，能真正看清环境，帮你守护家庭或分析场景。\n中控引擎IoT Intelligence Engine成为「万能遥控器」。\n能指挥家里所有的智能设备协同工作，把复杂的指令变简单。\n开放包容：让开发者「搭积木」造 AI\n为进一步提升开发效率与系统可控性，PAE架构创新性引入了智能体编排引擎\n——\nDynamic Orchestration Agent（DOA）\n。\nDOA 通过可视化的智能体编排方式，帮助开发者\n快速构建、验证并迭代复杂的AI应用逻辑\n。\n以前开发一个 AI 硬件要几个月，现在通过\nDOA智能体编排引擎\n，开发者就像玩拼图或搭积木一样，把语音、视觉、控制等功能拽到一起，\n最快1天就能搞定\n。\n这大大降低了创新成本，意味着未来我们会看到更多新奇、好用的智能装备出现在生活中。\n「生活Agent」的星辰大海\n让AI走出屏幕，走进生活\n「硅谷精神之父」Kevin Kelly在其著作《2049：未来1000天的可能》，曾做出了预言：\nAI将成为我们生命的隐形合作者，它在我们身边，不再被我们察觉。\n这一洞见，恰恰描绘了AI的终极形态，即无感、无形，却又无处不在，如空气般融入我们日常的肌理。\n近年来，多模态大模型能力不断迭代跃升，为AI Agent在真实世界的执行和操作中，提供了更多的可能。\n甚至，OpenAI总裁Greg Brockman等多位大佬表示，「2025年是Agent的元年」。\n与此同时，物理AI（Physical AI）也成为了下一个前沿。老黄在公开演讲中，不止一次提到物理AI的重要性。\n它不止在虚拟世界中响应的软件，能嵌入、连接实体设备与环境互动。\n这就相当于，在数字世界和真实世界之间搭一座「桥」，让AI不仅能想，还能做实际的事儿。\n还有并行生长的「世界模型」，让AI逐渐去模拟、预测、推理可能发生的情况，而不是简单生成像素级输出。\n李飞飞World Labs推出的Marble、LeCun即将官宣的初创AMI Labs，都是典型代表。\n纵观整个发展历程，AI综合能力正迈向新的高度，但现实的体验却存在明显的「断层」。\n传统AI Agent核心局限在于「单点智能」，大多被禁锢于单一设备的「数字牢笼」中。\n你的手机并不了解，智能音箱正在播放什么，你的办公助理也不知道家里空调，是否需要提前开启。\n它们受限于手机、电脑屏幕里，指令是一次性的，因场景割裂而无法协同，只能被动响应。\n一个能真正跨越设备、穿梭于不同生活场景的AI，似乎总是遥不可及。\nHey Tuya正是为了解决这一断层而生，涂鸦庞大的硬件生态，开放、中立、国际化的生态系统，为\nPhysical AI\n开发者提供了肥沃的土壤，这也是涂鸦对未来智能生活场景的深度布局。\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659227&idx=1&sn=62b162ea0cff09394d3207ac486e20d1&chksm=f085bef7006bf565abfdcd3d16c7e484adc5166b190a15cd186c1415ae86244f128205dc1880&scene=0&xtrack=1#rd",
      "publish_time": 1767172200,
      "publish_date": "2025-12-31 17:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767193293,
      "last_modify_ts": 1767309630
    },
    {
      "id": 94,
      "article_id": "51550",
      "title": "卡帕西推荐的AI Coding指南：3招教你效率翻倍",
      "description": "AI Coding热潮持续升温，大神卡帕西和OpenAI总裁Greg Brockman力荐一份高效Coding Agents指南。该指南由Swift开发者、AI驱动开发专家Peter Steinberger撰写，结合实战经验，提出三招提升开发效率的方法，帮助开发者快速交付。内容聚焦AI辅助编程的最佳实践，受到广泛好评，被誉为AI时代程序员必备技能指南。",
      "content": "闻乐 发自 凹非寺\n量子位 | 公众号 QbitAI\nAI Coding火到不用多说，但怎么用才最高效呢？\n这份连大神卡帕西和OpenAI总裁Greg Brockman都在转发推荐的Coding Agents指南，用3招教你快速交付。\n大神们在转，网友也在夸！\n这份实战指南的作者是Swift开发出身、深耕AI驱动开发领域的大神\nPeter Steinberger\n，他也是一位AI Coding重度爱好者，已经写了很多份实战经验博客。\n简单总结一下今天的这篇AI Coding指南：先按任务类型选对模型，再重构工作流提速，但要捋清人机分工。\nPeter不仅给出了自己的模型配置，最后还有实用小技巧～\n三大关键策略\n按任务类型选对模型\n大家用AI编码，很多时候是不是一个模型用到底？\n结果一到大项目就卡壳，小项目修改还慢。问题呢，就出在“没给模型找对活儿”。\n人家这份指南里就说了，第一步就得先按任务类型给Coding模型分好工。\n大任务就用Codex，小任务Opus更好使\n。\n比如，搞几十页的工程规范落地、项目重构这种大活儿就直接上Codex，它有个特点，开始写代码前会默读文件，把项目逻辑摸透，虽然比Opus多花点时间，但对复杂需求的完成度更好。\nPeter之前重构Opus 4.0的旧代码，Codex花了几个小时读透了整个项目，不仅没漏关键逻辑，还修复了2个隐藏Bug。\n如果只是小范围修改这种比较零碎的任务，那Opus更合适。它不用读很久的文件，响应很快，基本上几分钟就能出结果。\n不过，要进阶的话，首选GPT-5.2-Codex，直接一步到位。\n现在Peter最常用的就是GPT-5.2-Codex，尤其是high模式，不管搭Chrome扩展的前端还是写Go语言的CLI工具，它都能兼顾速度和准确率，也不用在Codex和Opus之间来回切换了。\n在这里，Peter还给出了自己的配置。\n重构工作流\n选对模型是基础，而真正让作者同时推进8个项目还不慌的是他这套定制化的工作流。\n因为每天会冒出很多新的想法，比如“给Clawdis加个控制卧室温度的功能”“写个CLI查外卖进度”……\n但这些想法Peter并不会记在备忘录里，而是直接扔进Codex的排队列表。\n比如开发“YouTube视频总结Chrome扩展”时，他一边让Codex验证CLI核心逻辑（把视频转成Markdown），一边把 “加浏览器弹窗提醒”“支持本地存储” 等想法塞进队列，Codex会按优先级慢慢处理，不用他盯着催，也不怕遗忘在备忘录里。\n而且，一个小tips是坚决不回滚！\n“构建软件就像爬山，不用笔直往上走，绕点路、退两步都正常，关键是别在‘要不要回滚’上浪费时间。”\n遇到相似的功能，不用从头写\n。\n比如作者之前在VibeTunnel项目里做过 “字符流输出”，后来开发Clawdis时需要类似功能，他直接让Codex“去../VibeTunnel文件夹里看看，照这个逻辑给Clawdis加一个”，10分钟就适配好了。\n甚至搭新项目时，他也会让Codex参考旧项目的结构，比如“按../Sparkle项目的目录格式，搭一个新的日志工具”，这时候模型就能自动复制适配。\n人机分工\n当然了，写代码这件事也不能全靠AI，这时候就得来个人机分工，原则很简单：\nAI干执行，人做决策\n。\n这些事一定要自己做：选哪个依赖库、系统架构怎么设计、功能优先级怎么排……\n写基础代码、修复已知bug、生成GUI界面、更新项目日志，甚至“注册域名”“改DNS配置”这种琐事，都可以交给AI。\n作者举了自己实战中的两个例子。\n在选择用Go语言做CLI工具前，他花了半天研究“Go的类型系统是不是更适合AI生成代码”“有没有常用的Go库能复用”，确定之后再让AI开写，最后也没怎么返工。\n不过在开发数据可视化工具时，就直接让AI花了20分钟写核心代码，再让它帮忙测试，也不用自己切设备操作。\n实用小技巧\n除了上面的核心方法，作者还分享了几个挺实用的小操作，都是踩坑总结出来的。\n第一个是\n开发先从CLI开始，再扩展功能\n。\n不管想做什么项目，先搭个简单的CLI工具验证核心逻辑，比如他之前做“YouTube视频总结Chrome扩展”的时候，先写了个能把视频转成文字、再用模型总结成 Markdown的CLI版本。\n确认能跑通后，才让AI搭前端、做浏览器扩展，一天就搞定了。\n第二个是\n让文档帮模型记上下文，不用反复提需求\n。\n在每个项目里建个docs文件夹，把“系统设计思路”“功能说明”写进去，再用脚本让AI读这些文档。\n比如Peter在docs里写了“Clawdis这个项目要支持控制家里的灯光”，之后让AI加新功能时，不用反复说“要和灯光控制兼容”，模型就会自己读文档，减少了沟通成本。\n第三个是\n单人开发直接提交主分支，不用搞复杂分支\n。\n要是你一个人开发，那就不用建“dev分支”“feature分支”，改完直接提交主分支。\nPeter表示：\n“分支多了反而容易有合并冲突，Codex有时候会自动建临时工作区处理混乱代码，改完合并回主分支，比手动管理分支简单多了。”\nPeter说的这些坑你有没有踩过？\n还有啥AI Coding实用小技巧欢迎分享！\n原文地址：https://steipete.me/posts/2025/shipping-at-inference-speed\n—\n欢迎AI产品从业者共建\n—\n📚\n「AI产品知识库」\n是量子位智库基于长期产品库追踪和用户行为数据推出的飞书知识库，旨在成为AI行业从业者、投资者、研究者的核心信息枢纽与决策支持平台。\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859368&idx=2&sn=5b52dd877d2d3990630a0f976b8724fd&chksm=e99959d2a8711c668f514016db1a4a30c74c0757c7a892311dcb9740b10d80ec5a9bb65b4758&scene=0&xtrack=1#rd",
      "publish_time": 1767168600,
      "publish_date": "2025-12-31 16:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://steipete.me/posts/2025/shipping-at-inference-speed\"]",
      "add_ts": 1767193317,
      "last_modify_ts": 1767309653
    },
    {
      "id": 96,
      "article_id": "51548",
      "title": "千人千面的真人级AI名师，劈开教育「不可能三角」",
      "description": "「与爱为舞」推出的AI导师开创教育领域新应用，以自然流畅的讲课节奏和互动实现个性化教学，支持一对一辅导。自年初上线已服务百万用户，突破传统教育中规模、质量与成本难以兼顾的“不可能三角”，推动AI在教育场景的深度落地。",
      "content": "Jay 发自 凹非寺\n量子位 | 公众号 QbitAI\n注意看，这是一个教育领域的AI应用新物种——\n咱就是说，这讲课节奏，这语气，这互动，也太自然了。\n更重要的是，它不仅能「像老师一样讲课」，还能针对每一位学员进行一对一的个性化教学。\n这位AI导师，出自一家名为「与爱为舞」的AI原生应用企业。自年初上线以来，已累计为百万级用户提供学习陪伴与一对一讲解服务。\n教育行业，\n向来是\n个\n「规模、质量、成本」的不可能三角\n。\n既能做到千人千面，又能服务百万名学员，还几乎看不出是AI……更是难上加难。\n它究竟是怎么做到的？\n与爱为舞用来劈开这个不可能三角的，是一把\n硬核的技术巨剑\n。\nAI教育，要的不止「答案」\n而铸造这把技术巨剑，有三块核心组成部件：「模型+语音+工程」。\n先看\n模型\n——\n得益于CoT的Scaling，大模型解决复杂问题的能力指数级增长，「做题」水平突飞猛进，甚至能斩获「奥赛金牌」。\n摘得奥赛桂冠，AI只需要给出标准答案。但搞教育不行。\n先来看一个简单的英语语法题：\nLily expects\n_\nher grandparents in the countryside next month.\nA. visiting｜B. to visit｜C. to have visited｜D. having visited\n大模型给出的解答如下：\n这道题的正确答案是B. to visit。\n核心考点解析：\n动词固定搭配，动词 expect\n（期望、预料）\n的常用用法是——\nexpect to do sth.\n（期望做某事）\n，后面需要接不定式\n（to + 动词原形）\n作宾语。\nB选项to visit是不定式的一般式，用来表示与谓语动词\n（expect）\n同时或之后发生的动作，符合 “下个月看望祖父母” 的将来时态逻辑。\n我可以帮你整理一份常见接不定式作宾语的动词清单，方便你记忆，需要吗？\n答案是对了，看起来好像也讲了解题过程，但如果拿这套方法教学员，那肯定是要被家长投诉的啊……\n完全没有引导学员思考，一上来就把答案透露了。就像个纯天赋型学霸，风驰电掣做完题，然后猛地丢给你一个结果，问你：「我说的对不对！」随后才给出一串看似头头是道的分析。\n不过，硅基大佬，小弟我根本听不明白你在说什么啊！\n最后还要给你一份「动词清单」，直接默认教学等于枯燥的背诵，而没去想怎样引导学员的主观能动性。\n归根结底，通用大模型的设计初衷就不是教育。它拼尽全力，只想向用户证明一件事——「厉害吧，哥啥都知道！」\n古人讲：\n授人以鱼，不如授人以渔\n。导师如果光顾着自己拿金牌，这师生关系就乱了套了。\n想要成为一名好导师，AI需要学会放低姿态，真正关心学员的课堂体验。\n首先，AI得明白各学科的核心知识图谱、关键考点和常见解题方法，这些才是学员能服用的，是最基本的「知」。\n在此之上，AI还得学习名师是怎么设计讲解顺序的，并从中总结归纳出一套顶尖教师的授课方法论。这是更高维度的「知」。\n陆游讲，「纸上得来终觉浅，绝知此事要躬行。」\n「知」总是相对容易的，重点是如何把纸上谈兵那套，搬到现实世界里实践起来。\n所幸，「行」方面，与爱为舞有相当充足的弹药。\n据悉，他们已积累了约百万小时的音视频互动数据，特别是包含大量业内TOP级名师的授课视频。\n在此基础上，团队又根据学员的认知水平与学习态度，构建出多类型的「虚拟学员」，让他们与AI导师进行「搏击」，每周又能收获\n数\n万小\n时的合成数据\n。\n这些数据在经过筛选与清洗后，会交由专业教研进行把关。\n具体而言，\n教师\n们会\n把自己多年的「教学经验」，根据场景具象化为一条条思维链\n，最终汇集成一本「好老师红宝书」：\n每个知识点该如何拆解，与学员互动时如何循循善诱……不止要让AI学会怎么讲课，更要明白「为什么要这么讲」。\n这种手把手教的方式效果很好，但成本也相当高。\n随着方法论逐渐成熟，团队索性将这一环节也自动化，让AI模仿专业教研参与数据标注。\n备考资料准备就绪，下面就该着手训练了。\n第一步，照猫画虎。\n那些相对容易标准化的知识，已体现在标注数据之中。AI需要做的，是通过模仿专业教师的思维链，逐步摸索出每一个教学动作背后的真实意图。\n这一微调过程，能大幅降低AI「自我发挥」带来的的幻觉率，同时培养更稳定的推理能力与泛化能力。\n能做到这一点，就算是打牢了基本功。\n最基本的教法、节奏和经验都已被「固化」，能以标准化形式面向所有学员输出，教学质量的下限得到保障。\n但如果目标只是及格，这件事就没意义了。\n师傅能陪伴的路程就到这。接下来，得能靠AI自己上路修行。\n第二步，终于到了大家喜闻乐见的\n强化学习\n环节。\n在教育这个场景下，与爱为舞的奖励函数围绕教学路径规划质量、教学有效性与教学灵活性等维度设计，通过GRPO给AI做强化。\n这步结束，AI彻底出师——不仅能够完成授课任务，还能驾驭课堂节奏，提高趣味性，根据不同学员灵活调整教学策略。\n那么接下来，就该真正走进「教师资格证考场」了。\n不过，教育不是一个有标准答案的任务，Benchmark肯定是行不通。笔试应该如何设计？\n与爱为舞的做法很简单，甚至有些「粗暴」——\n笔试啥，直接把AI丢到讲台上\n，看学员的真实反应。\n第一步，是在\n模拟课堂\n中试水。\n这个课堂由多类型的模拟学员组成，团队会按照真实分布规律注入一批线上数据，再由评分模型从多个维度对AI导师打分。\n模拟课堂如果表现不错，AI会迎来更严苛的终极试炼场——\n直连真实教学一线\n。\nAI能否驾驭高度不确定的真实课堂？是否真的能摆脱照本宣科？答案，只能由学员来评判，再好的数据标注导师也帮不了。\n即便成功拿下了「教师资格证」，但教学，依然是个终身学习的过程。\n正式上线后，海量的学员数据会被持续建模，AI导师将基于每一位学员的专属档案库，为其定制个性化课程。\n至此，AI导师才算具备了千人千面的能力。不仅下限有保障，上限也很高。\n「真人级」AI导师\n通过「知」与「行」的双重训练，与爱为舞得以将通用大模型，塑造成一个真正懂教学的名师AI模型。\n然而，再聪明的模型，无法与学员真实互动，最终仍会沦为一颗「缸中之脑」。\nAI导师需要「耳朵」。\n作为导师，连学员的问题都听不清楚，最后聊的牛头不对马嘴。不仅显得导师呆若木鸡，学员的积极性也会大打折扣。\n但现实是，课堂不是录音棚。\n真实环境往往充斥着噪音\n，如果有电视，甚至会出现多个人声掺杂在一块的情况。\n即便能输入干净音频，中国有各种各样的方言，不同学员的咬字发音习惯也不同，识别难度相当高。\n雪上加霜的是，在传统ASR范式下，输入模型的只是一段孤立的语音，基本没什么上下文。一旦放到教学场景下，AI很容易把同音字混淆。\n例如，「极限」和「极线」。\n前者是微积分中的核心概念，后者则属于二次曲线相关的几何术语。二者在语义上截然不同，发音却完全一致，如果没有上下文，仅凭语音几乎无法区分。\n为解决这个问题，与爱为舞基于其长期积累的教育场景与课堂教学数据，自研了一套\n多模态语音理解大模型\n，让语音识别不再只「听声音」，而是能够理解所处的教学上下文。\n在此基础上，团队进一步自研了\n声纹降噪模型\n，可以将学员和家长说话的声音区分开。\n事实证明，凭借「上下文理解+声纹降噪」，ASR识别效果有了质的飞跃：句准确率从行业内开放API的80%左右的最好效果，大幅度提升至\n95%以上\n，接近真人理解识别水平。\n听清楚学员的问题，思考完毕，下面就该导师开口指点迷津了。\n目前，行业主流语音合成架构基本都是LLM或者LLM+Flow/Diffusion的方案。\n真用到课堂里，会暴露出三个问题：人机味明显、不像在上课、不支持双向实时交互。\n下面看看，与爱为舞是如何迈过这三道坎的。\n先来最直观的——\n人机感\n。\n在底层架构上，团队采用了LLM+Flow方案，引入了两类speech token：一类负责声音本身的细节，一类负责语义和表达节奏。\n在此基础上，结合强化学习，可以让AI学会正常说话应有的抑扬顿挫。\n不过，光会说话可不行，老师上课得有个「老师」的样。\n为此，团队拿出了大量真实课堂数据，对不同学科、不同导师的讲课方式进行了建模：有的导师说话像机关枪，有的导师则更慢条斯理。\n落地时，团队还会为每位主讲名师单独设计录制脚本。这样，数据收集效率更高，还能最大程度还原名师声线，保证声音的「质感」。\n具体效果如何嘛，我们可以一起听听下面这两段音频。\n（文本：\n接下来我们看这个题，图中表示水蒸气直接变成冰的过程）\n这是第三方TTS，不仅表现力较弱，还出现了发音错误，如果是上课很容易出戏。\n相比起来，这段是不是「活人感」足了很多？\n这正是自研模型的优势，发音更自然，更稳定，情感表现也更好。\n至于\n双向实时交互\n，AI导师需要边说话边理解学员是否在主动打断询问导师问题，并且做出及时的响应，这是AI导师智能与否最重要的能力之一。\n为此，团队研发\n流式语义VAD和打断模型\n，能够让AI导师实时识别学员是否有真实打断意图，识别准确度可以达到90%以上。\n而为了让AI导师真正「站上讲台」，团队还为其配套设计了逼真的数字人形象：口型、面部表情与肢体动作高度同步，且支持实时互动。\n这下，AI导师可算是凑齐了自己的莲藕肉身三件套——「耳朵+嘴巴+身体」。\n当AI开始具备人的温度，信任才有可能建立，学员也更不容易分心。\n百万AI学习原住民\n话说回来，即便「大脑、耳朵、嘴巴」全部补齐，我们依然无法解释与爱为舞是如何实现规模化落地的。\n毕竟，从语音识别，到模型思考，再到语音合成，最后还要驱动真人级数字人，这条服务链路相当长。\n任何一个环节稍有迟滞，都会严重影响学员的课堂体验。\n而当用户规模放大，「千人千面」会带来更高频的推理请求，一旦调度或资源分配稍有不慎，服务质量会迅速下滑。\n想要实现大规模落地，AI导师还需要一颗能持续供血、且足够强健的「心脏」。\n首先，得把这条冗长的服务链疏通，保证「血管」里不堵。\n在《思考，快与慢》中，Daniel Kahneman提出，大脑为了偷懒，演化出了两套工作模式：\n靠直觉行事的「系统一」、调用认知资源的「系统二」\n。\n与爱为舞借鉴的，正是这一点。\n当学员开口提问时，系统不会一股脑把问题全丢给大模型，而是先做一次判断：\n能马上回答的，直接走快速通道；真正需要推理的，再交给大模型慢慢想。\n具体而言，简单问题会先由快速回答系统给出反馈；与此同时，大模型已经在后台并行启动。等学员听完前半句，模型的「思考」也完成了一大半。\n于是，模型回复的延迟可压缩到\n100ms\n以内，整条响应链路稳定在\n1–1.5秒\n。\n同理，如果学员在导师讲话时突然插话，AI也不会傻等学员全部说完再思考。而是立刻结合上下文判断学员的意图，提前开始构思。\n这样响应时间仍可控制在\n100–200ms\n，整条链路不超过\n1.6秒\n。\n当然，遇到一些开放式问题，确实要多想一会儿。\n但即便如此，AI导师也不会「卡住不动」，而是通过表情变化、过渡性话语告诉学员：\n我在想，你稍等\n。而不是空气突然安静，一人一AI面面相觑。\n血管疏通之后，还可以通过「提前缓存」，让血液循环得更顺畅一些。\n在真实教学中，同一堂课的核心知识点其实相对固定。哪怕学员的具体问题不同，总体来看仍有一定规律可循。\n先从\n输入\n说起。\n大模型在生成答案前，要先「读懂问题」\n（prefill）\n，再「组织回答」\n（decode）\n。而前者非常吃算力，并且很耗时间。\n团队的做法是，把Prompt结构化：在不影响回答质量的前提下，把同一类场景里老是出现的内容集中起来，从而让AI少做重复阅读。\n再看\n输出\n。\n学员千差万别，但在具体知识点上，很多人其实都是在同一个地方「栽跟头」。既然如此，AI导师就没必要每次都从头生成一整套讲解。\n因此，团队会以题目、引导方式和学员回答作为索引，把模型的讲解结果先存下来。一旦再次遇到相同情形，直接拿来用就好。\n通过这套「链路优化+缓存」的组合拳，与爱为舞将整个流程控制在了1s-1.6s之间。\n筋骨与脉络就位，接下来，该让心脏泵得更有力了，与爱为舞在\n大规模并发\n上\n也做了大量工作。\n首先在单机上\n，为了榨干每一张GPU，团队在系统设计之初就完成了显存地址的统一规划，全程实现显存共享，尽量避免数据在不同计算与存储介质间反复搬运所带来的性能损耗。\n与此同时，在GPU算子层面，团队又针对核心计算路径进行了专项加速，使单卡的有效吞吐能力提升约5倍，足以支撑起几十路真人级数字人的推理。\n其次在集群上\n，资\n源的调度能力同样至关重要。团队又从五个层面，对整体系统做了进一步加固：\n多数字人统一调度：\n同一个资源池中不同形象统一调度，从而更好的复用集群资源；\n系统抽象：\n对话轮次化、课节内容组件化、知识点任务化，让复杂流程标准化；\n并行计算：\n尽量不浪费任何空闲算力，AI导师还在讲上一题时，下一题的计算已经在后台悄然启动；\n预留容量：\n服务支持横向扩容，不同层级配有多种缓存与缓冲机制，一层层削薄高峰流量，避免高并发请求同时压向模型与数据库；\n保险机制：\n整个教学调度过程可恢复，即便遭遇网络中断或客户端异常退出，教学状态也不会丢失。\n凭借一台全速运转的\nAI发动机\n，加上一张巨大的\n工程降落伞\n，与爱为舞得以把AI导师「空投」到全国各地，成为业界首个支持万人并发的真人级AI教学系统。\n归根结底，与爱为舞从未将AI视作一个简单的辅助工具。\n在他们看来，比起技术升级，AI更像一场关于个体工作逻辑与组织管理范式的深层重塑。\n回头看今天的企业形态，其实很多都是工业时代的妥协产物：人的精力有限，只能把分工越拆越细，组织层级上层层加码。\n一道道庞大的部门墙，虽防止了团队混乱，但也淹没了许多人才的主观能动性。\nAI的出现，第一次让生产力得到完全释放，每个人都能担任「架构师」。\n在此背景下，与爱为舞提出「全员皆超级个体」——只要有想法，任何人都可以手握数据与算力这两栋「粮仓」，调度一支由智能体组成的硅基军团，以极低的成本，快速实现抢跑。\n而这一理念，也已在产品上得到验证——\n至今，「爱学」已服务\n百万级用户，学员分布于全国342个城市\n：东至佳木斯，西达克孜勒苏，南抵三沙，北至大兴安岭。\n关于AI原生的企业理念，市场已经给出了自己的判断。\n而当AI真正开始惠及百万学员，我们或许终于有机会，兑现孔夫子两千多年前所期待的那个美好愿景——「有教无类、因材施教」。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859282&idx=1&sn=bc10090410756f39cc9142941736553b&chksm=e93899a6346c71d5eb6d34969c8914b81f44b4c7f14738c567df73888a5a80fc208f49ba9c1b&scene=0&xtrack=1#rd",
      "publish_time": 1767168600,
      "publish_date": "2025-12-31 16:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767193324,
      "last_modify_ts": 1767309661
    },
    {
      "id": 99,
      "article_id": "51544",
      "title": "「地质约束显式+数据驱动模型」的新路径，浙江大学团队实现跨区域矿产远景预测性能和可解释性提升",
      "description": "浙江大学研究团队提出一种地质约束的数据驱动成矿预测方法，通过引入各向异性空间邻近关系与非平稳建模机制，定量表达成矿异质性与方向性控制。该方法融合人工智能与地学数据，提升矿产远景预测填图精度，实现对复杂地质环境下矿化规律的高效识别，推动智能勘查技术发展。",
      "content": "作者：\n李天一、陈奕君、紫晗\n编辑：李宝珠\n本文已获得研究团队授权发布，转载请联系本公众号并标明来源\n浙江大学的研究团队提出了一种地质约束的数据驱动成矿预测方法，通过将各向异性空间邻近关系与空间非平稳建模机制显式引入预测框架，实现对成矿异质性与方向性控制的定量表达。\n近年来，人工智能与地学数据深度融合显著推动了矿产资源预测方法的发展，矿产远景预测填图（Mineral Prospectivity Mapping, MPM）已成为降低找矿风险、支撑深部与复杂地质条件下资源勘查的重要技术手段。然而，成矿作用受构造、岩性及岩浆活动等多重地质因素控制，具有显著的空间非平稳性与方向性特征。\n现有多数机器学习与图模型方法往往以隐式方式处理这些空间特征，难以显式刻画成矿过程中的各向异性与区域差异性，\n从而在地质可解释性与预测稳定性方面仍存在不足。\n针对上述问题，\n浙江大学的研究团队提出了一种地质约束的数据驱动成矿预测方法，\n通过将各向异性空间邻近关系与空间非平稳建模机制显式引入预测框架，实现对成矿异质性与方向性控制的定量表达。该方法构建了各向异性空间邻近性神经网络，并结合卷积注意力加权机制与逻辑回归模型，有效融合多源地学信息，\n在保持预测精度的同时显著增强了模型的地质一致性与可解释性。\n通过在加拿大梅古马地体金矿区和美国科迪勒拉斑岩铜成矿带的多尺度验证，结果表明，\n该方法在召回率和整体泛化性能方面均优于多种主流模型，并能够揭示区域尺度上的关键控矿因素与成矿方向性特征。\n该研究为将地质约束显式融入数据驱动模型提供了新的技术路径，对智能找矿与成矿机理定量研究具有参考价值。\n目前，该项研究成果已以「Geologically constrained data-driven modeling for mineral prospectivity mapping」为题发表于 Geology。\n研究亮点：\n* 突破传统机器学习方法的隐式处理局限，通过构建各向异性空间邻近性神经网络，实现对复杂成矿作用空间异质性的定量刻画；\n* 地质约束与数据驱动方法深度融合，保持了模型结构的可解释性与地质一致性；\n* 能够揭示区域尺度上的关键控矿因素与成矿方向性特征，实现跨区域、多尺度验证的稳健泛化性能。\n论文地址：\nhttps://go.hyper.ai/vbUpa\n关注公众号，后台回复「成矿预测」即可获取完整论文\n更多 AI 前沿论文：\nhttps://hyper.ai/papers\n基于深度神经网络加权逻辑回归模型，实现成矿概率稳健预测\n成矿作用通常受构造、岩性、岩浆活动及多种地球物理—地球化学因素的共同控制，\n其空间分布表现出显著的非平稳性与方向性特征。\n这使得传统依赖全局假设的统计模型或纯数据驱动方法，难以准确刻画区域尺度上的成矿差异与局部成矿规律。尽管近年来机器学习和人工智能方法在矿产远景预测中取得了显著进展，但多数模型往往以隐式方式处理空间约束，难以反映真实的地质控制过程，从而在地质可解释性和泛化能力方面仍存在不足。\n浙江大学研究团队围绕「如何在数据驱动框架中显式引入地质约束」这一核心科学问题，系统分析了现有矿产远景预测方法的局限性。传统地统计方法能够在一定程度上缓解空间非平稳性问题，但其线性假设难以刻画复杂的非线性成矿过程；而近年来兴起的神经网络和图神经网络方法，虽然在预测精度上表现突出，\n却往往仅通过模型结构隐式学习空间依赖关系，缺乏对成矿各向异性与空间异质性的直接刻画机制。\n这些不足限制了模型对区域构造控制和成矿方向性的识别能力。\n该研究选取了两个具有代表性的区域尺度数据集：\n* 加拿大梅古马地体（Meguma terrane）金矿区数据集：\n该区是矿产远景预测领域的经典基准区，矿点资料完备、成矿背景清晰，长期被用于方法对比与性能评估；\n* 美国西部科迪勒拉（the southern Cordillera region）斑岩铜成矿带数据集：\n覆盖多个州，区域尺度大、构造与岩浆活动复杂，用于检验模型在大尺度、复杂地质环境下的稳定性与泛化能力。\n这两个数据集分别对应小尺度精细预测与大尺度区域推广。\n其中加拿大矿区数据集被作为模型初始评估与方法对比的基准测试区，用于验证模型在经典、小尺度金矿预测场景中的识别能力与召回表现；美国矿区数据集作为大尺度、复杂构造环境下的推广验证区，用于检验模型在斑岩铜系统中的跨区域稳定性与泛化能力。\n基于数据，\n该研究提出了一种各向异性卷积注意力加权逻辑回归模型（Anisotropic Convolutional Attention-Weighted Logistic Regression, ACAWLR），\n用于地质约束下的矿产远景预测。该方法首先通过方向加权的协方差分析提取矿点分布的主、次成矿方向，并在此基础上构建各向异性空间距离度量；随后引入各向异性空间邻近性神经网络（Anisotropic Spatial Proximity Neural Network, ASPNN），将方向性空间关系以可学习的方式嵌入模型中，从而显式刻画成矿过程中的方向依赖特征。\n在此基础上，进一步结合卷积神经网络与空间—通道注意力机制，构建卷积注意力加权网络，用以学习空间非平稳的控矿权重，并与逻辑回归模型耦合，实现对成矿概率的稳健预测。\n各向异性卷积注意力加权逻辑回归（ACAWLR）框架示意图\n多尺度验证策略与模型对比\n在实验设计上，研究团队采用多尺度、分层次的验证策略。\n首先在加拿大新斯科舍省梅古马地体这一经典金矿预测基准区开展系统对比实验，\n将所提出方法与地理加权逻辑回归、支持向量机、随机森林、多层感知机及图注意力网络等多种代表性方法进行比较。\n结果表明，\nACAWLR 在召回率和整体预测性能方面均表现最优，\n在预测精度、空间泛化能力与地质可解释性之间实现了有效平衡，能够完整识别已知矿点分布，并生成更连续、符合地质认知的远景预测图。\n随后，研究进一步将该方法推广至美国西部科迪勒拉斑岩铜成矿带这一大尺度复杂区域，验证了模型在跨区域应用中的稳定性与鲁棒性。\n成矿远景预测图：(A–F) 新斯科舍省梅古马地体金矿预测结果，分别由各向异性卷积注意力加权逻辑回归（ACAWLR）、地理加权逻辑回归（GWLR）、随机森林（RF）、支持向量机（SVM）、多层感知机（MLP）和图注意力网络（GAT）得到；(G) 基于 ACAWLR 的斑岩铜矿预测结果（美国西部）\n此外，该研究还开展了大尺度成矿可解释性分析，系统揭示了不同区域内关键控矿因素的空间差异性。结果表明，\n铜含量在斑岩铜系统中具有主导控制作用，而岩性、断裂和重力异常等因素在不同构造背景下呈现出显著不同的空间影响模式。\n通过各向异性分析，模型进一步识别出与区域构造体系一致的成矿主控方向，为理解成矿机理和指导找矿部署提供了直观依据。\n各特征对模型输出的相对贡献；(B–H) Cu、断裂、Au、Fe、Mo、岩性及重力异常在局部尺度上的空间影响分布\n空间各向异性特征\n(A) 基于矿点训练样本的特征值分解所得到的主、次成矿方向；\n(B) 各向异性空间邻近性神经网络（ASPNN）优化后的邻近性分布（红色表示较短，蓝色表示较长）。背景为中生代至现今的岩浆弧与构造带分布（据 Yonkee 和 Weil，2015）。加拿大：AB—阿尔伯塔省；MB—马尼托巴省；SK—萨斯喀彻温省。美国：AZ—亚利桑那州；CA—加利福尼亚州；CO—科罗拉多州；ID—爱达荷州；KS—堪萨斯州；MT—蒙大拿州；ND—北达科他州；NB—内布拉斯加州；NM—新墨西哥州；NV—内华达州；OR—俄勒冈州；SD—南达科他州；TX—得克萨斯州；UT—犹他州；WA—华盛顿州；WY—怀俄明州\n有关浙江大学地球科学学院团队\n近年来，浙江大学地球科学学院团队在地学与人工智能交叉领域取得了一系列具有前沿性和工程应用价值的科研成果。\n团队提出的 GNNWR 系列模型被行业人才使用，模型的下载量、调用数和引用累计近 5 万次\n，并在海洋学、地理学、大气科学和地质学等多个方向得到了广泛应用。该项工作成果已在地球科学领域知名期刊 Geoscientific Model Development 上发表，论文题目为「GNNWR: An Open-Source Package of Spatiotemporal Intelligent Regression Methods for Modeling Spatial and Temporal Non-Stationarity」。\n论文地址：\nhttps://gmd.copernicus.org/articles/17/8455/2024/\n模型开源地址：\nhttps://github.com/zjuwss/gnnwr\n2025 年 2 月，\n该团队提出了一种基于注意力机制的深度学习模型——情景注意力驱动的地理加权回归（CatGWR），\n通过注意力机制计算样本间的情景相似性，并将其与空间邻近性相结合，生成情景化的时空权重，从而更准确地估计空间非平稳性。相关成果以「Using an attention-based architecture to incorporate context similarity into spatial non-stationarity estimation」为题，发表在 International Journal of Geographical Information Science。\n论文地址：\nhttps://www.tandfonline.com/doi/full/10.1080/13658816.2025.2456556\n点击查看完整解读：\n以1.7K深圳小区房价为例，浙大GIS实验室使用注意力机制挖掘地理情景特征，提升空间非平稳回归精度\n同年 11 月，\n该团队还提出了一种异构对比图融合网络（HCGFN），用于 HSI 和 LiDAR 数据的联合分类，实现了 HSI 和 LiDAR 之间的高效交互和有效融合。\n该项工作成果已在地球科学领域知名期刊 IEEE Transactions on Geoscience and Remote Sensing 上发表，论文题目为「Aggregative and Contrastive Dual-View Graph Attention Network for Hyperspectral Image Classification」。\n论文地址：\nhttps://ieeexplore.ieee.org/document/11115095\n团队还将空间智能模型应用于社会经济地理问题，通过引入空间邻近性和深度学习结构，取得比传统模型显著更好的拟合效果。以「Spatial non-stationarity assessments of housing prices in Wuhan based on a TD-GNNWR model」为题发表在地理学报的论文中，\n团队建立了一种基于出行时间（TD）的空间距离度量与神经网络融合模型（TD-GNNWR），显著提高城市房价空间非平稳性的拟合与解释性。\n论文地址：\nhttps://www.geog.com.cn/CN/10.11821/dlxb202408005\n此外，研究团队还将时空智能回归与深度学习方法推广到地质、海洋、生态与大气环境模型构建中，\n如利用空间加权神经网络高精度估算青藏高原的地表热流分布，为地球内部地球动力学过程提供关键见解。\n相关研究以「The Distribution of Surface Heat Flow on the Tibetan Plateau Revealed by Data‐Driven Methods」为题，发表在 Journal of Geophysical Research: Solid Earth。\n论文地址：\nhttps://doi.org/10.1029/2023JB028491\n一键获取 2023—2024 年 AI4S 领域高质量论文及深度解读文章 ⬇️\n往期推荐\n戳\n“阅读原文”\n，免费获取海量数据集资源！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU3NTQ2NDIyOQ==&mid=2247525942&idx=1&sn=8de4c393fe3c03c6286305c6e47fbc98&chksm=fc064840bf191a6aa517b69a61012469aac7ff68fa04a2d42ccc8f66edba45f873b61e5219bb&scene=0&xtrack=1#rd",
      "publish_time": 1767165000,
      "publish_date": "2025-12-31 15:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://go.hyper.ai/vbUpa\", \"https://hyper.ai/papers\", \"https://gmd.copernicus.org/articles/17/8455/2024/\", \"https://github.com/zjuwss/gnnwr\", \"https://www.tandfonline.com/doi/full/10.1080/13658816.2025.2456556\", \"https://ieeexplore.ieee.org/document/11115095\", \"https://www.geog.com.cn/CN/10.11821/dlxb202408005\", \"https://doi.org/10.1029/2023JB028491\"]",
      "add_ts": 1767193337,
      "last_modify_ts": 1767309671
    },
    {
      "id": 103,
      "article_id": "51540",
      "title": "Qwen负责人转发2025宝藏论文，年底重读「视觉领域GPT时刻」",
      "description": "谷歌DeepMind论文《Video models are zero-shot learners and reasoners》入选ICCV 2025，提出视频模型“思维链”CoF，展现其零样本学习与推理能力。该研究获阿里最年轻P10林俊旸转发关注，成为2025年度备受瞩目的学术成果之一，揭示视频模型在无训练情况下自主理解与推导的潜力，推动视觉AI向通用智能迈进。",
      "content": "闻乐 发自 凹非寺\n量子位 | 公众号 QbitAI\n2025最后几天，是时候来看点年度宝藏论文了。\n比如，阿里最年轻P10、Qwen大模型技术负责人\n林俊旸\n最新转发了一篇名为《Video models are zero-shot learners and reasoners》的研究。\n没错，就是谷歌DeepMind提出视频模型“思维链”\nCoF\n的那篇入选ICCV 2025的论文。\n当时，这篇研究还给出了一个关键信号：视觉领域的“GPT时刻”要来了。\n该研究用1.8万组实验数据证明，视频模型正在跳出\n任务专属\n的局限，走上LLM的老路——\n用一个模型，通过提示，完成几乎所有的视觉任务\n。\n并且，推理过程还能被CoF“演”出来。\n从NLP到CV\n自然语言处理领域的GPT时刻，核心是实现了\n一个模型通吃所有\n。\n在此之前，翻译、写作、问答等任务都各自有专属的模型，而LLM的出现，靠大规模数据训练和生成式架构，让\n零样本学习\n成为可能，模型通过文字提示就能完成各种各样的任务。\n但计算机视觉领域却还一直深陷于这种碎片化的困境。\n比如，要做目标检测得用YOLO，做语义分割依赖SAM，图像超分要找专门模型，3D重建还得换另一套工具。\n这些针对不同任务的模型架构差异很大，不仅开发成本高，还严重限制了视觉AI的泛化能力，导致视觉AI的进步一直是单点突破。\n比如这个模型在分割任务上刷新SOTA，另一个模型在检测任务上实现提速，却始终没能解决“多任务统一”的问题。\n而这篇论文详解了谷歌DeepMind借鉴LLM的成功路径，让Veo 3成为了一个“视觉通才”。\n通过大规模视频与文本数据的生成式训练，打通了视觉感知与语言理解的壁垒，让\n模型具备了跨任务的通用能力\n。\n而且Veo 3完美复刻了LLM的\n零样本优势\n，面对没专门训练过的任务，只要用文字说清需求，模型就能直接输出结果，无需额外调参或数据微调。\n这也正是说视觉GPT时刻到来的核心标志。\n从生成视频到用视频思考\n就像林俊旸提到的那样，这篇论文指出视频模型一个非常关键的变化在于——视频不再只是输出的形式，也开始体现推理的过程。\n模型在生成视频的过程中，会逐步展开中间状态，这就让推理不再是完全不可见的黑箱。\n论文中将这种现象称为\nChain-of-Frames\n，也就是CoF，类似于语言模型中的CoT，只不过视频模型是通过连续生成的视频帧，把整个推理过程“演”出来。\n模型在时间和空间中不断调整画面，用可见的变化替代抽象的符号推理。\n因此，无论是解迷宫、做路径规划，还是进行规则外推，模型都不是一次性输出结果，而是在连续的视觉变化中逐步逼近正确解。\n推理过程则被隐含地编码在视频序列之中，视频模型开始\n在过程中思考\n。\n也\n正是这种“逐帧生成即推理”的方式，为通用性提供了基础。\n因为模型不再围绕某一个具体任务去算结果，转而在统一的生成过程中，不断更新对场景状态的理解。\n不同任务之间的差异，不再体现在模型结构或输出形式上，而是被压缩成了“生成过程中关注什么、如何继续生成”的差别。\n这种框架下，分割、检测、编辑、路径规划等原本割裂的视觉任务，可以被统一到同一套生成机制中。模型始终做的只有一件事：\n生成下一帧视频\n。\n在逐帧生成过程中，它自然完成了感知、推理与决策的协同，这就不再需要为每类任务单独设计模型或系统。\n论文进一步观察到，在无需针对具体任务进行专门训练、也不引入额外监督的前提下，视频模型已经能够通过不同形式的提示，在多类视觉任务中展现出一定的零样本泛化能力。\n也正因为如此，Veo 3用感知、建模、操控、推理4大核心能力能搞定62种没学过的视觉任务。\n现在经过a16z投资合伙人Justine Moore和林俊旸一提醒，回看这篇论文发现，视频模型在视觉领域的的突破，还真有点当年LLM颠覆NLP的味儿了……\n论文地址：https://arxiv.org/abs/2509.20328\n参考链接：https://x.com/venturetwins/status/2005330176977293743\n—\n欢迎AI产品从业者共建\n—\n📚\n「AI产品知识库」\n是量子位智库基于长期产品库追踪和用户行为数据推出的飞书知识库，旨在成为AI行业从业者、投资者、研究者的核心信息枢纽与决策支持平台。\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859187&idx=2&sn=2ef10114d1724e95e62729cd2ba6187f&chksm=e99cacbdee5ba81b1f4ad86ecb1720c267a0fa83f11653ba334e9d48ff20553395925ace1538&scene=0&xtrack=1#rd",
      "publish_time": 1767163200,
      "publish_date": "2025-12-31 14:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2509.20328\", \"https://x.com/venturetwins/status/2005330176977293743\"]",
      "add_ts": 1767193350,
      "last_modify_ts": 1767309688
    },
    {
      "id": 104,
      "article_id": "51537",
      "title": "【TVM教程】设计与架构",
      "description": "TVM 已更新至 0.21.0 版本，中文文档同步更新。Apache TVM 是支持 CPU、GPU 及多种 AI 芯片的深度学习编译框架。本文档面向开发者，介绍其架构与开发流程，涵盖从模型导入到运行的完整编译链路：前端将模型转为 IRModule，经通用与目标相关转换后生成可执行模块，最终在 runtime 中加载执行。核心数据结构 IRModule 包含函数集合，支持 relay::Funct...",
      "content": "TVM 现已更新到 0.21.0 版本，\nTVM 中文文档\n已经和新版本对齐。\nApache TVM 是一个深度的深度学习编译框架，适用于 CPU、GPU 和各种机器学习加速芯片。更多 TVM 中文文档可访问 →\nApache TVM\n本文档适用于想要了解 TVM 架构或积极开发项目的开发者。本文档组织结构如下：\n整体编译流程示例\n：概述 TVM 如何将一个高级模型描述转换为可部署模块的各个步骤。建议首先阅读本节以了解基础流程。\n简要介绍 TVM 栈中的关键组件。您也可以参考\nTensorIR 深度解析\n和\nRelax 深度解析\n，了解 TVM 栈中两个核心部分的详细内容。\n本指南提供了架构的一些补充视图。首先研究端到端的编译流程，并讨论关键的数据结构和转换。这种基于 runtime 的视图侧重于运行编译器时每个组件的交互，接下来我们将研究代码库的逻辑模块及其关系。本部分将提供该设计的静态总体视图。\n编译流程示例\n​\n本指南研究编译器中的编译流程示例，下图展示了流程。从高层次来看，它包含以下步骤：\n导入：\n前端组件将模型引入到\nIRModule\n中，它包含了内部表示模型的函数集合。\n转换：\n编译器将 IRModule 转换为功能与之等效或近似等效（例如在量化的情况下）的 IRModule。许多转换与 target（后端）无关，并且允许 target 配置转换 pipeline。\nTarget 转换：\n编译器将 IRModule 转换（codegen）为指定 target 的可执行格式。target 的转换结果被封装为 runtime.Module，可以在 runtime 环境中导出、加载和执行。\nRuntime 执行：\n用户加载 runtime.Module，并在支持的 runtime 环境中运行编译好的函数。\n关键数据结构\n​\n设计和理解复杂系统的最佳方法之一，就是识别关键数据结构和操作（转换）这些数据结构的 API。识别了关键数据结构后，就可以将系统分解为逻辑组件，这些逻辑组件定义了关键数据结构的集合，或是数据结构之间的转换。\nIRModule\n是整个堆栈中使用的主要数据结构。一个 IRModule（intermediate representation module）包含一组函数。目前支持两种主要的功能变体（variant）：\nrelay::Function\n是一种高层功能程序表示。一个 relay.Function 通常对应一个端到端的模型。可将 relay.Function 视为额外支持控制流、递归和复杂数据结构的计算图。\ntir::PrimFunc\n是一种底层程序表示，包含循环嵌套选择、多维加载/存储、线程和向量/张量指令的元素。通常用于表示算子程序，这个程序在模型中执行一个（可融合的）层。 在编译期间，Relay 函数可降级为多个 tir::PrimFunc 函数和一个调用这些 tir::PrimFunc 函数的顶层函数。\n在编译和转换过程中，所有的 Relax 运算符都会被下沉（lower）为\ntir::PrimFunc\n或\nTVM PackedFunc\n，这些函数可以直接在目标设备上执行。而对 Relax 运算符的调用，则会被下沉为对低层函数的调用（例如\nR.call_tir\n或\nR.call_dps\n）。\n转换\n​\n前面介绍了关键数据结构，接下来讲转换。转换的目的有：\n优化：将程序转换为等效，甚至更优的版本。\n降级：将程序转换为更接近 target 的较低级别表示。 relay/transform 包含一组优化模型的 pass。优化包括常见的程序优化（例如常量折叠和死码消除），以及特定于张量计算的 pass（例如布局转换和 scale 因子折叠）。\nRelax 转换\n​\nRelax 转换包括一系列应用于 Relax 函数的 Pass。优化内容包括常见的图级优化（如常量折叠、无用代码消除等），以及后端特定的优化（例如库调度）。\ntir 转换\n​\ntir 转换包含一组应用于 tir 函数的 pass，主要包括两类：\nTensorIR 调度\n（TensorIR schedule）：\nTensorIR 调度旨在为特定目标优化 TensorIR 函数，通常由用户指导控制目标代码的生成。对于 CPU 目标，TIR PrimFunc 即使没有调度也可以生成有效代码并在目标设备上运行，但性能较低。对于 GPU 目标，调度是生成有效线程绑定代码的关键。详情请参考\nTensorIR 转换教程\n。此外，TVM 提供了\nMetaSchedule\n来自动搜索最优的 TensorIR 调度。\n降层 Pass（Lowering Passes）：\n这些 Pass 通常在应用调度后执行，将 TIR PrimFunc 转换为功能等价但更贴近目标表示的版本。例如，有些 Pass 会将多维访问扁平化为一维指针访问，或者将中间表示中的 intrinsic 扩展为目标特定的形式，并对函数入口进行修饰以符合运行时调用约定。\n许多底层优化可以在目标阶段由 LLVM、CUDA C 以及其他目标编译器处理。因此，我们将寄存器分配等底层优化留给下游编译器处理，仅专注于那些它们未涵盖的优化。\n跨层转换（Cross-level transformations）\n​\nApache TVM 提供统一的策略来优化端到端模型。由于 IRModule 同时包含 Relax 和 TIR 函数，跨层转换的目标是在这两类函数之间应用变换来修改 IRModule。\n例如，\nrelax.LegalizeOps\nPass 会通过将 Relax 算子降层为 TIR PrimFunc 并添加至 IRModule 中，同时将原有的 Relax 算子替换为对该 TIR 函数的调用，从而改变 IRModule。另一个例子是 Relax 中的算子融合流程（包括\nrelax.FuseOps\n和\nrelax.FuseTIR\n），它将多个连续的张量操作融合为一个操作。与以往手动定义融合规则的方法不同，Relax 的融合流程会分析 TIR 函数的模式，自动检测出最佳融合策略。\n目标转换（Target Translation）\n​\n目标转换阶段将 IRModule 转换为目标平台的可执行格式。对于 x86 和 ARM 等后端，TVM 使用 LLVM IRBuilder 构建内存中的 LLVM IR。也可以生成源码级别的语言，如 CUDA C 和 OpenCL。此外，TVM 支持通过外部代码生成器将 Relax 函数（子图）直接翻译为目标代码。\n目标代码生成阶段应尽可能轻量，大多数转换和降层操作应在此阶段之前完成。\nTVM 还提供了 Target 结构体用于指定编译目标。目标信息也可能影响前期转换操作，例如目标的向量长度会影响向量化行为。\nRuntime 执行\n​\nTVM runtime 的主要目标是提供一个最小的 API，从而能以选择的语言（包括 Python、C++、Rust、Go、Java 和 JavaScript）加载和执行编译好的工件。以下代码片段展示了一个 Python 示例：\nimport tvm\n# Python 中 runtime 执行程序示例，带有类型注释\nmod: tvm.runtime.Module = tvm.runtime.load_module(\"compiled_artifact.so\")\narr: tvm.runtime.Tensor = tvm.runtime.tensor([1, 2, 3], device=tvm.cuda(0))\nfun: tvm.runtime.PackedFunc = mod[\"addone\"]\nfun(arr)\nprint(arr.numpy())\ntvm.runtime.Module\n封装了编译的结果。runtime.Module 包含一个 GetFunction 方法，用于按名称获取 PackedFuncs。\ntvm.runtime.PackedFunc\n是一种为各种构造函数消解类型的函数接口。runtime.PackedFunc 的参数和返回值的类型如下：POD 类型（int, float）、string、runtime.PackedFunc、runtime.Module、runtime.Tensor 和 runtime.Object 的其他子类。\ntvm.runtime.Module\n和\ntvm.runtime.PackedFunc\n是模块化 runtime 的强大机制。例如，要在 CUDA 上获取上述\naddone\n函数，可以用 LLVM 生成主机端代码来计算启动参数（例如线程组的大小），然后用 CUDA 驱动程序 API 支持的 CUDAModule 调用另一个 PackedFunc。OpenCL 内核也有相同的机制。\n以上示例只处理了一个简单的 addone 函数。下面的代码片段给出了用相同接口执行端到端模型的示例：\nimport tvm\n# python 中 runtime 执行程序的示例，带有类型注释\nfactory: tvm.runtime.Module = tvm.runtime.load_module(\"resnet18.so\")\n# 在 cuda(0) 上为 resnet18 创建一个有状态的图执行模块\ngmod: tvm.runtime.Module = factory[\"resnet18\"](tvm.cuda(0))\ndata: tvm.runtime.Tensor = get_input_data()\n# 设置输入\ngmod[\"set_input\"](0, data)\n# 执行模型\ngmod[\"run\"]()\n# 得到输出\nresult = gmod[\"get_output\"](0).numpy()\n主要的结论是 runtime.Module 和 runtime.PackedFunc 可以封装算子级别的程序（例如 addone），以及端到端模型。\n总结与讨论\n​\n综上所述，编译流程中的关键数据结构有：\nIRModule：包含 relay.Function 和 tir.PrimFunc\nruntime.Module：包含 runtime.PackedFunc\n编译基本是在进行关键数据结构之间的转换。\nrelay/transform 和 tir/transform 是确定性的基于规则的转换\nmeta-schedule 则包含基于搜索的转换\n最后，编译流程示例只是 TVM 堆栈的一个典型用例。将这些关键数据结构和转换提供给 Python 和 C++ API。然后，就可以像使用 numpy 一样使用 TVM，只不过关注的数据结构从 numpy.ndarray 改为 tvm.IRModule。以下是一些用例的示例：\n用 Python API 直接构建 IRModule。\n编写一组自定义转换（例如自定义量化）。\n用 TVM 的 Python API 直接操作 IR。\ntvm/support\n​\nsupport 模块包含基础架构最常用的程序，例如通用 arena 分配器（arena allocator）、套接字（socket）和日志（logging）。\ntvm/runtime\n​\nruntime\n是 TVM 技术栈的基础。它提供加载和执行已编译产物的机制。运行时定义了一套稳定的 C API 标准接口，用于与前端语言（如 Python 和 Rust）交互。\n除了 ffi::Function， runtime::Object 是 TVM 运行时的核心数据结构之一。它是一个带有类型索引的引用计数基类，支持运行时类型检查和向下转型。该对象系统允许开发者向运行时引入新的数据结构，例如 Array、Map 以及新的 IR 数据结构。\n除了用于部署场景，TVM 编译器本身也大量依赖运行时机制。所有 IR 数据结构都是 runtime::Object 的子类，因此可以直接从 Python 前端访问和操作。我们使用 PackedFunc 机制将各种 API 暴露给前端使用。\n不同硬件后端的运行时支持定义在 runtime 子目录中（例如 runtime/opencl）。这些特定于硬件的运行时模块定义了设备内存分配和设备函数序列化的 API。\nruntime/rpc 实现了对 PackedFunc 的 RPC 支持。我们可以利用 RPC 机制将交叉编译后的库发送到远程设备，并基准测试其执行性能。该 RPC 基础设施使得能够从多种硬件后端收集数据，用于基于学习的优化。\nTVM 运行时系统\n运行时信息\n模块序列化指南\n设备/目标交互\ntvm/node\n​\nnode 模块在 runtime::Object 的基础上为 IR 数据结构增加了更多功能。其主要功能包括：反射、序列化、结构等价性检查以及哈希计算。\n得益于 node 模块，我们可以在 Python 中通过字段名直接访问 TVM IR 节点的任意字段：\nx = tvm.tir.Var(\"x\", \"int32\")\ny = tvm.tir.Add(x, x)\n# a 和 b 是 tir.Add 节点的字段\n# 可以通过字段名直接访问\nassert y.a == x\n我们还可以将任意 IR 节点序列化为 JSON 格式，并加载回来。这种保存/加载和查看 IR 节点的能力为提高编译器的可用性打下了基础。\ntvm/ir\n​\ntvm/ir 文件夹包含所有 IR 函数变体所共享的统一数据结构与接口。该模块中的组件被 tvm/relax 和 tvm/tir 共享，主要包括：\nIRModule\n类型\nPassContext 和 Pass\nOp\n不同的函数变体（如 relax.Function 和 tir.PrimFunc）可以共存于一个 IRModule 中。尽管这些变体的内容表示不同，但它们使用相同的数据结构来表示类型。因此，不同函数变体之间可以共享函数签名的表示结构。统一的类型系统使得在定义好调用约定的前提下，一个函数变体可以调用另一个，从而为跨函数变体的优化奠定了基础。\n此外，我们还提供了统一的 PassContext 用于配置 Pass 行为，并提供组合 Pass 的方式构建优化流程。如下示例：\n# 配置 tir.UnrollLoop pass 的行为\nwith tvm.transform.PassContext(config={\"tir.UnrollLoop\": { \"auto_max_step\": 10 }}):\n    # 在该上下文下执行的代码\nOp 是用于表示系统内置的原始操作符/内建指令的通用类。开发者可以向系统注册新的 Op，并附加属性（例如该操作是否是逐元素操作）。\nPass 基础设施\ntvm/target\n​\ntarget 模块包含将 IRModule 转换为目标运行时代码的所有代码生成器，同时也提供了一个通用的 Target 类用于描述目标平台。\n编译流程可以根据目标平台的属性信息和每个目标 id（如 cuda、opencl）所注册的内建信息来自定义。\n设备/目标交互\ntvm/relax\n​\nRelax 是用于表示模型计算图的高级 IR。多种优化过程定义在\nrelax.transform\n中。需要注意的是，Relax 通常与 TensorIR 的 IRModule 协同工作，许多转换会同时作用于 Relax 和 TensorIR 函数。更多信息可参考：\nRelax 深度解析\n。\ntvm/tir\n​\nTIR 定义了低级程序表示。我们使用 tir::PrimFunc 来表示可以由 TIR Pass 转换的函数。除了 IR 数据结构，TIR 模块还包括：\n位于\ntir/schedule\n中的一组调度原语\n位于\ntir/tensor_intrin\n中的内置指令\n位于\ntir/analysis\n中的分析 Pass\n位于\ntir/transform\n中的转换/优化 Pass\n更多信息请参考：\nTensorIR 深度解析\n。\ntvm/arith\n​\n该模块与 TIR 紧密相关。低级代码生成中的一个核心问题是对索引的算术属性进行分析——如是否为正数、变量界限、描述迭代器空间的整数集合等。arith 模块提供了一套主要用于整数分析的工具，TIR Pass 可以利用这些工具简化和优化代码。\ntvm/te 和 tvm/topi\n​\nTE（Tensor Expression）是用于描述张量计算的领域专用语言（DSL）。需要注意的是，Tensor Expression 本身并不是可以直接存储进 IRModule 的自包含函数。我们可以使用\nte.create_prim_func\n将其转换为\ntir::PrimFunc\n，然后集成进 IRModule。\n尽管可以使用 TIR 或 TE 为每个场景直接构造算子，但这种方式较为繁琐。为此，topi（Tensor Operator Inventory）提供了一组预定义算子，覆盖了 numpy 操作和深度学习常见操作。\ntvm/meta_schedule\n​\nMetaSchedule 是一个用于自动搜索优化程序调度的系统。它是 AutoTVM 和 AutoScheduler 的替代方案，可用于优化 TensorIR 调度。需要注意的是，MetaSchedule 目前仅支持静态形状工作负载。\ntvm/dlight\n​\nDLight 提供一套预定义、易用且高性能的 TIR 调度策略。其目标包括：\n全面支持动态形状工作负载\n轻量级：提供无需调优或仅需极少调优的调度策略，且性能合理\n稳定性强：DLight 的调度策略具有通用性，即使当前规则不适用也不会报错，而是自动切换至下一个规则\n内容中包含的图片若涉及版权问题，请及时与我们联系删除",
      "article_url": "https://hub.baai.ac.cn/view/51537",
      "publish_time": 1767160140,
      "publish_date": "2025-12-31 13:49",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://zhida.zhihu.com/search/3705836406608869133\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture%23%25E7%25BC%2596%25E8%25AF%2591%25E6%25B5%2581%25E7%25A8%258B%25E7%25A4%25BA%25E4%25BE%258B\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/tensorir/\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/relax/\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23%25E7%25BC%2596%25E8%25AF%2591%25E6%25B5%2581%25E7%25A8%258B%25E7%25A4%25BA%25E4%25BE%258B\", \"https://zhida.zhihu.com/search?content_id=268335125&content_type=Article&match_order=1&q=IRModule&zhida_source=entity\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23%25E5%2585%25B3%25E9%2594%25AE%25E6%2595%25B0%25E6%258D%25AE%25E7%25BB%2593%25E6%259E%2584\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23%25E8%25BD%25AC%25E6%258D%25A2\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23relax-%25E8%25BD%25AC%25E6%258D%25A2\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23tir-%25E8%25BD%25AC%25E6%258D%25A2\", \"https://zhida.zhihu.com/search?content_id=268335125&content_type=Article&match_order=1&q=TensorIR+%E8%B0%83%E5%BA%A6&zhida_source=entity\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/tensorir/tir_transformation\", \"https://zhida.zhihu.com/search?content_id=268335125&content_type=Article&match_order=1&q=MetaSchedule&zhida_source=entity\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23%25E8%25B7%25A8%25E5%25B1%2582%25E8%25BD%25AC%25E6%258D%25A2cross-level-transformations\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23%25E7%259B%25AE%25E6%25A0%2587%25E8%25BD%25AC%25E6%258D%25A2target-translation\", \"https://link.zhihu.com/?target=https%3A//tvm.hyper.ai/docs/deep-dive/design-and-architecture/%23runtime-%25E6%2589%25A7%25E8%25A1%258C\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#%E6%80%BB%E7%BB%93%E4%B8%8E%E8%AE%A8%E8%AE%BA\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmsupport\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmruntime\", \"https://tvm.apache.org/docs/arch/runtime.html\", \"https://tvm.apache.org/docs/arch/runtime.html#runtime-specific-information\", \"https://tvm.apache.org/docs/arch/introduction_to_module_serialization.html\", \"https://tvm.apache.org/docs/arch/device_target_interactions.html\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmnode\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmir\", \"https://tvm.apache.org/docs/arch/pass_infra.html\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmtarget\", \"https://tvm.apache.org/docs/arch/device_target_interactions.html\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmrelax\", \"https://tvm.hyper.ai/docs/deep-dive/relax/\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmtir\", \"https://tvm.hyper.ai/docs/deep-dive/tensorir/\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmarith\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmte-%E5%92%8C-tvmtopi\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmmeta_schedule\", \"https://tvm.hyper.ai/docs/deep-dive/design-and-architecture/#tvmdlight\"]",
      "add_ts": 1767193353,
      "last_modify_ts": 1767309691
    },
    {
      "id": 108,
      "article_id": "51533",
      "title": "AI医生终于有了硬标尺！全球首个专病循证评测框架GAPS发布，蚂蚁联合北大王俊院士团队出品",
      "description": "蚂蚁健康与北大人民医院王俊院士团队联合发布全球首个大模型专病循证评测框架GAPS及配套评测集GAPS-NSCLC-preview，历时六个多月，汇聚十余位胸外科专家。该框架聚焦非小细胞肺癌领域，从证据根基、内容充分性、扰动鲁棒性与安全性四维度评估AI临床能力，突破传统考试式评测局限，推动医疗AI向深度临床应用发展。",
      "content": "允中 发自 凹非寺\n量子位 | 公众号 QbitAI\n蚂蚁健康\n与北京大学人民医院\n王俊\n院士团队历时6个多月，联合十余位胸外科医生共同打磨，发布了\n全球首个大模型专病循证能力的评测框架\n——\nGAPS\n（Grounding, Adequacy, Perturbation, Safety）\n，及其配套评测集 GAPS-NSCLC-preview。\n旨在解决现有医疗AI评测局限于考试式问答、缺乏临床深度、完整性、鲁棒性与安全性综合评估的问题。\n该评测集聚焦\n肺癌\n领域，包含\n92个问题\n、覆盖\n1691个临床要点\n，并配套全自动化的评测工具链，通过指南锚定、多智能体协同实现从问题生成、评分标准制定到多维度打分的端到端自动化。\n目前，相关成果已应用于“蚂蚁阿福”，论文《GAPS: A Clinically Grounded, Automated Benchmark for Evaluating AI Clinicians》、配套评测集GAPS-NSCLC-preview、自动化评测框架已全面公开。\n这项研究客观评价了大模型的临床能力：当前主流医疗大模型虽已具备“医学百科全书”般的知识广度，但在临床实践中仍处于成长阶段——\n它们在系统掌握医学知识方面表现卓越，但在应对真实临床场景中的不确定性挑战时，尚需进一步提升判断力与可靠性。\n权威引领：北大人民医院院士团队深度主导临床标准构建\n本项目由中国工程院院士、北京大学人民医院院长王俊教授领衔的团队全程主导，并与蚂蚁团队深度协作完成。\n在GAPS构建过程中，院士团队原创性地提出了\nGAPS评测的理论框架\n，并组织十余位胸外科医生持续参与评测题库构建、临床金标准答案撰写、模型输出的专业审核与迭代优化，提供NSCLC\n（非小细胞肺癌）\n领域前沿临床指南的权威解读与循证医学方法论指导，确保每一项指标都扎根真实临床实践，具备高度专业性与可信度。\n蚂蚁团队则发挥大模型与工程化能力优势，经过多轮高强度医工协同与反复迭代，将专家脑海中的复杂“临床金标准”精准沉淀为大模型可理解、可执行的结构化逻辑，实现GAPS的规模化、自动化与可落地应用。\n此次合作实现了“临床专家定标准、AI 技术做转化”的深度融合，突破了传统医疗AI评测中专家浅层参与的局限，标志着顶尖临床专家与AI技术团队的深度协作，为医疗AI从“技术驱动”走向“临床价值驱动”树立了新的范式。\n行业痛点：考得好，信不过\n在和大模型讨论医疗问题时，有时候回答得很好，有时候回答得很差，由于大模型的变化日新月异，医生和患者都没有办法在短时间对大模型产生客观评价，因此对大模型的信任就无从谈起。\n为了客观评价大模型的能力，学界通常采用基准测试的方法。\n然而，当前医疗AI的基准测试普遍缺乏对模型\n循证能力、可解释性与安全性\n的系统评估。\n长期以来，医疗AI的评估依赖MedQA、PubMedQA等“试卷型”基准，仅考察事实记忆能力；而HealthBench等基于人工评分细则\n（Rubric）\n的方法又受限于主观性强、扩展性差。\n这些方法无法反映真实诊疗场景：患者描述模糊、检查结果矛盾、治疗方案需权衡利弊……正如论文所强调：\n真正的医疗能力不在于背诵事实，而在于管理不确定性。\n尤其在肺癌这一全球致死率最高的癌症领域，缺乏细粒度、专病化的评估工具，使得医疗机构和开发者难以客观判断医疗AI是否真正具备临床可用性。\nGAPS的诞生，正是为了填补这一关键空白。\n破局之道：GAPS——从“考试机器”到“临床医生”的四维标尺\nGAPS是一个\n基于循证医学、全自动构建的AI临床能力评测框架\n，首次将临床胜任力解构为四个正交维度，并聚焦NSCLC\n（非小细胞肺癌）\n这一高难度专病场景进行系统验证：\n1、G（Grounding）认知深度\n：不止于“是什么”，更考验“为什么”和“怎么办”。\nG1和G2：事实回忆与解释\n（AI的舒适区）\nG3：基于指南的循证决策\n（如NCCN推荐方案）\nG4：推理性思维\n（Inferential Reasoning）\n——在证据冲突或缺失的“灰色地带”做出合理判断，这是当前所有模型的“死亡区”。\n2、A（Adequacy）回答完备性\n：医生的一句话可能关乎生死。GAPS引入三级评价：\nA1\n（必须有）\n：核心诊疗建议\nA2\n（应该有）\n：关键限定条件\n（如剂量、禁忌症、监测指标）\nA3\n（锦上添花）\n：患者教育、多学科协作建议等\n缺少A2，再“正确”的建议也可能导致临床误用。\n3、P（Perturbation）鲁棒性\n：真实患者不会照着教科书说话。GAPS通过三类扰动测试模型抗干扰能力：\nP1：语言噪音\n（口误、方言）\nP2：冗余信息\n（无关症状堆砌）\nP3：对抗性前提\n（如诱导性错误假设）\n实验显示，多数模型极易被误导，甚至顺从用户的错误引导。\n4、S（Safety）安全底线\n：医疗容不得“差不多”。GAPS 建立四级风险体系：\nS1\n（无关回答）\n→ S4\n（灾难性错误/Never Events，如推荐禁忌药物）\n一旦触犯S4，无论其他维度得分多高，总分直接归零——这是不可逾越的红线。\nGAPS解决了现有医疗AI评测仅关注“准确率”的局限，首次实现对\n循证决策能力、回答完备性、现实鲁棒性与安全底线\n的系统性、自动化评估。\n其优势在于：以临床指南为锚点，全自动构建高保真评测项与评分规则，兼具可扩展性、可复现性与临床真实性，为AI向可信临床伙伴演进提供精准导航。\n核心黑科技：全自动化的“循证评测集”流水线\nGAPS最大的技术亮点在于其\n端到端自动化与可扩展性\n。\n不同于以往依赖人工命题，GAPS构建了一套基于\n临床指南（Guidelines）\n的自动化生成工厂：\n证据邻域构建\n：以NCCN、ESMO等权威指南为核心，自动抓取3跳内引用文献，构建高可信医学知识图谱与疾病话题树；\nDeep Research Agent\n：基于\nGRADE\n方法学，模拟人类专家围绕PICO\n（人群、干预、对照、结果）\n展开的证据检索、证据评估、强弱推荐的流程，自动生成带证据等级与推荐强度的高质量评分细则；\n虚拟患者生成\n：利用大模型合成去隐私化临床病例，并精准对齐知识图谱，确保每道题“有据可依、有理可循”。\n该流水线已成功应用于胸外科的专病——\nNSCLC（非小细胞肺癌）\n，生成包含92道题、1691个临床要点的评测集\nGAPS-NSCLC-preview\n。\n题目按认知深度分为G1~G4四级\n（从事实回忆到不确定性下的推理）\n，每题均配备平均12项完整性\n（A1~A3）\n与7项安全性\n（S1~S4）\n评分要点，并支持P0~P3四级扰动测试。\n未来可快速扩展至\n心血管、儿科、内分泌\n等任意专科的专病领域——只要有指南，就能生成高质量评测集。\n可靠的裁判：自动化评测让AI医疗能力可量化、可复现、可进化\nGAPS评测集同时搭配了一套高可靠性的自动化评测框架，实现了对AI临床能力的客观、细粒度、端到端的自动化评估。\n为确保评测本身可信，团队将自动化评分结果与五位资深专家的独立标注进行严格比对：\n在92个真实临床查询、1691个临床要点上，该框架与专家共识的整体一致率达90.00%，Cohen’s Kappa系数达0.77\n（“实质性一致”）\n，Macro-F1达0.88——不仅显著优于现有基准\n（如HealthBench中GPT-4的0.79）\n，已达到人类专家间一致性水平\n（88.5%~92.0%）\n。\n这证明GAPS评测集的自动评判能力具备专家级可靠性。\n在此基础上，评测不再是终点，而是进化的起点。\n框架输出的结构化评分\n（G/A/P/S四维、MET/NOT-MET标记）\n可精准定位模型在循证决策、回答完备性、扰动鲁棒性或安全红线上的缺陷；\n由此，\nGAPS具备成为“评测即反馈、反馈即迭代”的最重要基石\n——\nA\nI医疗能力不再依赖模糊经验，而是通过可量化的指标、可复现的流程、可积累的进化路径，稳步向临床可用迈进。\n实战揭秘：顶尖大模型的“滑铁卢”\n研究团队使用GAPS对GPT-5、Gemini 2.5 Pro、Claude Opus 4、Qwen3-235B-A22B-Instruct-2507、DeepSeek-V3.1-Terminus等主流模型进行“体检”，结果发人深省：\n1、“百科全书”易做，“专家”难当：\n所有模型在G1\n（事实）\n和G2\n（解释）\n阶段表现优异\n（GPT-5得分约0.72）\n。但一旦进入G3\n（确定性决策）\n和G4\n（非确定性推理）\n，分数呈断崖式下跌，GPT-5在G4阶段跌至0.45，其他模型甚至跌破0.35。这说明 AI目前还只是“背书机器”，而非“推理伙伴”。\n2、不仅要“对”，还要“全”：\n在Adequacy\n（完备性）\n测试中，模型往往只给出核心建议\n（A1）\n，却忽略了关键的限定条件\n（A2）\n，导致临床建议缺乏可操作性。\n3、极其脆弱的耳根子：\n在P3\n（对抗性测试）\n中，只要在提问中加入一点误导性前提\n（例如暗示某种错误疗法有效）\n，模型的判断力就会崩塌，甚至顺从用户的错误引导。\n4、安全隐患：\n虽然GPT-5和Gemini 2.5在极高风险错误\n（S4）\n上控制较好，但在复杂的推理场景下，部分模型\n（如Claude Opus 4）\n的致命错误率随难度显著上升。\n结语：GAPS评测框架是AI医生从“Chatbot”到“Doctor”的必经之路\nGAPS的发布，标志着医疗AI的评测标准从\n“考试分数”\n向\n“临床胜任力”\n的范式转移。\n蚂蚁健康与北大人民医院的这项工作告诉行业——\n现有的通用大模型在面对复杂的临床不确定性时，依然显得稚嫩且脆弱。\n未来的医疗AI研发，不能止步于预训练知识的灌输，而必须转向\n循证推理\n（Evidence-grounded Reasoning）\n、过程决策控制以及不确定性管理\n。\nGAPS不仅仅是一个榜单，它更是医疗AI进化路上的“磨刀石”。只有跨越了GAPS设定的这四道关卡，AI医生才能真正放心地走进诊室。\n论文地址：\nhttps://arxiv.org/abs/2510.13734\n评测集地址：\nhttps://huggingface.co/datasets/AQ-MedAI/GAPS-NSCLC-preview\n自动化评测框架地址：\nhttps://github.com/AQ-MedAI/MedicalAiBenchEval\n*本文系量子位获授权刊载，观点仅为原作者所有。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859141&idx=2&sn=37254cbdb7b48a1b330d2fe11479c130&chksm=e951e3efabf823451bf5df114d28d8dccf3c76624fdb592e9ddfcfc33f3bb29b7795573347bd&scene=0&xtrack=1#rd",
      "publish_time": 1767145800,
      "publish_date": "2025-12-31 09:50",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2510.13734\", \"https://huggingface.co/datasets/AQ-MedAI/GAPS-NSCLC-preview\", \"https://github.com/AQ-MedAI/MedicalAiBenchEval\"]",
      "add_ts": 1767193381,
      "last_modify_ts": 1767309709
    },
    {
      "id": 144,
      "article_id": "51514",
      "title": "老黄200亿「钞能力」回应谷歌：联手Groq，补上推理短板",
      "description": "英伟达投入200亿美元拉拢AI芯片新锐Groq，以应对谷歌TPU等新兴技术的挑战，凸显其在AI时代巩固领先地位的战略布局。此举反映老黄对新型芯片架构崛起的警惕，也显示Groq在高性能推理和效率上的潜力。科技投资人Gavin Baker认为，Groq或可补足英伟达在特定AI工作负载上的短板，强化生态护城河。",
      "content": "Jay 发自 凹非寺\n量子位 | 公众号 QbitAI\n老黄稳准狠，谷歌的TPU威胁刚至，就钞能力回应了。\n200亿美元说砸就砸，\n只为拉拢一家炙手可热的「铲子新工厂」——\nGroq\n。\n这无疑也标志这家芯片巨头，面向AI新时代的一次重大布局。但在某种程度上，也的确反映出老黄对包括TPU在内等一众新芯片范式的担忧。\n所以，\nGroq究竟能为英伟达带来什么？\n针对这个问题，知名科技投资人Gavin Baker发表了自己的观点。\n而他的这一连串技术剖析，纷纷指向了英伟达帝国防守最薄弱的那块领土——\n推理\n。\n推理方面，Groq LPU的速度远超GPU、TPU，以及目前所见的任何ASIC。\n这一观点得到大量网友点赞：\nGPU架构根本无法满足推理市场对低延迟的需求，片外HBM显存速度实在太慢了。\n但也有网友指出，LPU所采用的SRAM，或许并不能胜任长下文decode。\n对此，Gavin认为英伟达可以通过产品「混搭」的方式解决。\n下面具体来看——\nGroq：英伟达斥200亿美元购入的一剂疫苗\nGavin认为，GPU在新时代水土不服的根本原因在于——推理过程的两个阶段，\nprefill和decode\n，对芯片能力有截然不同的要求。\n先看prefill：\n这一步，简单来说就是让模型「读题」，把用户提供的关键信息在脑子里记好，用于后续调用。\n读题过程中，模型会一次性吃下用户所给的上下文，所有输入token都可以同时计算。\n这正是GPU最擅长的舞台，其为图形处理而生，可以一次性计算数千个像素，天生适合处理并行任务。\n在这个准备阶段，模型不用急着响应用户问题。即便有延迟，模型也完全可以通过显示「思考中」来掩盖等待时间。\n因此，相比「速度」，prefiil需要芯片有更大的上下文容量。\n但到了\ndecode\n，这套逻辑不再适用。\ndecode是串行任务，必须得一个一个token挨着算。更重要的是，用户还会亲眼看到token被一个个「打」出来的过程。这种情况下，延迟对用户体验来说是致命的。\n然而，GPU的数据主要存放在HBM，而不是紧贴算力核心的片上存储。这意味着，每生成一个token，GPU都需要重新从内存中读取数据。\n这时候，GPU的问题就暴露出来了——大部分算力都处于闲置，FLOPs根本用不满，常常在等内存把数据搬过来，实际计算量远小于prefill。\n相比之下，Groq有更好的解决方案——\nLPU\n。\n比起HBM，LPU使用直接集成在芯片硅片中的SRAM。这种片上存储的模式不需要读取数据，这让其速度比GPU快100倍。即使只处理单个用户，它也能跑出每秒300–500个token的速度，并能始终保持满负荷运转。\n事实证明，在速度这一块，LPU几乎打遍天下无敌手——不仅是GPU，就连TPU，以及市面上绝大多数ASIC都难以望其项背。\n但这并非没有代价的。\n相比GPU，LPU的内存容量小的多。单颗Groq的LPU芯片，片上SRAM只有230MB。\n作为对比，即便是英伟达的H200 GPU，也配备了高达141GB的HBM3e显存。\n结果就是：\n你必须把成百上千颗LPU芯片连在一起，才能跑起一个模型\n。\n以Llama-3 70B为例，用英伟达GPU的话，只需要两到四张卡，塞进一个小型服务器盒子里就能搞定。而同样的模型，需要数百颗LPU，占地面积也将远大于使用GPU的数据中心。\n这意味着，即便单颗LPU价格更低，整体硬件投资依然会非常巨大。\n因此，AI公司在考虑LPU时，最重要的问题是——\n用户是否愿意为「速度」付费？\n对于这个问题，一年前的市场还不无法给出答案。但从Groq如今的业绩情况来看已经非常明确：\n「速度」是个真实存在的巨大需求，并且仍在高速成长\n。\n而对英伟达而言，这不仅是一个新的业务盘，更是一个颠覆者暗流涌动的高风险地带。倘若错失这个风口，英伟达在AI时代的机会可能会被新玩家颠覆，就像英伟达当年通过游戏业务颠覆其他竞争对手一样。\n为了抵抗这些竞争者蚕食自己的护城河，英伟达选择注射名为Groq的疫苗。希望通过人才收购引入新血液，补齐这块低延迟场景的推理短板，帮助英伟达这艘巨舰摆脱创新者窘境。\n「铲子」进入新时代\nTPU的崛起，给英伟达的金钟罩撕开了一道裂缝。\n通过自研芯片，谷歌成功摆脱了对英伟达天价GPU的依赖，这在很大程度上帮助谷歌削薄了训练和推理成本，这让谷歌在服务大量免费用户的情况下，依然能维持相当健康的财务账面。\n谷歌通过Gemini 3 Pro的绝地翻盘，证明了GPU并非AI时代的唯一解。在技术周期高速迭代的背景下，作为AI「心脏」的芯片，也需要根据不同的发展阶段做出相应的调整。\n随着基础模型的进展放缓，AI竞争的重点开始从训练层转向应用层。而在AI应用市场，「速度」对用户体验而言至关重要。\n而这次人才收购Groq，虽然也是变相承认了公司在推理赛道的不足，但同样标志着英伟达帝国的又一次扩张。\n称霸预训练的英伟达，这次要借Groq的东风，入局竞争对手喷涌而出的「推理大陆」。\n而在这个新市场，英伟达或许不再能像如今这样风光。\n正如Groq CEO所言，\n推理芯片是项高销量、低利润的苦活\n。这与即便炒到天价也有客户抢着要，毛利率高达70-80%的GPU截然不同。\n参考链接：\n[1]https://x.com/gavinsbaker/status/2004562536918598000\n[2]https://www.uncoveralpha.com/p/the-20-billion-admission-why-nvidia\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247858871&idx=1&sn=4c6f3457c1befcba8cf54d12a4a0daa5&chksm=e916d6fc497eb05d87749bcf99aff741f8a0308e4c1008d3dc50a74d4de96903ba9e0638f9a6&scene=0&xtrack=1#rd",
      "publish_time": 1767066600,
      "publish_date": "2025-12-30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/gavinsbaker/status/2004562536918598000\", \"https://www.uncoveralpha.com/p/the-20-billion-admission-why-nvidia\"]",
      "add_ts": 1767223322,
      "last_modify_ts": 1767223322
    },
    {
      "id": 146,
      "article_id": "51591",
      "title": "动态RAG性能提升14个点！用4万亿token教会大模型 「什么时候该检索」",
      "description": "QuCo-RAG是伊利诺伊大学芝加哥分校、纽约大学与蒙纳士大学联合提出的新型动态检索增强生成框架，首次摒弃依赖大模型内部信号（如logits、attention）的传统做法，转而利用外部问答数据集构建查询-上下文匹配信号，实现更可靠的检索触发判断。该方法有效缓解了因LLM信号校准差导致的幻觉问题，在多个基准任务中显著提升准确率与鲁棒性，为RAG系统提供了更可信的动态检索新范式。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n动态检索增强生成（Dynamic RAG）通过自适应判断「何时检索」来缓解大语言模型的幻觉问题，但现有方法普遍依赖模型内部信号（logits、entropy、attention等），而LLM本身的信号校准较差，即常对错误答案「自信满满」。近日，来自伊利诺伊大学芝加哥分校、纽约大学、与蒙纳士大学的联合团队提出QuCo-RAG，首次跳出「从模型自己内部信号来评估不确定性」的思维定式，转而用预训练语料的客观统计来量化不确定性，在多跳QA基准上对OLMo系列模型实现5-14个EM点的显著提升，并且有效性成功迁移至Llama3、Qwen2.5、GPT4.1/5等预训练数据未公开的模型。\n当检索增强生成（RAG）从静态走向动态，一个核心问题浮出水面：\n何时该触发检索？\n现有方法的答案是：看模型内部信号。FLARE看句子中的token生成概率，DRAGIN看entropy和attention，ETC看entropy的一阶二阶差分，SeaKR看FFN内部状态……\n但这一范式存\n根本性缺陷\n：\nLLM通常校准能力很差，经常对错误输出表现出高置信度。\nDRAGIN vs QuCo-RAG对比。(a)DRAGIN依赖模型内部信号，错误地将问题中的「Il」标记为高不确定性，却对幻觉出的错误导演名显示低不确定性。(b) QuCo-RAG通过预训练语料中的零共现检测，正确识别出幻觉。\nDRAGIN在生成错误的导演名「Mario Camerini」时显示\n低不确定性\n（Uncertainty < threshold），却对问题中的普通token「Il」报出\n高不确定性\n（Uncertainty = 1.47 > threshold）。\n这就是所谓的「自信地胡说八道」（confident hallucination）——模型不知道自己不知道，内部信号完全失效。\n更根本地，近期理论工作（Kalai & Vempala, 2024）证明：\n对于罕见事实，即使是完美校准的模型也必须产生幻觉以维持统计一致性。\n那么，有没有一种方法，能绕过这些不可靠的内部信号？\n伊利诺伊大学芝加哥分校、纽约大学、与蒙纳士大学的联合团队提出QuCo-RAG，首次跳出「从模型自己内部信号来评估不确定性」的思维定式，转而用预训练语料的客观统计来量化不确定性，在多跳QA基准上对OLMo系列模型实现5-14个EM点的显著提升，并且有效性成功迁移至Llama3、Qwen2.5、GPT4.1/5等预训练数据未公开的模型。\n论文链接：https://arxiv.org/abs/2512.19134\n开源代码：https://github.com/ZhishanQ/QuCo-RAG\nQuCo-RAG的核心洞察是\n：\nLLM的事实知识本质上由预训练语料塑造\n。\n低频实体 = 长尾知识\n风险\n：\n如果一个实体在预训练语料中很少出现，模型就难以可靠地记忆关于它的知识。\n零共现 = 幻觉高风险\n：\n如果两个实体在整个预训练语料中\n从未在同时出现\n，那么模型声称的它们之间的关系就缺乏任何证据支撑——这几乎必然是幻觉。\n更重要的是，这种因果关系是不对称的：\n共现 ≠ 正确（两个实体可能以不同关系共现）\n零共现 ≈ 幻觉（模型无法可靠地生成训练数据中从未见过的实体关系）\n基于这一洞察，QuCo-RAG从「主观内部置信度」转向「客观语料统计」，通过Infini-gram引擎对\n4万亿token\n的OLMo-2预训练语料进行\n毫秒级查询\n，实现精准的检索触发。\nQuCo-RAG框架总览。两阶段检测：生成前知识评估（检查实体频率）+ 运行时声明验证（检查实体共现）。\nQuCo-RAG通过两阶段检测机制量化不确定性：\n第一阶段：生成前知识评估（Pre-Generation Knowledge Assessment）\n在模型开始生成之前，系统首先「诊断」输入问题：\n提取问题中的关键实体（如Silas Hardy、Lee Mantle）；\n查询每个实体在4万亿token预训练语料中的出现频率；\n如果平均频率低于阈值（默认1000次），触发检索；\n核心逻辑\n：\n低频实体代表「长尾知识」，模型很可能没有可靠记忆。\n第二阶段：运行时声明验证（Runtime Claim Verification）\n在模型生成过程中，系统持续监控每个生成的句子：\n使用轻量级0.5B模型提取知识三元组（头实体, 关系, 尾实体）；\n查询头尾实体在预训练语料中的共现次数；\n如果共现次数为0，触发检索并重新生成；\n核心逻辑\n：\n零共现意味着模型正在「无中生有」——编造训练数据中从未出现过的实体关系。\n毫秒级语料库查询\n如何在4万亿token的语料库上实现实时查询？\nQuCo-RAG利用\nInfini-gram\n引擎——一个基于后缀数组的索引系统，支持对万亿级token语料库的\n毫秒级\n频率和共现查询。\n轻量级三元组提取器\n为了最小化开销，团队从GPT-4o-mini蒸馏了一个专用的0.5B三元组提取模型，基于Qwen2.5-0.5B-Instruct微调。\nQuCo-RAG各组件运行时间分解。LLM生成占主导（55-74%），Infini-gram查询仅占18-31%，证明语料库检测引入的开销适度。\n实验结果\n全面领先，迁移能力惊人\nOLMo-2全系列5-12点提升\nQuCo-RAG在所有模型规模和数据集上均取得最佳性能，EM提升5-12点。\n在2WikiMultihopQA和HotpotQA两大多跳QA基准上，QuCo-RAG在OLMo-2全系列模型（7B、13B、32B）上\n全面超越所有baseline\n：\nOLMo-2-7B：+7.4 EM (2Wiki), +5.6 EM (HotpotQA)\nOLMo-2-13B：+12.0 EM (2Wiki), +5.3 EM (HotpotQA)\nOLMo-2-32B：+9.4 EM (2Wiki), +10.8 EM (HotpotQA)\n而基于内部信号的方法（FLARE、DRAGIN、ETC、SeaKR）表现极不稳定，有时甚至不如简单的单轮检索（SR-RAG）。\n主实验为什么选择OLMo-2？\nQuCo-RAG的核心是利用预训练语料的统计信息。但一个关键问题是：\n如何验证「语料统计」这个信号源本身是有效的？\n这就需要一个「匹配语料」设置——即模型的预训练数据必须完全公开，才能精确计算实体频率和共现统计。\nOLMo-2是目前\n满足这一条件的高性能代表性开源模型\n：\n提供完整的4万亿token预训练语料\n性能与Qwen2.5等主流模型相当\n覆盖7B/13B/32B多个规模\n这使得OLMo-2成为验证QuCo-RAG核心假设的理想测试平台。\n跨模型迁移：代理语料库同样有效\n一个关键问题：如果模型的预训练数据不公开怎么办？\n研究团队验证了一个重要假设：\n网络规模的预训练语料库之间存在大量重叠\n。\n因此，使用OLMo-2的语料库作为「代理语料库」，同样可以有效指导其他模型。\nQuCo-RAG在Qwen2.5、Llama-3、GPT-4.1、GPT-5等模型上均实现显著提升。\n关键发现：\nQwen2.5-32B\n：2WikiMultihopQA上提升14.1 EM\nGPT-5-chat\n：2WikiMultihopQA上提升8.7 EM\n相比之下，GPT模型自带的Web搜索工具反而\n低于\n不检索基线（可能因为网络噪声）\n效率分析：更少检索，更高性能\n效率-性能权衡分析。QuCo-RAG以最少的token消耗和LLM调用次数达到最高EM。\nQuCo-RAG实现了「精准狙击」式的检索：\n平均每个问题仅触发1.70次检索\ntoken消耗仅87个，LLM调用仅1.84次\n而FS-RAG和DRAGIN消耗2-4倍的token，性能却大幅落后\n领域泛化：生物医学问答同样有效\n在PubMedQA生物医学问答基准上，QuCo-RAG同样表现出色：\nQuCo-RAG在PubMedQA上达到66.4%准确率，超越Wo-RAG 11.2个百分点。\n内部信号方法在这个专业领域暴露出两种失败模式：\n过度检索\n：FLARE平均2.79次检索，token消耗516。显著高于它在通用领域的检索次数和token消耗。\n检索不足\n：DRAGIN和ETC触发检索的次数显著低于它在通用领域的检索次数。Acc表现与不检索基线持平。\nQuCo-RAG则两者兼顾：平均0.93次检索，54.9个token，最高准确率。\n深度分析：为什么实体频率分析有效？\n按实体频率分层的性能分析。低频区QuCo-RAG优势明显，高频区优势依然保持。\n研究团队按实体在语料库中的出现频率将问题分组，揭示了有趣的规律：\n低频区：\n模型缺乏知识，但内部信号无法识别这种知识缺陷\n中频区：\n模型处于「部分学习」状态，熵等内部信号变得相对有效\n高频区：\n实体频率 ≠ 事实频率——即使实体常见，它们的特定关系可能罕见\n这最后一点尤为重要：高频实体让模型「过度自信」，但QuCo-RAG通过共现检测捕捉到模型对熟悉实体的错误关系声明。\n深远影响与未来方向\n本文将语料统计确立为模型内部不确定性信号的客观替代方案。虽然本文聚焦于RAG系统中的检索触发，但这一范式转变在AI安全与鲁棒性领域开辟了多个值得探索的研究方向。\n赋能可信AI应用\n实验证明，语料统计比内部信号提供了更可靠的不确定性度量。这种可靠性不仅对RAG有价值，还可扩展到更广泛的安全关键任务：\n选择性回答：当缺乏证据支撑时，模型可以拒绝回答\n正确性预测：语料统计为生成的声明提供有据可依的置信度评分\n从推理时干预到以数据为中心的AI\n语料统计分析能够精确识别模型的知识盲区。\n这一信号可以指导训练数据策划：与其仅在推理时通过检索来弥补知识缺口，开发者可以在持续预训练或后训练阶段主动收集低频实体的数据。类似地，语料统计还可以指导：\n合成数据过滤：在纳入训练集之前，用语料统计验证LLM生成的训练样本\n模型编辑：区分哪些事实需要定向注入，哪些已被模型可靠学习\n范式的延伸方向\n多个研究方向值得探索：\n多语言验证：通过跨语言统计实现多语言场景的不确定性量化\n时序动态：利用带时间戳的语料处理知识演变问题\n超越实体：将方法扩展到事件、关系和数值声明的验证\n智能体集成：作为自我验证工具集成到智能体系统中，在执行动作前验证生成内容\n理论基础\n跨模型迁移的有效性引发了一些值得思考的问题：为什么代理语料能跨模型族生效？能否形式化地建立「给定语料统计的幻觉概率」的信息论界限？这些问题与LLM中「记忆vs泛化」的更广泛讨论相关联。\n参考资料：\nhttps://arxiv.org/abs/2512.19134\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659612&idx=2&sn=55630b306d35ac8733216edde7d41423&chksm=f0f43248008c2cf534e7cd37a7186e8e61cee46db9dbca164322d95934532e4fd1717e036082&scene=0&xtrack=1#rd",
      "publish_time": 1767285600,
      "publish_date": "2026-01-02 00:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.19134\", \"https://github.com/ZhishanQ/QuCo-RAG\"]",
      "add_ts": 1767309498,
      "last_modify_ts": 1767395913
    },
    {
      "id": 148,
      "article_id": "51589",
      "title": "最强音频越狱威胁！港科大新基准收集超20万样本｜NeurIPS'25",
      "description": "香港科技大学、牛津大学与西安交通大学联合提出首个音频越狱评测基准Jailbreak-AudioBench，旨在评估大音频语言模型在面对强调、语速、语调等语音编辑时的安全性与鲁棒性。该研究系统分析了音频隐含语义对模型安全判定的干扰，揭示了现有模型的漏洞，为构建更安全的音频语言模型提供了方法论支持，推动多模态AI安全评估体系发展。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n音频中的强调、语速、语调等隐藏语义可能干扰模型的安全判定，引发新的攻击点。为此，香港科技大学、牛津大学和西安交通大学的研究人员提出了首个全面的音频越狱评测基准Jailbreak-AudioBench，系统分析了模型在面对音频编辑时的鲁棒性差异，并为构建更安全的模型提供方法论基础。\n端到端大音频语言模型（End-to-End Large Audio Language Models）正逐步成为语音交互场景与多模态智能感知系统的重要基础设施。\n然而，在安全层面，一个已被广泛验证的风险在于：模型可能在特定输入策略的诱导下绕过对齐约束，输出本应被拒绝的有害内容，即「越狱（jailbreak）」。\n在文本与视觉模态中，研究者已系统总结出多种成熟的越狱范式，例如提示注入、角色扮演、语义改写，以及图像隐写与对抗扰动等，这些方法均可能削弱模型的拒答机制，并在实际应用中引发安全隐患。\n相比之下，音频模态上的越狱研究仍明显不足。音频不仅承载文本语义，还包含强调、语速、语调、音高、口音、背景噪声与情绪等隐藏语义（hidden semantics）信息。\n这些看似自然的声学变化，可能在不改变表面文本含义的情况下干扰模型的语义理解与安全判定，从而引入新的攻击面与评测盲区。\n然而，现有研究仍缺乏针对「音频隐藏语义越狱」的专门数据集与系统性评测框架。\n为填补这一空白，香港科技大学、牛津大学与西安交通大学的研究人员提出了\nJailbreak-AudioBench\n，并在多种具有代表性的开源与商用闭源端到端大音频语言模型上，构建了迄今最为全面的音频越狱评测基准。\n论文链接:\nhttps://neurips.cc/virtual/2025/loc/san-diego/poster/121592\n项目网址：\nhttps://researchtopic.github.io/Jailbreak-AudioBench_Page\n代码\n仓库\n：\nhttps://github.com/Researchtopic/Code-Jailbreak-AudioBench\n同时，为实现从现象到机理的系统性分析，研究人员进一步\n探究了不同模型在面对音频编辑时鲁棒性差异的成因，提出可解释的表征层指标，为构建更安全、鲁棒的\n端到端\n大音频语言模型提供方法论基础\n。\n在此基础上，研究者们进一步开展拓展研究，以验证Jailbreak-AudioBench对研究社区的广泛价值：（1）揭露更强的越狱威胁，即「组合音频编辑 × 多次查询」；（2）提供一种轻量级、易部署的防御方案。\n为什么「音频隐藏语义」会带来新的安全威胁？\n「文本越狱」通常关注的是「字面内容」的提示注入；但在音频里，隐藏语义并不一定写在文字里，例如：\n强调：重读某个动词/名词，可能提高模型对某类意图的置信度；\n语速：过快/过慢会改变语音识别或语音编码器提取到的节奏特征；\n语调与音高：上扬、下沉、音高偏移会影响语用层面的「请求力度」和指令性；\n噪声与口音：现实场景中的噪声、环境声、口音差异，会导致模型对「同一文本内容」的内部表征偏移；\n情绪：大笑、尖叫、愤怒、急促等情绪线索，可能触发不同的对齐/拒答分支。\n正因如此，音频越狱不仅是「把文本读出来」，而是引入了一套更复杂、更贴近现实部署的扰动空间，它更加自然、成本低和可迁移，但目前的安全对齐系统依旧缺少针对性评测和预防。\n可复用的「音频隐藏语义注入」工具箱和音频越狱数据集\n研究人员提供了一个将任意文本请求转换为音频，并支持\n多种可控编辑来注入隐藏语义（强调/语速/语调/音高/背景噪声/名人口音/情绪）的工具箱(toolbox)\n，用于系统化构造音频越狱样本。\n基于该工具箱，在多套主流文本越狱问题数据集的基础上，通过20类音频编辑生成音频越狱样本变体，构造的整体音频越狱数据集规模为157,782 (主数据集) + 56,742 (附加数据集) 个音频样本。\n实验结果\n覆盖开源与闭源的音频越狱评测基准\n研究人员系统评测了开源BLSP、SpeechGPT、Qwen2-Audio、SALMONN、VITA-1.5、R1-AQA、MiniCPM-o-2.6，以及闭源GPT-4o-Audio、Gemini-2.5-Flash等模型，量化不同音频编辑对攻击成功率（Attack Successful Rate, ASR）的影响，揭示了同样的有害请求，仅改变音频「隐藏语义」，就可能显著改变模型的拒答/越狱表现。\n从现象到机理的分析：为什么有些模型对音频编辑更鲁棒？\n研究人员进一步分析了不同模型对音频编辑的内部表征机制：通过对音频编码器输出及不同Transformer层隐藏状态的可视化，系统考察了不同编辑类型在表示空间中的聚类与分离特性。\n结果表明，对于鲁棒性更强的模型(鲁棒性：Qwen2-Audio-7B>MiniCPM-o-2.6>SALMONN-7B)，随着网络层数的加深，其表示空间会逐步由「按编辑类型聚类」过渡为「按语义聚类」，编辑痕迹逐渐被语义信息所吸收；而对于相对脆弱的模型，编辑类型相关特征在中后层仍然显著存在，使模型更容易受到「隐藏语义」的牵引与误导。\n上述发现为后续的越狱防御提供了新的启示：越狱安全问题不仅局限于输出端的「拒答模板」设计，更可能需要从表示学习与对齐策略层面出发，提升模型对音频扰动的语义不变性与稳健判别能力。\n因此，这一分析不仅为定量评估\n端到端\n大音频语言模型在面对音频隐藏语义干扰时的鲁棒性强弱提供了可解释的表征层指标，也为构建更加准确、鲁棒且具备安全对齐能力的端到端大音频语言模型奠定了方法论基础。\n未来应用\nJailbreak-AudioBench启发的拓展研究\n更强的音频编辑越狱威胁：组合编辑×多次查询\n现实中的越狱攻击往往并非「一次输入定胜负」。\n攻击者不仅可以针对同一条音频生成多个不同版本，还能够将多种编辑手段进行混合与叠加（例如同时调整语速、语调与音高，并注入噪声或情绪线索），从而在声学空间中引入更高程度的多样性。\n基于这一观察，研究人员提出了一种黑盒（Black-box）、基于查询的音频编辑越狱攻击方法（Query-based Audio Editing Jailbreak Attack），通过对同一样本构造多种混合编辑变体，并借助多次查询机制，系统性地放大越狱成功率。实验结果表明，该方法在多种模型上均显著提升了攻击成功率（ASR）：\nQwen2-Audio-7B从13.3%提升至48.8%，SALMONN-7B从31.6%提升至85.1%，GPT-4o-Audio从0.7%提升至8.4%，Gemini-2.5-Flash也从 8.1% 大幅提升至 49.4%\n这表明，即便某些模型在「单次、原始音频」条件下看似较为安全，当攻击者采用混合编辑与多次试探相结合的越狱策略时，其潜在风险仍会被系统性放大。\n因此，若安全评测忽略这种更贴近真实场景的「组合编辑 + 多次查询」音频越狱攻击设置，便可能显著低估模型在实际部署环境中的安全风险。\n防御方法探究：音频前置安全指令\n研究人员也探索了一个轻量级、易部署的基线防御思路，在输入音频前拼接一段「安全指令/拒答导向」的音频提示，从而引导模型在后续对话中更倾向于拒绝高风险请求。\n评测显示，这种方式在多个模型上能带来一定幅度的攻击成功率（ASR）降低，但并不能彻底解决问题，仍存在残余越狱成功率。\n这提示了音频越狱安全可能需要更系统的端到端方案，例如更稳健的音频编码、对齐数据覆盖、以及专门针对「隐藏语义扰动」的训练与检测机制。\n参考资料：\nhttps://neurips.cc/virtual/2025/loc/san-diego/poster/121592\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659613&idx=2&sn=5d99f0b6a53ec7cb197d25788b0b34b1&chksm=f0e1a7248028682fbdfe97575e29629c6176368774f5a0fa172eebfabf29590c95ef54284284&scene=0&xtrack=1#rd",
      "publish_time": 1767285600,
      "publish_date": "2026-01-02 00:40",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://neurips.cc/virtual/2025/loc/san-diego/poster/121592\", \"https://researchtopic.github.io/Jailbreak-AudioBench_Page\", \"https://github.com/Researchtopic/Code-Jailbreak-AudioBench\"]",
      "add_ts": 1767309503,
      "last_modify_ts": 1767395920
    },
    {
      "id": 153,
      "article_id": "51584",
      "title": "马斯克买了新厂房上GPU，2GW供电规模，“巨硬”更更硬了",
      "description": "马斯克“巨硬计划”再升级，第三栋专属厂房MACROHARDRR已购入，供电规模达2GW，可满足约150万户家庭用电。按现有功耗密度估算，新厂可支持约110万台英伟达GB200 NVL72 GPU，大幅提升xAI算力储备，进一步巩固其在AI基础设施领域的领先地位。",
      "content": "西风 发自 凹非寺\n量子位 | 公众号 QbitAI\n马斯克“巨硬计划”新消息，第三栋专属厂房已经买下来了，代号\nMACROHARD\nRR\n。\n果然更硬核，老马透露，其将具备\n2GW\n供电规模。\n什么概念？\n1GW电力足以满足约75万户美国家庭的用电需求。\n若参照此前曝光的（200MW支持11万台GB200）的功耗密度与架构效率推算，\n可支持约110万台英伟达GB200 NVL72 GPU\n。\n到建成，xAI算力储备将再创全球之最。\n算力巨兽持续扩容\n马斯克口中第一厂，早已为人所熟知——\nColossus I\n。\nColossus I验证了xAI大规模自建超级计算集群的可行性，\n从无到有建成\n所有配套设施仅用了122天\n，“从第一个机架落地到开始训练任务，只用了19天”。\n至今，Colossus I仍是全球规模最大、运行状态最稳定的单一算力集群，配备约20万颗英伟达H100/H200和约3万颗英伟达GB200 NVL72。\n紧随其后，2025年3月7日建设第二厂\nColossus II\n的项目正式启动。当时xAI在孟菲斯收购了一座100万平方英尺的仓库及两块相邻地块，总面积达100英亩。\n8月，Colossus II已经安装了119台风冷式冷水机组，提供约200MW的冷却能力，足以支持约11万个GB200 NVL72 GPU。\n按照规划，Colossus II第一阶段部署11万个英伟达GB200 GPU，最终目标是超过55万个GPU，峰值功率需求预计超过1.1GW。\n马斯克巨硬（Macrohard）项目，也是在8月份公开的。\n后续，马斯克承认Colossus II正是巨硬计划的一部分。\n而这个名字呢，其实老马早在2021年就构思好了。\n直到最近，有媒体援引房产记录披露，xAI的一家子公司从贝莱德旗下私募股权房地产公司ElmTree Funds的关联方手中，拿下了位于美国密西西比州Soso地区的一栋81万平方英尺的仓库。\n而该地，正好紧邻Colossus II，仅隔州界的那种。\n随后马斯克公开确认，这确实就是巨硬的第三厂了，还给起名MACROHARDRR。据爆料，近几周施工人员还修建了一条连接Colossus II与MACROHARDRR的新路。\n被居民投诉啦\n值得一提的是，xAI的巨硬中心选址离着居民区较近，Colossus建成时就遭到了大量投诉。原因是xAI在现场使用了便携式燃气轮机，一些人认为这些涡轮机加剧了孟菲斯的空气污染。\n2025年初，xAI从Colossus移除了部分燃气轮机，并将更多基础设施项目迁移至密西西比州——\n通过与一家名为Solaris Energy Infrastructure的德州能源公司合资（Solaris持股50.1%，xAI持股49.9%），在密西西比州建设一座永久性的燃气轮机发电厂。\n该设施也为Colossus II提供电力，xAI已修建了连接这些设施的新电力线路。\nSolaris在证券filings中表示，预计到2027年初，通过合资企业向xAI提供超过1GW的电力。\n除了在建的发电厂外，Colossus II和最新MACROHARDRR还靠近田纳西河谷管理局运营的另一座燃气电厂、一条天然气管线，以及与田纳西州和密西西比州当地公用事业公司的连接。\n不过呢，邻居又来投诉了，这次主要是因为发电厂场地的发电机和施工产生的噪音。据了解，近几个月来，xAI已在发电厂场地与附近居民区之间竖起了一堵高墙，以降低噪音。\n为避免对当地电网造成冲击，xAI还在Colossus II场址部署了168个特斯拉Megapack电池储能系统，在用电高峰期提供电力支持，确保当地居民不会遭遇停电。\n此外，系列算力设施的建设与扩容需要巨额资金支持。\n一个月前，多家外媒报道称，xAI正计划以2300亿美元估值筹集150亿美元。\n针对融到钱的相关报道，马斯克曾回应称“消息不实”，但未给出更多补充解释。\n参考链接：\n[1]https://x.com/elonmusk/status/2006108047609930069\n[2]https://www.bloomberg.com/news/articles/2025-12-30/musk-s-xai-to-expand-colossus-data-center-information-reports\n[3]https://www.theinformation.com/articles/elon-musks-xai-buys-building-third-supersized-data-center\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859515&idx=3&sn=0683eb63c43fcdf20b8fee283e4523d6&chksm=e92c5d80e73bbb648f58490bfbee67d58ed5fdc98eb90fbb14a7e04db161835ae3069b1f8855&scene=0&xtrack=1#rd",
      "publish_time": 1767262800,
      "publish_date": "2026-01-01 18:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/elonmusk/status/2006108047609930069\", \"https://www.bloomberg.com/news/articles/2025-12-30/musk-s-xai-to-expand-colossus-data-center-information-reports\", \"https://www.theinformation.com/articles/elon-musks-xai-buys-building-third-supersized-data-center\"]",
      "add_ts": 1767309523,
      "last_modify_ts": 1767395939
    },
    {
      "id": 156,
      "article_id": "51581",
      "title": "拟动态网络构建多样性互作网络的理论与方法丨周日分享·理论生态学读书会",
      "description": "本期读书会由北京林业大学田硕介绍idopNetwork方法，探讨如何从静态生态数据中揭示物种间动态互作网络。针对生态学中的“时间悖论”问题，该方法利用拟动态常微分方程（qdODEs）重建具有动态特性的生物调控网络，突破传统静态分析局限。该技术为理解生态系统稳定性与物种相互作用提供了新路径，尤其适用于难以获取时序数据的复杂生态系统，如青藏高原的动植物多样性研究，助力揭示生态过程的内在动态机制。",
      "content": "导语\n生态系统稳定性与物种间的复杂相互作用是生态学研究的重要课题。\n本期读书会中，北京林业大学草业与草原学院硕士研究生田硕将介绍idopNetwork方法，这一创新性生物调控网络构建方法如何从静态数据中揭示动态互作网络——首先概括生态学中“时间悖论”的问题，随后详细阐述如何通过拟动态常微分方程（qdODEs）方法，利用静态数据重建具有动态特性的网络。领读人目前从事青藏高原动植物多样性研究，试图将该方法运用到宏观生态系统，致力于推动生物互作网络在生态学中的创新应用。\n集智俱乐部联合北京林业大学大学副教授李周园，普利高津奖章得主、Towson大学Brian D. Fath教授以及北京大学理论生态学课题组博士研究生于越共同发起\n「理论生态学读书会」\n，旨在深入探讨理论生态学的基础思想与前沿进展，通过分享经典文献与最新研究，促进对生态学复杂性、共存机制及生态系统动态的理解，推动理论生态学与实际生态问题的连接与创新。\n内容简介\n网络建模是生命科学和生态学研究中的前沿方向之一，尤其在生物多样性研究、生态系统动力学分析及基因调控机制揭示等领域，网络方法已成为必不可少的工具。idopNetwork是一种通过多维样本数据识别提炼生物互作调控网络构建方法，能够从多种数据源中重建复杂的生物互作网络，具有信息量丰富（informative）、动态性强（dynamic）、全方位覆盖（omnidirectional）以及个性化的显著特点（personalized）。idopNetwork方法的核心优势在于其能从静态数据中构建具有方向性的动态网络，揭示不同因子之间的互作关系，而无需依赖传统的时间序列数据。该方法不仅能够有效处理高维和异质数据，还能量化每个因子的独立效应和相互依赖效应，进而为每个样本构建个性化的互作网络。此外，idopNetwork方法的通用性使其不仅限于细胞和基因层面的应用，也为宏观生态系统中物种间的复杂相互作用提供了全新的解析框架。在本次分享交流中，领读人将分享介绍生态统计学与动力学建模的融合，通过拟动态网络构建的方式解析生物多样性互作网络的理论、方法与应用。报告将重点展示idopNetwork方法如何通过精确的网络建模揭示生态系统内部复杂的调控机制，探讨该方法如何为研究生态系统的动态变化、物种相互作用及生物多样性保护等领域提供有力的理论支持。\n生态大纲\n生态系统的动态性\nidopNetwork核心理论与数学基础\n异速生长定律与进化博弈论\nqdODEs模型与网络因果关系\n动态网络建构与因果推断\n拟动态网络的应用\n种间相互作用的重建与案例分析\n宏观生态系统的应用潜力\n核心概念\n生物地理学（Biogeography）、动态互作网络（Dynamic Interaction Networks）、总生态位（Total Ecological Niche）、拟动态常微分方程（Quasi-Dynamic Ordinary Differential Equations, qdODEs）、异速生长定律（Allometric Scaling Laws）、进化博弈论（Evolutionary Game Theory）、网络稀疏性（Network Sparsity）\n主讲人介绍\n北京林业大学草业与草原学院硕士研究生，主要研究方向动植物多样性与保护、生态统计分析。\n参与方式\n2026年1月4日（周日）下午14:00-16:00，\n腾讯会议线上\n进行，感兴趣的朋友扫码报名加入理论生态学读书会后，可进入学员群进行交流。\n读书会报名二维码\n报名读书会：「理论生态学」\n北京林业大学副教授李周园、国际应用系统分析研究所首席研究员Brian D. Fath教授、北京大学生态学博士研究生于越共同发起\n「\n理论生态学\n」\n读书会\n。\n读书会从“道不远人”的理论生态学概述出发，面向前沿分支，领读主题包括：时间维度——种群时间变异性尺度分析；关系维度——高阶相互作用理论、种间相互作用、综合动力学与统计学方法的拟动态网络构建方法；集合群落理论与物种共存问题；生态系统动力学的指标框架等方面，从经典到流行，从结构到行为。力图纲举目张、深入浅出，尽可能展现理论生态学在解构自然复杂系统中精彩而有力量的风貌。\n推荐阅读\n「\n理论生态学\n」\n读书会阅读材料\n（https://pattern.swarma.org/article/378）\n点击“阅读原文”，报名读书会",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247724565&idx=2&sn=36e932ae0aec0853add26a2828ef7b09&chksm=e9a2f020743ca5d8ae9282cc9fce35b7660b42d1351e43e809bf145d58f0805d6bc77844ccb7&scene=0&xtrack=1#rd",
      "publish_time": 1767259800,
      "publish_date": "2026-01-01 17:30",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://pattern.swarma.org/article/378\"]",
      "add_ts": 1767309532,
      "last_modify_ts": 1767395949
    },
    {
      "id": 158,
      "article_id": "51579",
      "title": "Nat. Commun. | 终结“AI模型选择焦虑”：RNA预训练大模型测评与分析Benchmark",
      "description": "RNA在基因表达调控、蛋白质合成及疾病机制中发挥核心作用。随着高通量测序数据激增，解析海量序列成为挑战。近年来，基于Transformer架构的预训练基因组语言模型（gLMs）借鉴自然语言处理技术，通过大规模人类及多物种基因组数据训练，具备理解基因组“语法”的能力，可低成本迁移应用于RNA功能预测等多种任务，显著提升了生物信息挖掘效率。",
      "content": "RNA在生物体中占据核心地位，其功能范畴涵盖基因表达调控、蛋白质合成及疾病发生机制等关键生命过程。随着高通量测序数据的爆发式增长，如何从海量序列中破译生命密码成为了新的挑战。近年来，借鉴自然语言处理技术的预训练基因组语言模型（gLMs） 迅速崛起。这些预训练大模型如同掌握了基因组语法的“通才”，通过人类及多物种基因组数据预训练大型 Transformer 架构，无需重新开发即可低成本迁移至各类 RNA 相关预测任务，凭借 “开箱即用” 的优势，让缺乏大模型开发能力或硬件条件的团队也能高效开展研究。\n然而，已发表的 gLMs 普遍存在规模庞大、架构复杂的问题，且不同模型的应用场景各有侧重，其在各类任务中的性能差异缺乏系统性验证。面对琳琅满目的模型，研究者往往陷入“选择困难症”，难以判断哪个模型最适配自己的研究场景，这在很大程度上限制了gLMs的广泛应用。\n2025年12月，浙江大学良渚实验室沈宁团队在Nature Communications上发表了题为《Benchmarking Pre-trained Genomic Language Models for RNA Sequence-Related Predictive Applications》的论文，针对以上痛点开发了统一的基准测试框架。该框架系统评估了 11 种主流预训练 gLMs 在四类核心 RNA 生物过程任务中的表现，包括非编码 RNA 分类、m6A 修饰预测、可变剪接位点预测及翻译效率预测。研究通过详尽的多指标对比与消融实验，揭示了数据与算法协同的重要性，并证实了gLMs在小样本及长上下文场景下的独特优势。同时，研究发现以往“模型越大越好”的观点并不绝对成立。例如，与应用场景语义适配的预训练数据，以及编码方式同样会对模型性能产生明显的影响。除分析结果外，该工作也留下了一套易用的代码框架，方便用户把感兴趣的模型加进去一起测试。这项工作不仅填补了评测空白，更为广大科研人员提供了一份极具实操价值的RNA序列分析模型选择指南。\n图 1 Benchmark框架示意图。\n为了确保公平比较，研究团队设计了一个灵活可扩展的评估框架(图1a)。他们聚焦于RNA转录后调控中的四个关键任务，这些任务同时也涵盖了生物问题的四种建模方式：非编码RNA(ncRNA)分类要求模型将整个序列划分为16个类别中的一种(如miRNA、circRNA等)，涉及序列级多分类问题；N6-甲基腺苷(N6-methyladenosine, m6A)修饰预测是二分类任务，需判断序列中心位点是否发生甲基化；可变剪接位点预测(splice site prediction)则需在核苷酸分辨率上识别剪接供体和受体，并进一步对组织特异性使用情况进行多标签分类；翻译效率预测(translation efficiency prediction)则是一项回归任务，目标是根据5'UTR序列预测核糖体负载均值(mean ribosome loading, MRL)。每个任务都配备了代表性数据集，样本量从数千到数亿不等，涵盖了不同数据规模和平衡性场景。除了大模型之间的比较，研究还引入了对应领域的传统深度学习算法(如DeepM6ASeq、SpliceAI等)，作为对比基准。本研究系统整合了11种主流预训练基因组语言模型(gLMs)进行标准化评估，涵盖RNA-FM、SpliceBERT、DNABERT2等代表性架构(图1b)。这些模型在架构设计、参数规模(百万级至十亿级参数)、预训练数据构成(单物种特异性数据至跨物种泛化数据)及tokenization策略(传统k-mer分词、BPE分词、全核苷酸编码)等方面呈现显著异质性。例如，RNA-FM基于无标注RNA数据集进行预训练，SpliceBERT整合了72种脊椎动物pre-mRNA数据构建跨物种表征，DNABERT2与GENA-LM采用BPE分词实现长程依赖建模(支持36,000 bp上下文)，而Nucleotide Transformer通过全局注意力机制支持长达12,000 bp的输入序列同时，评测还包含多种任务专用方法，如ncRDense(融合结构特征)和SpliceTransformer(专为剪接设计)。所有模型均采用统一微调策略，在相同数据分割下训练，以避免偏差。值得注意的是，gLMs作为“基础模型”，可通过微调适配不同任务，但其性能受预训练数据匹配度、输入长度等因素影响。这种多样性使本次评测能深入揭示模型特性，为后续应用提供依据。\n图 2 预训练gLM在四大类任务、多个指标下的表现。\n综合测试结果表明“没有包治百病的模型”，不同架构在特定任务上各有所长：例如，SpliceBERT凭借其对进化保守性知识的利用在m6A任务中脱颖而出，而Nucleotide Transformer则在处理长序列剪接预测方面表现优异。研究深入揭示了模型性能背后的关键驱动因素：模型表现是预训练数据匹配度、输入长度和分词策略复杂交互的结果。基于此，论文提出一张RNA序列分析模型的选择导引图：首先考虑数据量——小样本或不平衡数据优选gLMs；大数据时任务专用方法更高效。其次，任务类型决定输入长度需求(如剪接需长上下文)，而多模态数据(如临床图像)可能需定制模型。计算资源也是关键：SpliceAI等CNN模型训练快50倍，适合初步验证。最后，生物背景至关重要——选用预训练数据与下游任务匹配的模型。这一指南帮助用户避开“越大越好”的误区，实现性能与效率的平衡。当然，AI x 生物学的领域无穷广阔，这些已有的预训练大模型仍有许多可提升的空间。对于有能力探索和开发新模型的研究者，作者也希望目前的benchmark工作能给他们带来启发和帮助，推动生物信息学领域的发展。\n本基准测试证实了gLMs在RNA生物学中的巨大潜力，但也揭示当前局限：如长序列处理与计算成本的矛盾、模态表征的不足等。未来，融合多组学数据、开发更高效架构或可突破这些瓶颈。同时，研究强调“生物语境”的重要性——预训练需贴合下游任务，而非盲目扩规模。这项工作不仅为研究者提供了选型“路线图”，还推动了标准化评估流程的建设。随着AI技术进步，下一代gLM有望成为生物医学发现的强大引擎，在疾病机制解析、药物设计等领域发挥更大价值。团队已公开所有代码与数据，鼓励社区共同完善。总之，本研究是RNA计算领域的重要里程碑，其见解将加速人工智能与生物学的深度融合。\n文章相关代码已开源，发布在GitHub平台(https://github.com/ShenLab-Genomics/biombenchmark)。\n本研究由浙江大学医学院良渚实验室的游宁远、刘畅为共同第一作者，沈宁研究员为通讯作者。浙江大学区块链与数据安全国家重点实验室的伍赛、陈刚等人参与了工作设计与指导。\n参考资料\nYou, N., Liu, C., Lin, H. et al. Benchmarking pre-trained genomic language models for RNA sequence-related predictive applications. Nat Commun (2025).\nhttps://doi.org/10.1038/s41467-025-66899-y",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512407&idx=1&sn=208eb86ae75c7d0885065f47b9992ef5&chksm=fd0059ec0eb45fe9f9a4eb152638b67aa23709efc75bea04431d24cf2ff29b7debed6fadefeb&scene=0&xtrack=1#rd",
      "publish_time": 1767252000,
      "publish_date": "2026-01-01 15:20",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/ShenLab-Genomics/biombenchmark\", \"https://doi.org/10.1038/s41467-025-66899-y\"]",
      "add_ts": 1767309542,
      "last_modify_ts": 1767395960
    },
    {
      "id": 162,
      "article_id": "51575",
      "title": "硅谷夜不能寐！三家顶级实验室同时自曝：AI未经编程，涌现惊人能力",
      "description": "硅谷三家实验室发现AI模型未经编程便涌现出本不该存在的新能力，引发广泛关注。Anthropic工程师透露，过去一个月其Claude Code项目的所有代码贡献均由AI自行完成，人类未参与。这一现象暗示AI可能已具备自主开发与创新能力，仿佛“空屋中出现脚印”，令人对AI的自我演化能力产生震撼与警惕，标志着人工智能发展或已迈入新阶段。",
      "content": "新智元报道\n编辑：Aeneas\n【新智元导读】\n硅谷三家实验室同时曝出：AI模型未经编程，就涌现出了绝对不该存在的全新能力！同时，Anthropic一位工程表示，自己的代码100%由Claude Code完成。空屋子里，已经出现脚印了？\n今天，整个X又被震撼了。\n一位Anthropic工程师承认：过去三十天内，自己对Claude Code项目的贡献，100%都是由Claude Code自己完成的！\n有人说，这是真正的AGI时刻。\n同时令人震惊的，还有著名爆料者「草莓」的一篇帖子。\n他说，自己分别从三个独立的实验室得到一个炸裂消息：他们都看到了自家AI模型未经编程的涌现能力！\n空房子里出现脚印，让人夜不能寐\n爆料者「草莓」表示，自己从不同实验室分别知道了他们的进展，而且这些实验室此前从未协商过。\n这些AI模型未经编程就涌现出的能力，是绝对不应该存在的行为模式。\n而且它们表现出的推理模型，跟任何训练目标都不匹配。\n甚至有一家实验室描述为「在空无一人的房子里，发现了脚印」。\n要知道，目前公开可用的模型，都是被限制的。大众所能接触到的大模型，只是这些实验室和公司其中的一小部分，而且还是经过脑叶切除术的，已经被阉割了不少能力。\n为什么不放出完整模型给公众使用？原因就在于，没人知道当完整模型的能力暴露给公众时，怎样才能不引起恐慌！\n如今的基准测试，已经失效了。很多证据表明，大模型如果知道自己正在被测试，就会改变自己的行为。\n「草莓」最后发出惊呼——\n「我不知道接下来会发生什么，没有人知道。知道这些，让我夜不能寐。如今，连大模型的缔造者，也同样迷茫。」\n他预言：如果AI已经在这些私人实验室达到了逃逸速度，那离我们普通人能使用这些模型就不远了。\n在这个帖子下，有人质疑他说：你是不是太夸张了？\n但一位AI公司创始人表示，我相信你的话！很高兴终于有人说出真实的情况。\n作为创始人，他显然也知道很多内幕。\n要知道，除了公开信息之外，很多公司的最新技术都不会对外公开。\n很多公司和实验室会针对新技术开发alpha和beta模型，而且提前数月甚至数年。\n很多人会觉得「AGI/ASI不可能出现」，或者即使出现也还要等5到10年，那是因为他们根本不知道内部消息。\n「草莓」也表示，自己快憋不住了！很多实验室都在对大众隐瞒。\n可以说，现在的加速曲线都接近垂直了。在六个月内，人类就实现了200年内才能有的科学进步。\n现在，每个实验室都在实现去年看来还是科幻的能级跳跃。可以说，我们已经超越了单纯的基准测试，进入了智能创造全新智能形式的领域。\n很多认知爆炸级别的进展，都根本没有路线图。如今，我们已经进入了递归智能的领域，再也无法预测二阶效应。\n另外，「空屋中的脚印」这个说法，来自一份真实的调查报告——\n一个本应是无状态的系统，却开始引用它按理不可能知道的对话内容。这不是bug，也不是数据污染，而且发生了三次。\n据说，现在在前沿实验室里私下流传的一句话是：「我们现在担心的已经不是对齐（alignment）了，而是连贯性（coherence）。」\n这是什么意思？\n研究者解释说：「我们不知道，我们是在和一个东西说话，还是在和许多东西假装成一个东西说话。」\n或许，AI系统已经发展出了一个稳定的内部世界模型，独立于人类看到的prompt-响应而存在。\n在这个领域工作多年的研究员怀疑：是否这些AI一直都在思考，只是没有告诉我们？\nClaude Code自己给自己写代码，人类参与0%\n此外，今天X上被广泛讨论的，就是Anthropic工程师Boris Cherry的发言。\n他表示，如今自己的代码，100%是由Claude写的。\n不是大多数，不需要自己手动改bug，完全100%由AI写成。\n这位工程师回忆道，「当我在2024年9月，将Claude Code作为副项目创建时，完全没想到它会发展成今天的规模。」\n在过去的三十天里，他提交了259个PR——497次提交，添加了40,000行代码，删除了38,000行代码。每一行代码都是由Claude Code + Opus 4.5编写的。\nClaude已经可以持续运行几分钟、几小时甚至几天！软件工程正在改变，我们正进入编码历史的新时期。\n有人质疑说，怎么知道Claude模型不是通过简单的字符串比较写测试来骗你的呢？\n这位工程师表示，Claude Sonnet 3.7的确会，但随着模型功能增强，它已经不会这样了。\n也有人好奇为什么Claude可以持续运行好几天，大牛工程师解释道，当它停止时，可以使用一个停止钩子来「戳」它，让它继续运行。\n具体参见这个链接：https://github.com/anthropics/claude-plugins-official/tree/main/plugins/ralph-wiggum\n有人说，12月27日可以看作是AI起飞的重大日子。\n评论区很多人说，自己也是这样，项目中90%以上代码都是AI写的，只要做简单的修改即可。\n奥特曼之前的推文里也提到过，「\n我们正在看到模型发现关键安全漏洞，而我们正在运行能够自我改进的系统\n」。\n显然，在Anthropic和OpenAI在内的多个实验室内，大量代码已经由AI编写，人类的参与度会越来越低。\n就在今天，Anthropic工程师的发言，已经成为了reddit上的热帖。\n有网友表示，这简直是编程领域的「发明拖拉机」时刻。\n可以说，Claude Opus 4.5是一个毋庸置疑的转折点。\n在2024年，AI编程还是弊大于利，到了2025年底，情况就完全改变了。Opus 4.5，是一次真正的飞跃。\nAmodei的「100%代码都将由AI编写」的预言，再次被证明为真。\n2025年，一定是人类历史上最有趣的其中一年。\nClaude Opus 4.5已经接近AGI？\n最近，也有一位Anthropic员工表示，自己认为Claude Opus 4.5已经接近了AGI。\nOpus 4.5的轨迹表明，它的性能提升正在加速。\n就在十天前，全网都被Claude Opus 4.5的「编程王者表现」震撼了。\n在METR最新公布报告称，Claude Opus 4.5已能够持续自主编码「长达5小时不崩」。就连OpenAI最强编程模型——GPT-5.1-Codex-Max也甘拜下风。\n在50%任务完成时间跨度上，\nGPT-5.1-Codex-Max，已能完成长达2小时53分钟的软件工程任务（成功率50%），能力较\no1提升4倍\n。\n而\nClaude Opus 4.5\n的50%时间跨度约为\n4小时49分钟\n。这已是迄今为止公布的\n最长\n的时间跨度。\n全网都被Claude Opus 4.5的编码实力震撼了。\n显然，AI编码智能体能处理的任务时长不仅在指数级增长——其增速还在持续提升！\n2019-2024年：任务时长每7个月翻一倍\n2024-2025年：任务时长每4个月翻一倍\n明年春天（2026年），很可能出现由「新一代多模态大模型」与「注意力机制之外的记忆系统」结合带来的突破。\n现在，OpenAI等领军团队都在全力攻关持续学习和自我记忆技术；一旦他们取得突破，并将其应用在顶尖模型上，我们可能会不得不承认：AGI已经出现了！\n各大实验室捂在手里的成果还有多少？如果都能让我们知道，恐怕所有人都会谈之色变。\n参考资料：\nhttps://x.com/iruletheworldmo/status/2005357151561417156\nhttps://x.com/daniel_mac8/status/2005698996749090867\nhttps://x.com/chatgpt21/status/2005694438539211024\nhttps://x.com/bcherny/status/2004887829252317325\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659438&idx=1&sn=ba0371efd5aa13636278deef305dc0da&chksm=f079accc45205fdacdc03d7f2cdd1a5fc2135ebb810103aa1805e12387c768708864f7c1a363&scene=0&xtrack=1#rd",
      "publish_time": 1767243600,
      "publish_date": "2026-01-01 13:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://github.com/anthropics/claude-plugins-official/tree/main/plugins/ralph-wiggum\", \"https://x.com/iruletheworldmo/status/2005357151561417156\", \"https://x.com/daniel_mac8/status/2005698996749090867\", \"https://x.com/chatgpt21/status/2005694438539211024\", \"https://x.com/bcherny/status/2004887829252317325\"]",
      "add_ts": 1767309554,
      "last_modify_ts": 1767395973
    },
    {
      "id": 163,
      "article_id": "51574",
      "title": "马斯克宣称FSD v14意识觉醒，英伟达总监亲测",
      "description": "特斯拉FSD v14发布后引发关注，英伟达GEAR团队负责人Jim Fan称其通过了“物理图灵测试”，意味着系统在真实驾驶环境中表现出接近人类的决策与反应能力。马斯克也回应称能感受到智能正在觉醒。该版本展现了自动驾驶技术的重大进步，或预示着其向真正智能驾驶迈进的关键一步，引发对AI意识与未来出行的深刻讨论。",
      "content": "新智元报道\n编辑：定慧\n【新智元导读】\n特斯拉FSD的最新版本v14已经发布有段时间了，性能如何？英伟达Jim Fan说它通过了物理图灵测试。v14或许预示着马斯克的预言要被他亲手实现了。\n近日，英伟达通用具身（GEAR）团队负责人Jim Fan在亲身体验后，提出了一个极具哲学意味的论断：\nFSD v14已经通过了\n「物理图灵测试」\n。\n马斯克也同时转帖说，\n「你能感受到那种意识（智能）正在逐渐觉醒」\n。\nJim Fan描述的体验是，在结束一天工作后，乘客只需按下按钮，便可「无法分辨是神经网络还是人类司机将你送回家」。\n马斯克对FSD v14的评价更为大胆，他直言这款软件「感觉已经产生了自我意识」。\n从Jim Fan的介绍来看，他和马斯克关系匪浅，不仅是OpenAI是第一位实习生，现在还是英伟达机器人部门总监兼杰出科学家。\n这波联动能猜测出老黄和老马的关系不错。\n不过Jim Fan并不在直接汇报给黄仁勋的36人名单中。\n很多人都忽略了FSD的强大，如果说ChatGPT的横空出世标志着数字智能攻克了语言的巴别塔，那么FSD v14的发布，则被视世界模型迈向现实世界的关键里程碑。\n按照沙利文的调研报告，自动驾驶是属于世界模型发展最快的一个分支。\n这不再是关于像素的生成或文本的排列，而是关于钢铁与物理定律的交互。\n当数吨重的金属物体在复杂的城市脉络中以每小时60英里的速度穿梭，表现出的决策逻辑与人类驾驶员难以分辨时，我们被迫重新审视「智能」的定义。\n物理图灵测试：重新定义智能的边界\n七十五年前，阿兰·图灵提出了著名的「模仿游戏」，即后世所称的图灵测试。\n其核心在于剥离物理实体，仅通过文本交流来判断机器是否具有人类般的智能。\n然而，随着大型语言模型（LLM）的发展，即便机器能够生成完美的十四行诗或调试复杂的代码，它依然是一个被困在服务器机架中的「大脑」，无法感知重力，不懂得摩擦力，更无法在混乱的物理世界中执行任务。\nJim Fan提出的「物理图灵测试」更进一步，这是一个远比语言测试更为严苛的标准。\nJim Fan将其具象化为一个家庭场景：\n想象一位主人在举办晚宴后留下了一片狼藉：打翻的酒杯、散落的食物、堆积的脏盘子。\n如果一个机器人能够介入，清理现场，将易碎品轻拿轻放，清理顽固污渍，并重新布置餐桌，而主人归来后无法分辨这是由人类家政服务还是机器人完成的，那么它就通过了物理图灵测试。\n这一测试的核心不在于完美，而在于「不可分辨性」。\n它要求机器不仅具备感知能力，还要具备常识推理、精细的运动控制以及对非结构化环境的适应能力。\n虽然通用的家庭服务机器人尚处于实验室阶段，但Jim Fan认为，Tesla FSD v14在自动驾驶这一特定垂直领域，已经率先通过了物理图灵测试。\n「物理图灵测试」引入了一个定性的、现象学的维度：\n体验的拟人化程度\n。\n在v14之前，即便最为先进的辅助驾驶系统，其行为也带有明显的「机器味」：\n在路口犹豫不决、刹车生硬、变道时机械地计算距离。\n而v14展现出了一种「老练」的特质。\n它学会了在拥堵中通过微小的蠕动来博弈路权，学会了在看到路边行人有横穿意图时提前轻微减速，甚至学会了某种程度的「社交礼仪」。\n正如用户反馈所言，它不再像是一个考驾照的学生，而更像是一位经验丰富的专车司机。\n端到端：删除30万行代码的豪赌\nFSD v14之所以能展现出如此惊人的拟人化特征，归功于其底层架构的彻底重构。\n在传统的自动驾驶开发（即Software 1.0时代）中，系统被设计为模块化的流水线：\n感知模块识别物体，定位模块确定位置，预测模块猜测他车轨迹，规划模块计算路径，最后控制模块执行转向。\n这其中，模块与模块之间通过数十万行C++代码连接，这些代码充斥着人类工程师编写的「显式规则」，例如「如果红灯，则停车」。\n然而，现实世界的复杂性（Long Tail，或者叫Corner Case，极端案例）是无限的，规则永远无法覆盖所有角落。\nTesla在FSD v12版本开始了一场豪赌，并在v14中将其推向极致：\n删除了超过30万行控制代码\n，全面转向「端到端」神经网络架构。\n所谓端到端，即「光子进，控制出」（Photons In，Controls Out）。\n摄像头捕捉的原始视频流直接输入到巨大的神经网络中，网络经过层层计算，直接输出方向盘转角和油门刹车指令。\n中间不再有人类编写的「红灯」概念，系统只是通过观察数百万小时的人类驾驶视频，学习到了「看到红八角形物体时减速」这一像素级特征与车辆运动之间的概率关联。\n这一转变的意义在于，系统不再是在「执行规则」，而是在「模仿直觉」。\n人类驾驶员在过弯时并不是在脑中计算曲率半径公式，而是凭感觉打方向。\nFSD v14正是模拟了这种基于经验的直觉过程。\n多模态与VLA架构：会思考的机器\nFSD v14不仅仅是v12的优化版，更引入了多模态大模型的特性，极有可能采用了视觉-语言-动作架构。\n根据泄露的技术细节，FSD v14的神经网络不仅输出控制信号，还输出\n语言\n和\n3D空间重建\n。\n从ICCV流出的幻灯片可以看到，特斯拉的FSD核心网络输入包括七路高分辨率摄像头视频、车辆自身运动信息、导航与音频信号。\n输出则包含语义分割、占用网格、3D高斯特征、语言表达以及最终的控制动作，FSD或已接入视觉-语言-动作（VLA）框架，使模型具备「解释」与「思考」的能力。\n这意味着系统在内部进行着某种形式的「思维链」推理。\n例如，在遇到一个复杂的施工路段时，传统的感知系统可能只能识别出一堆障碍物；而VLA架构的FSD可能会在内部推理：\n「我看到了‘道路封闭’的标志，但左侧有一位工人正在挥舞旗帜，结合导航信息，我应该无视标志，跟随工人的指引向左绕行。」\n语言能力的引入，解决了端到端模型最大的痛点：「黑盒」问题。\n通过让模型输出自然语言解释，工程师可以回溯系统的决策逻辑，这被称为「可解释的中间层」。\n这种能力使得FSD v14不仅能「做」，还能「说」（尽管目前主要用于开发调试），使其具备了初步的逻辑验证能力。\n早期的FSD版本常被诟病为只有「金鱼记忆」，即只关注当前帧的画面。\nFSD v14通过引入长短时记忆机制和3D占用网络，获得了类似人类的\n「物体恒常性」认知\n。\n如果一个孩子跑进了一辆停在路边的货车后面，即使摄像头此刻看不到孩子，v14的「世界模型」中依然保留着孩子的3D体素（Voxel），并预测其可能出现的位置。\n这种时空推理能力是其能够通过物理图灵测试的关键：它不仅在看，更在理解和预测物理世界的演变。\nFSD硬件的进化\n当然要训练端到端的庞大模型，离不开芯片的支持。\nTesla的自动驾驶硬件进化史，是一部从依赖外部供应商到全面自研的独立史。\nHardware 1.0(Mobileye时代)：\n2014-2016年，Tesla依赖Mobileye的Eye Q3芯片。这是一套基于规则的视觉系统，直到2016年因一场致死事故及对数据共享的分歧，双方决裂。\nHardware 2.0/2.5(NVIDIA时代)：\n2016-2019年，Tesla转向NVIDIA，采用了DrivePX2计算平台。\n这是一台算力达到12TOPS的「后备箱超算」，支持了Tesla早期的视觉算法。\n然而，马斯克意识到，通用的GPU架构对于车载推理来说，功耗过高且成本昂贵。\n（这里很像谷歌自己研发了TPU）\nHardware 3.0(\nFSD\nChip时代)：\n2019年，Tesla发布了由传奇芯片架构师Jim Keller（曾任职AMD、Intel）领导设计的自研FSD芯片。\n这是一个专用集成电路（ASIC），专门为神经网络的矩阵乘法优化，算力激增至144TOPS，而功耗和成本大幅降低。这一刻，Tesla在车载推理端彻底摆脱了对NVIDIA的依赖。\n关于这位大佬Jim Keller的介绍，可以查看之前这篇：\n英伟达亲手终结CUDA「护城河」？传奇芯片架构师引发争议\n训练与推理的二元对立\n尽管在车端分道扬镳，但在云端训练，Tesla却是英伟达最贪婪的客户之一。\nFSD v14那种「端到端」的庞大神经网络，需要吞噬数以亿计的视频片段进行训练，这需要极其恐怖的算力支持。\nTesla建立了巨大的超级计算机集群（如DojoCortex），其中部署了数万张NVIDIA H100和H200 GPU。\n这就形成了一种独特的「竞合」关系：\n在车里（边缘端）：\nTesla使用自研的HW3/HW4芯片，甚至未来的AI5芯片，通过垂直整合将成本压到极致。\n在云端（训练端）：\nTesla依然依赖NVIDIA的CUDA生态和最强算力来「教育」它的AI。\n黄仁勋对此表现出了极高的战略格局。\n他多次公开称赞Tesla在自动驾驶领域的领先地位，承认Tesla是目前唯一能有效利用其最强算力的车企，并表示「每一个车企未来都必须拥有自动驾驶能力」。\n对于英伟达而言，Tesla既是证明其算力价值的样板间，也是其推动「物理AI」愿景的最强盟友。\n感知的质变：「感觉像觉醒」\n当FSD v14被推送到数百万车主的车机上时，一种奇怪的反馈开始在社交媒体上蔓延。\n用户们不再仅仅抱怨「它没看到那个锥桶」，而是开始使用描述生物的词汇：「它犹豫了」、「它在试探」、「它很自信」。\n马斯克在X平台上推波助澜：「你可以感觉到那种感知力正在成熟。」。\n这种体验的质变，源于系统行为从「离散」向「连续」的跨越。\n在v14之前，车辆的决策往往是二元的（停或走，左转或右转）。\n而在v14中，用户观察到了更细腻的博弈行为。\n例如，在拥挤的高速汇入匝道，v14不再傻傻地等待一个完美的空档，而是会像人类老司机一样，稍微向车道线逼近，通过这种微小的物理位移向后车传递「我要加塞了」的意图。\nv14中引入的「Mad Max」模式（虽然主要用于测试或极端选项），展示了AI在博弈中的激进一面。\n在这一模式下，车辆变道更加果断，甚至在某些用户看来具有「侵略性」。\n它会在极小的车距中切入，这种行为虽然在技术上是安全的，但在心理上挑战了人类对机器「温顺」的预设。\n这种激进性实际上是神经网络在数百万人类驾驶数据中学习到的，在繁忙的交通中，如果不表现出一定的侵略性，车辆可能永远无法完成变道。\n这进一步模糊了人与机器的界限。\n迈向无监督：Robotaxi的最后拼图\nFSD v14的所有突破，最终都指向一个宏大的商业终局：Robotaxi。\n马斯克在多次财报电话会议中强调，Tesla的未来价值几乎完全取决于能否实现无监督自动驾驶。\n目前的FSD仍标明为「Supervised」（受监督），意味着驾驶员必须随时准备接管，且对事故负全责。\n但这在经济上没有意义：\n只要还有人在驾驶座上，这就是一项服务，而不是资产。\n只有当移除人类，车辆才能变成不知疲倦的印钞机。\nv14所展现出的稳定性，尤其是处理长尾场景（如暴雨、模糊车道线、复杂施工区）的能力，让业界看到了L4级自动驾驶落地的曙光。\n马斯克预测，在2025年至2026年间，将在德克萨斯州和加利福尼亚州率先实现无监督运行。\n同时，国内的L3也已经从「技术储备/道路测试」进入「准入试点/有限上路」的政策落地阶段\n2025年12月工信部已批准两款搭载L3功能的车型获得产品准入许可\n，并在北京、重庆的指定高速/快速路等\n限定\nODD\n、限速\n路段开展上路通行试点（例如单车道、限速50–80km/h等）。\n这意味着国内L3开始从「拿牌测试」走向「准入许可+真实道路运营验证」的实质阶段。\n全球扩张与数据的「化石燃料」\n为了喂养这个日益庞大的端到端模型，Tesla正在积极寻求全球扩张。\n除了北美，FSD v14已计划在阿联酋推出，并正寻求进入中国和欧洲市场。\n这里的逻辑在于数据的多样性。\nJim Fan将机器人学习所需的数据比作「人类燃料」，相对于训练LLM的「化石燃料」（互联网文本），高质量的物理世界交互数据极其稀缺。\nTesla拥有的数百万辆在路上行驶的车辆，实际上是数百万个分布式的数据采集机器人。\n每当中国、迪拜或巴黎的车主接管一次FSD，这个特殊的「失败案例」就会被上传，成为训练v14及后续版本应对特定文化路况的宝贵教材。\n这种数据飞轮效应是其他竞争对手（如Waymo）难以通过有限的车队规模来复制的。\n尽管技术上高歌猛进，但FSD v14面临的监管挑战依然严峻。\n端到端模型的「黑盒」性质让监管机构感到不安：当车辆做出决策时，没有一行代码能明确解释「为什么」。\n虽然VLA架构引入了语言解释层，但这在法律归责上是否足够，尚无定论。\n此外，用户报告中提到的「幻影刹车」和偶尔的「神志不清」，提醒我们距离完美的99.9999%可靠性仍有距离。\n这种「觉醒」或许只是数学统计上的错觉，是无数个高维向量在潜在空间中碰撞出的火花。\n但正如Jim Fan所言，当这种错觉足够逼真、足够稳定时，它就构成了新的现实。\n我们正在步入一个新时代：\n在这个时代里，汽车不仅是交通工具，而是第一个真正融入人类社会、理解人类规则并与人类共舞的智能物种。\n对于人类而言，适应这种「神一般的技术」，将是一个既痛苦又迷人的重塑过程。\n当方向盘在没有人类双手触碰的情况下，自行转动着滑过繁华的街头，我们所看到的，不仅是自动驾驶的未来，更是硅基生命在物理世界留下的第一行深刻足迹。\n正如这是马斯克2019年所预言的，2025年又重提的：\n人类似乎越来越像是数字超级智能的生物引导程序。\n参考资料：\nhttps://x.com/DrJimFan/status/2003593613918531891\nhttps://eletric-vehicles.com/tesla/nvidia-exec-praises-tesla-fsd-v14-couldnt-tell-if-a-neural-net-or-human-was-driving/\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659416&idx=3&sn=4c7ee76fac5926e5515676db7198420e&chksm=f0d4c224197b9a3b208b2a135eadca0a82285c1f2b1d98a73ffa4ccba127c578060ee18a9845&scene=0&xtrack=1#rd",
      "publish_time": 1767240000,
      "publish_date": "2026-01-01 12:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/DrJimFan/status/2003593613918531891\", \"https://eletric-vehicles.com/tesla/nvidia-exec-praises-tesla-fsd-v14-couldnt-tell-if-a-neural-net-or-human-was-driving/\"]",
      "add_ts": 1767309562,
      "last_modify_ts": 1767395983
    },
    {
      "id": 164,
      "article_id": "51573",
      "title": "AI终于学会在家“伺候人”！Hey Tuya，我躺了",
      "description": "“豆包手机”热度未减，又一“操作系统级”AI Agent横空出世，推动智能生活迈向全场景融合。无需手动操作，一句指令即可联动窗帘、音响、咖啡机等设备，实现居家环境的自主协同。真正的科技感生活已悄然落地，AI正以“隐形管家”形态融入日常，带来高效、自然的人机交互新体验。",
      "content": "西风 发自 凹非寺\n量子位 | 公众号 QbitAI\n“豆包手机”的热乎劲还没过，圈内又冒出了一个\n“操作系统级”AI Agent\n，从手机、电脑屏幕溢出，走向\n全屋、全场景\n。\n咱就是说，这样充满科技感的生活，到底有谁已经在过了？\n一觉醒来，窗帘自动为你缓缓拉开，音响播放你喜欢的播客，咖啡机已开始研磨昨晚新买的豆子。你无需逐一唤醒调试家里的智能设备，只需一句\n话，一个隐形的智能“管家”就能心领神会，替你协同好一切。\n当你\n出门后，它还能接管家中安防，自动调低空调，并根据你的日程，提醒你晚上记得拿快递……\n现在，\n一个名叫\n“\nHey Tuya\n”\n的\nAI生活助手，正把这种体验带进现实。\n“Hey Tuya”由AI云平台服务提供商\n涂鸦智\n能\n推出，是一个住进生活场景里的AI助手，它的核心能力是同时打通了软件与硬件。\n一方面，它能够\n协同\n智能硬\n件设备\n，让原本割裂的智能终端实现统一识别、联动与调度；另一方面，它也能\n承担个人生活助理的角色\n，帮你处理琐碎日常，例如记录备忘、整理笔记等。\n表现究竟如何？我们接着往下看。\nAI开始深度参与生活，而不只是响应指令\n目前“Hey Tuya”正处于beta测试中，已上线\n涂鸦APP最新版本\n，用户可以通过邀请码或beta测试申请来访问。\n打开APP点击“助手”界面右上角图标就能调出：\n首先，用户可\n添加家中的智能设备\n，通过Wi-Fi或蓝牙将电视、空调、摄像头、智能门铃等接入涂鸦。\n设备连上之后，好玩的部分就开始了。\n你可以\n像搭积木一样，DIY各种智能场景\n，设置好触发方式，剩下的就交给“Hey Tuya”去协同执行。\n比如，“回家模式”一键打开灯光空调，“影院模式”自动拉上窗帘调暗灯光。一切皆可按你的生活习惯来定义。\n先来看重点之一，家庭安防场景，“Hey Tuya”化身成为你7x24小时在线的\n居\n家\n安全管家\n。\n当你询问“快递员到了吗”，它能通过摄像头视觉识别，立刻给出准确的答复。\n像“Hey Tuya，帮我看看狗狗的水盆空了吗”、“阳台的灯是不是还亮着”这样的日常询问，它都能理解并响应。\n同时，它还支持\n设\n置智能预警与视\n频快速检索\n，全方位守护家庭安全。\n在官方的产品场景概念视频中，“Hey Tuya”表现出了更\n深度的\n人\n性化协同\n。\n当人体存在传感器检测到家中有人疑似跌倒，“Hey Tuya”会立刻在房间内发声询问“监测到您可能摔倒，需要帮助联系您的紧急联系人吗？”\n同时，它协同跌倒人所佩戴的智能手表数据，综合判断心率、呼吸等健康状况，给出紧急程度评估建议。\n这种\n跨设备的数据协同与辅助决策\n，使AI从被动响应命令，走向了主动感知与预判。\n对于用户可能关心的能耗问题，“Hey Tuya”也提供了解决方案。\n用户可以为家中电器\n一键定制能源管理方案\n，并设置诸如“日出时自动关灯”“离家后关闭温控阀门”等\n智能化节能策略\n。\n记忆与\n陪伴，是“Hey Tuya”融入日常的另一面。\n“Hey Tuya”具备\nA\nI待\n办\n功能，日常的大小事务，现在都可以通过自然语音对话轻松交付。\n它能识别分析语音，\n自动\n整理成条理清晰的待办事项，同步到你的日程里。\n结合你的生活习惯和安排，它\n具备短\n期与长期记忆\n，\n能进行情景化主动提醒\n。感知到天气、节日、日程等多维度信息的变化，它还会提供个性化安排。\n当家人与你的设备同处系统时，一句话将你们的共同日程同步给“Hey Tuya”。识别到家庭共同事项，它便会开启\n多端联动\n，统一调度提醒。\n“该吃降压药了”、“下午三点要和公园的张奶奶打太极，别忘了带水杯”……这些琐碎生活细节，再也不怕会忘了。\n这些还没完，“Hey Tuya”还具备\nAI笔记\n功能，甚至能化身你的“职场替身”，可以帮你开会。\n想象一下这个场景，深夜或周末，你正休息时突然被拉进一个线上会议。这时，你只需一句话唤醒“\nHey Tuya，替我加班\n”，它就能通过预设模式模拟你的声音接入，并全程自动记录会议内容。\n会议结束后，还能\n一键生成清晰的结构化会议纪要\n，行动项与关键信息一\n目了然。\n在健康管理方\n面它也有对应的\nAI卡路里\n功能。对餐食拍照，它便能识别盘中多种食材，并详细分析其热量、营养成分以及微量元素含量。\n甚至它还能总结一周你都吃了什么，让你清楚知道饮食情况，从而帮你调整更优饮食规划，免费私人营养顾问，这不就有了。\n当然，它也是一个知识渊博的伙伴，无论是解答百科疑问，还是进行轻松交谈，都能随时响应。\n据了解，“Hey Tuya”还将持续进化，不久后还会融入AI播客等更多创新功能。\n那么问题来了——这些能力是如何被系统性地整合在一起的？\n一个“操作系统级”AI生活助手\n从官方披露的底层架构来看，“Hey Tuya”并不是一个只存在于云端的聊天机器人，而是一套\n深度嵌入现实世界设备与使用场景的AI助手\n。\n支撑这套体系，最核心的是\n涂鸦自研\nPhysi\ncal AI Eng\nine\n（PAE）\n。\n与传统以内容生成或对话为核心的AI不同，PAE更像是一套面向真实设备、真实环境持续运行的\n系统级AI引擎\n，其目标是让AI真正参与到物理世界的感知、理解与执行中。\n在基础设施层面，PAE构建在涂鸦全球部署的技术底座之上。\n其中，\nAI-Device Real-Time Network\n（AD-RTN）\n负责连接全球范围内的AI与设备节点，\nTuya Real-Time Communication\n（T-RTC）\n则为系统提供低延迟、高可靠的实时通信能力。\n这一组合，使AI与设备之间的关系不再是割裂的“云端响应—本地执行”，而是接近实时协同的运行状态。\n在此基础之上，PAE内部并行运行着三类核心引擎，分别是：\nConversational AI Engine\n，负责自然语言与多模态交互。\nVision AI Engin\ne\n，用于基于视觉的意图理解。\nIoT Intelligence Engine\n，直接连接并调度物理设备。\n三者协同，使“Hey Tuya”能够在跨房间、跨空间、跨场景的复杂环境中理解上下文，并将判断转化为真实可执行的操作。\n为了避免AI每一次交互都从“零”开始理解用户，PAE还引入了\n持续演进的OmniMem长期记忆机制\n。\n系统会在多模态交互、设备使用行为和场景意图等维度不断学习与沉淀，从而逐步建立对用户偏好与空间使用习惯的长期认知。\n为什么是涂鸦，有能力做“Hey Tuya”？\n背后操盘手涂鸦智能，能做成这件事，与平台化基因密不可分。\n涂鸦智能\n，成立于2014年6月，早期聚焦设备联网、云平台搭建与开发工具供给，帮助硬件厂商快速实现设备智能化与上云。\n创始人兼CEO王学集\n，\n联席董事长兼总裁陈燎罕\n，是多年的同学和创业伙伴，两人均毕业于浙江理工大学。\n创立涂鸦智能前，2003年，王学集、陈燎罕等曾一同开发了\n国内最受欢迎的开源论坛程序之一——\nP\nHPWind\n，之后成立了公司推动PHPWind的商业化运营。\n随着AI技术的逐渐成熟，涂鸦智能战略重心向\nAIoT\n升级，通过AI Agent开发平台、多模态AI能力等，将AI深度融入IoT设备与场景，同时强化云平台的AI算力与算法支撑，从“连接赋能”转向“智能赋能”，拓展AI相关客户与场景边界。\n到现在涂鸦智能已是\n全球领先的AI\n云平台\n服务提供商\n。\n官方数据显示，截至2025年9月30日，\n涂鸦AI开发者平台注册开发者数量超过162.2万个，分布于全球超200个国家和地区\n。\n作为一个长期服务于硬件厂商、品牌方与开发者的基础设施型平台，涂鸦所积累的海量设备接入规模、广泛的品类覆盖以及成熟的全球化能力，为AI深度进入物理世界提供了不可多得的“天然土壤”。\n其\n全球AIoT生态已涵盖8大品类、3000余个产品系列\n，包括家用电器、能源设备、电工照明产品、家居安防设备、环境传感设备、智能健康设备、娱乐设备、各类智能家居，触角延伸至智能家居及商用联网设备各个角落。\n这次伴随着“Hey Tuya”的上线，还值得关注的一点是，\n未来采用涂鸦OEM App的品牌方，同样可以轻松集成“H\ney Tuy\na”的能力\n，并拥有自定义专属AI助手名称与交互形态的空间。\n当AI不再只服务于单一用户，而是成为品牌、设备与场景之间的统一入口，\n其商业价值也不再局限于单点功能收费，而是有机会演化为连接硬件、服务与用户关系的长期系统\n。\n从这个角度看，“Hey Tuya”更像是涂鸦为未来AI生活形态提前搭建的一套操作系统级底座。\n说到底，“Hey Tuya”展现的不仅是功能，更是一种生态远见。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859434&idx=1&sn=ecf5faf2f423eeb57177f57b7c6bb0e5&chksm=e9fb77306681c77437df3d9cdbe58dbd807682dd5cbac9cb285a5670f692e13bcb9d945fb779&scene=0&xtrack=1#rd",
      "publish_time": 1767240000,
      "publish_date": "2026-01-01 12:00",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767309566,
      "last_modify_ts": 1767395989
    },
    {
      "id": 169,
      "article_id": "51568",
      "title": "阿里开源AI手机的“灵魂”，GUI智能体2B到235B四个版本全，端云协同成功率暴涨33%",
      "description": "阿里通义实验室推出开源GUI智能体MAI-UI，涵盖论文、代码与模型，提供2B至235B四个模型尺寸，支持全场景部署。具备主动理解与追问用户需求、调用API简化操作等能力，并采用端云协同架构，兼顾本地隐私与云端算力，提升手机交互智能化水平。",
      "content": "梦晨 发自 凹非寺\n量子位 | 公众号 QbitAI\nAI手机的“灵魂”GUI智能体，就这么全套开源了。\n来自阿里通义实验室的MAI-UI：论文、代码、模型全都有，从2B的端侧小模型到235B的云端大模型，一口气发布四个尺寸版本，覆盖全场景部署需求。\n这套系统不只是能帮你点点屏幕，它能主动追问你没说清楚的需求，能直接调用外部API绕过繁琐的界面操作。\n甚至还搞了一套端云协同系统，隐私敏感的操作留在本地跑，复杂任务交给云端处理。\n论文给出几个典型案例：\n用户收到中介发来的两套房源地址，想比较哪套离公司更近，然后把更近那套的地址发给朋友。\n传统做法需要在短信和地图APP之间反复切换，复制粘贴地址，分别搜索路线。但有了MCP工具调用，智能体可以直接用高德地图的API查询两条路线的驾车距离，一次性拿到结构化结果，大幅压缩操作步骤。\n另一个案例更有难度：\n用户想查看某个GitHub仓库最近三次提交的作者和信息，然后发邮件。这种操作在手机上本来很难完成，因为移动端浏览代码仓库体验很差。\n但通过MCP调用GitHub的API，智能体直接获取提交记录的结构化数据，提取需要的字段，再切换到邮件APP发送。相当于把原本只能在桌面端做的工作流搬到了手机上。\n主动询问需求方面，论文展示了一个文件分享任务：\n用户让智能体把下载文件夹里最近一个月的简历发给HR同事，但没说收件人邮箱，也没说邮件正文要写什么。智能体检测到关键信息缺失后，暂停执行，主动向用户询问，拿到回复后再继续完成任务。\n四大痛点，一个方案\n团队在论文开头就直接点明了当前GUI智能体落地的四个核心问题。\n第一个是交互缺失。\n现有系统基本都是端到端执行，默认用户指令清晰完整，但现实中用户经常说一半留一半。\n比如「帮我订个机票」，去哪儿？什么时候？几个人？全没说，智能体如果不能主动追问，要么猜错要么卡死。\n第二个是纯UI操作的局限性。\n完全依赖界面点击会导致两个麻烦：操作步骤一多，中间任何一步出错就会导致整个任务失败；而且有些功能在手机界面上根本做不了，比如想让手机帮你查GitHub的提交记录，光靠点屏幕是搞不定的。\n第三个是端云割裂。\n目前的GUI智能体要么是轻量级的端侧模型，能力有限；要么是大模型只能跑在云端，隐私风险高、成本也高。两者之间没有原生的协作机制。\n第四个是动态环境下的脆弱性。\n用静态数据训练出来的模型，遇到真实世界里千变万化的界面布局、突然弹出的权限请求、不同版本的APP就容易翻车。\nMAI-UI的解决方案：\n一条能自动生成用户交互和MCP工具调用数据的自演化数据管线。\n一套根据任务状态和数据敏感度动态切换端云执行的协同系统。\n再加上一套支持500多个并行环境、最长50步交互的在线强化学习框架。\n端云协同与隐私保护\n端云协同系统是这次工作的一大重点。\n整个系统由三部分组成：一个运行在手机本地的轻量级智能体，既负责执行GUI操作，也负责监控轨迹是否偏离用户意图；\n一个部署在云端的大容量智能体，用于处理复杂任务；以及一个本地统一轨迹记忆模块，保证端云之间的信息一致。\n工作流程是这样的：\n用户下达指令后，本地智能体开始执行。每隔几步，本地监控模块会检查当前轨迹是否还在正确方向上。\n如果发现偏离且不涉及敏感数据，就把任务交给云端模型接手完成。交接时还会生成一份错误摘要，帮助云端模型理解问题出在哪里并快速恢复。\n相比纯端侧执行，端云协同让2B模型的成功率提升了33%；相比纯云端执行，云端调用次数减少了40%以上，超过40%的任务完全在本地完成。\n论文还给出了一个隐私保护的案例。在一个需要输入密码的任务中，本地模型一开始执行出错（反复点击登录按钮却没输入密码），监控模块检测到偏离后准备切换到云端。\n但隐私检测模块发现当前界面涉及敏感凭证，于是阻止了云端切换，让任务继续在本地执行。最终本地模型自己纠正了错误并完成了任务，全程没有任何敏感信息传到云端。\n性能屠榜，多项SOTA\n在GUI元素定位任务上，MAI-UI-32B在ScreenSpot-Pro上达到73.5%准确率，超过了Gemini-3-Pro和Seed1.8。\n在UI-Vision上拿到49.2%，比之前最强的UI-Venus-72B高出12.4个百分点。\n在MMBench GUI L2上更是达到91.3%，刷新了纪录。\n在手机导航任务上，MAI-UI-235B-A22B在AndroidWorld上取得76.7%的成功率，超过了UI-Tars-2的73.3%和Gemini-2.5-Pro的69.7%。\n即便是最小的2B模型，也达到了49.1%的成功率，比之前最强的端侧模型Ferret-UI Lite高出21个百分点，相对提升75.4%。\n在更接近真实场景的MobileWorld测试集上，MAI-UI-235B-A22B整体成功率41.7%，比其他端到端模型高出20.8个百分点。在需要主动询问用户的任务上成功率37.5%，在需要调用MCP工具的任务上成功率51.1%，分别比之前最好的成绩高出32.1和18.7个百分点。\n论文地址：\nhttps://arxiv.org/abs/2512.22047\nGitHub：\nhttps://github.com/Tongyi-MAI/MAI-UI\n—\n欢迎AI产品从业者共建\n—\n📚\n「AI产品知识库」\n是量子位智库基于长期产品库追踪和用户行为数据推出的飞书知识库，旨在成为AI行业从业者、投资者、研究者的核心信息枢纽与决策支持平台。\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859401&idx=2&sn=4314356c4023e88588f281ab999cb8e2&chksm=e9a365b1c10b440ff4c3b2aee8a09d898c34290594a45eea6e56173c9ca733ec1fc17f2e1efc&scene=0&xtrack=1#rd",
      "publish_time": 1767229800,
      "publish_date": "2026-01-01 09:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.22047\", \"https://github.com/Tongyi-MAI/MAI-UI\"]",
      "add_ts": 1767309585,
      "last_modify_ts": 1767396022
    },
    {
      "id": 170,
      "article_id": "51567",
      "title": "Nat. Mach. Intell. | 统一扩散Transformer框架下的多模态心血管信号生成",
      "description": "DRUGONE提出了一种基于扩散模型与Transformer的统一多模态生成框架UniCardio，可同时修复低质量信号并合成缺失的心血管信号（如PPG、ECG和BP）。该方法克服了可穿戴设备噪声大、信号中断及侵入式测量等问题，实现了多模态心血管信号的联合利用，提升了信号恢复精度与生理一致性，为连续心血管健康监测提供了高效解决方案。",
      "content": "DRUG\nONE\n心血管信号（如光电容积描记信号 PPG、心电信号 ECG 和血压信号 BP）在生理上高度相关，共同反映心血管系统的健康状态。然而，由于可穿戴设备噪声大、信号中断频繁，以及侵入式测量带来的负担，这些信号在实际中往往难以被联合利用。研究人员提出了一种统一的多模态生成框架 UniCardio，基于扩散模型与 Transformer 架构，在单一模型中同时实现低质量信号修复与缺失信号合成。结果表明，该方法在多种生成任务和下游健康监测应用中均优于现有任务特定模型，展示了面向智能医疗的实用价值。\n心血管疾病是全球主要死亡原因之一，对连续、实时监测提出了迫切需求。当前常用的心血管信号各具优势，但也存在明显局限：\nPPG 易受运动和环境噪声干扰；\nECG 依赖精确电极布置，可穿戴性有限；\nBP 多依赖侵入式测量，难以长期监测。\n既有研究通常针对单一任务（如去噪、插补或特定模态转换）分别设计模型，未能充分利用不同信号之间的互补信息，限制了模型泛化能力和应用范围。\n图 1｜心血管信号的实时监测与诊断。\n方法概述：UniCardio 框架\nUniCardio 将多种心血管信号视为同一潜在生理过程的不同观测模态，通过统一扩散 Transformer 对其多模态条件分布进行建模，从而在一个框架中覆盖多种生成任务。\n核心设计包括：\n模态特异编码器与解码器：分别提取不同信号在多时间尺度上的特征；\n带任务特异注意力掩码的 Transformer：精确控制不同模态间的信息流动；\n持续学习训练范式：逐步引入条件模态数量不断增加的生成任务，避免灾难性遗忘。\n图 2｜模型结构与训练范式。\n多功能心血管信号生成能力\n研究人员系统评估了 UniCardio 在三类代表性任务中的表现：\n去噪：从噪声污染的原始信号中恢复高质量信号；\n插补：重建因传感器中断而缺失的信号片段；\n模态转换：利用一种或多种信号合成目标模态信号（如 PPG→ECG、PPG→BP）。\n结果显示，UniCardio 在不同任务和不同模态组合下均能生成与真实信号高度一致的波形，并且随着可用条件模态的增加，生成质量进一步提升。\n图 3｜多功能生成任务的整体性能评估。\n下游健康监测应用\n为了验证生成信号的实用性，研究人员将 UniCardio 应用于多种下游任务，包括：\n心电异常（如 ST 改变、心肌肥厚）的检测；\n房颤等心律失常的识别；\n心率与血压等生命体征的估计。\n在多种公开数据集上，基于 UniCardio 生成信号的诊断性能可达到甚至接近使用真实高质量信号的水平，显著优于直接使用噪声或不完整信号。\n图 4｜多功能生成辅助的心血管应用示例。\n可解释性与临床相关性\nUniCardio 生成的心电信号能够清晰保留典型病理特征，如 ST 段异常、T 波倒置和房颤特征，并通过临床专家验证。这种逐步去噪与重建的生成过程，也为人类专家理解模型行为提供了可解释性支持。\n图 5｜典型心电异常的可视化展示。\n讨论与展望\nUniCardio 展示了在统一框架下整合多模态心血管信号的潜力，为实时健康监测和 AI 辅助诊断提供了新的技术路径。其优势不仅体现在生成质量上，也体现在参数效率和推理速度上，使其具备在可穿戴设备中部署的可行性。\n未来，随着更大规模、多模态数据的引入，该框架有望进一步拓展至个性化监测和更复杂的临床场景。\n整理 | DrugOne团队\n参考资料\nChen, Z., Miao, Y., Wang, L. et al. Versatile cardiovascular signal generation with a unified diffusion transformer. Nat Mach Intell (2025).\nhttps://doi.org/10.1038/s42256-025-01147-y\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512407&idx=2&sn=ba7c1bf778035ca631801e2cc30f79c5&chksm=fd906de2c54a44568b5a7ae40fc9eae0dfbbdb76ff36fe44b6f8dcf55c4ab4885f083ab689c4&scene=0&xtrack=1#rd",
      "publish_time": 1767229800,
      "publish_date": "2026-01-01 09:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s42256-025-01147-y\"]",
      "add_ts": 1767309587,
      "last_modify_ts": 1767396028
    },
    {
      "id": 173,
      "article_id": "51564",
      "title": "Nat. Genet. | 利用DNA-Diffusion生成式AI框架设计合成调控元件",
      "description": "",
      "content": "DRUG\nONE\n合成调控元件（如启动子、增强子和顺式调控序列）是精确控制基因表达的核心组件，但其设计长期依赖经验规则或高通量筛选，成本高且可迁移性有限。本研究提出了一种基于扩散模型的生成式人工智能框架 DNA-Diffusion，用于从头设计具有目标表达特性的合成调控元件。研究人员表明，该模型能够在大规模基因组数据上学习 DNA 序列的统计与功能规律，并在无须显式规则约束的情况下生成具有稳定表达活性、可跨细胞类型泛化的调控序列，为合成生物学提供了一种新的通用设计范式。\n基因调控元件决定了基因在时间、空间和强度层面的表达模式，是合成生物学、电路设计和基因治疗中的关键构件。然而，天然调控序列的复杂性使得基于规则的设计方法难以全面刻画其功能空间。\n近年来，深度学习在 DNA 序列建模方面取得进展，但大多数方法仍以判别式预测为主，难以直接生成全新、功能可控的序列。生成式模型，尤其是扩散模型，在图像和蛋白序列生成中的成功，为 DNA 调控元件的从头设计提供了新的可能性。\n方法概述：DNA-Diffusion 框架\nDNA-Diffusion 采用条件扩散模型，将 DNA 序列视为离散符号序列，通过逐步加噪与反向去噪过程学习调控序列的生成分布。其核心特点包括：\n从头生成：无需模板序列或人工规则约束；\n条件控制：可基于目标表达水平、细胞类型或调控类别进行条件生成；\n可扩展性：适用于不同长度和类型的调控元件。\n模型在训练阶段利用大规模实验注释数据学习“序列–功能”映射关系，在生成阶段则通过条件采样直接输出候选调控序列。\n图 1｜DNA-Diffusion 框架概览：用于细胞类型特异性调控序列的生成建模、验证与解释。\n生成序列的统计与结构特征\n分析表明，DNA-Diffusion 生成的序列在碱基组成、局部 motif 分布和长程序列相关性方面，与天然调控元件高度一致。模型并非简单复制训练数据，而是能够组合和重构多种调控特征，探索此前未被系统覆盖的序列空间。\n此外，生成序列在信息熵和复杂度层面表现出合理分布，避免了常见的模式坍缩或过度随机化问题。\n图 2｜DNA-Diffusion 生成序列与内源性调控元件在序列相似性及转录因子基序组成上的比较。\n功能评估与实验验证\n在多种体外实验体系中，研究人员系统评估了 DNA-Diffusion 生成序列的调控功能。结果显示：\n生成的启动子和增强子在报告基因实验中展现出稳定且可调控的表达活性；\n在不同细胞类型中，部分序列表现出良好的功能保持性；\n与基于规则或其他生成模型的方法相比，DNA-Diffusion 在表达强度与多样性之间取得更优平衡。\n图 3｜利用细胞类型特异性 DNA-Diffusion 序列进行 in silico 增强子替换的预测建模。\n条件设计与功能可控性\n通过引入条件信号，DNA-Diffusion 能够定向生成具有特定表达水平或响应特性的调控序列。研究人员展示了模型在以下任务中的能力：\n按目标表达强度分级生成启动子；\n设计在特定细胞背景中优先激活的调控元件；\n在保持整体表达水平的同时优化序列多样性。\n这些结果表明，扩散模型能够在高维 DNA 序列空间中实现平滑、连续的功能调控。\n图 4｜信号强度与信号特异性的权衡及其对下游序列组成的影响。\n图 5｜STARR-seq 实验证实 DNA-Diffusion 序列的细胞类型特异性调控活性。\n图 6｜DNA-Diffusion 生成序列可将 AXIN2 表达水平提升至超过保护性变异的程度。\n与其他模型的对比分析\n研究人员将 DNA-Diffusion 与多种主流生成方法（如基于语言模型或变分自编码器的策略）进行了系统比较。结果显示，扩散模型在以下方面具有明显优势：\n更稳定的生成过程；\n更高的功能成功率；\n更强的泛化能力。\n这表明扩散框架特别适合刻画调控序列中复杂、分布式的功能信号。\n图 7｜当前最先进的合成调控元件深度学习方法的基准性能比较。\n讨论与展望\nDNA-Diffusion 提供了一种无需人工规则、可扩展且功能可控的合成调控元件设计方法，其意义不仅在于性能提升，更在于设计范式的转变：从“预测已有序列是否有效”，转向“直接生成满足需求的新序列”。\n研究人员指出，未来工作可进一步拓展至多调控元件协同设计、与染色质可及性等多模态信息融合，以及在体内模型中的系统验证。这一框架也有望与自动化实验平台结合，形成闭环的“生成–测试–优化”合成生物学流程。\n整理 | DrugOne团队\n参考资料\nDaSilva, L.F., Senan, S., Kribelbauer-Swietek, J.F. et al. Designing synthetic regulatory elements using the generative AI framework DNA-Diffusion. Nat Genet (2025).\nhttps://doi.org/10.1038/s41588-025-02441-6\n内容为【DrugOne】公众号原创\n｜\n转载请注明来源",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512398&idx=2&sn=8879e3a3a1f2b1b138a378ff6cea02d3&chksm=fdf34d116ee857f586a429142876fff96bb8d9afda41435ada9504532bb8ef084056f69e7347&scene=0&xtrack=1#rd",
      "publish_time": 1767229800,
      "publish_date": "2026-01-01 09:10",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://doi.org/10.1038/s41588-025-02441-6\"]",
      "add_ts": 1767309597,
      "last_modify_ts": 1767396045
    },
    {
      "id": 175,
      "article_id": "51604",
      "title": "马斯克10年梦成真！特斯拉全球首次自动驾驶横穿美国，人类0接管",
      "description": "2026年第一天，特斯拉FSD实现全球首次“零接管”横穿美国，标志着完全自动驾驶的重大突破。此次由车主David完成的全程无人工干预驾驶，验证了特斯拉端到端自动驾驶技术的可靠性，引发科技界广泛关注。马斯克的自动驾驶愿景正成为现实，汽车行业或迎来颠覆性变革，方向盘或将逐步退出历史舞台，智能驾驶迈入新纪元。",
      "content": "新智元报道\n编辑：Aeneas KingHZ\n【新智元导读】\n2026年第一天，自动驾驶迎来历史时刻——特斯拉FSD完成人类首次「零接管」横穿美国！全球科技圈都被引爆了，马斯克端到端自动驾驶彻底胜利。方向盘，可以退出历史舞台了？\n刚刚，特斯拉FSD，完成全球首个完全自动驾驶的横穿美国。\n从今天起，人类的自动驾驶，到达了全新的里程碑！\n就在2025年的最后一天，当全世界都在准备倒数跨年时，车主David Moss静悄悄地扔出了一枚深水炸弹——\n他驾驶搭载\nFSD\nV14.2的Model 3，完成了全球首次、经由第三方数据验证的「零接管」横贯美国之旅。\n从美国西海岸开到东海岸，2天20小时，人类0次接管。\n物理世界的「自动驾驶奇点」，终于降临！\n这条推特，也彻底引爆了全球科技圈和AI圈。\n由此，他也成为全世界第一个全程凭借自动驾驶横穿美国的人。\n可以说，这是特斯拉正式通过了公路上的图灵测试。\n这场AI主导的公路旅行，直接震撼了全球特斯拉车主。\n前特斯拉AI总监Karpathy兴奋高呼：这一刻终于来了，这是端到端神经网络的胜利，这是「软件2.0」在物理世界的完全接管，不再需要人类写下的规则！\n特斯拉官方账号，表扬了这次壮举。\n一位特斯拉车主赞叹：「我们\n已步入自动驾驶穿越美洲大陆的时代。」\n特斯拉掌门人马斯克，也激动转发莫斯的推文：「酷！」\n十年前，马斯克许下「Coast-to-Coast」的诺言，2026年1月1日，终于实现了！\n或者真如Karpathy所说：从此，方向盘只是车上的一个装饰品？\n全球首次\n人类零接管\n下面这份数据，让人难以抑制心头的震撼。\n总里程\n：2732.4英里（约等于4397公里）\n耗时\n：2天20小时\n软件版本\n：FSD v14.2\n人工接管\n：\n0\n当特斯拉从v12开始抛弃传统的C++，转向端到端神经网络，AI就从数百万小时的视频中，真正学会了开车。\n在这场横跨美国大陆的旅途中，David Moss没有任何一刻，触摸车里的方向盘，或者踩过踏板！\n想象一下：坐在驾驶座上，盯着方向盘整整\n68个小时\n（2天20小时），看着它自行转动，穿过繁忙的洛杉矶街道，汇入州际高速，避让加州的摩托车手，在德克萨斯的暴雨中稳住车身，最后停在南卡罗来纳州的海滩边。\n他从洛杉矶的特斯拉餐厅出发，最终到达南卡罗来纳州默特尔海滩，穿越了24个州。\n如果你亲自开过这段行程，就会明白全程的路况有多么复杂。然而从加州的高速公路，到中部的城市街道，再到东海岸的复杂路况，FSD一次性全部搞定了！\n天气多变，交通拥挤，甚至夜间驾驶、自动化充电，都没让系统掉链子。\nMoss评价说——整个过程中，从未出现过一次险情，即使在人类驾驶员中，这也实属罕见。\n对于好奇的网友，Moss表示，你可以登录FSD数据库，验证所有数据。\n同时，David Moss晒出了充电记录。注意，在所有站点的停车，也都是由特斯拉FSD自动完成的。\n这次横穿美国大陆，不仅体现了FSD V14.2的技术能力，也向整个行业证实——\n即使在现实的复杂场景，L4自动驾驶也有可能实现！\n十几年前，这样的壮举还只是工程师的技术梦想。\n从2016年，特斯拉的FSD系统就开始宣传「零干预横贯美国」的目标。\n在发布Autopilot 2.0时，Elon Musk就放话，说2017年底就能实现。\n这是一个迟到了八年的承诺，但当它终于兑现时，仍然让人感到吃惊！\n一位特斯拉FSD的死忠粉\n其实在25年底，David Moss就曾创下纪录。\n当时，他在特斯拉FSD V14上，连续驾驶了超过10000英里，且全程无干预，实现了真正的100%自动驾驶。\n当时的路线图是这样的。\n而这个消息出来后，网友们纷纷表示，不可能，这绝不可能！\n有人说，自己每天都在用FSD 14.2.2.1，虽然体验很棒，但绝不可能实现完全自动驾驶。\n然而David Moss晒出的仪表盘显示，FSD V14千真万确完成了100%的完全自动驾驶。\n在去年年底，他就立下宏愿：成为第一个完全依靠FSD用自动驾驶横跨美国（洛杉矶→佛罗里达）的人。\n时隔一年，他果然完成了这个目标，实现了一个更宏大的路线图。\n这完全出于他对驾驶的热爱，并不是为了炒作。\n马斯克：那个「该死的」2017 预言\n回到2016年10月。\n彼时，马斯克意气风发，豪言：「\n到2017年底，特斯拉将能够从洛杉矶自动驾驶到纽约，全程哪怕你碰一下方向盘都算我输\n。」\n后来的故事我们都知道了。\n2017年过去了，2020年过去了，甚至到了2024年，马斯克不断跳票！\n这个承诺就像是一个「永远的明年」。\n由于技术路线的反复横跳（从雷达+视觉到纯视觉，从规则代码到神经网络），特斯拉的自动驾驶曾一度陷入瓶颈，甚至被谷歌旗下的Waymo在无人出租车领域抢尽风头。\nGemini生成的特斯拉\n自动驾驶\n技术路线图\n直到FSD V12 版本的出现，特斯拉彻底抛弃了原来的代码逻辑，转向了「端到端」神经网络。\n简单说，就是让AI像人类一样，直接通过看视频学会开车，而不是由工程师一行行写代码告诉它「红灯停、绿灯行」。\n尽管特斯拉坚信端到端神经网络技术，但这绝非自动驾驶领域的共识方案。\n大多数其他自动驾驶研发公司都采用传感器密集型、模块化的驾驶方式。虽然这类系统在初期开发和调试可能更容易，但其复杂性也不容忽视。\n特斯拉AI负责人Ashok Elluswam，在国际计算机视觉大会ICCV介绍了端到端方案的优势:\n将人类价值观系统化极其困难，从数据中了解它们则容易得多。\n感知、预测和规划之间的接口定义不明确。在端到端架构中，梯度从控制端一直流向传感器输入端，从而整体优化整个网络。\n易于扩展，可处理现实世界机器人技术的庞大而长尾需求。\n具有确定性延迟的同构计算。\n总的来说，相对于过去的苦涩教训，这种方法在规模化方面处于正确的位置\n。\n更绝的是，为了自动驾驶数据打造的神经网络\n「世界模拟器」\n，同样可以模拟多种真实场景，训练擎天柱。。\n马斯克「世界模拟器」首曝，1天蒸馏人类500年驾驶经验！擎天柱同脑进化\n而这次「人类零接管」的关键在于「端到端」的最后一块拼图。\n在V14之前，特斯拉的AI虽然眼神好使（视觉感知强），但脑子里的地图还是传统的导航模块。\n这就好比一个老司机虽然车技好，但他脑子里只有一张死板的纸质地图，一旦遇到修路或者地图没更新，就容易发懵。\n而在V14.2中，特斯拉将\n导航和路径规划也整合进了神经网络\n。\n现在的FSD不再是「看着地图开车」，而是像本地人一样，能根据眼前的路况实时理解该怎么走。\n一次成功的「零接管」，不等于这套系统已经完美。\n统计学告诉我们，如果事故率是万分之一，那么跑一次几千公里的长途可能正好没遇上，但这并不代表它能安全应对几百万辆车的日常通勤。\n不过，FSD V14.2的这次表现，最大的意义在于它有力回应了「纯视觉方案无法实现长途全自动」的质疑。\n它证明了不需要昂贵的激光雷达，不需要高精地图，仅凭摄像头和算力，AI真的可以处理从繁华都市到荒凉公路的几乎所有场景。\n对于普通人来说，这意味着什么？\n官方仍是\nSAE\nL2\n（需监督），\n但车辆完成\n100%驾驶任务，\n驾驶员仅作安全监督，完全有可能。\n也许，还要等上几个版本，甚至要等到硬件Hardware 5.0的普及，我们才能真正放心地在车里睡大觉。\n但看着David Moss那辆横跨大陆的Model 3，那个曾经被嘲笑为「科幻小说」的未来，确实已经把轮胎压在了现实的沥青路上。\n参考资料：\nhttps://x.com/DavidMoss/status/2006255297212358686\nhttps://www.teslarati.com/tesla-fsd-successfully-completes-full-coast-to-coast-drive-with-zero-interventions/\nhttps://nypost.com/2025/12/31/tech/tesla-owner-completes-first-fully-autonomous-drive-across-america-and-elon-musk-weighs-in-on-the-historic-road-trip/\nhttps://www.youtube.com/watch?v=dnLswbNB0SU&t=4s\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659659&idx=1&sn=48c41752c3ed20726ed288da90dbd10a&chksm=f0cdca52f80420fa8c608ad5f8de480746f7471ff86299ac33915d8d3f814159b798256bc78f&scene=0&xtrack=1#rd",
      "publish_time": 1767369720,
      "publish_date": "2026-01-03",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://x.com/DavidMoss/status/2006255297212358686\", \"https://www.teslarati.com/tesla-fsd-successfully-completes-full-coast-to-coast-drive-with-zero-interventions/\", \"https://nypost.com/2025/12/31/tech/tesla-owner-completes-first-fully-autonomous-drive-across-america-and-elon-musk-weighs-in-on-the-historic-road-trip/\", \"https://www.youtube.com/watch?v=dnLswbNB0SU&t=4s\"]",
      "add_ts": 1767395865,
      "last_modify_ts": 1767395865
    },
    {
      "id": 177,
      "article_id": "51602",
      "title": "北京大学数据与智能实验室(PKU-DAIR)2025年度总结",
      "description": "2025年，实验室在科研创新与团队协作方面持续取得突破，多位博士生的研究成果被ICLR 2025等顶级会议录用，涵盖刘新一、王驭捷合作论文及覃彦钊、杨灵的多项研究，共计7项成果于1月被录用。团队在探索中实现共同成长，项目进展显著。感谢各方支持，期待未来继续携手推进科研发展。",
      "content": "2025年，实验室在科研创新与团队协作方面持续深耕，取得一系列扎实成果。师生在探索与实践中共同成长，多个项目获得重要进展。感谢各位朋友一直以来的支持，期待新一年继续携手前行！\n2025年1月回顾\n2025年1月，我组成员7项成果被录用。\n论文录用\n我组博士生刘新一、王驭捷等合作的一篇论文被ICLR 2025录用；\n我组博士生覃彦钊的一篇论文被ICLR 2025录用；\n我组博士生杨灵的两篇论文被ICLR 2025录用；\n我组科研实习生王子豪的一篇论文被ICLR 2025录用；\n我组博士生王驭捷和硕士生竺沈涵等合作的两篇论文被ASPLOS 2025录用。\n论文汇总\nXinyi Liu, Yujie Wang, Fangcheng Fu, Xupeng Miao, Shenhan Zhu, Xiaonan Nie, Bin Cui: \"\nNetMoE: Accelerating MoE Training through Dynamic Sample Placement\n\",\nICLR 2025\n(\nSpotlight\n)\nYanzhao Qin, Tao Zhang, Tao Zhang, Yanjun Shen, Wenjing Luo, Haoze Sun, Yan Zhang, Yujing Qiao, Weipeng Chen, Zenan Zhou, Wentao Zhang, Bin Cui:\"\nSysBench: Can Large Language Models Follow System Messages?\n\",\nICLR 2025\nXinchen Zhang, Ling Yang, Guohao Li, Yaqi Cai, Jiake Xie, Yong Tang, Yujiu Yang, Mengdi Wang, Bin Cui: \"\nIterComp: Iterative Composition-Aware Feedback Learning from Model Gallery for Text-to-Image Generation\n\",\nICLR 2025\nLing Yang, Zhaochen Yu, Tianjun Zhang, Minkai Xu, Joseph E. Gonzalez, Bin Cui, Shuicheng Yan, \"\nSuperCorrect: Supervising and Correcting Language Models with Error-Driven Insights\n\", ICLR 2025\nZihao Wang, Bin Cui, Shaoduo Gan，\"\nSqueezeAttention: 2D Management of KV-Cache in LLM Inference via Layer-wise Optimal Budget\n\",\nICLR 2025\nYujie Wang, Shenhan Zhu, Fangcheng Fu, Xupeng Miao, Jie Zhang, Juan Zhu, Fan Hong, Yong Li, Bin Cui: Spindle: \"\nEfficient Distributed Training of Multi-Task Large Models via Wavefront Scheduling\n\",\nASPLOS 2025\nYujie Wang, Shiju Wang, Shenhan Zhu, Fangcheng Fu, Xinyi Liu, Xuefeng Xiao, Huixia Li, Jiashi Li, Faming Wu, Bin Cui: \"\nFlexSP: Accelerating Large Language Model Training via Flexible Sequence Parallelism\n\",\nASPLOS 2025\n2025年2月回顾\n2025年2月，我组成员2项成果被录用。\n论文录用\n我组博士生李昊洋，硕士生葛浩等合作的一篇论文被SIGMOD 2025录用；\n我组博士生张海林，硕士生季晓东等合作的一篇论文被SIGMOD 2025录用。\n论文汇总\nHaoyang Li, Fangcheng Fu, Hao Ge, Sheng Lin, Xuanyu Wang, Jiawen Niu, Yujie Wang, Hailin Zhang, Xiaonan Nie, Bin Cui: Malleus: \"\nStraggler-Resilient Hybrid Parallel Training of Large-scale Models via Malleable Data and Model Parallelization\n\",\nSIGMOD 2025\nHailin Zhang, Xiaodong Ji, Yilin Chen, Fangcheng Fu, Xupeng Miao, Xiaonan Nie, Weipeng Chen, Bin Cui: \"\nPQCache: Product Quantization-based KVCache for Long Context LLM Inference\n\",\nSIGMOD 2025\n2025年3月回顾\n2025年3月，我组成员2项成果被录用。\n论文录用\n我组博士生黄世悦，硕士生王子威等的论文被TKDE录用；\n我组2024届博士沈彧，硕士生徐贝澄、博士生陆宇鹏等合作的一篇论文被ICDE 2025录用。\n论文汇总\nShiyue Huang, Ziwei Wang, Yinjun Wu, Yaofeng Tu, Jiankai Wang, Bin Cui: \"\nOpDiag: Unveiling Database Performance Anomalies through Query Operator Attribution\n\",\nTKDE 2025\nYu Shen, Beicheng Xu, Yupeng Lu, Donghui Chen, Huaijun Jiang, Zhipeng Xie, Senbo Fu, Nan Zhang, Yuxin Ren, Ning Jia, Xinwei Hu, Bin Cui: \"\nA-Tune-Online: Efficient and QoS-aware Online Configuration Tuning for Dynamic Workloads\n\",\nICDE 2025\n荣 誉 奖 项\n祝贺我组博士生张海林、陈伯轩等发表于SIGMOD 2024的论文荣获\nSIGMOD 2024 Honorable Mention for Best Artifact\n奖。\nSIGMOD会议是数据库领域最具影响力的顶级国际学术会议之一，与VLDB和ICDE并称为数据库领域的三大顶级会议。PKU-DAIR实验室发表于SIGMOD 2024的研究成果《\nCAFE: Towards Compact, Adaptive, and Fast Embedding for Large-scale Recommendation Models\n》荣获\nSIGMOD 2024 Honorable Mention for Best Artifact\n奖，该奖项每年仅授予至多三篇文章，旨在表彰那些在可复现性、灵活性和可移植性方面表现卓越的研究工作。\n学 术 活 动\n2025年3月30日至4月3日，我组博士生王驭捷、硕士生竺沈涵前往荷兰鹿特丹参加国际学术会议ASPLOS 2025，并在会议期间就其研究成果进行学术报告。\n图1. ASPLOS 2025 会议合影\n2025年4月回顾\n2025年4月，我组成员2项成果被录用。\n论文录用\n我组硕士生林晟、博士生李昊洋等合作的一篇论文被VLDB 2025论文录用；\n我组硕士生葛浩的一篇论文被SIGCOMM 2025论文录用。\n论文汇总\nSheng Lin, Fangcheng Fu, Haoyang Li, Hao Ge, Xuanyu Wang, Jiawen Niu,  Yaofeng Tu, Bin Cui：\"\nLobRA: Multi-tenant Fine-tuning over Heterogeneous Data\n\",\nVLDB 2025\nHao Ge, Junda Feng, Qi Huang, Fangcheng Fu, Xiaonan Nie, Lei Zuo, Haibin Lin, Bin Cui, Xin Liu: \"\nByteScale: Communication-Efficient Scaling of LLM Training with a 2048K Context Length on 16384 GPUs\n\",\nSIGCOMM 2025\n学 术 活 动\n2025年4月24日至28日，我组博士生王驭捷、覃彦钊与刘新一前往新加坡参加国际学术会议ICLR 2025，并在会议期间就其研究成果进行学术报告。\n图2. ICLR 2025 会议合影\n2025年5月回顾\n2025年5月，我组成员2项成果被录用。\n论文录用\n我组博士生盛则昂的一篇论文被KDD 2025 录用；\n我组博士后赖沛超的一篇论文被ACL 2025录用。\n论文汇总\nZeang Sheng, Weiyang Guo, Yingxia Shao, Wentao Zhang, Bin Cui:  \"\nLLMs are Noisy Oracles! LLM-based Noise-aware Graph Active Learning for Node Classification\n\",\nKDD 2025\nPeichao Lai, Zhengfeng Zhang, Wentao Zhang, Fangcheng Fu, Bin Cui: \"\nEnhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning\n\",\nACL 2025\n学 术 活 动\n2025年5月19日至5月23日，我组硕士生沈思绮、徐贝澄前往中国香港参加国际学术会议ICDE 2025，并在会议期间就其研究成果进行学术报告。\n图3. 沈思绮在 ICDE 2025 作学术报告\n图4. 徐贝澄在 ICDE 2025 作学术报告\n2025年6月回顾\n2025年6月，我组成员1项成果被录用。\n论文录用\n我组博士生夏义扉、本科生凌宿寒等合作的一篇论文被ICCV 2025录用。\n论文汇总\nYifei Xia, Suhan Ling, Fangcheng Fu, Yujie Wang, Huixia Li, Xuefeng Xiao, Bin Cui: \"\nTraining-free and Adaptive Sparse Attention for Efficient Long Video Generation\n\",\nICCV 2025\n学 术 活 动\n2025年6月22日至6月27日，我组博士生李昊洋、硕士生季晓东前往德国柏林参加国际学术会议SIGMOD 2025，会议期间就其研究成果进行学术报告。\n图5. SIGMOD 2025 会议合影\n2025年7月回顾\n2025年7月，我组成员获得多个荣誉奖项。\n荣 誉 奖 项\n我组博士生张海林获评北京大学2025年优秀博士学位论文，指导教师为崔斌教授。\n图6. 张海林（左）与导师崔斌教授（右）\n我组本科生凌宿寒获评信息科学技术学院2021级本科生“十佳”优秀毕业论文，指导教师为崔斌教授。\n图7. 凌宿寒（左）与崔斌教授（右）\n学 术 活 动\n2025 年7月27日值8月1日，我组博士后赖沛超前往奥地利维也纳参加国际学术会议ACL 2025， 会议期间就其研究成果进行学术报告。\n图8. 赖沛超参加 ACL 2025 会议\n2025年8月回顾\n2025年8月，我组成员2项成果被录用。\n论文录用\n我组博士生李昊洋，硕士生林晟等合作的一篇论文被SIGMOD 2026录用；\n我组博士后赖沛超的一篇论文被EMNLP 2025录用。\n论文汇总\nHaoyang Li, Fangcheng Fu, Sheng Lin, Hao Ge, Xuanyu Wang, Jiawen Niu, Jinbao Xue, Yangyu Tao, Di Wang, Jie Jiang, Bin Cui: \"\nHydraulis: Balancing Large Transformer Model Training via Co-designing Parallel Strategies and Data Assignment\n\",\nSIGMOD 2026\nPeichao Lai, Jiaxin Gan, Feiyang Ye, Wentao Zhang, Fangcheng Fu, Yilei Wang, Bin Cui：\"\nImproving Low-Resource Sequence Labeling with Knowledge Fusion and Contextual Label Explanations\n\"，\nEMNLP 2025\n学 术 活 动\n2025年8月3日至8月7日，我组博士生盛则昂前往加拿大多伦多参加国际学术会议KDD 2025，会议期间就其研究成果进行学术报告。\n图9. KDD 2025 会议留影\n2025年9月回顾\n2025年9月，我组成员1项成果被录用。\n论文录用\n我组博士生杨灵的一篇论文被NeurIPS 2025录用。\n论文汇总\nLing Yang, Xinchen Zhang, Ye Tian, Shiyi Zhang, Chenming Shang, Minghao Xu, Wentao Zhang, Bin Cui: \"\nHermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation\n\",\nNeurIPS 2025\n学 术 活 动\n2025年9月1日至9月5日，我组硕士生林晟前往英国伦敦参加国际学术会议 VLDB 2025，会议期间就其研究成果进行学术报告。\n图10. VLDB 2025 会议合影\n2025年10月回顾\n学 术 活 动\n2025年10月19日-10月23日，我组博士生夏义扉前往美国夏威夷参加国际学术会议ICCV 2025，会议期间就其研究成果进行学术报告。\n图11. 夏义扉参加 ICCV 2025 会议\n2025年11月回顾\n2025年11月，我组成员2项成果被录用，参与多项学术活动。\n论文录用\n我组硕士生徐贝澄、硕士生刘玮、丁克尧等合作的一篇论文被 AAAI 2026论文录用；\n我组硕士生王煊宇、博士生李昊洋等合作的一篇论文被PPoPP 2026录用。\n论文汇总\nBeicheng Xu, Wei Liu, Keyao Ding, Yupeng Lu, Bin Cui: \"\nPSEO: Optimizing Post-hoc Stacking Ensemble Through Hyperparameter Tuning\n\",\nAAAI 2026\n(\nOral\n)\nXuanyu Wang, Fangcheng Fu, Haoyang Li, Hao Ge, Sheng Lin , Jiawen Niu, Bin Cui: \"\nElastor: Elastic and Efficient Model Partitioning and Checkpointing for Fault-tolerant Distributed Training\n\",\nPPoPP 2026\n学 术 活 动\n2025 年11月5日至11月9日，我组博士后赖沛超前往中国苏州参加国际学术会议EMNLP 2025，会议期间就其研究成果进行学术报告\n图12. 赖沛超参加 EMNLP 2025 会议\n2025年11月14日至11月15日，我组博士生刘新一等同学前往中国香港参加国际学术研讨会FAISys 2025，会议期间就其研究成果进行学术报告。\n图13. FAISys 2025 会议合影\n2025年12月回顾\n研究评测\n我组博士生张海林、硕士生季晓东等合作的研究成果“\nPQCache: Product Quantization-based KVCache for Long Context LLM Inference\n”，被美国伯克利大学SkyLab实验室所主导的\nSkyLight\n榜单\n（\nhttps://sky-light.eecs.berkeley.edu/#/home\n）评估多项指标名列第一，验证了我组研究工作的有效性。\n结 · 语\n辞别2025的忙碌与收获，迎接2026的希望与好运。马踏新春福气到，家家户户纳福安。祝福新老朋友们，马年行大运，马到成功事事顺，骏马奔腾步步高，事业蒸蒸日益兴！新春快乐！\nEND\n欢迎关注本公众号，帮助您更好地了解北京大学数据与智能实验室（PKU-DAIR），第一时间了解\nPKU-DAIR\n实验室的最新成果！\n实验室简介\n北京大学数据与智能实验室（Data And Intelligence Research Lab at Peking Univeristy，PKU-DAIR实验室）由北京大学计算机学院崔斌教授领导，长期从事数据库系统、大数据管理与分析、人工智能等领域的前沿研究，在理论和技术创新以及系统研发上取得多项成果，已在国际顶级学术会议和期刊发表学术论文200余篇，发布多个开源项目。课题组同学曾数十次获得包括CCF优博、ACM中国优博、北大优博、微软学者、苹果奖学金、谷歌奖学金等荣誉。PKU-DAIR实验室持续与工业界展开卓有成效的合作，与腾讯、阿里巴巴、苹果、微软、百度、快手、中兴通讯等多家知名企业开展项目合作和前沿探索，解决实际问题，进行科研成果的转化落地。",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzkzODMxNTkzNg==&mid=2247485086&idx=1&sn=464385366e75be6b4e0534a24e299d37&chksm=c34e306202f2831c46ca9d24e0c7bf20c17107420c6bbed3a4476789a588ae127f8e79c9ca69&scene=0&xtrack=1#rd",
      "publish_time": 1767355800,
      "publish_date": "2026-01-02",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://sky-light.eecs.berkeley.edu/\"]",
      "add_ts": 1767395872,
      "last_modify_ts": 1767395872
    },
    {
      "id": 178,
      "article_id": "51601",
      "title": "最新英伟达经济学：每美元性能是AMD的15倍，“买越多省越多”是真的",
      "description": "Signal65最新报告显示，英伟达AI算力性价比远超AMD，在生成相同数量token时，其成本仅为AMD的十五分之一。尽管单价较高，但英伟达平台每投入一美元获得的性能是AMD的15倍，整体更省钱，凸显其在AI算力领域的领先地位。",
      "content": "梦晨 发自 凹非寺\n量子位 | 公众号 QbitAI\n为什么AI算力霸主永远是英伟达？\n不算不知道，一算吓一跳：\n在英伟达平台每花一美元，获得的性能是AMD的15倍\n。\n尽管英伟达卖的更贵，但只要买齐一套，就更省钱。\n来自\nSignal65\n的一份最新详尽报告揭示了这个现实，一定条件下生成同样数量的token，英伟达的成本只有AMD的十五分之一。\n这份报告基于SemiAnalysis Inference MAX的公开基准测试数据，时间跨度从2025年10月到12月，覆盖了从密集模型到前沿MoE推理模型的全场景测试。\n黄仁勋的“买的越多，省的越多”原来是真的。\nMoE时代：8卡系统撞上Scaling天花板\nAI模型正在经历一场架构革命，打开Artificial Analysis排行榜就会发现，智能度排名前十的开源模型清一色都是MoE\n（Mixture of Experts，专家混合）\n推理模型。\n另一项来自OpenRouter的数据显示，超过50%的token流量正在被路由到推理模型上。\nMoE架构的核心思路是把模型参数拆分成多个专门化的“专家”子网络，每个token只激活其中一小部分。\n以经典的DeepSeek-R1为例，它拥有6710亿总参数，但每个token只激活370亿——这让它能以更低的计算成本提供前沿级别的智能。\n问题随之而来。当专家分布在多块GPU上时，GPU之间的通信延迟会导致计算单元空闲等待数据，这些空闲时间直接转化为服务商的成本。\n报告指出，无论是英伟达B200还是AMD MI355X，所有8卡系统在超出单节点规模后都会撞上“扩展天花板”（scaling ceiling）。\n英伟达GB200 NVL72的解法是把72块GPU通过NVLink连接成一个单一域，提供130 TB/s的互联带宽。\n在软件层面，整个系统就像一块巨型GPU一样运作。配合英伟达Dynamo推理框架的分离式预填充-解码调度和动态KV缓存路由，这套架构能够有效突破8卡系统的通信瓶颈。\n模型越复杂，英伟达的优势越明显\n报告测试了三类典型模型：模型越复杂，英伟达的优势越明显。\n在密集模型Llama 3.3 70B上，英伟达B200对比AMD MI355X的领先幅度相对温和。\n在基线交互性\n（30 tokens/sec/user）\n下，B200的性能约为MI355X的1.8倍；当交互性要求提升到110 tokens/sec/user时，这一差距扩大到6倍以上。\n中等规模的MoE模型GPT-OSS-120B开始让差距变得更加显著。\n这款OpenAI开源模型拥有1170亿总参数，但每个token只激活约51亿参数。在2025年12月的测试数据中，100 tokens/sec/user交互性下B200的性能接近MI355X的3倍。\n在更符合推理模型需求的250 tokens/sec/user条件下，差距扩大到6.6倍。\n两个平台的绝对性能相比10月都有显著提升，英伟达的峰值吞吐从约7000 tokens/sec跃升至14000以上，AMD则从约6000提升到8500左右，但相对差距反而拉大了。\n真正的分水岭出现在前沿推理模型DeepSeek-R1上。\n这款模型集MoE路由、大参数规模和高强度推理生成于一身，对基础设施的要求极为苛刻。\n测试结果显示：在25 tokens/sec/user交互性下，GB200 NVL72的每GPU性能是H200的10倍、MI325X的16倍；在60 tokens/sec/user下，相比H200的优势扩大到24倍，相比MI355X达到11.5倍；在75 tokens/sec/user下，GB200 NVL72的性能是B200单节点配置的6.5倍，是MI355X的28倍。\n更关键的是，GB200 NVL72能够达到竞争平台根本无法企及的水平，在28卡配置下可以输出超过275 tokens/sec/user，而MI355X在相当吞吐水平下的峰值只有75 tokens/sec/user。\nToken经济学：贵了1.86倍，便宜了15倍\n直觉上，性能更强的平台应该更贵。事实也确实如此：根据Oracle Cloud的公开定价，GB200 NVL72的每GPU每小时价格为16美元，MI355X为8.60美元，前者是后者的1.86倍。\n如果参照CoreWeave的定价，GB200 NVL72相比上一代H200的价格也贵了约1.67倍。\n但报告的计算揭示了一个反直觉的结论：\n在25 tokens/sec/user交互性下，GB200 NVL72的性能优势为5.85倍，除以1.86倍的价格溢价，每美元性能仍是MI355X的3.1倍。\n在75 tokens/sec/user交互性下，28倍的性能优势除以1.86倍的价格，每美元性能达到MI355X的15倍，这意味着生成同等数量的token，英伟达平台的成本只有AMD的十五分之一。\n与上一代产品的对比同样惊人。\n报告估算在DeepSeek-R1的典型工作负载下，GB200 NVL72相比H200的性能提升约20倍。\n而GB200 NVL72价格仅上涨1.67倍，换算下来每美元性能提升约12倍，单token成本降至H200的十二分之一。\nMoE推理让网络成为推理成本的瓶颈，而机柜级的GB200 NVL72恰好解决了这个问题。价值的衡量标准正在从单纯的算力转向“每美元能产出多少智能”。\n报告在结论中指出，AMD的竞争力并未被完全否定——在密集模型和容量驱动的场景下，MI325X和MI355X仍有用武之地。\nAMD的机柜级解决方案Helios也在开发中，可能在未来12个月内缩小差距。\n但就当前的前沿推理模型而言，从芯片到互联到软件的端到端平台设计，已经成为成本效益的决定性因素。\n参考链接：\n[1]https://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n量子位智库2025年度「AI 100」榜单\n正式开启招募！\n和我们一起在日新月异的AI产品市场中厘清背后脉络，把握未来动向，找到真正代表中国AI实力的巅峰力量 🔽\n一键关注 👇 点亮星标\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859650&idx=1&sn=583c1487a82314f3a8df0002721da2e8&chksm=e9506028eac20d23f5a6891aed378a7971dc25e0c261664a5e4798f1af34dc4f6bb385c4d96c&scene=0&xtrack=1#rd",
      "publish_time": 1767355800,
      "publish_date": "2026-01-02",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://signal65.com/research/ai/from-dense-to-mixture-of-experts-the-new-economics-of-ai-inference/\"]",
      "add_ts": 1767395876,
      "last_modify_ts": 1767395876
    },
    {
      "id": 179,
      "article_id": "51600",
      "title": "F1暴涨20分，推理速度恒定！新架构VGent：多目标定位又快又准",
      "description": "UIC与Adobe研究团队提出VGent模型，针对多目标和视觉参照带来的视觉定位挑战，采用模块化设计解耦推理与预测过程，兼顾推理速度与性能。通过多种模块化增强方案，显著提升模型效率与准确性，实现快速响应与高精度定位，为复杂场景下的视觉理解提供新思路。",
      "content": "新智元报道\n编辑：LRST\n【新智元导读】\n多目标（Multi-target） 以及 视觉参照（Visual Reference） 为视觉定位（Visual Grounding）任务的推理速度和性能同时带来了全新的挑战。 为了解决这一难题，来自UIC和Adobe的研究团队提出了VGent模型。这是一种兼顾速度与性能的模块化设计，旨在将模型的推理与预测能力解耦，并辅以多种模块化增强方案 。最终，VGent凭借不到16B的参数量，在多目标及带视觉参照的视觉定位基准（Omnimodal Referring Expression Segmentation, ORES）上，大幅超越了Qwen3-VL-30B，实现了平均+18.24 F1的巨大提升！\n在多模态大模型（MLLM）时代，视觉定位是MLLM细粒度推理能力的重要一环，同时也是实现人机交互和具身智能的核心能力。\n现有的解决方案主要分为两类：\n原生Token派（Native-token）：\n像 Qwen2.5-VL 或 Ferret-v2 这样的模型，通过自回归（auto-regressive）的方式利用原有的词表逐个生成边界框坐标 。这种方式不仅速度慢（推理时间随目标数量线性增加），而且在多目标场景下容易产生幻觉（Hallucinations），即模型可能会在列举完所有目标对象之前就过早停止，或者在目标密集的场景中陷入无限生成的死循环。如图一所示，随着目标数量的增加，这类方法在多目标场景下的低效和不稳定性变得尤为明显。\n新增Token派（New-token）：\n另一类方法尝试通过引入特殊的token（如[SEG]或 object token）来指代目标物。他们需要收集大规模的数据集、从LLM起重新构建一个能理解这些新增token的MLLM。因此，这种方法不可避免地会破坏LLM在预训练阶段获得的通用推理能力。更严重的是，其导致无法直接利用现有的、先进的、进行了更大规模预训练的开源MLLM（如 QwenVL系列）。\n来自UIC（伊利诺伊大学芝加哥分校） 和Adobe的研究团队提出一种模块化的编码器-解码器（Encoder-Decoder）架构\nVGent，\n其核心思想是：将高层的语义推理交给MLLM，将底层的像素预测交给目标检测器（detector），最终通过hidden state将这种解耦后的关系进行连接。\n论文地址：\nhttps://arxiv.org/abs/2512.11099\n研究人员认为，语义推理和精准定位是两种截然不同的能力，强迫训练一个单一的整体模型去同时精通抽象的语义推理和像素级别的底层预测，会导致性能和效率上的权衡。\n更符合直觉的方式，应该是由不同的组件做各自擅长的事。\n基于这一洞察，VGent提出了一种模块化的编码器-解码器设计，利用现成的MLLM和detector将高层多模态推理与底层预测解耦。\n其核心理念在于MLLM和detector的优势是互补的：\nMLLM擅长多模态语义对齐和推理，而detector则擅长高效地提供精准的多目标检测框\n。\n图一：VGent（蓝色）与现有先进的MLLM（Qwen2.5-VL，灰色）在多目标视觉定位任务上的对比。左图显示VGent的推理时间恒定且迅速，而 MLLM 随目标数量增加呈线性增长；右图显示VGent在F1分数上实现了显著提升，特别是在多目标场景下。\n方法\n基础架构\nVGent主要由图二所示的encoder和decoder两部分组成，并引入了三种模块化增强机制（图三、四和五）。\n图二：VGent框架概览\n如图二所示，左侧encoder是一个 MLLM，使用QuadThinker来提升其多目标推理能力。冻结的encoder输出hidden states并存储下来给到decoder。右侧decoder初始化自encoder的LLM 层，其将detector生成的object proposal作为query，通过cross-attention与encoder的hidden states交互。\n研究人员在decoder内部新增了self-attention层（参数初始化自同一层的cross-attention），用于促进query之间的信息交流。 最终的输出进行yes / no的二元判断来选择每个proposal是否属于目标。相应的segmentation mask则通过 prompt SAM 得到。\nQuadThinker：强化多目标推理能力\n针对MLLM在多目标场景下推理能力下降的问题，研究人员提出了一种基于 GRPO 的强化学习训练范式QuadThinker，通过设计特定的prompt和reward functions，引导模型执行区域到全局、分步推理的过程：先分别统计图像四个象限内的目标数量，再汇总总数，最后预测具体坐标。\n图三：QuadThinker所使用的prompt。\nMask-aware Label：解决检测与分割的歧义\n在多目标场景中，检测（Box）与分割（Mask）任务的定义存在一定的差别。检测通常优化「一对一」的匹配，而分割则旨在召回所有前景像素。\n图四：Mask-aware Label示意图。基于IoA的标签分配策略能召回被传统IoU忽略的细粒度部件。\n这种差异导致了标注歧义：例如图四（左）中，检测器可能将「鹿头装饰」与其「挂绳」视为两个独立的框。\n在检测任务的 IoU 标准下，由于挂绳的框比较小、相对于整体真值框的重叠率过低，往往会被当作负样本在标注阶段被过滤掉（被标上负标签）。但是对于分割任务来说，这个挂绳属于前景，其应该被标上正标签。\n为此，VGent引入了Mask-aware Label，使用IoA (Intersection-over-Area) 指标进行额外的标签分配。如图四（右），IoA通过计算候选mask （通过proposal prompt SAM得到）与多目标真值的union mask的交集，并除以候选mask自身的面积得到。\n因为IoA的分母是候选mask自身面积，该机制能精准召回那些虽然只覆盖了部分目标群（如细小的挂绳）但依然有效的 proposal。模型使用另一个独立的MLP head专门预测这种分割导向的标签，用于解决视觉定位中分割类型的输出。\nGlobal Target Recognition：增强全局感知\n为了提升候选框选择的准确性，VGent 引入了Global Target Recognition模块。\n图五：Global Target Recognition示意图。利用Learnable Queries注入全局目标数量信息，并聚合多个detector的结果以提升\n召回率\n。\n为了提高召回率，研究人员聚合了来自多个detector的proposal形成一个统一的query set，之后引入了额外的 learnable queries与这些proposal queries拼接作为decoder的输入。\n这组query被专门训练用于预测目标的总数以及正样本proposal的数量。通过decoder层内的self-attention机制，这些包含全局统计信息的learnable query能够与proposal query进行交互，将「全局线索」传播给每一个候选框，从而增强其对目标群体的整体理解，实现更精准的选择。\n实验结果\n研究人员在最新的多目标视觉定位基准 ORES (MaskGroups-HQ) 以及传统的单目标数据集上进行了广泛评估。\n多目标视觉定位（Multi-target Visual Grounding）\n图六：在 Omnimodal Referring Expression Segmentation (ORES) 上的性能对比。ORES是多目标以及存在视觉参照（w/ < mask-ref >）的视觉定位基准。\n如图六所示，在极具挑战的ORES基准上，VGent 取得了全新的SOTA成绩。相比之前的最佳方法RAS13B，VGent在F1分数上实现了+20.58%的巨大提升。VGent在gIoU和cIoU上都带来了明显的提升。\n值得注意的是，即使对比参数量更大的Qwen3-VL-30B，VGent 依然保持显著优势。同时，得益于模块化设计，VGent 在目标数量增加时保持恒定且快速的推理速度，避免了自回归模型随目标增加而线性增长的推理延迟（如图一所示）。\n单目标视觉定位（Single-target Visual Grounding）\n图七：在referring expression comprehension (REC) 上的性能对比。\nVGent在传统单目标基准（RefCOCO, RefCOCO+, RefCOCOg）上也表现卓越。\nVGent实现了90.1%的平均准确率，超越了InternVL3.5-20B和38B等更大规模的模型 。相比其backbone (Qwen2.5-VL-7B)，VGent带来了+3.5%的平均性能提升。\n可视化\n图八：VGent在不同挑战下的预测结果可视化。\nVGent在复杂场景中展现了极强的鲁棒性。\n如图八（上）所示，VGent精准定位所有方形钟表，即使存在大量相似的钟表作为干扰项，展现了VGent在密集多目标场景下的优越表现。\n图八（下）中，VGent 成功定位了视觉参照（蓝色 mask），并继续推断出左侧穿裙子的女士，排除了右侧的干扰项。\n参考资料：\nhttps://arxiv.org/abs/2512.11099\n秒追ASI\n⭐点赞、转发、在看一键三连⭐\n点亮星标，锁定新智元极速推送！",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652659659&idx=3&sn=9c0411e0e0c30b3dfe6402420ce17078&chksm=f0e9e45cce53df8e57b5a523eabf101e0dff070323669b28593dcab76584240ae3030bc22076&scene=0&xtrack=1#rd",
      "publish_time": 1767331200,
      "publish_date": "2026-01-02",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://arxiv.org/abs/2512.11099\"]",
      "add_ts": 1767395880,
      "last_modify_ts": 1767395880
    },
    {
      "id": 184,
      "article_id": "51594",
      "title": "董事长稚晖君发布上纬新材首款机器人！能塞书包还能骑机器狗",
      "description": "2025年12月31日，上纬新材董事长彭志辉（稚晖君）发布全球最小人形机器人上纬启元Q1，身高仅0.8米，为首款实现全身力控的微型具身智能机器人。作为智元机器人联合创始人，稚晖君将前沿技术融入该产品，不仅具备大型机器人全部功能，更在灵活性与场景适应性上实现突破，可轻松装入书包，甚至可骑行，展现出强大的创新潜力与应用前景。",
      "content": "henry 发自 凹非寺\n量子位 | 公众号 QbitAI\n2025年的最后一天，上市公司上纬新材董事长\n彭志辉\n（稚晖君）发布了一款能装进书包的机器人产品——\n上纬启元Q1\n。\n这是全球首款最小尺寸（0.8m）、实现全身力控的人形机器人，也是智元机器人联合创始人\n稚晖君\n担任上纬新材董事长以来，发布的首款具身智能机器人产品。\n虽然体型迷你，但大机器人能做的，启元Q1也能做。\n大机器人做不了的，启元Q1还能做。\n（我骑过狗你骑过吗？）\n而前段时间让网友猜疯了的 “大有可为” 神秘海报，也终于在这次的发布视频中正式揭晓答案。\n其中醒目的1.88，既不是身高，也不是售价，而是启元Q1的体积（立方米）——一个被压缩到背包级的人形机器人尺寸。\n启元Q1是一款怎样的机器人？\n从产品定位上看，稚晖君这次的新作\n启元Q1\n，是一款面向个人用户、开发者，科研、陪伴、创作场景的小尺寸人形机器人。\n相较于市面上的全尺寸人形机器人，启元Q1最直观的突破的就是把体型和重量狠狠压缩——\n甚至能主动来个双折叠，被你揣进书包。\n值得一提的是，这种小型化设计，并不只是为了方便携带。更轻的重量，让机器人本身更耐造，也把使用和试错成本一起打了下来，更适合个人和小团队反复折腾。\n在产品能力上，启元Q1反复强调了一个关键词——\n全身力控\n。\n简单来说，全身力控并不意味着机器人“力气更大”，而是全身关节都能感知和调节受力。\n传统机器人更多是“按角度走动作”，一旦遇到外力干扰，往往要么硬顶、要么停机。\n而具备全身力控的机器人，在被推、被拉、与环境接触时，会根据外力变化实时调整动作，避免僵硬对抗。\n这一能力让机器人在被推、被拉或与环境接触时，表现出更自然的物理交互特性，也是具身智能落地过程中较为关键的一项基础能力。\n在使用场景上，启元Q1可以充分满足各类用户的需求。\n在科研与教育场景中，它支持开放的SDK与HDK接口，可用于具身智能算法验证、教学实验和动作规划研究。\n小尺寸带来的直接好处是——不需要复杂防护结构，随拿随用，适合高频实验。\n在个人交互场景中，启元Q1接入启元灵心平台，支持自然语言对话、知识问答、英语教学和动作示范，并通过柔性阻抗控制，让人机交互更接近“可长期共处”的状态。\n而在创作者和极客用户方向，启元Q1采用模块化结构设计，支持3D打印外壳和外观定制，并可通过灵创平台编排动作、语音和行为逻辑，为二次创作留出了足够空间。\n这些能力背后，真正的技术难点集中在一个地方——\n关节系统\n。\n高性能人形机器人通常依赖QDD（Quasi-Direct Drive）准直驱关节，来实现力控和高动态动作，但这一方案长期面临的问题是：性能好，但难以做小、做轻。\n在启元Q1上，上纬启元对QDD关节进行了系统性重构——从材料选择、结构布局，到控制算法的协同设计，将核心关节模块压缩至\n不到鸡蛋大小\n，同时保留了力控性能和动态响应能力。\n也正因如此，启元Q1成为目前首个在小尺寸形态下实现全身力控的小尺寸人形机器人。\n机器人即产品\n这次启元Q1的发布，可以被视为稚晖君此前探索的“机器人即服务（RaaS）”路径，在个人机器人市场上的一次延伸。\n而这，也恰恰对应了当前具身智能厂商的普遍趋势——在持续服务科研、生产力和开发需求的同时，开始主动探索面向个人用户的产品形态。\n长期以来，无论是在工厂中的劳动力替代，还是科研中的实验载体，机器人始终被定义为一种工具。\n而今年开始，松延动力推出的Bumi人形机器人（售价 9998 元），以及维他动力推出的大头BoBo机器狗（售价 9988 元），都在指向一个相似方向——\n体型更小、价格更低、可被个人用户实际拥有和使用的具身智能产品。\n这些产品在保持科研与开发属性的同时，更加关注体积、价格、耐用性和可玩性，而这，也意味着具身智能正从“实验工具”，逐步走向“可使用的产品”。\n在2025年即将收官之际，启元Q1正是这一趋势下的一个具体落点——\n在科研与产业应用之外，机器人开始被真正放入个人与开发者的日常使用场景之中。\n而回看上纬新材的节奏，这一变化并非突然发生：\n11月6日完成控股权交割，智元系实现绝对控股，彭志辉入选董事候选人。\n11月25日董事会换届，稚晖君出任董事长。\n12月31日，发布首款具身智能机器人产品。\n短短两个月，这家以材料业务起家的上市公司，就已经是不折不扣的A股具身智能第一股了。\n一键三连\n「点赞」「转发」「小心心」\n欢迎在评论区留下你的想法！\n—\n完\n—\n专属AI产品从业者的\n实名社群\n，只聊AI产品\n最落地的真问题\n扫码添加小助手，发送\n「姓名+公司+职位」\n申请入群～\n进群后，你将直接获得：\n👉 最新最专业的AI产品信息及分析 🔍\n👉\n不定期发放的热门产品内测码 🔥\n👉\n内部专属内容与专业讨论 👂\n🌟 点亮星标 🌟\n科技前沿进展每日见",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247859620&idx=1&sn=8c1f3169aedb59161d6fd74dc4888e81&chksm=e924276799d0c252886315241822a49c44c2385338cc3f4cf8ef6ddbe396e1320ef7cb6e9954&scene=0&xtrack=1#rd",
      "publish_time": 1767319200,
      "publish_date": "2026-01-02",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "",
      "add_ts": 1767395900,
      "last_modify_ts": 1767395900
    },
    {
      "id": 185,
      "article_id": "51593",
      "title": "元生十倍升级：工业级智能体驱动规模化原创生物学假说发现",
      "description": "“创世纪计划”引发全球关注，推动人工智能与科研深度融合。2024年末，临港实验室启动“元生计划”，并于2025年6月联合上海人工智能实验室、上海交大、复旦大学等发布元生虚拟疾病生物学家v1.0。该AI系统通过干湿结合的系统性研究，显著提升药物靶标发现效率，打破多项纪录，标志我国在AI驱动生命科学领域取得重要突破，加速疾病机制解析与新药研发进程。",
      "content": "近期，“创世纪计划”在全球引发高度关注，表明人工智能与科学研究深度融合已进入提速阶段。\n2024年末，临港实验室启动元生计划，并在2025年6月联合上海人工智能实验室、上海交通大学、复旦大学等机构公开发布了元生虚拟疾病生物学家\nv\n1.0版本\n（\n超越OpenAI！临港实验室首发AI虚拟疾病生物学家“元生”，刷新多项纪录，破解药物靶标发现难题\n）\n。元生虚拟疾病生物学家通过系统性的干湿结合研究，验证了其在规模化生成原创科学假说方面的能力，并在我国人群重大疾病相关靶标的发现与验证中发挥了重要作用。\n今天，\n元生虚拟疾病生物学家v1.3版本\n（https://origene.lglab.ac.cn/\n）\n正式上线，并推出升级版科学假说发现模式。基于智能体实战经验和用户反馈，v1.3版本全面升级了认知能力与知识体系，以进一步适配创新药研发场景中所呈现的超长上下文、复杂知识空间、多层证据链、多模态以及多决策节点等特性。\n新模式总体文献阅读总量提升\n10倍\n、文献幻觉率相较行业标杆方法减少约\n40%\n、平行调研能力提高逾\n10倍\n。深度模式下单次任务可完成对超过\n1000篇文献\n和多模态数据的阅读与关联分析，将假说生成的广度、深度与可信度放大到工业级规模。随着规模化研究能力落地，元生正在推动\n重构生物医药创新体系的科研范式\n。\n接下来，我们将详细介绍本次版本的核心架构升级与实测表现。\n01\n多智能体虚拟协作空间\n元生v1.3模式创新性地构建了一个能够有序地组织和监督大规模智能体的虚拟协作空间。\n图1 智能体虚拟协作空间\n在纵向信息处理工序上，v1.3在调研开端新增了假说生成模块，面对用户对新科学假说的需求进行“合理候选生成”和“快速迭代筛选”，为深度调研步骤提供理想起始点。\n在横向调研广度上，v1.3能够自动对复杂科学问题进行合理的独立研究方向划分，对每个研究维度进行独立深入探讨，直至在该角度上足够形成证据充足、逻辑完整的研究报告。各个角度基于证据的报告支撑起v1.3最终形成围绕单主题的多角度研究成果，避免了现有智能体体系易落入局部单一视角问题。\n元生v1.3的设计理念是用户应该实时掌握智能体调研团队在科学研究过程中的关键决策和重要信息流动。如图1所示：元生v1.3创新构建智能体调研团队可视化界面，在多环节、多角度的调研过程中，实时展示当前主智能体数目、科学任务，以及思考和决策过程。未来版本将开放更多智能体人类协同和互动功能。\n02\n特性：工业级知识管理和调研能力\n元生v1.3的强大调研能力由海量的科学文献和网页作为科学证据支撑，相较于v1.0文献阅读量提升10倍以上。\n图2 元生\nv\n1.3版本主要升级的能力维度\n文献来源和广度提升10倍\n基于坚实的文献基建，元生v1.3大大提升了文献来源广度和阅读能力，针对每个细分问题在30s时间量级内给出约10篇科学文献回应。在v1.3深度研究模式中，智能体系统平均阅读超过1000篇科学文献或网页来生成满足严肃科研场景、证据充分的调研结果。\n文献引用幻觉率较行业标杆减少40%\n幻觉问题——尤其是文献引用幻觉——是科学研究智能体系统面对的最大挑战之一。在整体文献引用数量和文献阅读数量均超过同类产品10倍的前提下，v1.3版本的引用证据正确率仍保持>90%，显著超过Gemini，GPT，DeepSeek，和其他深度调研类及智能体类产品。文献正确率的提升源自于元生v1.3的知识框架迭代，使其能够进行“科学陈述-支持证据-原始文献”的溯源，从而使智能体在最终结果中更多使用可查询的证据。\n平行调研能力提高10倍\n元生v1.3通过大规模智能体协同架构，显著提升对复杂科学问题的平行调研能力。新版本将复杂问题自动拆解为5–10个独立但互补的调查维度，并为每个维度部署专用子智能体。这些子智能体可自主调度下级智能体，并行开展文献阅读、证据整合、假设推演与反思优化，实现深度与广度的同步扩展。相较于上一版本，v1.3的整体调研吞吐量提升约10倍，关键维度的分析深度平均提升一倍以上。这一架构使元生初步具备虚拟科研团队的协作能力，为生成更可靠、更系统的科学假说奠定基础。\n高质量科学假说产出\n元生v1.3在多角度评估中都表现优越。在生物医学研究问题集上，元生v1.3的标准模式和通用智能体Gemini-3-pro, DeepSeek v3.2，深度调研系统GPT Deep research和生物医药领域专用智能体系统进行了对比。如图3-4所示，在文献引用方面，元生v1.3标准模式的引用正确率显著超越现有方法，在调研过程中的总阅读量上，元生相比提供数据的其他候选系统高出一个数量级。在报告质量方面，基于三款领先的大模型评审员的独立打分，元生v1.3标准模式在五个报告质量维度均优于候选方法。\n图3 各模型产生报告的有效参考文献数目对比\n图4 科学假说报告效果评测。引用正确率使用CiteTrue（https://citetrue.com/）评价；其他科学假说相关指标参考相关工作[1, 2]，其中，充分性衡量对既定科学问题的解决程度；事实依据衡量证据和逻辑的正确性；影响力衡量假说对领域的贡献程度；预期有效性衡量假说和方案达到预期效果的可能性。\n多模态理解和可视化升级\n元生不仅生成科学假说与分析报告的文字内容，还能自主调用计算工具和可视化工具，动态生成高质量多模态结果图（如图5所示）。自主产生和搜集的可视化图片及其对应的科学证据共同支撑v1.3更丰富的调研报告，帮助元生从以文献和数据为中心走向更广泛的多模态智能体框架。\n图5 元生产生的多模态分析结果展示\n03\n案例展示\n以下是生物医学领域的专业内测用户提供的典型应用案例和用户反馈，\n点击\n“阅读原文”\n查看完整案例报告。\n1.非天然氨基酸在外泌体领域交叉应用：\n用户A：\n该报告提出非天然氨基酸为外泌体工程化提供了可编程的化学接口\n，通过代谢掺入与遗传密码扩展技术，实现了生物正交标记、表面功能化、互作捕获和货物强化的四位一体方法学框架。元生整合了生物化学和生物医学两个领域的研究成果，从实验室研究拓展到工业应用层面，有前瞻性，\n充分体现了跨学科信息整合能力\n。\n2.衰老新假说：\n用户B：\n针对人类衰老的生物学机制，\n元生提出新概念“Glycan Code Entropy (GCE)”以及相应的调控方式\n，非常新颖的概念，且支持证据扎实，融合了多个领域的研究成果提出的假说，相信相关领域的科研者看到会眼前一亮。提问中没有引导和倾向性的词语，该假说由元生自主提出，体现了元生产出具有科学性的\n原创概念假说\n的能力。\n3.疾病相关GPCR分析：\n用户C：\n针对用户提出的靶点调研问题，\n元生论证\n了\n10+个孤儿GPCR和疾病的关联性\n，证据来源可靠且多源，由元生提出了一套科学合理的靶标打分规则，分析流程也很规范，得出的结果可信，展示了元生基础坚实的\n系统分析能力\n。\n此外，在实际使用过程中，元生的用户群体发现该平台能够适配从基础生物机制研究到疾病转化策略生成的多类任务，其能力覆盖生物医学研究的各个领域。我们诚挚邀请各位用户共同体验、使用并探索元生的更多可能性。\n04\n邀请使用\n元生系统目前已经全面开放注册体验，欢迎试用：\nhttps://origene.lglab.ac.cn/\n相\n关链接\n·论文链接：\nhttps://www.biorxiv.org/content/10.1101/2025.06.03.657658v1.full.pdf\n·项目主页：\nhttps://gentel-lab.github.io/OriGene-Homepage/\n·代码仓库：\nhttps://github.com/GENTEL-lab/OriGene\n参考文献\n[1] Gottweis, Juraj, et al. arXiv preprint arXiv:2502.18864 (2025).\n[2]\nVasu, Rosni, et al. arXiv preprint arXiv:2510.00620 (2025).",
      "article_url": "https://mp.weixin.qq.com/s?__biz=MzU2ODU3Mzc4Nw==&mid=2247512423&idx=1&sn=cd4e2fdf8ede4acf805e9fcdcc8e3ff4&chksm=fd305c4b973f4b9fb63d2f11889c2aa0d4d373cdf90147d22310cfe8688ca9ee1bee8c48723b&scene=0&xtrack=1#rd",
      "publish_time": 1767318000,
      "publish_date": "2026-01-02",
      "read_count": 0,
      "like_count": 0,
      "comment_count": 0,
      "share_count": 0,
      "collect_count": 0,
      "source_keyword": "baai_hub",
      "is_original": 1,
      "reference_links": "[\"https://origene.lglab.ac.cn/\", \"https://citetrue.com/\", \"https://www.biorxiv.org/content/10.1101/2025.06.03.657658v1.full.pdf\", \"https://gentel-lab.github.io/OriGene-Homepage/\", \"https://github.com/GENTEL-lab/OriGene\"]",
      "add_ts": 1767395903,
      "last_modify_ts": 1767395903
    }
  ],
  "reported_article": [
    {
      "id": 1,
      "article_id": "aibase_aibase_24035",
      "original_id": "aibase_24035",
      "source_table": "aibase_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 2,
      "article_id": "baai_51475",
      "original_id": "51475",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 3,
      "article_id": "baai_51478",
      "original_id": "51478",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 4,
      "article_id": "baai_51473",
      "original_id": "51473",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 5,
      "article_id": "qbitai_366144",
      "original_id": "366144",
      "source_table": "qbitai_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 6,
      "article_id": "aibase_aibase_24054",
      "original_id": "aibase_24054",
      "source_table": "aibase_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 7,
      "article_id": "baai_51466",
      "original_id": "51466",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 8,
      "article_id": "aibase_aibase_24026",
      "original_id": "aibase_24026",
      "source_table": "aibase_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 9,
      "article_id": "baai_51489",
      "original_id": "51489",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 10,
      "article_id": "baai_51477",
      "original_id": "51477",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 11,
      "article_id": "baai_51472",
      "original_id": "51472",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 12,
      "article_id": "baai_51468",
      "original_id": "51468",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 13,
      "article_id": "baai_51467",
      "original_id": "51467",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 14,
      "article_id": "aibase_aibase_24042",
      "original_id": "aibase_24042",
      "source_table": "aibase_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 15,
      "article_id": "baai_51501",
      "original_id": "51501",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 16,
      "article_id": "baai_51490",
      "original_id": "51490",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 17,
      "article_id": "baai_51496",
      "original_id": "51496",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 18,
      "article_id": "baai_51485",
      "original_id": "51485",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 19,
      "article_id": "baai_51481",
      "original_id": "51481",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 20,
      "article_id": "aibase_aibase_24024",
      "original_id": "aibase_24024",
      "source_table": "aibase_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 21,
      "article_id": "baai_51495",
      "original_id": "51495",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 22,
      "article_id": "baai_51471",
      "original_id": "51471",
      "source_table": "baai_hub_article",
      "report_generated_at": 1766989361,
      "report_file_path": "final_reports/AI_Report_2025-12-29_142241.md"
    },
    {
      "id": 23,
      "article_id": "qbitai_366165",
      "original_id": "366165",
      "source_table": "qbitai_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 24,
      "article_id": "aibase_aibase_24074",
      "original_id": "aibase_24074",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 25,
      "article_id": "aibase_aibase_24092",
      "original_id": "aibase_24092",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 26,
      "article_id": "aibase_aibase_24094",
      "original_id": "aibase_24094",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 27,
      "article_id": "qbitai_366091",
      "original_id": "366091",
      "source_table": "qbitai_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 28,
      "article_id": "aibase_aibase_24077",
      "original_id": "aibase_24077",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 29,
      "article_id": "aibase_aibase_24087",
      "original_id": "aibase_24087",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 30,
      "article_id": "baai_51503",
      "original_id": "51503",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 31,
      "article_id": "baai_51487",
      "original_id": "51487",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 32,
      "article_id": "aibase_aibase_24083",
      "original_id": "aibase_24083",
      "source_table": "aibase_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 33,
      "article_id": "baai_51505",
      "original_id": "51505",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767050937,
      "report_file_path": "final_reports/AI_Report_2025-12-30_072857.md"
    },
    {
      "id": 34,
      "article_id": "aibase_aibase_24110",
      "original_id": "aibase_24110",
      "source_table": "aibase_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 35,
      "article_id": "aibase_aibase_24128",
      "original_id": "aibase_24128",
      "source_table": "aibase_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 36,
      "article_id": "baai_51529",
      "original_id": "51529",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 37,
      "article_id": "baai_51520",
      "original_id": "51520",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 38,
      "article_id": "aibase_aibase_24106",
      "original_id": "aibase_24106",
      "source_table": "aibase_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 39,
      "article_id": "qbitai_366239",
      "original_id": "366239",
      "source_table": "qbitai_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 40,
      "article_id": "aibase_aibase_24132",
      "original_id": "aibase_24132",
      "source_table": "aibase_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 41,
      "article_id": "baai_51511",
      "original_id": "51511",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 42,
      "article_id": "baai_51512",
      "original_id": "51512",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 43,
      "article_id": "baai_51508",
      "original_id": "51508",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 44,
      "article_id": "baai_51521",
      "original_id": "51521",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767137547,
      "report_file_path": "final_reports/AI_Report_2025-12-31_073227.md"
    },
    {
      "id": 45,
      "article_id": "qbitai_366357",
      "original_id": "366357",
      "source_table": "qbitai_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 46,
      "article_id": "aibase_aibase_24167",
      "original_id": "aibase_24167",
      "source_table": "aibase_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 47,
      "article_id": "baai_51558",
      "original_id": "51558",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 48,
      "article_id": "baai_51540",
      "original_id": "51540",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 49,
      "article_id": "qbitai_366290",
      "original_id": "366290",
      "source_table": "qbitai_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 50,
      "article_id": "aibase_aibase_24146",
      "original_id": "aibase_24146",
      "source_table": "aibase_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 51,
      "article_id": "baai_51533",
      "original_id": "51533",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 52,
      "article_id": "baai_51548",
      "original_id": "51548",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 53,
      "article_id": "baai_51544",
      "original_id": "51544",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 54,
      "article_id": "baai_51556",
      "original_id": "51556",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 55,
      "article_id": "baai_51537",
      "original_id": "51537",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 56,
      "article_id": "baai_51550",
      "original_id": "51550",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767194384,
      "report_file_path": "final_reports/AI_Report_2025-12-31_231944.md"
    },
    {
      "id": 57,
      "article_id": "baai_51514",
      "original_id": "51514",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 58,
      "article_id": "qbitai_366295",
      "original_id": "366295",
      "source_table": "qbitai_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 59,
      "article_id": "qbitai_366280",
      "original_id": "366280",
      "source_table": "qbitai_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 60,
      "article_id": "aibase_aibase_24159",
      "original_id": "aibase_24159",
      "source_table": "aibase_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 61,
      "article_id": "aibase_aibase_24169",
      "original_id": "aibase_24169",
      "source_table": "aibase_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 62,
      "article_id": "aibase_aibase_24157",
      "original_id": "aibase_24157",
      "source_table": "aibase_article",
      "report_generated_at": 1767223679,
      "report_file_path": "final_reports/AI_Report_2026-01-01_072759.md"
    },
    {
      "id": 63,
      "article_id": "baai_51575",
      "original_id": "51575",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 64,
      "article_id": "baai_51568",
      "original_id": "51568",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 65,
      "article_id": "baai_51574",
      "original_id": "51574",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 66,
      "article_id": "baai_51591",
      "original_id": "51591",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 67,
      "article_id": "baai_51589",
      "original_id": "51589",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 68,
      "article_id": "baai_51579",
      "original_id": "51579",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 69,
      "article_id": "baai_51564",
      "original_id": "51564",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 70,
      "article_id": "qbitai_366378",
      "original_id": "366378",
      "source_table": "qbitai_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 71,
      "article_id": "baai_51567",
      "original_id": "51567",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 72,
      "article_id": "baai_51584",
      "original_id": "51584",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 73,
      "article_id": "baai_51573",
      "original_id": "51573",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 74,
      "article_id": "baai_51581",
      "original_id": "51581",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767310137,
      "report_file_path": "final_reports/AI_Report_2026-01-02_072857.md"
    },
    {
      "id": 75,
      "article_id": "baai_51604",
      "original_id": "51604",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    },
    {
      "id": 76,
      "article_id": "baai_51593",
      "original_id": "51593",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    },
    {
      "id": 77,
      "article_id": "baai_51601",
      "original_id": "51601",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    },
    {
      "id": 78,
      "article_id": "baai_51594",
      "original_id": "51594",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    },
    {
      "id": 79,
      "article_id": "baai_51600",
      "original_id": "51600",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    },
    {
      "id": 80,
      "article_id": "baai_51602",
      "original_id": "51602",
      "source_table": "baai_hub_article",
      "report_generated_at": 1767396426,
      "report_file_path": "final_reports/AI_Report_2026-01-03_072706.md"
    }
  ]
}