# AI 前沿动态速报 (2025-12-28 至 2025-12-29)

## ⚡ 本期速览

- **[大模型]** **ChatGPT Will Launch Skills! OpenAI's Internal Codename: Hazelnut**: OpenAI正在秘密开发代号为“Hazelnut”的新功能，旨在为ChatGPT构建“能力操作系统”，支持可组合、可移植的技能及代码执行，预计2026年初发布。
- **[开源]** **英伟达成美国大模型开源标杆：Nemotron 3连训练配方都公开**: 英伟达发布Nemotron 3系列模型，不仅开源模型权重，还公开了超10万亿token数据及完整训练配方，性能媲美主流模型且速度大幅提升。
- **[Agent]** **Meta公布“超级智能”新进展：无需人类，软件Agent即可自我训练！**: Meta提出Self-play SWE-RL（SSR）训练范式，让软件工程智能体通过自我对弈在无监督环境下自主进化，摆脱对人类数据的依赖。
- **[自动驾驶]** **特斯拉通过「物理图灵测试」！英伟达机器人主管爆吹**: 英伟达机器人主管Jim Fan亲测特斯拉FSD v14后给予高度评价，认为其展现了接近人类的驾驶能力，标志着AI在真实物理世界中的重大突破。
- **[多模态]** **ViT一作盛赞：这个中国开源“PS模型”强过Nano Banana**: ViT核心作者Lucas Beyer盛赞通义千问开源的Qwen-Image-Layered模型，认为其在图像处理能力上表现卓越，超越了ChatGPT和Nano Banana。
- **[大模型]** **2.6B Parameters Outperform Billion-Level Giants! Liquid AI Releases New Experimental Model**: 边缘AI初创公司Liquid AI发布仅2.6B参数的实验性模型LFM2-2.6B-Exp，以小博大，性能表现超越众多十亿级参数的大模型。
- **[算力]** **推理成本打到1元/每百万token，浪潮信息撬动Agent规模化的“最后一公里”**: 浪潮信息推出元脑HC1000服务器，将AI推理成本大幅降至1元/每百万token，有望破解产业化成本瓶颈，加速Agent规模化落地。
- **[AIGC]** **Xiaohongshu Open Sources InstanceAssemble! A Lightweight Layout-Controlled Generation Framework**: 小红书开源轻量级布局控制生成框架InstanceAssemble，进一步突破了复杂多实例图像生成的精度限制，推动AIGC向精准控制发展。
- **[AI制药]** **Proc. Natl. Acad. Sci. | 基于扩散模型侧链组装的柔性蛋白质-配体对接**: 研究提出利用扩散模型进行侧链组装，以更准确地捕捉蛋白质与配体结合时的动态构象变化，对新药开发具有重要意义。
- **[科学计算]** **Nat. Comput. Sci. | 深度学习驱动的电子结构计算**: 综述文章指出深度学习正在革新电子结构计算，通过DL-QMC和DL-DFT两条路线，分别在提升计算精度和加速计算效率上展现巨大潜力。

---

## 1. AI 基础设施

### **浪潮HC1000击穿推理成本**

> **概要**：浪潮信息发布元脑HC1000超扩展AI服务器，通过架构创新将大模型推理成本首次击穿至1元/每百万token。该产品旨在解决智能体规模化落地的成本瓶颈，应对未来Token消耗量的指数级增长挑战。

**💡内容详解**

 - **推理成本突破与产业意义**
     - **击穿1元底价**：将推理成本降低至1元/每百万token，相比当前主流模型（如Claude、Grok等约10-15美元）实现数量级下降。这一突破对于打破智能体产业化落地的“最后一公里”至关重要，避免了“杰文斯悖论”在Token经济中重演，即技术进步导致资源消耗激增带来的成本压力。
     - **应对指数级增长**：随着AI应用从简单问答转向支持超长上下文和多步规划的智能体，Token需求呈指数级增长。低成本是AI成为像“水电煤”一样基础资源的生存入场券。

 - **DirectCom极速架构创新**
     - **全对称设计**：采用全新设计的全对称DirectCom极速架构，每计算模组配置16颗AIPU。该架构解决了传统架构中的协议转换和带宽争抢问题，实现了超低延迟和全局无阻塞通信。
     - **无损超扩展**：支持超大规模无损扩展，通过算网深度协同，推理性能提升1.75倍。架构允许计算和通信的均衡配比，最大化资源利用率。

 - **精细化计算策略与效率提升**
     - **灵活的负载拆分**：支持P/D（Prefill/Decode）分离、A/F分离、KV并行等策略。针对推理负载特性（如KV Cache增长带来的存储墙问题），允许不同计算模块按需配置，将单卡MFU（模型算力利用率）最高提升5.7倍。
     - **智能流量调度**：通过自适应路由和智能拥塞控制算法，实现KV Cache传输和All-to-All通信流量的智能调度，显著降低数据传输对计算实例的影响。

---

## 2. AI 模型与技术

### **英伟达开源Nemotron 3**

> **概要**：英伟达发布并开源了Nemotron 3模型家族，采用Mamba-Transformer混合架构和NVFP4低精度训练技术。该系列模型在保持高性能的同时显著提升了推理吞吐量，并公开了包括10万亿token数据、训练配方及后训练软件在内的完整全栈资源。

**💡内容详解**

- **混合架构设计**
    - **Mamba-Transformer混合**
    为最大化推理效率，模型大量使用Mamba-2层替代自注意力层，仅保留少量注意力层。在长序列推理中，这种设计使吞吐量提升显著，例如Nano型号在8k输入下吞吐量是同级模型的3.3倍。
    - **LatentMoE机制**
    针对大规模模型，提出LatentMoE架构。通过将token投影到低维潜在空间进行专家路由和计算，降低了显存读取和通信开销，在保持参数量不变的情况下增加了专家数量，显著提升了代码和数学任务表现。

- **训练与后训练技术**
    - **NVFP4低精度训练**
    采用NVFP4（4位浮点）格式训练了25万亿token。通过保留关键层（如Mamba输出投影）的高精度，实现了与BF16训练几乎相同的准确率，同时在GB200上大幅提升了训练吞吐量。
    - **多环境强化学习**
    后训练阶段采用多环境同步RL，覆盖数学、代码等多种任务。利用混合架构的高效推理生成海量样本，配合异步RL架构和GRPO算法，避免了分阶段训练的能力退化，实现了各领域能力的同步提升。

[相关论文](https://arxiv.org/abs/2512.20856)
### **Meta发布SSR自进化Agent**

> **概要**：Meta与UIUC联合推出Self-play SWE-RL（SSR）框架，使软件工程智能体能在无人类数据的环境中自我进化。通过“Bug注入”与“Bug修复”的双角色自博弈机制，智能体在沙盒中自主生成并解决问题，在SWE-bench测试中超越了传统强化学习基线。

**💡内容详解**

- **SSR自博弈框架**
    - **双角色协同演化**
    框架包含“Bug注入”和“Bug修复”两个角色。注入者通过删除关键代码或回滚修复来制造高质量难题，修复者则在沙盒中尝试解决。两者共享参数并在博弈中不断提升，形成无需人工标注的闭环。
    - **无监督环境适应**
    SSR仅需访问代码仓库和依赖项，无需人工设计的测试用例。智能体通过与环境交互自主探索测试结构，利用逆向变异测试验证题目有效性，具备极强的通用性和低迁移成本。

- **训练效果与验证**
    - **超越基线性能**
    在SWE-bench测试中，SSR在不接触任务描述的情况下持续提升性能，优于传统强化学习基线。实验证明，模型自主生成的任务比人工构造的数据能提供更有效的信息量。
    - **动态任务分布**
    完整的自博弈（同时进行注入和修复）优于单一训练。随着训练进行，任务分布动态演化，持续提供处于“跳一跳够得着”难度的学习信号，避免了静态数据集导致的过拟合或学习停滞。

[相关论文](https://arxiv.org/pdf/2512.18552)
### **通义千问开源PS级修图模型**

> **概要**：阿里通义千问团队开源了名为Qwen-Image-Layered的新模型，被ViT核心作者Lucas Beyer盛赞强于Nano Banana。该模型基于扩散模型技术，能将普通图片拆解为带有透明度信息的多个图层，实现PS级别的精细化编辑与二次创作。

**💡内容详解**

- **PS级“拆图”能力**
    - **智能分层与透明度生成**
    不同于传统的生图模型，Qwen-Image-Layered的核心能力是将一张普通的RGB图片分解为多个包含RGBA（红绿蓝+透明度）信息的独立图层。它可以自动识别背景、人物、装饰等元素，并将其完美分离，互不干扰。
    - **精细化二次编辑**
    基于分层结果，用户可以实现真正的局部修改。例如，只替换背景颜色而不影响主体，或者将长发人物无缝替换为短发版本。模型还支持删除特定元素、调整元素大小比例，甚至修改局部文字，解决了以往AI生图“一处改动全图重画”的痛点。

- **技术架构创新**
    - **四通道 RGBA-VAE**
    为了处理透明度信息，团队设计了专门的RGBA-VAE，将RGB输入和RGBA输出统一压缩到同一个隐藏空间。模型在初始化阶段复用预训练参数，并自动将Alpha通道补全，使其天生“懂透明”。
    - **Transformer-VLD-MMDiT**
    模型核心采用Transformer-VLD-MMDiT架构，能根据图片复杂度自动决定拆分层数。配合Layer3D RoPE（三维位置编码），模型能精准标记图层的空间层级和顺序，有效解决遮挡问题。

- **训练策略与无限分解**
    - **渐进式训练**
    训练过程分为三个阶段：从文本生成单RGBA图层，到多图层合成，最后实现从图片反向拆解多图层。这种策略结合重建损失和感知损失，确保了语义分离的干净程度。
    - **递归分解潜力**
    模型支持对已分解的图层进行再次分解，理论上可实现无限层级的拆解。例如，可以将人物层进一步拆解为线稿层和上色层，极大地扩展了创作和编辑的自由度。

[相关论文](https://github.com/QwenLM/Qwen-Image-Layered)
### **Liquid AI发布2.6B强力模型**

[阅读原文](https://www.aibase.com/news/24054)  `[2025-12-29]`

> **概要**：边缘AI初创公司Liquid AI发布了仅26亿参数的实验性模型LFM2-2.6B-Exp，在指令遵循等基准测试中表现惊人，甚至超越了千亿参数级别的DeepSeek R1。该模型采用纯强化学习优化，专为端侧设备设计，被誉为“最强3B模型”。

**💡内容详解**

- **小参数高性能的突破**
    - **越级挑战巨头**
    尽管只有2.6B参数，LFM2-2.6B-Exp在IFBench（指令遵循）测试中大幅领先同类模型，甚至击败了参数量大263倍的DeepSeek R1-0528。在研究生级知识问答（GPQA）中达到约42%，数学推理（GSM8K）得分超82%，优于Llama3.2 3B和Gemma3系列。
    - **纯强化学习驱动**
    该模型基于LFM2基础架构，摒弃了传统的监督微调（SFT）预热和教师模型蒸馏，完全通过纯强化学习（RL）进行优化。这种训练范式证明了智能训练策略可以弥补参数量的不足。

- **专为边缘计算设计**
    - **混合架构优势**
    模型继承了LFM2的混合架构，结合了短程门控卷积和分组查询注意力（GQA），支持32K上下文长度。这种设计使其在智能手机、笔记本电脑和IoT设备上能高效运行。
    - **极致效率**
    在CPU上的预填充和解码速度是竞争对手的两倍，且内存占用极低。支持bfloat16量化，旨在实现“手机上的博士级推理能力”，推动高能效AI在端侧的普及。

- **开源与应用场景**
    - **全面开源**
    模型权重已在Hugging Face上完全开源，允许开发者自由集成。Liquid AI特别强调其在Agent工作流、RAG检索、数据提取和多轮对话中的潜力。
    - **隐私与低延迟**
    对于追求数据隐私、低延迟和低成本的企业及开发者，这款模型提供了极佳的本地化解决方案，标志着边缘智能（Edge AI）生态系统的进一步成熟。

[相关论文](https://huggingface.co/LiquidAI/LFM2-2.6B-Exp)
### **小红书开源InstanceAssemble**

[阅读原文](https://github.com/FireRedTeam/InstanceAssemble)  `[2025-12-29]`

> **概要**：小红书AIGC团队开源了轻量级布局控制生成框架InstanceAssemble，专为解决多对象、复杂空间关系的图像生成难题。该框架通过级联架构和轻量级适配器，在保持极低参数增加的同时，显著提升了生成图像的布局精准度和语义一致性。

**💡内容详解**

 - **级联两阶段建模架构**
     - **语义理解与空间组装**：采用创新的级联架构。第一阶段进行语义理解，分析文本描述与布局指令的关系；第二阶段通过自研的Assemble-Attention机制进行空间组装，动态建模实例间的相对位置、遮挡关系和层级结构，有效解决了“多对象堆叠”时的错位和语义不匹配问题。

 - **超轻量级LoRA适配**
     - **极低参数量增加**：为了降低部署门槛，框架采用LoRA适配器形式。适配Flux.1模型仅需增加0.84%的参数，适配Stable Diffusion 3-Medium仅需3.46%。这意味着用户无需重新训练基座模型，即可在保留原有生成能力的基础上注入强大的布局控制能力。

 - **DenseLayout基准与LGS指标**
     - **标准化评估体系**：针对传统IoU指标在密集场景下不准确的问题，小红书发布了DenseLayout评估数据集和可解释性指标LGS（Layout Grounding Score）。LGS从位置准确性、尺度匹配度和语义一致性三个维度量化生成质量，推动了行业对布局控制生成能力的标准化评估。

[相关论文](https://arxiv.org/abs/2509.16691)
### **基于扩散模型的柔性对接**

> **概要**：中国科学院上海药物研究所郑明月团队在PNAS发表新方法PackDock，利用扩散模型和等变图神经网络解决蛋白质-配体柔性对接难题。该方法通过精确建模侧链构象分布，显著提升了在真实药物设计场景中的预测精度和泛化能力。

**💡内容详解**

 - **PackDock核心架构**
     - **物理与AI融合**：PackDock框架整合了物理建模与深度学习。其核心模块PackPocket结合了等变图神经网络与扩散模型，能够学习口袋侧链构象空间的能量景观。通过从蛋白质“自由态”和“配体结合态”的分布中采样，它能高效模拟结合过程中的构象变化，避免了传统方法繁琐的迭代采样。

 - **解决柔性与结构偏差**
     - **鲁棒的交叉对接**：针对实际应用中常缺乏目标配体结合结构（Holo）的难题，PackDock在以无配体结构（Apo）或非同源结构为输入时，表现出优于现有方法的柔性对接性能。它不依赖于对特定配体姿态的“记忆”，而是学习真实的物理相互作用规律，因此在低相似度的分布外样本上具有更好的泛化性。

 - **真实场景应用验证**
     - **发现新骨架抑制剂**：在针对ALDH1B1靶点的前瞻性虚拟筛选中，研究团队利用PackDock成功识别出5个具有新型骨架的活性化合物，其中一个达到纳摩尔级亲和力。这一结果直接验证了该模型在实际药物发现流程中创造价值的能力。

[相关论文](https://doi.org/10.1073/pnas.2511925122)
### **AI重塑电子结构计算**

> **概要**：《Nature Computational Science》发表综述，系统回顾了深度学习在电子结构计算中的两大核心路线：DL-QMC与DL-DFT。前者利用神经网络波函数提升强关联体系精度，后者通过直接预测基本量实现大规模体系的高效模拟，共同推动了量子力学计算在精度与效率上的突破。

**💡内容详解**

 - **深度学习量子蒙特卡罗 (DL-QMC)**
     - **核心机制**
     DL-QMC 使用神经网络（如引入自注意力机制和Transformer结构）作为多电子波函数的表达形式，在变分量子蒙特卡罗框架下优化能量。相比传统波函数假设，神经网络具有更强的表示能力，能更充分地捕捉电子关联效应。
     - **应用边界**
     该方法已在分子、固体及强关联电子系统中达到或逼近化学精度。除了基态能量，还能扩展计算激发态、电偶极矩等静态物性，以及识别量子相变。目前主要受限于计算规模，难以直接用于超大体系。

 - **深度学习密度泛函理论 (DL-DFT)**
     - **效率优先策略**
     DL-DFT 旨在高效模拟真实材料体系，其核心策略是利用神经网络直接预测DFT中的电荷密度、哈密顿量等“基本量”。通过一次性预测收敛结果，可绕过传统自洽场（SCF）迭代，大幅降低计算成本。
     - **物理先验结合**
     该方法的成功高度依赖于物理先验的引入，包括量子近视性原理（局域性）和欧氏群 E(3) 等变性（旋转、平移不变性），这使得模型在保证效率的同时具备良好的泛化能力。

 - **挑战与未来展望**
     - **当前瓶颈**
     DL-QMC 的高通量能力受限，而 DL-DFT 在高阶理论中的适用性仍待验证。此外，构建大规模、高质量的训练数据成本高昂，且模型的自动化后处理与可解释性仍需加强。
     - **融合趋势**
     未来趋势指向 DL-QMC 与 DL-DFT 的深度融合，以及与量子嵌入、多尺度模拟的结合，有望催生新一代通用电子结构计算框架，服务于材料发现与基础科学研究。

[相关论文](https://doi.org/10.1038/s43588-025-00932-4)

---

## 3. AI 应用与智能体

### **特斯拉FSD获赞物理图灵测试**

> **概要**：特斯拉FSD v14.2.2版本近期获得广泛好评，英伟达机器人主管Jim Fan称其通过了“物理图灵测试”，体验令人难以置信。新版本在视觉编码器、路径规划及泊车能力上均有显著升级，展现出更接近人类老司机的驾驶风格。马斯克更是直言其Robotaxi体验近乎完美，正加速追赶Waymo。

**💡内容详解**

- **“物理图灵测试”时刻**
    - **英伟达高管背书**
    英伟达Project GR00T负责人Jim Fan体验后表示，FSD v14是他首次感受到AI通过了物理世界的图灵测试。在长途驾驶中，乘客几乎无法区分驾驶者是神经网络还是真人，这种体验不仅令人上瘾，更标志着AI在物理交互层面的质变。
    - **用户体验升级**
    大量车主反馈新版本解决了以往的痛点，如死胡同识别、拥堵路况下的博弈以及对行人的敏锐感知。驾驶风格更加果断丝滑，不再犹豫不决，被公认为迄今为止最好的FSD版本。

- **v14.2.2 技术核心升级**
    - **视觉编码器增强**
    新版本利用更高分辨率的视觉输入，显著提升了对紧急车辆（警车、消防车）、道路障碍物及手势的识别能力。针对特殊车辆，系统新增了专门的避让和靠边停车逻辑。
    - **动态路径与泊车**
    引入了更动态的路径规划能力，不再死板依赖预设导航，能实时应对拥堵和绕行。泊车功能新增“到达选项”，允许用户选择停车场、路边或地库等具体终点，并能记忆用户的停车偏好。

- **Robotaxi 赛道竞争**
    - **追赶 Waymo**
    尽管Waymo在车队规模（超2500辆）和运营城市上仍占据绝对优势，但特斯拉凭借端到端神经网络架构展现出强大的泛化潜力。马斯克强调特斯拉AI的“智能密度”远超对手，且不受高精地图限制，在极端场景（如停电）下更具适应性。
    - **风格模式细分**
    FSD推送了“SLOTH”（保守）和“MADMAX”（激进）两种速度模式，且系统会根据车主的历史驾驶画像自适应调整决策风格，实现了个性化的自动驾驶体验。

---

## 拓展阅读

### [行业动态]
* [https://dx.doi.org/10.1098/rsos.250921Key](https://dx.doi.org/10.1098/rsos.250921Key) - external
